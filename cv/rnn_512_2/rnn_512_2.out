using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 54, val: 3, test: 0	
vocab size: 91	
creating an rnn with 2 layers	
number of parameters in the model: 881755	
cloning rnn	
cloning criterion	
1/2700 (epoch 0.019), train_loss = 4.64210893, grad/param norm = 5.6153e+00, time/batch = 0.5202s	
2/2700 (epoch 0.037), train_loss = 4.09639289, grad/param norm = 9.7164e+00, time/batch = 0.1531s	
3/2700 (epoch 0.056), train_loss = 5.44089375, grad/param norm = 7.6837e+00, time/batch = 0.1490s	
4/2700 (epoch 0.074), train_loss = 4.91026450, grad/param norm = 6.2909e+00, time/batch = 0.1477s	
5/2700 (epoch 0.093), train_loss = 4.86466072, grad/param norm = 5.7736e+00, time/batch = 0.1429s	
6/2700 (epoch 0.111), train_loss = 4.27136530, grad/param norm = 5.6983e+00, time/batch = 0.1333s	
7/2700 (epoch 0.130), train_loss = 3.89740522, grad/param norm = 4.4736e+00, time/batch = 0.1121s	
8/2700 (epoch 0.148), train_loss = 3.83921845, grad/param norm = 4.7140e+00, time/batch = 0.1446s	
9/2700 (epoch 0.167), train_loss = 3.63962280, grad/param norm = 4.2289e+00, time/batch = 0.1434s	
10/2700 (epoch 0.185), train_loss = 3.51150678, grad/param norm = 3.7994e+00, time/batch = 0.1423s	
11/2700 (epoch 0.204), train_loss = 3.41334242, grad/param norm = 3.6103e+00, time/batch = 0.1633s	
12/2700 (epoch 0.222), train_loss = 3.34061779, grad/param norm = 4.0236e+00, time/batch = 0.1620s	
13/2700 (epoch 0.241), train_loss = 3.34668184, grad/param norm = 3.6548e+00, time/batch = 0.1628s	
14/2700 (epoch 0.259), train_loss = 3.41835097, grad/param norm = 4.1942e+00, time/batch = 0.1624s	
15/2700 (epoch 0.278), train_loss = 3.48631495, grad/param norm = 3.5411e+00, time/batch = 0.1634s	
16/2700 (epoch 0.296), train_loss = 3.44031944, grad/param norm = 3.2168e+00, time/batch = 0.1557s	
17/2700 (epoch 0.315), train_loss = 3.37758253, grad/param norm = 2.7678e+00, time/batch = 0.1410s	
18/2700 (epoch 0.333), train_loss = 3.42577238, grad/param norm = 2.3808e+00, time/batch = 0.1490s	
19/2700 (epoch 0.352), train_loss = 3.42020947, grad/param norm = 2.3280e+00, time/batch = 0.1468s	
20/2700 (epoch 0.370), train_loss = 3.37181091, grad/param norm = 2.5264e+00, time/batch = 0.1443s	
21/2700 (epoch 0.389), train_loss = 3.33449378, grad/param norm = 2.6909e+00, time/batch = 0.1641s	
22/2700 (epoch 0.407), train_loss = 3.38185452, grad/param norm = 2.7529e+00, time/batch = 0.1635s	
23/2700 (epoch 0.426), train_loss = 3.38844253, grad/param norm = 2.7725e+00, time/batch = 0.1633s	
24/2700 (epoch 0.444), train_loss = 3.31729544, grad/param norm = 3.0506e+00, time/batch = 0.1637s	
25/2700 (epoch 0.463), train_loss = 3.37931920, grad/param norm = 3.2064e+00, time/batch = 0.1630s	
26/2700 (epoch 0.481), train_loss = 3.45239858, grad/param norm = 3.0938e+00, time/batch = 0.1554s	
27/2700 (epoch 0.500), train_loss = 3.48704040, grad/param norm = 3.1491e+00, time/batch = 0.1443s	
28/2700 (epoch 0.519), train_loss = 3.44773825, grad/param norm = 3.1855e+00, time/batch = 0.1523s	
29/2700 (epoch 0.537), train_loss = 3.45279790, grad/param norm = 2.8803e+00, time/batch = 0.1512s	
30/2700 (epoch 0.556), train_loss = 3.41061234, grad/param norm = 2.7929e+00, time/batch = 0.1476s	
31/2700 (epoch 0.574), train_loss = 3.30226118, grad/param norm = 2.3609e+00, time/batch = 0.1635s	
32/2700 (epoch 0.593), train_loss = 3.32981682, grad/param norm = 3.2310e+00, time/batch = 0.1644s	
33/2700 (epoch 0.611), train_loss = 3.31499170, grad/param norm = 2.8722e+00, time/batch = 0.1643s	
34/2700 (epoch 0.630), train_loss = 3.29408033, grad/param norm = 2.6913e+00, time/batch = 0.1640s	
35/2700 (epoch 0.648), train_loss = 3.41366200, grad/param norm = 2.6795e+00, time/batch = 0.1634s	
36/2700 (epoch 0.667), train_loss = 3.32621497, grad/param norm = 2.7416e+00, time/batch = 0.1550s	
37/2700 (epoch 0.685), train_loss = 3.33345335, grad/param norm = 2.5732e+00, time/batch = 0.1450s	
38/2700 (epoch 0.704), train_loss = 3.33178603, grad/param norm = 3.0018e+00, time/batch = 0.1525s	
39/2700 (epoch 0.722), train_loss = 3.35826605, grad/param norm = 2.7741e+00, time/batch = 0.1515s	
40/2700 (epoch 0.741), train_loss = 3.43820367, grad/param norm = 2.5819e+00, time/batch = 0.1467s	
41/2700 (epoch 0.759), train_loss = 3.40634167, grad/param norm = 2.9115e+00, time/batch = 0.1660s	
42/2700 (epoch 0.778), train_loss = 3.40544152, grad/param norm = 3.2055e+00, time/batch = 0.1651s	
43/2700 (epoch 0.796), train_loss = 3.43154582, grad/param norm = 3.2023e+00, time/batch = 0.1701s	
44/2700 (epoch 0.815), train_loss = 3.31566932, grad/param norm = 3.2581e+00, time/batch = 0.1714s	
45/2700 (epoch 0.833), train_loss = 3.39592988, grad/param norm = 3.3565e+00, time/batch = 0.1687s	
46/2700 (epoch 0.852), train_loss = 3.34685543, grad/param norm = 3.2814e+00, time/batch = 0.1617s	
47/2700 (epoch 0.870), train_loss = 3.35950495, grad/param norm = 2.8993e+00, time/batch = 0.1279s	
48/2700 (epoch 0.889), train_loss = 3.35401412, grad/param norm = 2.9820e+00, time/batch = 0.1528s	
49/2700 (epoch 0.907), train_loss = 3.44584189, grad/param norm = 3.2678e+00, time/batch = 0.1507s	
50/2700 (epoch 0.926), train_loss = 3.38999146, grad/param norm = 3.1301e+00, time/batch = 0.1523s	
51/2700 (epoch 0.944), train_loss = 3.40572855, grad/param norm = 2.7050e+00, time/batch = 0.1645s	
52/2700 (epoch 0.963), train_loss = 3.43764200, grad/param norm = 2.5107e+00, time/batch = 0.1717s	
53/2700 (epoch 0.981), train_loss = 3.50479752, grad/param norm = 2.5114e+00, time/batch = 0.1680s	
54/2700 (epoch 1.000), train_loss = 3.42491424, grad/param norm = 2.6629e+00, time/batch = 0.1682s	
55/2700 (epoch 1.019), train_loss = 3.33806977, grad/param norm = 2.6855e+00, time/batch = 0.1668s	
56/2700 (epoch 1.037), train_loss = 3.38167474, grad/param norm = 2.9546e+00, time/batch = 0.1678s	
57/2700 (epoch 1.056), train_loss = 3.37517759, grad/param norm = 2.6073e+00, time/batch = 0.1504s	
58/2700 (epoch 1.074), train_loss = 3.37954524, grad/param norm = 2.4423e+00, time/batch = 0.1355s	
59/2700 (epoch 1.093), train_loss = 3.40554710, grad/param norm = 2.7225e+00, time/batch = 0.1425s	
60/2700 (epoch 1.111), train_loss = 3.41809896, grad/param norm = 3.0704e+00, time/batch = 0.1468s	
61/2700 (epoch 1.130), train_loss = 3.44196436, grad/param norm = 3.3395e+00, time/batch = 0.1465s	
62/2700 (epoch 1.148), train_loss = 3.40937539, grad/param norm = 3.5179e+00, time/batch = 0.1504s	
63/2700 (epoch 1.167), train_loss = 3.39957167, grad/param norm = 3.4161e+00, time/batch = 0.1552s	
64/2700 (epoch 1.185), train_loss = 3.37717766, grad/param norm = 3.1485e+00, time/batch = 0.1616s	
65/2700 (epoch 1.204), train_loss = 3.29165412, grad/param norm = 3.0405e+00, time/batch = 0.1796s	
66/2700 (epoch 1.222), train_loss = 3.26575046, grad/param norm = 3.3189e+00, time/batch = 0.1962s	
67/2700 (epoch 1.241), train_loss = 3.29036283, grad/param norm = 3.2083e+00, time/batch = 0.1974s	
68/2700 (epoch 1.259), train_loss = 3.36831444, grad/param norm = 3.7280e+00, time/batch = 0.2062s	
69/2700 (epoch 1.278), train_loss = 3.46685056, grad/param norm = 3.4591e+00, time/batch = 0.2347s	
70/2700 (epoch 1.296), train_loss = 3.38435532, grad/param norm = 2.6913e+00, time/batch = 0.2344s	
71/2700 (epoch 1.315), train_loss = 3.35674335, grad/param norm = 2.1609e+00, time/batch = 0.2229s	
72/2700 (epoch 1.333), train_loss = 3.41554445, grad/param norm = 1.8988e+00, time/batch = 0.2276s	
73/2700 (epoch 1.352), train_loss = 3.42274179, grad/param norm = 1.9468e+00, time/batch = 0.2286s	
74/2700 (epoch 1.370), train_loss = 3.40789364, grad/param norm = 2.4831e+00, time/batch = 0.2240s	
75/2700 (epoch 1.389), train_loss = 3.37072263, grad/param norm = 2.7741e+00, time/batch = 0.2208s	
76/2700 (epoch 1.407), train_loss = 3.41590590, grad/param norm = 2.8029e+00, time/batch = 0.2112s	
77/2700 (epoch 1.426), train_loss = 3.40503415, grad/param norm = 2.8077e+00, time/batch = 0.1906s	
78/2700 (epoch 1.444), train_loss = 3.31597355, grad/param norm = 2.9121e+00, time/batch = 0.1876s	
79/2700 (epoch 1.463), train_loss = 3.37431396, grad/param norm = 3.2427e+00, time/batch = 0.2166s	
80/2700 (epoch 1.481), train_loss = 3.45844122, grad/param norm = 3.4038e+00, time/batch = 0.2240s	
81/2700 (epoch 1.500), train_loss = 3.50373231, grad/param norm = 3.1047e+00, time/batch = 0.2164s	
82/2700 (epoch 1.519), train_loss = 3.42513302, grad/param norm = 2.7438e+00, time/batch = 0.2278s	
83/2700 (epoch 1.537), train_loss = 3.43217965, grad/param norm = 2.6965e+00, time/batch = 0.2354s	
84/2700 (epoch 1.556), train_loss = 3.40230672, grad/param norm = 2.7101e+00, time/batch = 0.2343s	
85/2700 (epoch 1.574), train_loss = 3.33374931, grad/param norm = 2.8613e+00, time/batch = 0.2271s	
86/2700 (epoch 1.593), train_loss = 3.41844052, grad/param norm = 3.6230e+00, time/batch = 0.2356s	
87/2700 (epoch 1.611), train_loss = 3.33425828, grad/param norm = 2.9842e+00, time/batch = 0.2324s	
88/2700 (epoch 1.630), train_loss = 3.31158675, grad/param norm = 3.0630e+00, time/batch = 0.2362s	
89/2700 (epoch 1.648), train_loss = 3.41386435, grad/param norm = 3.0094e+00, time/batch = 0.2123s	
90/2700 (epoch 1.667), train_loss = 3.33845513, grad/param norm = 2.9991e+00, time/batch = 0.2042s	
91/2700 (epoch 1.685), train_loss = 3.34138944, grad/param norm = 2.5580e+00, time/batch = 0.2395s	
92/2700 (epoch 1.704), train_loss = 3.29420729, grad/param norm = 2.7315e+00, time/batch = 0.2296s	
93/2700 (epoch 1.722), train_loss = 3.32964059, grad/param norm = 2.5973e+00, time/batch = 0.2218s	
94/2700 (epoch 1.741), train_loss = 3.42335039, grad/param norm = 2.5288e+00, time/batch = 0.2239s	
95/2700 (epoch 1.759), train_loss = 3.38248456, grad/param norm = 2.9272e+00, time/batch = 0.2091s	
96/2700 (epoch 1.778), train_loss = 3.39333641, grad/param norm = 3.3160e+00, time/batch = 0.1774s	
97/2700 (epoch 1.796), train_loss = 3.43025610, grad/param norm = 3.2209e+00, time/batch = 0.1719s	
98/2700 (epoch 1.815), train_loss = 3.34992841, grad/param norm = 3.4699e+00, time/batch = 0.2138s	
99/2700 (epoch 1.833), train_loss = 3.45966509, grad/param norm = 3.3903e+00, time/batch = 0.2012s	
100/2700 (epoch 1.852), train_loss = 3.37023035, grad/param norm = 3.1215e+00, time/batch = 0.2139s	
101/2700 (epoch 1.870), train_loss = 3.37502068, grad/param norm = 3.0333e+00, time/batch = 0.1976s	
102/2700 (epoch 1.889), train_loss = 3.38001229, grad/param norm = 2.8404e+00, time/batch = 0.1910s	
103/2700 (epoch 1.907), train_loss = 3.40077258, grad/param norm = 3.1167e+00, time/batch = 0.1902s	
104/2700 (epoch 1.926), train_loss = 3.39080495, grad/param norm = 3.2852e+00, time/batch = 0.1914s	
105/2700 (epoch 1.944), train_loss = 3.40684330, grad/param norm = 2.9329e+00, time/batch = 0.1952s	
106/2700 (epoch 1.963), train_loss = 3.47819043, grad/param norm = 2.8753e+00, time/batch = 0.1879s	
107/2700 (epoch 1.981), train_loss = 3.53531599, grad/param norm = 2.6215e+00, time/batch = 0.1748s	
108/2700 (epoch 2.000), train_loss = 3.42105271, grad/param norm = 2.5590e+00, time/batch = 0.1978s	
109/2700 (epoch 2.019), train_loss = 3.32362345, grad/param norm = 2.5571e+00, time/batch = 0.1804s	
110/2700 (epoch 2.037), train_loss = 3.37054220, grad/param norm = 2.7846e+00, time/batch = 0.2017s	
111/2700 (epoch 2.056), train_loss = 3.36284597, grad/param norm = 2.6117e+00, time/batch = 0.1931s	
112/2700 (epoch 2.074), train_loss = 3.37591298, grad/param norm = 2.5089e+00, time/batch = 0.2091s	
113/2700 (epoch 2.093), train_loss = 3.41525025, grad/param norm = 2.6284e+00, time/batch = 0.2176s	
114/2700 (epoch 2.111), train_loss = 3.40851463, grad/param norm = 2.9843e+00, time/batch = 0.2189s	
115/2700 (epoch 2.130), train_loss = 3.43446432, grad/param norm = 3.1548e+00, time/batch = 0.2214s	
116/2700 (epoch 2.148), train_loss = 3.39990554, grad/param norm = 3.4593e+00, time/batch = 0.2248s	
117/2700 (epoch 2.167), train_loss = 3.43028218, grad/param norm = 3.2663e+00, time/batch = 0.2013s	
118/2700 (epoch 2.185), train_loss = 3.36076657, grad/param norm = 2.9126e+00, time/batch = 0.2161s	
119/2700 (epoch 2.204), train_loss = 3.28856351, grad/param norm = 2.9073e+00, time/batch = 0.1981s	
120/2700 (epoch 2.222), train_loss = 3.26853641, grad/param norm = 3.3070e+00, time/batch = 0.1708s	
121/2700 (epoch 2.241), train_loss = 3.27696868, grad/param norm = 2.9273e+00, time/batch = 0.2235s	
122/2700 (epoch 2.259), train_loss = 3.31068560, grad/param norm = 3.0566e+00, time/batch = 0.2079s	
123/2700 (epoch 2.278), train_loss = 3.42599113, grad/param norm = 3.3122e+00, time/batch = 0.1941s	
124/2700 (epoch 2.296), train_loss = 3.40312590, grad/param norm = 2.8975e+00, time/batch = 0.2001s	
125/2700 (epoch 2.315), train_loss = 3.35529605, grad/param norm = 2.2814e+00, time/batch = 0.2135s	
126/2700 (epoch 2.333), train_loss = 3.41065010, grad/param norm = 2.0260e+00, time/batch = 0.2222s	
127/2700 (epoch 2.352), train_loss = 3.42268573, grad/param norm = 2.0352e+00, time/batch = 0.2105s	
128/2700 (epoch 2.370), train_loss = 3.39895580, grad/param norm = 2.4869e+00, time/batch = 0.1927s	
129/2700 (epoch 2.389), train_loss = 3.36493745, grad/param norm = 2.6480e+00, time/batch = 0.1997s	
130/2700 (epoch 2.407), train_loss = 3.39411575, grad/param norm = 2.6166e+00, time/batch = 0.1759s	
131/2700 (epoch 2.426), train_loss = 3.38773634, grad/param norm = 2.6237e+00, time/batch = 0.2340s	
132/2700 (epoch 2.444), train_loss = 3.31101227, grad/param norm = 2.9646e+00, time/batch = 0.2336s	
133/2700 (epoch 2.463), train_loss = 3.40585658, grad/param norm = 3.4622e+00, time/batch = 0.2282s	
134/2700 (epoch 2.481), train_loss = 3.50066922, grad/param norm = 3.7210e+00, time/batch = 0.2156s	
135/2700 (epoch 2.500), train_loss = 3.52929794, grad/param norm = 3.2657e+00, time/batch = 0.2064s	
136/2700 (epoch 2.519), train_loss = 3.42211249, grad/param norm = 2.6740e+00, time/batch = 0.1883s	
137/2700 (epoch 2.537), train_loss = 3.42654422, grad/param norm = 2.5605e+00, time/batch = 0.2082s	
138/2700 (epoch 2.556), train_loss = 3.40775155, grad/param norm = 2.7204e+00, time/batch = 0.2276s	
139/2700 (epoch 2.574), train_loss = 3.30351983, grad/param norm = 2.1760e+00, time/batch = 0.2299s	
140/2700 (epoch 2.593), train_loss = 3.34029379, grad/param norm = 2.7441e+00, time/batch = 0.2278s	
141/2700 (epoch 2.611), train_loss = 3.30822717, grad/param norm = 3.0247e+00, time/batch = 0.2366s	
142/2700 (epoch 2.630), train_loss = 3.36063105, grad/param norm = 3.2448e+00, time/batch = 0.2375s	
143/2700 (epoch 2.648), train_loss = 3.46229975, grad/param norm = 3.4044e+00, time/batch = 0.2351s	
144/2700 (epoch 2.667), train_loss = 3.36097807, grad/param norm = 3.2904e+00, time/batch = 0.2344s	
145/2700 (epoch 2.685), train_loss = 3.34838237, grad/param norm = 2.8625e+00, time/batch = 0.2348s	
146/2700 (epoch 2.704), train_loss = 3.31333779, grad/param norm = 3.0913e+00, time/batch = 0.2297s	
147/2700 (epoch 2.722), train_loss = 3.35617618, grad/param norm = 2.8759e+00, time/batch = 0.2318s	
148/2700 (epoch 2.741), train_loss = 3.43178873, grad/param norm = 2.9879e+00, time/batch = 0.2232s	
149/2700 (epoch 2.759), train_loss = 3.45513521, grad/param norm = 3.2691e+00, time/batch = 0.2084s	
150/2700 (epoch 2.778), train_loss = 3.41342909, grad/param norm = 3.1980e+00, time/batch = 0.1778s	
151/2700 (epoch 2.796), train_loss = 3.42897738, grad/param norm = 3.1149e+00, time/batch = 0.2257s	
152/2700 (epoch 2.815), train_loss = 3.33643148, grad/param norm = 3.0623e+00, time/batch = 0.2354s	
153/2700 (epoch 2.833), train_loss = 3.38245310, grad/param norm = 3.1808e+00, time/batch = 0.2339s	
154/2700 (epoch 2.852), train_loss = 3.35230897, grad/param norm = 3.1900e+00, time/batch = 0.2349s	
155/2700 (epoch 2.870), train_loss = 3.36046275, grad/param norm = 2.8798e+00, time/batch = 0.2329s	
156/2700 (epoch 2.889), train_loss = 3.34773880, grad/param norm = 2.8319e+00, time/batch = 0.2256s	
157/2700 (epoch 2.907), train_loss = 3.42020872, grad/param norm = 3.1001e+00, time/batch = 0.2295s	
158/2700 (epoch 2.926), train_loss = 3.43559144, grad/param norm = 3.7742e+00, time/batch = 0.2252s	
159/2700 (epoch 2.944), train_loss = 3.45442435, grad/param norm = 2.9789e+00, time/batch = 0.2235s	
160/2700 (epoch 2.963), train_loss = 3.46055725, grad/param norm = 2.5559e+00, time/batch = 0.2159s	
161/2700 (epoch 2.981), train_loss = 3.50978616, grad/param norm = 2.4449e+00, time/batch = 0.1927s	
162/2700 (epoch 3.000), train_loss = 3.41945503, grad/param norm = 2.4880e+00, time/batch = 0.1727s	
163/2700 (epoch 3.019), train_loss = 3.32788729, grad/param norm = 2.5803e+00, time/batch = 0.1615s	
164/2700 (epoch 3.037), train_loss = 3.37728316, grad/param norm = 2.8567e+00, time/batch = 0.1530s	
165/2700 (epoch 3.056), train_loss = 3.36089241, grad/param norm = 2.5849e+00, time/batch = 0.1666s	
166/2700 (epoch 3.074), train_loss = 3.36419713, grad/param norm = 2.4326e+00, time/batch = 0.1805s	
167/2700 (epoch 3.093), train_loss = 3.40672447, grad/param norm = 2.5689e+00, time/batch = 0.1981s	
168/2700 (epoch 3.111), train_loss = 3.40522463, grad/param norm = 2.9600e+00, time/batch = 0.2026s	
169/2700 (epoch 3.130), train_loss = 3.43836755, grad/param norm = 3.2401e+00, time/batch = 0.2088s	
170/2700 (epoch 3.148), train_loss = 3.40836794, grad/param norm = 3.4868e+00, time/batch = 0.2187s	
171/2700 (epoch 3.167), train_loss = 3.42484387, grad/param norm = 3.2883e+00, time/batch = 0.1995s	
172/2700 (epoch 3.185), train_loss = 3.36865842, grad/param norm = 2.9941e+00, time/batch = 0.2354s	
173/2700 (epoch 3.204), train_loss = 3.29150720, grad/param norm = 2.9968e+00, time/batch = 0.2357s	
174/2700 (epoch 3.222), train_loss = 3.27405814, grad/param norm = 3.3495e+00, time/batch = 0.2232s	
175/2700 (epoch 3.241), train_loss = 3.28338849, grad/param norm = 3.1561e+00, time/batch = 0.2044s	
176/2700 (epoch 3.259), train_loss = 3.34189292, grad/param norm = 3.7553e+00, time/batch = 0.1983s	
177/2700 (epoch 3.278), train_loss = 3.43169806, grad/param norm = 3.1567e+00, time/batch = 0.2045s	
178/2700 (epoch 3.296), train_loss = 3.40423073, grad/param norm = 2.9055e+00, time/batch = 0.2133s	
179/2700 (epoch 3.315), train_loss = 3.37588392, grad/param norm = 2.3677e+00, time/batch = 0.2273s	
180/2700 (epoch 3.333), train_loss = 3.41875773, grad/param norm = 2.1331e+00, time/batch = 0.2347s	
181/2700 (epoch 3.352), train_loss = 3.45385640, grad/param norm = 2.3170e+00, time/batch = 0.2154s	
182/2700 (epoch 3.370), train_loss = 3.43063269, grad/param norm = 2.5247e+00, time/batch = 0.2263s	
183/2700 (epoch 3.389), train_loss = 3.34470659, grad/param norm = 2.6417e+00, time/batch = 0.2366s	
184/2700 (epoch 3.407), train_loss = 3.38436131, grad/param norm = 2.8100e+00, time/batch = 0.2364s	
185/2700 (epoch 3.426), train_loss = 3.39929114, grad/param norm = 2.7931e+00, time/batch = 0.2347s	
186/2700 (epoch 3.444), train_loss = 3.31739263, grad/param norm = 2.9928e+00, time/batch = 0.2357s	
187/2700 (epoch 3.463), train_loss = 3.39882226, grad/param norm = 3.4517e+00, time/batch = 0.2359s	
188/2700 (epoch 3.481), train_loss = 3.48564528, grad/param norm = 3.5708e+00, time/batch = 0.2267s	
189/2700 (epoch 3.500), train_loss = 3.50933455, grad/param norm = 3.1563e+00, time/batch = 0.2134s	
190/2700 (epoch 3.519), train_loss = 3.42189325, grad/param norm = 2.6953e+00, time/batch = 0.1972s	
191/2700 (epoch 3.537), train_loss = 3.42860376, grad/param norm = 2.5928e+00, time/batch = 0.2175s	
192/2700 (epoch 3.556), train_loss = 3.40035538, grad/param norm = 2.5840e+00, time/batch = 0.2155s	
193/2700 (epoch 3.574), train_loss = 3.33711501, grad/param norm = 2.7340e+00, time/batch = 0.1861s	
194/2700 (epoch 3.593), train_loss = 3.43285779, grad/param norm = 3.5250e+00, time/batch = 0.2273s	
195/2700 (epoch 3.611), train_loss = 3.34441218, grad/param norm = 3.1391e+00, time/batch = 0.2166s	
196/2700 (epoch 3.630), train_loss = 3.30470212, grad/param norm = 2.8513e+00, time/batch = 0.2173s	
197/2700 (epoch 3.648), train_loss = 3.40306557, grad/param norm = 3.0846e+00, time/batch = 0.2111s	
198/2700 (epoch 3.667), train_loss = 3.35556133, grad/param norm = 3.3859e+00, time/batch = 0.2085s	
199/2700 (epoch 3.685), train_loss = 3.41926457, grad/param norm = 3.3645e+00, time/batch = 0.2043s	
200/2700 (epoch 3.704), train_loss = 3.45281751, grad/param norm = 3.8015e+00, time/batch = 0.2054s	
201/2700 (epoch 3.722), train_loss = 3.43984801, grad/param norm = 2.9396e+00, time/batch = 0.2288s	
202/2700 (epoch 3.741), train_loss = 3.39598268, grad/param norm = 2.1103e+00, time/batch = 0.2016s	
203/2700 (epoch 3.759), train_loss = 3.36939876, grad/param norm = 2.6054e+00, time/batch = 0.1961s	
204/2700 (epoch 3.778), train_loss = 3.36195372, grad/param norm = 2.9723e+00, time/batch = 0.1727s	
205/2700 (epoch 3.796), train_loss = 3.41450928, grad/param norm = 2.9255e+00, time/batch = 0.1510s	
206/2700 (epoch 3.815), train_loss = 3.34255997, grad/param norm = 3.1860e+00, time/batch = 0.1852s	
207/2700 (epoch 3.833), train_loss = 3.39076459, grad/param norm = 2.9656e+00, time/batch = 0.1979s	
208/2700 (epoch 3.852), train_loss = 3.34782747, grad/param norm = 2.5931e+00, time/batch = 0.2134s	
209/2700 (epoch 3.870), train_loss = 3.33401151, grad/param norm = 2.9959e+00, time/batch = 0.2199s	
210/2700 (epoch 3.889), train_loss = 3.36681655, grad/param norm = 3.0378e+00, time/batch = 0.2248s	
211/2700 (epoch 3.907), train_loss = 3.39926916, grad/param norm = 2.9435e+00, time/batch = 0.2085s	
212/2700 (epoch 3.926), train_loss = 3.35685978, grad/param norm = 2.9528e+00, time/batch = 0.2087s	
213/2700 (epoch 3.944), train_loss = 3.37283719, grad/param norm = 2.6958e+00, time/batch = 0.2310s	
214/2700 (epoch 3.963), train_loss = 3.47036465, grad/param norm = 3.0373e+00, time/batch = 0.2176s	
215/2700 (epoch 3.981), train_loss = 3.53978479, grad/param norm = 2.5098e+00, time/batch = 0.2000s	
216/2700 (epoch 4.000), train_loss = 3.40098170, grad/param norm = 2.5122e+00, time/batch = 0.2066s	
217/2700 (epoch 4.019), train_loss = 3.32711439, grad/param norm = 2.6167e+00, time/batch = 0.1992s	
218/2700 (epoch 4.037), train_loss = 3.37583749, grad/param norm = 2.9601e+00, time/batch = 0.2093s	
219/2700 (epoch 4.056), train_loss = 3.36910253, grad/param norm = 2.6438e+00, time/batch = 0.2205s	
220/2700 (epoch 4.074), train_loss = 3.38801699, grad/param norm = 2.6211e+00, time/batch = 0.2310s	
221/2700 (epoch 4.093), train_loss = 3.44200772, grad/param norm = 2.6235e+00, time/batch = 0.2087s	
222/2700 (epoch 4.111), train_loss = 3.41654611, grad/param norm = 2.9421e+00, time/batch = 0.1978s	
223/2700 (epoch 4.130), train_loss = 3.44531263, grad/param norm = 3.0213e+00, time/batch = 0.2177s	
224/2700 (epoch 4.148), train_loss = 3.38611212, grad/param norm = 3.1570e+00, time/batch = 0.2183s	
225/2700 (epoch 4.167), train_loss = 3.39691134, grad/param norm = 3.2001e+00, time/batch = 0.1768s	
226/2700 (epoch 4.185), train_loss = 3.36022206, grad/param norm = 2.9390e+00, time/batch = 0.2151s	
227/2700 (epoch 4.204), train_loss = 3.29271069, grad/param norm = 2.9468e+00, time/batch = 0.2053s	
228/2700 (epoch 4.222), train_loss = 3.28045831, grad/param norm = 3.3784e+00, time/batch = 0.1898s	
229/2700 (epoch 4.241), train_loss = 3.30039485, grad/param norm = 3.1146e+00, time/batch = 0.1754s	
230/2700 (epoch 4.259), train_loss = 3.34285038, grad/param norm = 3.0292e+00, time/batch = 0.1817s	
231/2700 (epoch 4.278), train_loss = 3.42894223, grad/param norm = 3.3937e+00, time/batch = 0.1657s	
232/2700 (epoch 4.296), train_loss = 3.42175434, grad/param norm = 3.1626e+00, time/batch = 0.1990s	
233/2700 (epoch 4.315), train_loss = 3.38318913, grad/param norm = 2.6316e+00, time/batch = 0.1961s	
234/2700 (epoch 4.333), train_loss = 3.42605189, grad/param norm = 2.3858e+00, time/batch = 0.2121s	
235/2700 (epoch 4.352), train_loss = 3.44459419, grad/param norm = 2.2755e+00, time/batch = 0.2105s	
236/2700 (epoch 4.370), train_loss = 3.40645780, grad/param norm = 2.3027e+00, time/batch = 0.2249s	
237/2700 (epoch 4.389), train_loss = 3.33608712, grad/param norm = 2.3930e+00, time/batch = 0.2188s	
238/2700 (epoch 4.407), train_loss = 3.38104455, grad/param norm = 2.6360e+00, time/batch = 0.2109s	
239/2700 (epoch 4.426), train_loss = 3.41032374, grad/param norm = 2.7449e+00, time/batch = 0.2017s	
240/2700 (epoch 4.444), train_loss = 3.33011023, grad/param norm = 3.1231e+00, time/batch = 0.2008s	
241/2700 (epoch 4.463), train_loss = 3.41795851, grad/param norm = 3.3172e+00, time/batch = 0.1837s	
242/2700 (epoch 4.481), train_loss = 3.45106516, grad/param norm = 2.9761e+00, time/batch = 0.1947s	
243/2700 (epoch 4.500), train_loss = 3.48181732, grad/param norm = 2.7773e+00, time/batch = 0.1953s	
244/2700 (epoch 4.519), train_loss = 3.40656462, grad/param norm = 2.5005e+00, time/batch = 0.2138s	
245/2700 (epoch 4.537), train_loss = 3.41336731, grad/param norm = 2.3484e+00, time/batch = 0.2064s	
246/2700 (epoch 4.556), train_loss = 3.41122866, grad/param norm = 2.8647e+00, time/batch = 0.2353s	
247/2700 (epoch 4.574), train_loss = 3.34298736, grad/param norm = 2.6192e+00, time/batch = 0.2090s	
248/2700 (epoch 4.593), train_loss = 3.40482595, grad/param norm = 3.3480e+00, time/batch = 0.2151s	
249/2700 (epoch 4.611), train_loss = 3.35427593, grad/param norm = 3.0954e+00, time/batch = 0.1981s	
250/2700 (epoch 4.630), train_loss = 3.34654536, grad/param norm = 2.8515e+00, time/batch = 0.1809s	
251/2700 (epoch 4.648), train_loss = 3.40219633, grad/param norm = 2.4243e+00, time/batch = 0.2380s	
252/2700 (epoch 4.667), train_loss = 3.30603616, grad/param norm = 2.2278e+00, time/batch = 0.2279s	
253/2700 (epoch 4.685), train_loss = 3.30724420, grad/param norm = 2.2827e+00, time/batch = 0.2146s	
254/2700 (epoch 4.704), train_loss = 3.30719410, grad/param norm = 3.0194e+00, time/batch = 0.1987s	
255/2700 (epoch 4.722), train_loss = 3.35553086, grad/param norm = 3.0656e+00, time/batch = 0.1905s	
256/2700 (epoch 4.741), train_loss = 3.44594410, grad/param norm = 2.9454e+00, time/batch = 0.1981s	
257/2700 (epoch 4.759), train_loss = 3.42239629, grad/param norm = 3.4153e+00, time/batch = 0.2142s	
258/2700 (epoch 4.778), train_loss = 3.42067750, grad/param norm = 3.4912e+00, time/batch = 0.2018s	
259/2700 (epoch 4.796), train_loss = 3.41981925, grad/param norm = 3.0249e+00, time/batch = 0.2152s	
260/2700 (epoch 4.815), train_loss = 3.34388026, grad/param norm = 3.3026e+00, time/batch = 0.2090s	
261/2700 (epoch 4.833), train_loss = 3.41790091, grad/param norm = 3.0683e+00, time/batch = 0.2357s	
262/2700 (epoch 4.852), train_loss = 3.31331275, grad/param norm = 2.7745e+00, time/batch = 0.2355s	
263/2700 (epoch 4.870), train_loss = 3.33766810, grad/param norm = 2.5585e+00, time/batch = 0.2344s	
264/2700 (epoch 4.889), train_loss = 3.34486810, grad/param norm = 2.6345e+00, time/batch = 0.2036s	
265/2700 (epoch 4.907), train_loss = 3.40540037, grad/param norm = 2.7442e+00, time/batch = 0.2057s	
266/2700 (epoch 4.926), train_loss = 3.39375160, grad/param norm = 3.2735e+00, time/batch = 0.2034s	
267/2700 (epoch 4.944), train_loss = 3.46284876, grad/param norm = 3.4109e+00, time/batch = 0.1945s	
268/2700 (epoch 4.963), train_loss = 3.46570632, grad/param norm = 2.5454e+00, time/batch = 0.1768s	
269/2700 (epoch 4.981), train_loss = 3.48624529, grad/param norm = 2.0639e+00, time/batch = 0.1643s	
270/2700 (epoch 5.000), train_loss = 3.40374449, grad/param norm = 2.3022e+00, time/batch = 0.2167s	
271/2700 (epoch 5.019), train_loss = 3.33324553, grad/param norm = 2.5122e+00, time/batch = 0.2190s	
272/2700 (epoch 5.037), train_loss = 3.38879893, grad/param norm = 2.9753e+00, time/batch = 0.2097s	
273/2700 (epoch 5.056), train_loss = 3.38315484, grad/param norm = 2.7298e+00, time/batch = 0.2044s	
274/2700 (epoch 5.074), train_loss = 3.38281423, grad/param norm = 2.6320e+00, time/batch = 0.1905s	
275/2700 (epoch 5.093), train_loss = 3.42665488, grad/param norm = 2.9196e+00, time/batch = 0.2332s	
276/2700 (epoch 5.111), train_loss = 3.44123905, grad/param norm = 3.3739e+00, time/batch = 0.2350s	
277/2700 (epoch 5.130), train_loss = 3.46305783, grad/param norm = 3.4825e+00, time/batch = 0.2357s	
278/2700 (epoch 5.148), train_loss = 3.40767166, grad/param norm = 3.4889e+00, time/batch = 0.2244s	
279/2700 (epoch 5.167), train_loss = 3.40757744, grad/param norm = 3.2792e+00, time/batch = 0.2139s	
280/2700 (epoch 5.185), train_loss = 3.36440403, grad/param norm = 2.9893e+00, time/batch = 0.1880s	
281/2700 (epoch 5.204), train_loss = 3.28783131, grad/param norm = 2.9143e+00, time/batch = 0.2191s	
282/2700 (epoch 5.222), train_loss = 3.26841844, grad/param norm = 3.3920e+00, time/batch = 0.2235s	
283/2700 (epoch 5.241), train_loss = 3.30424368, grad/param norm = 3.0256e+00, time/batch = 0.2258s	
284/2700 (epoch 5.259), train_loss = 3.33846956, grad/param norm = 2.8643e+00, time/batch = 0.2035s	
285/2700 (epoch 5.278), train_loss = 3.42812917, grad/param norm = 3.2329e+00, time/batch = 0.2311s	
286/2700 (epoch 5.296), train_loss = 3.42608902, grad/param norm = 3.0948e+00, time/batch = 0.2287s	
287/2700 (epoch 5.315), train_loss = 3.38171645, grad/param norm = 2.4704e+00, time/batch = 0.2237s	
288/2700 (epoch 5.333), train_loss = 3.42026406, grad/param norm = 2.1340e+00, time/batch = 0.2186s	
289/2700 (epoch 5.352), train_loss = 3.43221978, grad/param norm = 2.1205e+00, time/batch = 0.2159s	
290/2700 (epoch 5.370), train_loss = 3.40525326, grad/param norm = 2.3585e+00, time/batch = 0.2076s	
291/2700 (epoch 5.389), train_loss = 3.33560971, grad/param norm = 2.5423e+00, time/batch = 0.2386s	
292/2700 (epoch 5.407), train_loss = 3.38677936, grad/param norm = 2.7027e+00, time/batch = 0.2364s	
293/2700 (epoch 5.426), train_loss = 3.38936133, grad/param norm = 2.7911e+00, time/batch = 0.2304s	
294/2700 (epoch 5.444), train_loss = 3.32683261, grad/param norm = 2.9791e+00, time/batch = 0.2248s	
295/2700 (epoch 5.463), train_loss = 3.37119431, grad/param norm = 3.2110e+00, time/batch = 0.2157s	
296/2700 (epoch 5.481), train_loss = 3.46273023, grad/param norm = 3.2951e+00, time/batch = 0.2061s	
297/2700 (epoch 5.500), train_loss = 3.49317420, grad/param norm = 3.1067e+00, time/batch = 0.2061s	
298/2700 (epoch 5.519), train_loss = 3.43524653, grad/param norm = 2.8712e+00, time/batch = 0.2126s	
299/2700 (epoch 5.537), train_loss = 3.45174241, grad/param norm = 2.7315e+00, time/batch = 0.2233s	
300/2700 (epoch 5.556), train_loss = 3.40360096, grad/param norm = 2.7861e+00, time/batch = 0.2254s	
301/2700 (epoch 5.574), train_loss = 3.32114744, grad/param norm = 2.4488e+00, time/batch = 0.2108s	
302/2700 (epoch 5.593), train_loss = 3.31812679, grad/param norm = 2.7761e+00, time/batch = 0.2356s	
303/2700 (epoch 5.611), train_loss = 3.28754813, grad/param norm = 2.7154e+00, time/batch = 0.2284s	
304/2700 (epoch 5.630), train_loss = 3.32185421, grad/param norm = 3.0464e+00, time/batch = 0.2358s	
305/2700 (epoch 5.648), train_loss = 3.43822532, grad/param norm = 3.2062e+00, time/batch = 0.2093s	
306/2700 (epoch 5.667), train_loss = 3.35694824, grad/param norm = 3.2040e+00, time/batch = 0.2063s	
307/2700 (epoch 5.685), train_loss = 3.36766545, grad/param norm = 2.9538e+00, time/batch = 0.2059s	
308/2700 (epoch 5.704), train_loss = 3.33936749, grad/param norm = 3.2019e+00, time/batch = 0.1948s	
309/2700 (epoch 5.722), train_loss = 3.37184378, grad/param norm = 2.6990e+00, time/batch = 0.1951s	
310/2700 (epoch 5.741), train_loss = 3.43561130, grad/param norm = 2.5855e+00, time/batch = 0.1988s	
311/2700 (epoch 5.759), train_loss = 3.42345384, grad/param norm = 3.0623e+00, time/batch = 0.1901s	
312/2700 (epoch 5.778), train_loss = 3.40662835, grad/param norm = 2.8349e+00, time/batch = 0.1931s	
313/2700 (epoch 5.796), train_loss = 3.40669665, grad/param norm = 3.0299e+00, time/batch = 0.2222s	
314/2700 (epoch 5.815), train_loss = 3.31343552, grad/param norm = 2.9948e+00, time/batch = 0.2343s	
315/2700 (epoch 5.833), train_loss = 3.37739067, grad/param norm = 3.2728e+00, time/batch = 0.2267s	
316/2700 (epoch 5.852), train_loss = 3.38228111, grad/param norm = 3.2371e+00, time/batch = 0.2358s	
317/2700 (epoch 5.870), train_loss = 3.34717461, grad/param norm = 3.0411e+00, time/batch = 0.2347s	
318/2700 (epoch 5.889), train_loss = 3.36464270, grad/param norm = 2.9981e+00, time/batch = 0.2347s	
319/2700 (epoch 5.907), train_loss = 3.40877285, grad/param norm = 3.0836e+00, time/batch = 0.2273s	
320/2700 (epoch 5.926), train_loss = 3.42104325, grad/param norm = 3.5604e+00, time/batch = 0.2140s	
321/2700 (epoch 5.944), train_loss = 3.45000271, grad/param norm = 2.9797e+00, time/batch = 0.2379s	
322/2700 (epoch 5.963), train_loss = 3.46215991, grad/param norm = 2.5949e+00, time/batch = 0.2373s	
323/2700 (epoch 5.981), train_loss = 3.50236145, grad/param norm = 2.3710e+00, time/batch = 0.2000s	
324/2700 (epoch 6.000), train_loss = 3.39546035, grad/param norm = 2.2981e+00, time/batch = 0.2016s	
325/2700 (epoch 6.019), train_loss = 3.31070802, grad/param norm = 2.4158e+00, time/batch = 0.2001s	
326/2700 (epoch 6.037), train_loss = 3.36071690, grad/param norm = 2.7053e+00, time/batch = 0.2281s	
327/2700 (epoch 6.056), train_loss = 3.34828449, grad/param norm = 2.4471e+00, time/batch = 0.2361s	
328/2700 (epoch 6.074), train_loss = 3.36071562, grad/param norm = 2.3217e+00, time/batch = 0.2363s	
329/2700 (epoch 6.093), train_loss = 3.42572159, grad/param norm = 2.3789e+00, time/batch = 0.2372s	
330/2700 (epoch 6.111), train_loss = 3.40261962, grad/param norm = 2.7409e+00, time/batch = 0.2364s	
331/2700 (epoch 6.130), train_loss = 3.42824062, grad/param norm = 2.7605e+00, time/batch = 0.2363s	
332/2700 (epoch 6.148), train_loss = 3.37179676, grad/param norm = 3.0171e+00, time/batch = 0.2370s	
333/2700 (epoch 6.167), train_loss = 3.40910743, grad/param norm = 3.5606e+00, time/batch = 0.2221s	
334/2700 (epoch 6.185), train_loss = 3.39118629, grad/param norm = 2.8905e+00, time/batch = 0.2343s	
335/2700 (epoch 6.204), train_loss = 3.28385760, grad/param norm = 3.1556e+00, time/batch = 0.2286s	
336/2700 (epoch 6.222), train_loss = 3.29702259, grad/param norm = 3.4217e+00, time/batch = 0.2367s	
337/2700 (epoch 6.241), train_loss = 3.30471931, grad/param norm = 3.1228e+00, time/batch = 0.2255s	
338/2700 (epoch 6.259), train_loss = 3.36497441, grad/param norm = 3.3280e+00, time/batch = 0.2124s	
339/2700 (epoch 6.278), train_loss = 3.43851751, grad/param norm = 3.3902e+00, time/batch = 0.2027s	
340/2700 (epoch 6.296), train_loss = 3.45608102, grad/param norm = 3.4827e+00, time/batch = 0.1996s	
341/2700 (epoch 6.315), train_loss = 3.39492278, grad/param norm = 2.5366e+00, time/batch = 0.1987s	
342/2700 (epoch 6.333), train_loss = 3.41476637, grad/param norm = 2.1015e+00, time/batch = 0.2034s	
343/2700 (epoch 6.352), train_loss = 3.42805928, grad/param norm = 2.0669e+00, time/batch = 0.2041s	
344/2700 (epoch 6.370), train_loss = 3.40167571, grad/param norm = 2.4916e+00, time/batch = 0.2074s	
345/2700 (epoch 6.389), train_loss = 3.36170544, grad/param norm = 2.6649e+00, time/batch = 0.2199s	
346/2700 (epoch 6.407), train_loss = 3.40657912, grad/param norm = 2.7948e+00, time/batch = 0.1946s	
347/2700 (epoch 6.426), train_loss = 3.39482774, grad/param norm = 2.8977e+00, time/batch = 0.2226s	
348/2700 (epoch 6.444), train_loss = 3.33138046, grad/param norm = 3.0825e+00, time/batch = 0.2130s	
349/2700 (epoch 6.463), train_loss = 3.38810421, grad/param norm = 3.3072e+00, time/batch = 0.2075s	
350/2700 (epoch 6.481), train_loss = 3.48759303, grad/param norm = 3.4053e+00, time/batch = 0.2058s	
351/2700 (epoch 6.500), train_loss = 3.51980632, grad/param norm = 3.3802e+00, time/batch = 0.2021s	
352/2700 (epoch 6.519), train_loss = 3.46485476, grad/param norm = 3.2936e+00, time/batch = 0.2052s	
353/2700 (epoch 6.537), train_loss = 3.46390216, grad/param norm = 2.8953e+00, time/batch = 0.2054s	
354/2700 (epoch 6.556), train_loss = 3.42367057, grad/param norm = 2.8083e+00, time/batch = 0.2272s	
355/2700 (epoch 6.574), train_loss = 3.30449913, grad/param norm = 2.1410e+00, time/batch = 0.2228s	
356/2700 (epoch 6.593), train_loss = 3.31902890, grad/param norm = 2.6828e+00, time/batch = 0.2263s	
357/2700 (epoch 6.611), train_loss = 3.28876938, grad/param norm = 2.5763e+00, time/batch = 0.2336s	
358/2700 (epoch 6.630), train_loss = 3.31226627, grad/param norm = 2.8478e+00, time/batch = 0.2333s	
359/2700 (epoch 6.648), train_loss = 3.43354994, grad/param norm = 2.9444e+00, time/batch = 0.2124s	
360/2700 (epoch 6.667), train_loss = 3.34735819, grad/param norm = 2.9233e+00, time/batch = 0.2013s	
361/2700 (epoch 6.685), train_loss = 3.34963535, grad/param norm = 2.8784e+00, time/batch = 0.2107s	
362/2700 (epoch 6.704), train_loss = 3.35774723, grad/param norm = 3.4860e+00, time/batch = 0.2059s	
363/2700 (epoch 6.722), train_loss = 3.38535573, grad/param norm = 2.9511e+00, time/batch = 0.1797s	
364/2700 (epoch 6.741), train_loss = 3.61040978, grad/param norm = 4.0735e+00, time/batch = 0.1929s	
365/2700 (epoch 6.759), train_loss = 3.73039263, grad/param norm = 3.7114e+00, time/batch = 0.2117s	
366/2700 (epoch 6.778), train_loss = 3.72576566, grad/param norm = 4.3568e+00, time/batch = 0.2062s	
367/2700 (epoch 6.796), train_loss = 3.60700681, grad/param norm = 4.1147e+00, time/batch = 0.2194s	
368/2700 (epoch 6.815), train_loss = 3.53539927, grad/param norm = 3.7678e+00, time/batch = 0.2162s	
369/2700 (epoch 6.833), train_loss = 3.41257224, grad/param norm = 3.7340e+00, time/batch = 0.2152s	
370/2700 (epoch 6.852), train_loss = 3.35476387, grad/param norm = 2.7822e+00, time/batch = 0.2067s	
371/2700 (epoch 6.870), train_loss = 3.28752040, grad/param norm = 2.1597e+00, time/batch = 0.2385s	
372/2700 (epoch 6.889), train_loss = 3.30961966, grad/param norm = 2.0344e+00, time/batch = 0.2325s	
373/2700 (epoch 6.907), train_loss = 3.35118431, grad/param norm = 1.9496e+00, time/batch = 0.2374s	
374/2700 (epoch 6.926), train_loss = 3.31709661, grad/param norm = 2.2678e+00, time/batch = 0.2296s	
375/2700 (epoch 6.944), train_loss = 3.35168801, grad/param norm = 2.6809e+00, time/batch = 0.2138s	
376/2700 (epoch 6.963), train_loss = 3.43787762, grad/param norm = 2.7376e+00, time/batch = 0.2059s	
377/2700 (epoch 6.981), train_loss = 3.50330623, grad/param norm = 2.6522e+00, time/batch = 0.1707s	
378/2700 (epoch 7.000), train_loss = 3.41380944, grad/param norm = 2.5619e+00, time/batch = 0.2181s	
379/2700 (epoch 7.019), train_loss = 3.32863388, grad/param norm = 2.6501e+00, time/batch = 0.2096s	
380/2700 (epoch 7.037), train_loss = 3.37255251, grad/param norm = 2.9397e+00, time/batch = 0.2042s	
381/2700 (epoch 7.056), train_loss = 3.37672505, grad/param norm = 3.2464e+00, time/batch = 0.2354s	
382/2700 (epoch 7.074), train_loss = 3.40592977, grad/param norm = 3.1280e+00, time/batch = 0.2292s	
383/2700 (epoch 7.093), train_loss = 3.41570523, grad/param norm = 2.9965e+00, time/batch = 0.2356s	
384/2700 (epoch 7.111), train_loss = 3.39186026, grad/param norm = 2.4355e+00, time/batch = 0.2331s	
385/2700 (epoch 7.130), train_loss = 3.37003822, grad/param norm = 2.0036e+00, time/batch = 0.2319s	
386/2700 (epoch 7.148), train_loss = 3.31859171, grad/param norm = 2.1186e+00, time/batch = 0.2223s	
387/2700 (epoch 7.167), train_loss = 3.34559163, grad/param norm = 2.6194e+00, time/batch = 0.1834s	
388/2700 (epoch 7.185), train_loss = 3.34760374, grad/param norm = 2.7048e+00, time/batch = 0.1902s	
389/2700 (epoch 7.204), train_loss = 3.27579259, grad/param norm = 2.7340e+00, time/batch = 0.2217s	
390/2700 (epoch 7.222), train_loss = 3.25344072, grad/param norm = 2.9641e+00, time/batch = 0.2358s	
391/2700 (epoch 7.241), train_loss = 3.33301476, grad/param norm = 3.5293e+00, time/batch = 0.2124s	
392/2700 (epoch 7.259), train_loss = 3.40947546, grad/param norm = 3.7315e+00, time/batch = 0.2246s	
393/2700 (epoch 7.278), train_loss = 3.45970695, grad/param norm = 3.6139e+00, time/batch = 0.2369s	
394/2700 (epoch 7.296), train_loss = 3.46230353, grad/param norm = 3.5351e+00, time/batch = 0.2292s	
395/2700 (epoch 7.315), train_loss = 3.39018041, grad/param norm = 2.9682e+00, time/batch = 0.2236s	
396/2700 (epoch 7.333), train_loss = 3.44766095, grad/param norm = 2.6017e+00, time/batch = 0.2219s	
397/2700 (epoch 7.352), train_loss = 3.44470126, grad/param norm = 2.5148e+00, time/batch = 0.2130s	
398/2700 (epoch 7.370), train_loss = 3.42644711, grad/param norm = 2.3786e+00, time/batch = 0.2139s	
399/2700 (epoch 7.389), train_loss = 3.35439541, grad/param norm = 2.3018e+00, time/batch = 0.1893s	
400/2700 (epoch 7.407), train_loss = 3.38227947, grad/param norm = 2.3184e+00, time/batch = 0.1833s	
401/2700 (epoch 7.426), train_loss = 3.38649208, grad/param norm = 2.4672e+00, time/batch = 0.2189s	
402/2700 (epoch 7.444), train_loss = 3.30163429, grad/param norm = 2.5462e+00, time/batch = 0.1992s	
403/2700 (epoch 7.463), train_loss = 3.36234910, grad/param norm = 2.7990e+00, time/batch = 0.1943s	
404/2700 (epoch 7.481), train_loss = 3.45220886, grad/param norm = 2.7304e+00, time/batch = 0.2096s	
405/2700 (epoch 7.500), train_loss = 3.47148743, grad/param norm = 2.4737e+00, time/batch = 0.2221s	
406/2700 (epoch 7.519), train_loss = 3.41930283, grad/param norm = 2.3094e+00, time/batch = 0.2345s	
407/2700 (epoch 7.537), train_loss = 3.42560532, grad/param norm = 2.5161e+00, time/batch = 0.2299s	
408/2700 (epoch 7.556), train_loss = 3.41099775, grad/param norm = 2.7408e+00, time/batch = 0.2266s	
409/2700 (epoch 7.574), train_loss = 3.34539950, grad/param norm = 3.1796e+00, time/batch = 0.2152s	
410/2700 (epoch 7.593), train_loss = 3.39629813, grad/param norm = 3.6136e+00, time/batch = 0.2204s	
411/2700 (epoch 7.611), train_loss = 3.31666076, grad/param norm = 3.3632e+00, time/batch = 0.2345s	
412/2700 (epoch 7.630), train_loss = 3.33223387, grad/param norm = 3.1798e+00, time/batch = 0.2375s	
413/2700 (epoch 7.648), train_loss = 3.40983705, grad/param norm = 3.0804e+00, time/batch = 0.2362s	
414/2700 (epoch 7.667), train_loss = 3.35217217, grad/param norm = 3.1401e+00, time/batch = 0.2350s	
415/2700 (epoch 7.685), train_loss = 3.36113659, grad/param norm = 3.2901e+00, time/batch = 0.2370s	
416/2700 (epoch 7.704), train_loss = 3.35033926, grad/param norm = 3.3867e+00, time/batch = 0.2269s	
417/2700 (epoch 7.722), train_loss = 3.37557425, grad/param norm = 3.3468e+00, time/batch = 0.2115s	
418/2700 (epoch 7.741), train_loss = 3.45584728, grad/param norm = 3.1969e+00, time/batch = 0.1901s	
419/2700 (epoch 7.759), train_loss = 3.38052394, grad/param norm = 2.7813e+00, time/batch = 0.1862s	
420/2700 (epoch 7.778), train_loss = 3.37279565, grad/param norm = 2.4552e+00, time/batch = 0.1847s	
421/2700 (epoch 7.796), train_loss = 3.38074338, grad/param norm = 2.1292e+00, time/batch = 0.2208s	
422/2700 (epoch 7.815), train_loss = 3.29539340, grad/param norm = 2.2582e+00, time/batch = 0.2336s	
423/2700 (epoch 7.833), train_loss = 3.34291612, grad/param norm = 2.2713e+00, time/batch = 0.2340s	
424/2700 (epoch 7.852), train_loss = 3.30306218, grad/param norm = 2.1283e+00, time/batch = 0.2345s	
425/2700 (epoch 7.870), train_loss = 3.29564525, grad/param norm = 2.0461e+00, time/batch = 0.2350s	
426/2700 (epoch 7.889), train_loss = 3.32730091, grad/param norm = 2.1165e+00, time/batch = 0.2349s	
427/2700 (epoch 7.907), train_loss = 3.39441866, grad/param norm = 2.3721e+00, time/batch = 0.2314s	
428/2700 (epoch 7.926), train_loss = 3.40260848, grad/param norm = 2.9639e+00, time/batch = 0.2034s	
429/2700 (epoch 7.944), train_loss = 3.43914866, grad/param norm = 3.2570e+00, time/batch = 0.2135s	
430/2700 (epoch 7.963), train_loss = 3.51060226, grad/param norm = 3.5710e+00, time/batch = 0.2041s	
431/2700 (epoch 7.981), train_loss = 3.56721073, grad/param norm = 3.2989e+00, time/batch = 0.1830s	
432/2700 (epoch 8.000), train_loss = 3.44519618, grad/param norm = 2.8973e+00, time/batch = 0.1816s	
433/2700 (epoch 8.019), train_loss = 3.34146513, grad/param norm = 2.9154e+00, time/batch = 0.1719s	
434/2700 (epoch 8.037), train_loss = 3.40901186, grad/param norm = 3.2563e+00, time/batch = 0.1907s	
435/2700 (epoch 8.056), train_loss = 3.39522565, grad/param norm = 3.2064e+00, time/batch = 0.2060s	
436/2700 (epoch 8.074), train_loss = 3.43371091, grad/param norm = 3.4313e+00, time/batch = 0.2150s	
437/2700 (epoch 8.093), train_loss = 3.45159409, grad/param norm = 3.0070e+00, time/batch = 0.2206s	
438/2700 (epoch 8.111), train_loss = 3.40179071, grad/param norm = 2.5696e+00, time/batch = 0.2155s	
439/2700 (epoch 8.130), train_loss = 3.40338383, grad/param norm = 2.3665e+00, time/batch = 0.2371s	
440/2700 (epoch 8.148), train_loss = 3.33795413, grad/param norm = 2.3882e+00, time/batch = 0.2342s	
441/2700 (epoch 8.167), train_loss = 3.35040355, grad/param norm = 2.8187e+00, time/batch = 0.2112s	
442/2700 (epoch 8.185), train_loss = 3.37866679, grad/param norm = 2.7465e+00, time/batch = 0.2298s	
443/2700 (epoch 8.204), train_loss = 3.28708475, grad/param norm = 2.8329e+00, time/batch = 0.2195s	
444/2700 (epoch 8.222), train_loss = 3.31468832, grad/param norm = 3.3317e+00, time/batch = 0.2127s	
445/2700 (epoch 8.241), train_loss = 3.33268273, grad/param norm = 3.2839e+00, time/batch = 0.2038s	
446/2700 (epoch 8.259), train_loss = 3.35112060, grad/param norm = 3.2111e+00, time/batch = 0.2086s	
447/2700 (epoch 8.278), train_loss = 3.39634935, grad/param norm = 3.0524e+00, time/batch = 0.2212s	
448/2700 (epoch 8.296), train_loss = 3.41204568, grad/param norm = 2.8792e+00, time/batch = 0.2164s	
449/2700 (epoch 8.315), train_loss = 3.35164097, grad/param norm = 2.6205e+00, time/batch = 0.2323s	
450/2700 (epoch 8.333), train_loss = 3.44671305, grad/param norm = 2.4905e+00, time/batch = 0.2260s	
451/2700 (epoch 8.352), train_loss = 3.46499872, grad/param norm = 2.7514e+00, time/batch = 0.2012s	
452/2700 (epoch 8.370), train_loss = 3.45523121, grad/param norm = 2.6797e+00, time/batch = 0.2098s	
453/2700 (epoch 8.389), train_loss = 3.36194263, grad/param norm = 2.2623e+00, time/batch = 0.2180s	
454/2700 (epoch 8.407), train_loss = 3.37530852, grad/param norm = 2.1085e+00, time/batch = 0.2122s	
455/2700 (epoch 8.426), train_loss = 3.37879394, grad/param norm = 2.2607e+00, time/batch = 0.2141s	
456/2700 (epoch 8.444), train_loss = 3.29842487, grad/param norm = 2.2759e+00, time/batch = 0.2128s	
457/2700 (epoch 8.463), train_loss = 3.36220717, grad/param norm = 2.8460e+00, time/batch = 0.2059s	
458/2700 (epoch 8.481), train_loss = 3.49527178, grad/param norm = 2.8619e+00, time/batch = 0.1935s	
459/2700 (epoch 8.500), train_loss = 3.49599164, grad/param norm = 2.7300e+00, time/batch = 0.1825s	
460/2700 (epoch 8.519), train_loss = 3.45105133, grad/param norm = 2.4670e+00, time/batch = 0.1897s	
461/2700 (epoch 8.537), train_loss = 3.42186648, grad/param norm = 2.6689e+00, time/batch = 0.2080s	
462/2700 (epoch 8.556), train_loss = 3.43814568, grad/param norm = 2.6453e+00, time/batch = 0.2157s	
463/2700 (epoch 8.574), train_loss = 3.30373193, grad/param norm = 2.4386e+00, time/batch = 0.2104s	
464/2700 (epoch 8.593), train_loss = 3.34330907, grad/param norm = 3.2471e+00, time/batch = 0.2281s	
465/2700 (epoch 8.611), train_loss = 3.32123224, grad/param norm = 3.3042e+00, time/batch = 0.2278s	
466/2700 (epoch 8.630), train_loss = 3.32473497, grad/param norm = 3.1086e+00, time/batch = 0.2227s	
467/2700 (epoch 8.648), train_loss = 3.41909194, grad/param norm = 3.3638e+00, time/batch = 0.2158s	
468/2700 (epoch 8.667), train_loss = 3.40315020, grad/param norm = 3.3970e+00, time/batch = 0.2031s	
469/2700 (epoch 8.685), train_loss = 3.37756297, grad/param norm = 3.3545e+00, time/batch = 0.1701s	
470/2700 (epoch 8.704), train_loss = 3.34455769, grad/param norm = 3.3583e+00, time/batch = 0.1952s	
471/2700 (epoch 8.722), train_loss = 3.33797444, grad/param norm = 3.1985e+00, time/batch = 0.2096s	
472/2700 (epoch 8.741), train_loss = 3.45732159, grad/param norm = 3.1229e+00, time/batch = 0.1990s	
473/2700 (epoch 8.759), train_loss = 3.38644640, grad/param norm = 2.8776e+00, time/batch = 0.2127s	
474/2700 (epoch 8.778), train_loss = 3.38419607, grad/param norm = 2.6537e+00, time/batch = 0.2122s	
475/2700 (epoch 8.796), train_loss = 3.39554227, grad/param norm = 2.5299e+00, time/batch = 0.2353s	
476/2700 (epoch 8.815), train_loss = 3.31612807, grad/param norm = 2.5905e+00, time/batch = 0.2363s	
477/2700 (epoch 8.833), train_loss = 3.39353671, grad/param norm = 2.6367e+00, time/batch = 0.2342s	
478/2700 (epoch 8.852), train_loss = 3.33858087, grad/param norm = 2.3116e+00, time/batch = 0.2348s	
479/2700 (epoch 8.870), train_loss = 3.31934735, grad/param norm = 2.0457e+00, time/batch = 0.2310s	
480/2700 (epoch 8.889), train_loss = 3.32749485, grad/param norm = 2.3167e+00, time/batch = 0.2296s	
481/2700 (epoch 8.907), train_loss = 3.41458957, grad/param norm = 2.7974e+00, time/batch = 0.2369s	
482/2700 (epoch 8.926), train_loss = 3.40894106, grad/param norm = 3.0462e+00, time/batch = 0.2342s	
483/2700 (epoch 8.944), train_loss = 3.42315637, grad/param norm = 3.1473e+00, time/batch = 0.2345s	
484/2700 (epoch 8.963), train_loss = 3.48617030, grad/param norm = 3.2223e+00, time/batch = 0.2317s	
485/2700 (epoch 8.981), train_loss = 3.52584311, grad/param norm = 3.1118e+00, time/batch = 0.2019s	
486/2700 (epoch 9.000), train_loss = 3.42927468, grad/param norm = 2.5607e+00, time/batch = 0.2077s	
487/2700 (epoch 9.019), train_loss = 3.33609066, grad/param norm = 2.7027e+00, time/batch = 0.2219s	
488/2700 (epoch 9.037), train_loss = 3.40590502, grad/param norm = 2.9493e+00, time/batch = 0.2333s	
489/2700 (epoch 9.056), train_loss = 3.39457523, grad/param norm = 3.1627e+00, time/batch = 0.2261s	
490/2700 (epoch 9.074), train_loss = 3.44415580, grad/param norm = 3.3563e+00, time/batch = 0.2173s	
491/2700 (epoch 9.093), train_loss = 3.45317156, grad/param norm = 3.1347e+00, time/batch = 0.2230s	
492/2700 (epoch 9.111), train_loss = 3.41782120, grad/param norm = 2.8735e+00, time/batch = 0.2209s	
493/2700 (epoch 9.130), train_loss = 3.41907609, grad/param norm = 2.7922e+00, time/batch = 0.2144s	
494/2700 (epoch 9.148), train_loss = 3.36125299, grad/param norm = 2.8890e+00, time/batch = 0.2133s	
495/2700 (epoch 9.167), train_loss = 3.38338588, grad/param norm = 3.1226e+00, time/batch = 0.1997s	
496/2700 (epoch 9.185), train_loss = 3.36264381, grad/param norm = 2.9810e+00, time/batch = 0.2205s	
497/2700 (epoch 9.204), train_loss = 3.28366248, grad/param norm = 2.9984e+00, time/batch = 0.2174s	
498/2700 (epoch 9.222), train_loss = 3.28477960, grad/param norm = 3.3604e+00, time/batch = 0.1997s	
499/2700 (epoch 9.241), train_loss = 3.33400012, grad/param norm = 3.4101e+00, time/batch = 0.1806s	
500/2700 (epoch 9.259), train_loss = 3.34246658, grad/param norm = 3.1020e+00, time/batch = 0.1651s	
501/2700 (epoch 9.278), train_loss = 3.38858949, grad/param norm = 2.8769e+00, time/batch = 0.1833s	
502/2700 (epoch 9.296), train_loss = 3.39703328, grad/param norm = 2.7978e+00, time/batch = 0.2002s	
503/2700 (epoch 9.315), train_loss = 3.36073813, grad/param norm = 2.5180e+00, time/batch = 0.2166s	
504/2700 (epoch 9.333), train_loss = 3.43776814, grad/param norm = 2.3633e+00, time/batch = 0.2168s	
505/2700 (epoch 9.352), train_loss = 3.46118640, grad/param norm = 2.6368e+00, time/batch = 0.2174s	
506/2700 (epoch 9.370), train_loss = 3.46101503, grad/param norm = 2.4680e+00, time/batch = 0.2119s	
507/2700 (epoch 9.389), train_loss = 3.35323935, grad/param norm = 2.1641e+00, time/batch = 0.2263s	
508/2700 (epoch 9.407), train_loss = 3.38729916, grad/param norm = 2.1567e+00, time/batch = 0.2192s	
509/2700 (epoch 9.426), train_loss = 3.37792415, grad/param norm = 2.1364e+00, time/batch = 0.2103s	
510/2700 (epoch 9.444), train_loss = 3.29028517, grad/param norm = 2.0726e+00, time/batch = 0.1880s	
511/2700 (epoch 9.463), train_loss = 3.37003970, grad/param norm = 2.8090e+00, time/batch = 0.2341s	
512/2700 (epoch 9.481), train_loss = 3.49266865, grad/param norm = 2.8514e+00, time/batch = 0.2180s	
513/2700 (epoch 9.500), train_loss = 3.50166432, grad/param norm = 2.6145e+00, time/batch = 0.2102s	
514/2700 (epoch 9.519), train_loss = 3.44014985, grad/param norm = 2.1334e+00, time/batch = 0.2024s	
515/2700 (epoch 9.537), train_loss = 3.43348862, grad/param norm = 2.4955e+00, time/batch = 0.2108s	
516/2700 (epoch 9.556), train_loss = 3.42921601, grad/param norm = 2.2204e+00, time/batch = 0.2199s	
517/2700 (epoch 9.574), train_loss = 3.28738455, grad/param norm = 1.8924e+00, time/batch = 0.2240s	
518/2700 (epoch 9.593), train_loss = 3.32538243, grad/param norm = 2.7619e+00, time/batch = 0.2385s	
519/2700 (epoch 9.611), train_loss = 3.29618095, grad/param norm = 3.0910e+00, time/batch = 0.2362s	
520/2700 (epoch 9.630), train_loss = 3.32176578, grad/param norm = 3.0120e+00, time/batch = 0.2288s	
521/2700 (epoch 9.648), train_loss = 3.39448132, grad/param norm = 3.1024e+00, time/batch = 0.2309s	
522/2700 (epoch 9.667), train_loss = 3.37817718, grad/param norm = 3.2302e+00, time/batch = 0.2258s	
523/2700 (epoch 9.685), train_loss = 3.36448426, grad/param norm = 3.3561e+00, time/batch = 0.2216s	
524/2700 (epoch 9.704), train_loss = 3.35705062, grad/param norm = 3.1633e+00, time/batch = 0.2163s	
525/2700 (epoch 9.722), train_loss = 3.33838445, grad/param norm = 3.1838e+00, time/batch = 0.2141s	
526/2700 (epoch 9.741), train_loss = 3.49866569, grad/param norm = 3.6047e+00, time/batch = 0.2166s	
527/2700 (epoch 9.759), train_loss = 3.44668294, grad/param norm = 3.3401e+00, time/batch = 0.2219s	
528/2700 (epoch 9.778), train_loss = 3.40850731, grad/param norm = 3.0127e+00, time/batch = 0.2008s	
529/2700 (epoch 9.796), train_loss = 3.42037543, grad/param norm = 2.7740e+00, time/batch = 0.1738s	
530/2700 (epoch 9.815), train_loss = 3.29582855, grad/param norm = 2.5384e+00, time/batch = 0.1863s	
531/2700 (epoch 9.833), train_loss = 3.35603508, grad/param norm = 2.6445e+00, time/batch = 0.1942s	
532/2700 (epoch 9.852), train_loss = 3.33470902, grad/param norm = 2.6329e+00, time/batch = 0.2072s	
533/2700 (epoch 9.870), train_loss = 3.32513926, grad/param norm = 2.6791e+00, time/batch = 0.2146s	
534/2700 (epoch 9.889), train_loss = 3.36688766, grad/param norm = 2.8119e+00, time/batch = 0.2139s	
535/2700 (epoch 9.907), train_loss = 3.43010586, grad/param norm = 3.1294e+00, time/batch = 0.2204s	
536/2700 (epoch 9.926), train_loss = 3.40647303, grad/param norm = 3.0124e+00, time/batch = 0.2124s	
537/2700 (epoch 9.944), train_loss = 3.39697931, grad/param norm = 3.0831e+00, time/batch = 0.2063s	
538/2700 (epoch 9.963), train_loss = 3.50638310, grad/param norm = 3.1585e+00, time/batch = 0.2014s	
539/2700 (epoch 9.981), train_loss = 3.53986658, grad/param norm = 2.9096e+00, time/batch = 0.1915s	
decayed learning rate by a factor 0.97 to 0.00194	
540/2700 (epoch 10.000), train_loss = 3.42461455, grad/param norm = 2.4751e+00, time/batch = 0.1847s	
541/2700 (epoch 10.019), train_loss = 3.31321564, grad/param norm = 2.4468e+00, time/batch = 0.1866s	
542/2700 (epoch 10.037), train_loss = 3.36262806, grad/param norm = 2.6048e+00, time/batch = 0.2122s	
543/2700 (epoch 10.056), train_loss = 3.34782716, grad/param norm = 2.6462e+00, time/batch = 0.2079s	
544/2700 (epoch 10.074), train_loss = 3.38908857, grad/param norm = 3.0830e+00, time/batch = 0.2028s	
545/2700 (epoch 10.093), train_loss = 3.43341053, grad/param norm = 3.0817e+00, time/batch = 0.2111s	
546/2700 (epoch 10.111), train_loss = 3.40774283, grad/param norm = 2.6824e+00, time/batch = 0.2218s	
547/2700 (epoch 10.130), train_loss = 3.39639890, grad/param norm = 2.5193e+00, time/batch = 0.2315s	
548/2700 (epoch 10.148), train_loss = 3.34646054, grad/param norm = 2.6917e+00, time/batch = 0.2292s	
549/2700 (epoch 10.167), train_loss = 3.37316682, grad/param norm = 2.8923e+00, time/batch = 0.2219s	
550/2700 (epoch 10.185), train_loss = 3.35064001, grad/param norm = 2.7227e+00, time/batch = 0.2297s	
551/2700 (epoch 10.204), train_loss = 3.26723697, grad/param norm = 2.7689e+00, time/batch = 0.2289s	
552/2700 (epoch 10.222), train_loss = 3.26914976, grad/param norm = 3.2182e+00, time/batch = 0.2363s	
553/2700 (epoch 10.241), train_loss = 3.32416472, grad/param norm = 3.3568e+00, time/batch = 0.2369s	
554/2700 (epoch 10.259), train_loss = 3.33477709, grad/param norm = 3.1054e+00, time/batch = 0.2350s	
555/2700 (epoch 10.278), train_loss = 3.39017337, grad/param norm = 2.8777e+00, time/batch = 0.2375s	
556/2700 (epoch 10.296), train_loss = 3.39910283, grad/param norm = 2.7920e+00, time/batch = 0.2309s	
557/2700 (epoch 10.315), train_loss = 3.35996800, grad/param norm = 2.5246e+00, time/batch = 0.2198s	
558/2700 (epoch 10.333), train_loss = 3.43882424, grad/param norm = 2.3509e+00, time/batch = 0.1977s	
559/2700 (epoch 10.352), train_loss = 3.45622903, grad/param norm = 2.6403e+00, time/batch = 0.2039s	
560/2700 (epoch 10.370), train_loss = 3.45769458, grad/param norm = 2.5272e+00, time/batch = 0.1962s	
561/2700 (epoch 10.389), train_loss = 3.35339891, grad/param norm = 2.1996e+00, time/batch = 0.2287s	
562/2700 (epoch 10.407), train_loss = 3.38383908, grad/param norm = 2.1678e+00, time/batch = 0.2221s	
563/2700 (epoch 10.426), train_loss = 3.37702552, grad/param norm = 2.0442e+00, time/batch = 0.2172s	
564/2700 (epoch 10.444), train_loss = 3.27853975, grad/param norm = 1.8541e+00, time/batch = 0.2143s	
565/2700 (epoch 10.463), train_loss = 3.34935060, grad/param norm = 2.5436e+00, time/batch = 0.2108s	
566/2700 (epoch 10.481), train_loss = 3.46768729, grad/param norm = 2.5688e+00, time/batch = 0.2070s	
567/2700 (epoch 10.500), train_loss = 3.48609108, grad/param norm = 2.5073e+00, time/batch = 0.2071s	
568/2700 (epoch 10.519), train_loss = 3.43284385, grad/param norm = 2.0451e+00, time/batch = 0.1871s	
569/2700 (epoch 10.537), train_loss = 3.42323795, grad/param norm = 2.2860e+00, time/batch = 0.1921s	
570/2700 (epoch 10.556), train_loss = 3.42271779, grad/param norm = 2.1033e+00, time/batch = 0.1865s	
571/2700 (epoch 10.574), train_loss = 3.27863685, grad/param norm = 1.5459e+00, time/batch = 0.1636s	
572/2700 (epoch 10.593), train_loss = 3.30644807, grad/param norm = 2.1396e+00, time/batch = 0.2107s	
573/2700 (epoch 10.611), train_loss = 3.25904675, grad/param norm = 2.2785e+00, time/batch = 0.2358s	
574/2700 (epoch 10.630), train_loss = 3.30229498, grad/param norm = 2.9750e+00, time/batch = 0.2340s	
575/2700 (epoch 10.648), train_loss = 3.43429136, grad/param norm = 3.3642e+00, time/batch = 0.2354s	
576/2700 (epoch 10.667), train_loss = 3.40308473, grad/param norm = 3.4908e+00, time/batch = 0.2343s	
577/2700 (epoch 10.685), train_loss = 3.39718989, grad/param norm = 3.5281e+00, time/batch = 0.2368s	
578/2700 (epoch 10.704), train_loss = 3.35607455, grad/param norm = 3.4124e+00, time/batch = 0.2271s	
579/2700 (epoch 10.722), train_loss = 3.34706060, grad/param norm = 3.3630e+00, time/batch = 0.2268s	
580/2700 (epoch 10.741), train_loss = 3.48044211, grad/param norm = 3.3181e+00, time/batch = 0.2168s	
581/2700 (epoch 10.759), train_loss = 3.41429685, grad/param norm = 3.1731e+00, time/batch = 0.2358s	
582/2700 (epoch 10.778), train_loss = 3.40663649, grad/param norm = 2.9012e+00, time/batch = 0.2016s	
583/2700 (epoch 10.796), train_loss = 3.40558758, grad/param norm = 2.7436e+00, time/batch = 0.2052s	
584/2700 (epoch 10.815), train_loss = 3.30517130, grad/param norm = 2.5128e+00, time/batch = 0.1997s	
585/2700 (epoch 10.833), train_loss = 3.35995934, grad/param norm = 2.7812e+00, time/batch = 0.2038s	
586/2700 (epoch 10.852), train_loss = 3.35878562, grad/param norm = 2.5465e+00, time/batch = 0.2156s	
587/2700 (epoch 10.870), train_loss = 3.31067277, grad/param norm = 2.3334e+00, time/batch = 0.2171s	
588/2700 (epoch 10.889), train_loss = 3.35784451, grad/param norm = 2.4748e+00, time/batch = 0.2097s	
589/2700 (epoch 10.907), train_loss = 3.41894104, grad/param norm = 3.0303e+00, time/batch = 0.2334s	
590/2700 (epoch 10.926), train_loss = 3.41610986, grad/param norm = 3.0041e+00, time/batch = 0.2336s	
591/2700 (epoch 10.944), train_loss = 3.38790946, grad/param norm = 2.9033e+00, time/batch = 0.2157s	
592/2700 (epoch 10.963), train_loss = 3.47518632, grad/param norm = 2.9944e+00, time/batch = 0.2031s	
593/2700 (epoch 10.981), train_loss = 3.51368049, grad/param norm = 2.9662e+00, time/batch = 0.2045s	
decayed learning rate by a factor 0.97 to 0.0018818	
594/2700 (epoch 11.000), train_loss = 3.42039483, grad/param norm = 2.4791e+00, time/batch = 0.2025s	
595/2700 (epoch 11.019), train_loss = 3.31946007, grad/param norm = 2.5425e+00, time/batch = 0.2023s	
596/2700 (epoch 11.037), train_loss = 3.36407797, grad/param norm = 2.6973e+00, time/batch = 0.1856s	
597/2700 (epoch 11.056), train_loss = 3.34355409, grad/param norm = 2.7294e+00, time/batch = 0.1644s	
598/2700 (epoch 11.074), train_loss = 3.38436831, grad/param norm = 3.0701e+00, time/batch = 0.1681s	
599/2700 (epoch 11.093), train_loss = 3.42651482, grad/param norm = 3.0597e+00, time/batch = 0.1890s	
600/2700 (epoch 11.111), train_loss = 3.40301768, grad/param norm = 2.6600e+00, time/batch = 0.2101s	
601/2700 (epoch 11.130), train_loss = 3.39498604, grad/param norm = 2.4923e+00, time/batch = 0.2034s	
602/2700 (epoch 11.148), train_loss = 3.34026361, grad/param norm = 2.5621e+00, time/batch = 0.2148s	
603/2700 (epoch 11.167), train_loss = 3.36296964, grad/param norm = 2.7458e+00, time/batch = 0.1996s	
604/2700 (epoch 11.185), train_loss = 3.33371511, grad/param norm = 2.5950e+00, time/batch = 0.2358s	
605/2700 (epoch 11.204), train_loss = 3.25886130, grad/param norm = 2.6785e+00, time/batch = 0.2360s	
606/2700 (epoch 11.222), train_loss = 3.26148938, grad/param norm = 3.1563e+00, time/batch = 0.2233s	
607/2700 (epoch 11.241), train_loss = 3.31748920, grad/param norm = 3.3194e+00, time/batch = 0.2090s	
608/2700 (epoch 11.259), train_loss = 3.32790690, grad/param norm = 3.0473e+00, time/batch = 0.2018s	
609/2700 (epoch 11.278), train_loss = 3.37887802, grad/param norm = 2.7733e+00, time/batch = 0.2064s	
610/2700 (epoch 11.296), train_loss = 3.38565631, grad/param norm = 2.6992e+00, time/batch = 0.2156s	
611/2700 (epoch 11.315), train_loss = 3.35343946, grad/param norm = 2.4765e+00, time/batch = 0.2088s	
612/2700 (epoch 11.333), train_loss = 3.43274270, grad/param norm = 2.2736e+00, time/batch = 0.2210s	
613/2700 (epoch 11.352), train_loss = 3.44727188, grad/param norm = 2.5175e+00, time/batch = 0.2196s	
614/2700 (epoch 11.370), train_loss = 3.44118883, grad/param norm = 2.3825e+00, time/batch = 0.2255s	
615/2700 (epoch 11.389), train_loss = 3.34201949, grad/param norm = 2.0248e+00, time/batch = 0.2379s	
616/2700 (epoch 11.407), train_loss = 3.36798325, grad/param norm = 1.9510e+00, time/batch = 0.2373s	
617/2700 (epoch 11.426), train_loss = 3.36179629, grad/param norm = 1.9267e+00, time/batch = 0.2347s	
618/2700 (epoch 11.444), train_loss = 3.27385561, grad/param norm = 1.8354e+00, time/batch = 0.2338s	
619/2700 (epoch 11.463), train_loss = 3.34922369, grad/param norm = 2.5353e+00, time/batch = 0.2194s	
620/2700 (epoch 11.481), train_loss = 3.46999531, grad/param norm = 2.6602e+00, time/batch = 0.2061s	
621/2700 (epoch 11.500), train_loss = 3.48679762, grad/param norm = 2.4693e+00, time/batch = 0.2363s	
622/2700 (epoch 11.519), train_loss = 3.42143715, grad/param norm = 1.9406e+00, time/batch = 0.2341s	
623/2700 (epoch 11.537), train_loss = 3.41551387, grad/param norm = 2.1767e+00, time/batch = 0.2113s	
624/2700 (epoch 11.556), train_loss = 3.40079865, grad/param norm = 1.9471e+00, time/batch = 0.2056s	
625/2700 (epoch 11.574), train_loss = 3.27865552, grad/param norm = 1.5276e+00, time/batch = 0.1775s	
626/2700 (epoch 11.593), train_loss = 3.30213562, grad/param norm = 2.0815e+00, time/batch = 0.2218s	
627/2700 (epoch 11.611), train_loss = 3.25293205, grad/param norm = 2.2345e+00, time/batch = 0.2115s	
628/2700 (epoch 11.630), train_loss = 3.29816058, grad/param norm = 2.8576e+00, time/batch = 0.2120s	
629/2700 (epoch 11.648), train_loss = 3.42280185, grad/param norm = 3.3540e+00, time/batch = 0.2062s	
630/2700 (epoch 11.667), train_loss = 3.40359025, grad/param norm = 3.5368e+00, time/batch = 0.2049s	
631/2700 (epoch 11.685), train_loss = 3.38806690, grad/param norm = 3.4550e+00, time/batch = 0.2369s	
632/2700 (epoch 11.704), train_loss = 3.34148492, grad/param norm = 3.2458e+00, time/batch = 0.2301s	
633/2700 (epoch 11.722), train_loss = 3.33268922, grad/param norm = 3.2825e+00, time/batch = 0.2252s	
634/2700 (epoch 11.741), train_loss = 3.47625917, grad/param norm = 3.2932e+00, time/batch = 0.1947s	
635/2700 (epoch 11.759), train_loss = 3.40503713, grad/param norm = 3.1065e+00, time/batch = 0.1895s	
636/2700 (epoch 11.778), train_loss = 3.39743378, grad/param norm = 2.8341e+00, time/batch = 0.1616s	
637/2700 (epoch 11.796), train_loss = 3.39862813, grad/param norm = 2.6808e+00, time/batch = 0.1479s	
638/2700 (epoch 11.815), train_loss = 3.29820300, grad/param norm = 2.4170e+00, time/batch = 0.1913s	
639/2700 (epoch 11.833), train_loss = 3.35097301, grad/param norm = 2.6299e+00, time/batch = 0.2045s	
640/2700 (epoch 11.852), train_loss = 3.34534172, grad/param norm = 2.4329e+00, time/batch = 0.2189s	
641/2700 (epoch 11.870), train_loss = 3.30323976, grad/param norm = 2.2100e+00, time/batch = 0.1982s	
642/2700 (epoch 11.889), train_loss = 3.34653472, grad/param norm = 2.3332e+00, time/batch = 0.2134s	
643/2700 (epoch 11.907), train_loss = 3.40720471, grad/param norm = 2.8654e+00, time/batch = 0.2113s	
644/2700 (epoch 11.926), train_loss = 3.40222441, grad/param norm = 2.8942e+00, time/batch = 0.2012s	
645/2700 (epoch 11.944), train_loss = 3.38244442, grad/param norm = 2.8461e+00, time/batch = 0.2098s	
646/2700 (epoch 11.963), train_loss = 3.46950732, grad/param norm = 2.9665e+00, time/batch = 0.2035s	
647/2700 (epoch 11.981), train_loss = 3.51373412, grad/param norm = 2.9325e+00, time/batch = 0.1898s	
decayed learning rate by a factor 0.97 to 0.001825346	
648/2700 (epoch 12.000), train_loss = 3.41402433, grad/param norm = 2.4522e+00, time/batch = 0.2104s	
649/2700 (epoch 12.019), train_loss = 3.31668333, grad/param norm = 2.5220e+00, time/batch = 0.2062s	
650/2700 (epoch 12.037), train_loss = 3.35982509, grad/param norm = 2.6492e+00, time/batch = 0.2044s	
651/2700 (epoch 12.056), train_loss = 3.33987973, grad/param norm = 2.6817e+00, time/batch = 0.1882s	
652/2700 (epoch 12.074), train_loss = 3.38291748, grad/param norm = 3.0397e+00, time/batch = 0.1942s	
653/2700 (epoch 12.093), train_loss = 3.42379626, grad/param norm = 3.0052e+00, time/batch = 0.2025s	
654/2700 (epoch 12.111), train_loss = 3.39380096, grad/param norm = 2.6119e+00, time/batch = 0.2018s	
655/2700 (epoch 12.130), train_loss = 3.38838769, grad/param norm = 2.4330e+00, time/batch = 0.2150s	
656/2700 (epoch 12.148), train_loss = 3.33187512, grad/param norm = 2.5018e+00, time/batch = 0.2181s	
657/2700 (epoch 12.167), train_loss = 3.35538189, grad/param norm = 2.6687e+00, time/batch = 0.1802s	
658/2700 (epoch 12.185), train_loss = 3.32719916, grad/param norm = 2.4756e+00, time/batch = 0.2108s	
659/2700 (epoch 12.204), train_loss = 3.25189256, grad/param norm = 2.5656e+00, time/batch = 0.1953s	
660/2700 (epoch 12.222), train_loss = 3.25306136, grad/param norm = 3.0361e+00, time/batch = 0.1797s	
661/2700 (epoch 12.241), train_loss = 3.30683434, grad/param norm = 3.2291e+00, time/batch = 0.1794s	
662/2700 (epoch 12.259), train_loss = 3.32279041, grad/param norm = 3.0223e+00, time/batch = 0.1753s	
663/2700 (epoch 12.278), train_loss = 3.37503665, grad/param norm = 2.7404e+00, time/batch = 0.1622s	
664/2700 (epoch 12.296), train_loss = 3.38100132, grad/param norm = 2.6492e+00, time/batch = 0.1707s	
665/2700 (epoch 12.315), train_loss = 3.34852479, grad/param norm = 2.4345e+00, time/batch = 0.1743s	
666/2700 (epoch 12.333), train_loss = 3.42974615, grad/param norm = 2.2341e+00, time/batch = 0.2185s	
667/2700 (epoch 12.352), train_loss = 3.44413394, grad/param norm = 2.4938e+00, time/batch = 0.2102s	
668/2700 (epoch 12.370), train_loss = 3.43491640, grad/param norm = 2.3614e+00, time/batch = 0.2082s	
669/2700 (epoch 12.389), train_loss = 3.33658337, grad/param norm = 1.9799e+00, time/batch = 0.2083s	
670/2700 (epoch 12.407), train_loss = 3.36266417, grad/param norm = 1.8781e+00, time/batch = 0.1920s	
671/2700 (epoch 12.426), train_loss = 3.35532906, grad/param norm = 1.8254e+00, time/batch = 0.2263s	
672/2700 (epoch 12.444), train_loss = 3.26586205, grad/param norm = 1.7043e+00, time/batch = 0.2166s	
673/2700 (epoch 12.463), train_loss = 3.33874516, grad/param norm = 2.3633e+00, time/batch = 0.2080s	
674/2700 (epoch 12.481), train_loss = 3.45533577, grad/param norm = 2.5406e+00, time/batch = 0.2003s	
675/2700 (epoch 12.500), train_loss = 3.48120100, grad/param norm = 2.4224e+00, time/batch = 0.1968s	
676/2700 (epoch 12.519), train_loss = 3.41500052, grad/param norm = 1.8758e+00, time/batch = 0.2160s	
677/2700 (epoch 12.537), train_loss = 3.40861330, grad/param norm = 2.0468e+00, time/batch = 0.2193s	
678/2700 (epoch 12.556), train_loss = 3.39574358, grad/param norm = 1.9746e+00, time/batch = 0.2271s	
679/2700 (epoch 12.574), train_loss = 3.27794352, grad/param norm = 1.5216e+00, time/batch = 0.2209s	
680/2700 (epoch 12.593), train_loss = 3.29604355, grad/param norm = 2.1315e+00, time/batch = 0.2353s	
681/2700 (epoch 12.611), train_loss = 3.25547678, grad/param norm = 2.1392e+00, time/batch = 0.2384s	
682/2700 (epoch 12.630), train_loss = 3.28669252, grad/param norm = 2.6726e+00, time/batch = 0.2359s	
683/2700 (epoch 12.648), train_loss = 3.41996091, grad/param norm = 3.3122e+00, time/batch = 0.2355s	
684/2700 (epoch 12.667), train_loss = 3.35928026, grad/param norm = 3.2490e+00, time/batch = 0.2356s	
685/2700 (epoch 12.685), train_loss = 3.33035527, grad/param norm = 2.9208e+00, time/batch = 0.2295s	
686/2700 (epoch 12.704), train_loss = 3.33766442, grad/param norm = 3.4186e+00, time/batch = 0.2181s	
687/2700 (epoch 12.722), train_loss = 3.35257758, grad/param norm = 3.2784e+00, time/batch = 0.2135s	
688/2700 (epoch 12.741), train_loss = 3.45413801, grad/param norm = 3.0882e+00, time/batch = 0.2032s	
689/2700 (epoch 12.759), train_loss = 3.40842371, grad/param norm = 3.2195e+00, time/batch = 0.1894s	
690/2700 (epoch 12.778), train_loss = 3.39752431, grad/param norm = 3.2713e+00, time/batch = 0.1869s	
691/2700 (epoch 12.796), train_loss = 3.39389060, grad/param norm = 2.8386e+00, time/batch = 0.2381s	
692/2700 (epoch 12.815), train_loss = 3.29027873, grad/param norm = 2.7749e+00, time/batch = 0.2350s	
693/2700 (epoch 12.833), train_loss = 3.35714754, grad/param norm = 2.8364e+00, time/batch = 0.2344s	
694/2700 (epoch 12.852), train_loss = 3.33731555, grad/param norm = 2.9756e+00, time/batch = 0.2351s	
695/2700 (epoch 12.870), train_loss = 3.35771350, grad/param norm = 2.6277e+00, time/batch = 0.2320s	
696/2700 (epoch 12.889), train_loss = 3.35073750, grad/param norm = 2.5973e+00, time/batch = 0.2070s	
697/2700 (epoch 12.907), train_loss = 3.40328576, grad/param norm = 2.7228e+00, time/batch = 0.2079s	
698/2700 (epoch 12.926), train_loss = 3.36023870, grad/param norm = 2.5555e+00, time/batch = 0.2029s	
699/2700 (epoch 12.944), train_loss = 3.36917744, grad/param norm = 2.3510e+00, time/batch = 0.1994s	
700/2700 (epoch 12.963), train_loss = 3.41556109, grad/param norm = 2.2100e+00, time/batch = 0.1941s	
701/2700 (epoch 12.981), train_loss = 3.48350483, grad/param norm = 2.1896e+00, time/batch = 0.1885s	
decayed learning rate by a factor 0.97 to 0.00177058562	
702/2700 (epoch 13.000), train_loss = 3.39878464, grad/param norm = 2.3011e+00, time/batch = 0.1965s	
703/2700 (epoch 13.019), train_loss = 3.31647052, grad/param norm = 2.4446e+00, time/batch = 0.2056s	
704/2700 (epoch 13.037), train_loss = 3.35217463, grad/param norm = 2.5457e+00, time/batch = 0.2059s	
705/2700 (epoch 13.056), train_loss = 3.32764013, grad/param norm = 2.1551e+00, time/batch = 0.1997s	
706/2700 (epoch 13.074), train_loss = 3.33989122, grad/param norm = 1.9730e+00, time/batch = 0.1821s	
707/2700 (epoch 13.093), train_loss = 3.37322421, grad/param norm = 2.1596e+00, time/batch = 0.2340s	
708/2700 (epoch 13.111), train_loss = 3.36995594, grad/param norm = 2.5203e+00, time/batch = 0.2349s	
709/2700 (epoch 13.130), train_loss = 3.39420645, grad/param norm = 2.7246e+00, time/batch = 0.2333s	
710/2700 (epoch 13.148), train_loss = 3.35729336, grad/param norm = 2.8949e+00, time/batch = 0.2348s	
711/2700 (epoch 13.167), train_loss = 3.37372365, grad/param norm = 3.0411e+00, time/batch = 0.2178s	
712/2700 (epoch 13.185), train_loss = 3.37472342, grad/param norm = 3.0389e+00, time/batch = 0.1953s	
713/2700 (epoch 13.204), train_loss = 3.29593217, grad/param norm = 2.8275e+00, time/batch = 0.1784s	
714/2700 (epoch 13.222), train_loss = 3.26338280, grad/param norm = 3.1020e+00, time/batch = 0.1837s	
715/2700 (epoch 13.241), train_loss = 3.27265415, grad/param norm = 2.6763e+00, time/batch = 0.1977s	
716/2700 (epoch 13.259), train_loss = 3.28859533, grad/param norm = 2.4715e+00, time/batch = 0.1892s	
717/2700 (epoch 13.278), train_loss = 3.38767729, grad/param norm = 2.7993e+00, time/batch = 0.2194s	
718/2700 (epoch 13.296), train_loss = 3.38389679, grad/param norm = 2.6238e+00, time/batch = 0.2124s	
719/2700 (epoch 13.315), train_loss = 3.35121219, grad/param norm = 2.2038e+00, time/batch = 0.2124s	
720/2700 (epoch 13.333), train_loss = 3.41779489, grad/param norm = 2.0884e+00, time/batch = 0.2102s	
721/2700 (epoch 13.352), train_loss = 3.46594865, grad/param norm = 2.2806e+00, time/batch = 0.2380s	
722/2700 (epoch 13.370), train_loss = 3.44390029, grad/param norm = 2.2602e+00, time/batch = 0.2312s	
723/2700 (epoch 13.389), train_loss = 3.44903654, grad/param norm = 2.9508e+00, time/batch = 0.2361s	
724/2700 (epoch 13.407), train_loss = 3.45926224, grad/param norm = 2.7002e+00, time/batch = 0.2358s	
725/2700 (epoch 13.426), train_loss = 3.38917243, grad/param norm = 2.3800e+00, time/batch = 0.2329s	
726/2700 (epoch 13.444), train_loss = 3.32537821, grad/param norm = 2.4230e+00, time/batch = 0.2337s	
727/2700 (epoch 13.463), train_loss = 3.33884583, grad/param norm = 2.0635e+00, time/batch = 0.2179s	
728/2700 (epoch 13.481), train_loss = 3.39677575, grad/param norm = 2.0013e+00, time/batch = 0.2052s	
729/2700 (epoch 13.500), train_loss = 3.44865232, grad/param norm = 2.3252e+00, time/batch = 0.1916s	
730/2700 (epoch 13.519), train_loss = 3.41815066, grad/param norm = 2.3892e+00, time/batch = 0.1745s	
731/2700 (epoch 13.537), train_loss = 3.41646921, grad/param norm = 2.7222e+00, time/batch = 0.2126s	
732/2700 (epoch 13.556), train_loss = 3.39931869, grad/param norm = 2.6025e+00, time/batch = 0.1968s	
733/2700 (epoch 13.574), train_loss = 3.31221291, grad/param norm = 2.6178e+00, time/batch = 0.1926s	
734/2700 (epoch 13.593), train_loss = 3.33391807, grad/param norm = 3.2806e+00, time/batch = 0.2255s	
735/2700 (epoch 13.611), train_loss = 3.30330206, grad/param norm = 3.1701e+00, time/batch = 0.2197s	
736/2700 (epoch 13.630), train_loss = 3.28546337, grad/param norm = 2.7561e+00, time/batch = 0.1883s	
737/2700 (epoch 13.648), train_loss = 3.35839278, grad/param norm = 2.7005e+00, time/batch = 0.1719s	
738/2700 (epoch 13.667), train_loss = 3.31521356, grad/param norm = 2.6882e+00, time/batch = 0.2045s	
739/2700 (epoch 13.685), train_loss = 3.31493180, grad/param norm = 2.8095e+00, time/batch = 0.2336s	
740/2700 (epoch 13.704), train_loss = 3.29841391, grad/param norm = 2.9324e+00, time/batch = 0.2311s	
741/2700 (epoch 13.722), train_loss = 3.31229740, grad/param norm = 2.9851e+00, time/batch = 0.2193s	
742/2700 (epoch 13.741), train_loss = 3.43126549, grad/param norm = 3.1062e+00, time/batch = 0.2159s	
743/2700 (epoch 13.759), train_loss = 3.37082281, grad/param norm = 2.6624e+00, time/batch = 0.2003s	
744/2700 (epoch 13.778), train_loss = 3.33994535, grad/param norm = 2.2540e+00, time/batch = 0.1755s	
745/2700 (epoch 13.796), train_loss = 3.35368218, grad/param norm = 2.0478e+00, time/batch = 0.1881s	
746/2700 (epoch 13.815), train_loss = 3.27145844, grad/param norm = 1.9533e+00, time/batch = 0.2037s	
747/2700 (epoch 13.833), train_loss = 3.33130675, grad/param norm = 1.9700e+00, time/batch = 0.2016s	
748/2700 (epoch 13.852), train_loss = 3.29727098, grad/param norm = 2.0048e+00, time/batch = 0.2067s	
749/2700 (epoch 13.870), train_loss = 3.31041172, grad/param norm = 1.8951e+00, time/batch = 0.2278s	
750/2700 (epoch 13.889), train_loss = 3.33023746, grad/param norm = 1.9004e+00, time/batch = 0.2128s	
751/2700 (epoch 13.907), train_loss = 3.36600268, grad/param norm = 2.1116e+00, time/batch = 0.2230s	
752/2700 (epoch 13.926), train_loss = 3.34476254, grad/param norm = 2.3271e+00, time/batch = 0.2162s	
753/2700 (epoch 13.944), train_loss = 3.38472688, grad/param norm = 2.7017e+00, time/batch = 0.2178s	
754/2700 (epoch 13.963), train_loss = 3.46877936, grad/param norm = 3.0722e+00, time/batch = 0.2122s	
755/2700 (epoch 13.981), train_loss = 3.53236644, grad/param norm = 3.0756e+00, time/batch = 0.2191s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
756/2700 (epoch 14.000), train_loss = 3.42276964, grad/param norm = 2.7950e+00, time/batch = 0.2072s	
757/2700 (epoch 14.019), train_loss = 3.32152210, grad/param norm = 2.7753e+00, time/batch = 0.1948s	
758/2700 (epoch 14.037), train_loss = 3.36209960, grad/param norm = 2.7424e+00, time/batch = 0.1529s	
759/2700 (epoch 14.056), train_loss = 3.34901406, grad/param norm = 2.8008e+00, time/batch = 0.1608s	
760/2700 (epoch 14.074), train_loss = 3.38669213, grad/param norm = 2.9831e+00, time/batch = 0.1797s	
761/2700 (epoch 14.093), train_loss = 3.39833493, grad/param norm = 2.6081e+00, time/batch = 0.1984s	
762/2700 (epoch 14.111), train_loss = 3.35628714, grad/param norm = 2.1772e+00, time/batch = 0.2075s	
763/2700 (epoch 14.130), train_loss = 3.36324782, grad/param norm = 1.9770e+00, time/batch = 0.2065s	
764/2700 (epoch 14.148), train_loss = 3.30822598, grad/param norm = 1.9316e+00, time/batch = 0.2084s	
765/2700 (epoch 14.167), train_loss = 3.32102752, grad/param norm = 2.2859e+00, time/batch = 0.2008s	
766/2700 (epoch 14.185), train_loss = 3.33467091, grad/param norm = 2.2417e+00, time/batch = 0.2146s	
767/2700 (epoch 14.204), train_loss = 3.25610562, grad/param norm = 2.3410e+00, time/batch = 0.2103s	
768/2700 (epoch 14.222), train_loss = 3.25612092, grad/param norm = 2.7453e+00, time/batch = 0.1848s	
769/2700 (epoch 14.241), train_loss = 3.28562154, grad/param norm = 2.8942e+00, time/batch = 0.2056s	
770/2700 (epoch 14.259), train_loss = 3.31542438, grad/param norm = 2.9935e+00, time/batch = 0.1977s	
771/2700 (epoch 14.278), train_loss = 3.37576038, grad/param norm = 2.8387e+00, time/batch = 0.2034s	
772/2700 (epoch 14.296), train_loss = 3.38675783, grad/param norm = 2.5686e+00, time/batch = 0.2073s	
773/2700 (epoch 14.315), train_loss = 3.33038577, grad/param norm = 2.2730e+00, time/batch = 0.2172s	
774/2700 (epoch 14.333), train_loss = 3.41473330, grad/param norm = 1.9181e+00, time/batch = 0.2273s	
775/2700 (epoch 14.352), train_loss = 3.40576726, grad/param norm = 1.9914e+00, time/batch = 0.2350s	
776/2700 (epoch 14.370), train_loss = 3.39874868, grad/param norm = 2.2558e+00, time/batch = 0.2303s	
777/2700 (epoch 14.389), train_loss = 3.32958703, grad/param norm = 1.9871e+00, time/batch = 0.2295s	
778/2700 (epoch 14.407), train_loss = 3.35591302, grad/param norm = 1.8213e+00, time/batch = 0.2234s	
779/2700 (epoch 14.426), train_loss = 3.35775598, grad/param norm = 1.7047e+00, time/batch = 0.2340s	
780/2700 (epoch 14.444), train_loss = 3.25595013, grad/param norm = 1.4818e+00, time/batch = 0.2306s	
781/2700 (epoch 14.463), train_loss = 3.31786277, grad/param norm = 1.9428e+00, time/batch = 0.2393s	
782/2700 (epoch 14.481), train_loss = 3.41046679, grad/param norm = 1.8980e+00, time/batch = 0.2363s	
783/2700 (epoch 14.500), train_loss = 3.44115679, grad/param norm = 1.8962e+00, time/batch = 0.2356s	
784/2700 (epoch 14.519), train_loss = 3.39691467, grad/param norm = 2.2649e+00, time/batch = 0.2353s	
785/2700 (epoch 14.537), train_loss = 3.43101233, grad/param norm = 2.7151e+00, time/batch = 0.2358s	
786/2700 (epoch 14.556), train_loss = 3.39975662, grad/param norm = 2.8208e+00, time/batch = 0.2279s	
787/2700 (epoch 14.574), train_loss = 3.30474839, grad/param norm = 2.6968e+00, time/batch = 0.1877s	
788/2700 (epoch 14.593), train_loss = 3.33253036, grad/param norm = 3.0734e+00, time/batch = 0.2181s	
789/2700 (epoch 14.611), train_loss = 3.28836770, grad/param norm = 2.9278e+00, time/batch = 0.1987s	
790/2700 (epoch 14.630), train_loss = 3.30259475, grad/param norm = 2.9630e+00, time/batch = 0.2057s	
791/2700 (epoch 14.648), train_loss = 3.38776621, grad/param norm = 2.7705e+00, time/batch = 0.2158s	
792/2700 (epoch 14.667), train_loss = 3.32234323, grad/param norm = 2.7817e+00, time/batch = 0.2204s	
793/2700 (epoch 14.685), train_loss = 3.31559516, grad/param norm = 2.4383e+00, time/batch = 0.2163s	
794/2700 (epoch 14.704), train_loss = 3.30237687, grad/param norm = 2.7570e+00, time/batch = 0.2116s	
795/2700 (epoch 14.722), train_loss = 3.32900632, grad/param norm = 2.6761e+00, time/batch = 0.2059s	
796/2700 (epoch 14.741), train_loss = 3.42435296, grad/param norm = 2.3944e+00, time/batch = 0.2065s	
797/2700 (epoch 14.759), train_loss = 3.35822607, grad/param norm = 2.4609e+00, time/batch = 0.1983s	
798/2700 (epoch 14.778), train_loss = 3.34562606, grad/param norm = 2.6576e+00, time/batch = 0.1850s	
799/2700 (epoch 14.796), train_loss = 3.36735852, grad/param norm = 2.5753e+00, time/batch = 0.1696s	
800/2700 (epoch 14.815), train_loss = 3.27804814, grad/param norm = 2.6114e+00, time/batch = 0.2075s	
801/2700 (epoch 14.833), train_loss = 3.36331812, grad/param norm = 2.7886e+00, time/batch = 0.2018s	
802/2700 (epoch 14.852), train_loss = 3.33366762, grad/param norm = 2.7416e+00, time/batch = 0.2107s	
803/2700 (epoch 14.870), train_loss = 3.31927876, grad/param norm = 2.4993e+00, time/batch = 0.2194s	
804/2700 (epoch 14.889), train_loss = 3.32693139, grad/param norm = 2.5009e+00, time/batch = 0.2303s	
805/2700 (epoch 14.907), train_loss = 3.40416081, grad/param norm = 2.6570e+00, time/batch = 0.2363s	
806/2700 (epoch 14.926), train_loss = 3.36663927, grad/param norm = 2.5219e+00, time/batch = 0.2358s	
807/2700 (epoch 14.944), train_loss = 3.36630231, grad/param norm = 2.2710e+00, time/batch = 0.2356s	
808/2700 (epoch 14.963), train_loss = 3.40972341, grad/param norm = 2.0269e+00, time/batch = 0.2231s	
809/2700 (epoch 14.981), train_loss = 3.46465394, grad/param norm = 1.9579e+00, time/batch = 0.2163s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
810/2700 (epoch 15.000), train_loss = 3.38338509, grad/param norm = 2.0689e+00, time/batch = 0.2134s	
811/2700 (epoch 15.019), train_loss = 3.30546210, grad/param norm = 2.2350e+00, time/batch = 0.2225s	
812/2700 (epoch 15.037), train_loss = 3.33993260, grad/param norm = 2.3336e+00, time/batch = 0.2060s	
813/2700 (epoch 15.056), train_loss = 3.31808261, grad/param norm = 1.9426e+00, time/batch = 0.1898s	
814/2700 (epoch 15.074), train_loss = 3.33242385, grad/param norm = 1.7832e+00, time/batch = 0.1845s	
815/2700 (epoch 15.093), train_loss = 3.36637351, grad/param norm = 2.0011e+00, time/batch = 0.1840s	
816/2700 (epoch 15.111), train_loss = 3.36292616, grad/param norm = 2.4646e+00, time/batch = 0.1955s	
817/2700 (epoch 15.130), train_loss = 3.39943787, grad/param norm = 2.6913e+00, time/batch = 0.2059s	
818/2700 (epoch 15.148), train_loss = 3.36869392, grad/param norm = 2.8783e+00, time/batch = 0.2325s	
819/2700 (epoch 15.167), train_loss = 3.38001119, grad/param norm = 2.9352e+00, time/batch = 0.2103s	
820/2700 (epoch 15.185), train_loss = 3.35896089, grad/param norm = 2.8288e+00, time/batch = 0.2010s	
821/2700 (epoch 15.204), train_loss = 3.27148608, grad/param norm = 2.6690e+00, time/batch = 0.1969s	
822/2700 (epoch 15.222), train_loss = 3.23920439, grad/param norm = 2.9232e+00, time/batch = 0.1893s	
823/2700 (epoch 15.241), train_loss = 3.25361537, grad/param norm = 2.5580e+00, time/batch = 0.1796s	
824/2700 (epoch 15.259), train_loss = 3.28208769, grad/param norm = 2.4363e+00, time/batch = 0.1796s	
825/2700 (epoch 15.278), train_loss = 3.38051502, grad/param norm = 2.7824e+00, time/batch = 0.1754s	
826/2700 (epoch 15.296), train_loss = 3.37762595, grad/param norm = 2.5486e+00, time/batch = 0.1748s	
827/2700 (epoch 15.315), train_loss = 3.33638922, grad/param norm = 2.0987e+00, time/batch = 0.1801s	
828/2700 (epoch 15.333), train_loss = 3.39652906, grad/param norm = 1.7877e+00, time/batch = 0.1991s	
829/2700 (epoch 15.352), train_loss = 3.39936516, grad/param norm = 1.8073e+00, time/batch = 0.2070s	
830/2700 (epoch 15.370), train_loss = 3.36613324, grad/param norm = 2.0870e+00, time/batch = 0.1886s	
831/2700 (epoch 15.389), train_loss = 3.31194039, grad/param norm = 2.1639e+00, time/batch = 0.2262s	
832/2700 (epoch 15.407), train_loss = 3.35797805, grad/param norm = 2.2834e+00, time/batch = 0.2329s	
833/2700 (epoch 15.426), train_loss = 3.35969173, grad/param norm = 2.3086e+00, time/batch = 0.2340s	
834/2700 (epoch 15.444), train_loss = 3.28838185, grad/param norm = 2.3652e+00, time/batch = 0.2342s	
835/2700 (epoch 15.463), train_loss = 3.33077979, grad/param norm = 2.8145e+00, time/batch = 0.2199s	
836/2700 (epoch 15.481), train_loss = 3.42946618, grad/param norm = 2.8569e+00, time/batch = 0.2054s	
837/2700 (epoch 15.500), train_loss = 3.45569164, grad/param norm = 2.6408e+00, time/batch = 0.2023s	
838/2700 (epoch 15.519), train_loss = 3.40294240, grad/param norm = 2.4723e+00, time/batch = 0.2074s	
839/2700 (epoch 15.537), train_loss = 3.40047783, grad/param norm = 2.2098e+00, time/batch = 0.2143s	
840/2700 (epoch 15.556), train_loss = 3.35350999, grad/param norm = 2.0542e+00, time/batch = 0.2197s	
841/2700 (epoch 15.574), train_loss = 3.27472526, grad/param norm = 1.7301e+00, time/batch = 0.2037s	
842/2700 (epoch 15.593), train_loss = 3.30241114, grad/param norm = 2.2755e+00, time/batch = 0.2371s	
843/2700 (epoch 15.611), train_loss = 3.27912352, grad/param norm = 2.7897e+00, time/batch = 0.2361s	
844/2700 (epoch 15.630), train_loss = 3.33345296, grad/param norm = 2.5320e+00, time/batch = 0.2364s	
845/2700 (epoch 15.648), train_loss = 3.36160685, grad/param norm = 2.3459e+00, time/batch = 0.2366s	
846/2700 (epoch 15.667), train_loss = 3.30145294, grad/param norm = 2.4551e+00, time/batch = 0.2244s	
847/2700 (epoch 15.685), train_loss = 3.29811235, grad/param norm = 2.2501e+00, time/batch = 0.2187s	
848/2700 (epoch 15.704), train_loss = 3.27977239, grad/param norm = 2.4895e+00, time/batch = 0.2109s	
849/2700 (epoch 15.722), train_loss = 3.29989568, grad/param norm = 2.4058e+00, time/batch = 0.2028s	
850/2700 (epoch 15.741), train_loss = 3.41266144, grad/param norm = 2.3323e+00, time/batch = 0.2085s	
851/2700 (epoch 15.759), train_loss = 3.36349368, grad/param norm = 2.2403e+00, time/batch = 0.1955s	
852/2700 (epoch 15.778), train_loss = 3.33838535, grad/param norm = 2.6185e+00, time/batch = 0.1935s	
853/2700 (epoch 15.796), train_loss = 3.37338541, grad/param norm = 2.5891e+00, time/batch = 0.2209s	
854/2700 (epoch 15.815), train_loss = 3.27939045, grad/param norm = 2.5333e+00, time/batch = 0.2145s	
855/2700 (epoch 15.833), train_loss = 3.35803395, grad/param norm = 2.7184e+00, time/batch = 0.2092s	
856/2700 (epoch 15.852), train_loss = 3.31844738, grad/param norm = 2.6634e+00, time/batch = 0.2007s	
857/2700 (epoch 15.870), train_loss = 3.32240460, grad/param norm = 2.5760e+00, time/batch = 0.2117s	
858/2700 (epoch 15.889), train_loss = 3.33759819, grad/param norm = 2.5915e+00, time/batch = 0.2015s	
859/2700 (epoch 15.907), train_loss = 3.38997561, grad/param norm = 2.7144e+00, time/batch = 0.1983s	
860/2700 (epoch 15.926), train_loss = 3.37280032, grad/param norm = 2.9841e+00, time/batch = 0.1971s	
861/2700 (epoch 15.944), train_loss = 3.39170995, grad/param norm = 2.5398e+00, time/batch = 0.1757s	
862/2700 (epoch 15.963), train_loss = 3.42398625, grad/param norm = 2.2398e+00, time/batch = 0.2080s	
863/2700 (epoch 15.981), train_loss = 3.48559922, grad/param norm = 2.1182e+00, time/batch = 0.2115s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
864/2700 (epoch 16.000), train_loss = 3.38035896, grad/param norm = 2.0364e+00, time/batch = 0.2354s	
865/2700 (epoch 16.019), train_loss = 3.29906134, grad/param norm = 2.0834e+00, time/batch = 0.2367s	
866/2700 (epoch 16.037), train_loss = 3.32963503, grad/param norm = 2.1655e+00, time/batch = 0.2338s	
867/2700 (epoch 16.056), train_loss = 3.31695715, grad/param norm = 1.8271e+00, time/batch = 0.2370s	
868/2700 (epoch 16.074), train_loss = 3.32999053, grad/param norm = 1.6516e+00, time/batch = 0.2356s	
869/2700 (epoch 16.093), train_loss = 3.35803746, grad/param norm = 1.7839e+00, time/batch = 0.2308s	
870/2700 (epoch 16.111), train_loss = 3.34237924, grad/param norm = 2.0903e+00, time/batch = 0.2167s	
871/2700 (epoch 16.130), train_loss = 3.37126571, grad/param norm = 2.2695e+00, time/batch = 0.2312s	
872/2700 (epoch 16.148), train_loss = 3.33181023, grad/param norm = 2.5664e+00, time/batch = 0.2349s	
873/2700 (epoch 16.167), train_loss = 3.36471578, grad/param norm = 2.7066e+00, time/batch = 0.2301s	
874/2700 (epoch 16.185), train_loss = 3.33865736, grad/param norm = 2.6354e+00, time/batch = 0.2013s	
875/2700 (epoch 16.204), train_loss = 3.26208079, grad/param norm = 2.5266e+00, time/batch = 0.2095s	
876/2700 (epoch 16.222), train_loss = 3.22913468, grad/param norm = 2.8297e+00, time/batch = 0.2101s	
877/2700 (epoch 16.241), train_loss = 3.24836207, grad/param norm = 2.4142e+00, time/batch = 0.2241s	
878/2700 (epoch 16.259), train_loss = 3.26779905, grad/param norm = 2.1358e+00, time/batch = 0.2344s	
879/2700 (epoch 16.278), train_loss = 3.35674953, grad/param norm = 2.5969e+00, time/batch = 0.2351s	
880/2700 (epoch 16.296), train_loss = 3.38078437, grad/param norm = 2.6780e+00, time/batch = 0.2345s	
881/2700 (epoch 16.315), train_loss = 3.35728165, grad/param norm = 2.2558e+00, time/batch = 0.2192s	
882/2700 (epoch 16.333), train_loss = 3.39585494, grad/param norm = 1.7981e+00, time/batch = 0.2095s	
883/2700 (epoch 16.352), train_loss = 3.39950690, grad/param norm = 1.8252e+00, time/batch = 0.2019s	
884/2700 (epoch 16.370), train_loss = 3.36445506, grad/param norm = 2.0844e+00, time/batch = 0.1785s	
885/2700 (epoch 16.389), train_loss = 3.31288330, grad/param norm = 2.1990e+00, time/batch = 0.1857s	
886/2700 (epoch 16.407), train_loss = 3.35779366, grad/param norm = 2.2908e+00, time/batch = 0.1541s	
887/2700 (epoch 16.426), train_loss = 3.35342310, grad/param norm = 2.3030e+00, time/batch = 0.1754s	
888/2700 (epoch 16.444), train_loss = 3.27892313, grad/param norm = 2.3645e+00, time/batch = 0.1825s	
889/2700 (epoch 16.463), train_loss = 3.31834867, grad/param norm = 2.7732e+00, time/batch = 0.1931s	
890/2700 (epoch 16.481), train_loss = 3.41569830, grad/param norm = 2.7522e+00, time/batch = 0.2085s	
891/2700 (epoch 16.500), train_loss = 3.45116267, grad/param norm = 2.5756e+00, time/batch = 0.1934s	
892/2700 (epoch 16.519), train_loss = 3.42030927, grad/param norm = 2.7720e+00, time/batch = 0.2002s	
893/2700 (epoch 16.537), train_loss = 3.43286553, grad/param norm = 2.5019e+00, time/batch = 0.2251s	
894/2700 (epoch 16.556), train_loss = 3.36271231, grad/param norm = 2.1156e+00, time/batch = 0.2322s	
895/2700 (epoch 16.574), train_loss = 3.27403734, grad/param norm = 1.7515e+00, time/batch = 0.2211s	
896/2700 (epoch 16.593), train_loss = 3.29067697, grad/param norm = 2.1393e+00, time/batch = 0.2070s	
897/2700 (epoch 16.611), train_loss = 3.24486139, grad/param norm = 2.0981e+00, time/batch = 0.2130s	
898/2700 (epoch 16.630), train_loss = 3.28855805, grad/param norm = 2.4627e+00, time/batch = 0.2037s	
899/2700 (epoch 16.648), train_loss = 3.39233172, grad/param norm = 2.5800e+00, time/batch = 0.2079s	
900/2700 (epoch 16.667), train_loss = 3.31896729, grad/param norm = 2.5691e+00, time/batch = 0.2178s	
901/2700 (epoch 16.685), train_loss = 3.31032129, grad/param norm = 2.3502e+00, time/batch = 0.2075s	
902/2700 (epoch 16.704), train_loss = 3.29758073, grad/param norm = 2.7112e+00, time/batch = 0.2102s	
903/2700 (epoch 16.722), train_loss = 3.31253251, grad/param norm = 2.3534e+00, time/batch = 0.1905s	
904/2700 (epoch 16.741), train_loss = 3.38914529, grad/param norm = 1.9950e+00, time/batch = 0.1888s	
905/2700 (epoch 16.759), train_loss = 3.34515441, grad/param norm = 2.0896e+00, time/batch = 0.1859s	
906/2700 (epoch 16.778), train_loss = 3.33173317, grad/param norm = 2.3909e+00, time/batch = 0.1782s	
907/2700 (epoch 16.796), train_loss = 3.35565207, grad/param norm = 2.4398e+00, time/batch = 0.1995s	
908/2700 (epoch 16.815), train_loss = 3.27081375, grad/param norm = 2.4545e+00, time/batch = 0.1950s	
909/2700 (epoch 16.833), train_loss = 3.33908260, grad/param norm = 2.7341e+00, time/batch = 0.1957s	
910/2700 (epoch 16.852), train_loss = 3.32242074, grad/param norm = 2.7864e+00, time/batch = 0.1872s	
911/2700 (epoch 16.870), train_loss = 3.32072732, grad/param norm = 2.5348e+00, time/batch = 0.2215s	
912/2700 (epoch 16.889), train_loss = 3.32492370, grad/param norm = 2.4327e+00, time/batch = 0.2049s	
913/2700 (epoch 16.907), train_loss = 3.37102044, grad/param norm = 2.5233e+00, time/batch = 0.1883s	
914/2700 (epoch 16.926), train_loss = 3.35481343, grad/param norm = 2.8472e+00, time/batch = 0.1725s	
915/2700 (epoch 16.944), train_loss = 3.38097421, grad/param norm = 2.4465e+00, time/batch = 0.1696s	
916/2700 (epoch 16.963), train_loss = 3.42148678, grad/param norm = 2.2221e+00, time/batch = 0.2185s	
917/2700 (epoch 16.981), train_loss = 3.48223122, grad/param norm = 2.0753e+00, time/batch = 0.2173s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
918/2700 (epoch 17.000), train_loss = 3.37821768, grad/param norm = 1.9687e+00, time/batch = 0.2309s	
919/2700 (epoch 17.019), train_loss = 3.29548001, grad/param norm = 2.0098e+00, time/batch = 0.2361s	
920/2700 (epoch 17.037), train_loss = 3.32715593, grad/param norm = 2.0858e+00, time/batch = 0.2375s	
921/2700 (epoch 17.056), train_loss = 3.31076606, grad/param norm = 1.7047e+00, time/batch = 0.2309s	
922/2700 (epoch 17.074), train_loss = 3.32544433, grad/param norm = 1.5211e+00, time/batch = 0.2345s	
923/2700 (epoch 17.093), train_loss = 3.35213784, grad/param norm = 1.6846e+00, time/batch = 0.2333s	
924/2700 (epoch 17.111), train_loss = 3.33652841, grad/param norm = 1.9744e+00, time/batch = 0.2262s	
925/2700 (epoch 17.130), train_loss = 3.36332273, grad/param norm = 2.1285e+00, time/batch = 0.2002s	
926/2700 (epoch 17.148), train_loss = 3.32256582, grad/param norm = 2.4294e+00, time/batch = 0.2068s	
927/2700 (epoch 17.167), train_loss = 3.35927297, grad/param norm = 2.6222e+00, time/batch = 0.2029s	
928/2700 (epoch 17.185), train_loss = 3.33394389, grad/param norm = 2.5939e+00, time/batch = 0.1983s	
929/2700 (epoch 17.204), train_loss = 3.25993108, grad/param norm = 2.5476e+00, time/batch = 0.2360s	
930/2700 (epoch 17.222), train_loss = 3.22926207, grad/param norm = 2.8480e+00, time/batch = 0.2363s	
931/2700 (epoch 17.241), train_loss = 3.24520280, grad/param norm = 2.4338e+00, time/batch = 0.2390s	
932/2700 (epoch 17.259), train_loss = 3.26655951, grad/param norm = 2.1660e+00, time/batch = 0.2348s	
933/2700 (epoch 17.278), train_loss = 3.35745579, grad/param norm = 2.6635e+00, time/batch = 0.2342s	
934/2700 (epoch 17.296), train_loss = 3.38926948, grad/param norm = 2.9125e+00, time/batch = 0.2365s	
935/2700 (epoch 17.315), train_loss = 3.35982201, grad/param norm = 2.1759e+00, time/batch = 0.2225s	
936/2700 (epoch 17.333), train_loss = 3.38577287, grad/param norm = 1.5712e+00, time/batch = 0.2363s	
937/2700 (epoch 17.352), train_loss = 3.38776228, grad/param norm = 1.5626e+00, time/batch = 0.2358s	
938/2700 (epoch 17.370), train_loss = 3.35194650, grad/param norm = 1.8398e+00, time/batch = 0.2251s	
939/2700 (epoch 17.389), train_loss = 3.30119886, grad/param norm = 1.9769e+00, time/batch = 0.1928s	
940/2700 (epoch 17.407), train_loss = 3.34946864, grad/param norm = 2.1185e+00, time/batch = 0.2259s	
941/2700 (epoch 17.426), train_loss = 3.34582647, grad/param norm = 2.2230e+00, time/batch = 0.2156s	
942/2700 (epoch 17.444), train_loss = 3.27464843, grad/param norm = 2.3500e+00, time/batch = 0.2258s	
943/2700 (epoch 17.463), train_loss = 3.31770547, grad/param norm = 2.7909e+00, time/batch = 0.2353s	
944/2700 (epoch 17.481), train_loss = 3.41708288, grad/param norm = 2.7659e+00, time/batch = 0.2322s	
945/2700 (epoch 17.500), train_loss = 3.45321753, grad/param norm = 2.6057e+00, time/batch = 0.2178s	
946/2700 (epoch 17.519), train_loss = 3.42247336, grad/param norm = 2.8010e+00, time/batch = 0.2137s	
947/2700 (epoch 17.537), train_loss = 3.42699618, grad/param norm = 2.4618e+00, time/batch = 0.2099s	
948/2700 (epoch 17.556), train_loss = 3.35399026, grad/param norm = 2.0483e+00, time/batch = 0.2056s	
949/2700 (epoch 17.574), train_loss = 3.27144051, grad/param norm = 1.7025e+00, time/batch = 0.2067s	
950/2700 (epoch 17.593), train_loss = 3.28564453, grad/param norm = 2.0823e+00, time/batch = 0.1870s	
951/2700 (epoch 17.611), train_loss = 3.23917502, grad/param norm = 2.0215e+00, time/batch = 0.1897s	
952/2700 (epoch 17.630), train_loss = 3.27775066, grad/param norm = 2.2765e+00, time/batch = 0.1691s	
953/2700 (epoch 17.648), train_loss = 3.37408187, grad/param norm = 2.4004e+00, time/batch = 0.1599s	
954/2700 (epoch 17.667), train_loss = 3.30807341, grad/param norm = 2.4395e+00, time/batch = 0.1664s	
955/2700 (epoch 17.685), train_loss = 3.30569031, grad/param norm = 2.3051e+00, time/batch = 0.1741s	
956/2700 (epoch 17.704), train_loss = 3.29479783, grad/param norm = 2.7194e+00, time/batch = 0.2056s	
957/2700 (epoch 17.722), train_loss = 3.30832861, grad/param norm = 2.3334e+00, time/batch = 0.2272s	
958/2700 (epoch 17.741), train_loss = 3.38477443, grad/param norm = 1.9810e+00, time/batch = 0.2217s	
959/2700 (epoch 17.759), train_loss = 3.34371791, grad/param norm = 2.0804e+00, time/batch = 0.2196s	
960/2700 (epoch 17.778), train_loss = 3.32788759, grad/param norm = 2.3574e+00, time/batch = 0.2051s	
961/2700 (epoch 17.796), train_loss = 3.34829728, grad/param norm = 2.3980e+00, time/batch = 0.2201s	
962/2700 (epoch 17.815), train_loss = 3.26660138, grad/param norm = 2.3876e+00, time/batch = 0.2162s	
963/2700 (epoch 17.833), train_loss = 3.33099182, grad/param norm = 2.6567e+00, time/batch = 0.2101s	
964/2700 (epoch 17.852), train_loss = 3.31642051, grad/param norm = 2.7158e+00, time/batch = 0.2062s	
965/2700 (epoch 17.870), train_loss = 3.31456354, grad/param norm = 2.4678e+00, time/batch = 0.1930s	
966/2700 (epoch 17.889), train_loss = 3.32092443, grad/param norm = 2.3616e+00, time/batch = 0.1945s	
967/2700 (epoch 17.907), train_loss = 3.36614198, grad/param norm = 2.4477e+00, time/batch = 0.2223s	
968/2700 (epoch 17.926), train_loss = 3.34946650, grad/param norm = 2.7745e+00, time/batch = 0.2347s	
969/2700 (epoch 17.944), train_loss = 3.37550751, grad/param norm = 2.3929e+00, time/batch = 0.2352s	
970/2700 (epoch 17.963), train_loss = 3.41525491, grad/param norm = 2.1438e+00, time/batch = 0.2353s	
971/2700 (epoch 17.981), train_loss = 3.47657960, grad/param norm = 2.0219e+00, time/batch = 0.2257s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
972/2700 (epoch 18.000), train_loss = 3.37369990, grad/param norm = 1.9222e+00, time/batch = 0.2366s	
973/2700 (epoch 18.019), train_loss = 3.29251723, grad/param norm = 1.9637e+00, time/batch = 0.2377s	
974/2700 (epoch 18.037), train_loss = 3.32297388, grad/param norm = 2.0333e+00, time/batch = 0.2327s	
975/2700 (epoch 18.056), train_loss = 3.30735581, grad/param norm = 1.6480e+00, time/batch = 0.2371s	
976/2700 (epoch 18.074), train_loss = 3.32287712, grad/param norm = 1.4571e+00, time/batch = 0.2319s	
977/2700 (epoch 18.093), train_loss = 3.34821528, grad/param norm = 1.6173e+00, time/batch = 0.2237s	
978/2700 (epoch 18.111), train_loss = 3.33091086, grad/param norm = 1.8906e+00, time/batch = 0.2077s	
979/2700 (epoch 18.130), train_loss = 3.35702748, grad/param norm = 2.0209e+00, time/batch = 0.1905s	
980/2700 (epoch 18.148), train_loss = 3.31572679, grad/param norm = 2.3259e+00, time/batch = 0.1817s	
981/2700 (epoch 18.167), train_loss = 3.35401914, grad/param norm = 2.5286e+00, time/batch = 0.2073s	
982/2700 (epoch 18.185), train_loss = 3.32793854, grad/param norm = 2.5124e+00, time/batch = 0.1907s	
983/2700 (epoch 18.204), train_loss = 3.25648152, grad/param norm = 2.5033e+00, time/batch = 0.2254s	
984/2700 (epoch 18.222), train_loss = 3.22545702, grad/param norm = 2.8021e+00, time/batch = 0.2151s	
985/2700 (epoch 18.241), train_loss = 3.24136276, grad/param norm = 2.4032e+00, time/batch = 0.2139s	
986/2700 (epoch 18.259), train_loss = 3.26385297, grad/param norm = 2.1512e+00, time/batch = 0.2089s	
987/2700 (epoch 18.278), train_loss = 3.35603694, grad/param norm = 2.6498e+00, time/batch = 0.1915s	
988/2700 (epoch 18.296), train_loss = 3.38657848, grad/param norm = 2.8934e+00, time/batch = 0.2350s	
989/2700 (epoch 18.315), train_loss = 3.35438800, grad/param norm = 2.1317e+00, time/batch = 0.2304s	
990/2700 (epoch 18.333), train_loss = 3.38305568, grad/param norm = 1.5299e+00, time/batch = 0.2163s	
991/2700 (epoch 18.352), train_loss = 3.38525974, grad/param norm = 1.5293e+00, time/batch = 0.2308s	
992/2700 (epoch 18.370), train_loss = 3.34861392, grad/param norm = 1.8042e+00, time/batch = 0.2257s	
993/2700 (epoch 18.389), train_loss = 3.29874219, grad/param norm = 1.9229e+00, time/batch = 0.1959s	
994/2700 (epoch 18.407), train_loss = 3.34407290, grad/param norm = 2.0413e+00, time/batch = 0.1947s	
995/2700 (epoch 18.426), train_loss = 3.33962793, grad/param norm = 2.1387e+00, time/batch = 0.2183s	
996/2700 (epoch 18.444), train_loss = 3.26790530, grad/param norm = 2.2689e+00, time/batch = 0.2294s	
997/2700 (epoch 18.463), train_loss = 3.31207254, grad/param norm = 2.7213e+00, time/batch = 0.2220s	
998/2700 (epoch 18.481), train_loss = 3.41231582, grad/param norm = 2.7133e+00, time/batch = 0.2291s	
999/2700 (epoch 18.500), train_loss = 3.44830911, grad/param norm = 2.5601e+00, time/batch = 0.2234s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch18.52_3.2945.t7	
1000/2700 (epoch 18.519), train_loss = 3.41581934, grad/param norm = 2.7154e+00, time/batch = 0.2191s	
1001/2700 (epoch 18.537), train_loss = 3.41893685, grad/param norm = 2.3921e+00, time/batch = 0.1699s	
1002/2700 (epoch 18.556), train_loss = 3.35045531, grad/param norm = 2.0073e+00, time/batch = 0.2147s	
1003/2700 (epoch 18.574), train_loss = 3.26825902, grad/param norm = 1.6487e+00, time/batch = 0.2280s	
1004/2700 (epoch 18.593), train_loss = 3.28238109, grad/param norm = 2.0125e+00, time/batch = 0.2314s	
1005/2700 (epoch 18.611), train_loss = 3.23618461, grad/param norm = 1.9796e+00, time/batch = 0.2276s	
1006/2700 (epoch 18.630), train_loss = 3.27801899, grad/param norm = 2.2853e+00, time/batch = 0.2374s	
1007/2700 (epoch 18.648), train_loss = 3.37407820, grad/param norm = 2.3839e+00, time/batch = 0.2360s	
1008/2700 (epoch 18.667), train_loss = 3.30444118, grad/param norm = 2.4099e+00, time/batch = 0.2351s	
1009/2700 (epoch 18.685), train_loss = 3.30065611, grad/param norm = 2.2628e+00, time/batch = 0.2358s	
1010/2700 (epoch 18.704), train_loss = 3.28813013, grad/param norm = 2.6643e+00, time/batch = 0.2366s	
1011/2700 (epoch 18.722), train_loss = 3.29852767, grad/param norm = 2.2557e+00, time/batch = 0.2188s	
1012/2700 (epoch 18.741), train_loss = 3.38006756, grad/param norm = 1.8843e+00, time/batch = 0.2177s	
1013/2700 (epoch 18.759), train_loss = 3.33472067, grad/param norm = 1.9609e+00, time/batch = 0.2043s	
1014/2700 (epoch 18.778), train_loss = 3.32203210, grad/param norm = 2.2663e+00, time/batch = 0.2047s	
1015/2700 (epoch 18.796), train_loss = 3.34171239, grad/param norm = 2.3248e+00, time/batch = 0.2064s	
1016/2700 (epoch 18.815), train_loss = 3.26339986, grad/param norm = 2.3297e+00, time/batch = 0.2282s	
1017/2700 (epoch 18.833), train_loss = 3.32700630, grad/param norm = 2.5895e+00, time/batch = 0.2357s	
1018/2700 (epoch 18.852), train_loss = 3.31174798, grad/param norm = 2.6549e+00, time/batch = 0.2337s	
1019/2700 (epoch 18.870), train_loss = 3.30999475, grad/param norm = 2.4344e+00, time/batch = 0.2305s	
1020/2700 (epoch 18.889), train_loss = 3.31764450, grad/param norm = 2.3235e+00, time/batch = 0.2265s	
1021/2700 (epoch 18.907), train_loss = 3.36215005, grad/param norm = 2.4070e+00, time/batch = 0.2189s	
1022/2700 (epoch 18.926), train_loss = 3.34489109, grad/param norm = 2.7250e+00, time/batch = 0.2252s	
1023/2700 (epoch 18.944), train_loss = 3.36848828, grad/param norm = 2.3339e+00, time/batch = 0.2363s	
1024/2700 (epoch 18.963), train_loss = 3.40948300, grad/param norm = 2.0691e+00, time/batch = 0.2369s	
1025/2700 (epoch 18.981), train_loss = 3.46877877, grad/param norm = 1.9616e+00, time/batch = 0.2253s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1026/2700 (epoch 19.000), train_loss = 3.36964419, grad/param norm = 1.8708e+00, time/batch = 0.1914s	
1027/2700 (epoch 19.019), train_loss = 3.28917496, grad/param norm = 1.9154e+00, time/batch = 0.1739s	
1028/2700 (epoch 19.037), train_loss = 3.31854731, grad/param norm = 1.9755e+00, time/batch = 0.1757s	
1029/2700 (epoch 19.056), train_loss = 3.30374475, grad/param norm = 1.5777e+00, time/batch = 0.1827s	
1030/2700 (epoch 19.074), train_loss = 3.32013730, grad/param norm = 1.3853e+00, time/batch = 0.1969s	
1031/2700 (epoch 19.093), train_loss = 3.34403394, grad/param norm = 1.5507e+00, time/batch = 0.1711s	
1032/2700 (epoch 19.111), train_loss = 3.32580131, grad/param norm = 1.8076e+00, time/batch = 0.1955s	
1033/2700 (epoch 19.130), train_loss = 3.35123833, grad/param norm = 1.9196e+00, time/batch = 0.1813s	
1034/2700 (epoch 19.148), train_loss = 3.31000852, grad/param norm = 2.2319e+00, time/batch = 0.1930s	
1035/2700 (epoch 19.167), train_loss = 3.34723355, grad/param norm = 2.4416e+00, time/batch = 0.1843s	
1036/2700 (epoch 19.185), train_loss = 3.32276477, grad/param norm = 2.4394e+00, time/batch = 0.1606s	
1037/2700 (epoch 19.204), train_loss = 3.25246318, grad/param norm = 2.4676e+00, time/batch = 0.1782s	
1038/2700 (epoch 19.222), train_loss = 3.22228826, grad/param norm = 2.7687e+00, time/batch = 0.1910s	
1039/2700 (epoch 19.241), train_loss = 3.23754167, grad/param norm = 2.3825e+00, time/batch = 0.2105s	
1040/2700 (epoch 19.259), train_loss = 3.26204582, grad/param norm = 2.1501e+00, time/batch = 0.2234s	
1041/2700 (epoch 19.278), train_loss = 3.35510205, grad/param norm = 2.6401e+00, time/batch = 0.2087s	
1042/2700 (epoch 19.296), train_loss = 3.38322259, grad/param norm = 2.8648e+00, time/batch = 0.2181s	
1043/2700 (epoch 19.315), train_loss = 3.34877662, grad/param norm = 2.0847e+00, time/batch = 0.2268s	
1044/2700 (epoch 19.333), train_loss = 3.38039135, grad/param norm = 1.4879e+00, time/batch = 0.2252s	
1045/2700 (epoch 19.352), train_loss = 3.38286435, grad/param norm = 1.4896e+00, time/batch = 0.2335s	
1046/2700 (epoch 19.370), train_loss = 3.34524384, grad/param norm = 1.7529e+00, time/batch = 0.2310s	
1047/2700 (epoch 19.389), train_loss = 3.29602110, grad/param norm = 1.8521e+00, time/batch = 0.2432s	
1048/2700 (epoch 19.407), train_loss = 3.33845943, grad/param norm = 1.9527e+00, time/batch = 0.2368s	
1049/2700 (epoch 19.426), train_loss = 3.33371150, grad/param norm = 2.0394e+00, time/batch = 0.2222s	
1050/2700 (epoch 19.444), train_loss = 3.26098883, grad/param norm = 2.1742e+00, time/batch = 0.2125s	
1051/2700 (epoch 19.463), train_loss = 3.30865145, grad/param norm = 2.6187e+00, time/batch = 0.2359s	
1052/2700 (epoch 19.481), train_loss = 3.41013911, grad/param norm = 2.6517e+00, time/batch = 0.2354s	
1053/2700 (epoch 19.500), train_loss = 3.44454588, grad/param norm = 2.5378e+00, time/batch = 0.2226s	
1054/2700 (epoch 19.519), train_loss = 3.40674494, grad/param norm = 2.6218e+00, time/batch = 0.2131s	
1055/2700 (epoch 19.537), train_loss = 3.40599294, grad/param norm = 2.2962e+00, time/batch = 0.1843s	
1056/2700 (epoch 19.556), train_loss = 3.34183691, grad/param norm = 1.9299e+00, time/batch = 0.2292s	
1057/2700 (epoch 19.574), train_loss = 3.26410212, grad/param norm = 1.5899e+00, time/batch = 0.2205s	
1058/2700 (epoch 19.593), train_loss = 3.27988694, grad/param norm = 1.9614e+00, time/batch = 0.2139s	
1059/2700 (epoch 19.611), train_loss = 3.23937465, grad/param norm = 1.9968e+00, time/batch = 0.2117s	
1060/2700 (epoch 19.630), train_loss = 3.28395252, grad/param norm = 2.4105e+00, time/batch = 0.2032s	
1061/2700 (epoch 19.648), train_loss = 3.37608819, grad/param norm = 2.3630e+00, time/batch = 0.2365s	
1062/2700 (epoch 19.667), train_loss = 3.30086606, grad/param norm = 2.4116e+00, time/batch = 0.2351s	
1063/2700 (epoch 19.685), train_loss = 3.29976288, grad/param norm = 2.2249e+00, time/batch = 0.2344s	
1064/2700 (epoch 19.704), train_loss = 3.28277121, grad/param norm = 2.5522e+00, time/batch = 0.2363s	
1065/2700 (epoch 19.722), train_loss = 3.29080059, grad/param norm = 2.1391e+00, time/batch = 0.2360s	
1066/2700 (epoch 19.741), train_loss = 3.36309866, grad/param norm = 1.6693e+00, time/batch = 0.2072s	
1067/2700 (epoch 19.759), train_loss = 3.31721260, grad/param norm = 1.8298e+00, time/batch = 0.1756s	
1068/2700 (epoch 19.778), train_loss = 3.31529537, grad/param norm = 2.1576e+00, time/batch = 0.1801s	
1069/2700 (epoch 19.796), train_loss = 3.33426224, grad/param norm = 2.2322e+00, time/batch = 0.1891s	
1070/2700 (epoch 19.815), train_loss = 3.26047016, grad/param norm = 2.2639e+00, time/batch = 0.1919s	
1071/2700 (epoch 19.833), train_loss = 3.32337383, grad/param norm = 2.5328e+00, time/batch = 0.2003s	
1072/2700 (epoch 19.852), train_loss = 3.30860810, grad/param norm = 2.6157e+00, time/batch = 0.1970s	
1073/2700 (epoch 19.870), train_loss = 3.30670561, grad/param norm = 2.4201e+00, time/batch = 0.1896s	
1074/2700 (epoch 19.889), train_loss = 3.31576820, grad/param norm = 2.3005e+00, time/batch = 0.1898s	
1075/2700 (epoch 19.907), train_loss = 3.35878506, grad/param norm = 2.3842e+00, time/batch = 0.1958s	
1076/2700 (epoch 19.926), train_loss = 3.34188531, grad/param norm = 2.7100e+00, time/batch = 0.1912s	
1077/2700 (epoch 19.944), train_loss = 3.36389384, grad/param norm = 2.2843e+00, time/batch = 0.1588s	
1078/2700 (epoch 19.963), train_loss = 3.40345721, grad/param norm = 1.9696e+00, time/batch = 0.1789s	
1079/2700 (epoch 19.981), train_loss = 3.46208716, grad/param norm = 1.8904e+00, time/batch = 0.1844s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1080/2700 (epoch 20.000), train_loss = 3.36597689, grad/param norm = 1.8229e+00, time/batch = 0.1888s	
1081/2700 (epoch 20.019), train_loss = 3.28706159, grad/param norm = 1.8714e+00, time/batch = 0.2069s	
1082/2700 (epoch 20.037), train_loss = 3.31588003, grad/param norm = 1.9176e+00, time/batch = 0.2183s	
1083/2700 (epoch 20.056), train_loss = 3.30000489, grad/param norm = 1.5059e+00, time/batch = 0.2261s	
1084/2700 (epoch 20.074), train_loss = 3.31750919, grad/param norm = 1.3123e+00, time/batch = 0.2274s	
1085/2700 (epoch 20.093), train_loss = 3.34025808, grad/param norm = 1.4876e+00, time/batch = 0.2187s	
1086/2700 (epoch 20.111), train_loss = 3.32122733, grad/param norm = 1.7238e+00, time/batch = 0.2215s	
1087/2700 (epoch 20.130), train_loss = 3.34558023, grad/param norm = 1.8123e+00, time/batch = 0.2003s	
1088/2700 (epoch 20.148), train_loss = 3.30395406, grad/param norm = 2.1281e+00, time/batch = 0.1923s	
1089/2700 (epoch 20.167), train_loss = 3.34079553, grad/param norm = 2.3416e+00, time/batch = 0.1790s	
1090/2700 (epoch 20.185), train_loss = 3.31697434, grad/param norm = 2.3450e+00, time/batch = 0.1385s	
1091/2700 (epoch 20.204), train_loss = 3.24817823, grad/param norm = 2.4223e+00, time/batch = 0.2027s	
1092/2700 (epoch 20.222), train_loss = 3.21943852, grad/param norm = 2.7372e+00, time/batch = 0.1949s	
1093/2700 (epoch 20.241), train_loss = 3.23433370, grad/param norm = 2.3818e+00, time/batch = 0.2088s	
1094/2700 (epoch 20.259), train_loss = 3.26138691, grad/param norm = 2.1723e+00, time/batch = 0.2145s	
1095/2700 (epoch 20.278), train_loss = 3.35471972, grad/param norm = 2.6433e+00, time/batch = 0.2104s	
1096/2700 (epoch 20.296), train_loss = 3.37905347, grad/param norm = 2.8149e+00, time/batch = 0.2060s	
1097/2700 (epoch 20.315), train_loss = 3.34286220, grad/param norm = 2.0405e+00, time/batch = 0.1991s	
1098/2700 (epoch 20.333), train_loss = 3.37827323, grad/param norm = 1.4518e+00, time/batch = 0.1817s	
1099/2700 (epoch 20.352), train_loss = 3.38072674, grad/param norm = 1.4569e+00, time/batch = 0.2054s	
1100/2700 (epoch 20.370), train_loss = 3.34244113, grad/param norm = 1.7080e+00, time/batch = 0.1867s	
1101/2700 (epoch 20.389), train_loss = 3.29376776, grad/param norm = 1.7894e+00, time/batch = 0.2127s	
1102/2700 (epoch 20.407), train_loss = 3.33408304, grad/param norm = 1.8722e+00, time/batch = 0.2034s	
1103/2700 (epoch 20.426), train_loss = 3.32902742, grad/param norm = 1.9422e+00, time/batch = 0.1980s	
1104/2700 (epoch 20.444), train_loss = 3.25478588, grad/param norm = 2.0741e+00, time/batch = 0.2000s	
1105/2700 (epoch 20.463), train_loss = 3.30438556, grad/param norm = 2.5073e+00, time/batch = 0.2103s	
1106/2700 (epoch 20.481), train_loss = 3.40525282, grad/param norm = 2.5819e+00, time/batch = 0.2186s	
1107/2700 (epoch 20.500), train_loss = 3.44145640, grad/param norm = 2.4955e+00, time/batch = 0.2213s	
1108/2700 (epoch 20.519), train_loss = 3.40140656, grad/param norm = 2.6019e+00, time/batch = 0.2017s	
1109/2700 (epoch 20.537), train_loss = 3.41906909, grad/param norm = 2.4231e+00, time/batch = 0.2048s	
1110/2700 (epoch 20.556), train_loss = 3.36410532, grad/param norm = 1.9453e+00, time/batch = 0.2063s	
1111/2700 (epoch 20.574), train_loss = 3.26100584, grad/param norm = 1.4958e+00, time/batch = 0.2299s	
1112/2700 (epoch 20.593), train_loss = 3.27527270, grad/param norm = 1.8659e+00, time/batch = 0.2358s	
1113/2700 (epoch 20.611), train_loss = 3.22871409, grad/param norm = 1.8293e+00, time/batch = 0.2369s	
1114/2700 (epoch 20.630), train_loss = 3.26325864, grad/param norm = 2.0456e+00, time/batch = 0.2352s	
1115/2700 (epoch 20.648), train_loss = 3.35122648, grad/param norm = 2.0915e+00, time/batch = 0.2280s	
1116/2700 (epoch 20.667), train_loss = 3.28190114, grad/param norm = 2.1380e+00, time/batch = 0.2163s	
1117/2700 (epoch 20.685), train_loss = 3.28207262, grad/param norm = 1.9513e+00, time/batch = 0.2064s	
1118/2700 (epoch 20.704), train_loss = 3.26483674, grad/param norm = 2.2136e+00, time/batch = 0.2042s	
1119/2700 (epoch 20.722), train_loss = 3.27763614, grad/param norm = 2.0757e+00, time/batch = 0.1951s	
1120/2700 (epoch 20.741), train_loss = 3.37089100, grad/param norm = 1.7850e+00, time/batch = 0.1786s	
1121/2700 (epoch 20.759), train_loss = 3.31834450, grad/param norm = 1.8874e+00, time/batch = 0.2354s	
1122/2700 (epoch 20.778), train_loss = 3.32079232, grad/param norm = 2.1935e+00, time/batch = 0.2354s	
1123/2700 (epoch 20.796), train_loss = 3.33934018, grad/param norm = 2.2759e+00, time/batch = 0.2347s	
1124/2700 (epoch 20.815), train_loss = 3.26280726, grad/param norm = 2.3214e+00, time/batch = 0.2368s	
1125/2700 (epoch 20.833), train_loss = 3.32551490, grad/param norm = 2.5920e+00, time/batch = 0.2362s	
1126/2700 (epoch 20.852), train_loss = 3.30560497, grad/param norm = 2.6502e+00, time/batch = 0.2357s	
1127/2700 (epoch 20.870), train_loss = 3.30174139, grad/param norm = 2.3330e+00, time/batch = 0.2356s	
1128/2700 (epoch 20.889), train_loss = 3.31180153, grad/param norm = 2.2247e+00, time/batch = 0.2356s	
1129/2700 (epoch 20.907), train_loss = 3.35527739, grad/param norm = 2.3446e+00, time/batch = 0.2020s	
1130/2700 (epoch 20.926), train_loss = 3.34121023, grad/param norm = 2.7558e+00, time/batch = 0.1745s	
1131/2700 (epoch 20.944), train_loss = 3.36618180, grad/param norm = 2.2576e+00, time/batch = 0.1935s	
1132/2700 (epoch 20.963), train_loss = 3.39295892, grad/param norm = 1.8190e+00, time/batch = 0.2240s	
1133/2700 (epoch 20.981), train_loss = 3.46212169, grad/param norm = 1.9776e+00, time/batch = 0.2351s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1134/2700 (epoch 21.000), train_loss = 3.36553380, grad/param norm = 1.8730e+00, time/batch = 0.2341s	
1135/2700 (epoch 21.019), train_loss = 3.28805183, grad/param norm = 1.9501e+00, time/batch = 0.2360s	
1136/2700 (epoch 21.037), train_loss = 3.31597241, grad/param norm = 1.9920e+00, time/batch = 0.2368s	
1137/2700 (epoch 21.056), train_loss = 3.29962770, grad/param norm = 1.5546e+00, time/batch = 0.2334s	
1138/2700 (epoch 21.074), train_loss = 3.31858603, grad/param norm = 1.3615e+00, time/batch = 0.2279s	
1139/2700 (epoch 21.093), train_loss = 3.33946561, grad/param norm = 1.5226e+00, time/batch = 0.2004s	
1140/2700 (epoch 21.111), train_loss = 3.31919439, grad/param norm = 1.7085e+00, time/batch = 0.2190s	
1141/2700 (epoch 21.130), train_loss = 3.33962901, grad/param norm = 1.7534e+00, time/batch = 0.2079s	
1142/2700 (epoch 21.148), train_loss = 3.29980596, grad/param norm = 2.0699e+00, time/batch = 0.1738s	
1143/2700 (epoch 21.167), train_loss = 3.33595324, grad/param norm = 2.2835e+00, time/batch = 0.1849s	
1144/2700 (epoch 21.185), train_loss = 3.31271246, grad/param norm = 2.2451e+00, time/batch = 0.1643s	
1145/2700 (epoch 21.204), train_loss = 3.24000277, grad/param norm = 2.2642e+00, time/batch = 0.2116s	
1146/2700 (epoch 21.222), train_loss = 3.21390606, grad/param norm = 2.5852e+00, time/batch = 0.2121s	
1147/2700 (epoch 21.241), train_loss = 3.23386643, grad/param norm = 2.3569e+00, time/batch = 0.2006s	
1148/2700 (epoch 21.259), train_loss = 3.27171686, grad/param norm = 2.3637e+00, time/batch = 0.2106s	
1149/2700 (epoch 21.278), train_loss = 3.36947685, grad/param norm = 2.6477e+00, time/batch = 0.2090s	
1150/2700 (epoch 21.296), train_loss = 3.35188165, grad/param norm = 2.2668e+00, time/batch = 0.2206s	
1151/2700 (epoch 21.315), train_loss = 3.31194805, grad/param norm = 1.8183e+00, time/batch = 0.2159s	
1152/2700 (epoch 21.333), train_loss = 3.37795786, grad/param norm = 1.5230e+00, time/batch = 0.2263s	
1153/2700 (epoch 21.352), train_loss = 3.38221960, grad/param norm = 1.5736e+00, time/batch = 0.2349s	
1154/2700 (epoch 21.370), train_loss = 3.34368651, grad/param norm = 1.8204e+00, time/batch = 0.2349s	
1155/2700 (epoch 21.389), train_loss = 3.29593639, grad/param norm = 1.8715e+00, time/batch = 0.2251s	
1156/2700 (epoch 21.407), train_loss = 3.33320007, grad/param norm = 1.9026e+00, time/batch = 0.2353s	
1157/2700 (epoch 21.426), train_loss = 3.32612591, grad/param norm = 1.8908e+00, time/batch = 0.2353s	
1158/2700 (epoch 21.444), train_loss = 3.25066818, grad/param norm = 1.9792e+00, time/batch = 0.2292s	
1159/2700 (epoch 21.463), train_loss = 3.30307576, grad/param norm = 2.3560e+00, time/batch = 0.2158s	
1160/2700 (epoch 21.481), train_loss = 3.40261395, grad/param norm = 2.4620e+00, time/batch = 0.1778s	
1161/2700 (epoch 21.500), train_loss = 3.43871242, grad/param norm = 2.4901e+00, time/batch = 0.2366s	
1162/2700 (epoch 21.519), train_loss = 3.40592946, grad/param norm = 2.6237e+00, time/batch = 0.2216s	
1163/2700 (epoch 21.537), train_loss = 3.41784386, grad/param norm = 2.4367e+00, time/batch = 0.2122s	
1164/2700 (epoch 21.556), train_loss = 3.35383936, grad/param norm = 1.8714e+00, time/batch = 0.1996s	
1165/2700 (epoch 21.574), train_loss = 3.25684980, grad/param norm = 1.4370e+00, time/batch = 0.2127s	
1166/2700 (epoch 21.593), train_loss = 3.27075222, grad/param norm = 1.7923e+00, time/batch = 0.2116s	
1167/2700 (epoch 21.611), train_loss = 3.22382561, grad/param norm = 1.7562e+00, time/batch = 0.2284s	
1168/2700 (epoch 21.630), train_loss = 3.26086700, grad/param norm = 1.9555e+00, time/batch = 0.2234s	
1169/2700 (epoch 21.648), train_loss = 3.34186058, grad/param norm = 2.0050e+00, time/batch = 0.2177s	
1170/2700 (epoch 21.667), train_loss = 3.27779230, grad/param norm = 2.0883e+00, time/batch = 0.1922s	
1171/2700 (epoch 21.685), train_loss = 3.27213910, grad/param norm = 1.8537e+00, time/batch = 0.2155s	
1172/2700 (epoch 21.704), train_loss = 3.24479943, grad/param norm = 2.0418e+00, time/batch = 0.2179s	
1173/2700 (epoch 21.722), train_loss = 3.25778753, grad/param norm = 1.9438e+00, time/batch = 0.2279s	
1174/2700 (epoch 21.741), train_loss = 3.37131876, grad/param norm = 1.8043e+00, time/batch = 0.2307s	
1175/2700 (epoch 21.759), train_loss = 3.32275534, grad/param norm = 1.9304e+00, time/batch = 0.2160s	
1176/2700 (epoch 21.778), train_loss = 3.31951135, grad/param norm = 2.2593e+00, time/batch = 0.2097s	
1177/2700 (epoch 21.796), train_loss = 3.34295252, grad/param norm = 2.3171e+00, time/batch = 0.1929s	
1178/2700 (epoch 21.815), train_loss = 3.25896340, grad/param norm = 2.2272e+00, time/batch = 0.2336s	
1179/2700 (epoch 21.833), train_loss = 3.31885582, grad/param norm = 2.3795e+00, time/batch = 0.2389s	
1180/2700 (epoch 21.852), train_loss = 3.29681773, grad/param norm = 2.4850e+00, time/batch = 0.2206s	
1181/2700 (epoch 21.870), train_loss = 3.30009406, grad/param norm = 2.2626e+00, time/batch = 0.2234s	
1182/2700 (epoch 21.889), train_loss = 3.30941793, grad/param norm = 2.1605e+00, time/batch = 0.2209s	
1183/2700 (epoch 21.907), train_loss = 3.35702053, grad/param norm = 2.2740e+00, time/batch = 0.2136s	
1184/2700 (epoch 21.926), train_loss = 3.32279464, grad/param norm = 2.3792e+00, time/batch = 0.2123s	
1185/2700 (epoch 21.944), train_loss = 3.33699933, grad/param norm = 1.9179e+00, time/batch = 0.2127s	
1186/2700 (epoch 21.963), train_loss = 3.37601533, grad/param norm = 1.5878e+00, time/batch = 0.2158s	
1187/2700 (epoch 21.981), train_loss = 3.43752184, grad/param norm = 1.5642e+00, time/batch = 0.2146s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1188/2700 (epoch 22.000), train_loss = 3.35281569, grad/param norm = 1.7098e+00, time/batch = 0.2101s	
1189/2700 (epoch 22.019), train_loss = 3.28408312, grad/param norm = 1.8828e+00, time/batch = 0.1981s	
1190/2700 (epoch 22.037), train_loss = 3.31519062, grad/param norm = 1.9322e+00, time/batch = 0.1776s	
1191/2700 (epoch 22.056), train_loss = 3.30153666, grad/param norm = 1.5458e+00, time/batch = 0.2141s	
1192/2700 (epoch 22.074), train_loss = 3.32086667, grad/param norm = 1.3771e+00, time/batch = 0.2023s	
1193/2700 (epoch 22.093), train_loss = 3.33677068, grad/param norm = 1.4895e+00, time/batch = 0.2103s	
1194/2700 (epoch 22.111), train_loss = 3.31503531, grad/param norm = 1.6781e+00, time/batch = 0.2195s	
1195/2700 (epoch 22.130), train_loss = 3.34096548, grad/param norm = 1.7513e+00, time/batch = 0.2326s	
1196/2700 (epoch 22.148), train_loss = 3.29880239, grad/param norm = 2.1477e+00, time/batch = 0.2313s	
1197/2700 (epoch 22.167), train_loss = 3.33937055, grad/param norm = 2.2570e+00, time/batch = 0.2312s	
1198/2700 (epoch 22.185), train_loss = 3.29826871, grad/param norm = 2.0447e+00, time/batch = 0.2224s	
1199/2700 (epoch 22.204), train_loss = 3.23194112, grad/param norm = 2.1099e+00, time/batch = 0.2260s	
1200/2700 (epoch 22.222), train_loss = 3.21440483, grad/param norm = 2.5328e+00, time/batch = 0.2250s	
1201/2700 (epoch 22.241), train_loss = 3.23913843, grad/param norm = 2.2261e+00, time/batch = 0.2308s	
1202/2700 (epoch 22.259), train_loss = 3.26756775, grad/param norm = 1.9833e+00, time/batch = 0.2245s	
1203/2700 (epoch 22.278), train_loss = 3.34564577, grad/param norm = 2.4776e+00, time/batch = 0.2217s	
1204/2700 (epoch 22.296), train_loss = 3.36477542, grad/param norm = 2.4655e+00, time/batch = 0.2180s	
1205/2700 (epoch 22.315), train_loss = 3.32630497, grad/param norm = 2.0433e+00, time/batch = 0.2151s	
1206/2700 (epoch 22.333), train_loss = 3.38013999, grad/param norm = 1.6819e+00, time/batch = 0.2052s	
1207/2700 (epoch 22.352), train_loss = 3.38624719, grad/param norm = 1.7295e+00, time/batch = 0.1879s	
1208/2700 (epoch 22.370), train_loss = 3.34639611, grad/param norm = 1.9577e+00, time/batch = 0.1717s	
1209/2700 (epoch 22.389), train_loss = 3.29878836, grad/param norm = 2.0058e+00, time/batch = 0.1666s	
1210/2700 (epoch 22.407), train_loss = 3.33077902, grad/param norm = 2.0121e+00, time/batch = 0.2147s	
1211/2700 (epoch 22.426), train_loss = 3.32931756, grad/param norm = 1.9617e+00, time/batch = 0.1983s	
1212/2700 (epoch 22.444), train_loss = 3.25270646, grad/param norm = 2.0547e+00, time/batch = 0.2229s	
1213/2700 (epoch 22.463), train_loss = 3.30408074, grad/param norm = 2.3409e+00, time/batch = 0.2305s	
1214/2700 (epoch 22.481), train_loss = 3.39955292, grad/param norm = 2.3947e+00, time/batch = 0.2282s	
1215/2700 (epoch 22.500), train_loss = 3.43321845, grad/param norm = 2.3828e+00, time/batch = 0.2332s	
1216/2700 (epoch 22.519), train_loss = 3.38963688, grad/param norm = 2.4004e+00, time/batch = 0.2343s	
1217/2700 (epoch 22.537), train_loss = 3.39328469, grad/param norm = 2.1406e+00, time/batch = 0.2324s	
1218/2700 (epoch 22.556), train_loss = 3.33313293, grad/param norm = 1.7815e+00, time/batch = 0.2350s	
1219/2700 (epoch 22.574), train_loss = 3.25504403, grad/param norm = 1.3914e+00, time/batch = 0.2190s	
1220/2700 (epoch 22.593), train_loss = 3.26795826, grad/param norm = 1.7273e+00, time/batch = 0.1920s	
1221/2700 (epoch 22.611), train_loss = 3.21560868, grad/param norm = 1.6539e+00, time/batch = 0.1940s	
1222/2700 (epoch 22.630), train_loss = 3.25504126, grad/param norm = 1.8813e+00, time/batch = 0.2139s	
1223/2700 (epoch 22.648), train_loss = 3.34419540, grad/param norm = 2.0029e+00, time/batch = 0.2240s	
1224/2700 (epoch 22.667), train_loss = 3.28045760, grad/param norm = 2.0469e+00, time/batch = 0.2361s	
1225/2700 (epoch 22.685), train_loss = 3.27002849, grad/param norm = 1.8953e+00, time/batch = 0.2350s	
1226/2700 (epoch 22.704), train_loss = 3.25056368, grad/param norm = 2.1309e+00, time/batch = 0.2349s	
1227/2700 (epoch 22.722), train_loss = 3.25939945, grad/param norm = 2.1053e+00, time/batch = 0.2367s	
1228/2700 (epoch 22.741), train_loss = 3.37401669, grad/param norm = 2.1095e+00, time/batch = 0.2370s	
1229/2700 (epoch 22.759), train_loss = 3.34536736, grad/param norm = 2.3604e+00, time/batch = 0.2327s	
1230/2700 (epoch 22.778), train_loss = 3.32470679, grad/param norm = 2.4997e+00, time/batch = 0.2332s	
1231/2700 (epoch 22.796), train_loss = 3.33672684, grad/param norm = 2.4865e+00, time/batch = 0.2273s	
1232/2700 (epoch 22.815), train_loss = 3.26543493, grad/param norm = 2.3852e+00, time/batch = 0.2344s	
1233/2700 (epoch 22.833), train_loss = 3.31970800, grad/param norm = 2.3940e+00, time/batch = 0.2261s	
1234/2700 (epoch 22.852), train_loss = 3.29253884, grad/param norm = 2.3023e+00, time/batch = 0.2089s	
1235/2700 (epoch 22.870), train_loss = 3.28333921, grad/param norm = 1.9915e+00, time/batch = 0.2005s	
1236/2700 (epoch 22.889), train_loss = 3.28970994, grad/param norm = 1.7960e+00, time/batch = 0.1984s	
1237/2700 (epoch 22.907), train_loss = 3.33857067, grad/param norm = 1.8574e+00, time/batch = 0.1911s	
1238/2700 (epoch 22.926), train_loss = 3.31106900, grad/param norm = 2.1298e+00, time/batch = 0.1999s	
1239/2700 (epoch 22.944), train_loss = 3.33277370, grad/param norm = 1.9265e+00, time/batch = 0.2088s	
1240/2700 (epoch 22.963), train_loss = 3.39128346, grad/param norm = 1.7720e+00, time/batch = 0.2301s	
1241/2700 (epoch 22.981), train_loss = 3.45095304, grad/param norm = 1.7645e+00, time/batch = 0.1965s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1242/2700 (epoch 23.000), train_loss = 3.35601714, grad/param norm = 1.7165e+00, time/batch = 0.2045s	
1243/2700 (epoch 23.019), train_loss = 3.27991389, grad/param norm = 1.7699e+00, time/batch = 0.2099s	
1244/2700 (epoch 23.037), train_loss = 3.30671238, grad/param norm = 1.7846e+00, time/batch = 0.2083s	
1245/2700 (epoch 23.056), train_loss = 3.29276711, grad/param norm = 1.3810e+00, time/batch = 0.2062s	
1246/2700 (epoch 23.074), train_loss = 3.31329926, grad/param norm = 1.2027e+00, time/batch = 0.1861s	
1247/2700 (epoch 23.093), train_loss = 3.33254485, grad/param norm = 1.3647e+00, time/batch = 0.1803s	
1248/2700 (epoch 23.111), train_loss = 3.31042338, grad/param norm = 1.5622e+00, time/batch = 0.1799s	
1249/2700 (epoch 23.130), train_loss = 3.33366593, grad/param norm = 1.6081e+00, time/batch = 0.1732s	
1250/2700 (epoch 23.148), train_loss = 3.29051151, grad/param norm = 1.9518e+00, time/batch = 0.1907s	
1251/2700 (epoch 23.167), train_loss = 3.32854305, grad/param norm = 2.1621e+00, time/batch = 0.1969s	
1252/2700 (epoch 23.185), train_loss = 3.30338978, grad/param norm = 2.1327e+00, time/batch = 0.1857s	
1253/2700 (epoch 23.204), train_loss = 3.23582727, grad/param norm = 2.2330e+00, time/batch = 0.2244s	
1254/2700 (epoch 23.222), train_loss = 3.20968792, grad/param norm = 2.5711e+00, time/batch = 0.2263s	
1255/2700 (epoch 23.241), train_loss = 3.22569014, grad/param norm = 2.2711e+00, time/batch = 0.2317s	
1256/2700 (epoch 23.259), train_loss = 3.25554258, grad/param norm = 2.0841e+00, time/batch = 0.2214s	
1257/2700 (epoch 23.278), train_loss = 3.34688118, grad/param norm = 2.5297e+00, time/batch = 0.2118s	
1258/2700 (epoch 23.296), train_loss = 3.36563831, grad/param norm = 2.6369e+00, time/batch = 0.1972s	
1259/2700 (epoch 23.315), train_loss = 3.32890261, grad/param norm = 1.9169e+00, time/batch = 0.2007s	
1260/2700 (epoch 23.333), train_loss = 3.37141167, grad/param norm = 1.3561e+00, time/batch = 0.2198s	
1261/2700 (epoch 23.352), train_loss = 3.37513509, grad/param norm = 1.3812e+00, time/batch = 0.2118s	
1262/2700 (epoch 23.370), train_loss = 3.33491462, grad/param norm = 1.6156e+00, time/batch = 0.2124s	
1263/2700 (epoch 23.389), train_loss = 3.28849729, grad/param norm = 1.6598e+00, time/batch = 0.2232s	
1264/2700 (epoch 23.407), train_loss = 3.32303103, grad/param norm = 1.6984e+00, time/batch = 0.2362s	
1265/2700 (epoch 23.426), train_loss = 3.31966327, grad/param norm = 1.7287e+00, time/batch = 0.2370s	
1266/2700 (epoch 23.444), train_loss = 3.24377183, grad/param norm = 1.8565e+00, time/batch = 0.2365s	
1267/2700 (epoch 23.463), train_loss = 3.29881072, grad/param norm = 2.2649e+00, time/batch = 0.2359s	
1268/2700 (epoch 23.481), train_loss = 3.40165200, grad/param norm = 2.4250e+00, time/batch = 0.2226s	
1269/2700 (epoch 23.500), train_loss = 3.43610042, grad/param norm = 2.4661e+00, time/batch = 0.2162s	
1270/2700 (epoch 23.519), train_loss = 3.39481989, grad/param norm = 2.5066e+00, time/batch = 0.2078s	
1271/2700 (epoch 23.537), train_loss = 3.39737480, grad/param norm = 2.2122e+00, time/batch = 0.2359s	
1272/2700 (epoch 23.556), train_loss = 3.33343036, grad/param norm = 1.7867e+00, time/batch = 0.2161s	
1273/2700 (epoch 23.574), train_loss = 3.25335928, grad/param norm = 1.3827e+00, time/batch = 0.2143s	
1274/2700 (epoch 23.593), train_loss = 3.26576330, grad/param norm = 1.7110e+00, time/batch = 0.1878s	
1275/2700 (epoch 23.611), train_loss = 3.21360553, grad/param norm = 1.6446e+00, time/batch = 0.2365s	
1276/2700 (epoch 23.630), train_loss = 3.25109948, grad/param norm = 1.8365e+00, time/batch = 0.2320s	
1277/2700 (epoch 23.648), train_loss = 3.33867958, grad/param norm = 1.9305e+00, time/batch = 0.2316s	
1278/2700 (epoch 23.667), train_loss = 3.27755801, grad/param norm = 1.9973e+00, time/batch = 0.2232s	
1279/2700 (epoch 23.685), train_loss = 3.26564307, grad/param norm = 1.8457e+00, time/batch = 0.2216s	
1280/2700 (epoch 23.704), train_loss = 3.24558075, grad/param norm = 2.0617e+00, time/batch = 0.2175s	
1281/2700 (epoch 23.722), train_loss = 3.25201991, grad/param norm = 2.0199e+00, time/batch = 0.2316s	
1282/2700 (epoch 23.741), train_loss = 3.36844336, grad/param norm = 2.0019e+00, time/batch = 0.2262s	
1283/2700 (epoch 23.759), train_loss = 3.33814324, grad/param norm = 2.2847e+00, time/batch = 0.2049s	
1284/2700 (epoch 23.778), train_loss = 3.32260273, grad/param norm = 2.4771e+00, time/batch = 0.1992s	
1285/2700 (epoch 23.796), train_loss = 3.33380484, grad/param norm = 2.4542e+00, time/batch = 0.1760s	
1286/2700 (epoch 23.815), train_loss = 3.26192392, grad/param norm = 2.3305e+00, time/batch = 0.1641s	
1287/2700 (epoch 23.833), train_loss = 3.31481605, grad/param norm = 2.3415e+00, time/batch = 0.1643s	
1288/2700 (epoch 23.852), train_loss = 3.28872179, grad/param norm = 2.2583e+00, time/batch = 0.1779s	
1289/2700 (epoch 23.870), train_loss = 3.27966689, grad/param norm = 1.9455e+00, time/batch = 0.2188s	
1290/2700 (epoch 23.889), train_loss = 3.28746491, grad/param norm = 1.7448e+00, time/batch = 0.2195s	
1291/2700 (epoch 23.907), train_loss = 3.33613330, grad/param norm = 1.8070e+00, time/batch = 0.2021s	
1292/2700 (epoch 23.926), train_loss = 3.30734878, grad/param norm = 2.0754e+00, time/batch = 0.2019s	
1293/2700 (epoch 23.944), train_loss = 3.32817627, grad/param norm = 1.8664e+00, time/batch = 0.1924s	
1294/2700 (epoch 23.963), train_loss = 3.38711824, grad/param norm = 1.7070e+00, time/batch = 0.2230s	
1295/2700 (epoch 23.981), train_loss = 3.44642547, grad/param norm = 1.7032e+00, time/batch = 0.2124s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1296/2700 (epoch 24.000), train_loss = 3.35258843, grad/param norm = 1.6684e+00, time/batch = 0.1971s	
1297/2700 (epoch 24.019), train_loss = 3.27749450, grad/param norm = 1.7268e+00, time/batch = 0.1850s	
1298/2700 (epoch 24.037), train_loss = 3.30371849, grad/param norm = 1.7363e+00, time/batch = 0.1786s	
1299/2700 (epoch 24.056), train_loss = 3.29032582, grad/param norm = 1.3323e+00, time/batch = 0.2202s	
1300/2700 (epoch 24.074), train_loss = 3.31180311, grad/param norm = 1.1597e+00, time/batch = 0.2300s	
1301/2700 (epoch 24.093), train_loss = 3.33020414, grad/param norm = 1.3252e+00, time/batch = 0.2135s	
1302/2700 (epoch 24.111), train_loss = 3.30741807, grad/param norm = 1.5052e+00, time/batch = 0.2204s	
1303/2700 (epoch 24.130), train_loss = 3.33001788, grad/param norm = 1.5317e+00, time/batch = 0.2089s	
1304/2700 (epoch 24.148), train_loss = 3.28656924, grad/param norm = 1.8731e+00, time/batch = 0.2085s	
1305/2700 (epoch 24.167), train_loss = 3.32354574, grad/param norm = 2.0809e+00, time/batch = 0.2032s	
1306/2700 (epoch 24.185), train_loss = 3.29870084, grad/param norm = 2.0403e+00, time/batch = 0.1826s	
1307/2700 (epoch 24.204), train_loss = 3.23158727, grad/param norm = 2.1533e+00, time/batch = 0.1890s	
1308/2700 (epoch 24.222), train_loss = 3.20630064, grad/param norm = 2.5145e+00, time/batch = 0.1557s	
1309/2700 (epoch 24.241), train_loss = 3.22329398, grad/param norm = 2.2586e+00, time/batch = 0.1779s	
1310/2700 (epoch 24.259), train_loss = 3.25377601, grad/param norm = 2.0755e+00, time/batch = 0.1777s	
1311/2700 (epoch 24.278), train_loss = 3.34261317, grad/param norm = 2.5039e+00, time/batch = 0.1864s	
1312/2700 (epoch 24.296), train_loss = 3.36180749, grad/param norm = 2.6028e+00, time/batch = 0.1900s	
1313/2700 (epoch 24.315), train_loss = 3.32592702, grad/param norm = 1.8874e+00, time/batch = 0.1976s	
1314/2700 (epoch 24.333), train_loss = 3.36990534, grad/param norm = 1.3341e+00, time/batch = 0.2022s	
1315/2700 (epoch 24.352), train_loss = 3.37374956, grad/param norm = 1.3609e+00, time/batch = 0.2187s	
1316/2700 (epoch 24.370), train_loss = 3.33273382, grad/param norm = 1.5827e+00, time/batch = 0.2212s	
1317/2700 (epoch 24.389), train_loss = 3.28668111, grad/param norm = 1.6110e+00, time/batch = 0.2055s	
1318/2700 (epoch 24.407), train_loss = 3.31974289, grad/param norm = 1.6362e+00, time/batch = 0.1979s	
1319/2700 (epoch 24.426), train_loss = 3.31695997, grad/param norm = 1.6573e+00, time/batch = 0.2103s	
1320/2700 (epoch 24.444), train_loss = 3.24090493, grad/param norm = 1.7800e+00, time/batch = 0.2034s	
1321/2700 (epoch 24.463), train_loss = 3.29635641, grad/param norm = 2.1871e+00, time/batch = 0.1937s	
1322/2700 (epoch 24.481), train_loss = 3.39770431, grad/param norm = 2.3486e+00, time/batch = 0.1967s	
1323/2700 (epoch 24.500), train_loss = 3.43133601, grad/param norm = 2.4241e+00, time/batch = 0.2026s	
1324/2700 (epoch 24.519), train_loss = 3.38908858, grad/param norm = 2.4554e+00, time/batch = 0.1935s	
1325/2700 (epoch 24.537), train_loss = 3.39211005, grad/param norm = 2.1518e+00, time/batch = 0.2131s	
1326/2700 (epoch 24.556), train_loss = 3.32829574, grad/param norm = 1.7438e+00, time/batch = 0.2129s	
1327/2700 (epoch 24.574), train_loss = 3.25178860, grad/param norm = 1.3515e+00, time/batch = 0.2172s	
1328/2700 (epoch 24.593), train_loss = 3.26380548, grad/param norm = 1.6659e+00, time/batch = 0.1916s	
1329/2700 (epoch 24.611), train_loss = 3.21017781, grad/param norm = 1.5911e+00, time/batch = 0.2270s	
1330/2700 (epoch 24.630), train_loss = 3.24831081, grad/param norm = 1.7816e+00, time/batch = 0.2159s	
1331/2700 (epoch 24.648), train_loss = 3.33573294, grad/param norm = 1.8847e+00, time/batch = 0.2138s	
1332/2700 (epoch 24.667), train_loss = 3.27462298, grad/param norm = 1.9473e+00, time/batch = 0.1967s	
1333/2700 (epoch 24.685), train_loss = 3.26247046, grad/param norm = 1.8047e+00, time/batch = 0.1841s	
1334/2700 (epoch 24.704), train_loss = 3.24281188, grad/param norm = 2.0224e+00, time/batch = 0.1705s	
1335/2700 (epoch 24.722), train_loss = 3.24742440, grad/param norm = 1.9752e+00, time/batch = 0.1734s	
1336/2700 (epoch 24.741), train_loss = 3.36432006, grad/param norm = 1.9314e+00, time/batch = 0.1922s	
1337/2700 (epoch 24.759), train_loss = 3.33172405, grad/param norm = 2.2179e+00, time/batch = 0.2019s	
1338/2700 (epoch 24.778), train_loss = 3.31908874, grad/param norm = 2.4389e+00, time/batch = 0.1781s	
1339/2700 (epoch 24.796), train_loss = 3.32923304, grad/param norm = 2.4100e+00, time/batch = 0.1797s	
1340/2700 (epoch 24.815), train_loss = 3.25762498, grad/param norm = 2.2692e+00, time/batch = 0.1857s	
1341/2700 (epoch 24.833), train_loss = 3.30903218, grad/param norm = 2.2820e+00, time/batch = 0.2147s	
1342/2700 (epoch 24.852), train_loss = 3.28520854, grad/param norm = 2.2166e+00, time/batch = 0.2093s	
1343/2700 (epoch 24.870), train_loss = 3.27638109, grad/param norm = 1.8985e+00, time/batch = 0.1925s	
1344/2700 (epoch 24.889), train_loss = 3.28532594, grad/param norm = 1.6928e+00, time/batch = 0.1760s	
1345/2700 (epoch 24.907), train_loss = 3.33390228, grad/param norm = 1.7559e+00, time/batch = 0.1661s	
1346/2700 (epoch 24.926), train_loss = 3.30395697, grad/param norm = 2.0222e+00, time/batch = 0.2126s	
1347/2700 (epoch 24.944), train_loss = 3.32408398, grad/param norm = 1.8106e+00, time/batch = 0.2222s	
1348/2700 (epoch 24.963), train_loss = 3.38342248, grad/param norm = 1.6456e+00, time/batch = 0.2187s	
1349/2700 (epoch 24.981), train_loss = 3.44226028, grad/param norm = 1.6444e+00, time/batch = 0.2214s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1350/2700 (epoch 25.000), train_loss = 3.34934961, grad/param norm = 1.6205e+00, time/batch = 0.2150s	
1351/2700 (epoch 25.019), train_loss = 3.27521467, grad/param norm = 1.6851e+00, time/batch = 0.2387s	
1352/2700 (epoch 25.037), train_loss = 3.30096532, grad/param norm = 1.6903e+00, time/batch = 0.2362s	
1353/2700 (epoch 25.056), train_loss = 3.28807200, grad/param norm = 1.2860e+00, time/batch = 0.2358s	
1354/2700 (epoch 25.074), train_loss = 3.31041423, grad/param norm = 1.1205e+00, time/batch = 0.2361s	
1355/2700 (epoch 25.093), train_loss = 3.32809477, grad/param norm = 1.2904e+00, time/batch = 0.2283s	
1356/2700 (epoch 25.111), train_loss = 3.30467902, grad/param norm = 1.4518e+00, time/batch = 0.2351s	
1357/2700 (epoch 25.130), train_loss = 3.32665051, grad/param norm = 1.4608e+00, time/batch = 0.2181s	
1358/2700 (epoch 25.148), train_loss = 3.28297547, grad/param norm = 1.7979e+00, time/batch = 0.2132s	
1359/2700 (epoch 25.167), train_loss = 3.31919338, grad/param norm = 2.0043e+00, time/batch = 0.2070s	
1360/2700 (epoch 25.185), train_loss = 3.29857596, grad/param norm = 2.0190e+00, time/batch = 0.2047s	
1361/2700 (epoch 25.204), train_loss = 3.24000224, grad/param norm = 2.0256e+00, time/batch = 0.1841s	
1362/2700 (epoch 25.222), train_loss = 3.19409570, grad/param norm = 2.2449e+00, time/batch = 0.2343s	
1363/2700 (epoch 25.241), train_loss = 3.21327389, grad/param norm = 2.1214e+00, time/batch = 0.2355s	
1364/2700 (epoch 25.259), train_loss = 3.25102873, grad/param norm = 2.0766e+00, time/batch = 0.2360s	
1365/2700 (epoch 25.278), train_loss = 3.34277186, grad/param norm = 2.6079e+00, time/batch = 0.2341s	
1366/2700 (epoch 25.296), train_loss = 3.35364671, grad/param norm = 2.5201e+00, time/batch = 0.2119s	
1367/2700 (epoch 25.315), train_loss = 3.31738282, grad/param norm = 1.8276e+00, time/batch = 0.2041s	
1368/2700 (epoch 25.333), train_loss = 3.36982743, grad/param norm = 1.3755e+00, time/batch = 0.2006s	
1369/2700 (epoch 25.352), train_loss = 3.37513022, grad/param norm = 1.3969e+00, time/batch = 0.1908s	
1370/2700 (epoch 25.370), train_loss = 3.33207539, grad/param norm = 1.5789e+00, time/batch = 0.1882s	
1371/2700 (epoch 25.389), train_loss = 3.28718988, grad/param norm = 1.6231e+00, time/batch = 0.1854s	
1372/2700 (epoch 25.407), train_loss = 3.32023910, grad/param norm = 1.6304e+00, time/batch = 0.1629s	
1373/2700 (epoch 25.426), train_loss = 3.31431822, grad/param norm = 1.6224e+00, time/batch = 0.2218s	
1374/2700 (epoch 25.444), train_loss = 3.23716712, grad/param norm = 1.7255e+00, time/batch = 0.2227s	
1375/2700 (epoch 25.463), train_loss = 3.29094577, grad/param norm = 2.0830e+00, time/batch = 0.2234s	
1376/2700 (epoch 25.481), train_loss = 3.38860554, grad/param norm = 2.2336e+00, time/batch = 0.2195s	
1377/2700 (epoch 25.500), train_loss = 3.42789990, grad/param norm = 2.3243e+00, time/batch = 0.2316s	
1378/2700 (epoch 25.519), train_loss = 3.38723642, grad/param norm = 2.3940e+00, time/batch = 0.2359s	
1379/2700 (epoch 25.537), train_loss = 3.39119143, grad/param norm = 2.1398e+00, time/batch = 0.2287s	
1380/2700 (epoch 25.556), train_loss = 3.32534152, grad/param norm = 1.6984e+00, time/batch = 0.2165s	
1381/2700 (epoch 25.574), train_loss = 3.24906516, grad/param norm = 1.3054e+00, time/batch = 0.2349s	
1382/2700 (epoch 25.593), train_loss = 3.26098616, grad/param norm = 1.6232e+00, time/batch = 0.2356s	
1383/2700 (epoch 25.611), train_loss = 3.20730379, grad/param norm = 1.5545e+00, time/batch = 0.2047s	
1384/2700 (epoch 25.630), train_loss = 3.24652337, grad/param norm = 1.7510e+00, time/batch = 0.2003s	
1385/2700 (epoch 25.648), train_loss = 3.33266158, grad/param norm = 1.8459e+00, time/batch = 0.2047s	
1386/2700 (epoch 25.667), train_loss = 3.27067786, grad/param norm = 1.8913e+00, time/batch = 0.1949s	
1387/2700 (epoch 25.685), train_loss = 3.25865803, grad/param norm = 1.7507e+00, time/batch = 0.2078s	
1388/2700 (epoch 25.704), train_loss = 3.23985717, grad/param norm = 1.9806e+00, time/batch = 0.2318s	
1389/2700 (epoch 25.722), train_loss = 3.24324944, grad/param norm = 1.9230e+00, time/batch = 0.2253s	
1390/2700 (epoch 25.741), train_loss = 3.36016623, grad/param norm = 1.8559e+00, time/batch = 0.2213s	
1391/2700 (epoch 25.759), train_loss = 3.32723848, grad/param norm = 2.1567e+00, time/batch = 0.2327s	
1392/2700 (epoch 25.778), train_loss = 3.31571589, grad/param norm = 2.3978e+00, time/batch = 0.2351s	
1393/2700 (epoch 25.796), train_loss = 3.32488349, grad/param norm = 2.3596e+00, time/batch = 0.2313s	
1394/2700 (epoch 25.815), train_loss = 3.25358330, grad/param norm = 2.2060e+00, time/batch = 0.2378s	
1395/2700 (epoch 25.833), train_loss = 3.30358253, grad/param norm = 2.2201e+00, time/batch = 0.2378s	
1396/2700 (epoch 25.852), train_loss = 3.28169760, grad/param norm = 2.1705e+00, time/batch = 0.2216s	
1397/2700 (epoch 25.870), train_loss = 3.27318814, grad/param norm = 1.8507e+00, time/batch = 0.2010s	
1398/2700 (epoch 25.889), train_loss = 3.28341568, grad/param norm = 1.6428e+00, time/batch = 0.1767s	
1399/2700 (epoch 25.907), train_loss = 3.33190114, grad/param norm = 1.7087e+00, time/batch = 0.1904s	
1400/2700 (epoch 25.926), train_loss = 3.30095278, grad/param norm = 1.9722e+00, time/batch = 0.2015s	
1401/2700 (epoch 25.944), train_loss = 3.32037516, grad/param norm = 1.7590e+00, time/batch = 0.2067s	
1402/2700 (epoch 25.963), train_loss = 3.38020271, grad/param norm = 1.5905e+00, time/batch = 0.2150s	
1403/2700 (epoch 25.981), train_loss = 3.43868179, grad/param norm = 1.5911e+00, time/batch = 0.2156s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1404/2700 (epoch 26.000), train_loss = 3.34638214, grad/param norm = 1.5743e+00, time/batch = 0.2016s	
1405/2700 (epoch 26.019), train_loss = 3.27310242, grad/param norm = 1.6439e+00, time/batch = 0.2082s	
1406/2700 (epoch 26.037), train_loss = 3.29835885, grad/param norm = 1.6447e+00, time/batch = 0.2019s	
1407/2700 (epoch 26.056), train_loss = 3.28596471, grad/param norm = 1.2409e+00, time/batch = 0.1859s	
1408/2700 (epoch 26.074), train_loss = 3.30910920, grad/param norm = 1.0840e+00, time/batch = 0.2148s	
1409/2700 (epoch 26.093), train_loss = 3.32612386, grad/param norm = 1.2586e+00, time/batch = 0.2072s	
1410/2700 (epoch 26.111), train_loss = 3.30222338, grad/param norm = 1.4057e+00, time/batch = 0.1961s	
1411/2700 (epoch 26.130), train_loss = 3.32371147, grad/param norm = 1.3991e+00, time/batch = 0.2075s	
1412/2700 (epoch 26.148), train_loss = 3.27985435, grad/param norm = 1.7310e+00, time/batch = 0.2026s	
1413/2700 (epoch 26.167), train_loss = 3.31512255, grad/param norm = 1.9344e+00, time/batch = 0.2104s	
1414/2700 (epoch 26.185), train_loss = 3.29006834, grad/param norm = 1.8532e+00, time/batch = 0.2216s	
1415/2700 (epoch 26.204), train_loss = 3.22267588, grad/param norm = 1.9622e+00, time/batch = 0.2236s	
1416/2700 (epoch 26.222), train_loss = 3.19853055, grad/param norm = 2.3657e+00, time/batch = 0.2312s	
1417/2700 (epoch 26.241), train_loss = 3.21847123, grad/param norm = 2.2194e+00, time/batch = 0.2216s	
1418/2700 (epoch 26.259), train_loss = 3.25147777, grad/param norm = 2.0711e+00, time/batch = 0.2376s	
1419/2700 (epoch 26.278), train_loss = 3.33672429, grad/param norm = 2.4818e+00, time/batch = 0.2362s	
1420/2700 (epoch 26.296), train_loss = 3.35434124, grad/param norm = 2.5221e+00, time/batch = 0.2317s	
1421/2700 (epoch 26.315), train_loss = 3.31881623, grad/param norm = 1.8177e+00, time/batch = 0.2380s	
1422/2700 (epoch 26.333), train_loss = 3.36673478, grad/param norm = 1.2901e+00, time/batch = 0.2355s	
1423/2700 (epoch 26.352), train_loss = 3.37128015, grad/param norm = 1.3273e+00, time/batch = 0.2352s	
1424/2700 (epoch 26.370), train_loss = 3.32883542, grad/param norm = 1.5244e+00, time/batch = 0.2352s	
1425/2700 (epoch 26.389), train_loss = 3.28327068, grad/param norm = 1.5194e+00, time/batch = 0.2299s	
1426/2700 (epoch 26.407), train_loss = 3.31365176, grad/param norm = 1.5157e+00, time/batch = 0.1912s	
1427/2700 (epoch 26.426), train_loss = 3.31188754, grad/param norm = 1.5184e+00, time/batch = 0.2124s	
1428/2700 (epoch 26.444), train_loss = 3.23570948, grad/param norm = 1.6226e+00, time/batch = 0.2034s	
1429/2700 (epoch 26.463), train_loss = 3.29009888, grad/param norm = 2.0080e+00, time/batch = 0.2092s	
1430/2700 (epoch 26.481), train_loss = 3.38756314, grad/param norm = 2.1782e+00, time/batch = 0.2070s	
1431/2700 (epoch 26.500), train_loss = 3.42352824, grad/param norm = 2.3254e+00, time/batch = 0.2291s	
1432/2700 (epoch 26.519), train_loss = 3.38135103, grad/param norm = 2.3611e+00, time/batch = 0.2322s	
1433/2700 (epoch 26.537), train_loss = 3.38381090, grad/param norm = 2.0562e+00, time/batch = 0.2280s	
1434/2700 (epoch 26.556), train_loss = 3.31909407, grad/param norm = 1.6647e+00, time/batch = 0.2253s	
1435/2700 (epoch 26.574), train_loss = 3.24873469, grad/param norm = 1.2958e+00, time/batch = 0.2227s	
1436/2700 (epoch 26.593), train_loss = 3.26021093, grad/param norm = 1.5870e+00, time/batch = 0.2013s	
1437/2700 (epoch 26.611), train_loss = 3.20494947, grad/param norm = 1.4983e+00, time/batch = 0.2006s	
1438/2700 (epoch 26.630), train_loss = 3.24430361, grad/param norm = 1.6784e+00, time/batch = 0.1699s	
1439/2700 (epoch 26.648), train_loss = 3.32965677, grad/param norm = 1.7946e+00, time/batch = 0.2050s	
1440/2700 (epoch 26.667), train_loss = 3.26846213, grad/param norm = 1.8549e+00, time/batch = 0.2087s	
1441/2700 (epoch 26.685), train_loss = 3.25670141, grad/param norm = 1.7267e+00, time/batch = 0.2020s	
1442/2700 (epoch 26.704), train_loss = 3.23733091, grad/param norm = 1.9435e+00, time/batch = 0.2147s	
1443/2700 (epoch 26.722), train_loss = 3.23848529, grad/param norm = 1.8795e+00, time/batch = 0.2245s	
1444/2700 (epoch 26.741), train_loss = 3.35667203, grad/param norm = 1.7903e+00, time/batch = 0.2358s	
1445/2700 (epoch 26.759), train_loss = 3.32014768, grad/param norm = 2.0811e+00, time/batch = 0.2359s	
1446/2700 (epoch 26.778), train_loss = 3.31264197, grad/param norm = 2.3596e+00, time/batch = 0.2225s	
1447/2700 (epoch 26.796), train_loss = 3.32077029, grad/param norm = 2.3168e+00, time/batch = 0.2228s	
1448/2700 (epoch 26.815), train_loss = 3.24971594, grad/param norm = 2.1439e+00, time/batch = 0.2089s	
1449/2700 (epoch 26.833), train_loss = 3.29824942, grad/param norm = 2.1592e+00, time/batch = 0.2121s	
1450/2700 (epoch 26.852), train_loss = 3.27879715, grad/param norm = 2.1329e+00, time/batch = 0.2006s	
1451/2700 (epoch 26.870), train_loss = 3.27043114, grad/param norm = 1.8058e+00, time/batch = 0.1909s	
1452/2700 (epoch 26.889), train_loss = 3.28140681, grad/param norm = 1.5915e+00, time/batch = 0.1910s	
1453/2700 (epoch 26.907), train_loss = 3.32991066, grad/param norm = 1.6608e+00, time/batch = 0.1952s	
1454/2700 (epoch 26.926), train_loss = 3.29793752, grad/param norm = 1.9225e+00, time/batch = 0.2057s	
1455/2700 (epoch 26.944), train_loss = 3.31667723, grad/param norm = 1.7067e+00, time/batch = 0.2153s	
1456/2700 (epoch 26.963), train_loss = 3.37691132, grad/param norm = 1.5328e+00, time/batch = 0.2060s	
1457/2700 (epoch 26.981), train_loss = 3.43503209, grad/param norm = 1.5342e+00, time/batch = 0.2276s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1458/2700 (epoch 27.000), train_loss = 3.34341387, grad/param norm = 1.5261e+00, time/batch = 0.2073s	
1459/2700 (epoch 27.019), train_loss = 3.27104631, grad/param norm = 1.6030e+00, time/batch = 0.1880s	
1460/2700 (epoch 27.037), train_loss = 3.29586819, grad/param norm = 1.6019e+00, time/batch = 0.2032s	
1461/2700 (epoch 27.056), train_loss = 3.28404493, grad/param norm = 1.1997e+00, time/batch = 0.1844s	
1462/2700 (epoch 27.074), train_loss = 3.30795119, grad/param norm = 1.0521e+00, time/batch = 0.1755s	
1463/2700 (epoch 27.093), train_loss = 3.32432900, grad/param norm = 1.2313e+00, time/batch = 0.1850s	
1464/2700 (epoch 27.111), train_loss = 3.29996733, grad/param norm = 1.3627e+00, time/batch = 0.1954s	
1465/2700 (epoch 27.130), train_loss = 3.32095164, grad/param norm = 1.3404e+00, time/batch = 0.2015s	
1466/2700 (epoch 27.148), train_loss = 3.27692801, grad/param norm = 1.6639e+00, time/batch = 0.2086s	
1467/2700 (epoch 27.167), train_loss = 3.31110100, grad/param norm = 1.8636e+00, time/batch = 0.2226s	
1468/2700 (epoch 27.185), train_loss = 3.28596869, grad/param norm = 1.7539e+00, time/batch = 0.2151s	
1469/2700 (epoch 27.204), train_loss = 3.21801322, grad/param norm = 1.8439e+00, time/batch = 0.1975s	
1470/2700 (epoch 27.222), train_loss = 3.19393639, grad/param norm = 2.2639e+00, time/batch = 0.2070s	
1471/2700 (epoch 27.241), train_loss = 3.21590796, grad/param norm = 2.1783e+00, time/batch = 0.2359s	
1472/2700 (epoch 27.259), train_loss = 3.25019078, grad/param norm = 2.0594e+00, time/batch = 0.2343s	
1473/2700 (epoch 27.278), train_loss = 3.33372465, grad/param norm = 2.4842e+00, time/batch = 0.2348s	
1474/2700 (epoch 27.296), train_loss = 3.35117487, grad/param norm = 2.4899e+00, time/batch = 0.2202s	
1475/2700 (epoch 27.315), train_loss = 3.31552031, grad/param norm = 1.7855e+00, time/batch = 0.2064s	
1476/2700 (epoch 27.333), train_loss = 3.36519711, grad/param norm = 1.2739e+00, time/batch = 0.2021s	
1477/2700 (epoch 27.352), train_loss = 3.37032328, grad/param norm = 1.3205e+00, time/batch = 0.2070s	
1478/2700 (epoch 27.370), train_loss = 3.32734509, grad/param norm = 1.5078e+00, time/batch = 0.2179s	
1479/2700 (epoch 27.389), train_loss = 3.28189839, grad/param norm = 1.4857e+00, time/batch = 0.2146s	
1480/2700 (epoch 27.407), train_loss = 3.31104993, grad/param norm = 1.4666e+00, time/batch = 0.2204s	
1481/2700 (epoch 27.426), train_loss = 3.30962078, grad/param norm = 1.4589e+00, time/batch = 0.2351s	
1482/2700 (epoch 27.444), train_loss = 3.23341493, grad/param norm = 1.5518e+00, time/batch = 0.2365s	
1483/2700 (epoch 27.463), train_loss = 3.28690911, grad/param norm = 1.9182e+00, time/batch = 0.2386s	
1484/2700 (epoch 27.481), train_loss = 3.38229682, grad/param norm = 2.0911e+00, time/batch = 0.2355s	
1485/2700 (epoch 27.500), train_loss = 3.41993912, grad/param norm = 2.2646e+00, time/batch = 0.2303s	
1486/2700 (epoch 27.519), train_loss = 3.37792902, grad/param norm = 2.3074e+00, time/batch = 0.2368s	
1487/2700 (epoch 27.537), train_loss = 3.38048584, grad/param norm = 2.0175e+00, time/batch = 0.2307s	
1488/2700 (epoch 27.556), train_loss = 3.31538853, grad/param norm = 1.6294e+00, time/batch = 0.2177s	
1489/2700 (epoch 27.574), train_loss = 3.24716255, grad/param norm = 1.2670e+00, time/batch = 0.2070s	
1490/2700 (epoch 27.593), train_loss = 3.25834962, grad/param norm = 1.5483e+00, time/batch = 0.1849s	
1491/2700 (epoch 27.611), train_loss = 3.20262751, grad/param norm = 1.4546e+00, time/batch = 0.1861s	
1492/2700 (epoch 27.630), train_loss = 3.24244437, grad/param norm = 1.6288e+00, time/batch = 0.2344s	
1493/2700 (epoch 27.648), train_loss = 3.32670981, grad/param norm = 1.7499e+00, time/batch = 0.2288s	
1494/2700 (epoch 27.667), train_loss = 3.26559824, grad/param norm = 1.8124e+00, time/batch = 0.2246s	
1495/2700 (epoch 27.685), train_loss = 3.25409754, grad/param norm = 1.6901e+00, time/batch = 0.2173s	
1496/2700 (epoch 27.704), train_loss = 3.23463829, grad/param norm = 1.9044e+00, time/batch = 0.2152s	
1497/2700 (epoch 27.722), train_loss = 3.23415331, grad/param norm = 1.8304e+00, time/batch = 0.2134s	
1498/2700 (epoch 27.741), train_loss = 3.35339237, grad/param norm = 1.7254e+00, time/batch = 0.2077s	
1499/2700 (epoch 27.759), train_loss = 3.31521671, grad/param norm = 2.0150e+00, time/batch = 0.1908s	
1500/2700 (epoch 27.778), train_loss = 3.30964298, grad/param norm = 2.3185e+00, time/batch = 0.1613s	
1501/2700 (epoch 27.796), train_loss = 3.31685559, grad/param norm = 2.2710e+00, time/batch = 0.2228s	
1502/2700 (epoch 27.815), train_loss = 3.24614057, grad/param norm = 2.0838e+00, time/batch = 0.1950s	
1503/2700 (epoch 27.833), train_loss = 3.29325395, grad/param norm = 2.0992e+00, time/batch = 0.2186s	
1504/2700 (epoch 27.852), train_loss = 3.27587751, grad/param norm = 2.0937e+00, time/batch = 0.2294s	
1505/2700 (epoch 27.870), train_loss = 3.26773558, grad/param norm = 1.7625e+00, time/batch = 0.2318s	
1506/2700 (epoch 27.889), train_loss = 3.27960533, grad/param norm = 1.5444e+00, time/batch = 0.2366s	
1507/2700 (epoch 27.907), train_loss = 3.32812978, grad/param norm = 1.6180e+00, time/batch = 0.2362s	
1508/2700 (epoch 27.926), train_loss = 3.29527448, grad/param norm = 1.8769e+00, time/batch = 0.2336s	
1509/2700 (epoch 27.944), train_loss = 3.31327683, grad/param norm = 1.6590e+00, time/batch = 0.2343s	
1510/2700 (epoch 27.963), train_loss = 3.37403427, grad/param norm = 1.4823e+00, time/batch = 0.2244s	
1511/2700 (epoch 27.981), train_loss = 3.43194257, grad/param norm = 1.4843e+00, time/batch = 0.2205s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1512/2700 (epoch 28.000), train_loss = 3.34070994, grad/param norm = 1.4817e+00, time/batch = 0.2139s	
1513/2700 (epoch 28.019), train_loss = 3.26915977, grad/param norm = 1.5643e+00, time/batch = 0.2102s	
1514/2700 (epoch 28.037), train_loss = 3.29351468, grad/param norm = 1.5607e+00, time/batch = 0.2056s	
1515/2700 (epoch 28.056), train_loss = 3.28225539, grad/param norm = 1.1606e+00, time/batch = 0.1739s	
1516/2700 (epoch 28.074), train_loss = 3.30687625, grad/param norm = 1.0233e+00, time/batch = 0.1925s	
1517/2700 (epoch 28.093), train_loss = 3.32265859, grad/param norm = 1.2067e+00, time/batch = 0.2070s	
1518/2700 (epoch 28.111), train_loss = 3.29788570, grad/param norm = 1.3234e+00, time/batch = 0.2185s	
1519/2700 (epoch 28.130), train_loss = 3.31843720, grad/param norm = 1.2877e+00, time/batch = 0.2196s	
1520/2700 (epoch 28.148), train_loss = 3.27433685, grad/param norm = 1.6012e+00, time/batch = 0.2225s	
1521/2700 (epoch 28.167), train_loss = 3.30724881, grad/param norm = 1.7969e+00, time/batch = 0.2388s	
1522/2700 (epoch 28.185), train_loss = 3.28213936, grad/param norm = 1.6555e+00, time/batch = 0.2350s	
1523/2700 (epoch 28.204), train_loss = 3.21338396, grad/param norm = 1.7158e+00, time/batch = 0.2310s	
1524/2700 (epoch 28.222), train_loss = 3.18900039, grad/param norm = 2.1406e+00, time/batch = 0.2323s	
1525/2700 (epoch 28.241), train_loss = 3.21283015, grad/param norm = 2.1019e+00, time/batch = 0.2365s	
1526/2700 (epoch 28.259), train_loss = 3.24834004, grad/param norm = 2.0264e+00, time/batch = 0.2366s	
1527/2700 (epoch 28.278), train_loss = 3.33140112, grad/param norm = 2.5047e+00, time/batch = 0.2357s	
1528/2700 (epoch 28.296), train_loss = 3.34846863, grad/param norm = 2.4635e+00, time/batch = 0.2297s	
1529/2700 (epoch 28.315), train_loss = 3.31194844, grad/param norm = 1.7526e+00, time/batch = 0.2180s	
1530/2700 (epoch 28.333), train_loss = 3.36353713, grad/param norm = 1.2601e+00, time/batch = 0.2049s	
1531/2700 (epoch 28.352), train_loss = 3.36950417, grad/param norm = 1.3214e+00, time/batch = 0.2379s	
1532/2700 (epoch 28.370), train_loss = 3.32618473, grad/param norm = 1.5035e+00, time/batch = 0.2272s	
1533/2700 (epoch 28.389), train_loss = 3.28084172, grad/param norm = 1.4651e+00, time/batch = 0.2143s	
1534/2700 (epoch 28.407), train_loss = 3.30879332, grad/param norm = 1.4295e+00, time/batch = 0.1816s	
1535/2700 (epoch 28.426), train_loss = 3.30753344, grad/param norm = 1.4090e+00, time/batch = 0.2242s	
1536/2700 (epoch 28.444), train_loss = 3.23134225, grad/param norm = 1.4923e+00, time/batch = 0.2342s	
1537/2700 (epoch 28.463), train_loss = 3.28405751, grad/param norm = 1.8378e+00, time/batch = 0.2345s	
1538/2700 (epoch 28.481), train_loss = 3.37746239, grad/param norm = 2.0092e+00, time/batch = 0.2350s	
1539/2700 (epoch 28.500), train_loss = 3.41648156, grad/param norm = 2.1986e+00, time/batch = 0.2296s	
1540/2700 (epoch 28.519), train_loss = 3.37448287, grad/param norm = 2.2473e+00, time/batch = 0.2255s	
1541/2700 (epoch 28.537), train_loss = 3.37733558, grad/param norm = 1.9783e+00, time/batch = 0.2083s	
1542/2700 (epoch 28.556), train_loss = 3.31203886, grad/param norm = 1.5940e+00, time/batch = 0.2059s	
1543/2700 (epoch 28.574), train_loss = 3.24566309, grad/param norm = 1.2370e+00, time/batch = 0.1966s	
1544/2700 (epoch 28.593), train_loss = 3.25655119, grad/param norm = 1.5096e+00, time/batch = 0.1823s	
1545/2700 (epoch 28.611), train_loss = 3.20045646, grad/param norm = 1.4112e+00, time/batch = 0.1891s	
1546/2700 (epoch 28.630), train_loss = 3.24061912, grad/param norm = 1.5795e+00, time/batch = 0.1876s	
1547/2700 (epoch 28.648), train_loss = 3.32385029, grad/param norm = 1.7049e+00, time/batch = 0.1876s	
1548/2700 (epoch 28.667), train_loss = 3.26286605, grad/param norm = 1.7708e+00, time/batch = 0.2039s	
1549/2700 (epoch 28.685), train_loss = 3.25165968, grad/param norm = 1.6538e+00, time/batch = 0.2160s	
1550/2700 (epoch 28.704), train_loss = 3.23192337, grad/param norm = 1.8640e+00, time/batch = 0.2281s	
1551/2700 (epoch 28.722), train_loss = 3.22984052, grad/param norm = 1.7802e+00, time/batch = 0.2071s	
1552/2700 (epoch 28.741), train_loss = 3.35047590, grad/param norm = 1.6659e+00, time/batch = 0.2373s	
1553/2700 (epoch 28.759), train_loss = 3.31082080, grad/param norm = 1.9525e+00, time/batch = 0.2351s	
1554/2700 (epoch 28.778), train_loss = 3.30677967, grad/param norm = 2.2775e+00, time/batch = 0.2315s	
1555/2700 (epoch 28.796), train_loss = 3.31315766, grad/param norm = 2.2282e+00, time/batch = 0.2248s	
1556/2700 (epoch 28.815), train_loss = 3.24288735, grad/param norm = 2.0286e+00, time/batch = 0.2189s	
1557/2700 (epoch 28.833), train_loss = 3.28858092, grad/param norm = 2.0424e+00, time/batch = 0.2112s	
1558/2700 (epoch 28.852), train_loss = 3.27306298, grad/param norm = 2.0559e+00, time/batch = 0.2039s	
1559/2700 (epoch 28.870), train_loss = 3.26514511, grad/param norm = 1.7222e+00, time/batch = 0.2102s	
1560/2700 (epoch 28.889), train_loss = 3.27790840, grad/param norm = 1.5007e+00, time/batch = 0.2153s	
1561/2700 (epoch 28.907), train_loss = 3.32647387, grad/param norm = 1.5784e+00, time/batch = 0.1820s	
1562/2700 (epoch 28.926), train_loss = 3.29280418, grad/param norm = 1.8339e+00, time/batch = 0.2010s	
1563/2700 (epoch 28.944), train_loss = 3.31005183, grad/param norm = 1.6140e+00, time/batch = 0.2103s	
1564/2700 (epoch 28.963), train_loss = 3.37139170, grad/param norm = 1.4357e+00, time/batch = 0.2076s	
1565/2700 (epoch 28.981), train_loss = 3.42917535, grad/param norm = 1.4383e+00, time/batch = 0.2318s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
1566/2700 (epoch 29.000), train_loss = 3.33817219, grad/param norm = 1.4398e+00, time/batch = 0.2100s	
1567/2700 (epoch 29.019), train_loss = 3.26740255, grad/param norm = 1.5276e+00, time/batch = 0.2152s	
1568/2700 (epoch 29.037), train_loss = 3.29129241, grad/param norm = 1.5219e+00, time/batch = 0.1920s	
1569/2700 (epoch 29.056), train_loss = 3.28059446, grad/param norm = 1.1243e+00, time/batch = 0.1722s	
1570/2700 (epoch 29.074), train_loss = 3.30588868, grad/param norm = 9.9818e-01, time/batch = 0.1645s	
1571/2700 (epoch 29.093), train_loss = 3.32110065, grad/param norm = 1.1857e+00, time/batch = 0.1562s	
1572/2700 (epoch 29.111), train_loss = 3.29596284, grad/param norm = 1.2884e+00, time/batch = 0.1543s	
1573/2700 (epoch 29.130), train_loss = 3.31613627, grad/param norm = 1.2410e+00, time/batch = 0.2025s	
1574/2700 (epoch 29.148), train_loss = 3.27200793, grad/param norm = 1.5436e+00, time/batch = 0.2081s	
1575/2700 (epoch 29.167), train_loss = 3.30360030, grad/param norm = 1.7357e+00, time/batch = 0.2225s	
1576/2700 (epoch 29.185), train_loss = 3.27856146, grad/param norm = 1.5595e+00, time/batch = 0.2189s	
1577/2700 (epoch 29.204), train_loss = 3.20886223, grad/param norm = 1.5824e+00, time/batch = 0.2054s	
1578/2700 (epoch 29.222), train_loss = 3.18387664, grad/param norm = 1.9944e+00, time/batch = 0.1966s	
1579/2700 (epoch 29.241), train_loss = 3.20885462, grad/param norm = 1.9683e+00, time/batch = 0.1894s	
1580/2700 (epoch 29.259), train_loss = 3.24513592, grad/param norm = 1.9500e+00, time/batch = 0.1825s	
1581/2700 (epoch 29.278), train_loss = 3.32965246, grad/param norm = 2.5413e+00, time/batch = 0.2108s	
1582/2700 (epoch 29.296), train_loss = 3.34656067, grad/param norm = 2.4500e+00, time/batch = 0.1844s	
1583/2700 (epoch 29.315), train_loss = 3.30834980, grad/param norm = 1.7293e+00, time/batch = 0.2118s	
1584/2700 (epoch 29.333), train_loss = 3.36216280, grad/param norm = 1.2644e+00, time/batch = 0.2054s	
1585/2700 (epoch 29.352), train_loss = 3.36903815, grad/param norm = 1.3370e+00, time/batch = 0.2196s	
1586/2700 (epoch 29.370), train_loss = 3.32541637, grad/param norm = 1.5191e+00, time/batch = 0.2219s	
1587/2700 (epoch 29.389), train_loss = 3.28048947, grad/param norm = 1.4691e+00, time/batch = 0.2269s	
1588/2700 (epoch 29.407), train_loss = 3.30721123, grad/param norm = 1.4155e+00, time/batch = 0.2216s	
1589/2700 (epoch 29.426), train_loss = 3.30589303, grad/param norm = 1.3784e+00, time/batch = 0.2318s	
1590/2700 (epoch 29.444), train_loss = 3.22981214, grad/param norm = 1.4533e+00, time/batch = 0.2259s	
1591/2700 (epoch 29.463), train_loss = 3.28171240, grad/param norm = 1.7747e+00, time/batch = 0.2372s	
1592/2700 (epoch 29.481), train_loss = 3.37313695, grad/param norm = 1.9370e+00, time/batch = 0.2285s	
1593/2700 (epoch 29.500), train_loss = 3.41313844, grad/param norm = 2.1273e+00, time/batch = 0.2230s	
1594/2700 (epoch 29.519), train_loss = 3.37069645, grad/param norm = 2.1738e+00, time/batch = 0.2207s	
1595/2700 (epoch 29.537), train_loss = 3.37390523, grad/param norm = 1.9304e+00, time/batch = 0.2107s	
1596/2700 (epoch 29.556), train_loss = 3.30873568, grad/param norm = 1.5537e+00, time/batch = 0.1933s	
1597/2700 (epoch 29.574), train_loss = 3.24418127, grad/param norm = 1.2026e+00, time/batch = 0.1736s	
1598/2700 (epoch 29.593), train_loss = 3.25475206, grad/param norm = 1.4667e+00, time/batch = 0.1823s	
1599/2700 (epoch 29.611), train_loss = 3.19821061, grad/param norm = 1.3618e+00, time/batch = 0.1822s	
1600/2700 (epoch 29.630), train_loss = 3.23862944, grad/param norm = 1.5238e+00, time/batch = 0.2093s	
1601/2700 (epoch 29.648), train_loss = 3.32092179, grad/param norm = 1.6555e+00, time/batch = 0.2375s	
1602/2700 (epoch 29.667), train_loss = 3.26020954, grad/param norm = 1.7266e+00, time/batch = 0.2343s	
1603/2700 (epoch 29.685), train_loss = 3.24931409, grad/param norm = 1.6160e+00, time/batch = 0.2013s	
1604/2700 (epoch 29.704), train_loss = 3.22930144, grad/param norm = 1.8225e+00, time/batch = 0.2098s	
1605/2700 (epoch 29.722), train_loss = 3.22561782, grad/param norm = 1.7279e+00, time/batch = 0.2147s	
1606/2700 (epoch 29.741), train_loss = 3.34771821, grad/param norm = 1.6079e+00, time/batch = 0.2179s	
1607/2700 (epoch 29.759), train_loss = 3.30671289, grad/param norm = 1.8926e+00, time/batch = 0.2255s	
1608/2700 (epoch 29.778), train_loss = 3.30421281, grad/param norm = 2.2408e+00, time/batch = 0.2187s	
1609/2700 (epoch 29.796), train_loss = 3.30987492, grad/param norm = 2.1922e+00, time/batch = 0.2128s	
1610/2700 (epoch 29.815), train_loss = 3.23999730, grad/param norm = 1.9799e+00, time/batch = 0.1908s	
1611/2700 (epoch 29.833), train_loss = 3.28427274, grad/param norm = 1.9898e+00, time/batch = 0.2090s	
1612/2700 (epoch 29.852), train_loss = 3.27029821, grad/param norm = 2.0181e+00, time/batch = 0.2207s	
1613/2700 (epoch 29.870), train_loss = 3.26260113, grad/param norm = 1.6841e+00, time/batch = 0.2152s	
1614/2700 (epoch 29.889), train_loss = 3.27630888, grad/param norm = 1.4596e+00, time/batch = 0.2375s	
1615/2700 (epoch 29.907), train_loss = 3.32492545, grad/param norm = 1.5408e+00, time/batch = 0.2363s	
1616/2700 (epoch 29.926), train_loss = 3.29050658, grad/param norm = 1.7924e+00, time/batch = 0.2360s	
1617/2700 (epoch 29.944), train_loss = 3.30701145, grad/param norm = 1.5708e+00, time/batch = 0.2361s	
1618/2700 (epoch 29.963), train_loss = 3.36896825, grad/param norm = 1.3918e+00, time/batch = 0.2372s	
1619/2700 (epoch 29.981), train_loss = 3.42669890, grad/param norm = 1.3953e+00, time/batch = 0.2367s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
1620/2700 (epoch 30.000), train_loss = 3.33578629, grad/param norm = 1.3995e+00, time/batch = 0.2350s	
1621/2700 (epoch 30.019), train_loss = 3.26576328, grad/param norm = 1.4921e+00, time/batch = 0.1974s	
1622/2700 (epoch 30.037), train_loss = 3.28919655, grad/param norm = 1.4843e+00, time/batch = 0.1857s	
1623/2700 (epoch 30.056), train_loss = 3.27904440, grad/param norm = 1.0897e+00, time/batch = 0.1639s	
1624/2700 (epoch 30.074), train_loss = 3.30498338, grad/param norm = 9.7628e-01, time/batch = 0.1935s	
1625/2700 (epoch 30.093), train_loss = 3.31964708, grad/param norm = 1.1675e+00, time/batch = 0.2030s	
1626/2700 (epoch 30.111), train_loss = 3.29418211, grad/param norm = 1.2568e+00, time/batch = 0.2098s	
1627/2700 (epoch 30.130), train_loss = 3.31401665, grad/param norm = 1.1992e+00, time/batch = 0.2112s	
1628/2700 (epoch 30.148), train_loss = 3.26991832, grad/param norm = 1.4903e+00, time/batch = 0.2064s	
1629/2700 (epoch 30.167), train_loss = 3.30016000, grad/param norm = 1.6799e+00, time/batch = 0.2097s	
1630/2700 (epoch 30.185), train_loss = 3.27526971, grad/param norm = 1.4669e+00, time/batch = 0.2056s	
1631/2700 (epoch 30.204), train_loss = 3.20457854, grad/param norm = 1.4496e+00, time/batch = 0.1910s	
1632/2700 (epoch 30.222), train_loss = 3.17886238, grad/param norm = 1.8243e+00, time/batch = 0.1948s	
1633/2700 (epoch 30.241), train_loss = 3.20360714, grad/param norm = 1.7476e+00, time/batch = 0.1648s	
1634/2700 (epoch 30.259), train_loss = 3.23932258, grad/param norm = 1.7737e+00, time/batch = 0.1602s	
1635/2700 (epoch 30.278), train_loss = 3.32771118, grad/param norm = 2.5514e+00, time/batch = 0.2073s	
1636/2700 (epoch 30.296), train_loss = 3.34533386, grad/param norm = 2.4459e+00, time/batch = 0.2276s	
1637/2700 (epoch 30.315), train_loss = 3.30482231, grad/param norm = 1.7317e+00, time/batch = 0.2371s	
1638/2700 (epoch 30.333), train_loss = 3.36150071, grad/param norm = 1.3099e+00, time/batch = 0.2371s	
1639/2700 (epoch 30.352), train_loss = 3.36926727, grad/param norm = 1.3854e+00, time/batch = 0.2379s	
1640/2700 (epoch 30.370), train_loss = 3.32540302, grad/param norm = 1.5769e+00, time/batch = 0.2382s	
1641/2700 (epoch 30.389), train_loss = 3.28124300, grad/param norm = 1.5189e+00, time/batch = 0.2283s	
1642/2700 (epoch 30.407), train_loss = 3.30653431, grad/param norm = 1.4429e+00, time/batch = 0.2114s	
1643/2700 (epoch 30.426), train_loss = 3.30483507, grad/param norm = 1.3805e+00, time/batch = 0.2095s	
1644/2700 (epoch 30.444), train_loss = 3.22897707, grad/param norm = 1.4501e+00, time/batch = 0.2031s	
1645/2700 (epoch 30.463), train_loss = 3.28011012, grad/param norm = 1.7416e+00, time/batch = 0.2093s	
1646/2700 (epoch 30.481), train_loss = 3.36967504, grad/param norm = 1.8795e+00, time/batch = 0.2010s	
1647/2700 (epoch 30.500), train_loss = 3.40978185, grad/param norm = 2.0464e+00, time/batch = 0.2106s	
1648/2700 (epoch 30.519), train_loss = 3.36645144, grad/param norm = 2.0814e+00, time/batch = 0.2186s	
1649/2700 (epoch 30.537), train_loss = 3.37007079, grad/param norm = 1.8656e+00, time/batch = 0.2296s	
1650/2700 (epoch 30.556), train_loss = 3.30536622, grad/param norm = 1.5000e+00, time/batch = 0.2321s	
1651/2700 (epoch 30.574), train_loss = 3.24271557, grad/param norm = 1.1587e+00, time/batch = 0.2140s	
1652/2700 (epoch 30.593), train_loss = 3.25299370, grad/param norm = 1.4177e+00, time/batch = 0.2088s	
1653/2700 (epoch 30.611), train_loss = 3.19600988, grad/param norm = 1.3063e+00, time/batch = 0.1946s	
1654/2700 (epoch 30.630), train_loss = 3.23650718, grad/param norm = 1.4585e+00, time/batch = 0.2361s	
1655/2700 (epoch 30.648), train_loss = 3.31780319, grad/param norm = 1.5953e+00, time/batch = 0.2067s	
1656/2700 (epoch 30.667), train_loss = 3.25744036, grad/param norm = 1.6728e+00, time/batch = 0.1989s	
1657/2700 (epoch 30.685), train_loss = 3.24686031, grad/param norm = 1.5707e+00, time/batch = 0.1850s	
1658/2700 (epoch 30.704), train_loss = 3.22646820, grad/param norm = 1.7731e+00, time/batch = 0.1774s	
1659/2700 (epoch 30.722), train_loss = 3.22132020, grad/param norm = 1.6695e+00, time/batch = 0.1832s	
1660/2700 (epoch 30.741), train_loss = 3.34497037, grad/param norm = 1.5503e+00, time/batch = 0.1907s	
1661/2700 (epoch 30.759), train_loss = 3.30289031, grad/param norm = 1.8369e+00, time/batch = 0.1737s	
1662/2700 (epoch 30.778), train_loss = 3.30198463, grad/param norm = 2.2106e+00, time/batch = 0.1955s	
1663/2700 (epoch 30.796), train_loss = 3.30714752, grad/param norm = 2.1667e+00, time/batch = 0.1969s	
1664/2700 (epoch 30.815), train_loss = 3.23761519, grad/param norm = 1.9418e+00, time/batch = 0.2016s	
1665/2700 (epoch 30.833), train_loss = 3.28056487, grad/param norm = 1.9452e+00, time/batch = 0.1989s	
1666/2700 (epoch 30.852), train_loss = 3.26763706, grad/param norm = 1.9813e+00, time/batch = 0.2038s	
1667/2700 (epoch 30.870), train_loss = 3.26005395, grad/param norm = 1.6472e+00, time/batch = 0.1917s	
1668/2700 (epoch 30.889), train_loss = 3.27478983, grad/param norm = 1.4200e+00, time/batch = 0.1822s	
1669/2700 (epoch 30.907), train_loss = 3.32346189, grad/param norm = 1.5035e+00, time/batch = 0.1850s	
1670/2700 (epoch 30.926), train_loss = 3.28834505, grad/param norm = 1.7509e+00, time/batch = 0.1915s	
1671/2700 (epoch 30.944), train_loss = 3.30414782, grad/param norm = 1.5283e+00, time/batch = 0.2048s	
1672/2700 (epoch 30.963), train_loss = 3.36676126, grad/param norm = 1.3498e+00, time/batch = 0.2205s	
1673/2700 (epoch 30.981), train_loss = 3.42448974, grad/param norm = 1.3551e+00, time/batch = 0.2109s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
1674/2700 (epoch 31.000), train_loss = 3.33355113, grad/param norm = 1.3605e+00, time/batch = 0.2166s	
1675/2700 (epoch 31.019), train_loss = 3.26423182, grad/param norm = 1.4569e+00, time/batch = 0.2084s	
1676/2700 (epoch 31.037), train_loss = 3.28721607, grad/param norm = 1.4466e+00, time/batch = 0.2133s	
1677/2700 (epoch 31.056), train_loss = 3.27757710, grad/param norm = 1.0560e+00, time/batch = 0.2142s	
1678/2700 (epoch 31.074), train_loss = 3.30414884, grad/param norm = 9.5739e-01, time/batch = 0.2063s	
1679/2700 (epoch 31.093), train_loss = 3.31829108, grad/param norm = 1.1521e+00, time/batch = 0.1904s	
1680/2700 (epoch 31.111), train_loss = 3.29253069, grad/param norm = 1.2283e+00, time/batch = 0.1719s	
1681/2700 (epoch 31.130), train_loss = 3.31205511, grad/param norm = 1.1622e+00, time/batch = 0.2034s	
1682/2700 (epoch 31.148), train_loss = 3.26804723, grad/param norm = 1.4412e+00, time/batch = 0.1734s	
1683/2700 (epoch 31.167), train_loss = 3.29692790, grad/param norm = 1.6302e+00, time/batch = 0.1836s	
1684/2700 (epoch 31.185), train_loss = 3.27229730, grad/param norm = 1.3809e+00, time/batch = 0.1957s	
1685/2700 (epoch 31.204), train_loss = 3.20068640, grad/param norm = 1.3293e+00, time/batch = 0.2051s	
1686/2700 (epoch 31.222), train_loss = 3.17448205, grad/param norm = 1.6407e+00, time/batch = 0.1878s	
1687/2700 (epoch 31.241), train_loss = 3.19729517, grad/param norm = 1.4347e+00, time/batch = 0.2360s	
1688/2700 (epoch 31.259), train_loss = 3.22995975, grad/param norm = 1.3827e+00, time/batch = 0.2349s	
1689/2700 (epoch 31.278), train_loss = 3.31891640, grad/param norm = 2.2304e+00, time/batch = 0.2284s	
1690/2700 (epoch 31.296), train_loss = 3.33926276, grad/param norm = 2.3421e+00, time/batch = 0.2143s	
1691/2700 (epoch 31.315), train_loss = 3.30411489, grad/param norm = 1.9235e+00, time/batch = 0.2297s	
1692/2700 (epoch 31.333), train_loss = 3.36654007, grad/param norm = 1.6051e+00, time/batch = 0.2193s	
1693/2700 (epoch 31.352), train_loss = 3.37347472, grad/param norm = 1.6204e+00, time/batch = 0.2178s	
1694/2700 (epoch 31.370), train_loss = 3.32937832, grad/param norm = 1.8180e+00, time/batch = 0.2087s	
1695/2700 (epoch 31.389), train_loss = 3.28541836, grad/param norm = 1.7186e+00, time/batch = 0.2014s	
1696/2700 (epoch 31.407), train_loss = 3.30793516, grad/param norm = 1.5753e+00, time/batch = 0.1985s	
1697/2700 (epoch 31.426), train_loss = 3.30435561, grad/param norm = 1.4249e+00, time/batch = 0.2077s	
1698/2700 (epoch 31.444), train_loss = 3.22844702, grad/param norm = 1.4686e+00, time/batch = 0.2360s	
1699/2700 (epoch 31.463), train_loss = 3.27833191, grad/param norm = 1.6844e+00, time/batch = 0.2364s	
1700/2700 (epoch 31.481), train_loss = 3.36554754, grad/param norm = 1.7680e+00, time/batch = 0.2350s	
1701/2700 (epoch 31.500), train_loss = 3.40483693, grad/param norm = 1.8905e+00, time/batch = 0.2398s	
1702/2700 (epoch 31.519), train_loss = 3.36025477, grad/param norm = 1.9166e+00, time/batch = 0.2313s	
1703/2700 (epoch 31.537), train_loss = 3.36493377, grad/param norm = 1.7616e+00, time/batch = 0.2350s	
1704/2700 (epoch 31.556), train_loss = 3.30184142, grad/param norm = 1.4257e+00, time/batch = 0.2354s	
1705/2700 (epoch 31.574), train_loss = 3.24138239, grad/param norm = 1.1057e+00, time/batch = 0.2351s	
1706/2700 (epoch 31.593), train_loss = 3.25130945, grad/param norm = 1.3635e+00, time/batch = 0.2261s	
1707/2700 (epoch 31.611), train_loss = 3.19379670, grad/param norm = 1.2443e+00, time/batch = 0.2255s	
1708/2700 (epoch 31.630), train_loss = 3.23421485, grad/param norm = 1.3825e+00, time/batch = 0.1938s	
1709/2700 (epoch 31.648), train_loss = 3.31460148, grad/param norm = 1.5272e+00, time/batch = 0.2223s	
1710/2700 (epoch 31.667), train_loss = 3.25481169, grad/param norm = 1.6163e+00, time/batch = 0.2315s	
1711/2700 (epoch 31.685), train_loss = 3.24451538, grad/param norm = 1.5262e+00, time/batch = 0.2103s	
1712/2700 (epoch 31.704), train_loss = 3.22373189, grad/param norm = 1.7254e+00, time/batch = 0.2103s	
1713/2700 (epoch 31.722), train_loss = 3.21736924, grad/param norm = 1.6170e+00, time/batch = 0.2333s	
1714/2700 (epoch 31.741), train_loss = 3.34238913, grad/param norm = 1.5039e+00, time/batch = 0.2339s	
1715/2700 (epoch 31.759), train_loss = 3.29966772, grad/param norm = 1.7975e+00, time/batch = 0.2312s	
1716/2700 (epoch 31.778), train_loss = 3.30027981, grad/param norm = 2.1936e+00, time/batch = 0.2244s	
1717/2700 (epoch 31.796), train_loss = 3.30503769, grad/param norm = 2.1550e+00, time/batch = 0.2001s	
1718/2700 (epoch 31.815), train_loss = 3.23569354, grad/param norm = 1.9128e+00, time/batch = 0.1935s	
1719/2700 (epoch 31.833), train_loss = 3.27732956, grad/param norm = 1.9028e+00, time/batch = 0.1723s	
1720/2700 (epoch 31.852), train_loss = 3.26498359, grad/param norm = 1.9398e+00, time/batch = 0.1646s	
1721/2700 (epoch 31.870), train_loss = 3.25737335, grad/param norm = 1.6038e+00, time/batch = 0.1451s	
1722/2700 (epoch 31.889), train_loss = 3.27313466, grad/param norm = 1.3730e+00, time/batch = 0.1648s	
1723/2700 (epoch 31.907), train_loss = 3.32194321, grad/param norm = 1.4599e+00, time/batch = 0.1767s	
1724/2700 (epoch 31.926), train_loss = 3.28620953, grad/param norm = 1.7059e+00, time/batch = 0.1848s	
1725/2700 (epoch 31.944), train_loss = 3.30143946, grad/param norm = 1.4855e+00, time/batch = 0.2011s	
1726/2700 (epoch 31.963), train_loss = 3.36475136, grad/param norm = 1.3092e+00, time/batch = 0.2067s	
1727/2700 (epoch 31.981), train_loss = 3.42252079, grad/param norm = 1.3175e+00, time/batch = 0.2094s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
1728/2700 (epoch 32.000), train_loss = 3.33146389, grad/param norm = 1.3227e+00, time/batch = 0.2246s	
1729/2700 (epoch 32.019), train_loss = 3.26280521, grad/param norm = 1.4222e+00, time/batch = 0.2179s	
1730/2700 (epoch 32.037), train_loss = 3.28534973, grad/param norm = 1.4092e+00, time/batch = 0.2155s	
1731/2700 (epoch 32.056), train_loss = 3.27619243, grad/param norm = 1.0236e+00, time/batch = 0.2362s	
1732/2700 (epoch 32.074), train_loss = 3.30337696, grad/param norm = 9.4180e-01, time/batch = 0.2342s	
1733/2700 (epoch 32.093), train_loss = 3.31703640, grad/param norm = 1.1399e+00, time/batch = 0.2349s	
1734/2700 (epoch 32.111), train_loss = 3.29100959, grad/param norm = 1.2038e+00, time/batch = 0.2177s	
1735/2700 (epoch 32.130), train_loss = 3.31026236, grad/param norm = 1.1312e+00, time/batch = 0.2120s	
1736/2700 (epoch 32.148), train_loss = 3.26640495, grad/param norm = 1.3984e+00, time/batch = 0.2063s	
1737/2700 (epoch 32.167), train_loss = 3.29397275, grad/param norm = 1.5893e+00, time/batch = 0.1939s	
1738/2700 (epoch 32.185), train_loss = 3.26973148, grad/param norm = 1.3094e+00, time/batch = 0.2140s	
1739/2700 (epoch 32.204), train_loss = 3.19750551, grad/param norm = 1.2457e+00, time/batch = 0.2237s	
1740/2700 (epoch 32.222), train_loss = 3.17168330, grad/param norm = 1.4927e+00, time/batch = 0.2240s	
1741/2700 (epoch 32.241), train_loss = 3.19241868, grad/param norm = 1.1995e+00, time/batch = 0.2382s	
1742/2700 (epoch 32.259), train_loss = 3.22347037, grad/param norm = 9.0650e-01, time/batch = 0.2368s	
1743/2700 (epoch 32.278), train_loss = 3.29779426, grad/param norm = 1.1168e+00, time/batch = 0.2375s	
1744/2700 (epoch 32.296), train_loss = 3.30521113, grad/param norm = 1.2547e+00, time/batch = 0.2326s	
1745/2700 (epoch 32.315), train_loss = 3.28357421, grad/param norm = 1.2471e+00, time/batch = 0.2388s	
1746/2700 (epoch 32.333), train_loss = 3.36084660, grad/param norm = 1.3282e+00, time/batch = 0.2376s	
1747/2700 (epoch 32.352), train_loss = 3.38155561, grad/param norm = 1.8102e+00, time/batch = 0.2300s	
1748/2700 (epoch 32.370), train_loss = 3.34827176, grad/param norm = 2.3506e+00, time/batch = 0.2355s	
1749/2700 (epoch 32.389), train_loss = 3.31189607, grad/param norm = 2.8015e+00, time/batch = 0.2363s	
1750/2700 (epoch 32.407), train_loss = 3.34228886, grad/param norm = 2.4800e+00, time/batch = 0.2285s	
1751/2700 (epoch 32.426), train_loss = 3.30882405, grad/param norm = 1.6202e+00, time/batch = 0.1970s	
1752/2700 (epoch 32.444), train_loss = 3.23099717, grad/param norm = 1.5571e+00, time/batch = 0.1848s	
1753/2700 (epoch 32.463), train_loss = 3.27430729, grad/param norm = 1.5777e+00, time/batch = 0.1848s	
1754/2700 (epoch 32.481), train_loss = 3.35673645, grad/param norm = 1.5881e+00, time/batch = 0.1818s	
1755/2700 (epoch 32.500), train_loss = 3.40012680, grad/param norm = 1.7005e+00, time/batch = 0.2266s	
1756/2700 (epoch 32.519), train_loss = 3.35326100, grad/param norm = 1.7005e+00, time/batch = 0.2351s	
1757/2700 (epoch 32.537), train_loss = 3.35835344, grad/param norm = 1.6068e+00, time/batch = 0.2288s	
1758/2700 (epoch 32.556), train_loss = 3.29748680, grad/param norm = 1.3096e+00, time/batch = 0.2009s	
1759/2700 (epoch 32.574), train_loss = 3.24044554, grad/param norm = 1.0378e+00, time/batch = 0.1909s	
1760/2700 (epoch 32.593), train_loss = 3.24982265, grad/param norm = 1.2978e+00, time/batch = 0.1946s	
1761/2700 (epoch 32.611), train_loss = 3.19113105, grad/param norm = 1.1572e+00, time/batch = 0.2034s	
1762/2700 (epoch 32.630), train_loss = 3.23089412, grad/param norm = 1.2529e+00, time/batch = 0.2143s	
1763/2700 (epoch 32.648), train_loss = 3.30982929, grad/param norm = 1.4052e+00, time/batch = 0.2037s	
1764/2700 (epoch 32.667), train_loss = 3.25083947, grad/param norm = 1.4945e+00, time/batch = 0.1858s	
1765/2700 (epoch 32.685), train_loss = 3.24003589, grad/param norm = 1.4067e+00, time/batch = 0.1793s	
1766/2700 (epoch 32.704), train_loss = 3.21867078, grad/param norm = 1.6053e+00, time/batch = 0.1740s	
1767/2700 (epoch 32.722), train_loss = 3.21114038, grad/param norm = 1.4764e+00, time/batch = 0.1854s	
1768/2700 (epoch 32.741), train_loss = 3.33766626, grad/param norm = 1.3744e+00, time/batch = 0.2000s	
1769/2700 (epoch 32.759), train_loss = 3.29401724, grad/param norm = 1.6906e+00, time/batch = 0.2362s	
1770/2700 (epoch 32.778), train_loss = 3.29933680, grad/param norm = 2.1871e+00, time/batch = 0.2366s	
1771/2700 (epoch 32.796), train_loss = 3.30565708, grad/param norm = 2.1879e+00, time/batch = 0.2258s	
1772/2700 (epoch 32.815), train_loss = 3.23554743, grad/param norm = 1.9416e+00, time/batch = 0.2171s	
1773/2700 (epoch 32.833), train_loss = 3.27595149, grad/param norm = 1.9289e+00, time/batch = 0.2210s	
1774/2700 (epoch 32.852), train_loss = 3.26430948, grad/param norm = 1.9574e+00, time/batch = 0.2320s	
1775/2700 (epoch 32.870), train_loss = 3.25575035, grad/param norm = 1.6007e+00, time/batch = 0.2320s	
1776/2700 (epoch 32.889), train_loss = 3.27202654, grad/param norm = 1.3575e+00, time/batch = 0.2362s	
1777/2700 (epoch 32.907), train_loss = 3.32075500, grad/param norm = 1.4317e+00, time/batch = 0.2258s	
1778/2700 (epoch 32.926), train_loss = 3.28430387, grad/param norm = 1.6664e+00, time/batch = 0.2018s	
1779/2700 (epoch 32.944), train_loss = 3.29894474, grad/param norm = 1.4430e+00, time/batch = 0.2072s	
1780/2700 (epoch 32.963), train_loss = 3.36294207, grad/param norm = 1.2687e+00, time/batch = 0.2077s	
1781/2700 (epoch 32.981), train_loss = 3.42092087, grad/param norm = 1.2840e+00, time/batch = 0.2096s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
1782/2700 (epoch 33.000), train_loss = 3.32957602, grad/param norm = 1.2855e+00, time/batch = 0.2038s	
1783/2700 (epoch 33.019), train_loss = 3.26135907, grad/param norm = 1.3835e+00, time/batch = 0.1940s	
1784/2700 (epoch 33.037), train_loss = 3.28344532, grad/param norm = 1.3625e+00, time/batch = 0.2364s	
1785/2700 (epoch 33.056), train_loss = 3.27475701, grad/param norm = 9.8516e-01, time/batch = 0.2382s	
1786/2700 (epoch 33.074), train_loss = 3.30271559, grad/param norm = 9.3298e-01, time/batch = 0.2362s	
1787/2700 (epoch 33.093), train_loss = 3.31591175, grad/param norm = 1.1353e+00, time/batch = 0.2369s	
1788/2700 (epoch 33.111), train_loss = 3.28962441, grad/param norm = 1.1824e+00, time/batch = 0.2361s	
1789/2700 (epoch 33.130), train_loss = 3.30849575, grad/param norm = 1.1044e+00, time/batch = 0.2204s	
1790/2700 (epoch 33.148), train_loss = 3.26496861, grad/param norm = 1.3576e+00, time/batch = 0.2000s	
1791/2700 (epoch 33.167), train_loss = 3.29120207, grad/param norm = 1.5642e+00, time/batch = 0.2362s	
1792/2700 (epoch 33.185), train_loss = 3.26787706, grad/param norm = 1.2659e+00, time/batch = 0.2357s	
1793/2700 (epoch 33.204), train_loss = 3.19556635, grad/param norm = 1.2526e+00, time/batch = 0.2220s	
1794/2700 (epoch 33.222), train_loss = 3.17291747, grad/param norm = 1.5064e+00, time/batch = 0.1988s	
1795/2700 (epoch 33.241), train_loss = 3.19664309, grad/param norm = 1.5558e+00, time/batch = 0.2129s	
1796/2700 (epoch 33.259), train_loss = 3.24420825, grad/param norm = 2.1825e+00, time/batch = 0.2260s	
1797/2700 (epoch 33.278), train_loss = 3.32885723, grad/param norm = 2.3116e+00, time/batch = 0.2343s	
1798/2700 (epoch 33.296), train_loss = 3.32185587, grad/param norm = 2.2728e+00, time/batch = 0.2342s	
1799/2700 (epoch 33.315), train_loss = 3.29550961, grad/param norm = 2.0000e+00, time/batch = 0.2063s	
1800/2700 (epoch 33.333), train_loss = 3.36502069, grad/param norm = 1.5765e+00, time/batch = 0.2088s	
1801/2700 (epoch 33.352), train_loss = 3.37679570, grad/param norm = 1.5832e+00, time/batch = 0.2326s	
1802/2700 (epoch 33.370), train_loss = 3.32512291, grad/param norm = 1.3825e+00, time/batch = 0.2251s	
1803/2700 (epoch 33.389), train_loss = 3.27302453, grad/param norm = 1.1232e+00, time/batch = 0.2179s	
1804/2700 (epoch 33.407), train_loss = 3.29423491, grad/param norm = 9.7995e-01, time/batch = 0.2112s	
1805/2700 (epoch 33.426), train_loss = 3.29721918, grad/param norm = 1.0026e+00, time/batch = 0.2089s	
1806/2700 (epoch 33.444), train_loss = 3.21771992, grad/param norm = 9.5224e-01, time/batch = 0.1895s	
1807/2700 (epoch 33.463), train_loss = 3.26508704, grad/param norm = 1.0179e+00, time/batch = 0.1748s	
1808/2700 (epoch 33.481), train_loss = 3.33950689, grad/param norm = 8.3289e-01, time/batch = 0.1782s	
1809/2700 (epoch 33.500), train_loss = 3.38183424, grad/param norm = 9.1998e-01, time/batch = 0.1848s	
1810/2700 (epoch 33.519), train_loss = 3.33859983, grad/param norm = 1.1210e+00, time/batch = 0.2339s	
1811/2700 (epoch 33.537), train_loss = 3.35134130, grad/param norm = 1.3718e+00, time/batch = 0.2156s	
1812/2700 (epoch 33.556), train_loss = 3.29602187, grad/param norm = 1.3478e+00, time/batch = 0.2287s	
1813/2700 (epoch 33.574), train_loss = 3.24283881, grad/param norm = 1.2800e+00, time/batch = 0.2310s	
1814/2700 (epoch 33.593), train_loss = 3.25567603, grad/param norm = 1.6384e+00, time/batch = 0.2357s	
1815/2700 (epoch 33.611), train_loss = 3.20239532, grad/param norm = 1.7203e+00, time/batch = 0.2223s	
1816/2700 (epoch 33.630), train_loss = 3.24748202, grad/param norm = 1.9903e+00, time/batch = 0.2217s	
1817/2700 (epoch 33.648), train_loss = 3.33080976, grad/param norm = 2.1500e+00, time/batch = 0.2138s	
1818/2700 (epoch 33.667), train_loss = 3.26982362, grad/param norm = 2.2553e+00, time/batch = 0.2020s	
1819/2700 (epoch 33.685), train_loss = 3.25496385, grad/param norm = 1.8629e+00, time/batch = 0.1955s	
1820/2700 (epoch 33.704), train_loss = 3.22534758, grad/param norm = 1.8179e+00, time/batch = 0.2183s	
1821/2700 (epoch 33.722), train_loss = 3.21124376, grad/param norm = 1.5141e+00, time/batch = 0.2056s	
1822/2700 (epoch 33.741), train_loss = 3.33416900, grad/param norm = 1.2651e+00, time/batch = 0.2143s	
1823/2700 (epoch 33.759), train_loss = 3.28649594, grad/param norm = 1.4745e+00, time/batch = 0.2122s	
1824/2700 (epoch 33.778), train_loss = 3.28641684, grad/param norm = 1.8062e+00, time/batch = 0.2333s	
1825/2700 (epoch 33.796), train_loss = 3.28840091, grad/param norm = 1.7643e+00, time/batch = 0.2345s	
1826/2700 (epoch 33.815), train_loss = 3.22598212, grad/param norm = 1.5671e+00, time/batch = 0.2162s	
1827/2700 (epoch 33.833), train_loss = 3.26467505, grad/param norm = 1.5540e+00, time/batch = 0.2274s	
1828/2700 (epoch 33.852), train_loss = 3.25192838, grad/param norm = 1.5976e+00, time/batch = 0.2213s	
1829/2700 (epoch 33.870), train_loss = 3.24966493, grad/param norm = 1.4638e+00, time/batch = 0.2057s	
1830/2700 (epoch 33.889), train_loss = 3.27138515, grad/param norm = 1.3315e+00, time/batch = 0.1749s	
1831/2700 (epoch 33.907), train_loss = 3.32557822, grad/param norm = 1.5688e+00, time/batch = 0.1736s	
1832/2700 (epoch 33.926), train_loss = 3.29378100, grad/param norm = 1.8949e+00, time/batch = 0.1705s	
1833/2700 (epoch 33.944), train_loss = 3.30011075, grad/param norm = 1.5334e+00, time/batch = 0.1653s	
1834/2700 (epoch 33.963), train_loss = 3.36230181, grad/param norm = 1.3239e+00, time/batch = 0.2057s	
1835/2700 (epoch 33.981), train_loss = 3.42099479, grad/param norm = 1.3189e+00, time/batch = 0.2167s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
1836/2700 (epoch 34.000), train_loss = 3.32789253, grad/param norm = 1.3050e+00, time/batch = 0.2201s	
1837/2700 (epoch 34.019), train_loss = 3.26128187, grad/param norm = 1.4066e+00, time/batch = 0.2078s	
1838/2700 (epoch 34.037), train_loss = 3.28250931, grad/param norm = 1.4067e+00, time/batch = 0.2207s	
1839/2700 (epoch 34.056), train_loss = 3.27417614, grad/param norm = 1.0043e+00, time/batch = 0.2139s	
1840/2700 (epoch 34.074), train_loss = 3.30088188, grad/param norm = 8.7868e-01, time/batch = 0.1977s	
1841/2700 (epoch 34.093), train_loss = 3.31373250, grad/param norm = 1.0712e+00, time/batch = 0.2118s	
1842/2700 (epoch 34.111), train_loss = 3.28708650, grad/param norm = 1.1497e+00, time/batch = 0.1998s	
1843/2700 (epoch 34.130), train_loss = 3.30726391, grad/param norm = 1.0940e+00, time/batch = 0.1819s	
1844/2700 (epoch 34.148), train_loss = 3.26369676, grad/param norm = 1.3878e+00, time/batch = 0.2079s	
1845/2700 (epoch 34.167), train_loss = 3.29105564, grad/param norm = 1.5707e+00, time/batch = 0.2168s	
1846/2700 (epoch 34.185), train_loss = 3.26734342, grad/param norm = 1.3767e+00, time/batch = 0.2271s	
1847/2700 (epoch 34.204), train_loss = 3.19790606, grad/param norm = 1.3958e+00, time/batch = 0.2344s	
1848/2700 (epoch 34.222), train_loss = 3.17359719, grad/param norm = 1.7783e+00, time/batch = 0.2267s	
1849/2700 (epoch 34.241), train_loss = 3.19686160, grad/param norm = 1.6987e+00, time/batch = 0.2341s	
1850/2700 (epoch 34.259), train_loss = 3.23350040, grad/param norm = 1.6736e+00, time/batch = 0.2288s	
1851/2700 (epoch 34.278), train_loss = 3.31662512, grad/param norm = 2.2184e+00, time/batch = 0.2174s	
1852/2700 (epoch 34.296), train_loss = 3.32674541, grad/param norm = 2.1387e+00, time/batch = 0.2143s	
1853/2700 (epoch 34.315), train_loss = 3.29179747, grad/param norm = 1.4966e+00, time/batch = 0.2023s	
1854/2700 (epoch 34.333), train_loss = 3.35294254, grad/param norm = 1.0850e+00, time/batch = 0.2358s	
1855/2700 (epoch 34.352), train_loss = 3.36289963, grad/param norm = 1.2105e+00, time/batch = 0.2276s	
1856/2700 (epoch 34.370), train_loss = 3.31718261, grad/param norm = 1.3877e+00, time/batch = 0.2149s	
1857/2700 (epoch 34.389), train_loss = 3.27490407, grad/param norm = 1.3113e+00, time/batch = 0.2021s	
1858/2700 (epoch 34.407), train_loss = 3.29772310, grad/param norm = 1.1913e+00, time/batch = 0.1969s	
1859/2700 (epoch 34.426), train_loss = 3.29662436, grad/param norm = 1.1232e+00, time/batch = 0.1944s	
1860/2700 (epoch 34.444), train_loss = 3.22033508, grad/param norm = 1.1699e+00, time/batch = 0.2221s	
1861/2700 (epoch 34.463), train_loss = 3.26956357, grad/param norm = 1.4428e+00, time/batch = 0.1879s	
1862/2700 (epoch 34.481), train_loss = 3.35543777, grad/param norm = 1.6155e+00, time/batch = 0.1924s	
1863/2700 (epoch 34.500), train_loss = 3.40086448, grad/param norm = 1.8812e+00, time/batch = 0.1848s	
1864/2700 (epoch 34.519), train_loss = 3.35763448, grad/param norm = 1.9270e+00, time/batch = 0.2102s	
1865/2700 (epoch 34.537), train_loss = 3.36073236, grad/param norm = 1.7528e+00, time/batch = 0.2119s	
1866/2700 (epoch 34.556), train_loss = 3.29618906, grad/param norm = 1.4122e+00, time/batch = 0.2170s	
1867/2700 (epoch 34.574), train_loss = 3.23994853, grad/param norm = 1.0991e+00, time/batch = 0.2229s	
1868/2700 (epoch 34.593), train_loss = 3.24894916, grad/param norm = 1.3344e+00, time/batch = 0.2221s	
1869/2700 (epoch 34.611), train_loss = 3.19055065, grad/param norm = 1.1998e+00, time/batch = 0.2108s	
1870/2700 (epoch 34.630), train_loss = 3.23117851, grad/param norm = 1.3214e+00, time/batch = 0.1901s	
1871/2700 (epoch 34.648), train_loss = 3.31002903, grad/param norm = 1.4536e+00, time/batch = 0.1570s	
1872/2700 (epoch 34.667), train_loss = 3.24834131, grad/param norm = 1.5119e+00, time/batch = 0.1831s	
1873/2700 (epoch 34.685), train_loss = 3.23821738, grad/param norm = 1.4040e+00, time/batch = 0.1923s	
1874/2700 (epoch 34.704), train_loss = 3.21583728, grad/param norm = 1.5850e+00, time/batch = 0.2202s	
1875/2700 (epoch 34.722), train_loss = 3.20684583, grad/param norm = 1.4340e+00, time/batch = 0.2200s	
1876/2700 (epoch 34.741), train_loss = 3.33375778, grad/param norm = 1.3008e+00, time/batch = 0.2167s	
1877/2700 (epoch 34.759), train_loss = 3.28896904, grad/param norm = 1.5868e+00, time/batch = 0.2142s	
1878/2700 (epoch 34.778), train_loss = 3.29123880, grad/param norm = 2.0029e+00, time/batch = 0.2109s	
1879/2700 (epoch 34.796), train_loss = 3.29444872, grad/param norm = 1.9913e+00, time/batch = 0.2122s	
1880/2700 (epoch 34.815), train_loss = 3.22856301, grad/param norm = 1.7632e+00, time/batch = 0.2123s	
1881/2700 (epoch 34.833), train_loss = 3.26765866, grad/param norm = 1.7529e+00, time/batch = 0.2318s	
1882/2700 (epoch 34.852), train_loss = 3.25638780, grad/param norm = 1.7913e+00, time/batch = 0.2333s	
1883/2700 (epoch 34.870), train_loss = 3.25026700, grad/param norm = 1.5148e+00, time/batch = 0.2375s	
1884/2700 (epoch 34.889), train_loss = 3.26999021, grad/param norm = 1.3040e+00, time/batch = 0.2366s	
1885/2700 (epoch 34.907), train_loss = 3.31915963, grad/param norm = 1.3993e+00, time/batch = 0.2318s	
1886/2700 (epoch 34.926), train_loss = 3.28158110, grad/param norm = 1.6178e+00, time/batch = 0.2167s	
1887/2700 (epoch 34.944), train_loss = 3.29467395, grad/param norm = 1.3885e+00, time/batch = 0.2110s	
1888/2700 (epoch 34.963), train_loss = 3.36010016, grad/param norm = 1.2224e+00, time/batch = 0.2036s	
1889/2700 (epoch 34.981), train_loss = 3.41828815, grad/param norm = 1.2352e+00, time/batch = 0.1991s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
1890/2700 (epoch 35.000), train_loss = 3.32617244, grad/param norm = 1.2375e+00, time/batch = 0.2118s	
1891/2700 (epoch 35.019), train_loss = 3.25960200, grad/param norm = 1.3423e+00, time/batch = 0.1949s	
1892/2700 (epoch 35.037), train_loss = 3.28060606, grad/param norm = 1.3170e+00, time/batch = 0.1964s	
1893/2700 (epoch 35.056), train_loss = 3.27261992, grad/param norm = 9.4116e-01, time/batch = 0.2058s	
1894/2700 (epoch 35.074), train_loss = 3.30122417, grad/param norm = 9.0109e-01, time/batch = 0.2051s	
1895/2700 (epoch 35.093), train_loss = 3.31356622, grad/param norm = 1.1016e+00, time/batch = 0.2110s	
1896/2700 (epoch 35.111), train_loss = 3.28672143, grad/param norm = 1.1361e+00, time/batch = 0.2152s	
1897/2700 (epoch 35.130), train_loss = 3.30548675, grad/param norm = 1.0534e+00, time/batch = 0.2127s	
1898/2700 (epoch 35.148), train_loss = 3.26224407, grad/param norm = 1.3014e+00, time/batch = 0.2036s	
1899/2700 (epoch 35.167), train_loss = 3.28701855, grad/param norm = 1.5004e+00, time/batch = 0.2016s	
1900/2700 (epoch 35.185), train_loss = 3.26384959, grad/param norm = 1.1914e+00, time/batch = 0.2020s	
1901/2700 (epoch 35.204), train_loss = 3.19199765, grad/param norm = 1.1768e+00, time/batch = 0.1934s	
1902/2700 (epoch 35.222), train_loss = 3.16954884, grad/param norm = 1.4336e+00, time/batch = 0.1692s	
1903/2700 (epoch 35.241), train_loss = 3.19281625, grad/param norm = 1.4580e+00, time/batch = 0.2292s	
1904/2700 (epoch 35.259), train_loss = 3.23814397, grad/param norm = 2.0168e+00, time/batch = 0.2312s	
1905/2700 (epoch 35.278), train_loss = 3.32174830, grad/param norm = 2.1765e+00, time/batch = 0.2364s	
1906/2700 (epoch 35.296), train_loss = 3.31848973, grad/param norm = 2.2195e+00, time/batch = 0.2363s	
1907/2700 (epoch 35.315), train_loss = 3.29286164, grad/param norm = 1.9590e+00, time/batch = 0.2233s	
1908/2700 (epoch 35.333), train_loss = 3.36294283, grad/param norm = 1.5383e+00, time/batch = 0.2117s	
1909/2700 (epoch 35.352), train_loss = 3.37387402, grad/param norm = 1.5214e+00, time/batch = 0.2022s	
1910/2700 (epoch 35.370), train_loss = 3.31939514, grad/param norm = 1.3069e+00, time/batch = 0.2095s	
1911/2700 (epoch 35.389), train_loss = 3.26961807, grad/param norm = 1.0512e+00, time/batch = 0.2036s	
1912/2700 (epoch 35.407), train_loss = 3.29129422, grad/param norm = 9.1544e-01, time/batch = 0.2026s	
1913/2700 (epoch 35.426), train_loss = 3.29437378, grad/param norm = 9.4070e-01, time/batch = 0.1845s	
1914/2700 (epoch 35.444), train_loss = 3.21557055, grad/param norm = 8.8521e-01, time/batch = 0.2100s	
1915/2700 (epoch 35.463), train_loss = 3.26255402, grad/param norm = 9.5659e-01, time/batch = 0.2078s	
1916/2700 (epoch 35.481), train_loss = 3.33713512, grad/param norm = 7.9021e-01, time/batch = 0.2063s	
1917/2700 (epoch 35.500), train_loss = 3.38070427, grad/param norm = 9.3754e-01, time/batch = 0.2084s	
1918/2700 (epoch 35.519), train_loss = 3.33775372, grad/param norm = 1.1429e+00, time/batch = 0.2008s	
1919/2700 (epoch 35.537), train_loss = 3.34932198, grad/param norm = 1.3763e+00, time/batch = 0.1985s	
1920/2700 (epoch 35.556), train_loss = 3.29218996, grad/param norm = 1.3181e+00, time/batch = 0.1997s	
1921/2700 (epoch 35.574), train_loss = 3.24090819, grad/param norm = 1.2409e+00, time/batch = 0.1895s	
1922/2700 (epoch 35.593), train_loss = 3.25351127, grad/param norm = 1.5943e+00, time/batch = 0.1952s	
1923/2700 (epoch 35.611), train_loss = 3.19931720, grad/param norm = 1.6562e+00, time/batch = 0.1953s	
1924/2700 (epoch 35.630), train_loss = 3.24552275, grad/param norm = 1.9393e+00, time/batch = 0.2162s	
1925/2700 (epoch 35.648), train_loss = 3.32757734, grad/param norm = 2.0561e+00, time/batch = 0.2361s	
1926/2700 (epoch 35.667), train_loss = 3.25995451, grad/param norm = 2.0119e+00, time/batch = 0.2350s	
1927/2700 (epoch 35.685), train_loss = 3.24453050, grad/param norm = 1.6549e+00, time/batch = 0.2372s	
1928/2700 (epoch 35.704), train_loss = 3.21778144, grad/param norm = 1.6857e+00, time/batch = 0.2364s	
1929/2700 (epoch 35.722), train_loss = 3.20529860, grad/param norm = 1.4057e+00, time/batch = 0.2315s	
1930/2700 (epoch 35.741), train_loss = 3.32957551, grad/param norm = 1.1652e+00, time/batch = 0.2203s	
1931/2700 (epoch 35.759), train_loss = 3.28189007, grad/param norm = 1.3859e+00, time/batch = 0.2370s	
1932/2700 (epoch 35.778), train_loss = 3.28197741, grad/param norm = 1.7158e+00, time/batch = 0.2284s	
1933/2700 (epoch 35.796), train_loss = 3.28253833, grad/param norm = 1.6802e+00, time/batch = 0.2328s	
1934/2700 (epoch 35.815), train_loss = 3.22205893, grad/param norm = 1.4885e+00, time/batch = 0.1913s	
1935/2700 (epoch 35.833), train_loss = 3.26019261, grad/param norm = 1.4749e+00, time/batch = 0.1594s	
1936/2700 (epoch 35.852), train_loss = 3.24777098, grad/param norm = 1.5220e+00, time/batch = 0.1905s	
1937/2700 (epoch 35.870), train_loss = 3.24526639, grad/param norm = 1.3947e+00, time/batch = 0.2349s	
1938/2700 (epoch 35.889), train_loss = 3.26902862, grad/param norm = 1.2714e+00, time/batch = 0.2372s	
1939/2700 (epoch 35.907), train_loss = 3.31931082, grad/param norm = 1.4305e+00, time/batch = 0.2374s	
1940/2700 (epoch 35.926), train_loss = 3.28182518, grad/param norm = 1.6542e+00, time/batch = 0.2372s	
1941/2700 (epoch 35.944), train_loss = 3.29402565, grad/param norm = 1.4231e+00, time/batch = 0.2270s	
1942/2700 (epoch 35.963), train_loss = 3.36029599, grad/param norm = 1.2688e+00, time/batch = 0.2190s	
1943/2700 (epoch 35.981), train_loss = 3.41861334, grad/param norm = 1.2635e+00, time/batch = 0.2339s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
1944/2700 (epoch 36.000), train_loss = 3.32527997, grad/param norm = 1.2670e+00, time/batch = 0.2351s	
1945/2700 (epoch 36.019), train_loss = 3.26013026, grad/param norm = 1.3824e+00, time/batch = 0.2283s	
1946/2700 (epoch 36.037), train_loss = 3.28029106, grad/param norm = 1.3631e+00, time/batch = 0.1907s	
1947/2700 (epoch 36.056), train_loss = 3.27229028, grad/param norm = 9.6545e-01, time/batch = 0.1965s	
1948/2700 (epoch 36.074), train_loss = 3.30024402, grad/param norm = 8.7039e-01, time/batch = 0.2067s	
1949/2700 (epoch 36.093), train_loss = 3.31232945, grad/param norm = 1.0637e+00, time/batch = 0.2112s	
1950/2700 (epoch 36.111), train_loss = 3.28532784, grad/param norm = 1.1230e+00, time/batch = 0.2136s	
1951/2700 (epoch 36.130), train_loss = 3.30473715, grad/param norm = 1.0579e+00, time/batch = 0.2095s	
1952/2700 (epoch 36.148), train_loss = 3.26154385, grad/param norm = 1.3380e+00, time/batch = 0.2099s	
1953/2700 (epoch 36.167), train_loss = 3.28666783, grad/param norm = 1.5022e+00, time/batch = 0.2204s	
1954/2700 (epoch 36.185), train_loss = 3.26295598, grad/param norm = 1.2652e+00, time/batch = 0.2159s	
1955/2700 (epoch 36.204), train_loss = 3.19275847, grad/param norm = 1.2670e+00, time/batch = 0.2146s	
1956/2700 (epoch 36.222), train_loss = 3.16994527, grad/param norm = 1.6580e+00, time/batch = 0.1874s	
1957/2700 (epoch 36.241), train_loss = 3.19266408, grad/param norm = 1.5686e+00, time/batch = 0.1647s	
1958/2700 (epoch 36.259), train_loss = 3.22975833, grad/param norm = 1.5727e+00, time/batch = 0.1938s	
1959/2700 (epoch 36.278), train_loss = 3.31376897, grad/param norm = 2.1676e+00, time/batch = 0.1865s	
1960/2700 (epoch 36.296), train_loss = 3.32228461, grad/param norm = 2.0709e+00, time/batch = 0.1908s	
1961/2700 (epoch 36.315), train_loss = 3.28706338, grad/param norm = 1.4398e+00, time/batch = 0.1888s	
1962/2700 (epoch 36.333), train_loss = 3.35063865, grad/param norm = 1.0489e+00, time/batch = 0.1943s	
1963/2700 (epoch 36.352), train_loss = 3.36072430, grad/param norm = 1.1700e+00, time/batch = 0.2071s	
1964/2700 (epoch 36.370), train_loss = 3.31385446, grad/param norm = 1.3501e+00, time/batch = 0.2127s	
1965/2700 (epoch 36.389), train_loss = 3.27326856, grad/param norm = 1.2735e+00, time/batch = 0.2203s	
1966/2700 (epoch 36.407), train_loss = 3.29482988, grad/param norm = 1.1312e+00, time/batch = 0.2206s	
1967/2700 (epoch 36.426), train_loss = 3.29389929, grad/param norm = 1.0545e+00, time/batch = 0.1926s	
1968/2700 (epoch 36.444), train_loss = 3.21779082, grad/param norm = 1.0940e+00, time/batch = 0.2065s	
1969/2700 (epoch 36.463), train_loss = 3.26635143, grad/param norm = 1.3496e+00, time/batch = 0.1964s	
1970/2700 (epoch 36.481), train_loss = 3.35055316, grad/param norm = 1.5098e+00, time/batch = 0.1823s	
1971/2700 (epoch 36.500), train_loss = 3.39687206, grad/param norm = 1.7799e+00, time/batch = 0.2084s	
1972/2700 (epoch 36.519), train_loss = 3.35295774, grad/param norm = 1.8205e+00, time/batch = 0.2040s	
1973/2700 (epoch 36.537), train_loss = 3.35619122, grad/param norm = 1.6715e+00, time/batch = 0.2109s	
1974/2700 (epoch 36.556), train_loss = 3.29178488, grad/param norm = 1.3443e+00, time/batch = 0.2211s	
1975/2700 (epoch 36.574), train_loss = 3.23856472, grad/param norm = 1.0514e+00, time/batch = 0.2299s	
1976/2700 (epoch 36.593), train_loss = 3.24694791, grad/param norm = 1.2808e+00, time/batch = 0.2301s	
1977/2700 (epoch 36.611), train_loss = 3.18797988, grad/param norm = 1.1362e+00, time/batch = 0.2267s	
1978/2700 (epoch 36.630), train_loss = 3.22870411, grad/param norm = 1.2455e+00, time/batch = 0.1929s	
1979/2700 (epoch 36.648), train_loss = 3.30650108, grad/param norm = 1.3724e+00, time/batch = 0.2283s	
1980/2700 (epoch 36.667), train_loss = 3.24384139, grad/param norm = 1.4145e+00, time/batch = 0.2320s	
1981/2700 (epoch 36.685), train_loss = 3.23405619, grad/param norm = 1.3057e+00, time/batch = 0.2108s	
1982/2700 (epoch 36.704), train_loss = 3.21097938, grad/param norm = 1.4823e+00, time/batch = 0.2199s	
1983/2700 (epoch 36.722), train_loss = 3.20098957, grad/param norm = 1.3132e+00, time/batch = 0.2101s	
1984/2700 (epoch 36.741), train_loss = 3.32879899, grad/param norm = 1.1803e+00, time/batch = 0.2050s	
1985/2700 (epoch 36.759), train_loss = 3.28339958, grad/param norm = 1.4722e+00, time/batch = 0.2001s	
1986/2700 (epoch 36.778), train_loss = 3.28645949, grad/param norm = 1.8995e+00, time/batch = 0.2068s	
1987/2700 (epoch 36.796), train_loss = 3.28904839, grad/param norm = 1.9157e+00, time/batch = 0.2198s	
1988/2700 (epoch 36.815), train_loss = 3.22522614, grad/param norm = 1.6986e+00, time/batch = 0.2178s	
1989/2700 (epoch 36.833), train_loss = 3.26319496, grad/param norm = 1.6870e+00, time/batch = 0.2270s	
1990/2700 (epoch 36.852), train_loss = 3.25184363, grad/param norm = 1.7142e+00, time/batch = 0.2371s	
1991/2700 (epoch 36.870), train_loss = 3.24580400, grad/param norm = 1.4572e+00, time/batch = 0.2279s	
1992/2700 (epoch 36.889), train_loss = 3.26800887, grad/param norm = 1.2584e+00, time/batch = 0.2348s	
1993/2700 (epoch 36.907), train_loss = 3.31752327, grad/param norm = 1.3556e+00, time/batch = 0.2381s	
1994/2700 (epoch 36.926), train_loss = 3.27874268, grad/param norm = 1.5541e+00, time/batch = 0.2365s	
1995/2700 (epoch 36.944), train_loss = 3.29064771, grad/param norm = 1.3230e+00, time/batch = 0.2362s	
1996/2700 (epoch 36.963), train_loss = 3.35752135, grad/param norm = 1.1671e+00, time/batch = 0.2367s	
1997/2700 (epoch 36.981), train_loss = 3.41603790, grad/param norm = 1.1869e+00, time/batch = 0.2351s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
1998/2700 (epoch 37.000), train_loss = 3.32313372, grad/param norm = 1.1852e+00, time/batch = 0.2218s	
1999/2700 (epoch 37.019), train_loss = 3.25774045, grad/param norm = 1.2894e+00, time/batch = 0.2202s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch37.04_3.1960.t7	
2000/2700 (epoch 37.037), train_loss = 3.27771025, grad/param norm = 1.2527e+00, time/batch = 0.1888s	
2001/2700 (epoch 37.056), train_loss = 3.27053224, grad/param norm = 8.8921e-01, time/batch = 0.2098s	
2002/2700 (epoch 37.074), train_loss = 3.30005571, grad/param norm = 8.8626e-01, time/batch = 0.2114s	
2003/2700 (epoch 37.093), train_loss = 3.31161082, grad/param norm = 1.0851e+00, time/batch = 0.2149s	
2004/2700 (epoch 37.111), train_loss = 3.28424364, grad/param norm = 1.0995e+00, time/batch = 0.2059s	
2005/2700 (epoch 37.130), train_loss = 3.30271108, grad/param norm = 1.0132e+00, time/batch = 0.2006s	
2006/2700 (epoch 37.148), train_loss = 3.26002850, grad/param norm = 1.2482e+00, time/batch = 0.1839s	
2007/2700 (epoch 37.167), train_loss = 3.28310570, grad/param norm = 1.4585e+00, time/batch = 0.2093s	
2008/2700 (epoch 37.185), train_loss = 3.26091939, grad/param norm = 1.1540e+00, time/batch = 0.2032s	
2009/2700 (epoch 37.204), train_loss = 3.19009516, grad/param norm = 1.2035e+00, time/batch = 0.2270s	
2010/2700 (epoch 37.222), train_loss = 3.17030184, grad/param norm = 1.5252e+00, time/batch = 0.2292s	
2011/2700 (epoch 37.241), train_loss = 3.19665420, grad/param norm = 1.7093e+00, time/batch = 0.2374s	
2012/2700 (epoch 37.259), train_loss = 3.24166055, grad/param norm = 2.2941e+00, time/batch = 0.2363s	
2013/2700 (epoch 37.278), train_loss = 3.31809587, grad/param norm = 2.1088e+00, time/batch = 0.2365s	
2014/2700 (epoch 37.296), train_loss = 3.30764031, grad/param norm = 1.7898e+00, time/batch = 0.2361s	
2015/2700 (epoch 37.315), train_loss = 3.28078583, grad/param norm = 1.5778e+00, time/batch = 0.2359s	
2016/2700 (epoch 37.333), train_loss = 3.35790520, grad/param norm = 1.3519e+00, time/batch = 0.2293s	
2017/2700 (epoch 37.352), train_loss = 3.36796468, grad/param norm = 1.3532e+00, time/batch = 0.2297s	
2018/2700 (epoch 37.370), train_loss = 3.31263950, grad/param norm = 1.1831e+00, time/batch = 0.2115s	
2019/2700 (epoch 37.389), train_loss = 3.26630855, grad/param norm = 9.6846e-01, time/batch = 0.1912s	
2020/2700 (epoch 37.407), train_loss = 3.28885641, grad/param norm = 8.5788e-01, time/batch = 0.2346s	
2021/2700 (epoch 37.426), train_loss = 3.29205954, grad/param norm = 8.8884e-01, time/batch = 0.2223s	
2022/2700 (epoch 37.444), train_loss = 3.21450979, grad/param norm = 8.6120e-01, time/batch = 0.2342s	
2023/2700 (epoch 37.463), train_loss = 3.26136765, grad/param norm = 9.4615e-01, time/batch = 0.2343s	
2024/2700 (epoch 37.481), train_loss = 3.33558233, grad/param norm = 7.8829e-01, time/batch = 0.2345s	
2025/2700 (epoch 37.500), train_loss = 3.37990298, grad/param norm = 9.8278e-01, time/batch = 0.2347s	
2026/2700 (epoch 37.519), train_loss = 3.33687759, grad/param norm = 1.1827e+00, time/batch = 0.2316s	
2027/2700 (epoch 37.537), train_loss = 3.34742564, grad/param norm = 1.3957e+00, time/batch = 0.2109s	
2028/2700 (epoch 37.556), train_loss = 3.29473918, grad/param norm = 1.4114e+00, time/batch = 0.2011s	
2029/2700 (epoch 37.574), train_loss = 3.25151425, grad/param norm = 1.3723e+00, time/batch = 0.2053s	
2030/2700 (epoch 37.593), train_loss = 3.25403772, grad/param norm = 1.5305e+00, time/batch = 0.1881s	
2031/2700 (epoch 37.611), train_loss = 3.19321673, grad/param norm = 1.4261e+00, time/batch = 0.2247s	
2032/2700 (epoch 37.630), train_loss = 3.23145768, grad/param norm = 1.5703e+00, time/batch = 0.2166s	
2033/2700 (epoch 37.648), train_loss = 3.31128591, grad/param norm = 1.7293e+00, time/batch = 0.1988s	
2034/2700 (epoch 37.667), train_loss = 3.24815120, grad/param norm = 1.7584e+00, time/batch = 0.1802s	
2035/2700 (epoch 37.685), train_loss = 3.23699354, grad/param norm = 1.4847e+00, time/batch = 0.1854s	
2036/2700 (epoch 37.704), train_loss = 3.21209767, grad/param norm = 1.5737e+00, time/batch = 0.1974s	
2037/2700 (epoch 37.722), train_loss = 3.20179822, grad/param norm = 1.3678e+00, time/batch = 0.2030s	
2038/2700 (epoch 37.741), train_loss = 3.32852865, grad/param norm = 1.1509e+00, time/batch = 0.2254s	
2039/2700 (epoch 37.759), train_loss = 3.27867350, grad/param norm = 1.3448e+00, time/batch = 0.2335s	
2040/2700 (epoch 37.778), train_loss = 3.28041243, grad/param norm = 1.7080e+00, time/batch = 0.2217s	
2041/2700 (epoch 37.796), train_loss = 3.28007882, grad/param norm = 1.6534e+00, time/batch = 0.2122s	
2042/2700 (epoch 37.815), train_loss = 3.21907797, grad/param norm = 1.4447e+00, time/batch = 0.2073s	
2043/2700 (epoch 37.833), train_loss = 3.25699005, grad/param norm = 1.4396e+00, time/batch = 0.2003s	
2044/2700 (epoch 37.852), train_loss = 3.24521239, grad/param norm = 1.4906e+00, time/batch = 0.1949s	
2045/2700 (epoch 37.870), train_loss = 3.24175278, grad/param norm = 1.3506e+00, time/batch = 0.1947s	
2046/2700 (epoch 37.889), train_loss = 3.26678408, grad/param norm = 1.2200e+00, time/batch = 0.1989s	
2047/2700 (epoch 37.907), train_loss = 3.31740305, grad/param norm = 1.3727e+00, time/batch = 0.1899s	
2048/2700 (epoch 37.926), train_loss = 3.27896903, grad/param norm = 1.5831e+00, time/batch = 0.2051s	
2049/2700 (epoch 37.944), train_loss = 3.29041501, grad/param norm = 1.3555e+00, time/batch = 0.2267s	
2050/2700 (epoch 37.963), train_loss = 3.35793299, grad/param norm = 1.2047e+00, time/batch = 0.2199s	
2051/2700 (epoch 37.981), train_loss = 3.41602003, grad/param norm = 1.2031e+00, time/batch = 0.2251s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2052/2700 (epoch 38.000), train_loss = 3.32200553, grad/param norm = 1.1940e+00, time/batch = 0.2376s	
2053/2700 (epoch 38.019), train_loss = 3.25785902, grad/param norm = 1.3091e+00, time/batch = 0.2368s	
2054/2700 (epoch 38.037), train_loss = 3.27711058, grad/param norm = 1.2775e+00, time/batch = 0.2365s	
2055/2700 (epoch 38.056), train_loss = 3.27003673, grad/param norm = 8.9403e-01, time/batch = 0.2368s	
2056/2700 (epoch 38.074), train_loss = 3.29902628, grad/param norm = 8.4227e-01, time/batch = 0.2353s	
2057/2700 (epoch 38.093), train_loss = 3.31032984, grad/param norm = 1.0372e+00, time/batch = 0.2206s	
2058/2700 (epoch 38.111), train_loss = 3.28276731, grad/param norm = 1.0671e+00, time/batch = 0.2197s	
2059/2700 (epoch 38.130), train_loss = 3.30159782, grad/param norm = 9.8608e-01, time/batch = 0.2110s	
2060/2700 (epoch 38.148), train_loss = 3.25890099, grad/param norm = 1.2429e+00, time/batch = 0.1947s	
2061/2700 (epoch 38.167), train_loss = 3.28166287, grad/param norm = 1.4069e+00, time/batch = 0.2134s	
2062/2700 (epoch 38.185), train_loss = 3.25856890, grad/param norm = 1.1054e+00, time/batch = 0.1829s	
2063/2700 (epoch 38.204), train_loss = 3.18762219, grad/param norm = 1.0539e+00, time/batch = 0.2347s	
2064/2700 (epoch 38.222), train_loss = 3.16404515, grad/param norm = 1.3661e+00, time/batch = 0.2371s	
2065/2700 (epoch 38.241), train_loss = 3.18501766, grad/param norm = 1.1241e+00, time/batch = 0.2365s	
2066/2700 (epoch 38.259), train_loss = 3.21834239, grad/param norm = 1.0162e+00, time/batch = 0.2365s	
2067/2700 (epoch 38.278), train_loss = 3.30151862, grad/param norm = 1.6944e+00, time/batch = 0.2306s	
2068/2700 (epoch 38.296), train_loss = 3.31637645, grad/param norm = 1.9469e+00, time/batch = 0.2074s	
2069/2700 (epoch 38.315), train_loss = 3.28844506, grad/param norm = 1.7066e+00, time/batch = 0.1951s	
2070/2700 (epoch 38.333), train_loss = 3.35568373, grad/param norm = 1.4102e+00, time/batch = 0.1935s	
2071/2700 (epoch 38.352), train_loss = 3.36312153, grad/param norm = 1.4130e+00, time/batch = 0.2195s	
2072/2700 (epoch 38.370), train_loss = 3.31592072, grad/param norm = 1.6122e+00, time/batch = 0.2048s	
2073/2700 (epoch 38.389), train_loss = 3.27686960, grad/param norm = 1.4951e+00, time/batch = 0.1694s	
2074/2700 (epoch 38.407), train_loss = 3.29570230, grad/param norm = 1.3007e+00, time/batch = 0.2012s	
2075/2700 (epoch 38.426), train_loss = 3.29370690, grad/param norm = 1.1437e+00, time/batch = 0.2076s	
2076/2700 (epoch 38.444), train_loss = 3.21862175, grad/param norm = 1.1836e+00, time/batch = 0.2059s	
2077/2700 (epoch 38.463), train_loss = 3.26576030, grad/param norm = 1.3529e+00, time/batch = 0.2062s	
2078/2700 (epoch 38.481), train_loss = 3.34714397, grad/param norm = 1.4147e+00, time/batch = 0.2066s	
2079/2700 (epoch 38.500), train_loss = 3.39161676, grad/param norm = 1.5817e+00, time/batch = 0.2346s	
2080/2700 (epoch 38.519), train_loss = 3.34507839, grad/param norm = 1.5677e+00, time/batch = 0.2352s	
2081/2700 (epoch 38.537), train_loss = 3.34891457, grad/param norm = 1.4677e+00, time/batch = 0.2233s	
2082/2700 (epoch 38.556), train_loss = 3.28668308, grad/param norm = 1.1885e+00, time/batch = 0.2263s	
2083/2700 (epoch 38.574), train_loss = 3.23747126, grad/param norm = 9.5519e-01, time/batch = 0.2200s	
2084/2700 (epoch 38.593), train_loss = 3.24445008, grad/param norm = 1.1690e+00, time/batch = 0.1927s	
2085/2700 (epoch 38.611), train_loss = 3.18444417, grad/param norm = 9.9960e-01, time/batch = 0.1806s	
2086/2700 (epoch 38.630), train_loss = 3.22439826, grad/param norm = 1.0726e+00, time/batch = 0.1844s	
2087/2700 (epoch 38.648), train_loss = 3.30084291, grad/param norm = 1.1994e+00, time/batch = 0.1886s	
2088/2700 (epoch 38.667), train_loss = 3.23841815, grad/param norm = 1.2442e+00, time/batch = 0.2162s	
2089/2700 (epoch 38.685), train_loss = 3.22945634, grad/param norm = 1.1631e+00, time/batch = 0.2265s	
2090/2700 (epoch 38.704), train_loss = 3.20603569, grad/param norm = 1.3438e+00, time/batch = 0.2224s	
2091/2700 (epoch 38.722), train_loss = 3.19531757, grad/param norm = 1.1613e+00, time/batch = 0.2302s	
2092/2700 (epoch 38.741), train_loss = 3.32452744, grad/param norm = 1.0569e+00, time/batch = 0.2357s	
2093/2700 (epoch 38.759), train_loss = 3.27882838, grad/param norm = 1.3611e+00, time/batch = 0.2356s	
2094/2700 (epoch 38.778), train_loss = 3.28315176, grad/param norm = 1.8185e+00, time/batch = 0.2247s	
2095/2700 (epoch 38.796), train_loss = 3.28614808, grad/param norm = 1.8877e+00, time/batch = 0.2354s	
2096/2700 (epoch 38.815), train_loss = 3.22382611, grad/param norm = 1.6922e+00, time/batch = 0.2360s	
2097/2700 (epoch 38.833), train_loss = 3.26100981, grad/param norm = 1.6956e+00, time/batch = 0.2191s	
2098/2700 (epoch 38.852), train_loss = 3.24983036, grad/param norm = 1.7051e+00, time/batch = 0.2090s	
2099/2700 (epoch 38.870), train_loss = 3.24229417, grad/param norm = 1.4205e+00, time/batch = 0.1923s	
2100/2700 (epoch 38.889), train_loss = 3.26626407, grad/param norm = 1.2172e+00, time/batch = 0.1780s	
2101/2700 (epoch 38.907), train_loss = 3.31596859, grad/param norm = 1.3019e+00, time/batch = 0.2102s	
2102/2700 (epoch 38.926), train_loss = 3.27585041, grad/param norm = 1.4738e+00, time/batch = 0.1975s	
2103/2700 (epoch 38.944), train_loss = 3.28670079, grad/param norm = 1.2430e+00, time/batch = 0.2028s	
2104/2700 (epoch 38.963), train_loss = 3.35494450, grad/param norm = 1.0982e+00, time/batch = 0.2127s	
2105/2700 (epoch 38.981), train_loss = 3.41385085, grad/param norm = 1.1302e+00, time/batch = 0.2039s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2106/2700 (epoch 39.000), train_loss = 3.32030247, grad/param norm = 1.1266e+00, time/batch = 0.2074s	
2107/2700 (epoch 39.019), train_loss = 3.25580350, grad/param norm = 1.2254e+00, time/batch = 0.2009s	
2108/2700 (epoch 39.037), train_loss = 3.27484251, grad/param norm = 1.1758e+00, time/batch = 0.2036s	
2109/2700 (epoch 39.056), train_loss = 3.26866282, grad/param norm = 8.3903e-01, time/batch = 0.1845s	
2110/2700 (epoch 39.074), train_loss = 3.29923720, grad/param norm = 8.9156e-01, time/batch = 0.2126s	
2111/2700 (epoch 39.093), train_loss = 3.31004548, grad/param norm = 1.0832e+00, time/batch = 0.2355s	
2112/2700 (epoch 39.111), train_loss = 3.28208633, grad/param norm = 1.0726e+00, time/batch = 0.2364s	
2113/2700 (epoch 39.130), train_loss = 3.30020859, grad/param norm = 9.8319e-01, time/batch = 0.2347s	
2114/2700 (epoch 39.148), train_loss = 3.25815408, grad/param norm = 1.2030e+00, time/batch = 0.2230s	
2115/2700 (epoch 39.167), train_loss = 3.27982869, grad/param norm = 1.4323e+00, time/batch = 0.2135s	
2116/2700 (epoch 39.185), train_loss = 3.25870322, grad/param norm = 1.1495e+00, time/batch = 0.1798s	
2117/2700 (epoch 39.204), train_loss = 3.18915382, grad/param norm = 1.2546e+00, time/batch = 0.2345s	
2118/2700 (epoch 39.222), train_loss = 3.17080237, grad/param norm = 1.5949e+00, time/batch = 0.2360s	
2119/2700 (epoch 39.241), train_loss = 3.19661634, grad/param norm = 1.7535e+00, time/batch = 0.2268s	
2120/2700 (epoch 39.259), train_loss = 3.23532056, grad/param norm = 2.0743e+00, time/batch = 0.2252s	
2121/2700 (epoch 39.278), train_loss = 3.30750672, grad/param norm = 1.8381e+00, time/batch = 0.2368s	
2122/2700 (epoch 39.296), train_loss = 3.30298985, grad/param norm = 1.6296e+00, time/batch = 0.2349s	
2123/2700 (epoch 39.315), train_loss = 3.27701221, grad/param norm = 1.4542e+00, time/batch = 0.2356s	
2124/2700 (epoch 39.333), train_loss = 3.35922462, grad/param norm = 1.3755e+00, time/batch = 0.2347s	
2125/2700 (epoch 39.352), train_loss = 3.36813212, grad/param norm = 1.4112e+00, time/batch = 0.2317s	
2126/2700 (epoch 39.370), train_loss = 3.31113464, grad/param norm = 1.1613e+00, time/batch = 0.2183s	
2127/2700 (epoch 39.389), train_loss = 3.26430958, grad/param norm = 9.1183e-01, time/batch = 0.2072s	
2128/2700 (epoch 39.407), train_loss = 3.28699543, grad/param norm = 8.2990e-01, time/batch = 0.2037s	
2129/2700 (epoch 39.426), train_loss = 3.29131101, grad/param norm = 8.9199e-01, time/batch = 0.2101s	
2130/2700 (epoch 39.444), train_loss = 3.21456377, grad/param norm = 8.8090e-01, time/batch = 0.1998s	
2131/2700 (epoch 39.463), train_loss = 3.26012707, grad/param norm = 9.2585e-01, time/batch = 0.2109s	
2132/2700 (epoch 39.481), train_loss = 3.33319434, grad/param norm = 7.4027e-01, time/batch = 0.2156s	
2133/2700 (epoch 39.500), train_loss = 3.37867690, grad/param norm = 9.8424e-01, time/batch = 0.2259s	
2134/2700 (epoch 39.519), train_loss = 3.33574317, grad/param norm = 1.1745e+00, time/batch = 0.2197s	
2135/2700 (epoch 39.537), train_loss = 3.34494881, grad/param norm = 1.3567e+00, time/batch = 0.2113s	
2136/2700 (epoch 39.556), train_loss = 3.28567730, grad/param norm = 1.2494e+00, time/batch = 0.2026s	
2137/2700 (epoch 39.574), train_loss = 3.23877599, grad/param norm = 1.1458e+00, time/batch = 0.2022s	
2138/2700 (epoch 39.593), train_loss = 3.24888462, grad/param norm = 1.4500e+00, time/batch = 0.1864s	
2139/2700 (epoch 39.611), train_loss = 3.19121449, grad/param norm = 1.3957e+00, time/batch = 0.1879s	
2140/2700 (epoch 39.630), train_loss = 3.23394902, grad/param norm = 1.5704e+00, time/batch = 0.1827s	
2141/2700 (epoch 39.648), train_loss = 3.31254168, grad/param norm = 1.6860e+00, time/batch = 0.2081s	
2142/2700 (epoch 39.667), train_loss = 3.24471860, grad/param norm = 1.6390e+00, time/batch = 0.2091s	
2143/2700 (epoch 39.685), train_loss = 3.23253206, grad/param norm = 1.3571e+00, time/batch = 0.2161s	
2144/2700 (epoch 39.704), train_loss = 3.20633409, grad/param norm = 1.4441e+00, time/batch = 0.2270s	
2145/2700 (epoch 39.722), train_loss = 3.19595770, grad/param norm = 1.2078e+00, time/batch = 0.2346s	
2146/2700 (epoch 39.741), train_loss = 3.32249334, grad/param norm = 1.0012e+00, time/batch = 0.2252s	
2147/2700 (epoch 39.759), train_loss = 3.27467914, grad/param norm = 1.2391e+00, time/batch = 0.2352s	
2148/2700 (epoch 39.778), train_loss = 3.27434592, grad/param norm = 1.5381e+00, time/batch = 0.2217s	
2149/2700 (epoch 39.796), train_loss = 3.27323929, grad/param norm = 1.5492e+00, time/batch = 0.2232s	
2150/2700 (epoch 39.815), train_loss = 3.21678545, grad/param norm = 1.3941e+00, time/batch = 0.1987s	
2151/2700 (epoch 39.833), train_loss = 3.25426418, grad/param norm = 1.3807e+00, time/batch = 0.2024s	
2152/2700 (epoch 39.852), train_loss = 3.24189965, grad/param norm = 1.4180e+00, time/batch = 0.1902s	
2153/2700 (epoch 39.870), train_loss = 3.23789193, grad/param norm = 1.2814e+00, time/batch = 0.1861s	
2154/2700 (epoch 39.889), train_loss = 3.26492418, grad/param norm = 1.1642e+00, time/batch = 0.1813s	
2155/2700 (epoch 39.907), train_loss = 3.31602948, grad/param norm = 1.3235e+00, time/batch = 0.1962s	
2156/2700 (epoch 39.926), train_loss = 3.27613192, grad/param norm = 1.5093e+00, time/batch = 0.1963s	
2157/2700 (epoch 39.944), train_loss = 3.28652717, grad/param norm = 1.2838e+00, time/batch = 0.2045s	
2158/2700 (epoch 39.963), train_loss = 3.35566055, grad/param norm = 1.1494e+00, time/batch = 0.2024s	
2159/2700 (epoch 39.981), train_loss = 3.41443494, grad/param norm = 1.1612e+00, time/batch = 0.1800s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2160/2700 (epoch 40.000), train_loss = 3.31970138, grad/param norm = 1.1510e+00, time/batch = 0.1878s	
2161/2700 (epoch 40.019), train_loss = 3.25641266, grad/param norm = 1.2618e+00, time/batch = 0.2071s	
2162/2700 (epoch 40.037), train_loss = 3.27464183, grad/param norm = 1.2141e+00, time/batch = 0.2080s	
2163/2700 (epoch 40.056), train_loss = 3.26821478, grad/param norm = 8.4039e-01, time/batch = 0.2110s	
2164/2700 (epoch 40.074), train_loss = 3.29800313, grad/param norm = 8.2406e-01, time/batch = 0.2157s	
2165/2700 (epoch 40.093), train_loss = 3.30850426, grad/param norm = 1.0135e+00, time/batch = 0.2129s	
2166/2700 (epoch 40.111), train_loss = 3.28053444, grad/param norm = 1.0232e+00, time/batch = 0.2098s	
2167/2700 (epoch 40.130), train_loss = 3.29906581, grad/param norm = 9.3813e-01, time/batch = 0.2042s	
2168/2700 (epoch 40.148), train_loss = 3.25691927, grad/param norm = 1.1729e+00, time/batch = 0.2003s	
2169/2700 (epoch 40.167), train_loss = 3.27770221, grad/param norm = 1.3410e+00, time/batch = 0.2103s	
2170/2700 (epoch 40.185), train_loss = 3.25552096, grad/param norm = 1.0108e+00, time/batch = 0.2106s	
2171/2700 (epoch 40.204), train_loss = 3.18480881, grad/param norm = 9.7013e-01, time/batch = 0.2146s	
2172/2700 (epoch 40.222), train_loss = 3.16197005, grad/param norm = 1.2274e+00, time/batch = 0.2371s	
2173/2700 (epoch 40.241), train_loss = 3.18189641, grad/param norm = 1.0159e+00, time/batch = 0.2385s	
2174/2700 (epoch 40.259), train_loss = 3.21719538, grad/param norm = 1.0295e+00, time/batch = 0.2372s	
2175/2700 (epoch 40.278), train_loss = 3.29456326, grad/param norm = 1.3585e+00, time/batch = 0.2317s	
2176/2700 (epoch 40.296), train_loss = 3.31069654, grad/param norm = 2.0046e+00, time/batch = 0.2356s	
2177/2700 (epoch 40.315), train_loss = 3.29636875, grad/param norm = 2.0690e+00, time/batch = 0.2356s	
2178/2700 (epoch 40.333), train_loss = 3.36328423, grad/param norm = 1.7315e+00, time/batch = 0.2340s	
2179/2700 (epoch 40.352), train_loss = 3.37156940, grad/param norm = 1.6040e+00, time/batch = 0.2265s	
2180/2700 (epoch 40.370), train_loss = 3.30998827, grad/param norm = 1.2293e+00, time/batch = 0.2141s	
2181/2700 (epoch 40.389), train_loss = 3.26280314, grad/param norm = 9.2760e-01, time/batch = 0.1813s	
2182/2700 (epoch 40.407), train_loss = 3.28548621, grad/param norm = 7.9915e-01, time/batch = 0.1971s	
2183/2700 (epoch 40.426), train_loss = 3.28905630, grad/param norm = 8.5772e-01, time/batch = 0.2032s	
2184/2700 (epoch 40.444), train_loss = 3.21178543, grad/param norm = 7.5336e-01, time/batch = 0.2172s	
2185/2700 (epoch 40.463), train_loss = 3.25723250, grad/param norm = 8.1964e-01, time/batch = 0.2128s	
2186/2700 (epoch 40.481), train_loss = 3.33261695, grad/param norm = 6.8989e-01, time/batch = 0.2345s	
2187/2700 (epoch 40.500), train_loss = 3.37881338, grad/param norm = 9.1924e-01, time/batch = 0.2357s	
2188/2700 (epoch 40.519), train_loss = 3.33571894, grad/param norm = 1.0688e+00, time/batch = 0.2350s	
2189/2700 (epoch 40.537), train_loss = 3.34195087, grad/param norm = 1.2113e+00, time/batch = 0.2327s	
2190/2700 (epoch 40.556), train_loss = 3.28615266, grad/param norm = 1.1613e+00, time/batch = 0.2308s	
2191/2700 (epoch 40.574), train_loss = 3.23859694, grad/param norm = 1.0661e+00, time/batch = 0.2062s	
2192/2700 (epoch 40.593), train_loss = 3.24648127, grad/param norm = 1.3445e+00, time/batch = 0.2007s	
2193/2700 (epoch 40.611), train_loss = 3.18941248, grad/param norm = 1.2868e+00, time/batch = 0.1867s	
2194/2700 (epoch 40.630), train_loss = 3.22886219, grad/param norm = 1.4354e+00, time/batch = 0.1667s	
2195/2700 (epoch 40.648), train_loss = 3.30381807, grad/param norm = 1.6023e+00, time/batch = 0.1685s	
2196/2700 (epoch 40.667), train_loss = 3.24312781, grad/param norm = 1.6997e+00, time/batch = 0.1785s	
2197/2700 (epoch 40.685), train_loss = 3.23355874, grad/param norm = 1.4511e+00, time/batch = 0.1888s	
2198/2700 (epoch 40.704), train_loss = 3.20813899, grad/param norm = 1.5295e+00, time/batch = 0.1929s	
2199/2700 (epoch 40.722), train_loss = 3.19879419, grad/param norm = 1.3539e+00, time/batch = 0.2033s	
2200/2700 (epoch 40.741), train_loss = 3.32675119, grad/param norm = 1.1293e+00, time/batch = 0.2077s	
2201/2700 (epoch 40.759), train_loss = 3.27397441, grad/param norm = 1.2604e+00, time/batch = 0.2116s	
2202/2700 (epoch 40.778), train_loss = 3.27324548, grad/param norm = 1.5293e+00, time/batch = 0.1963s	
2203/2700 (epoch 40.796), train_loss = 3.27060378, grad/param norm = 1.4920e+00, time/batch = 0.2301s	
2204/2700 (epoch 40.815), train_loss = 3.21413355, grad/param norm = 1.3101e+00, time/batch = 0.2170s	
2205/2700 (epoch 40.833), train_loss = 3.25205068, grad/param norm = 1.2969e+00, time/batch = 0.1989s	
2206/2700 (epoch 40.852), train_loss = 3.24036044, grad/param norm = 1.3405e+00, time/batch = 0.1934s	
2207/2700 (epoch 40.870), train_loss = 3.23608690, grad/param norm = 1.1951e+00, time/batch = 0.2078s	
2208/2700 (epoch 40.889), train_loss = 3.26274262, grad/param norm = 1.0704e+00, time/batch = 0.2267s	
2209/2700 (epoch 40.907), train_loss = 3.31457252, grad/param norm = 1.2536e+00, time/batch = 0.2324s	
2210/2700 (epoch 40.926), train_loss = 3.27484058, grad/param norm = 1.4643e+00, time/batch = 0.2351s	
2211/2700 (epoch 40.944), train_loss = 3.28565670, grad/param norm = 1.2694e+00, time/batch = 0.2334s	
2212/2700 (epoch 40.963), train_loss = 3.35548618, grad/param norm = 1.1387e+00, time/batch = 0.2232s	
2213/2700 (epoch 40.981), train_loss = 3.41310979, grad/param norm = 1.1286e+00, time/batch = 0.2228s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2214/2700 (epoch 41.000), train_loss = 3.31773916, grad/param norm = 1.1131e+00, time/batch = 0.2176s	
2215/2700 (epoch 41.019), train_loss = 3.25583931, grad/param norm = 1.2333e+00, time/batch = 0.2206s	
2216/2700 (epoch 41.037), train_loss = 3.27334263, grad/param norm = 1.1884e+00, time/batch = 0.2167s	
2217/2700 (epoch 41.056), train_loss = 3.26743896, grad/param norm = 8.2019e-01, time/batch = 0.2096s	
2218/2700 (epoch 41.074), train_loss = 3.29732653, grad/param norm = 8.0208e-01, time/batch = 0.1977s	
2219/2700 (epoch 41.093), train_loss = 3.30759739, grad/param norm = 9.9171e-01, time/batch = 0.1805s	
2220/2700 (epoch 41.111), train_loss = 3.27944277, grad/param norm = 9.9938e-01, time/batch = 0.1767s	
2221/2700 (epoch 41.130), train_loss = 3.29792469, grad/param norm = 9.1524e-01, time/batch = 0.1769s	
2222/2700 (epoch 41.148), train_loss = 3.25608149, grad/param norm = 1.1557e+00, time/batch = 0.1788s	
2223/2700 (epoch 41.167), train_loss = 3.27639131, grad/param norm = 1.3152e+00, time/batch = 0.1861s	
2224/2700 (epoch 41.185), train_loss = 3.25430547, grad/param norm = 9.9082e-01, time/batch = 0.2273s	
2225/2700 (epoch 41.204), train_loss = 3.18395084, grad/param norm = 9.4255e-01, time/batch = 0.1968s	
2226/2700 (epoch 41.222), train_loss = 3.16091646, grad/param norm = 1.2304e+00, time/batch = 0.1914s	
2227/2700 (epoch 41.241), train_loss = 3.18043622, grad/param norm = 9.4094e-01, time/batch = 0.1913s	
2228/2700 (epoch 41.259), train_loss = 3.21282903, grad/param norm = 7.1030e-01, time/batch = 0.2305s	
2229/2700 (epoch 41.278), train_loss = 3.29007827, grad/param norm = 1.0834e+00, time/batch = 0.2336s	
2230/2700 (epoch 41.296), train_loss = 3.29946373, grad/param norm = 1.3967e+00, time/batch = 0.2349s	
2231/2700 (epoch 41.315), train_loss = 3.28082188, grad/param norm = 1.5156e+00, time/batch = 0.2281s	
2232/2700 (epoch 41.333), train_loss = 3.35712995, grad/param norm = 1.5063e+00, time/batch = 0.2373s	
2233/2700 (epoch 41.352), train_loss = 3.36609106, grad/param norm = 1.6879e+00, time/batch = 0.2319s	
2234/2700 (epoch 41.370), train_loss = 3.31918090, grad/param norm = 1.8706e+00, time/batch = 0.2270s	
2235/2700 (epoch 41.389), train_loss = 3.28129361, grad/param norm = 1.6508e+00, time/batch = 0.2362s	
2236/2700 (epoch 41.407), train_loss = 3.29981735, grad/param norm = 1.4360e+00, time/batch = 0.2357s	
2237/2700 (epoch 41.426), train_loss = 3.29220565, grad/param norm = 1.1599e+00, time/batch = 0.2298s	
2238/2700 (epoch 41.444), train_loss = 3.21484814, grad/param norm = 1.1040e+00, time/batch = 0.2150s	
2239/2700 (epoch 41.463), train_loss = 3.26071222, grad/param norm = 1.1208e+00, time/batch = 0.2097s	
2240/2700 (epoch 41.481), train_loss = 3.33736163, grad/param norm = 1.1253e+00, time/batch = 0.2014s	
2241/2700 (epoch 41.500), train_loss = 3.38348899, grad/param norm = 1.3924e+00, time/batch = 0.2173s	
2242/2700 (epoch 41.519), train_loss = 3.33879418, grad/param norm = 1.3780e+00, time/batch = 0.2125s	
2243/2700 (epoch 41.537), train_loss = 3.33994864, grad/param norm = 1.2921e+00, time/batch = 0.1891s	
2244/2700 (epoch 41.556), train_loss = 3.28211265, grad/param norm = 1.1115e+00, time/batch = 0.2015s	
2245/2700 (epoch 41.574), train_loss = 3.23892483, grad/param norm = 9.8222e-01, time/batch = 0.2187s	
2246/2700 (epoch 41.593), train_loss = 3.24518697, grad/param norm = 1.1113e+00, time/batch = 0.2249s	
2247/2700 (epoch 41.611), train_loss = 3.17837316, grad/param norm = 7.5621e-01, time/batch = 0.2234s	
2248/2700 (epoch 41.630), train_loss = 3.21680081, grad/param norm = 7.5877e-01, time/batch = 0.2106s	
2249/2700 (epoch 41.648), train_loss = 3.29231939, grad/param norm = 9.1333e-01, time/batch = 0.2173s	
2250/2700 (epoch 41.667), train_loss = 3.22952068, grad/param norm = 1.0040e+00, time/batch = 0.2111s	
2251/2700 (epoch 41.685), train_loss = 3.22240649, grad/param norm = 9.9789e-01, time/batch = 0.2383s	
2252/2700 (epoch 41.704), train_loss = 3.20514115, grad/param norm = 1.2915e+00, time/batch = 0.2359s	
2253/2700 (epoch 41.722), train_loss = 3.19392435, grad/param norm = 1.2089e+00, time/batch = 0.2320s	
2254/2700 (epoch 41.741), train_loss = 3.32431633, grad/param norm = 1.2037e+00, time/batch = 0.2062s	
2255/2700 (epoch 41.759), train_loss = 3.26660191, grad/param norm = 1.1800e+00, time/batch = 0.2125s	
2256/2700 (epoch 41.778), train_loss = 3.26811678, grad/param norm = 1.2966e+00, time/batch = 0.2073s	
2257/2700 (epoch 41.796), train_loss = 3.27047602, grad/param norm = 1.4415e+00, time/batch = 0.1907s	
2258/2700 (epoch 41.815), train_loss = 3.21591306, grad/param norm = 1.2378e+00, time/batch = 0.1742s	
2259/2700 (epoch 41.833), train_loss = 3.24690157, grad/param norm = 1.0743e+00, time/batch = 0.1680s	
2260/2700 (epoch 41.852), train_loss = 3.23378586, grad/param norm = 1.1474e+00, time/batch = 0.2151s	
2261/2700 (epoch 41.870), train_loss = 3.23389366, grad/param norm = 1.2419e+00, time/batch = 0.2282s	
2262/2700 (epoch 41.889), train_loss = 3.27130755, grad/param norm = 1.4815e+00, time/batch = 0.2190s	
2263/2700 (epoch 41.907), train_loss = 3.33744584, grad/param norm = 2.0340e+00, time/batch = 0.2146s	
2264/2700 (epoch 41.926), train_loss = 3.30615083, grad/param norm = 2.2987e+00, time/batch = 0.1930s	
2265/2700 (epoch 41.944), train_loss = 3.29870686, grad/param norm = 1.6451e+00, time/batch = 0.2329s	
2266/2700 (epoch 41.963), train_loss = 3.34848289, grad/param norm = 1.1121e+00, time/batch = 0.2347s	
2267/2700 (epoch 41.981), train_loss = 3.40898847, grad/param norm = 1.0899e+00, time/batch = 0.2332s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2268/2700 (epoch 42.000), train_loss = 3.31962490, grad/param norm = 1.1877e+00, time/batch = 0.2315s	
2269/2700 (epoch 42.019), train_loss = 3.25363674, grad/param norm = 1.2625e+00, time/batch = 0.2188s	
2270/2700 (epoch 42.037), train_loss = 3.26813148, grad/param norm = 1.1405e+00, time/batch = 0.1918s	
2271/2700 (epoch 42.056), train_loss = 3.25963681, grad/param norm = 7.2396e-01, time/batch = 0.2112s	
2272/2700 (epoch 42.074), train_loss = 3.29054645, grad/param norm = 7.5216e-01, time/batch = 0.2160s	
2273/2700 (epoch 42.093), train_loss = 3.30185296, grad/param norm = 9.2833e-01, time/batch = 0.2192s	
2274/2700 (epoch 42.111), train_loss = 3.27556628, grad/param norm = 1.0101e+00, time/batch = 0.2088s	
2275/2700 (epoch 42.130), train_loss = 3.29424612, grad/param norm = 9.4226e-01, time/batch = 0.2349s	
2276/2700 (epoch 42.148), train_loss = 3.24921915, grad/param norm = 1.1665e+00, time/batch = 0.2207s	
2277/2700 (epoch 42.167), train_loss = 3.27029255, grad/param norm = 1.3656e+00, time/batch = 0.2138s	
2278/2700 (epoch 42.185), train_loss = 3.24719054, grad/param norm = 1.0888e+00, time/batch = 0.2123s	
2279/2700 (epoch 42.204), train_loss = 3.17565259, grad/param norm = 1.0834e+00, time/batch = 0.2123s	
2280/2700 (epoch 42.222), train_loss = 3.15829781, grad/param norm = 1.5103e+00, time/batch = 0.2084s	
2281/2700 (epoch 42.241), train_loss = 3.17866999, grad/param norm = 1.4651e+00, time/batch = 0.2368s	
2282/2700 (epoch 42.259), train_loss = 3.22756574, grad/param norm = 1.7787e+00, time/batch = 0.2352s	
2283/2700 (epoch 42.278), train_loss = 3.31614392, grad/param norm = 1.9786e+00, time/batch = 0.2308s	
2284/2700 (epoch 42.296), train_loss = 3.29073071, grad/param norm = 1.3714e+00, time/batch = 0.2258s	
2285/2700 (epoch 42.315), train_loss = 3.26069337, grad/param norm = 9.9043e-01, time/batch = 0.2167s	
2286/2700 (epoch 42.333), train_loss = 3.33343076, grad/param norm = 8.1615e-01, time/batch = 0.2086s	
2287/2700 (epoch 42.352), train_loss = 3.34575677, grad/param norm = 9.1268e-01, time/batch = 0.2040s	
2288/2700 (epoch 42.370), train_loss = 3.28982671, grad/param norm = 1.0379e+00, time/batch = 0.2105s	
2289/2700 (epoch 42.389), train_loss = 3.26015101, grad/param norm = 1.1294e+00, time/batch = 0.2215s	
2290/2700 (epoch 42.407), train_loss = 3.28734892, grad/param norm = 1.0665e+00, time/batch = 0.2315s	
2291/2700 (epoch 42.426), train_loss = 3.28024647, grad/param norm = 8.9301e-01, time/batch = 0.2056s	
2292/2700 (epoch 42.444), train_loss = 3.20082191, grad/param norm = 8.2361e-01, time/batch = 0.2352s	
2293/2700 (epoch 42.463), train_loss = 3.24866792, grad/param norm = 1.0667e+00, time/batch = 0.2318s	
2294/2700 (epoch 42.481), train_loss = 3.33325080, grad/param norm = 1.3235e+00, time/batch = 0.2328s	
2295/2700 (epoch 42.500), train_loss = 3.38835787, grad/param norm = 1.6808e+00, time/batch = 0.2150s	
2296/2700 (epoch 42.519), train_loss = 3.34590359, grad/param norm = 1.7691e+00, time/batch = 0.2100s	
2297/2700 (epoch 42.537), train_loss = 3.34281877, grad/param norm = 1.5391e+00, time/batch = 0.2038s	
2298/2700 (epoch 42.556), train_loss = 3.27602107, grad/param norm = 1.1711e+00, time/batch = 0.1956s	
2299/2700 (epoch 42.574), train_loss = 3.22775194, grad/param norm = 9.8289e-01, time/batch = 0.1879s	
2300/2700 (epoch 42.593), train_loss = 3.23158123, grad/param norm = 1.1308e+00, time/batch = 0.1810s	
2301/2700 (epoch 42.611), train_loss = 3.17041294, grad/param norm = 8.8993e-01, time/batch = 0.1717s	
2302/2700 (epoch 42.630), train_loss = 3.20591386, grad/param norm = 9.5441e-01, time/batch = 0.1857s	
2303/2700 (epoch 42.648), train_loss = 3.28053095, grad/param norm = 9.7568e-01, time/batch = 0.2057s	
2304/2700 (epoch 42.667), train_loss = 3.21288832, grad/param norm = 9.8505e-01, time/batch = 0.2191s	
2305/2700 (epoch 42.685), train_loss = 3.20885073, grad/param norm = 9.2398e-01, time/batch = 0.2131s	
2306/2700 (epoch 42.704), train_loss = 3.18147223, grad/param norm = 1.1228e+00, time/batch = 0.2346s	
2307/2700 (epoch 42.722), train_loss = 3.17535063, grad/param norm = 1.0177e+00, time/batch = 0.2332s	
2308/2700 (epoch 42.741), train_loss = 3.31129901, grad/param norm = 1.0319e+00, time/batch = 0.2355s	
2309/2700 (epoch 42.759), train_loss = 3.25924590, grad/param norm = 1.2380e+00, time/batch = 0.2244s	
2310/2700 (epoch 42.778), train_loss = 3.26299569, grad/param norm = 1.5691e+00, time/batch = 0.2123s	
2311/2700 (epoch 42.796), train_loss = 3.26457823, grad/param norm = 1.6575e+00, time/batch = 0.2373s	
2312/2700 (epoch 42.815), train_loss = 3.20502303, grad/param norm = 1.5597e+00, time/batch = 0.2371s	
2313/2700 (epoch 42.833), train_loss = 3.24469561, grad/param norm = 1.6056e+00, time/batch = 0.2006s	
2314/2700 (epoch 42.852), train_loss = 3.23082723, grad/param norm = 1.6245e+00, time/batch = 0.2073s	
2315/2700 (epoch 42.870), train_loss = 3.21938632, grad/param norm = 1.3139e+00, time/batch = 0.2027s	
2316/2700 (epoch 42.889), train_loss = 3.24945109, grad/param norm = 1.2191e+00, time/batch = 0.2221s	
2317/2700 (epoch 42.907), train_loss = 3.30812356, grad/param norm = 1.3845e+00, time/batch = 0.2220s	
2318/2700 (epoch 42.926), train_loss = 3.27149035, grad/param norm = 1.6411e+00, time/batch = 0.2328s	
2319/2700 (epoch 42.944), train_loss = 3.27448776, grad/param norm = 1.3600e+00, time/batch = 0.2346s	
2320/2700 (epoch 42.963), train_loss = 3.33569268, grad/param norm = 1.1136e+00, time/batch = 0.2354s	
2321/2700 (epoch 42.981), train_loss = 3.38671821, grad/param norm = 9.0672e-01, time/batch = 0.2286s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
2322/2700 (epoch 43.000), train_loss = 3.30291088, grad/param norm = 1.1499e+00, time/batch = 0.2356s	
2323/2700 (epoch 43.019), train_loss = 3.24153728, grad/param norm = 1.2570e+00, time/batch = 0.2214s	
2324/2700 (epoch 43.037), train_loss = 3.25886640, grad/param norm = 1.2128e+00, time/batch = 0.2368s	
2325/2700 (epoch 43.056), train_loss = 3.24309194, grad/param norm = 7.5179e-01, time/batch = 0.2296s	
2326/2700 (epoch 43.074), train_loss = 3.28101558, grad/param norm = 1.0751e+00, time/batch = 0.2349s	
2327/2700 (epoch 43.093), train_loss = 3.30235440, grad/param norm = 1.4213e+00, time/batch = 0.2198s	
2328/2700 (epoch 43.111), train_loss = 3.26348707, grad/param norm = 1.2166e+00, time/batch = 0.2098s	
2329/2700 (epoch 43.130), train_loss = 3.27667207, grad/param norm = 9.3991e-01, time/batch = 0.2020s	
2330/2700 (epoch 43.148), train_loss = 3.22771606, grad/param norm = 9.3643e-01, time/batch = 0.2108s	
2331/2700 (epoch 43.167), train_loss = 3.24776040, grad/param norm = 1.1483e+00, time/batch = 0.1967s	
2332/2700 (epoch 43.185), train_loss = 3.22948889, grad/param norm = 1.0131e+00, time/batch = 0.2034s	
2333/2700 (epoch 43.204), train_loss = 3.16584065, grad/param norm = 1.0872e+00, time/batch = 0.2111s	
2334/2700 (epoch 43.222), train_loss = 3.13850828, grad/param norm = 1.2277e+00, time/batch = 0.2186s	
2335/2700 (epoch 43.241), train_loss = 3.15673325, grad/param norm = 1.3607e+00, time/batch = 0.2283s	
2336/2700 (epoch 43.259), train_loss = 3.19510422, grad/param norm = 1.4980e+00, time/batch = 0.2039s	
2337/2700 (epoch 43.278), train_loss = 3.26483167, grad/param norm = 1.2995e+00, time/batch = 0.2061s	
2338/2700 (epoch 43.296), train_loss = 3.26427933, grad/param norm = 1.2840e+00, time/batch = 0.1972s	
2339/2700 (epoch 43.315), train_loss = 3.24377509, grad/param norm = 1.1331e+00, time/batch = 0.1912s	
2340/2700 (epoch 43.333), train_loss = 3.32615330, grad/param norm = 1.2043e+00, time/batch = 0.1961s	
2341/2700 (epoch 43.352), train_loss = 3.36889192, grad/param norm = 1.7338e+00, time/batch = 0.1767s	
2342/2700 (epoch 43.370), train_loss = 3.30706762, grad/param norm = 1.5295e+00, time/batch = 0.1848s	
2343/2700 (epoch 43.389), train_loss = 3.24303257, grad/param norm = 1.2691e+00, time/batch = 0.1946s	
2344/2700 (epoch 43.407), train_loss = 3.26377988, grad/param norm = 1.2472e+00, time/batch = 0.2180s	
2345/2700 (epoch 43.426), train_loss = 3.26604189, grad/param norm = 1.2662e+00, time/batch = 0.2030s	
2346/2700 (epoch 43.444), train_loss = 3.19822828, grad/param norm = 1.6390e+00, time/batch = 0.2030s	
2347/2700 (epoch 43.463), train_loss = 3.24363153, grad/param norm = 1.5124e+00, time/batch = 0.1996s	
2348/2700 (epoch 43.481), train_loss = 3.31026762, grad/param norm = 1.3452e+00, time/batch = 0.1899s	
2349/2700 (epoch 43.500), train_loss = 3.34653198, grad/param norm = 1.4357e+00, time/batch = 0.1851s	
2350/2700 (epoch 43.519), train_loss = 3.30763630, grad/param norm = 1.5218e+00, time/batch = 0.1894s	
2351/2700 (epoch 43.537), train_loss = 3.31604707, grad/param norm = 1.3818e+00, time/batch = 0.1899s	
2352/2700 (epoch 43.556), train_loss = 3.25786697, grad/param norm = 1.1817e+00, time/batch = 0.2051s	
2353/2700 (epoch 43.574), train_loss = 3.20333511, grad/param norm = 8.6476e-01, time/batch = 0.2046s	
2354/2700 (epoch 43.593), train_loss = 3.20844438, grad/param norm = 1.0589e+00, time/batch = 0.2103s	
2355/2700 (epoch 43.611), train_loss = 3.15588875, grad/param norm = 9.3419e-01, time/batch = 0.2153s	
2356/2700 (epoch 43.630), train_loss = 3.18681182, grad/param norm = 1.0373e+00, time/batch = 0.2045s	
2357/2700 (epoch 43.648), train_loss = 3.26243147, grad/param norm = 9.1029e-01, time/batch = 0.2080s	
2358/2700 (epoch 43.667), train_loss = 3.19192080, grad/param norm = 1.0611e+00, time/batch = 0.2091s	
2359/2700 (epoch 43.685), train_loss = 3.20113942, grad/param norm = 1.6279e+00, time/batch = 0.2017s	
2360/2700 (epoch 43.704), train_loss = 3.17702925, grad/param norm = 1.6995e+00, time/batch = 0.1849s	
2361/2700 (epoch 43.722), train_loss = 3.15664141, grad/param norm = 1.4512e+00, time/batch = 0.2380s	
2362/2700 (epoch 43.741), train_loss = 3.29300164, grad/param norm = 1.4655e+00, time/batch = 0.2315s	
2363/2700 (epoch 43.759), train_loss = 3.23134388, grad/param norm = 1.3279e+00, time/batch = 0.2252s	
2364/2700 (epoch 43.778), train_loss = 3.23727654, grad/param norm = 1.4981e+00, time/batch = 0.2156s	
2365/2700 (epoch 43.796), train_loss = 3.24282220, grad/param norm = 1.5365e+00, time/batch = 0.2092s	
2366/2700 (epoch 43.815), train_loss = 3.16922213, grad/param norm = 1.0441e+00, time/batch = 0.2018s	
2367/2700 (epoch 43.833), train_loss = 3.20278676, grad/param norm = 9.3199e-01, time/batch = 0.1749s	
2368/2700 (epoch 43.852), train_loss = 3.19415555, grad/param norm = 1.1885e+00, time/batch = 0.2073s	
2369/2700 (epoch 43.870), train_loss = 3.20576156, grad/param norm = 1.4140e+00, time/batch = 0.2068s	
2370/2700 (epoch 43.889), train_loss = 3.24936412, grad/param norm = 1.6769e+00, time/batch = 0.2102s	
2371/2700 (epoch 43.907), train_loss = 3.32570173, grad/param norm = 1.9610e+00, time/batch = 0.2330s	
2372/2700 (epoch 43.926), train_loss = 3.26193505, grad/param norm = 1.9177e+00, time/batch = 0.2252s	
2373/2700 (epoch 43.944), train_loss = 3.24611605, grad/param norm = 1.3015e+00, time/batch = 0.2257s	
2374/2700 (epoch 43.963), train_loss = 3.30891438, grad/param norm = 1.0966e+00, time/batch = 0.2240s	
2375/2700 (epoch 43.981), train_loss = 3.36204087, grad/param norm = 1.1908e+00, time/batch = 0.2192s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
2376/2700 (epoch 44.000), train_loss = 3.28082416, grad/param norm = 1.4228e+00, time/batch = 0.2057s	
2377/2700 (epoch 44.019), train_loss = 3.21825185, grad/param norm = 1.5105e+00, time/batch = 0.1781s	
2378/2700 (epoch 44.037), train_loss = 3.22011160, grad/param norm = 1.2552e+00, time/batch = 0.1905s	
2379/2700 (epoch 44.056), train_loss = 3.21554030, grad/param norm = 1.0159e+00, time/batch = 0.2390s	
2380/2700 (epoch 44.074), train_loss = 3.24128475, grad/param norm = 8.4887e-01, time/batch = 0.2362s	
2381/2700 (epoch 44.093), train_loss = 3.25327498, grad/param norm = 9.1314e-01, time/batch = 0.2212s	
2382/2700 (epoch 44.111), train_loss = 3.22549587, grad/param norm = 1.0199e+00, time/batch = 0.2177s	
2383/2700 (epoch 44.130), train_loss = 3.24754887, grad/param norm = 1.1008e+00, time/batch = 0.2359s	
2384/2700 (epoch 44.148), train_loss = 3.21064681, grad/param norm = 1.5564e+00, time/batch = 0.2327s	
2385/2700 (epoch 44.167), train_loss = 3.23345580, grad/param norm = 1.5638e+00, time/batch = 0.2276s	
2386/2700 (epoch 44.185), train_loss = 3.19703586, grad/param norm = 1.0763e+00, time/batch = 0.2219s	
2387/2700 (epoch 44.204), train_loss = 3.14318012, grad/param norm = 1.1335e+00, time/batch = 0.2111s	
2388/2700 (epoch 44.222), train_loss = 3.11324384, grad/param norm = 1.5565e+00, time/batch = 0.2180s	
2389/2700 (epoch 44.241), train_loss = 3.14327395, grad/param norm = 1.7149e+00, time/batch = 0.1871s	
2390/2700 (epoch 44.259), train_loss = 3.18358896, grad/param norm = 2.0464e+00, time/batch = 0.1818s	
2391/2700 (epoch 44.278), train_loss = 3.27493672, grad/param norm = 1.9679e+00, time/batch = 0.2152s	
2392/2700 (epoch 44.296), train_loss = 3.23387448, grad/param norm = 1.3895e+00, time/batch = 0.1998s	
2393/2700 (epoch 44.315), train_loss = 3.21211464, grad/param norm = 1.0407e+00, time/batch = 0.1971s	
2394/2700 (epoch 44.333), train_loss = 3.27557702, grad/param norm = 9.2650e-01, time/batch = 0.2113s	
2395/2700 (epoch 44.352), train_loss = 3.29332056, grad/param norm = 1.0636e+00, time/batch = 0.2253s	
2396/2700 (epoch 44.370), train_loss = 3.22742356, grad/param norm = 1.1751e+00, time/batch = 0.2352s	
2397/2700 (epoch 44.389), train_loss = 3.19402557, grad/param norm = 9.6683e-01, time/batch = 0.2291s	
2398/2700 (epoch 44.407), train_loss = 3.21604614, grad/param norm = 1.0383e+00, time/batch = 0.2218s	
2399/2700 (epoch 44.426), train_loss = 3.23084115, grad/param norm = 1.2659e+00, time/batch = 0.2109s	
2400/2700 (epoch 44.444), train_loss = 3.15426269, grad/param norm = 1.3876e+00, time/batch = 0.2165s	
2401/2700 (epoch 44.463), train_loss = 3.21145924, grad/param norm = 1.5298e+00, time/batch = 0.2332s	
2402/2700 (epoch 44.481), train_loss = 3.28059580, grad/param norm = 1.2802e+00, time/batch = 0.2361s	
2403/2700 (epoch 44.500), train_loss = 3.31250579, grad/param norm = 1.0975e+00, time/batch = 0.2370s	
2404/2700 (epoch 44.519), train_loss = 3.25828857, grad/param norm = 1.0538e+00, time/batch = 0.2358s	
2405/2700 (epoch 44.537), train_loss = 3.26092802, grad/param norm = 1.1704e+00, time/batch = 0.2362s	
2406/2700 (epoch 44.556), train_loss = 3.20858863, grad/param norm = 1.2317e+00, time/batch = 0.2288s	
2407/2700 (epoch 44.574), train_loss = 3.17092014, grad/param norm = 1.4255e+00, time/batch = 0.2135s	
2408/2700 (epoch 44.593), train_loss = 3.18296378, grad/param norm = 1.8947e+00, time/batch = 0.1907s	
2409/2700 (epoch 44.611), train_loss = 3.13327127, grad/param norm = 1.9203e+00, time/batch = 0.1800s	
2410/2700 (epoch 44.630), train_loss = 3.16222113, grad/param norm = 2.0009e+00, time/batch = 0.1806s	
2411/2700 (epoch 44.648), train_loss = 3.25243198, grad/param norm = 1.7264e+00, time/batch = 0.2286s	
2412/2700 (epoch 44.667), train_loss = 3.15533160, grad/param norm = 1.1767e+00, time/batch = 0.2125s	
2413/2700 (epoch 44.685), train_loss = 3.14658130, grad/param norm = 1.0918e+00, time/batch = 0.2024s	
2414/2700 (epoch 44.704), train_loss = 3.11564042, grad/param norm = 1.3714e+00, time/batch = 0.1895s	
2415/2700 (epoch 44.722), train_loss = 3.11371293, grad/param norm = 1.4401e+00, time/batch = 0.1836s	
2416/2700 (epoch 44.741), train_loss = 3.27001729, grad/param norm = 1.8062e+00, time/batch = 0.1789s	
2417/2700 (epoch 44.759), train_loss = 3.20508503, grad/param norm = 1.7205e+00, time/batch = 0.1760s	
2418/2700 (epoch 44.778), train_loss = 3.18947736, grad/param norm = 1.2865e+00, time/batch = 0.1550s	
2419/2700 (epoch 44.796), train_loss = 3.18833022, grad/param norm = 1.1864e+00, time/batch = 0.1539s	
2420/2700 (epoch 44.815), train_loss = 3.12512634, grad/param norm = 1.0380e+00, time/batch = 0.1472s	
2421/2700 (epoch 44.833), train_loss = 3.16181391, grad/param norm = 1.2129e+00, time/batch = 0.1650s	
2422/2700 (epoch 44.852), train_loss = 3.16490846, grad/param norm = 1.4340e+00, time/batch = 0.1493s	
2423/2700 (epoch 44.870), train_loss = 3.15163802, grad/param norm = 1.2304e+00, time/batch = 0.1365s	
2424/2700 (epoch 44.889), train_loss = 3.18427523, grad/param norm = 1.3696e+00, time/batch = 0.1287s	
2425/2700 (epoch 44.907), train_loss = 3.25674558, grad/param norm = 1.5782e+00, time/batch = 0.1377s	
2426/2700 (epoch 44.926), train_loss = 3.20982183, grad/param norm = 1.6079e+00, time/batch = 0.1414s	
2427/2700 (epoch 44.944), train_loss = 3.19889856, grad/param norm = 1.1917e+00, time/batch = 0.1535s	
2428/2700 (epoch 44.963), train_loss = 3.26570835, grad/param norm = 1.1014e+00, time/batch = 0.1593s	
2429/2700 (epoch 44.981), train_loss = 3.31883181, grad/param norm = 1.0975e+00, time/batch = 0.1760s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
2430/2700 (epoch 45.000), train_loss = 3.22938394, grad/param norm = 1.0534e+00, time/batch = 0.1761s	
2431/2700 (epoch 45.019), train_loss = 3.17110475, grad/param norm = 1.2120e+00, time/batch = 0.1522s	
2432/2700 (epoch 45.037), train_loss = 3.17682186, grad/param norm = 9.7889e-01, time/batch = 0.1714s	
2433/2700 (epoch 45.056), train_loss = 3.15724797, grad/param norm = 1.0013e+00, time/batch = 0.1622s	
2434/2700 (epoch 45.074), train_loss = 3.22122025, grad/param norm = 1.9774e+00, time/batch = 0.1538s	
2435/2700 (epoch 45.093), train_loss = 3.25420336, grad/param norm = 2.1612e+00, time/batch = 0.1618s	
2436/2700 (epoch 45.111), train_loss = 3.19421687, grad/param norm = 1.4233e+00, time/batch = 0.1707s	
2437/2700 (epoch 45.130), train_loss = 3.20229044, grad/param norm = 1.0178e+00, time/batch = 0.1816s	
2438/2700 (epoch 45.148), train_loss = 3.14279084, grad/param norm = 1.2282e+00, time/batch = 0.1786s	
2439/2700 (epoch 45.167), train_loss = 3.18572752, grad/param norm = 1.8088e+00, time/batch = 0.1854s	
2440/2700 (epoch 45.185), train_loss = 3.17336210, grad/param norm = 1.5198e+00, time/batch = 0.1857s	
2441/2700 (epoch 45.204), train_loss = 3.11455930, grad/param norm = 1.5088e+00, time/batch = 0.1761s	
2442/2700 (epoch 45.222), train_loss = 3.06476551, grad/param norm = 1.4273e+00, time/batch = 0.1796s	
2443/2700 (epoch 45.241), train_loss = 3.08611382, grad/param norm = 1.4395e+00, time/batch = 0.1877s	
2444/2700 (epoch 45.259), train_loss = 3.12991857, grad/param norm = 1.6197e+00, time/batch = 0.1873s	
2445/2700 (epoch 45.278), train_loss = 3.20905758, grad/param norm = 1.5291e+00, time/batch = 0.1873s	
2446/2700 (epoch 45.296), train_loss = 3.18711333, grad/param norm = 1.2917e+00, time/batch = 0.1863s	
2447/2700 (epoch 45.315), train_loss = 3.17388526, grad/param norm = 1.3113e+00, time/batch = 0.1867s	
2448/2700 (epoch 45.333), train_loss = 3.22918112, grad/param norm = 1.3472e+00, time/batch = 0.1799s	
2449/2700 (epoch 45.352), train_loss = 3.25346210, grad/param norm = 1.6736e+00, time/batch = 0.1727s	
2450/2700 (epoch 45.370), train_loss = 3.17702612, grad/param norm = 1.6057e+00, time/batch = 0.1616s	
2451/2700 (epoch 45.389), train_loss = 3.14484996, grad/param norm = 1.4144e+00, time/batch = 0.1891s	
2452/2700 (epoch 45.407), train_loss = 3.17147912, grad/param norm = 1.3472e+00, time/batch = 0.1824s	
2453/2700 (epoch 45.426), train_loss = 3.18330353, grad/param norm = 1.3801e+00, time/batch = 0.1594s	
2454/2700 (epoch 45.444), train_loss = 3.09839482, grad/param norm = 1.7249e+00, time/batch = 0.1548s	
2455/2700 (epoch 45.463), train_loss = 3.15399010, grad/param norm = 2.0867e+00, time/batch = 0.1641s	
2456/2700 (epoch 45.481), train_loss = 3.24446651, grad/param norm = 2.0075e+00, time/batch = 0.1740s	
2457/2700 (epoch 45.500), train_loss = 3.29160139, grad/param norm = 2.0568e+00, time/batch = 0.1875s	
2458/2700 (epoch 45.519), train_loss = 3.23618720, grad/param norm = 1.8556e+00, time/batch = 0.1773s	
2459/2700 (epoch 45.537), train_loss = 3.22458922, grad/param norm = 1.4714e+00, time/batch = 0.1861s	
2460/2700 (epoch 45.556), train_loss = 3.17840353, grad/param norm = 1.3073e+00, time/batch = 0.1850s	
2461/2700 (epoch 45.574), train_loss = 3.13203878, grad/param norm = 1.3275e+00, time/batch = 0.1787s	
2462/2700 (epoch 45.593), train_loss = 3.15253335, grad/param norm = 1.5819e+00, time/batch = 0.1875s	
2463/2700 (epoch 45.611), train_loss = 3.13811421, grad/param norm = 2.0834e+00, time/batch = 0.1765s	
2464/2700 (epoch 45.630), train_loss = 3.17102991, grad/param norm = 2.2556e+00, time/batch = 0.1873s	
2465/2700 (epoch 45.648), train_loss = 3.20401702, grad/param norm = 1.4023e+00, time/batch = 0.1875s	
2466/2700 (epoch 45.667), train_loss = 3.11013860, grad/param norm = 1.1984e+00, time/batch = 0.1889s	
2467/2700 (epoch 45.685), train_loss = 3.09244660, grad/param norm = 1.1824e+00, time/batch = 0.1783s	
2468/2700 (epoch 45.704), train_loss = 3.05192127, grad/param norm = 1.2363e+00, time/batch = 0.1605s	
2469/2700 (epoch 45.722), train_loss = 3.05041729, grad/param norm = 1.0716e+00, time/batch = 0.1568s	
2470/2700 (epoch 45.741), train_loss = 3.19678279, grad/param norm = 1.3568e+00, time/batch = 0.1524s	
2471/2700 (epoch 45.759), train_loss = 3.14305324, grad/param norm = 1.7287e+00, time/batch = 0.1536s	
2472/2700 (epoch 45.778), train_loss = 3.15007785, grad/param norm = 1.7530e+00, time/batch = 0.1588s	
2473/2700 (epoch 45.796), train_loss = 3.15711416, grad/param norm = 1.6800e+00, time/batch = 0.1691s	
2474/2700 (epoch 45.815), train_loss = 3.08595059, grad/param norm = 1.3899e+00, time/batch = 0.1638s	
2475/2700 (epoch 45.833), train_loss = 3.11951687, grad/param norm = 1.4475e+00, time/batch = 0.1887s	
2476/2700 (epoch 45.852), train_loss = 3.11925633, grad/param norm = 1.3262e+00, time/batch = 0.1894s	
2477/2700 (epoch 45.870), train_loss = 3.08328295, grad/param norm = 1.0631e+00, time/batch = 0.1862s	
2478/2700 (epoch 45.889), train_loss = 3.12438615, grad/param norm = 1.1668e+00, time/batch = 0.1714s	
2479/2700 (epoch 45.907), train_loss = 3.19780330, grad/param norm = 1.4024e+00, time/batch = 0.1462s	
2480/2700 (epoch 45.926), train_loss = 3.15386884, grad/param norm = 1.5631e+00, time/batch = 0.1331s	
2481/2700 (epoch 45.944), train_loss = 3.15574656, grad/param norm = 1.5628e+00, time/batch = 0.1820s	
2482/2700 (epoch 45.963), train_loss = 3.24821496, grad/param norm = 1.8717e+00, time/batch = 0.1666s	
2483/2700 (epoch 45.981), train_loss = 3.30259055, grad/param norm = 1.9580e+00, time/batch = 0.1583s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
2484/2700 (epoch 46.000), train_loss = 3.22554449, grad/param norm = 1.7723e+00, time/batch = 0.1552s	
2485/2700 (epoch 46.019), train_loss = 3.13848518, grad/param norm = 1.5983e+00, time/batch = 0.1449s	
2486/2700 (epoch 46.037), train_loss = 3.15413279, grad/param norm = 1.8254e+00, time/batch = 0.1868s	
2487/2700 (epoch 46.056), train_loss = 3.15870591, grad/param norm = 2.4027e+00, time/batch = 0.1877s	
2488/2700 (epoch 46.074), train_loss = 3.20895463, grad/param norm = 2.5268e+00, time/batch = 0.1887s	
2489/2700 (epoch 46.093), train_loss = 3.19934270, grad/param norm = 1.9449e+00, time/batch = 0.1624s	
2490/2700 (epoch 46.111), train_loss = 3.16443674, grad/param norm = 1.6267e+00, time/batch = 0.1474s	
2491/2700 (epoch 46.130), train_loss = 3.17640648, grad/param norm = 1.4689e+00, time/batch = 0.1888s	
2492/2700 (epoch 46.148), train_loss = 3.09391413, grad/param norm = 9.8152e-01, time/batch = 0.1870s	
2493/2700 (epoch 46.167), train_loss = 3.10713625, grad/param norm = 9.6075e-01, time/batch = 0.1873s	
2494/2700 (epoch 46.185), train_loss = 3.07628416, grad/param norm = 6.9547e-01, time/batch = 0.1864s	
2495/2700 (epoch 46.204), train_loss = 3.02038596, grad/param norm = 7.6280e-01, time/batch = 0.1799s	
2496/2700 (epoch 46.222), train_loss = 2.97871732, grad/param norm = 1.0627e+00, time/batch = 0.1428s	
2497/2700 (epoch 46.241), train_loss = 3.00705382, grad/param norm = 1.1147e+00, time/batch = 0.1804s	
2498/2700 (epoch 46.259), train_loss = 3.04091315, grad/param norm = 1.0801e+00, time/batch = 0.1803s	
2499/2700 (epoch 46.278), train_loss = 3.14240318, grad/param norm = 1.3025e+00, time/batch = 0.1765s	
2500/2700 (epoch 46.296), train_loss = 3.14747886, grad/param norm = 1.6665e+00, time/batch = 0.1696s	
2501/2700 (epoch 46.315), train_loss = 3.15820346, grad/param norm = 1.8765e+00, time/batch = 0.1799s	
2502/2700 (epoch 46.333), train_loss = 3.19490973, grad/param norm = 1.5841e+00, time/batch = 0.1855s	
2503/2700 (epoch 46.352), train_loss = 3.23429325, grad/param norm = 1.6674e+00, time/batch = 0.1856s	
2504/2700 (epoch 46.370), train_loss = 3.13586777, grad/param norm = 1.3817e+00, time/batch = 0.1855s	
2505/2700 (epoch 46.389), train_loss = 3.09257690, grad/param norm = 1.1096e+00, time/batch = 0.1861s	
2506/2700 (epoch 46.407), train_loss = 3.11013482, grad/param norm = 9.7849e-01, time/batch = 0.1798s	
2507/2700 (epoch 46.426), train_loss = 3.12093888, grad/param norm = 1.0343e+00, time/batch = 0.1675s	
2508/2700 (epoch 46.444), train_loss = 3.01251616, grad/param norm = 1.0505e+00, time/batch = 0.1555s	
2509/2700 (epoch 46.463), train_loss = 3.08161365, grad/param norm = 1.3658e+00, time/batch = 0.1489s	
2510/2700 (epoch 46.481), train_loss = 3.17777606, grad/param norm = 1.8639e+00, time/batch = 0.1521s	
2511/2700 (epoch 46.500), train_loss = 3.29629834, grad/param norm = 2.7595e+00, time/batch = 0.1565s	
2512/2700 (epoch 46.519), train_loss = 3.23449881, grad/param norm = 2.7529e+00, time/batch = 0.1670s	
2513/2700 (epoch 46.537), train_loss = 3.19147368, grad/param norm = 1.9744e+00, time/batch = 0.1766s	
2514/2700 (epoch 46.556), train_loss = 3.11194160, grad/param norm = 1.5933e+00, time/batch = 0.1840s	
2515/2700 (epoch 46.574), train_loss = 3.06019960, grad/param norm = 1.3370e+00, time/batch = 0.1778s	
2516/2700 (epoch 46.593), train_loss = 3.06470106, grad/param norm = 1.5434e+00, time/batch = 0.1730s	
2517/2700 (epoch 46.611), train_loss = 3.00881208, grad/param norm = 1.8270e+00, time/batch = 0.1567s	
2518/2700 (epoch 46.630), train_loss = 3.06319768, grad/param norm = 2.2011e+00, time/batch = 0.1545s	
2519/2700 (epoch 46.648), train_loss = 3.15731000, grad/param norm = 2.1484e+00, time/batch = 0.1256s	
2520/2700 (epoch 46.667), train_loss = 3.06340878, grad/param norm = 1.8126e+00, time/batch = 0.1551s	
2521/2700 (epoch 46.685), train_loss = 3.06386773, grad/param norm = 1.7457e+00, time/batch = 0.1544s	
2522/2700 (epoch 46.704), train_loss = 3.04404834, grad/param norm = 1.8762e+00, time/batch = 0.1505s	
2523/2700 (epoch 46.722), train_loss = 3.02332211, grad/param norm = 1.5708e+00, time/batch = 0.1518s	
2524/2700 (epoch 46.741), train_loss = 3.17562701, grad/param norm = 2.0657e+00, time/batch = 0.1647s	
2525/2700 (epoch 46.759), train_loss = 3.09833879, grad/param norm = 1.9786e+00, time/batch = 0.1772s	
2526/2700 (epoch 46.778), train_loss = 3.09191513, grad/param norm = 1.7384e+00, time/batch = 0.1870s	
2527/2700 (epoch 46.796), train_loss = 3.08019121, grad/param norm = 1.5063e+00, time/batch = 0.1869s	
2528/2700 (epoch 46.815), train_loss = 3.00534636, grad/param norm = 1.3649e+00, time/batch = 0.1719s	
2529/2700 (epoch 46.833), train_loss = 3.03922328, grad/param norm = 1.3896e+00, time/batch = 0.1578s	
2530/2700 (epoch 46.852), train_loss = 3.04652633, grad/param norm = 1.2731e+00, time/batch = 0.1594s	
2531/2700 (epoch 46.870), train_loss = 3.01006032, grad/param norm = 1.2655e+00, time/batch = 0.1889s	
2532/2700 (epoch 46.889), train_loss = 3.06756519, grad/param norm = 1.4759e+00, time/batch = 0.1892s	
2533/2700 (epoch 46.907), train_loss = 3.15355035, grad/param norm = 1.6496e+00, time/batch = 0.1883s	
2534/2700 (epoch 46.926), train_loss = 3.09623614, grad/param norm = 1.4649e+00, time/batch = 0.1858s	
2535/2700 (epoch 46.944), train_loss = 3.08281352, grad/param norm = 1.3019e+00, time/batch = 0.1713s	
2536/2700 (epoch 46.963), train_loss = 3.16865485, grad/param norm = 1.5316e+00, time/batch = 0.1616s	
2537/2700 (epoch 46.981), train_loss = 3.21673800, grad/param norm = 1.5122e+00, time/batch = 0.1534s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
2538/2700 (epoch 47.000), train_loss = 3.11965324, grad/param norm = 1.3666e+00, time/batch = 0.1616s	
2539/2700 (epoch 47.019), train_loss = 3.09514871, grad/param norm = 2.0834e+00, time/batch = 0.1518s	
2540/2700 (epoch 47.037), train_loss = 3.13184313, grad/param norm = 2.6519e+00, time/batch = 0.1856s	
2541/2700 (epoch 47.056), train_loss = 3.10364111, grad/param norm = 2.6626e+00, time/batch = 0.1754s	
2542/2700 (epoch 47.074), train_loss = 3.15251826, grad/param norm = 2.6565e+00, time/batch = 0.1861s	
2543/2700 (epoch 47.093), train_loss = 3.14164706, grad/param norm = 2.1118e+00, time/batch = 0.1865s	
2544/2700 (epoch 47.111), train_loss = 3.05749274, grad/param norm = 1.2007e+00, time/batch = 0.1864s	
2545/2700 (epoch 47.130), train_loss = 3.06062369, grad/param norm = 9.9835e-01, time/batch = 0.1879s	
2546/2700 (epoch 47.148), train_loss = 2.99926818, grad/param norm = 1.0661e+00, time/batch = 0.1868s	
2547/2700 (epoch 47.167), train_loss = 3.03315238, grad/param norm = 1.5442e+00, time/batch = 0.1876s	
2548/2700 (epoch 47.185), train_loss = 3.02243918, grad/param norm = 1.7680e+00, time/batch = 0.1867s	
2549/2700 (epoch 47.204), train_loss = 3.00176318, grad/param norm = 2.2265e+00, time/batch = 0.1829s	
2550/2700 (epoch 47.222), train_loss = 2.96232337, grad/param norm = 2.4737e+00, time/batch = 0.1585s	
2551/2700 (epoch 47.241), train_loss = 2.94005735, grad/param norm = 1.9531e+00, time/batch = 0.1889s	
2552/2700 (epoch 47.259), train_loss = 2.99453195, grad/param norm = 2.6435e+00, time/batch = 0.1867s	
2553/2700 (epoch 47.278), train_loss = 3.12851310, grad/param norm = 2.6168e+00, time/batch = 0.1794s	
2554/2700 (epoch 47.296), train_loss = 3.12216635, grad/param norm = 2.2490e+00, time/batch = 0.1673s	
2555/2700 (epoch 47.315), train_loss = 3.12706062, grad/param norm = 2.2919e+00, time/batch = 0.1583s	
2556/2700 (epoch 47.333), train_loss = 3.16801538, grad/param norm = 1.8906e+00, time/batch = 0.1569s	
2557/2700 (epoch 47.352), train_loss = 3.16911115, grad/param norm = 1.6268e+00, time/batch = 0.1619s	
2558/2700 (epoch 47.370), train_loss = 3.04717710, grad/param norm = 1.4416e+00, time/batch = 0.1724s	
2559/2700 (epoch 47.389), train_loss = 3.00128421, grad/param norm = 1.2140e+00, time/batch = 0.1726s	
2560/2700 (epoch 47.407), train_loss = 3.02386902, grad/param norm = 1.1773e+00, time/batch = 0.1718s	
2561/2700 (epoch 47.426), train_loss = 3.04319385, grad/param norm = 1.2220e+00, time/batch = 0.1874s	
2562/2700 (epoch 47.444), train_loss = 2.93921040, grad/param norm = 1.3756e+00, time/batch = 0.1897s	
2563/2700 (epoch 47.463), train_loss = 2.99503042, grad/param norm = 1.4680e+00, time/batch = 0.1893s	
2564/2700 (epoch 47.481), train_loss = 3.07021230, grad/param norm = 1.4912e+00, time/batch = 0.1882s	
2565/2700 (epoch 47.500), train_loss = 3.13204505, grad/param norm = 1.5847e+00, time/batch = 0.1872s	
2566/2700 (epoch 47.519), train_loss = 3.08434641, grad/param norm = 1.6013e+00, time/batch = 0.1880s	
2567/2700 (epoch 47.537), train_loss = 3.11185541, grad/param norm = 1.8640e+00, time/batch = 0.1873s	
2568/2700 (epoch 47.556), train_loss = 3.07576469, grad/param norm = 1.8011e+00, time/batch = 0.1875s	
2569/2700 (epoch 47.574), train_loss = 3.03832507, grad/param norm = 1.8183e+00, time/batch = 0.1747s	
2570/2700 (epoch 47.593), train_loss = 2.99542871, grad/param norm = 1.5415e+00, time/batch = 0.1676s	
2571/2700 (epoch 47.611), train_loss = 2.93975259, grad/param norm = 1.3291e+00, time/batch = 0.1477s	
2572/2700 (epoch 47.630), train_loss = 2.94140461, grad/param norm = 1.4120e+00, time/batch = 0.1508s	
2573/2700 (epoch 47.648), train_loss = 3.04641186, grad/param norm = 1.4684e+00, time/batch = 0.1636s	
2574/2700 (epoch 47.667), train_loss = 2.96399365, grad/param norm = 1.7305e+00, time/batch = 0.1749s	
2575/2700 (epoch 47.685), train_loss = 2.95303733, grad/param norm = 1.5340e+00, time/batch = 0.1886s	
2576/2700 (epoch 47.704), train_loss = 2.93103813, grad/param norm = 2.0247e+00, time/batch = 0.1870s	
2577/2700 (epoch 47.722), train_loss = 2.97005634, grad/param norm = 2.5623e+00, time/batch = 0.1872s	
2578/2700 (epoch 47.741), train_loss = 3.19039065, grad/param norm = 2.9721e+00, time/batch = 0.1860s	
2579/2700 (epoch 47.759), train_loss = 3.07973423, grad/param norm = 2.7424e+00, time/batch = 0.1815s	
2580/2700 (epoch 47.778), train_loss = 3.03655688, grad/param norm = 2.1321e+00, time/batch = 0.1856s	
2581/2700 (epoch 47.796), train_loss = 3.05248801, grad/param norm = 2.2199e+00, time/batch = 0.1602s	
2582/2700 (epoch 47.815), train_loss = 2.98284348, grad/param norm = 1.7389e+00, time/batch = 0.1600s	
2583/2700 (epoch 47.833), train_loss = 2.97449190, grad/param norm = 1.4320e+00, time/batch = 0.1538s	
2584/2700 (epoch 47.852), train_loss = 2.95263051, grad/param norm = 1.2656e+00, time/batch = 0.1537s	
2585/2700 (epoch 47.870), train_loss = 2.92312460, grad/param norm = 1.2163e+00, time/batch = 0.1662s	
2586/2700 (epoch 47.889), train_loss = 2.96845752, grad/param norm = 1.4114e+00, time/batch = 0.1737s	
2587/2700 (epoch 47.907), train_loss = 3.04010959, grad/param norm = 1.5321e+00, time/batch = 0.1860s	
2588/2700 (epoch 47.926), train_loss = 2.99049754, grad/param norm = 1.6240e+00, time/batch = 0.1872s	
2589/2700 (epoch 47.944), train_loss = 3.01021859, grad/param norm = 1.6151e+00, time/batch = 0.1824s	
2590/2700 (epoch 47.963), train_loss = 3.09276745, grad/param norm = 1.9603e+00, time/batch = 0.1871s	
2591/2700 (epoch 47.981), train_loss = 3.17862520, grad/param norm = 2.6163e+00, time/batch = 0.1752s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
2592/2700 (epoch 48.000), train_loss = 3.12440120, grad/param norm = 2.7698e+00, time/batch = 0.1566s	
2593/2700 (epoch 48.019), train_loss = 3.03422868, grad/param norm = 2.3880e+00, time/batch = 0.1634s	
2594/2700 (epoch 48.037), train_loss = 2.98810449, grad/param norm = 1.3166e+00, time/batch = 0.1578s	
2595/2700 (epoch 48.056), train_loss = 2.93006905, grad/param norm = 8.8837e-01, time/batch = 0.1514s	
2596/2700 (epoch 48.074), train_loss = 2.99070000, grad/param norm = 1.1381e+00, time/batch = 0.1496s	
2597/2700 (epoch 48.093), train_loss = 3.00722876, grad/param norm = 1.5411e+00, time/batch = 0.1686s	
2598/2700 (epoch 48.111), train_loss = 2.99042106, grad/param norm = 1.9817e+00, time/batch = 0.1870s	
2599/2700 (epoch 48.130), train_loss = 3.03759440, grad/param norm = 2.1356e+00, time/batch = 0.1785s	
2600/2700 (epoch 48.148), train_loss = 2.97108735, grad/param norm = 2.3553e+00, time/batch = 0.1877s	
2601/2700 (epoch 48.167), train_loss = 3.04646660, grad/param norm = 2.8382e+00, time/batch = 0.1730s	
2602/2700 (epoch 48.185), train_loss = 3.00936870, grad/param norm = 2.7012e+00, time/batch = 0.1749s	
2603/2700 (epoch 48.204), train_loss = 2.91431766, grad/param norm = 2.3083e+00, time/batch = 0.1665s	
2604/2700 (epoch 48.222), train_loss = 2.82278576, grad/param norm = 1.6616e+00, time/batch = 0.1606s	
2605/2700 (epoch 48.241), train_loss = 2.82635703, grad/param norm = 1.4515e+00, time/batch = 0.1479s	
2606/2700 (epoch 48.259), train_loss = 2.87753190, grad/param norm = 1.5429e+00, time/batch = 0.1513s	
2607/2700 (epoch 48.278), train_loss = 3.00519485, grad/param norm = 1.8007e+00, time/batch = 0.1629s	
2608/2700 (epoch 48.296), train_loss = 2.98835150, grad/param norm = 1.7631e+00, time/batch = 0.1739s	
2609/2700 (epoch 48.315), train_loss = 2.96583351, grad/param norm = 1.3671e+00, time/batch = 0.1736s	
2610/2700 (epoch 48.333), train_loss = 2.97480247, grad/param norm = 9.7665e-01, time/batch = 0.1751s	
2611/2700 (epoch 48.352), train_loss = 2.99933880, grad/param norm = 1.0921e+00, time/batch = 0.1695s	
2612/2700 (epoch 48.370), train_loss = 2.93384088, grad/param norm = 1.4547e+00, time/batch = 0.1819s	
2613/2700 (epoch 48.389), train_loss = 2.91205148, grad/param norm = 1.8590e+00, time/batch = 0.1868s	
2614/2700 (epoch 48.407), train_loss = 2.97240036, grad/param norm = 2.2441e+00, time/batch = 0.1757s	
2615/2700 (epoch 48.426), train_loss = 2.99231289, grad/param norm = 2.0126e+00, time/batch = 0.1828s	
2616/2700 (epoch 48.444), train_loss = 2.89838551, grad/param norm = 2.1497e+00, time/batch = 0.1772s	
2617/2700 (epoch 48.463), train_loss = 2.92497699, grad/param norm = 2.0186e+00, time/batch = 0.1722s	
2618/2700 (epoch 48.481), train_loss = 3.00191431, grad/param norm = 2.1086e+00, time/batch = 0.1566s	
2619/2700 (epoch 48.500), train_loss = 3.08859613, grad/param norm = 2.7751e+00, time/batch = 0.1419s	
2620/2700 (epoch 48.519), train_loss = 3.10356306, grad/param norm = 3.0464e+00, time/batch = 0.1041s	
2621/2700 (epoch 48.537), train_loss = 3.08648762, grad/param norm = 2.2945e+00, time/batch = 0.1819s	
2622/2700 (epoch 48.556), train_loss = 2.99179009, grad/param norm = 2.1978e+00, time/batch = 0.1689s	
2623/2700 (epoch 48.574), train_loss = 2.92701519, grad/param norm = 1.7836e+00, time/batch = 0.1580s	
2624/2700 (epoch 48.593), train_loss = 2.88614610, grad/param norm = 1.7214e+00, time/batch = 0.1489s	
2625/2700 (epoch 48.611), train_loss = 2.81925303, grad/param norm = 1.3241e+00, time/batch = 0.1471s	
2626/2700 (epoch 48.630), train_loss = 2.83489653, grad/param norm = 1.3612e+00, time/batch = 0.1887s	
2627/2700 (epoch 48.648), train_loss = 2.92794057, grad/param norm = 1.6585e+00, time/batch = 0.1891s	
2628/2700 (epoch 48.667), train_loss = 2.89953429, grad/param norm = 2.3405e+00, time/batch = 0.1888s	
2629/2700 (epoch 48.685), train_loss = 2.95267402, grad/param norm = 2.9256e+00, time/batch = 0.1880s	
2630/2700 (epoch 48.704), train_loss = 2.98277132, grad/param norm = 3.2215e+00, time/batch = 0.1766s	
2631/2700 (epoch 48.722), train_loss = 2.86681554, grad/param norm = 2.3882e+00, time/batch = 0.1855s	
2632/2700 (epoch 48.741), train_loss = 2.98785567, grad/param norm = 1.9502e+00, time/batch = 0.1859s	
2633/2700 (epoch 48.759), train_loss = 2.89668684, grad/param norm = 1.4735e+00, time/batch = 0.1874s	
2634/2700 (epoch 48.778), train_loss = 2.88069975, grad/param norm = 1.3557e+00, time/batch = 0.1894s	
2635/2700 (epoch 48.796), train_loss = 2.88235250, grad/param norm = 1.3609e+00, time/batch = 0.1784s	
2636/2700 (epoch 48.815), train_loss = 2.82830684, grad/param norm = 1.2180e+00, time/batch = 0.1817s	
2637/2700 (epoch 48.833), train_loss = 2.85668762, grad/param norm = 1.5397e+00, time/batch = 0.1686s	
2638/2700 (epoch 48.852), train_loss = 2.89279524, grad/param norm = 2.1218e+00, time/batch = 0.1547s	
2639/2700 (epoch 48.870), train_loss = 2.88471038, grad/param norm = 2.1503e+00, time/batch = 0.1507s	
2640/2700 (epoch 48.889), train_loss = 2.91309125, grad/param norm = 2.1841e+00, time/batch = 0.1576s	
2641/2700 (epoch 48.907), train_loss = 2.99502368, grad/param norm = 1.9314e+00, time/batch = 0.1495s	
2642/2700 (epoch 48.926), train_loss = 2.90086407, grad/param norm = 1.4821e+00, time/batch = 0.1584s	
2643/2700 (epoch 48.944), train_loss = 2.90473677, grad/param norm = 1.1751e+00, time/batch = 0.1649s	
2644/2700 (epoch 48.963), train_loss = 2.96811757, grad/param norm = 1.2600e+00, time/batch = 0.1747s	
2645/2700 (epoch 48.981), train_loss = 3.04812992, grad/param norm = 2.0316e+00, time/batch = 0.1750s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
2646/2700 (epoch 49.000), train_loss = 3.06244821, grad/param norm = 2.5717e+00, time/batch = 0.1626s	
2647/2700 (epoch 49.019), train_loss = 2.95433293, grad/param norm = 2.2279e+00, time/batch = 0.1675s	
2648/2700 (epoch 49.037), train_loss = 2.95329455, grad/param norm = 2.7044e+00, time/batch = 0.1628s	
2649/2700 (epoch 49.056), train_loss = 2.94289042, grad/param norm = 2.6074e+00, time/batch = 0.1548s	
2650/2700 (epoch 49.074), train_loss = 2.94610056, grad/param norm = 2.4076e+00, time/batch = 0.1456s	
2651/2700 (epoch 49.093), train_loss = 2.94346763, grad/param norm = 2.1614e+00, time/batch = 0.1574s	
2652/2700 (epoch 49.111), train_loss = 2.91069591, grad/param norm = 1.9056e+00, time/batch = 0.1562s	
2653/2700 (epoch 49.130), train_loss = 2.93394741, grad/param norm = 1.9478e+00, time/batch = 0.1344s	
2654/2700 (epoch 49.148), train_loss = 2.86819599, grad/param norm = 2.0044e+00, time/batch = 0.1121s	
2655/2700 (epoch 49.167), train_loss = 2.89937344, grad/param norm = 2.0724e+00, time/batch = 0.0977s	
2656/2700 (epoch 49.185), train_loss = 2.84117020, grad/param norm = 1.5194e+00, time/batch = 0.0844s	
2657/2700 (epoch 49.204), train_loss = 2.78348749, grad/param norm = 1.5043e+00, time/batch = 0.0532s	
2658/2700 (epoch 49.222), train_loss = 2.74897320, grad/param norm = 1.7179e+00, time/batch = 0.1078s	
2659/2700 (epoch 49.241), train_loss = 2.75405695, grad/param norm = 1.6311e+00, time/batch = 0.0949s	
2660/2700 (epoch 49.259), train_loss = 2.79830282, grad/param norm = 1.6438e+00, time/batch = 0.0818s	
2661/2700 (epoch 49.278), train_loss = 2.92442771, grad/param norm = 1.7857e+00, time/batch = 0.1170s	
2662/2700 (epoch 49.296), train_loss = 2.86830028, grad/param norm = 1.3493e+00, time/batch = 0.1074s	
2663/2700 (epoch 49.315), train_loss = 2.83800236, grad/param norm = 9.0380e-01, time/batch = 0.0948s	
2664/2700 (epoch 49.333), train_loss = 2.85557483, grad/param norm = 9.1572e-01, time/batch = 0.0803s	
2665/2700 (epoch 49.352), train_loss = 2.92576312, grad/param norm = 1.5663e+00, time/batch = 0.0883s	
2666/2700 (epoch 49.370), train_loss = 2.88269304, grad/param norm = 2.3104e+00, time/batch = 0.1004s	
2667/2700 (epoch 49.389), train_loss = 2.85095247, grad/param norm = 2.3343e+00, time/batch = 0.1141s	
2668/2700 (epoch 49.407), train_loss = 2.89409244, grad/param norm = 2.4816e+00, time/batch = 0.0951s	
2669/2700 (epoch 49.426), train_loss = 2.93883999, grad/param norm = 2.5684e+00, time/batch = 0.0999s	
2670/2700 (epoch 49.444), train_loss = 2.82843746, grad/param norm = 2.6661e+00, time/batch = 0.0874s	
2671/2700 (epoch 49.463), train_loss = 2.91369126, grad/param norm = 2.2905e+00, time/batch = 0.1155s	
2672/2700 (epoch 49.481), train_loss = 2.90777288, grad/param norm = 1.7284e+00, time/batch = 0.1157s	
2673/2700 (epoch 49.500), train_loss = 2.97882375, grad/param norm = 2.0183e+00, time/batch = 0.1147s	
2674/2700 (epoch 49.519), train_loss = 2.92066720, grad/param norm = 2.1818e+00, time/batch = 0.1051s	
2675/2700 (epoch 49.537), train_loss = 2.98008743, grad/param norm = 2.7029e+00, time/batch = 0.0921s	
2676/2700 (epoch 49.556), train_loss = 2.93195849, grad/param norm = 2.7900e+00, time/batch = 0.0776s	
2677/2700 (epoch 49.574), train_loss = 2.88002184, grad/param norm = 2.4245e+00, time/batch = 0.0902s	
2678/2700 (epoch 49.593), train_loss = 2.85931393, grad/param norm = 2.0104e+00, time/batch = 0.1039s	
2679/2700 (epoch 49.611), train_loss = 2.74753618, grad/param norm = 1.5329e+00, time/batch = 0.0930s	
2680/2700 (epoch 49.630), train_loss = 2.75299020, grad/param norm = 1.3273e+00, time/batch = 0.1026s	
2681/2700 (epoch 49.648), train_loss = 2.80860990, grad/param norm = 1.3765e+00, time/batch = 0.1167s	
2682/2700 (epoch 49.667), train_loss = 2.75648934, grad/param norm = 1.4401e+00, time/batch = 0.1151s	
2683/2700 (epoch 49.685), train_loss = 2.75996255, grad/param norm = 1.6023e+00, time/batch = 0.1149s	
2684/2700 (epoch 49.704), train_loss = 2.73222149, grad/param norm = 1.7362e+00, time/batch = 0.1152s	
2685/2700 (epoch 49.722), train_loss = 2.73960690, grad/param norm = 1.5826e+00, time/batch = 0.1164s	
2686/2700 (epoch 49.741), train_loss = 2.90518778, grad/param norm = 1.6923e+00, time/batch = 0.1111s	
2687/2700 (epoch 49.759), train_loss = 2.88569583, grad/param norm = 2.1802e+00, time/batch = 0.0988s	
2688/2700 (epoch 49.778), train_loss = 2.89626833, grad/param norm = 2.5728e+00, time/batch = 0.0876s	
2689/2700 (epoch 49.796), train_loss = 2.86349166, grad/param norm = 2.1784e+00, time/batch = 0.0819s	
2690/2700 (epoch 49.815), train_loss = 2.78810411, grad/param norm = 1.9299e+00, time/batch = 0.0634s	
2691/2700 (epoch 49.833), train_loss = 2.81618285, grad/param norm = 2.3076e+00, time/batch = 0.1152s	
2692/2700 (epoch 49.852), train_loss = 2.81447440, grad/param norm = 2.4261e+00, time/batch = 0.1157s	
2693/2700 (epoch 49.870), train_loss = 2.81792671, grad/param norm = 2.7401e+00, time/batch = 0.1155s	
2694/2700 (epoch 49.889), train_loss = 2.83475244, grad/param norm = 2.3816e+00, time/batch = 0.1149s	
2695/2700 (epoch 49.907), train_loss = 2.92441645, grad/param norm = 2.7516e+00, time/batch = 0.1152s	
2696/2700 (epoch 49.926), train_loss = 2.87264765, grad/param norm = 2.4775e+00, time/batch = 0.1150s	
2697/2700 (epoch 49.944), train_loss = 2.82468086, grad/param norm = 1.5956e+00, time/batch = 0.1100s	
2698/2700 (epoch 49.963), train_loss = 2.88966691, grad/param norm = 1.3427e+00, time/batch = 0.0999s	
2699/2700 (epoch 49.981), train_loss = 2.92496077, grad/param norm = 1.3440e+00, time/batch = 0.0870s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch50.00_2.8093.t7	
2700/2700 (epoch 50.000), train_loss = 2.92717493, grad/param norm = 2.5118e+00, time/batch = 0.0808s	
