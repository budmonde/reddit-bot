using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 54, val: 3, test: 0	
vocab size: 91	
creating an rnn with 4 layers	
number of parameters in the model: 139099	
cloning rnn	
cloning criterion	
1/2700 (epoch 0.019), train_loss = 4.54443194, grad/param norm = 1.4483e+00, time/batch = 0.3418s	
2/2700 (epoch 0.037), train_loss = 4.15793630, grad/param norm = 5.2858e+00, time/batch = 0.1240s	
3/2700 (epoch 0.056), train_loss = 3.46186572, grad/param norm = 2.3721e+00, time/batch = 0.1223s	
4/2700 (epoch 0.074), train_loss = 3.40748803, grad/param norm = 3.0029e+00, time/batch = 0.1224s	
5/2700 (epoch 0.093), train_loss = 3.39460398, grad/param norm = 3.4812e+00, time/batch = 0.1227s	
6/2700 (epoch 0.111), train_loss = 3.34595247, grad/param norm = 3.2462e+00, time/batch = 0.1353s	
7/2700 (epoch 0.130), train_loss = 3.32378545, grad/param norm = 2.1549e+00, time/batch = 0.1249s	
8/2700 (epoch 0.148), train_loss = 3.26340917, grad/param norm = 1.7291e+00, time/batch = 0.1439s	
9/2700 (epoch 0.167), train_loss = 3.26547468, grad/param norm = 1.0718e+00, time/batch = 0.1455s	
10/2700 (epoch 0.185), train_loss = 3.24626705, grad/param norm = 8.9536e-01, time/batch = 0.1425s	
11/2700 (epoch 0.204), train_loss = 3.18420021, grad/param norm = 9.0401e-01, time/batch = 0.1433s	
12/2700 (epoch 0.222), train_loss = 3.15690136, grad/param norm = 1.0917e+00, time/batch = 0.1347s	
13/2700 (epoch 0.241), train_loss = 3.17727124, grad/param norm = 9.2157e-01, time/batch = 0.1402s	
14/2700 (epoch 0.259), train_loss = 3.21081425, grad/param norm = 9.5042e-01, time/batch = 0.1338s	
15/2700 (epoch 0.278), train_loss = 3.28036004, grad/param norm = 9.7800e-01, time/batch = 0.1218s	
16/2700 (epoch 0.296), train_loss = 3.28244399, grad/param norm = 9.7653e-01, time/batch = 0.1143s	
17/2700 (epoch 0.315), train_loss = 3.26255465, grad/param norm = 1.1202e+00, time/batch = 0.1455s	
18/2700 (epoch 0.333), train_loss = 3.34575947, grad/param norm = 1.0913e+00, time/batch = 0.1255s	
19/2700 (epoch 0.352), train_loss = 3.34274934, grad/param norm = 1.0213e+00, time/batch = 0.1268s	
20/2700 (epoch 0.370), train_loss = 3.29295962, grad/param norm = 1.2485e+00, time/batch = 0.1361s	
21/2700 (epoch 0.389), train_loss = 3.26216880, grad/param norm = 1.2498e+00, time/batch = 0.1481s	
22/2700 (epoch 0.407), train_loss = 3.28273115, grad/param norm = 1.2551e+00, time/batch = 0.1246s	
23/2700 (epoch 0.426), train_loss = 3.28555459, grad/param norm = 1.1998e+00, time/batch = 0.1253s	
24/2700 (epoch 0.444), train_loss = 3.21447292, grad/param norm = 1.2773e+00, time/batch = 0.1400s	
25/2700 (epoch 0.463), train_loss = 3.25534503, grad/param norm = 1.3757e+00, time/batch = 0.1259s	
26/2700 (epoch 0.481), train_loss = 3.33104677, grad/param norm = 1.2199e+00, time/batch = 0.1370s	
27/2700 (epoch 0.500), train_loss = 3.37619355, grad/param norm = 1.5058e+00, time/batch = 0.1479s	
28/2700 (epoch 0.519), train_loss = 3.33265654, grad/param norm = 1.4857e+00, time/batch = 0.1445s	
29/2700 (epoch 0.537), train_loss = 3.33171221, grad/param norm = 1.2628e+00, time/batch = 0.1467s	
30/2700 (epoch 0.556), train_loss = 3.26595180, grad/param norm = 8.6546e-01, time/batch = 0.1480s	
31/2700 (epoch 0.574), train_loss = 3.23069858, grad/param norm = 8.6440e-01, time/batch = 0.1211s	
32/2700 (epoch 0.593), train_loss = 3.23500724, grad/param norm = 1.2034e+00, time/batch = 0.1369s	
33/2700 (epoch 0.611), train_loss = 3.96547513, grad/param norm = 3.3593e+01, time/batch = 0.1407s	
34/2700 (epoch 0.630), train_loss = 4.24933136, grad/param norm = 2.2402e+00, time/batch = 0.1373s	
35/2700 (epoch 0.648), train_loss = 3.49069784, grad/param norm = 5.3275e+00, time/batch = 0.1407s	
36/2700 (epoch 0.667), train_loss = 3.25099244, grad/param norm = 1.2262e+00, time/batch = 0.1436s	
37/2700 (epoch 0.685), train_loss = 3.23499434, grad/param norm = 1.1392e+00, time/batch = 0.1450s	
38/2700 (epoch 0.704), train_loss = 3.19768593, grad/param norm = 1.2995e+00, time/batch = 0.1454s	
39/2700 (epoch 0.722), train_loss = 3.18399255, grad/param norm = 9.6691e-01, time/batch = 0.1451s	
40/2700 (epoch 0.741), train_loss = 3.30986894, grad/param norm = 1.0822e+00, time/batch = 0.1493s	
41/2700 (epoch 0.759), train_loss = 3.26791545, grad/param norm = 1.3537e+00, time/batch = 0.1468s	
42/2700 (epoch 0.778), train_loss = 3.26217076, grad/param norm = 1.4216e+00, time/batch = 0.1393s	
43/2700 (epoch 0.796), train_loss = 3.25378628, grad/param norm = 1.5151e+00, time/batch = 0.1373s	
44/2700 (epoch 0.815), train_loss = 3.20205559, grad/param norm = 1.3661e+00, time/batch = 0.1245s	
45/2700 (epoch 0.833), train_loss = 3.24256754, grad/param norm = 1.4413e+00, time/batch = 0.1453s	
46/2700 (epoch 0.852), train_loss = 3.23071048, grad/param norm = 1.3679e+00, time/batch = 0.1404s	
47/2700 (epoch 0.870), train_loss = 3.21915676, grad/param norm = 9.9230e-01, time/batch = 0.1336s	
48/2700 (epoch 0.889), train_loss = 3.25255798, grad/param norm = 9.5764e-01, time/batch = 0.1226s	
49/2700 (epoch 0.907), train_loss = 3.30496082, grad/param norm = 1.1915e+00, time/batch = 0.1310s	
50/2700 (epoch 0.926), train_loss = 3.25762600, grad/param norm = 1.2009e+00, time/batch = 0.1378s	
51/2700 (epoch 0.944), train_loss = 3.26555270, grad/param norm = 1.0172e+00, time/batch = 0.1348s	
52/2700 (epoch 0.963), train_loss = 3.34346120, grad/param norm = 1.0140e+00, time/batch = 0.1393s	
53/2700 (epoch 0.981), train_loss = 3.40734518, grad/param norm = 1.2248e+00, time/batch = 0.1298s	
54/2700 (epoch 1.000), train_loss = 3.31011912, grad/param norm = 1.2579e+00, time/batch = 0.1414s	
55/2700 (epoch 1.019), train_loss = 3.23571406, grad/param norm = 1.2578e+00, time/batch = 0.1345s	
56/2700 (epoch 1.037), train_loss = 3.26143341, grad/param norm = 1.2725e+00, time/batch = 0.1250s	
57/2700 (epoch 1.056), train_loss = 3.26834849, grad/param norm = 1.3770e+00, time/batch = 0.1232s	
58/2700 (epoch 1.074), train_loss = 3.30182326, grad/param norm = 1.7729e+00, time/batch = 0.1269s	
59/2700 (epoch 1.093), train_loss = 3.30549819, grad/param norm = 1.6586e+00, time/batch = 0.1344s	
60/2700 (epoch 1.111), train_loss = 3.27188558, grad/param norm = 1.1783e+00, time/batch = 0.1456s	
61/2700 (epoch 1.130), train_loss = 3.28744013, grad/param norm = 9.5276e-01, time/batch = 0.1359s	
62/2700 (epoch 1.148), train_loss = 3.24745157, grad/param norm = 1.0199e+00, time/batch = 0.1343s	
63/2700 (epoch 1.167), train_loss = 3.25939890, grad/param norm = 1.2356e+00, time/batch = 0.1268s	
64/2700 (epoch 1.185), train_loss = 3.24284818, grad/param norm = 8.7515e-01, time/batch = 0.1378s	
65/2700 (epoch 1.204), train_loss = 3.17765371, grad/param norm = 9.3913e-01, time/batch = 0.1465s	
66/2700 (epoch 1.222), train_loss = 3.15555480, grad/param norm = 1.3139e+00, time/batch = 0.1445s	
67/2700 (epoch 1.241), train_loss = 3.17345035, grad/param norm = 9.6521e-01, time/batch = 0.1480s	
68/2700 (epoch 1.259), train_loss = 3.20520792, grad/param norm = 8.1155e-01, time/batch = 0.1459s	
69/2700 (epoch 1.278), train_loss = 3.27792268, grad/param norm = 9.2846e-01, time/batch = 0.1434s	
70/2700 (epoch 1.296), train_loss = 3.28364616, grad/param norm = 1.1270e+00, time/batch = 0.1343s	
71/2700 (epoch 1.315), train_loss = 3.26153326, grad/param norm = 1.1805e+00, time/batch = 0.1489s	
72/2700 (epoch 1.333), train_loss = 3.34283216, grad/param norm = 1.2056e+00, time/batch = 0.1459s	
73/2700 (epoch 1.352), train_loss = 3.34791165, grad/param norm = 1.2586e+00, time/batch = 0.1469s	
74/2700 (epoch 1.370), train_loss = 3.29048979, grad/param norm = 1.1208e+00, time/batch = 0.1454s	
75/2700 (epoch 1.389), train_loss = 3.25402677, grad/param norm = 8.2287e-01, time/batch = 0.1433s	
76/2700 (epoch 1.407), train_loss = 3.27763850, grad/param norm = 7.8895e-01, time/batch = 0.1220s	
77/2700 (epoch 1.426), train_loss = 3.28150704, grad/param norm = 8.8982e-01, time/batch = 0.1207s	
78/2700 (epoch 1.444), train_loss = 3.20985934, grad/param norm = 8.9512e-01, time/batch = 0.1134s	
79/2700 (epoch 1.463), train_loss = 3.25264937, grad/param norm = 1.0863e+00, time/batch = 0.1436s	
80/2700 (epoch 1.481), train_loss = 3.33035920, grad/param norm = 1.1956e+00, time/batch = 0.1252s	
81/2700 (epoch 1.500), train_loss = 3.37810765, grad/param norm = 1.8668e+00, time/batch = 0.1491s	
82/2700 (epoch 1.519), train_loss = 3.33808038, grad/param norm = 1.9112e+00, time/batch = 0.1268s	
83/2700 (epoch 1.537), train_loss = 3.33330590, grad/param norm = 1.4559e+00, time/batch = 0.1230s	
84/2700 (epoch 1.556), train_loss = 3.26584265, grad/param norm = 9.8842e-01, time/batch = 0.1293s	
85/2700 (epoch 1.574), train_loss = 3.23188138, grad/param norm = 8.8794e-01, time/batch = 0.1368s	
86/2700 (epoch 1.593), train_loss = 3.23662353, grad/param norm = 1.2896e+00, time/batch = 0.1476s	
87/2700 (epoch 1.611), train_loss = 3.17531647, grad/param norm = 9.4869e-01, time/batch = 0.1429s	
88/2700 (epoch 1.630), train_loss = 3.21422171, grad/param norm = 9.8453e-01, time/batch = 0.1405s	
89/2700 (epoch 1.648), train_loss = 3.28665825, grad/param norm = 1.0935e+00, time/batch = 0.1460s	
90/2700 (epoch 1.667), train_loss = 3.21870252, grad/param norm = 9.6846e-01, time/batch = 0.1448s	
91/2700 (epoch 1.685), train_loss = 3.21337980, grad/param norm = 8.9102e-01, time/batch = 0.1199s	
92/2700 (epoch 1.704), train_loss = 3.18742044, grad/param norm = 1.1389e+00, time/batch = 0.1259s	
93/2700 (epoch 1.722), train_loss = 3.17764276, grad/param norm = 8.3459e-01, time/batch = 0.1383s	
94/2700 (epoch 1.741), train_loss = 3.30938385, grad/param norm = 9.5806e-01, time/batch = 0.1460s	
95/2700 (epoch 1.759), train_loss = 3.25962675, grad/param norm = 1.1920e+00, time/batch = 0.1427s	
96/2700 (epoch 1.778), train_loss = 3.25669546, grad/param norm = 1.3328e+00, time/batch = 0.1440s	
97/2700 (epoch 1.796), train_loss = 3.25117666, grad/param norm = 1.4074e+00, time/batch = 0.1391s	
98/2700 (epoch 1.815), train_loss = 3.19957677, grad/param norm = 1.1597e+00, time/batch = 0.1480s	
99/2700 (epoch 1.833), train_loss = 3.23735251, grad/param norm = 1.3282e+00, time/batch = 0.1530s	
100/2700 (epoch 1.852), train_loss = 3.22976377, grad/param norm = 1.4928e+00, time/batch = 0.1536s	
101/2700 (epoch 1.870), train_loss = 3.22230122, grad/param norm = 1.4278e+00, time/batch = 0.1371s	
102/2700 (epoch 1.889), train_loss = 3.25869543, grad/param norm = 1.4427e+00, time/batch = 0.1324s	
103/2700 (epoch 1.907), train_loss = 3.30871802, grad/param norm = 1.5229e+00, time/batch = 0.1388s	
104/2700 (epoch 1.926), train_loss = 3.25770741, grad/param norm = 1.3304e+00, time/batch = 0.1428s	
105/2700 (epoch 1.944), train_loss = 3.26429996, grad/param norm = 1.0110e+00, time/batch = 0.1254s	
106/2700 (epoch 1.963), train_loss = 3.34298568, grad/param norm = 1.0157e+00, time/batch = 0.1491s	
107/2700 (epoch 1.981), train_loss = 3.40692356, grad/param norm = 1.1934e+00, time/batch = 0.1520s	
108/2700 (epoch 2.000), train_loss = 3.30794836, grad/param norm = 1.1880e+00, time/batch = 0.1510s	
109/2700 (epoch 2.019), train_loss = 3.24152009, grad/param norm = 1.2196e+00, time/batch = 0.1538s	
110/2700 (epoch 2.037), train_loss = 3.26405023, grad/param norm = 1.2267e+00, time/batch = 0.1472s	
111/2700 (epoch 2.056), train_loss = 3.26277494, grad/param norm = 9.5978e-01, time/batch = 0.1408s	
112/2700 (epoch 2.074), train_loss = 3.29388578, grad/param norm = 1.2126e+00, time/batch = 0.1326s	
113/2700 (epoch 2.093), train_loss = 3.30168595, grad/param norm = 1.3871e+00, time/batch = 0.1377s	
114/2700 (epoch 2.111), train_loss = 3.27299170, grad/param norm = 1.3647e+00, time/batch = 0.1477s	
115/2700 (epoch 2.130), train_loss = 3.29227746, grad/param norm = 1.3693e+00, time/batch = 0.1247s	
116/2700 (epoch 2.148), train_loss = 3.25034500, grad/param norm = 1.2419e+00, time/batch = 0.1257s	
117/2700 (epoch 2.167), train_loss = 3.25819110, grad/param norm = 1.3621e+00, time/batch = 0.1284s	
118/2700 (epoch 2.185), train_loss = 3.24340058, grad/param norm = 9.8587e-01, time/batch = 0.1372s	
119/2700 (epoch 2.204), train_loss = 3.17639560, grad/param norm = 1.0393e+00, time/batch = 0.1449s	
120/2700 (epoch 2.222), train_loss = 3.15567323, grad/param norm = 1.4509e+00, time/batch = 0.1559s	
121/2700 (epoch 2.241), train_loss = 3.17264115, grad/param norm = 1.0505e+00, time/batch = 0.1586s	
122/2700 (epoch 2.259), train_loss = 3.20522401, grad/param norm = 8.3442e-01, time/batch = 0.1624s	
123/2700 (epoch 2.278), train_loss = 3.27749065, grad/param norm = 9.3659e-01, time/batch = 0.1792s	
124/2700 (epoch 2.296), train_loss = 3.28003847, grad/param norm = 1.0108e+00, time/batch = 0.1564s	
125/2700 (epoch 2.315), train_loss = 3.25650051, grad/param norm = 9.2399e-01, time/batch = 0.1830s	
126/2700 (epoch 2.333), train_loss = 3.33788720, grad/param norm = 8.8123e-01, time/batch = 0.1824s	
127/2700 (epoch 2.352), train_loss = 3.34379109, grad/param norm = 1.0654e+00, time/batch = 0.1834s	
128/2700 (epoch 2.370), train_loss = 3.28974421, grad/param norm = 1.3117e+00, time/batch = 0.1828s	
129/2700 (epoch 2.389), train_loss = 3.26060314, grad/param norm = 1.8832e+00, time/batch = 0.1850s	
130/2700 (epoch 2.407), train_loss = 3.30928542, grad/param norm = 2.5022e+00, time/batch = 0.1846s	
131/2700 (epoch 2.426), train_loss = 3.28860973, grad/param norm = 1.4625e+00, time/batch = 0.1432s	
132/2700 (epoch 2.444), train_loss = 3.20662075, grad/param norm = 1.0319e+00, time/batch = 0.1697s	
133/2700 (epoch 2.463), train_loss = 3.24994570, grad/param norm = 1.2343e+00, time/batch = 0.1680s	
134/2700 (epoch 2.481), train_loss = 3.33139035, grad/param norm = 1.4460e+00, time/batch = 0.1526s	
135/2700 (epoch 2.500), train_loss = 3.36938641, grad/param norm = 1.3118e+00, time/batch = 0.1805s	
136/2700 (epoch 2.519), train_loss = 3.31216137, grad/param norm = 8.8592e-01, time/batch = 0.1843s	
137/2700 (epoch 2.537), train_loss = 3.31541797, grad/param norm = 1.1933e+00, time/batch = 0.1802s	
138/2700 (epoch 2.556), train_loss = 3.24673765, grad/param norm = 1.0486e+00, time/batch = 0.1597s	
139/2700 (epoch 2.574), train_loss = 3.22844856, grad/param norm = 1.9610e+00, time/batch = 0.1572s	
140/2700 (epoch 2.593), train_loss = 3.26913575, grad/param norm = 2.5834e+00, time/batch = 0.1604s	
141/2700 (epoch 2.611), train_loss = 3.17843073, grad/param norm = 1.9671e+00, time/batch = 0.1791s	
142/2700 (epoch 2.630), train_loss = 3.18704621, grad/param norm = 1.4538e+00, time/batch = 0.1784s	
143/2700 (epoch 2.648), train_loss = 3.23567204, grad/param norm = 1.6334e+00, time/batch = 0.1508s	
144/2700 (epoch 2.667), train_loss = 3.16600495, grad/param norm = 1.8332e+00, time/batch = 0.1822s	
145/2700 (epoch 2.685), train_loss = 3.18148119, grad/param norm = 1.9776e+00, time/batch = 0.1835s	
146/2700 (epoch 2.704), train_loss = 3.11480267, grad/param norm = 1.6889e+00, time/batch = 0.1869s	
147/2700 (epoch 2.722), train_loss = 3.08020405, grad/param norm = 1.0079e+00, time/batch = 0.1867s	
148/2700 (epoch 2.741), train_loss = 3.23021356, grad/param norm = 1.0883e+00, time/batch = 0.1875s	
149/2700 (epoch 2.759), train_loss = 3.16947968, grad/param norm = 1.7788e+00, time/batch = 0.1832s	
150/2700 (epoch 2.778), train_loss = 3.24032385, grad/param norm = 3.4167e+00, time/batch = 0.1642s	
151/2700 (epoch 2.796), train_loss = 3.23398980, grad/param norm = 3.1632e+00, time/batch = 0.1757s	
152/2700 (epoch 2.815), train_loss = 3.08199558, grad/param norm = 1.3244e+00, time/batch = 0.1641s	
153/2700 (epoch 2.833), train_loss = 3.07215469, grad/param norm = 1.1878e+00, time/batch = 0.1567s	
154/2700 (epoch 2.852), train_loss = 3.05561540, grad/param norm = 1.2116e+00, time/batch = 0.1739s	
155/2700 (epoch 2.870), train_loss = 3.03239041, grad/param norm = 1.2560e+00, time/batch = 0.1810s	
156/2700 (epoch 2.889), train_loss = 3.09300604, grad/param norm = 1.7121e+00, time/batch = 0.1872s	
157/2700 (epoch 2.907), train_loss = 3.18084765, grad/param norm = 2.2780e+00, time/batch = 0.1850s	
158/2700 (epoch 2.926), train_loss = 3.10236780, grad/param norm = 2.3305e+00, time/batch = 0.1864s	
159/2700 (epoch 2.944), train_loss = 3.09863421, grad/param norm = 2.1080e+00, time/batch = 0.1803s	
160/2700 (epoch 2.963), train_loss = 3.14060668, grad/param norm = 1.4803e+00, time/batch = 0.1847s	
161/2700 (epoch 2.981), train_loss = 3.42360819, grad/param norm = 9.5543e+00, time/batch = 0.1718s	
162/2700 (epoch 3.000), train_loss = 3.40292935, grad/param norm = 3.2176e+00, time/batch = 0.1511s	
163/2700 (epoch 3.019), train_loss = 2.99441035, grad/param norm = 1.3053e+00, time/batch = 0.1682s	
164/2700 (epoch 3.037), train_loss = 3.01444830, grad/param norm = 1.3992e+00, time/batch = 0.1725s	
165/2700 (epoch 3.056), train_loss = 3.00404326, grad/param norm = 1.6739e+00, time/batch = 0.1656s	
166/2700 (epoch 3.074), train_loss = 3.05882494, grad/param norm = 1.9266e+00, time/batch = 0.1725s	
167/2700 (epoch 3.093), train_loss = 3.03817831, grad/param norm = 1.5007e+00, time/batch = 0.1777s	
168/2700 (epoch 3.111), train_loss = 2.97847304, grad/param norm = 1.1738e+00, time/batch = 0.1829s	
169/2700 (epoch 3.130), train_loss = 2.99529657, grad/param norm = 1.2095e+00, time/batch = 0.1753s	
170/2700 (epoch 3.148), train_loss = 2.93397327, grad/param norm = 1.5725e+00, time/batch = 0.1809s	
171/2700 (epoch 3.167), train_loss = 2.95167789, grad/param norm = 1.6517e+00, time/batch = 0.1607s	
172/2700 (epoch 3.185), train_loss = 2.90256946, grad/param norm = 1.2121e+00, time/batch = 0.1569s	
173/2700 (epoch 3.204), train_loss = 2.83842302, grad/param norm = 1.2000e+00, time/batch = 0.1861s	
174/2700 (epoch 3.222), train_loss = 2.78652402, grad/param norm = 1.4003e+00, time/batch = 0.1884s	
175/2700 (epoch 3.241), train_loss = 2.81861974, grad/param norm = 1.4896e+00, time/batch = 0.1690s	
176/2700 (epoch 3.259), train_loss = 2.83986444, grad/param norm = 1.5030e+00, time/batch = 0.1663s	
177/2700 (epoch 3.278), train_loss = 2.93135376, grad/param norm = 1.4581e+00, time/batch = 0.1649s	
178/2700 (epoch 3.296), train_loss = 2.92844019, grad/param norm = 1.5530e+00, time/batch = 0.1553s	
179/2700 (epoch 3.315), train_loss = 2.98859987, grad/param norm = 1.9335e+00, time/batch = 0.1758s	
180/2700 (epoch 3.333), train_loss = 3.04708881, grad/param norm = 2.4968e+00, time/batch = 0.1792s	
181/2700 (epoch 3.352), train_loss = 3.14447092, grad/param norm = 3.8801e+00, time/batch = 0.1632s	
182/2700 (epoch 3.370), train_loss = 3.03603386, grad/param norm = 2.6222e+00, time/batch = 0.1654s	
183/2700 (epoch 3.389), train_loss = 2.85150246, grad/param norm = 8.2885e-01, time/batch = 0.1729s	
184/2700 (epoch 3.407), train_loss = 2.86276813, grad/param norm = 9.7886e-01, time/batch = 0.1844s	
185/2700 (epoch 3.426), train_loss = 2.89475962, grad/param norm = 1.0080e+00, time/batch = 0.1839s	
186/2700 (epoch 3.444), train_loss = 2.77081343, grad/param norm = 1.2952e+00, time/batch = 0.1852s	
187/2700 (epoch 3.463), train_loss = 2.86889018, grad/param norm = 1.5524e+00, time/batch = 0.1779s	
188/2700 (epoch 3.481), train_loss = 2.93107167, grad/param norm = 1.5639e+00, time/batch = 0.1882s	
189/2700 (epoch 3.500), train_loss = 2.96780680, grad/param norm = 1.6948e+00, time/batch = 0.1861s	
190/2700 (epoch 3.519), train_loss = 2.89090729, grad/param norm = 1.5833e+00, time/batch = 0.1838s	
191/2700 (epoch 3.537), train_loss = 2.89952368, grad/param norm = 1.5801e+00, time/batch = 0.1519s	
192/2700 (epoch 3.556), train_loss = 2.83513862, grad/param norm = 1.2249e+00, time/batch = 0.1819s	
193/2700 (epoch 3.574), train_loss = 2.77953545, grad/param norm = 1.0851e+00, time/batch = 0.1802s	
194/2700 (epoch 3.593), train_loss = 2.76604628, grad/param norm = 1.4380e+00, time/batch = 0.1732s	
195/2700 (epoch 3.611), train_loss = 2.73274607, grad/param norm = 1.7803e+00, time/batch = 0.1753s	
196/2700 (epoch 3.630), train_loss = 2.79000671, grad/param norm = 2.2630e+00, time/batch = 0.1845s	
197/2700 (epoch 3.648), train_loss = 2.84014397, grad/param norm = 2.3292e+00, time/batch = 0.1741s	
198/2700 (epoch 3.667), train_loss = 2.77821359, grad/param norm = 2.1462e+00, time/batch = 0.1729s	
199/2700 (epoch 3.685), train_loss = 2.79199391, grad/param norm = 1.7881e+00, time/batch = 0.1690s	
200/2700 (epoch 3.704), train_loss = 2.70445922, grad/param norm = 1.2574e+00, time/batch = 0.1717s	
201/2700 (epoch 3.722), train_loss = 2.68437520, grad/param norm = 9.5284e-01, time/batch = 0.1765s	
202/2700 (epoch 3.741), train_loss = 2.87470417, grad/param norm = 1.3240e+00, time/batch = 0.1602s	
203/2700 (epoch 3.759), train_loss = 2.77435735, grad/param norm = 1.2995e+00, time/batch = 0.1756s	
204/2700 (epoch 3.778), train_loss = 2.77339920, grad/param norm = 1.4754e+00, time/batch = 0.1874s	
205/2700 (epoch 3.796), train_loss = 2.75660805, grad/param norm = 1.6345e+00, time/batch = 0.1876s	
206/2700 (epoch 3.815), train_loss = 2.72507853, grad/param norm = 1.4536e+00, time/batch = 0.1785s	
207/2700 (epoch 3.833), train_loss = 2.72929269, grad/param norm = 1.8019e+00, time/batch = 0.1747s	
208/2700 (epoch 3.852), train_loss = 2.79575931, grad/param norm = 2.1318e+00, time/batch = 0.1840s	
209/2700 (epoch 3.870), train_loss = 2.71294712, grad/param norm = 1.5282e+00, time/batch = 0.1829s	
210/2700 (epoch 3.889), train_loss = 2.71281340, grad/param norm = 9.3331e-01, time/batch = 0.1736s	
211/2700 (epoch 3.907), train_loss = 2.78862245, grad/param norm = 9.0915e-01, time/batch = 0.1767s	
212/2700 (epoch 3.926), train_loss = 2.71881318, grad/param norm = 1.4235e+00, time/batch = 0.1857s	
213/2700 (epoch 3.944), train_loss = 2.77254143, grad/param norm = 1.2626e+00, time/batch = 0.1858s	
214/2700 (epoch 3.963), train_loss = 2.80404406, grad/param norm = 1.8979e+00, time/batch = 0.1782s	
215/2700 (epoch 3.981), train_loss = 2.92222367, grad/param norm = 2.9005e+00, time/batch = 0.1589s	
216/2700 (epoch 4.000), train_loss = 2.89429465, grad/param norm = 1.6852e+00, time/batch = 0.1794s	
217/2700 (epoch 4.019), train_loss = 2.71133650, grad/param norm = 1.1366e+00, time/batch = 0.1805s	
218/2700 (epoch 4.037), train_loss = 2.72891003, grad/param norm = 1.0712e+00, time/batch = 0.1692s	
219/2700 (epoch 4.056), train_loss = 2.71887236, grad/param norm = 1.7171e+00, time/batch = 0.1734s	
220/2700 (epoch 4.074), train_loss = 2.83166962, grad/param norm = 3.1570e+00, time/batch = 0.1683s	
221/2700 (epoch 4.093), train_loss = 2.86175186, grad/param norm = 2.3481e+00, time/batch = 0.1800s	
222/2700 (epoch 4.111), train_loss = 2.73720156, grad/param norm = 1.6540e+00, time/batch = 0.1644s	
223/2700 (epoch 4.130), train_loss = 2.78450480, grad/param norm = 1.7092e+00, time/batch = 0.1706s	
224/2700 (epoch 4.148), train_loss = 2.71081661, grad/param norm = 1.9891e+00, time/batch = 0.1637s	
225/2700 (epoch 4.167), train_loss = 2.72340640, grad/param norm = 1.4783e+00, time/batch = 0.1746s	
226/2700 (epoch 4.185), train_loss = 2.65494899, grad/param norm = 9.9128e-01, time/batch = 0.1883s	
227/2700 (epoch 4.204), train_loss = 2.59071554, grad/param norm = 8.8070e-01, time/batch = 0.1870s	
228/2700 (epoch 4.222), train_loss = 2.54209234, grad/param norm = 1.1893e+00, time/batch = 0.1826s	
229/2700 (epoch 4.241), train_loss = 2.56603705, grad/param norm = 1.3176e+00, time/batch = 0.1782s	
230/2700 (epoch 4.259), train_loss = 2.61128923, grad/param norm = 1.8111e+00, time/batch = 0.1780s	
231/2700 (epoch 4.278), train_loss = 2.70263962, grad/param norm = 1.6752e+00, time/batch = 0.1748s	
232/2700 (epoch 4.296), train_loss = 2.65479180, grad/param norm = 1.3601e+00, time/batch = 0.1733s	
233/2700 (epoch 4.315), train_loss = 2.70965092, grad/param norm = 1.4485e+00, time/batch = 0.1780s	
234/2700 (epoch 4.333), train_loss = 2.70683043, grad/param norm = 1.3053e+00, time/batch = 0.1836s	
235/2700 (epoch 4.352), train_loss = 2.74524328, grad/param norm = 1.3763e+00, time/batch = 0.1805s	
236/2700 (epoch 4.370), train_loss = 2.68425551, grad/param norm = 1.7615e+00, time/batch = 0.1827s	
237/2700 (epoch 4.389), train_loss = 2.67533195, grad/param norm = 2.1132e+00, time/batch = 0.1833s	
238/2700 (epoch 4.407), train_loss = 2.68018748, grad/param norm = 1.6941e+00, time/batch = 0.1830s	
239/2700 (epoch 4.426), train_loss = 2.68119411, grad/param norm = 1.1937e+00, time/batch = 0.1799s	
240/2700 (epoch 4.444), train_loss = 2.56863017, grad/param norm = 1.3948e+00, time/batch = 0.1857s	
241/2700 (epoch 4.463), train_loss = 2.67172758, grad/param norm = 1.5267e+00, time/batch = 0.1675s	
242/2700 (epoch 4.481), train_loss = 2.72468982, grad/param norm = 1.7355e+00, time/batch = 0.1568s	
243/2700 (epoch 4.500), train_loss = 2.73476426, grad/param norm = 1.9462e+00, time/batch = 0.1501s	
244/2700 (epoch 4.519), train_loss = 2.78560507, grad/param norm = 4.2864e+00, time/batch = 0.1514s	
245/2700 (epoch 4.537), train_loss = 2.74695534, grad/param norm = 1.3575e+00, time/batch = 0.1602s	
246/2700 (epoch 4.556), train_loss = 2.64808296, grad/param norm = 1.2373e+00, time/batch = 0.1706s	
247/2700 (epoch 4.574), train_loss = 2.59401068, grad/param norm = 1.6819e+00, time/batch = 0.1874s	
248/2700 (epoch 4.593), train_loss = 2.60430576, grad/param norm = 1.9650e+00, time/batch = 0.1865s	
249/2700 (epoch 4.611), train_loss = 2.52689546, grad/param norm = 1.7267e+00, time/batch = 0.1727s	
250/2700 (epoch 4.630), train_loss = 2.58513528, grad/param norm = 1.5744e+00, time/batch = 0.1750s	
251/2700 (epoch 4.648), train_loss = 2.59261145, grad/param norm = 1.3384e+00, time/batch = 0.1706s	
252/2700 (epoch 4.667), train_loss = 2.52297097, grad/param norm = 1.4124e+00, time/batch = 0.1571s	
253/2700 (epoch 4.685), train_loss = 2.60357684, grad/param norm = 1.9354e+00, time/batch = 0.1659s	
254/2700 (epoch 4.704), train_loss = 2.61360415, grad/param norm = 2.3811e+00, time/batch = 0.1715s	
255/2700 (epoch 4.722), train_loss = 2.61440229, grad/param norm = 2.1069e+00, time/batch = 0.1720s	
256/2700 (epoch 4.741), train_loss = 2.73550495, grad/param norm = 1.3234e+00, time/batch = 0.1790s	
257/2700 (epoch 4.759), train_loss = 2.60910268, grad/param norm = 8.9070e-01, time/batch = 0.1826s	
258/2700 (epoch 4.778), train_loss = 2.58873032, grad/param norm = 1.0437e+00, time/batch = 0.1755s	
259/2700 (epoch 4.796), train_loss = 2.56784791, grad/param norm = 1.2865e+00, time/batch = 0.1796s	
260/2700 (epoch 4.815), train_loss = 2.55846492, grad/param norm = 1.3064e+00, time/batch = 0.1792s	
261/2700 (epoch 4.833), train_loss = 2.54493194, grad/param norm = 1.1283e+00, time/batch = 0.1764s	
262/2700 (epoch 4.852), train_loss = 2.57310738, grad/param norm = 7.9081e-01, time/batch = 0.1610s	
263/2700 (epoch 4.870), train_loss = 2.52452016, grad/param norm = 7.8696e-01, time/batch = 0.1824s	
264/2700 (epoch 4.889), train_loss = 2.54681678, grad/param norm = 1.1542e+00, time/batch = 0.1727s	
265/2700 (epoch 4.907), train_loss = 2.70042900, grad/param norm = 1.4516e+00, time/batch = 0.1733s	
266/2700 (epoch 4.926), train_loss = 2.58517605, grad/param norm = 1.8756e+00, time/batch = 0.1808s	
267/2700 (epoch 4.944), train_loss = 2.68295565, grad/param norm = 2.6613e+00, time/batch = 0.1812s	
268/2700 (epoch 4.963), train_loss = 2.74821317, grad/param norm = 2.2655e+00, time/batch = 0.1735s	
269/2700 (epoch 4.981), train_loss = 2.66721080, grad/param norm = 1.2017e+00, time/batch = 0.1837s	
270/2700 (epoch 5.000), train_loss = 2.66351937, grad/param norm = 1.5067e+00, time/batch = 0.1879s	
271/2700 (epoch 5.019), train_loss = 2.62142276, grad/param norm = 2.0627e+00, time/batch = 0.1432s	
272/2700 (epoch 5.037), train_loss = 2.66180914, grad/param norm = 1.4603e+00, time/batch = 0.1742s	
273/2700 (epoch 5.056), train_loss = 2.58764304, grad/param norm = 1.1156e+00, time/batch = 0.1657s	
274/2700 (epoch 5.074), train_loss = 2.58565507, grad/param norm = 1.0511e+00, time/batch = 0.1701s	
275/2700 (epoch 5.093), train_loss = 2.60295719, grad/param norm = 1.2674e+00, time/batch = 0.1730s	
276/2700 (epoch 5.111), train_loss = 2.58277412, grad/param norm = 1.5764e+00, time/batch = 0.1776s	
277/2700 (epoch 5.130), train_loss = 2.59812748, grad/param norm = 1.7420e+00, time/batch = 0.1767s	
278/2700 (epoch 5.148), train_loss = 2.53578776, grad/param norm = 1.1841e+00, time/batch = 0.1609s	
279/2700 (epoch 5.167), train_loss = 2.53736437, grad/param norm = 8.2805e-01, time/batch = 0.1624s	
280/2700 (epoch 5.185), train_loss = 2.50151325, grad/param norm = 1.0176e+00, time/batch = 0.1628s	
281/2700 (epoch 5.204), train_loss = 2.49436434, grad/param norm = 1.3567e+00, time/batch = 0.1593s	
282/2700 (epoch 5.222), train_loss = 2.47546419, grad/param norm = 2.1378e+00, time/batch = 0.1821s	
283/2700 (epoch 5.241), train_loss = 2.52816199, grad/param norm = 2.0442e+00, time/batch = 0.1811s	
284/2700 (epoch 5.259), train_loss = 2.49283537, grad/param norm = 1.6087e+00, time/batch = 0.1841s	
285/2700 (epoch 5.278), train_loss = 2.56226710, grad/param norm = 1.1145e+00, time/batch = 0.1835s	
286/2700 (epoch 5.296), train_loss = 2.51703068, grad/param norm = 1.0537e+00, time/batch = 0.1775s	
287/2700 (epoch 5.315), train_loss = 2.57164117, grad/param norm = 1.0773e+00, time/batch = 0.1610s	
288/2700 (epoch 5.333), train_loss = 2.57422832, grad/param norm = 1.1060e+00, time/batch = 0.1782s	
289/2700 (epoch 5.352), train_loss = 2.65034435, grad/param norm = 1.6370e+00, time/batch = 0.1757s	
290/2700 (epoch 5.370), train_loss = 2.60483562, grad/param norm = 1.4329e+00, time/batch = 0.1638s	
291/2700 (epoch 5.389), train_loss = 2.54345771, grad/param norm = 1.3564e+00, time/batch = 0.1731s	
292/2700 (epoch 5.407), train_loss = 2.53418848, grad/param norm = 1.5024e+00, time/batch = 0.1816s	
293/2700 (epoch 5.426), train_loss = 2.55911811, grad/param norm = 1.5553e+00, time/batch = 0.1816s	
294/2700 (epoch 5.444), train_loss = 2.44635560, grad/param norm = 1.0884e+00, time/batch = 0.1821s	
295/2700 (epoch 5.463), train_loss = 2.51701544, grad/param norm = 1.3025e+00, time/batch = 0.1803s	
296/2700 (epoch 5.481), train_loss = 2.59460267, grad/param norm = 1.3722e+00, time/batch = 0.1800s	
297/2700 (epoch 5.500), train_loss = 2.61535374, grad/param norm = 1.5001e+00, time/batch = 0.1698s	
298/2700 (epoch 5.519), train_loss = 2.58220109, grad/param norm = 2.2500e+00, time/batch = 0.1813s	
299/2700 (epoch 5.537), train_loss = 2.63466574, grad/param norm = 2.2362e+00, time/batch = 0.1759s	
300/2700 (epoch 5.556), train_loss = 2.54818207, grad/param norm = 1.5931e+00, time/batch = 0.1746s	
301/2700 (epoch 5.574), train_loss = 2.46610630, grad/param norm = 1.5155e+00, time/batch = 0.1698s	
302/2700 (epoch 5.593), train_loss = 2.44565114, grad/param norm = 1.1298e+00, time/batch = 0.1531s	
303/2700 (epoch 5.611), train_loss = 2.38858324, grad/param norm = 1.0019e+00, time/batch = 0.1613s	
304/2700 (epoch 5.630), train_loss = 2.43867546, grad/param norm = 1.4390e+00, time/batch = 0.1591s	
305/2700 (epoch 5.648), train_loss = 2.51623354, grad/param norm = 1.8765e+00, time/batch = 0.1613s	
306/2700 (epoch 5.667), train_loss = 2.47196185, grad/param norm = 1.9292e+00, time/batch = 0.1697s	
307/2700 (epoch 5.685), train_loss = 2.51050554, grad/param norm = 1.5292e+00, time/batch = 0.1572s	
308/2700 (epoch 5.704), train_loss = 2.44916859, grad/param norm = 1.0398e+00, time/batch = 0.1801s	
309/2700 (epoch 5.722), train_loss = 2.42439388, grad/param norm = 7.0565e-01, time/batch = 0.1664s	
310/2700 (epoch 5.741), train_loss = 2.58677625, grad/param norm = 7.2266e-01, time/batch = 0.1604s	
311/2700 (epoch 5.759), train_loss = 2.50571344, grad/param norm = 9.0070e-01, time/batch = 0.1796s	
312/2700 (epoch 5.778), train_loss = 2.49247790, grad/param norm = 1.3611e+00, time/batch = 0.1810s	
313/2700 (epoch 5.796), train_loss = 2.50087785, grad/param norm = 1.5888e+00, time/batch = 0.1834s	
314/2700 (epoch 5.815), train_loss = 2.47786323, grad/param norm = 1.7113e+00, time/batch = 0.1838s	
315/2700 (epoch 5.833), train_loss = 2.46930196, grad/param norm = 1.5778e+00, time/batch = 0.1848s	
316/2700 (epoch 5.852), train_loss = 2.49399378, grad/param norm = 1.2643e+00, time/batch = 0.1758s	
317/2700 (epoch 5.870), train_loss = 2.43776874, grad/param norm = 1.1980e+00, time/batch = 0.1826s	
318/2700 (epoch 5.889), train_loss = 2.43347527, grad/param norm = 1.0486e+00, time/batch = 0.1726s	
319/2700 (epoch 5.907), train_loss = 2.55658797, grad/param norm = 9.3744e-01, time/batch = 0.1673s	
320/2700 (epoch 5.926), train_loss = 2.46913253, grad/param norm = 8.2978e-01, time/batch = 0.1821s	
321/2700 (epoch 5.944), train_loss = 2.48685407, grad/param norm = 7.3032e-01, time/batch = 0.1722s	
322/2700 (epoch 5.963), train_loss = 2.52271341, grad/param norm = 8.2242e-01, time/batch = 0.1596s	
323/2700 (epoch 5.981), train_loss = 2.49597538, grad/param norm = 1.0346e+00, time/batch = 0.1666s	
324/2700 (epoch 6.000), train_loss = 2.52417075, grad/param norm = 1.3472e+00, time/batch = 0.1803s	
325/2700 (epoch 6.019), train_loss = 2.51057914, grad/param norm = 1.6439e+00, time/batch = 0.1841s	
326/2700 (epoch 6.037), train_loss = 2.54860207, grad/param norm = 1.7536e+00, time/batch = 0.1773s	
327/2700 (epoch 6.056), train_loss = 2.49137341, grad/param norm = 1.2148e+00, time/batch = 0.1813s	
328/2700 (epoch 6.074), train_loss = 2.45471703, grad/param norm = 8.9077e-01, time/batch = 0.1828s	
329/2700 (epoch 6.093), train_loss = 2.48550162, grad/param norm = 1.1212e+00, time/batch = 0.1845s	
330/2700 (epoch 6.111), train_loss = 2.46651472, grad/param norm = 1.4897e+00, time/batch = 0.1848s	
331/2700 (epoch 6.130), train_loss = 2.51985138, grad/param norm = 2.0486e+00, time/batch = 0.1632s	
332/2700 (epoch 6.148), train_loss = 2.50826099, grad/param norm = 2.1026e+00, time/batch = 0.1595s	
333/2700 (epoch 6.167), train_loss = 2.53364257, grad/param norm = 1.3928e+00, time/batch = 0.1646s	
334/2700 (epoch 6.185), train_loss = 2.43063457, grad/param norm = 9.9693e-01, time/batch = 0.1678s	
335/2700 (epoch 6.204), train_loss = 2.40819098, grad/param norm = 1.3339e+00, time/batch = 0.1716s	
336/2700 (epoch 6.222), train_loss = 2.35293183, grad/param norm = 1.3122e+00, time/batch = 0.1560s	
337/2700 (epoch 6.241), train_loss = 2.34109190, grad/param norm = 1.2393e+00, time/batch = 0.1738s	
338/2700 (epoch 6.259), train_loss = 2.36494191, grad/param norm = 1.0984e+00, time/batch = 0.1614s	
339/2700 (epoch 6.278), train_loss = 2.46104684, grad/param norm = 1.0779e+00, time/batch = 0.1629s	
340/2700 (epoch 6.296), train_loss = 2.42440734, grad/param norm = 1.1471e+00, time/batch = 0.1693s	
341/2700 (epoch 6.315), train_loss = 2.45426904, grad/param norm = 9.5442e-01, time/batch = 0.1814s	
342/2700 (epoch 6.333), train_loss = 2.44991810, grad/param norm = 8.5212e-01, time/batch = 0.1699s	
343/2700 (epoch 6.352), train_loss = 2.48951627, grad/param norm = 9.6521e-01, time/batch = 0.1743s	
344/2700 (epoch 6.370), train_loss = 2.43630481, grad/param norm = 7.4466e-01, time/batch = 0.1753s	
345/2700 (epoch 6.389), train_loss = 2.40598321, grad/param norm = 9.9769e-01, time/batch = 0.1574s	
346/2700 (epoch 6.407), train_loss = 2.45054800, grad/param norm = 1.4399e+00, time/batch = 0.1658s	
347/2700 (epoch 6.426), train_loss = 2.47219188, grad/param norm = 1.8547e+00, time/batch = 0.1833s	
348/2700 (epoch 6.444), train_loss = 2.40689198, grad/param norm = 2.0708e+00, time/batch = 0.1674s	
349/2700 (epoch 6.463), train_loss = 2.46070253, grad/param norm = 1.4909e+00, time/batch = 0.1640s	
350/2700 (epoch 6.481), train_loss = 2.50359087, grad/param norm = 1.5212e+00, time/batch = 0.1795s	
351/2700 (epoch 6.500), train_loss = 2.50676386, grad/param norm = 1.4217e+00, time/batch = 0.1823s	
352/2700 (epoch 6.519), train_loss = 2.43142460, grad/param norm = 1.1509e+00, time/batch = 0.1781s	
353/2700 (epoch 6.537), train_loss = 2.43360122, grad/param norm = 1.1873e+00, time/batch = 0.1662s	
354/2700 (epoch 6.556), train_loss = 2.42130790, grad/param norm = 1.1947e+00, time/batch = 0.1631s	
355/2700 (epoch 6.574), train_loss = 2.35543468, grad/param norm = 1.3901e+00, time/batch = 0.1264s	
356/2700 (epoch 6.593), train_loss = 2.37349033, grad/param norm = 1.4032e+00, time/batch = 0.1869s	
357/2700 (epoch 6.611), train_loss = 2.29719613, grad/param norm = 1.6105e+00, time/batch = 0.1768s	
358/2700 (epoch 6.630), train_loss = 2.37357241, grad/param norm = 1.2304e+00, time/batch = 0.1816s	
359/2700 (epoch 6.648), train_loss = 2.35823673, grad/param norm = 8.4693e-01, time/batch = 0.1773s	
360/2700 (epoch 6.667), train_loss = 2.30554650, grad/param norm = 9.3606e-01, time/batch = 0.1648s	
361/2700 (epoch 6.685), train_loss = 2.36870889, grad/param norm = 1.0290e+00, time/batch = 0.1839s	
362/2700 (epoch 6.704), train_loss = 2.36551020, grad/param norm = 1.3149e+00, time/batch = 0.1841s	
363/2700 (epoch 6.722), train_loss = 2.37671679, grad/param norm = 1.4411e+00, time/batch = 0.1829s	
364/2700 (epoch 6.741), train_loss = 2.55609231, grad/param norm = 1.9313e+00, time/batch = 0.1735s	
365/2700 (epoch 6.759), train_loss = 2.55068477, grad/param norm = 2.0944e+00, time/batch = 0.1712s	
366/2700 (epoch 6.778), train_loss = 2.45792538, grad/param norm = 1.4618e+00, time/batch = 0.1553s	
367/2700 (epoch 6.796), train_loss = 2.39118710, grad/param norm = 1.2852e+00, time/batch = 0.1811s	
368/2700 (epoch 6.815), train_loss = 2.36575369, grad/param norm = 1.1255e+00, time/batch = 0.1848s	
369/2700 (epoch 6.833), train_loss = 2.33036137, grad/param norm = 1.0287e+00, time/batch = 0.1852s	
370/2700 (epoch 6.852), train_loss = 2.38073509, grad/param norm = 9.8060e-01, time/batch = 0.1647s	
371/2700 (epoch 6.870), train_loss = 2.34023401, grad/param norm = 1.0682e+00, time/batch = 0.1845s	
372/2700 (epoch 6.889), train_loss = 2.33280993, grad/param norm = 1.0908e+00, time/batch = 0.1851s	
373/2700 (epoch 6.907), train_loss = 2.46346169, grad/param norm = 1.1078e+00, time/batch = 0.1741s	
374/2700 (epoch 6.926), train_loss = 2.39135209, grad/param norm = 1.2965e+00, time/batch = 0.1760s	
375/2700 (epoch 6.944), train_loss = 2.40114330, grad/param norm = 1.0605e+00, time/batch = 0.1782s	
376/2700 (epoch 6.963), train_loss = 2.43068736, grad/param norm = 9.6405e-01, time/batch = 0.1826s	
377/2700 (epoch 6.981), train_loss = 2.40905831, grad/param norm = 9.0064e-01, time/batch = 0.1656s	
378/2700 (epoch 7.000), train_loss = 2.45075375, grad/param norm = 1.5136e+00, time/batch = 0.1719s	
379/2700 (epoch 7.019), train_loss = 2.43441505, grad/param norm = 1.4609e+00, time/batch = 0.1758s	
380/2700 (epoch 7.037), train_loss = 2.45578110, grad/param norm = 1.4570e+00, time/batch = 0.1764s	
381/2700 (epoch 7.056), train_loss = 2.40369854, grad/param norm = 1.3581e+00, time/batch = 0.1787s	
382/2700 (epoch 7.074), train_loss = 2.38011705, grad/param norm = 1.1270e+00, time/batch = 0.1699s	
383/2700 (epoch 7.093), train_loss = 2.38797673, grad/param norm = 1.0387e+00, time/batch = 0.1652s	
384/2700 (epoch 7.111), train_loss = 2.35597264, grad/param norm = 1.1583e+00, time/batch = 0.1767s	
385/2700 (epoch 7.130), train_loss = 2.36804268, grad/param norm = 1.0695e+00, time/batch = 0.1663s	
386/2700 (epoch 7.148), train_loss = 2.33223129, grad/param norm = 1.2171e+00, time/batch = 0.1790s	
387/2700 (epoch 7.167), train_loss = 2.38748354, grad/param norm = 1.4041e+00, time/batch = 0.1704s	
388/2700 (epoch 7.185), train_loss = 2.35044325, grad/param norm = 1.4916e+00, time/batch = 0.1727s	
389/2700 (epoch 7.204), train_loss = 2.33868815, grad/param norm = 1.2572e+00, time/batch = 0.1798s	
390/2700 (epoch 7.222), train_loss = 2.26482237, grad/param norm = 1.1684e+00, time/batch = 0.1812s	
391/2700 (epoch 7.241), train_loss = 2.23477993, grad/param norm = 9.9054e-01, time/batch = 0.1767s	
392/2700 (epoch 7.259), train_loss = 2.25761639, grad/param norm = 8.4619e-01, time/batch = 0.1782s	
393/2700 (epoch 7.278), train_loss = 2.36168410, grad/param norm = 7.7274e-01, time/batch = 0.1515s	
394/2700 (epoch 7.296), train_loss = 2.31692285, grad/param norm = 7.8833e-01, time/batch = 0.1565s	
395/2700 (epoch 7.315), train_loss = 2.35431297, grad/param norm = 9.5351e-01, time/batch = 0.1823s	
396/2700 (epoch 7.333), train_loss = 2.38704935, grad/param norm = 1.3123e+00, time/batch = 0.1825s	
397/2700 (epoch 7.352), train_loss = 2.46261609, grad/param norm = 1.7073e+00, time/batch = 0.1851s	
398/2700 (epoch 7.370), train_loss = 2.43687770, grad/param norm = 1.6816e+00, time/batch = 0.1822s	
399/2700 (epoch 7.389), train_loss = 2.37504518, grad/param norm = 1.5706e+00, time/batch = 0.1811s	
400/2700 (epoch 7.407), train_loss = 2.35401064, grad/param norm = 9.9542e-01, time/batch = 0.1730s	
401/2700 (epoch 7.426), train_loss = 2.33242106, grad/param norm = 6.6072e-01, time/batch = 0.1521s	
402/2700 (epoch 7.444), train_loss = 2.24588783, grad/param norm = 5.9388e-01, time/batch = 0.1562s	
403/2700 (epoch 7.463), train_loss = 2.31570646, grad/param norm = 7.3887e-01, time/batch = 0.1457s	
404/2700 (epoch 7.481), train_loss = 2.39463034, grad/param norm = 1.2453e+00, time/batch = 0.1817s	
405/2700 (epoch 7.500), train_loss = 2.42128903, grad/param norm = 1.2651e+00, time/batch = 0.1839s	
406/2700 (epoch 7.519), train_loss = 2.36912683, grad/param norm = 1.9213e+00, time/batch = 0.1824s	
407/2700 (epoch 7.537), train_loss = 2.39868491, grad/param norm = 1.1403e+00, time/batch = 0.1837s	
408/2700 (epoch 7.556), train_loss = 2.31818964, grad/param norm = 9.6245e-01, time/batch = 0.1828s	
409/2700 (epoch 7.574), train_loss = 2.28535765, grad/param norm = 1.2554e+00, time/batch = 0.1844s	
410/2700 (epoch 7.593), train_loss = 2.30682013, grad/param norm = 1.5505e+00, time/batch = 0.1775s	
411/2700 (epoch 7.611), train_loss = 2.22066800, grad/param norm = 1.6253e+00, time/batch = 0.1643s	
412/2700 (epoch 7.630), train_loss = 2.27412965, grad/param norm = 1.4035e+00, time/batch = 0.1599s	
413/2700 (epoch 7.648), train_loss = 2.28793514, grad/param norm = 1.4435e+00, time/batch = 0.1291s	
414/2700 (epoch 7.667), train_loss = 2.24157140, grad/param norm = 1.1385e+00, time/batch = 0.1864s	
415/2700 (epoch 7.685), train_loss = 2.26637845, grad/param norm = 9.5902e-01, time/batch = 0.1875s	
416/2700 (epoch 7.704), train_loss = 2.24969159, grad/param norm = 9.1638e-01, time/batch = 0.1759s	
417/2700 (epoch 7.722), train_loss = 2.23676239, grad/param norm = 8.9704e-01, time/batch = 0.1600s	
418/2700 (epoch 7.741), train_loss = 2.39193099, grad/param norm = 1.0862e+00, time/batch = 0.1678s	
419/2700 (epoch 7.759), train_loss = 2.36203440, grad/param norm = 1.3141e+00, time/batch = 0.1774s	
420/2700 (epoch 7.778), train_loss = 2.34990277, grad/param norm = 1.3622e+00, time/batch = 0.1783s	
421/2700 (epoch 7.796), train_loss = 2.28875047, grad/param norm = 9.2118e-01, time/batch = 0.1790s	
422/2700 (epoch 7.815), train_loss = 2.28882418, grad/param norm = 6.6445e-01, time/batch = 0.1698s	
423/2700 (epoch 7.833), train_loss = 2.24524300, grad/param norm = 7.5773e-01, time/batch = 0.1588s	
424/2700 (epoch 7.852), train_loss = 2.29743306, grad/param norm = 1.0024e+00, time/batch = 0.1755s	
425/2700 (epoch 7.870), train_loss = 2.26425174, grad/param norm = 1.2468e+00, time/batch = 0.1636s	
426/2700 (epoch 7.889), train_loss = 2.25661535, grad/param norm = 9.8652e-01, time/batch = 0.1658s	
427/2700 (epoch 7.907), train_loss = 2.37254580, grad/param norm = 8.6599e-01, time/batch = 0.1693s	
428/2700 (epoch 7.926), train_loss = 2.30619560, grad/param norm = 1.1682e+00, time/batch = 0.1717s	
429/2700 (epoch 7.944), train_loss = 2.33111375, grad/param norm = 1.1644e+00, time/batch = 0.1622s	
430/2700 (epoch 7.963), train_loss = 2.37572583, grad/param norm = 1.1099e+00, time/batch = 0.1778s	
431/2700 (epoch 7.981), train_loss = 2.35668446, grad/param norm = 1.1834e+00, time/batch = 0.1715s	
432/2700 (epoch 8.000), train_loss = 2.36267887, grad/param norm = 1.1586e+00, time/batch = 0.1580s	
433/2700 (epoch 8.019), train_loss = 2.30936015, grad/param norm = 1.0592e+00, time/batch = 0.1794s	
434/2700 (epoch 8.037), train_loss = 2.33360774, grad/param norm = 1.0274e+00, time/batch = 0.1801s	
435/2700 (epoch 8.056), train_loss = 2.30161440, grad/param norm = 1.1506e+00, time/batch = 0.1747s	
436/2700 (epoch 8.074), train_loss = 2.29827206, grad/param norm = 1.3922e+00, time/batch = 0.1763s	
437/2700 (epoch 8.093), train_loss = 2.31871712, grad/param norm = 1.2240e+00, time/batch = 0.1795s	
438/2700 (epoch 8.111), train_loss = 2.28316062, grad/param norm = 1.2310e+00, time/batch = 0.1693s	
439/2700 (epoch 8.130), train_loss = 2.29200816, grad/param norm = 1.1160e+00, time/batch = 0.1806s	
440/2700 (epoch 8.148), train_loss = 2.26756146, grad/param norm = 1.1626e+00, time/batch = 0.1845s	
441/2700 (epoch 8.167), train_loss = 2.30902531, grad/param norm = 9.8368e-01, time/batch = 0.1837s	
442/2700 (epoch 8.185), train_loss = 2.24258626, grad/param norm = 9.7903e-01, time/batch = 0.1573s	
443/2700 (epoch 8.204), train_loss = 2.24319075, grad/param norm = 9.7853e-01, time/batch = 0.1678s	
444/2700 (epoch 8.222), train_loss = 2.16710858, grad/param norm = 8.5031e-01, time/batch = 0.1781s	
445/2700 (epoch 8.241), train_loss = 2.13932675, grad/param norm = 7.8302e-01, time/batch = 0.1870s	
446/2700 (epoch 8.259), train_loss = 2.17104582, grad/param norm = 7.9541e-01, time/batch = 0.1872s	
447/2700 (epoch 8.278), train_loss = 2.28504305, grad/param norm = 9.4518e-01, time/batch = 0.1819s	
448/2700 (epoch 8.296), train_loss = 2.26028457, grad/param norm = 1.0581e+00, time/batch = 0.1845s	
449/2700 (epoch 8.315), train_loss = 2.30007717, grad/param norm = 1.1974e+00, time/batch = 0.1828s	
450/2700 (epoch 8.333), train_loss = 2.31202446, grad/param norm = 1.3455e+00, time/batch = 0.1836s	
451/2700 (epoch 8.352), train_loss = 2.34531393, grad/param norm = 1.1073e+00, time/batch = 0.1533s	
452/2700 (epoch 8.370), train_loss = 2.28649770, grad/param norm = 7.6146e-01, time/batch = 0.1649s	
453/2700 (epoch 8.389), train_loss = 2.23699394, grad/param norm = 7.1079e-01, time/batch = 0.1879s	
454/2700 (epoch 8.407), train_loss = 2.24056600, grad/param norm = 7.9764e-01, time/batch = 0.1834s	
455/2700 (epoch 8.426), train_loss = 2.25596318, grad/param norm = 9.1078e-01, time/batch = 0.1603s	
456/2700 (epoch 8.444), train_loss = 2.18901402, grad/param norm = 1.2761e+00, time/batch = 0.1615s	
457/2700 (epoch 8.463), train_loss = 2.28987121, grad/param norm = 1.6891e+00, time/batch = 0.1515s	
458/2700 (epoch 8.481), train_loss = 2.35274025, grad/param norm = 1.5333e+00, time/batch = 0.1745s	
459/2700 (epoch 8.500), train_loss = 2.32703841, grad/param norm = 1.2635e+00, time/batch = 0.1775s	
460/2700 (epoch 8.519), train_loss = 2.26470363, grad/param norm = 1.3903e+00, time/batch = 0.1773s	
461/2700 (epoch 8.537), train_loss = 2.29922216, grad/param norm = 1.0585e+00, time/batch = 0.1820s	
462/2700 (epoch 8.556), train_loss = 2.22635350, grad/param norm = 8.8055e-01, time/batch = 0.1836s	
463/2700 (epoch 8.574), train_loss = 2.20274009, grad/param norm = 8.9592e-01, time/batch = 0.1811s	
464/2700 (epoch 8.593), train_loss = 2.20378438, grad/param norm = 9.0638e-01, time/batch = 0.1726s	
465/2700 (epoch 8.611), train_loss = 2.10569010, grad/param norm = 8.0052e-01, time/batch = 0.1800s	
466/2700 (epoch 8.630), train_loss = 2.16904845, grad/param norm = 7.8026e-01, time/batch = 0.1652s	
467/2700 (epoch 8.648), train_loss = 2.21335153, grad/param norm = 8.7122e-01, time/batch = 0.1690s	
468/2700 (epoch 8.667), train_loss = 2.17885877, grad/param norm = 9.2785e-01, time/batch = 0.1777s	
469/2700 (epoch 8.685), train_loss = 2.21324074, grad/param norm = 1.0067e+00, time/batch = 0.1864s	
470/2700 (epoch 8.704), train_loss = 2.19456009, grad/param norm = 1.0252e+00, time/batch = 0.1769s	
471/2700 (epoch 8.722), train_loss = 2.15721259, grad/param norm = 9.4735e-01, time/batch = 0.1549s	
472/2700 (epoch 8.741), train_loss = 2.30004739, grad/param norm = 1.1776e+00, time/batch = 0.1687s	
473/2700 (epoch 8.759), train_loss = 2.28851868, grad/param norm = 1.3492e+00, time/batch = 0.1749s	
474/2700 (epoch 8.778), train_loss = 2.27476733, grad/param norm = 9.9287e-01, time/batch = 0.1840s	
475/2700 (epoch 8.796), train_loss = 2.19945781, grad/param norm = 8.2348e-01, time/batch = 0.1700s	
476/2700 (epoch 8.815), train_loss = 2.21210399, grad/param norm = 8.2896e-01, time/batch = 0.1714s	
477/2700 (epoch 8.833), train_loss = 2.16752594, grad/param norm = 8.4329e-01, time/batch = 0.1586s	
478/2700 (epoch 8.852), train_loss = 2.21445524, grad/param norm = 9.0388e-01, time/batch = 0.1633s	
479/2700 (epoch 8.870), train_loss = 2.19409012, grad/param norm = 1.1186e+00, time/batch = 0.1415s	
480/2700 (epoch 8.889), train_loss = 2.21044454, grad/param norm = 1.4431e+00, time/batch = 0.1658s	
481/2700 (epoch 8.907), train_loss = 2.35319182, grad/param norm = 1.4840e+00, time/batch = 0.1651s	
482/2700 (epoch 8.926), train_loss = 2.25515687, grad/param norm = 1.2325e+00, time/batch = 0.1675s	
483/2700 (epoch 8.944), train_loss = 2.24888377, grad/param norm = 8.5714e-01, time/batch = 0.1701s	
484/2700 (epoch 8.963), train_loss = 2.27458652, grad/param norm = 7.7775e-01, time/batch = 0.1848s	
485/2700 (epoch 8.981), train_loss = 2.26693396, grad/param norm = 1.0328e+00, time/batch = 0.1870s	
486/2700 (epoch 9.000), train_loss = 2.29360563, grad/param norm = 1.1150e+00, time/batch = 0.1825s	
487/2700 (epoch 9.019), train_loss = 2.28704209, grad/param norm = 1.3109e+00, time/batch = 0.1849s	
488/2700 (epoch 9.037), train_loss = 2.29179853, grad/param norm = 1.2732e+00, time/batch = 0.1796s	
489/2700 (epoch 9.056), train_loss = 2.21434509, grad/param norm = 1.0244e+00, time/batch = 0.1845s	
490/2700 (epoch 9.074), train_loss = 2.19651057, grad/param norm = 1.2309e+00, time/batch = 0.1801s	
491/2700 (epoch 9.093), train_loss = 2.22533197, grad/param norm = 9.7637e-01, time/batch = 0.1796s	
492/2700 (epoch 9.111), train_loss = 2.17439948, grad/param norm = 7.8319e-01, time/batch = 0.1643s	
493/2700 (epoch 9.130), train_loss = 2.18831640, grad/param norm = 7.6854e-01, time/batch = 0.1620s	
494/2700 (epoch 9.148), train_loss = 2.15929735, grad/param norm = 1.0574e+00, time/batch = 0.1683s	
495/2700 (epoch 9.167), train_loss = 2.23707363, grad/param norm = 1.1069e+00, time/batch = 0.1732s	
496/2700 (epoch 9.185), train_loss = 2.15810040, grad/param norm = 9.4993e-01, time/batch = 0.1657s	
497/2700 (epoch 9.204), train_loss = 2.18617594, grad/param norm = 7.9277e-01, time/batch = 0.1700s	
498/2700 (epoch 9.222), train_loss = 2.08144711, grad/param norm = 8.1202e-01, time/batch = 0.1757s	
499/2700 (epoch 9.241), train_loss = 2.05964622, grad/param norm = 7.1840e-01, time/batch = 0.1848s	
500/2700 (epoch 9.259), train_loss = 2.09795785, grad/param norm = 8.2160e-01, time/batch = 0.1675s	
501/2700 (epoch 9.278), train_loss = 2.22142865, grad/param norm = 1.0455e+00, time/batch = 0.1725s	
502/2700 (epoch 9.296), train_loss = 2.18540206, grad/param norm = 1.0090e+00, time/batch = 0.1709s	
503/2700 (epoch 9.315), train_loss = 2.21925588, grad/param norm = 1.0947e+00, time/batch = 0.1820s	
504/2700 (epoch 9.333), train_loss = 2.20959402, grad/param norm = 1.0471e+00, time/batch = 0.1840s	
505/2700 (epoch 9.352), train_loss = 2.22371413, grad/param norm = 8.4045e-01, time/batch = 0.1712s	
506/2700 (epoch 9.370), train_loss = 2.21169414, grad/param norm = 9.7310e-01, time/batch = 0.1790s	
507/2700 (epoch 9.389), train_loss = 2.19031830, grad/param norm = 9.0417e-01, time/batch = 0.1629s	
508/2700 (epoch 9.407), train_loss = 2.19439814, grad/param norm = 9.0620e-01, time/batch = 0.1784s	
509/2700 (epoch 9.426), train_loss = 2.20467946, grad/param norm = 8.3289e-01, time/batch = 0.1629s	
510/2700 (epoch 9.444), train_loss = 2.10257390, grad/param norm = 7.4395e-01, time/batch = 0.1776s	
511/2700 (epoch 9.463), train_loss = 2.16072330, grad/param norm = 7.9757e-01, time/batch = 0.1852s	
512/2700 (epoch 9.481), train_loss = 2.23304732, grad/param norm = 8.8462e-01, time/batch = 0.1739s	
513/2700 (epoch 9.500), train_loss = 2.23097173, grad/param norm = 1.0325e+00, time/batch = 0.1701s	
514/2700 (epoch 9.519), train_loss = 2.19102894, grad/param norm = 1.0806e+00, time/batch = 0.1637s	
515/2700 (epoch 9.537), train_loss = 2.21554705, grad/param norm = 8.5881e-01, time/batch = 0.1633s	
516/2700 (epoch 9.556), train_loss = 2.13722418, grad/param norm = 6.4822e-01, time/batch = 0.1439s	
517/2700 (epoch 9.574), train_loss = 2.12521952, grad/param norm = 6.7238e-01, time/batch = 0.1670s	
518/2700 (epoch 9.593), train_loss = 2.12624118, grad/param norm = 7.9014e-01, time/batch = 0.1727s	
519/2700 (epoch 9.611), train_loss = 2.04250947, grad/param norm = 9.8315e-01, time/batch = 0.1555s	
520/2700 (epoch 9.630), train_loss = 2.12840989, grad/param norm = 1.1177e+00, time/batch = 0.1815s	
521/2700 (epoch 9.648), train_loss = 2.16180615, grad/param norm = 1.2903e+00, time/batch = 0.1594s	
522/2700 (epoch 9.667), train_loss = 2.14543229, grad/param norm = 1.5930e+00, time/batch = 0.1614s	
523/2700 (epoch 9.685), train_loss = 2.17789645, grad/param norm = 1.3101e+00, time/batch = 0.1619s	
524/2700 (epoch 9.704), train_loss = 2.14046854, grad/param norm = 1.0973e+00, time/batch = 0.1826s	
525/2700 (epoch 9.722), train_loss = 2.07909916, grad/param norm = 7.3531e-01, time/batch = 0.1855s	
526/2700 (epoch 9.741), train_loss = 2.21639661, grad/param norm = 8.9087e-01, time/batch = 0.1775s	
527/2700 (epoch 9.759), train_loss = 2.20420791, grad/param norm = 1.0922e+00, time/batch = 0.1812s	
528/2700 (epoch 9.778), train_loss = 2.18863711, grad/param norm = 1.2970e+00, time/batch = 0.1785s	
529/2700 (epoch 9.796), train_loss = 2.14808167, grad/param norm = 1.2788e+00, time/batch = 0.1837s	
530/2700 (epoch 9.815), train_loss = 2.17900039, grad/param norm = 1.1454e+00, time/batch = 0.1844s	
531/2700 (epoch 9.833), train_loss = 2.13692271, grad/param norm = 1.2142e+00, time/batch = 0.1864s	
532/2700 (epoch 9.852), train_loss = 2.18974654, grad/param norm = 1.0600e+00, time/batch = 0.1855s	
533/2700 (epoch 9.870), train_loss = 2.13260291, grad/param norm = 9.2815e-01, time/batch = 0.1755s	
534/2700 (epoch 9.889), train_loss = 2.14164009, grad/param norm = 8.6764e-01, time/batch = 0.1769s	
535/2700 (epoch 9.907), train_loss = 2.25514939, grad/param norm = 8.0884e-01, time/batch = 0.1716s	
536/2700 (epoch 9.926), train_loss = 2.15861067, grad/param norm = 7.8846e-01, time/batch = 0.1844s	
537/2700 (epoch 9.944), train_loss = 2.16090016, grad/param norm = 6.1961e-01, time/batch = 0.1874s	
538/2700 (epoch 9.963), train_loss = 2.18986065, grad/param norm = 6.3828e-01, time/batch = 0.1812s	
539/2700 (epoch 9.981), train_loss = 2.17158144, grad/param norm = 1.0642e+00, time/batch = 0.1757s	
decayed learning rate by a factor 0.97 to 0.00194	
540/2700 (epoch 10.000), train_loss = 2.19627454, grad/param norm = 8.3328e-01, time/batch = 0.1778s	
541/2700 (epoch 10.019), train_loss = 2.18603372, grad/param norm = 8.8851e-01, time/batch = 0.1751s	
542/2700 (epoch 10.037), train_loss = 2.19632044, grad/param norm = 8.5923e-01, time/batch = 0.1682s	
543/2700 (epoch 10.056), train_loss = 2.13359113, grad/param norm = 7.1067e-01, time/batch = 0.1709s	
544/2700 (epoch 10.074), train_loss = 2.10272584, grad/param norm = 6.1181e-01, time/batch = 0.1621s	
545/2700 (epoch 10.093), train_loss = 2.13672463, grad/param norm = 6.3481e-01, time/batch = 0.1810s	
546/2700 (epoch 10.111), train_loss = 2.09458562, grad/param norm = 7.8345e-01, time/batch = 0.1821s	
547/2700 (epoch 10.130), train_loss = 2.13612024, grad/param norm = 1.0125e+00, time/batch = 0.1740s	
548/2700 (epoch 10.148), train_loss = 2.11800315, grad/param norm = 1.3999e+00, time/batch = 0.1807s	
549/2700 (epoch 10.167), train_loss = 2.20922990, grad/param norm = 1.2639e+00, time/batch = 0.1810s	
550/2700 (epoch 10.185), train_loss = 2.08101787, grad/param norm = 8.8307e-01, time/batch = 0.1843s	
551/2700 (epoch 10.204), train_loss = 2.09653481, grad/param norm = 5.8596e-01, time/batch = 0.1746s	
552/2700 (epoch 10.222), train_loss = 2.00263363, grad/param norm = 5.7914e-01, time/batch = 0.1829s	
553/2700 (epoch 10.241), train_loss = 1.96882642, grad/param norm = 5.1283e-01, time/batch = 0.1780s	
554/2700 (epoch 10.259), train_loss = 2.01781192, grad/param norm = 6.3362e-01, time/batch = 0.1730s	
555/2700 (epoch 10.278), train_loss = 2.12568125, grad/param norm = 8.0112e-01, time/batch = 0.1763s	
556/2700 (epoch 10.296), train_loss = 2.10307078, grad/param norm = 8.3415e-01, time/batch = 0.1819s	
557/2700 (epoch 10.315), train_loss = 2.13843479, grad/param norm = 8.6270e-01, time/batch = 0.1742s	
558/2700 (epoch 10.333), train_loss = 2.12702781, grad/param norm = 8.2516e-01, time/batch = 0.1848s	
559/2700 (epoch 10.352), train_loss = 2.14436454, grad/param norm = 7.1346e-01, time/batch = 0.1890s	
560/2700 (epoch 10.370), train_loss = 2.13418040, grad/param norm = 6.6410e-01, time/batch = 0.1797s	
561/2700 (epoch 10.389), train_loss = 2.10904654, grad/param norm = 7.3950e-01, time/batch = 0.1660s	
562/2700 (epoch 10.407), train_loss = 2.11884365, grad/param norm = 7.2247e-01, time/batch = 0.1543s	
563/2700 (epoch 10.426), train_loss = 2.13295813, grad/param norm = 6.2384e-01, time/batch = 0.1513s	
564/2700 (epoch 10.444), train_loss = 2.04714043, grad/param norm = 7.9251e-01, time/batch = 0.1528s	
565/2700 (epoch 10.463), train_loss = 2.12044305, grad/param norm = 9.8366e-01, time/batch = 0.1589s	
566/2700 (epoch 10.481), train_loss = 2.19244077, grad/param norm = 1.2304e+00, time/batch = 0.1691s	
567/2700 (epoch 10.500), train_loss = 2.19820777, grad/param norm = 1.1373e+00, time/batch = 0.1556s	
568/2700 (epoch 10.519), train_loss = 2.14704818, grad/param norm = 1.1667e+00, time/batch = 0.1822s	
569/2700 (epoch 10.537), train_loss = 2.17281620, grad/param norm = 1.0295e+00, time/batch = 0.1827s	
570/2700 (epoch 10.556), train_loss = 2.11500362, grad/param norm = 1.1096e+00, time/batch = 0.1676s	
571/2700 (epoch 10.574), train_loss = 2.10090150, grad/param norm = 1.1617e+00, time/batch = 0.1739s	
572/2700 (epoch 10.593), train_loss = 2.08219102, grad/param norm = 9.8601e-01, time/batch = 0.1696s	
573/2700 (epoch 10.611), train_loss = 1.97309076, grad/param norm = 9.0329e-01, time/batch = 0.1883s	
574/2700 (epoch 10.630), train_loss = 2.02883196, grad/param norm = 8.4399e-01, time/batch = 0.1863s	
575/2700 (epoch 10.648), train_loss = 2.06806103, grad/param norm = 7.8269e-01, time/batch = 0.1865s	
576/2700 (epoch 10.667), train_loss = 2.02328641, grad/param norm = 8.0195e-01, time/batch = 0.1801s	
577/2700 (epoch 10.685), train_loss = 2.06505537, grad/param norm = 8.5065e-01, time/batch = 0.1820s	
578/2700 (epoch 10.704), train_loss = 2.04558338, grad/param norm = 7.8525e-01, time/batch = 0.1828s	
579/2700 (epoch 10.722), train_loss = 2.01715291, grad/param norm = 7.8821e-01, time/batch = 0.1858s	
580/2700 (epoch 10.741), train_loss = 2.14060404, grad/param norm = 8.4660e-01, time/batch = 0.2036s	
581/2700 (epoch 10.759), train_loss = 2.12899669, grad/param norm = 9.1693e-01, time/batch = 0.1764s	
582/2700 (epoch 10.778), train_loss = 2.12092420, grad/param norm = 9.7351e-01, time/batch = 0.1773s	
583/2700 (epoch 10.796), train_loss = 2.07916828, grad/param norm = 9.7114e-01, time/batch = 0.1703s	
584/2700 (epoch 10.815), train_loss = 2.10477831, grad/param norm = 9.9739e-01, time/batch = 0.1668s	
585/2700 (epoch 10.833), train_loss = 2.06758215, grad/param norm = 1.0610e+00, time/batch = 0.1675s	
586/2700 (epoch 10.852), train_loss = 2.11099592, grad/param norm = 1.0015e+00, time/batch = 0.1776s	
587/2700 (epoch 10.870), train_loss = 2.05894144, grad/param norm = 8.5842e-01, time/batch = 0.1789s	
588/2700 (epoch 10.889), train_loss = 2.06294590, grad/param norm = 7.4687e-01, time/batch = 0.1513s	
589/2700 (epoch 10.907), train_loss = 2.17584554, grad/param norm = 7.9466e-01, time/batch = 0.1684s	
590/2700 (epoch 10.926), train_loss = 2.09713433, grad/param norm = 8.5284e-01, time/batch = 0.1698s	
591/2700 (epoch 10.944), train_loss = 2.10721648, grad/param norm = 8.1523e-01, time/batch = 0.1617s	
592/2700 (epoch 10.963), train_loss = 2.16102381, grad/param norm = 9.8717e-01, time/batch = 0.1812s	
593/2700 (epoch 10.981), train_loss = 2.16007786, grad/param norm = 1.3514e+00, time/batch = 0.1963s	
decayed learning rate by a factor 0.97 to 0.0018818	
594/2700 (epoch 11.000), train_loss = 2.19864403, grad/param norm = 1.3606e+00, time/batch = 0.1869s	
595/2700 (epoch 11.019), train_loss = 2.15864875, grad/param norm = 1.0129e+00, time/batch = 0.1668s	
596/2700 (epoch 11.037), train_loss = 2.13980723, grad/param norm = 7.4931e-01, time/batch = 0.1811s	
597/2700 (epoch 11.056), train_loss = 2.06262635, grad/param norm = 7.0714e-01, time/batch = 0.1755s	
598/2700 (epoch 11.074), train_loss = 2.05358581, grad/param norm = 8.8740e-01, time/batch = 0.1846s	
599/2700 (epoch 11.093), train_loss = 2.08109231, grad/param norm = 7.2225e-01, time/batch = 0.1830s	
600/2700 (epoch 11.111), train_loss = 2.02417512, grad/param norm = 5.7302e-01, time/batch = 0.1850s	
601/2700 (epoch 11.130), train_loss = 2.03737250, grad/param norm = 4.9032e-01, time/batch = 0.1698s	
602/2700 (epoch 11.148), train_loss = 2.00370649, grad/param norm = 6.0497e-01, time/batch = 0.1663s	
603/2700 (epoch 11.167), train_loss = 2.07835033, grad/param norm = 7.0628e-01, time/batch = 0.1634s	
604/2700 (epoch 11.185), train_loss = 1.99907064, grad/param norm = 6.7944e-01, time/batch = 0.1706s	
605/2700 (epoch 11.204), train_loss = 2.04833820, grad/param norm = 6.7729e-01, time/batch = 0.1574s	
606/2700 (epoch 11.222), train_loss = 1.96226310, grad/param norm = 8.2759e-01, time/batch = 0.1843s	
607/2700 (epoch 11.241), train_loss = 1.92496275, grad/param norm = 8.2767e-01, time/batch = 0.1709s	
608/2700 (epoch 11.259), train_loss = 1.97345744, grad/param norm = 7.2468e-01, time/batch = 0.1690s	
609/2700 (epoch 11.278), train_loss = 2.06640159, grad/param norm = 7.0428e-01, time/batch = 0.1626s	
610/2700 (epoch 11.296), train_loss = 2.04742268, grad/param norm = 7.6302e-01, time/batch = 0.1440s	
611/2700 (epoch 11.315), train_loss = 2.08967764, grad/param norm = 9.0908e-01, time/batch = 0.1728s	
612/2700 (epoch 11.333), train_loss = 2.08867659, grad/param norm = 8.2963e-01, time/batch = 0.1704s	
613/2700 (epoch 11.352), train_loss = 2.10084178, grad/param norm = 9.9680e-01, time/batch = 0.1749s	
614/2700 (epoch 11.370), train_loss = 2.10465870, grad/param norm = 1.1201e+00, time/batch = 0.1706s	
615/2700 (epoch 11.389), train_loss = 2.06731700, grad/param norm = 7.7445e-01, time/batch = 0.1842s	
616/2700 (epoch 11.407), train_loss = 2.06294848, grad/param norm = 6.1181e-01, time/batch = 0.1738s	
617/2700 (epoch 11.426), train_loss = 2.07815176, grad/param norm = 6.3359e-01, time/batch = 0.1836s	
618/2700 (epoch 11.444), train_loss = 1.97954844, grad/param norm = 5.3202e-01, time/batch = 0.1842s	
619/2700 (epoch 11.463), train_loss = 2.03474336, grad/param norm = 5.6525e-01, time/batch = 0.1792s	
620/2700 (epoch 11.481), train_loss = 2.10153137, grad/param norm = 6.4278e-01, time/batch = 0.1827s	
621/2700 (epoch 11.500), train_loss = 2.08760989, grad/param norm = 7.4532e-01, time/batch = 0.1811s	
622/2700 (epoch 11.519), train_loss = 2.05100265, grad/param norm = 7.9019e-01, time/batch = 0.1848s	
623/2700 (epoch 11.537), train_loss = 2.09096170, grad/param norm = 7.9229e-01, time/batch = 0.1775s	
624/2700 (epoch 11.556), train_loss = 2.01389669, grad/param norm = 8.0353e-01, time/batch = 0.1553s	
625/2700 (epoch 11.574), train_loss = 2.02210309, grad/param norm = 8.1489e-01, time/batch = 0.1787s	
626/2700 (epoch 11.593), train_loss = 2.00845453, grad/param norm = 8.3849e-01, time/batch = 0.1797s	
627/2700 (epoch 11.611), train_loss = 1.91043160, grad/param norm = 7.5561e-01, time/batch = 0.1688s	
628/2700 (epoch 11.630), train_loss = 1.96343437, grad/param norm = 6.6590e-01, time/batch = 0.1605s	
629/2700 (epoch 11.648), train_loss = 2.02267465, grad/param norm = 8.0635e-01, time/batch = 0.1441s	
630/2700 (epoch 11.667), train_loss = 1.99611238, grad/param norm = 1.0242e+00, time/batch = 0.1679s	
631/2700 (epoch 11.685), train_loss = 2.07011234, grad/param norm = 1.1179e+00, time/batch = 0.1717s	
632/2700 (epoch 11.704), train_loss = 2.03916878, grad/param norm = 1.0701e+00, time/batch = 0.1701s	
633/2700 (epoch 11.722), train_loss = 1.99484477, grad/param norm = 9.9638e-01, time/batch = 0.1644s	
634/2700 (epoch 11.741), train_loss = 2.08455983, grad/param norm = 8.1539e-01, time/batch = 0.1674s	
635/2700 (epoch 11.759), train_loss = 2.07012141, grad/param norm = 8.2824e-01, time/batch = 0.1607s	
636/2700 (epoch 11.778), train_loss = 2.06775073, grad/param norm = 9.9035e-01, time/batch = 0.1702s	
637/2700 (epoch 11.796), train_loss = 2.02163444, grad/param norm = 8.4263e-01, time/batch = 0.1756s	
638/2700 (epoch 11.815), train_loss = 2.03946091, grad/param norm = 8.0922e-01, time/batch = 0.1829s	
639/2700 (epoch 11.833), train_loss = 2.00079741, grad/param norm = 7.4338e-01, time/batch = 0.1692s	
640/2700 (epoch 11.852), train_loss = 2.03215404, grad/param norm = 6.4145e-01, time/batch = 0.1744s	
641/2700 (epoch 11.870), train_loss = 1.99492059, grad/param norm = 5.3005e-01, time/batch = 0.1733s	
642/2700 (epoch 11.889), train_loss = 2.00201818, grad/param norm = 5.3650e-01, time/batch = 0.1775s	
643/2700 (epoch 11.907), train_loss = 2.12419488, grad/param norm = 7.0424e-01, time/batch = 0.1702s	
644/2700 (epoch 11.926), train_loss = 2.03460601, grad/param norm = 8.0017e-01, time/batch = 0.1865s	
645/2700 (epoch 11.944), train_loss = 2.04235554, grad/param norm = 7.0542e-01, time/batch = 0.1798s	
646/2700 (epoch 11.963), train_loss = 2.07697114, grad/param norm = 7.3979e-01, time/batch = 0.1816s	
647/2700 (epoch 11.981), train_loss = 2.05677210, grad/param norm = 7.9713e-01, time/batch = 0.1871s	
decayed learning rate by a factor 0.97 to 0.001825346	
648/2700 (epoch 12.000), train_loss = 2.07078672, grad/param norm = 6.9769e-01, time/batch = 0.1726s	
649/2700 (epoch 12.019), train_loss = 2.05298278, grad/param norm = 8.5824e-01, time/batch = 0.1853s	
650/2700 (epoch 12.037), train_loss = 2.07520247, grad/param norm = 9.9466e-01, time/batch = 0.1834s	
651/2700 (epoch 12.056), train_loss = 2.02981015, grad/param norm = 1.0807e+00, time/batch = 0.1680s	
652/2700 (epoch 12.074), train_loss = 2.03748582, grad/param norm = 1.2669e+00, time/batch = 0.1652s	
653/2700 (epoch 12.093), train_loss = 2.06874526, grad/param norm = 1.0471e+00, time/batch = 0.1704s	
654/2700 (epoch 12.111), train_loss = 2.01368670, grad/param norm = 9.1068e-01, time/batch = 0.1780s	
655/2700 (epoch 12.130), train_loss = 2.02249681, grad/param norm = 8.1095e-01, time/batch = 0.1843s	
656/2700 (epoch 12.148), train_loss = 1.96645370, grad/param norm = 7.3831e-01, time/batch = 0.1842s	
657/2700 (epoch 12.167), train_loss = 2.03032322, grad/param norm = 6.5967e-01, time/batch = 0.1803s	
658/2700 (epoch 12.185), train_loss = 1.93833896, grad/param norm = 5.3352e-01, time/batch = 0.1842s	
659/2700 (epoch 12.204), train_loss = 1.99412107, grad/param norm = 5.7104e-01, time/batch = 0.1829s	
660/2700 (epoch 12.222), train_loss = 1.90899929, grad/param norm = 6.9889e-01, time/batch = 0.1837s	
661/2700 (epoch 12.241), train_loss = 1.86066762, grad/param norm = 6.8245e-01, time/batch = 0.1581s	
662/2700 (epoch 12.259), train_loss = 1.91129598, grad/param norm = 5.4906e-01, time/batch = 0.1620s	
663/2700 (epoch 12.278), train_loss = 1.99993578, grad/param norm = 4.7902e-01, time/batch = 0.1463s	
664/2700 (epoch 12.296), train_loss = 1.97079904, grad/param norm = 4.7303e-01, time/batch = 0.1845s	
665/2700 (epoch 12.315), train_loss = 2.01305917, grad/param norm = 4.9620e-01, time/batch = 0.1831s	
666/2700 (epoch 12.333), train_loss = 2.00307186, grad/param norm = 4.5580e-01, time/batch = 0.1843s	
667/2700 (epoch 12.352), train_loss = 2.01769198, grad/param norm = 5.6484e-01, time/batch = 0.1778s	
668/2700 (epoch 12.370), train_loss = 2.02568756, grad/param norm = 5.9618e-01, time/batch = 0.1843s	
669/2700 (epoch 12.389), train_loss = 2.00574963, grad/param norm = 6.4729e-01, time/batch = 0.1819s	
670/2700 (epoch 12.407), train_loss = 2.01749782, grad/param norm = 6.1303e-01, time/batch = 0.1808s	
671/2700 (epoch 12.426), train_loss = 2.03925264, grad/param norm = 7.8225e-01, time/batch = 0.1613s	
672/2700 (epoch 12.444), train_loss = 1.94244117, grad/param norm = 7.5119e-01, time/batch = 0.1376s	
673/2700 (epoch 12.463), train_loss = 1.99390823, grad/param norm = 6.8802e-01, time/batch = 0.1455s	
674/2700 (epoch 12.481), train_loss = 2.05899288, grad/param norm = 7.7345e-01, time/batch = 0.1736s	
675/2700 (epoch 12.500), train_loss = 2.05436022, grad/param norm = 1.0075e+00, time/batch = 0.1788s	
676/2700 (epoch 12.519), train_loss = 2.03334522, grad/param norm = 1.1237e+00, time/batch = 0.1867s	
677/2700 (epoch 12.537), train_loss = 2.07773747, grad/param norm = 1.0298e+00, time/batch = 0.1597s	
678/2700 (epoch 12.556), train_loss = 1.97480376, grad/param norm = 8.2555e-01, time/batch = 0.1567s	
679/2700 (epoch 12.574), train_loss = 1.97038138, grad/param norm = 7.8485e-01, time/batch = 0.1616s	
680/2700 (epoch 12.593), train_loss = 1.95253215, grad/param norm = 7.5256e-01, time/batch = 0.1700s	
681/2700 (epoch 12.611), train_loss = 1.85694333, grad/param norm = 7.3929e-01, time/batch = 0.1786s	
682/2700 (epoch 12.630), train_loss = 1.92114491, grad/param norm = 8.6598e-01, time/batch = 0.1733s	
683/2700 (epoch 12.648), train_loss = 1.97518759, grad/param norm = 8.1876e-01, time/batch = 0.1770s	
684/2700 (epoch 12.667), train_loss = 1.91772460, grad/param norm = 7.4060e-01, time/batch = 0.1743s	
685/2700 (epoch 12.685), train_loss = 1.96029573, grad/param norm = 7.3484e-01, time/batch = 0.1727s	
686/2700 (epoch 12.704), train_loss = 1.95911876, grad/param norm = 7.6391e-01, time/batch = 0.1660s	
687/2700 (epoch 12.722), train_loss = 1.92599918, grad/param norm = 6.8815e-01, time/batch = 0.1771s	
688/2700 (epoch 12.741), train_loss = 2.01547115, grad/param norm = 6.3537e-01, time/batch = 0.1701s	
689/2700 (epoch 12.759), train_loss = 2.01912941, grad/param norm = 8.4208e-01, time/batch = 0.1807s	
690/2700 (epoch 12.778), train_loss = 2.02372643, grad/param norm = 1.0180e+00, time/batch = 0.1842s	
691/2700 (epoch 12.796), train_loss = 1.99228620, grad/param norm = 9.3388e-01, time/batch = 0.1804s	
692/2700 (epoch 12.815), train_loss = 2.00369982, grad/param norm = 8.9588e-01, time/batch = 0.1670s	
693/2700 (epoch 12.833), train_loss = 1.96692964, grad/param norm = 8.7206e-01, time/batch = 0.1785s	
694/2700 (epoch 12.852), train_loss = 1.99453752, grad/param norm = 7.2351e-01, time/batch = 0.1757s	
695/2700 (epoch 12.870), train_loss = 1.95056194, grad/param norm = 5.7032e-01, time/batch = 0.1682s	
696/2700 (epoch 12.889), train_loss = 1.95759619, grad/param norm = 5.3558e-01, time/batch = 0.1652s	
697/2700 (epoch 12.907), train_loss = 2.07823384, grad/param norm = 5.9861e-01, time/batch = 0.1694s	
698/2700 (epoch 12.926), train_loss = 1.97588032, grad/param norm = 6.5744e-01, time/batch = 0.1833s	
699/2700 (epoch 12.944), train_loss = 1.98197905, grad/param norm = 6.1232e-01, time/batch = 0.1816s	
700/2700 (epoch 12.963), train_loss = 2.02056773, grad/param norm = 6.0665e-01, time/batch = 0.1768s	
701/2700 (epoch 12.981), train_loss = 1.99783644, grad/param norm = 6.6020e-01, time/batch = 0.1799s	
decayed learning rate by a factor 0.97 to 0.00177058562	
702/2700 (epoch 13.000), train_loss = 2.03511475, grad/param norm = 9.2224e-01, time/batch = 0.1785s	
703/2700 (epoch 13.019), train_loss = 2.01794828, grad/param norm = 9.9716e-01, time/batch = 0.1640s	
704/2700 (epoch 13.037), train_loss = 2.02840585, grad/param norm = 6.8628e-01, time/batch = 0.1594s	
705/2700 (epoch 13.056), train_loss = 1.96546151, grad/param norm = 7.6299e-01, time/batch = 0.1842s	
706/2700 (epoch 13.074), train_loss = 1.95676448, grad/param norm = 8.3994e-01, time/batch = 0.1812s	
707/2700 (epoch 13.093), train_loss = 1.98011433, grad/param norm = 7.1039e-01, time/batch = 0.1802s	
708/2700 (epoch 13.111), train_loss = 1.93018768, grad/param norm = 6.3026e-01, time/batch = 0.1668s	
709/2700 (epoch 13.130), train_loss = 1.95583449, grad/param norm = 5.3228e-01, time/batch = 0.1754s	
710/2700 (epoch 13.148), train_loss = 1.90697448, grad/param norm = 5.5886e-01, time/batch = 0.1805s	
711/2700 (epoch 13.167), train_loss = 1.97907504, grad/param norm = 6.0833e-01, time/batch = 0.1704s	
712/2700 (epoch 13.185), train_loss = 1.89666514, grad/param norm = 6.1894e-01, time/batch = 0.1721s	
713/2700 (epoch 13.204), train_loss = 1.96124030, grad/param norm = 7.6638e-01, time/batch = 0.1709s	
714/2700 (epoch 13.222), train_loss = 1.89458993, grad/param norm = 9.9763e-01, time/batch = 0.1816s	
715/2700 (epoch 13.241), train_loss = 1.83425427, grad/param norm = 9.3156e-01, time/batch = 0.1812s	
716/2700 (epoch 13.259), train_loss = 1.87659673, grad/param norm = 6.5214e-01, time/batch = 0.1828s	
717/2700 (epoch 13.278), train_loss = 1.95799631, grad/param norm = 5.1920e-01, time/batch = 0.1797s	
718/2700 (epoch 13.296), train_loss = 1.93246442, grad/param norm = 5.1961e-01, time/batch = 0.1808s	
719/2700 (epoch 13.315), train_loss = 1.96984737, grad/param norm = 5.5014e-01, time/batch = 0.1817s	
720/2700 (epoch 13.333), train_loss = 1.95855244, grad/param norm = 4.7303e-01, time/batch = 0.1806s	
721/2700 (epoch 13.352), train_loss = 1.97793707, grad/param norm = 6.9458e-01, time/batch = 0.1513s	
722/2700 (epoch 13.370), train_loss = 1.98792639, grad/param norm = 6.9069e-01, time/batch = 0.1741s	
723/2700 (epoch 13.389), train_loss = 1.95325346, grad/param norm = 6.2722e-01, time/batch = 0.1615s	
724/2700 (epoch 13.407), train_loss = 1.96058304, grad/param norm = 5.1636e-01, time/batch = 0.1842s	
725/2700 (epoch 13.426), train_loss = 1.97874726, grad/param norm = 5.0458e-01, time/batch = 0.1828s	
726/2700 (epoch 13.444), train_loss = 1.88615746, grad/param norm = 5.2229e-01, time/batch = 0.1773s	
727/2700 (epoch 13.463), train_loss = 1.95544305, grad/param norm = 6.8707e-01, time/batch = 0.1483s	
728/2700 (epoch 13.481), train_loss = 2.01413652, grad/param norm = 6.6876e-01, time/batch = 0.1777s	
729/2700 (epoch 13.500), train_loss = 1.98847636, grad/param norm = 7.1372e-01, time/batch = 0.1789s	
730/2700 (epoch 13.519), train_loss = 1.96586259, grad/param norm = 8.0108e-01, time/batch = 0.1734s	
731/2700 (epoch 13.537), train_loss = 2.00691623, grad/param norm = 8.7706e-01, time/batch = 0.1587s	
732/2700 (epoch 13.556), train_loss = 1.93203773, grad/param norm = 8.1246e-01, time/batch = 0.1767s	
733/2700 (epoch 13.574), train_loss = 1.92875963, grad/param norm = 8.1340e-01, time/batch = 0.1846s	
734/2700 (epoch 13.593), train_loss = 1.91277138, grad/param norm = 7.7987e-01, time/batch = 0.1783s	
735/2700 (epoch 13.611), train_loss = 1.81841066, grad/param norm = 7.6978e-01, time/batch = 0.1698s	
736/2700 (epoch 13.630), train_loss = 1.86708780, grad/param norm = 6.5040e-01, time/batch = 0.1417s	
737/2700 (epoch 13.648), train_loss = 1.91866975, grad/param norm = 5.8343e-01, time/batch = 0.1699s	
738/2700 (epoch 13.667), train_loss = 1.86001281, grad/param norm = 5.5518e-01, time/batch = 0.1725s	
739/2700 (epoch 13.685), train_loss = 1.90127568, grad/param norm = 6.3138e-01, time/batch = 0.1746s	
740/2700 (epoch 13.704), train_loss = 1.90650208, grad/param norm = 6.7121e-01, time/batch = 0.1797s	
741/2700 (epoch 13.722), train_loss = 1.88257455, grad/param norm = 7.6694e-01, time/batch = 0.1692s	
742/2700 (epoch 13.741), train_loss = 1.98985795, grad/param norm = 1.0185e+00, time/batch = 0.1648s	
743/2700 (epoch 13.759), train_loss = 2.00895286, grad/param norm = 1.2702e+00, time/batch = 0.1843s	
744/2700 (epoch 13.778), train_loss = 2.00508612, grad/param norm = 1.0353e+00, time/batch = 0.1846s	
745/2700 (epoch 13.796), train_loss = 1.94829720, grad/param norm = 9.0969e-01, time/batch = 0.1771s	
746/2700 (epoch 13.815), train_loss = 1.95385212, grad/param norm = 7.8976e-01, time/batch = 0.1810s	
747/2700 (epoch 13.833), train_loss = 1.91021326, grad/param norm = 6.8563e-01, time/batch = 0.1805s	
748/2700 (epoch 13.852), train_loss = 1.93131147, grad/param norm = 5.7094e-01, time/batch = 0.1832s	
749/2700 (epoch 13.870), train_loss = 1.89702432, grad/param norm = 4.5415e-01, time/batch = 0.1820s	
750/2700 (epoch 13.889), train_loss = 1.91380564, grad/param norm = 4.7918e-01, time/batch = 0.1763s	
751/2700 (epoch 13.907), train_loss = 2.03212060, grad/param norm = 5.5092e-01, time/batch = 0.1709s	
752/2700 (epoch 13.926), train_loss = 1.92879734, grad/param norm = 5.4896e-01, time/batch = 0.1681s	
753/2700 (epoch 13.944), train_loss = 1.92993506, grad/param norm = 4.9729e-01, time/batch = 0.1766s	
754/2700 (epoch 13.963), train_loss = 1.97171532, grad/param norm = 5.7926e-01, time/batch = 0.1839s	
755/2700 (epoch 13.981), train_loss = 1.94786508, grad/param norm = 6.5526e-01, time/batch = 0.1812s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
756/2700 (epoch 14.000), train_loss = 1.98457101, grad/param norm = 7.2788e-01, time/batch = 0.1844s	
757/2700 (epoch 14.019), train_loss = 1.97181417, grad/param norm = 7.9640e-01, time/batch = 0.1829s	
758/2700 (epoch 14.037), train_loss = 1.97999515, grad/param norm = 6.5240e-01, time/batch = 0.1838s	
759/2700 (epoch 14.056), train_loss = 1.89752671, grad/param norm = 5.0081e-01, time/batch = 0.1825s	
760/2700 (epoch 14.074), train_loss = 1.88593926, grad/param norm = 5.6852e-01, time/batch = 0.1785s	
761/2700 (epoch 14.093), train_loss = 1.91677100, grad/param norm = 5.5737e-01, time/batch = 0.1550s	
762/2700 (epoch 14.111), train_loss = 1.87326725, grad/param norm = 6.0878e-01, time/batch = 0.1717s	
763/2700 (epoch 14.130), train_loss = 1.91207802, grad/param norm = 6.3310e-01, time/batch = 0.1804s	
764/2700 (epoch 14.148), train_loss = 1.86762668, grad/param norm = 7.3418e-01, time/batch = 0.1640s	
765/2700 (epoch 14.167), train_loss = 1.94765986, grad/param norm = 7.3206e-01, time/batch = 0.1673s	
766/2700 (epoch 14.185), train_loss = 1.85565146, grad/param norm = 6.3132e-01, time/batch = 0.1674s	
767/2700 (epoch 14.204), train_loss = 1.91002250, grad/param norm = 5.3605e-01, time/batch = 0.1668s	
768/2700 (epoch 14.222), train_loss = 1.83323136, grad/param norm = 5.5129e-01, time/batch = 0.1668s	
769/2700 (epoch 14.241), train_loss = 1.76971755, grad/param norm = 5.1246e-01, time/batch = 0.1672s	
770/2700 (epoch 14.259), train_loss = 1.84253408, grad/param norm = 5.7316e-01, time/batch = 0.1576s	
771/2700 (epoch 14.278), train_loss = 1.94235773, grad/param norm = 8.1019e-01, time/batch = 0.1540s	
772/2700 (epoch 14.296), train_loss = 1.93086017, grad/param norm = 1.0635e+00, time/batch = 0.1704s	
773/2700 (epoch 14.315), train_loss = 1.97178352, grad/param norm = 8.9921e-01, time/batch = 0.1614s	
774/2700 (epoch 14.333), train_loss = 1.93668585, grad/param norm = 6.4646e-01, time/batch = 0.1652s	
775/2700 (epoch 14.352), train_loss = 1.93251942, grad/param norm = 6.0093e-01, time/batch = 0.1616s	
776/2700 (epoch 14.370), train_loss = 1.95034919, grad/param norm = 7.3344e-01, time/batch = 0.1604s	
777/2700 (epoch 14.389), train_loss = 1.92201408, grad/param norm = 7.0159e-01, time/batch = 0.1601s	
778/2700 (epoch 14.407), train_loss = 1.93655935, grad/param norm = 6.5139e-01, time/batch = 0.1591s	
779/2700 (epoch 14.426), train_loss = 1.95200595, grad/param norm = 5.6438e-01, time/batch = 0.1618s	
780/2700 (epoch 14.444), train_loss = 1.84695578, grad/param norm = 5.5355e-01, time/batch = 0.1558s	
781/2700 (epoch 14.463), train_loss = 1.91811112, grad/param norm = 6.6294e-01, time/batch = 0.1577s	
782/2700 (epoch 14.481), train_loss = 1.96057377, grad/param norm = 6.7252e-01, time/batch = 0.1625s	
783/2700 (epoch 14.500), train_loss = 1.94744958, grad/param norm = 7.6391e-01, time/batch = 0.1581s	
784/2700 (epoch 14.519), train_loss = 1.91939581, grad/param norm = 7.5260e-01, time/batch = 0.1674s	
785/2700 (epoch 14.537), train_loss = 1.94432568, grad/param norm = 6.3891e-01, time/batch = 0.1717s	
786/2700 (epoch 14.556), train_loss = 1.86987317, grad/param norm = 6.1005e-01, time/batch = 0.1700s	
787/2700 (epoch 14.574), train_loss = 1.87334404, grad/param norm = 6.8865e-01, time/batch = 0.1689s	
788/2700 (epoch 14.593), train_loss = 1.86593153, grad/param norm = 7.0682e-01, time/batch = 0.1681s	
789/2700 (epoch 14.611), train_loss = 1.77846464, grad/param norm = 7.0981e-01, time/batch = 0.1658s	
790/2700 (epoch 14.630), train_loss = 1.83418322, grad/param norm = 6.6255e-01, time/batch = 0.1475s	
791/2700 (epoch 14.648), train_loss = 1.88429848, grad/param norm = 6.7741e-01, time/batch = 0.1661s	
792/2700 (epoch 14.667), train_loss = 1.83410560, grad/param norm = 8.1823e-01, time/batch = 0.1525s	
793/2700 (epoch 14.685), train_loss = 1.88801334, grad/param norm = 9.1920e-01, time/batch = 0.1645s	
794/2700 (epoch 14.704), train_loss = 1.88427443, grad/param norm = 7.7664e-01, time/batch = 0.1697s	
795/2700 (epoch 14.722), train_loss = 1.84416028, grad/param norm = 7.0707e-01, time/batch = 0.1758s	
796/2700 (epoch 14.741), train_loss = 1.93115530, grad/param norm = 7.2793e-01, time/batch = 0.1844s	
797/2700 (epoch 14.759), train_loss = 1.92951616, grad/param norm = 8.4780e-01, time/batch = 0.1860s	
798/2700 (epoch 14.778), train_loss = 1.93921320, grad/param norm = 7.9853e-01, time/batch = 0.1856s	
799/2700 (epoch 14.796), train_loss = 1.89125597, grad/param norm = 6.9250e-01, time/batch = 0.1778s	
800/2700 (epoch 14.815), train_loss = 1.89737996, grad/param norm = 6.2115e-01, time/batch = 0.1546s	
801/2700 (epoch 14.833), train_loss = 1.86276583, grad/param norm = 6.1634e-01, time/batch = 0.1587s	
802/2700 (epoch 14.852), train_loss = 1.88781797, grad/param norm = 5.8382e-01, time/batch = 0.1755s	
803/2700 (epoch 14.870), train_loss = 1.86313643, grad/param norm = 5.1891e-01, time/batch = 0.1785s	
804/2700 (epoch 14.889), train_loss = 1.88737208, grad/param norm = 5.7593e-01, time/batch = 0.1829s	
805/2700 (epoch 14.907), train_loss = 2.01397439, grad/param norm = 7.2180e-01, time/batch = 0.1809s	
806/2700 (epoch 14.926), train_loss = 1.90943803, grad/param norm = 7.5909e-01, time/batch = 0.1823s	
807/2700 (epoch 14.944), train_loss = 1.90914360, grad/param norm = 8.3711e-01, time/batch = 0.1778s	
808/2700 (epoch 14.963), train_loss = 1.94906208, grad/param norm = 8.1533e-01, time/batch = 0.1732s	
809/2700 (epoch 14.981), train_loss = 1.91427477, grad/param norm = 6.7533e-01, time/batch = 0.1673s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
810/2700 (epoch 15.000), train_loss = 1.95884633, grad/param norm = 7.3115e-01, time/batch = 0.1859s	
811/2700 (epoch 15.019), train_loss = 1.92748728, grad/param norm = 6.9452e-01, time/batch = 0.1795s	
812/2700 (epoch 15.037), train_loss = 1.93730861, grad/param norm = 5.4165e-01, time/batch = 0.1692s	
813/2700 (epoch 15.056), train_loss = 1.86848094, grad/param norm = 5.9139e-01, time/batch = 0.1599s	
814/2700 (epoch 15.074), train_loss = 1.87035419, grad/param norm = 7.4880e-01, time/batch = 0.1681s	
815/2700 (epoch 15.093), train_loss = 1.90374627, grad/param norm = 8.0999e-01, time/batch = 0.1728s	
816/2700 (epoch 15.111), train_loss = 1.85311360, grad/param norm = 7.8368e-01, time/batch = 0.1854s	
817/2700 (epoch 15.130), train_loss = 1.88951525, grad/param norm = 6.7248e-01, time/batch = 0.1774s	
818/2700 (epoch 15.148), train_loss = 1.82126439, grad/param norm = 5.7038e-01, time/batch = 0.1714s	
819/2700 (epoch 15.167), train_loss = 1.89592752, grad/param norm = 5.5472e-01, time/batch = 0.1792s	
820/2700 (epoch 15.185), train_loss = 1.80736327, grad/param norm = 5.0220e-01, time/batch = 0.1818s	
821/2700 (epoch 15.204), train_loss = 1.86696883, grad/param norm = 5.3554e-01, time/batch = 0.1862s	
822/2700 (epoch 15.222), train_loss = 1.80162553, grad/param norm = 6.3398e-01, time/batch = 0.1874s	
823/2700 (epoch 15.241), train_loss = 1.73171952, grad/param norm = 5.7692e-01, time/batch = 0.1670s	
824/2700 (epoch 15.259), train_loss = 1.79506877, grad/param norm = 5.0920e-01, time/batch = 0.1667s	
825/2700 (epoch 15.278), train_loss = 1.88391968, grad/param norm = 5.2455e-01, time/batch = 0.1697s	
826/2700 (epoch 15.296), train_loss = 1.85692081, grad/param norm = 5.4233e-01, time/batch = 0.1741s	
827/2700 (epoch 15.315), train_loss = 1.89321164, grad/param norm = 5.5463e-01, time/batch = 0.1735s	
828/2700 (epoch 15.333), train_loss = 1.87751729, grad/param norm = 5.5688e-01, time/batch = 0.1547s	
829/2700 (epoch 15.352), train_loss = 1.89961565, grad/param norm = 6.7050e-01, time/batch = 0.1814s	
830/2700 (epoch 15.370), train_loss = 1.91561225, grad/param norm = 6.3591e-01, time/batch = 0.1703s	
831/2700 (epoch 15.389), train_loss = 1.87925884, grad/param norm = 6.0367e-01, time/batch = 0.1777s	
832/2700 (epoch 15.407), train_loss = 1.89126593, grad/param norm = 5.4561e-01, time/batch = 0.1653s	
833/2700 (epoch 15.426), train_loss = 1.90952277, grad/param norm = 7.0688e-01, time/batch = 0.1712s	
834/2700 (epoch 15.444), train_loss = 1.82190289, grad/param norm = 6.7393e-01, time/batch = 0.1782s	
835/2700 (epoch 15.463), train_loss = 1.87334097, grad/param norm = 5.8026e-01, time/batch = 0.1694s	
836/2700 (epoch 15.481), train_loss = 1.91864817, grad/param norm = 5.7955e-01, time/batch = 0.1732s	
837/2700 (epoch 15.500), train_loss = 1.90265169, grad/param norm = 7.6590e-01, time/batch = 0.1494s	
838/2700 (epoch 15.519), train_loss = 1.87843103, grad/param norm = 7.3634e-01, time/batch = 0.1801s	
839/2700 (epoch 15.537), train_loss = 1.90409909, grad/param norm = 5.8690e-01, time/batch = 0.1784s	
840/2700 (epoch 15.556), train_loss = 1.82084943, grad/param norm = 5.0020e-01, time/batch = 0.1741s	
841/2700 (epoch 15.574), train_loss = 1.83151569, grad/param norm = 5.4273e-01, time/batch = 0.1811s	
842/2700 (epoch 15.593), train_loss = 1.82338991, grad/param norm = 6.2700e-01, time/batch = 0.1720s	
843/2700 (epoch 15.611), train_loss = 1.73693986, grad/param norm = 6.5927e-01, time/batch = 0.1598s	
844/2700 (epoch 15.630), train_loss = 1.78723783, grad/param norm = 5.8724e-01, time/batch = 0.1633s	
845/2700 (epoch 15.648), train_loss = 1.85181406, grad/param norm = 6.3437e-01, time/batch = 0.1734s	
846/2700 (epoch 15.667), train_loss = 1.80153417, grad/param norm = 6.6735e-01, time/batch = 0.1729s	
847/2700 (epoch 15.685), train_loss = 1.83865325, grad/param norm = 6.5493e-01, time/batch = 0.1617s	
848/2700 (epoch 15.704), train_loss = 1.83152247, grad/param norm = 6.6541e-01, time/batch = 0.1616s	
849/2700 (epoch 15.722), train_loss = 1.80865924, grad/param norm = 7.2716e-01, time/batch = 0.1472s	
850/2700 (epoch 15.741), train_loss = 1.89607258, grad/param norm = 7.9552e-01, time/batch = 0.1819s	
851/2700 (epoch 15.759), train_loss = 1.89305213, grad/param norm = 7.7433e-01, time/batch = 0.1795s	
852/2700 (epoch 15.778), train_loss = 1.89528481, grad/param norm = 6.5371e-01, time/batch = 0.1647s	
853/2700 (epoch 15.796), train_loss = 1.84943786, grad/param norm = 5.9869e-01, time/batch = 0.1739s	
854/2700 (epoch 15.815), train_loss = 1.86379738, grad/param norm = 5.6794e-01, time/batch = 0.1851s	
855/2700 (epoch 15.833), train_loss = 1.83014303, grad/param norm = 6.0477e-01, time/batch = 0.1820s	
856/2700 (epoch 15.852), train_loss = 1.85011854, grad/param norm = 5.9168e-01, time/batch = 0.1772s	
857/2700 (epoch 15.870), train_loss = 1.82555075, grad/param norm = 5.4039e-01, time/batch = 0.1825s	
858/2700 (epoch 15.889), train_loss = 1.86111807, grad/param norm = 6.2164e-01, time/batch = 0.1798s	
859/2700 (epoch 15.907), train_loss = 1.98548286, grad/param norm = 7.9094e-01, time/batch = 0.1751s	
860/2700 (epoch 15.926), train_loss = 1.88698596, grad/param norm = 9.0649e-01, time/batch = 0.1846s	
861/2700 (epoch 15.944), train_loss = 1.90105845, grad/param norm = 9.3017e-01, time/batch = 0.1710s	
862/2700 (epoch 15.963), train_loss = 1.93324926, grad/param norm = 8.7503e-01, time/batch = 0.1613s	
863/2700 (epoch 15.981), train_loss = 1.89416302, grad/param norm = 7.2637e-01, time/batch = 0.1561s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
864/2700 (epoch 16.000), train_loss = 1.92632479, grad/param norm = 6.6844e-01, time/batch = 0.1597s	
865/2700 (epoch 16.019), train_loss = 1.89312018, grad/param norm = 6.6499e-01, time/batch = 0.1531s	
866/2700 (epoch 16.037), train_loss = 1.90578375, grad/param norm = 5.6001e-01, time/batch = 0.1834s	
867/2700 (epoch 16.056), train_loss = 1.83007313, grad/param norm = 6.1706e-01, time/batch = 0.1837s	
868/2700 (epoch 16.074), train_loss = 1.82684263, grad/param norm = 6.6726e-01, time/batch = 0.1806s	
869/2700 (epoch 16.093), train_loss = 1.83807114, grad/param norm = 5.2577e-01, time/batch = 0.1787s	
870/2700 (epoch 16.111), train_loss = 1.78985162, grad/param norm = 4.8508e-01, time/batch = 0.1762s	
871/2700 (epoch 16.130), train_loss = 1.83822989, grad/param norm = 4.8489e-01, time/batch = 0.1758s	
872/2700 (epoch 16.148), train_loss = 1.78065802, grad/param norm = 5.1456e-01, time/batch = 0.1745s	
873/2700 (epoch 16.167), train_loss = 1.86916541, grad/param norm = 6.4647e-01, time/batch = 0.1833s	
874/2700 (epoch 16.185), train_loss = 1.78910880, grad/param norm = 7.2838e-01, time/batch = 0.1690s	
875/2700 (epoch 16.204), train_loss = 1.86155838, grad/param norm = 7.7349e-01, time/batch = 0.1843s	
876/2700 (epoch 16.222), train_loss = 1.78920788, grad/param norm = 7.0098e-01, time/batch = 0.1832s	
877/2700 (epoch 16.241), train_loss = 1.70227848, grad/param norm = 5.9945e-01, time/batch = 0.1845s	
878/2700 (epoch 16.259), train_loss = 1.76916105, grad/param norm = 5.6159e-01, time/batch = 0.1781s	
879/2700 (epoch 16.278), train_loss = 1.85913422, grad/param norm = 6.4266e-01, time/batch = 0.1869s	
880/2700 (epoch 16.296), train_loss = 1.83569473, grad/param norm = 7.7716e-01, time/batch = 0.1884s	
881/2700 (epoch 16.315), train_loss = 1.86936279, grad/param norm = 7.7652e-01, time/batch = 0.1621s	
882/2700 (epoch 16.333), train_loss = 1.84406787, grad/param norm = 5.8025e-01, time/batch = 0.1556s	
883/2700 (epoch 16.352), train_loss = 1.85413958, grad/param norm = 6.0850e-01, time/batch = 0.1607s	
884/2700 (epoch 16.370), train_loss = 1.87171160, grad/param norm = 5.8727e-01, time/batch = 0.1562s	
885/2700 (epoch 16.389), train_loss = 1.84296061, grad/param norm = 6.6513e-01, time/batch = 0.1583s	
886/2700 (epoch 16.407), train_loss = 1.87085826, grad/param norm = 6.7402e-01, time/batch = 0.1636s	
887/2700 (epoch 16.426), train_loss = 1.88921110, grad/param norm = 7.3868e-01, time/batch = 0.1701s	
888/2700 (epoch 16.444), train_loss = 1.79287487, grad/param norm = 6.7740e-01, time/batch = 0.1550s	
889/2700 (epoch 16.463), train_loss = 1.84793178, grad/param norm = 6.0893e-01, time/batch = 0.1812s	
890/2700 (epoch 16.481), train_loss = 1.87567294, grad/param norm = 5.6526e-01, time/batch = 0.1825s	
891/2700 (epoch 16.500), train_loss = 1.85290138, grad/param norm = 5.8075e-01, time/batch = 0.1648s	
892/2700 (epoch 16.519), train_loss = 1.83252448, grad/param norm = 5.4172e-01, time/batch = 0.1509s	
893/2700 (epoch 16.537), train_loss = 1.85666271, grad/param norm = 4.9130e-01, time/batch = 0.1664s	
894/2700 (epoch 16.556), train_loss = 1.78394744, grad/param norm = 5.4375e-01, time/batch = 0.1731s	
895/2700 (epoch 16.574), train_loss = 1.79137342, grad/param norm = 5.9789e-01, time/batch = 0.1699s	
896/2700 (epoch 16.593), train_loss = 1.79342256, grad/param norm = 6.4305e-01, time/batch = 0.1857s	
897/2700 (epoch 16.611), train_loss = 1.71358806, grad/param norm = 7.0401e-01, time/batch = 0.1823s	
898/2700 (epoch 16.630), train_loss = 1.76518805, grad/param norm = 7.1178e-01, time/batch = 0.1759s	
899/2700 (epoch 16.648), train_loss = 1.81864905, grad/param norm = 6.6017e-01, time/batch = 0.1791s	
900/2700 (epoch 16.667), train_loss = 1.76353906, grad/param norm = 5.7530e-01, time/batch = 0.1778s	
901/2700 (epoch 16.685), train_loss = 1.80762965, grad/param norm = 6.2046e-01, time/batch = 0.1625s	
902/2700 (epoch 16.704), train_loss = 1.81706400, grad/param norm = 6.5109e-01, time/batch = 0.1738s	
903/2700 (epoch 16.722), train_loss = 1.78077951, grad/param norm = 5.9667e-01, time/batch = 0.1610s	
904/2700 (epoch 16.741), train_loss = 1.84161472, grad/param norm = 5.7183e-01, time/batch = 0.1821s	
905/2700 (epoch 16.759), train_loss = 1.84723530, grad/param norm = 6.4971e-01, time/batch = 0.1815s	
906/2700 (epoch 16.778), train_loss = 1.86107767, grad/param norm = 6.4559e-01, time/batch = 0.1737s	
907/2700 (epoch 16.796), train_loss = 1.81993673, grad/param norm = 6.3013e-01, time/batch = 0.1660s	
908/2700 (epoch 16.815), train_loss = 1.83293073, grad/param norm = 6.5624e-01, time/batch = 0.1812s	
909/2700 (epoch 16.833), train_loss = 1.80664908, grad/param norm = 7.5868e-01, time/batch = 0.1807s	
910/2700 (epoch 16.852), train_loss = 1.82994100, grad/param norm = 7.6616e-01, time/batch = 0.1757s	
911/2700 (epoch 16.870), train_loss = 1.80904137, grad/param norm = 6.6652e-01, time/batch = 0.1798s	
912/2700 (epoch 16.889), train_loss = 1.82682445, grad/param norm = 6.3556e-01, time/batch = 0.1563s	
913/2700 (epoch 16.907), train_loss = 1.95025509, grad/param norm = 7.1598e-01, time/batch = 0.1656s	
914/2700 (epoch 16.926), train_loss = 1.84179222, grad/param norm = 7.1293e-01, time/batch = 0.1675s	
915/2700 (epoch 16.944), train_loss = 1.83688368, grad/param norm = 6.9497e-01, time/batch = 0.1714s	
916/2700 (epoch 16.963), train_loss = 1.86429528, grad/param norm = 5.7898e-01, time/batch = 0.1771s	
917/2700 (epoch 16.981), train_loss = 1.82888697, grad/param norm = 4.6004e-01, time/batch = 0.1613s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
918/2700 (epoch 17.000), train_loss = 1.88527089, grad/param norm = 5.9993e-01, time/batch = 0.1766s	
919/2700 (epoch 17.019), train_loss = 1.86227623, grad/param norm = 6.5730e-01, time/batch = 0.1667s	
920/2700 (epoch 17.037), train_loss = 1.87995903, grad/param norm = 6.2585e-01, time/batch = 0.1449s	
921/2700 (epoch 17.056), train_loss = 1.80980093, grad/param norm = 7.1890e-01, time/batch = 0.1819s	
922/2700 (epoch 17.074), train_loss = 1.81231509, grad/param norm = 7.5461e-01, time/batch = 0.1845s	
923/2700 (epoch 17.093), train_loss = 1.82889951, grad/param norm = 7.6217e-01, time/batch = 0.1845s	
924/2700 (epoch 17.111), train_loss = 1.77558782, grad/param norm = 7.1278e-01, time/batch = 0.1839s	
925/2700 (epoch 17.130), train_loss = 1.82151149, grad/param norm = 6.0282e-01, time/batch = 0.1840s	
926/2700 (epoch 17.148), train_loss = 1.75363026, grad/param norm = 6.0022e-01, time/batch = 0.1633s	
927/2700 (epoch 17.167), train_loss = 1.83772817, grad/param norm = 6.5660e-01, time/batch = 0.1791s	
928/2700 (epoch 17.185), train_loss = 1.74384162, grad/param norm = 5.8172e-01, time/batch = 0.1853s	
929/2700 (epoch 17.204), train_loss = 1.81207586, grad/param norm = 6.2618e-01, time/batch = 0.1794s	
930/2700 (epoch 17.222), train_loss = 1.75055337, grad/param norm = 6.6397e-01, time/batch = 0.1841s	
931/2700 (epoch 17.241), train_loss = 1.67159958, grad/param norm = 5.9162e-01, time/batch = 0.1508s	
932/2700 (epoch 17.259), train_loss = 1.73337709, grad/param norm = 4.8542e-01, time/batch = 0.1678s	
933/2700 (epoch 17.278), train_loss = 1.82255342, grad/param norm = 5.0585e-01, time/batch = 0.1696s	
934/2700 (epoch 17.296), train_loss = 1.79647060, grad/param norm = 5.6840e-01, time/batch = 0.1762s	
935/2700 (epoch 17.315), train_loss = 1.82343266, grad/param norm = 5.6746e-01, time/batch = 0.1788s	
936/2700 (epoch 17.333), train_loss = 1.80821355, grad/param norm = 5.4101e-01, time/batch = 0.1622s	
937/2700 (epoch 17.352), train_loss = 1.82495615, grad/param norm = 6.6997e-01, time/batch = 0.1693s	
938/2700 (epoch 17.370), train_loss = 1.85199495, grad/param norm = 7.7720e-01, time/batch = 0.1538s	
939/2700 (epoch 17.389), train_loss = 1.83327657, grad/param norm = 8.1142e-01, time/batch = 0.1707s	
940/2700 (epoch 17.407), train_loss = 1.85864902, grad/param norm = 7.6192e-01, time/batch = 0.1857s	
941/2700 (epoch 17.426), train_loss = 1.86552271, grad/param norm = 6.3831e-01, time/batch = 0.1833s	
942/2700 (epoch 17.444), train_loss = 1.76736964, grad/param norm = 6.0853e-01, time/batch = 0.1815s	
943/2700 (epoch 17.463), train_loss = 1.83417562, grad/param norm = 6.4070e-01, time/batch = 0.1839s	
944/2700 (epoch 17.481), train_loss = 1.84767889, grad/param norm = 5.2719e-01, time/batch = 0.1830s	
945/2700 (epoch 17.500), train_loss = 1.81811882, grad/param norm = 5.3419e-01, time/batch = 0.1760s	
946/2700 (epoch 17.519), train_loss = 1.80122713, grad/param norm = 5.1215e-01, time/batch = 0.1836s	
947/2700 (epoch 17.537), train_loss = 1.82615334, grad/param norm = 5.2993e-01, time/batch = 0.1764s	
948/2700 (epoch 17.556), train_loss = 1.75903379, grad/param norm = 6.4979e-01, time/batch = 0.1811s	
949/2700 (epoch 17.574), train_loss = 1.76795643, grad/param norm = 7.2890e-01, time/batch = 0.1788s	
950/2700 (epoch 17.593), train_loss = 1.77333594, grad/param norm = 8.5067e-01, time/batch = 0.1607s	
951/2700 (epoch 17.611), train_loss = 1.68778453, grad/param norm = 7.9294e-01, time/batch = 0.1659s	
952/2700 (epoch 17.630), train_loss = 1.72671864, grad/param norm = 5.5470e-01, time/batch = 0.1589s	
953/2700 (epoch 17.648), train_loss = 1.77898988, grad/param norm = 5.7383e-01, time/batch = 0.1622s	
954/2700 (epoch 17.667), train_loss = 1.73066008, grad/param norm = 5.1304e-01, time/batch = 0.1598s	
955/2700 (epoch 17.685), train_loss = 1.77014481, grad/param norm = 5.6468e-01, time/batch = 0.1530s	
956/2700 (epoch 17.704), train_loss = 1.77486998, grad/param norm = 5.8392e-01, time/batch = 0.1833s	
957/2700 (epoch 17.722), train_loss = 1.73777520, grad/param norm = 5.0008e-01, time/batch = 0.1739s	
958/2700 (epoch 17.741), train_loss = 1.80624824, grad/param norm = 5.3793e-01, time/batch = 0.1832s	
959/2700 (epoch 17.759), train_loss = 1.82100163, grad/param norm = 6.5192e-01, time/batch = 0.1830s	
960/2700 (epoch 17.778), train_loss = 1.84238262, grad/param norm = 6.5011e-01, time/batch = 0.1690s	
961/2700 (epoch 17.796), train_loss = 1.79767321, grad/param norm = 6.7824e-01, time/batch = 0.1671s	
962/2700 (epoch 17.815), train_loss = 1.81177141, grad/param norm = 6.3345e-01, time/batch = 0.1726s	
963/2700 (epoch 17.833), train_loss = 1.78524635, grad/param norm = 6.3168e-01, time/batch = 0.1767s	
964/2700 (epoch 17.852), train_loss = 1.79266399, grad/param norm = 5.7478e-01, time/batch = 0.1822s	
965/2700 (epoch 17.870), train_loss = 1.76172312, grad/param norm = 4.8246e-01, time/batch = 0.1643s	
966/2700 (epoch 17.889), train_loss = 1.78952401, grad/param norm = 5.4023e-01, time/batch = 0.1608s	
967/2700 (epoch 17.907), train_loss = 1.90885874, grad/param norm = 5.8865e-01, time/batch = 0.1676s	
968/2700 (epoch 17.926), train_loss = 1.80307289, grad/param norm = 5.0771e-01, time/batch = 0.1724s	
969/2700 (epoch 17.944), train_loss = 1.79648923, grad/param norm = 4.5232e-01, time/batch = 0.1612s	
970/2700 (epoch 17.963), train_loss = 1.83360357, grad/param norm = 5.7093e-01, time/batch = 0.1804s	
971/2700 (epoch 17.981), train_loss = 1.81472085, grad/param norm = 6.8245e-01, time/batch = 0.1596s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
972/2700 (epoch 18.000), train_loss = 1.86237519, grad/param norm = 6.6360e-01, time/batch = 0.1709s	
973/2700 (epoch 18.019), train_loss = 1.84803779, grad/param norm = 7.8426e-01, time/batch = 0.1820s	
974/2700 (epoch 18.037), train_loss = 1.87212687, grad/param norm = 9.0548e-01, time/batch = 0.1776s	
975/2700 (epoch 18.056), train_loss = 1.78424428, grad/param norm = 8.4963e-01, time/batch = 0.1835s	
976/2700 (epoch 18.074), train_loss = 1.77859485, grad/param norm = 7.3062e-01, time/batch = 0.1863s	
977/2700 (epoch 18.093), train_loss = 1.78145389, grad/param norm = 5.7532e-01, time/batch = 0.1842s	
978/2700 (epoch 18.111), train_loss = 1.72889385, grad/param norm = 4.7748e-01, time/batch = 0.1791s	
979/2700 (epoch 18.130), train_loss = 1.78129756, grad/param norm = 4.3425e-01, time/batch = 0.1864s	
980/2700 (epoch 18.148), train_loss = 1.71531949, grad/param norm = 4.6165e-01, time/batch = 0.1865s	
981/2700 (epoch 18.167), train_loss = 1.80350960, grad/param norm = 5.4394e-01, time/batch = 0.1810s	
982/2700 (epoch 18.185), train_loss = 1.71215988, grad/param norm = 5.1807e-01, time/batch = 0.1832s	
983/2700 (epoch 18.204), train_loss = 1.77922562, grad/param norm = 5.6596e-01, time/batch = 0.1645s	
984/2700 (epoch 18.222), train_loss = 1.72351515, grad/param norm = 5.4710e-01, time/batch = 0.1557s	
985/2700 (epoch 18.241), train_loss = 1.64615444, grad/param norm = 5.1462e-01, time/batch = 0.1813s	
986/2700 (epoch 18.259), train_loss = 1.71827583, grad/param norm = 5.2066e-01, time/batch = 0.1846s	
987/2700 (epoch 18.278), train_loss = 1.80921648, grad/param norm = 6.4516e-01, time/batch = 0.1850s	
988/2700 (epoch 18.296), train_loss = 1.78784232, grad/param norm = 8.0816e-01, time/batch = 0.1819s	
989/2700 (epoch 18.315), train_loss = 1.81121260, grad/param norm = 6.8494e-01, time/batch = 0.1845s	
990/2700 (epoch 18.333), train_loss = 1.78573811, grad/param norm = 5.6225e-01, time/batch = 0.1835s	
991/2700 (epoch 18.352), train_loss = 1.80215657, grad/param norm = 6.9325e-01, time/batch = 0.1576s	
992/2700 (epoch 18.370), train_loss = 1.81841570, grad/param norm = 6.8696e-01, time/batch = 0.1635s	
993/2700 (epoch 18.389), train_loss = 1.78645615, grad/param norm = 6.8966e-01, time/batch = 0.1666s	
994/2700 (epoch 18.407), train_loss = 1.80363556, grad/param norm = 5.8355e-01, time/batch = 0.1495s	
995/2700 (epoch 18.426), train_loss = 1.81404811, grad/param norm = 4.9581e-01, time/batch = 0.1832s	
996/2700 (epoch 18.444), train_loss = 1.72402554, grad/param norm = 5.0532e-01, time/batch = 0.1822s	
997/2700 (epoch 18.463), train_loss = 1.79724322, grad/param norm = 5.8207e-01, time/batch = 0.1761s	
998/2700 (epoch 18.481), train_loss = 1.81657004, grad/param norm = 5.0787e-01, time/batch = 0.1814s	
999/2700 (epoch 18.500), train_loss = 1.78746520, grad/param norm = 5.0398e-01, time/batch = 0.1844s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch18.52_1.8415.t7	
1000/2700 (epoch 18.519), train_loss = 1.77225163, grad/param norm = 4.8252e-01, time/batch = 0.1828s	
1001/2700 (epoch 18.537), train_loss = 1.86671009, grad/param norm = 5.1639e-01, time/batch = 0.1473s	
1002/2700 (epoch 18.556), train_loss = 1.73333597, grad/param norm = 6.3102e-01, time/batch = 0.1760s	
1003/2700 (epoch 18.574), train_loss = 1.74798477, grad/param norm = 7.4358e-01, time/batch = 0.1816s	
1004/2700 (epoch 18.593), train_loss = 1.75538611, grad/param norm = 8.6555e-01, time/batch = 0.1660s	
1005/2700 (epoch 18.611), train_loss = 1.66395159, grad/param norm = 7.8054e-01, time/batch = 0.1742s	
1006/2700 (epoch 18.630), train_loss = 1.69661254, grad/param norm = 5.2504e-01, time/batch = 0.1724s	
1007/2700 (epoch 18.648), train_loss = 1.74690136, grad/param norm = 5.0926e-01, time/batch = 0.1744s	
1008/2700 (epoch 18.667), train_loss = 1.70298980, grad/param norm = 4.6577e-01, time/batch = 0.1666s	
1009/2700 (epoch 18.685), train_loss = 1.74090370, grad/param norm = 5.1363e-01, time/batch = 0.1793s	
1010/2700 (epoch 18.704), train_loss = 1.74654804, grad/param norm = 5.3467e-01, time/batch = 0.1686s	
1011/2700 (epoch 18.722), train_loss = 1.71255132, grad/param norm = 4.6718e-01, time/batch = 0.1758s	
1012/2700 (epoch 18.741), train_loss = 1.76987843, grad/param norm = 4.8701e-01, time/batch = 0.1873s	
1013/2700 (epoch 18.759), train_loss = 1.77521517, grad/param norm = 5.3024e-01, time/batch = 0.1683s	
1014/2700 (epoch 18.778), train_loss = 1.79544089, grad/param norm = 4.9775e-01, time/batch = 0.1847s	
1015/2700 (epoch 18.796), train_loss = 1.75213269, grad/param norm = 5.2792e-01, time/batch = 0.1666s	
1016/2700 (epoch 18.815), train_loss = 1.77181319, grad/param norm = 4.9893e-01, time/batch = 0.1726s	
1017/2700 (epoch 18.833), train_loss = 1.74050938, grad/param norm = 5.1667e-01, time/batch = 0.1825s	
1018/2700 (epoch 18.852), train_loss = 1.75927413, grad/param norm = 5.4912e-01, time/batch = 0.1816s	
1019/2700 (epoch 18.870), train_loss = 1.74124127, grad/param norm = 5.1309e-01, time/batch = 0.1833s	
1020/2700 (epoch 18.889), train_loss = 1.77315717, grad/param norm = 5.7089e-01, time/batch = 0.1827s	
1021/2700 (epoch 18.907), train_loss = 1.89292564, grad/param norm = 6.2375e-01, time/batch = 0.1616s	
1022/2700 (epoch 18.926), train_loss = 1.79085970, grad/param norm = 5.6738e-01, time/batch = 0.1760s	
1023/2700 (epoch 18.944), train_loss = 1.79046121, grad/param norm = 6.0747e-01, time/batch = 0.1761s	
1024/2700 (epoch 18.963), train_loss = 1.82401178, grad/param norm = 6.6355e-01, time/batch = 0.1691s	
1025/2700 (epoch 18.981), train_loss = 1.79382731, grad/param norm = 5.7183e-01, time/batch = 0.1803s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1026/2700 (epoch 19.000), train_loss = 1.83025788, grad/param norm = 5.5623e-01, time/batch = 0.1805s	
1027/2700 (epoch 19.019), train_loss = 1.81238412, grad/param norm = 6.3429e-01, time/batch = 0.1791s	
1028/2700 (epoch 19.037), train_loss = 1.82384692, grad/param norm = 5.2564e-01, time/batch = 0.1662s	
1029/2700 (epoch 19.056), train_loss = 1.73237134, grad/param norm = 5.2418e-01, time/batch = 0.1685s	
1030/2700 (epoch 19.074), train_loss = 1.73871902, grad/param norm = 5.8377e-01, time/batch = 0.1684s	
1031/2700 (epoch 19.093), train_loss = 1.74742846, grad/param norm = 4.9250e-01, time/batch = 0.1791s	
1032/2700 (epoch 19.111), train_loss = 1.70887984, grad/param norm = 6.3774e-01, time/batch = 0.1669s	
1033/2700 (epoch 19.130), train_loss = 1.78061404, grad/param norm = 8.5340e-01, time/batch = 0.1714s	
1034/2700 (epoch 19.148), train_loss = 1.71341852, grad/param norm = 8.4397e-01, time/batch = 0.1685s	
1035/2700 (epoch 19.167), train_loss = 1.80282776, grad/param norm = 6.8540e-01, time/batch = 0.1686s	
1036/2700 (epoch 19.185), train_loss = 1.69964000, grad/param norm = 5.9475e-01, time/batch = 0.1785s	
1037/2700 (epoch 19.204), train_loss = 1.75820765, grad/param norm = 5.5414e-01, time/batch = 0.1696s	
1038/2700 (epoch 19.222), train_loss = 1.70086131, grad/param norm = 5.8067e-01, time/batch = 0.1725s	
1039/2700 (epoch 19.241), train_loss = 1.62184767, grad/param norm = 5.5264e-01, time/batch = 0.1819s	
1040/2700 (epoch 19.259), train_loss = 1.69279018, grad/param norm = 5.8360e-01, time/batch = 0.1758s	
1041/2700 (epoch 19.278), train_loss = 1.78240348, grad/param norm = 6.2273e-01, time/batch = 0.1693s	
1042/2700 (epoch 19.296), train_loss = 1.75071695, grad/param norm = 6.6181e-01, time/batch = 0.1856s	
1043/2700 (epoch 19.315), train_loss = 1.77083207, grad/param norm = 6.0968e-01, time/batch = 0.1865s	
1044/2700 (epoch 19.333), train_loss = 1.75096455, grad/param norm = 5.0148e-01, time/batch = 0.1664s	
1045/2700 (epoch 19.352), train_loss = 1.76256291, grad/param norm = 5.5615e-01, time/batch = 0.1608s	
1046/2700 (epoch 19.370), train_loss = 1.78298575, grad/param norm = 5.5162e-01, time/batch = 0.1658s	
1047/2700 (epoch 19.389), train_loss = 1.75954694, grad/param norm = 6.3937e-01, time/batch = 0.1823s	
1048/2700 (epoch 19.407), train_loss = 1.78321096, grad/param norm = 6.1089e-01, time/batch = 0.1839s	
1049/2700 (epoch 19.426), train_loss = 1.79479429, grad/param norm = 5.7008e-01, time/batch = 0.1824s	
1050/2700 (epoch 19.444), train_loss = 1.70156288, grad/param norm = 5.2559e-01, time/batch = 0.1783s	
1051/2700 (epoch 19.463), train_loss = 1.77139475, grad/param norm = 5.7832e-01, time/batch = 0.1681s	
1052/2700 (epoch 19.481), train_loss = 1.79230405, grad/param norm = 5.4185e-01, time/batch = 0.1589s	
1053/2700 (epoch 19.500), train_loss = 1.76285025, grad/param norm = 5.3756e-01, time/batch = 0.1653s	
1054/2700 (epoch 19.519), train_loss = 1.74945177, grad/param norm = 4.9924e-01, time/batch = 0.1673s	
1055/2700 (epoch 19.537), train_loss = 1.76721668, grad/param norm = 4.5826e-01, time/batch = 0.1739s	
1056/2700 (epoch 19.556), train_loss = 1.69583334, grad/param norm = 4.8607e-01, time/batch = 0.1831s	
1057/2700 (epoch 19.574), train_loss = 1.70826328, grad/param norm = 5.5366e-01, time/batch = 0.1820s	
1058/2700 (epoch 19.593), train_loss = 1.71404282, grad/param norm = 6.6461e-01, time/batch = 0.1817s	
1059/2700 (epoch 19.611), train_loss = 1.62957527, grad/param norm = 6.5231e-01, time/batch = 0.1828s	
1060/2700 (epoch 19.630), train_loss = 1.66972064, grad/param norm = 5.4655e-01, time/batch = 0.1668s	
1061/2700 (epoch 19.648), train_loss = 1.72421856, grad/param norm = 5.2915e-01, time/batch = 0.1536s	
1062/2700 (epoch 19.667), train_loss = 1.68047006, grad/param norm = 4.6078e-01, time/batch = 0.1422s	
1063/2700 (epoch 19.685), train_loss = 1.71511207, grad/param norm = 5.2163e-01, time/batch = 0.1840s	
1064/2700 (epoch 19.704), train_loss = 1.72575950, grad/param norm = 5.8901e-01, time/batch = 0.1786s	
1065/2700 (epoch 19.722), train_loss = 1.69971835, grad/param norm = 5.6849e-01, time/batch = 0.1834s	
1066/2700 (epoch 19.741), train_loss = 1.75636967, grad/param norm = 5.7339e-01, time/batch = 0.1824s	
1067/2700 (epoch 19.759), train_loss = 1.75117019, grad/param norm = 5.6249e-01, time/batch = 0.1830s	
1068/2700 (epoch 19.778), train_loss = 1.76767838, grad/param norm = 5.0678e-01, time/batch = 0.1832s	
1069/2700 (epoch 19.796), train_loss = 1.72270759, grad/param norm = 5.1969e-01, time/batch = 0.1740s	
1070/2700 (epoch 19.815), train_loss = 1.75404560, grad/param norm = 5.5530e-01, time/batch = 0.1843s	
1071/2700 (epoch 19.833), train_loss = 1.72438796, grad/param norm = 6.0770e-01, time/batch = 0.1722s	
1072/2700 (epoch 19.852), train_loss = 1.74327507, grad/param norm = 6.4526e-01, time/batch = 0.1635s	
1073/2700 (epoch 19.870), train_loss = 1.72414869, grad/param norm = 5.6090e-01, time/batch = 0.1518s	
1074/2700 (epoch 19.889), train_loss = 1.74423385, grad/param norm = 5.8842e-01, time/batch = 0.1740s	
1075/2700 (epoch 19.907), train_loss = 1.86299705, grad/param norm = 6.2021e-01, time/batch = 0.1693s	
1076/2700 (epoch 19.926), train_loss = 1.76803025, grad/param norm = 7.1588e-01, time/batch = 0.1814s	
1077/2700 (epoch 19.944), train_loss = 1.76971987, grad/param norm = 7.7165e-01, time/batch = 0.1844s	
1078/2700 (epoch 19.963), train_loss = 1.79315275, grad/param norm = 6.3589e-01, time/batch = 0.1843s	
1079/2700 (epoch 19.981), train_loss = 1.75970973, grad/param norm = 5.6576e-01, time/batch = 0.1766s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1080/2700 (epoch 20.000), train_loss = 1.81074750, grad/param norm = 5.6547e-01, time/batch = 0.1857s	
1081/2700 (epoch 20.019), train_loss = 1.78755764, grad/param norm = 5.8694e-01, time/batch = 0.1565s	
1082/2700 (epoch 20.037), train_loss = 1.79753745, grad/param norm = 5.8534e-01, time/batch = 0.1460s	
1083/2700 (epoch 20.056), train_loss = 1.71076246, grad/param norm = 6.2951e-01, time/batch = 0.1656s	
1084/2700 (epoch 20.074), train_loss = 1.71837655, grad/param norm = 6.5238e-01, time/batch = 0.1652s	
1085/2700 (epoch 20.093), train_loss = 1.72723511, grad/param norm = 6.3593e-01, time/batch = 0.1660s	
1086/2700 (epoch 20.111), train_loss = 1.68027381, grad/param norm = 6.2783e-01, time/batch = 0.1674s	
1087/2700 (epoch 20.130), train_loss = 1.74118853, grad/param norm = 5.8309e-01, time/batch = 0.1824s	
1088/2700 (epoch 20.148), train_loss = 1.67560626, grad/param norm = 6.2884e-01, time/batch = 0.1841s	
1089/2700 (epoch 20.167), train_loss = 1.76486461, grad/param norm = 6.8389e-01, time/batch = 0.1776s	
1090/2700 (epoch 20.185), train_loss = 1.66953120, grad/param norm = 5.8203e-01, time/batch = 0.1765s	
1091/2700 (epoch 20.204), train_loss = 1.74583937, grad/param norm = 6.6488e-01, time/batch = 0.1480s	
1092/2700 (epoch 20.222), train_loss = 1.69042033, grad/param norm = 7.0157e-01, time/batch = 0.1827s	
1093/2700 (epoch 20.241), train_loss = 1.60220935, grad/param norm = 6.5907e-01, time/batch = 0.1819s	
1094/2700 (epoch 20.259), train_loss = 1.66133958, grad/param norm = 5.4214e-01, time/batch = 0.1815s	
1095/2700 (epoch 20.278), train_loss = 1.75418097, grad/param norm = 5.2959e-01, time/batch = 0.1848s	
1096/2700 (epoch 20.296), train_loss = 1.72491131, grad/param norm = 6.3159e-01, time/batch = 0.1808s	
1097/2700 (epoch 20.315), train_loss = 1.74460054, grad/param norm = 6.2217e-01, time/batch = 0.1654s	
1098/2700 (epoch 20.333), train_loss = 1.72953745, grad/param norm = 5.4317e-01, time/batch = 0.1590s	
1099/2700 (epoch 20.352), train_loss = 1.75003783, grad/param norm = 8.8306e-01, time/batch = 0.1869s	
1100/2700 (epoch 20.370), train_loss = 1.77125491, grad/param norm = 6.7532e-01, time/batch = 0.1845s	
1101/2700 (epoch 20.389), train_loss = 1.73490545, grad/param norm = 5.7818e-01, time/batch = 0.1759s	
1102/2700 (epoch 20.407), train_loss = 1.75311476, grad/param norm = 6.2842e-01, time/batch = 0.1712s	
1103/2700 (epoch 20.426), train_loss = 1.76356944, grad/param norm = 6.2939e-01, time/batch = 0.1665s	
1104/2700 (epoch 20.444), train_loss = 1.67880213, grad/param norm = 4.6789e-01, time/batch = 0.1688s	
1105/2700 (epoch 20.463), train_loss = 1.74640498, grad/param norm = 4.7532e-01, time/batch = 0.1649s	
1106/2700 (epoch 20.481), train_loss = 1.76140554, grad/param norm = 4.9177e-01, time/batch = 0.1686s	
1107/2700 (epoch 20.500), train_loss = 1.74248826, grad/param norm = 6.4166e-01, time/batch = 0.1853s	
1108/2700 (epoch 20.519), train_loss = 1.73403603, grad/param norm = 5.7244e-01, time/batch = 0.1603s	
1109/2700 (epoch 20.537), train_loss = 1.74641786, grad/param norm = 5.0839e-01, time/batch = 0.1564s	
1110/2700 (epoch 20.556), train_loss = 1.67595560, grad/param norm = 5.4742e-01, time/batch = 0.1476s	
1111/2700 (epoch 20.574), train_loss = 1.68532608, grad/param norm = 5.7580e-01, time/batch = 0.1762s	
1112/2700 (epoch 20.593), train_loss = 1.68779747, grad/param norm = 6.4724e-01, time/batch = 0.1732s	
1113/2700 (epoch 20.611), train_loss = 1.60652310, grad/param norm = 6.2158e-01, time/batch = 0.1782s	
1114/2700 (epoch 20.630), train_loss = 1.65264803, grad/param norm = 5.2454e-01, time/batch = 0.1800s	
1115/2700 (epoch 20.648), train_loss = 1.70181367, grad/param norm = 5.4489e-01, time/batch = 0.1855s	
1116/2700 (epoch 20.667), train_loss = 1.65581850, grad/param norm = 4.3992e-01, time/batch = 0.1700s	
1117/2700 (epoch 20.685), train_loss = 1.69067812, grad/param norm = 4.8172e-01, time/batch = 0.1704s	
1118/2700 (epoch 20.704), train_loss = 1.70365705, grad/param norm = 5.5085e-01, time/batch = 0.1847s	
1119/2700 (epoch 20.722), train_loss = 1.67493452, grad/param norm = 5.3755e-01, time/batch = 0.1755s	
1120/2700 (epoch 20.741), train_loss = 1.72320533, grad/param norm = 4.8591e-01, time/batch = 0.1828s	
1121/2700 (epoch 20.759), train_loss = 1.71706812, grad/param norm = 4.5320e-01, time/batch = 0.1786s	
1122/2700 (epoch 20.778), train_loss = 1.74386924, grad/param norm = 4.5767e-01, time/batch = 0.1739s	
1123/2700 (epoch 20.796), train_loss = 1.69811137, grad/param norm = 5.4364e-01, time/batch = 0.1613s	
1124/2700 (epoch 20.815), train_loss = 1.73030327, grad/param norm = 5.5360e-01, time/batch = 0.1679s	
1125/2700 (epoch 20.833), train_loss = 1.70493994, grad/param norm = 5.9411e-01, time/batch = 0.1818s	
1126/2700 (epoch 20.852), train_loss = 1.71973670, grad/param norm = 6.0792e-01, time/batch = 0.1858s	
1127/2700 (epoch 20.870), train_loss = 1.69763106, grad/param norm = 5.5755e-01, time/batch = 0.1573s	
1128/2700 (epoch 20.889), train_loss = 1.71822392, grad/param norm = 6.0303e-01, time/batch = 0.1632s	
1129/2700 (epoch 20.907), train_loss = 1.84232469, grad/param norm = 6.3408e-01, time/batch = 0.1569s	
1130/2700 (epoch 20.926), train_loss = 1.74657014, grad/param norm = 5.7227e-01, time/batch = 0.1826s	
1131/2700 (epoch 20.944), train_loss = 1.73013454, grad/param norm = 5.3397e-01, time/batch = 0.1755s	
1132/2700 (epoch 20.963), train_loss = 1.76265362, grad/param norm = 5.7350e-01, time/batch = 0.1780s	
1133/2700 (epoch 20.981), train_loss = 1.73391013, grad/param norm = 5.6736e-01, time/batch = 0.1826s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1134/2700 (epoch 21.000), train_loss = 1.78912854, grad/param norm = 6.0395e-01, time/batch = 0.1762s	
1135/2700 (epoch 21.019), train_loss = 1.77636583, grad/param norm = 7.4277e-01, time/batch = 0.1750s	
1136/2700 (epoch 21.037), train_loss = 1.79059374, grad/param norm = 7.9548e-01, time/batch = 0.1774s	
1137/2700 (epoch 21.056), train_loss = 1.68226961, grad/param norm = 6.1198e-01, time/batch = 0.1795s	
1138/2700 (epoch 21.074), train_loss = 1.68940969, grad/param norm = 4.9014e-01, time/batch = 0.1771s	
1139/2700 (epoch 21.093), train_loss = 1.69870032, grad/param norm = 4.5576e-01, time/batch = 0.1864s	
1140/2700 (epoch 21.111), train_loss = 1.65029201, grad/param norm = 4.7745e-01, time/batch = 0.1850s	
1141/2700 (epoch 21.130), train_loss = 1.71191731, grad/param norm = 4.9707e-01, time/batch = 0.1790s	
1142/2700 (epoch 21.148), train_loss = 1.64487787, grad/param norm = 4.8289e-01, time/batch = 0.1602s	
1143/2700 (epoch 21.167), train_loss = 1.72848415, grad/param norm = 4.4746e-01, time/batch = 0.1632s	
1144/2700 (epoch 21.185), train_loss = 1.63674673, grad/param norm = 4.1526e-01, time/batch = 0.1636s	
1145/2700 (epoch 21.204), train_loss = 1.70539858, grad/param norm = 4.8732e-01, time/batch = 0.1710s	
1146/2700 (epoch 21.222), train_loss = 1.65403785, grad/param norm = 5.0107e-01, time/batch = 0.1634s	
1147/2700 (epoch 21.241), train_loss = 1.57360365, grad/param norm = 4.7178e-01, time/batch = 0.1697s	
1148/2700 (epoch 21.259), train_loss = 1.64045662, grad/param norm = 4.7816e-01, time/batch = 0.1604s	
1149/2700 (epoch 21.278), train_loss = 1.73506711, grad/param norm = 5.6369e-01, time/batch = 0.1662s	
1150/2700 (epoch 21.296), train_loss = 1.70890727, grad/param norm = 6.9284e-01, time/batch = 0.1725s	
1151/2700 (epoch 21.315), train_loss = 1.72608699, grad/param norm = 7.2999e-01, time/batch = 0.1773s	
1152/2700 (epoch 21.333), train_loss = 1.70266670, grad/param norm = 6.8936e-01, time/batch = 0.1707s	
1153/2700 (epoch 21.352), train_loss = 1.71747492, grad/param norm = 6.6979e-01, time/batch = 0.1751s	
1154/2700 (epoch 21.370), train_loss = 1.74338973, grad/param norm = 7.1024e-01, time/batch = 0.1836s	
1155/2700 (epoch 21.389), train_loss = 1.71605573, grad/param norm = 7.9585e-01, time/batch = 0.1582s	
1156/2700 (epoch 21.407), train_loss = 1.74642928, grad/param norm = 7.0910e-01, time/batch = 0.1739s	
1157/2700 (epoch 21.426), train_loss = 1.74611746, grad/param norm = 6.2960e-01, time/batch = 0.1607s	
1158/2700 (epoch 21.444), train_loss = 1.66534276, grad/param norm = 6.1141e-01, time/batch = 0.1843s	
1159/2700 (epoch 21.463), train_loss = 1.73557814, grad/param norm = 5.8769e-01, time/batch = 0.1823s	
1160/2700 (epoch 21.481), train_loss = 1.74208131, grad/param norm = 5.0018e-01, time/batch = 0.1831s	
1161/2700 (epoch 21.500), train_loss = 1.71672882, grad/param norm = 5.2575e-01, time/batch = 0.1811s	
1162/2700 (epoch 21.519), train_loss = 1.71682645, grad/param norm = 5.1461e-01, time/batch = 0.1759s	
1163/2700 (epoch 21.537), train_loss = 1.73306817, grad/param norm = 5.7841e-01, time/batch = 0.1652s	
1164/2700 (epoch 21.556), train_loss = 1.66729905, grad/param norm = 7.2409e-01, time/batch = 0.1587s	
1165/2700 (epoch 21.574), train_loss = 1.67226224, grad/param norm = 6.6265e-01, time/batch = 0.1480s	
1166/2700 (epoch 21.593), train_loss = 1.67037516, grad/param norm = 6.0890e-01, time/batch = 0.1780s	
1167/2700 (epoch 21.611), train_loss = 1.57941432, grad/param norm = 5.6802e-01, time/batch = 0.1837s	
1168/2700 (epoch 21.630), train_loss = 1.62340525, grad/param norm = 5.0255e-01, time/batch = 0.1847s	
1169/2700 (epoch 21.648), train_loss = 1.67192864, grad/param norm = 5.0830e-01, time/batch = 0.1836s	
1170/2700 (epoch 21.667), train_loss = 1.62953297, grad/param norm = 3.9524e-01, time/batch = 0.1854s	
1171/2700 (epoch 21.685), train_loss = 1.66470669, grad/param norm = 4.3155e-01, time/batch = 0.1636s	
1172/2700 (epoch 21.704), train_loss = 1.68150137, grad/param norm = 4.8983e-01, time/batch = 0.1663s	
1173/2700 (epoch 21.722), train_loss = 1.64961753, grad/param norm = 4.6861e-01, time/batch = 0.1679s	
1174/2700 (epoch 21.741), train_loss = 1.69586182, grad/param norm = 4.5287e-01, time/batch = 0.1866s	
1175/2700 (epoch 21.759), train_loss = 1.69808079, grad/param norm = 4.9791e-01, time/batch = 0.1581s	
1176/2700 (epoch 21.778), train_loss = 1.72878195, grad/param norm = 5.0050e-01, time/batch = 0.1488s	
1177/2700 (epoch 21.796), train_loss = 1.68098264, grad/param norm = 5.6601e-01, time/batch = 0.1764s	
1178/2700 (epoch 21.815), train_loss = 1.71081485, grad/param norm = 5.4787e-01, time/batch = 0.1780s	
1179/2700 (epoch 21.833), train_loss = 1.68204498, grad/param norm = 5.4551e-01, time/batch = 0.1796s	
1180/2700 (epoch 21.852), train_loss = 1.68825878, grad/param norm = 5.4799e-01, time/batch = 0.1808s	
1181/2700 (epoch 21.870), train_loss = 1.67711993, grad/param norm = 6.0622e-01, time/batch = 0.1698s	
1182/2700 (epoch 21.889), train_loss = 1.70058008, grad/param norm = 6.8618e-01, time/batch = 0.1562s	
1183/2700 (epoch 21.907), train_loss = 1.81722649, grad/param norm = 6.5755e-01, time/batch = 0.1817s	
1184/2700 (epoch 21.926), train_loss = 1.72787353, grad/param norm = 6.2465e-01, time/batch = 0.1733s	
1185/2700 (epoch 21.944), train_loss = 1.71420050, grad/param norm = 6.8448e-01, time/batch = 0.1872s	
1186/2700 (epoch 21.963), train_loss = 1.74821591, grad/param norm = 7.8338e-01, time/batch = 0.1699s	
1187/2700 (epoch 21.981), train_loss = 1.72280348, grad/param norm = 7.3060e-01, time/batch = 0.1665s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1188/2700 (epoch 22.000), train_loss = 1.76579539, grad/param norm = 5.5804e-01, time/batch = 0.1746s	
1189/2700 (epoch 22.019), train_loss = 1.74498313, grad/param norm = 5.4409e-01, time/batch = 0.1845s	
1190/2700 (epoch 22.037), train_loss = 1.75061654, grad/param norm = 5.1376e-01, time/batch = 0.1845s	
1191/2700 (epoch 22.056), train_loss = 1.65535296, grad/param norm = 5.2828e-01, time/batch = 0.1772s	
1192/2700 (epoch 22.074), train_loss = 1.66974347, grad/param norm = 5.3617e-01, time/batch = 0.1626s	
1193/2700 (epoch 22.093), train_loss = 1.67403948, grad/param norm = 4.3093e-01, time/batch = 0.1583s	
1194/2700 (epoch 22.111), train_loss = 1.62728420, grad/param norm = 4.9346e-01, time/batch = 0.1481s	
1195/2700 (epoch 22.130), train_loss = 1.69483864, grad/param norm = 5.7113e-01, time/batch = 0.1665s	
1196/2700 (epoch 22.148), train_loss = 1.62574827, grad/param norm = 5.4310e-01, time/batch = 0.1804s	
1197/2700 (epoch 22.167), train_loss = 1.71133744, grad/param norm = 4.9952e-01, time/batch = 0.1738s	
1198/2700 (epoch 22.185), train_loss = 1.61796577, grad/param norm = 4.3890e-01, time/batch = 0.1739s	
1199/2700 (epoch 22.204), train_loss = 1.68265022, grad/param norm = 4.5969e-01, time/batch = 0.1774s	
1200/2700 (epoch 22.222), train_loss = 1.63264125, grad/param norm = 4.7880e-01, time/batch = 0.1753s	
1201/2700 (epoch 22.241), train_loss = 1.56017797, grad/param norm = 5.0199e-01, time/batch = 0.1587s	
1202/2700 (epoch 22.259), train_loss = 1.63311410, grad/param norm = 5.6972e-01, time/batch = 0.1608s	
1203/2700 (epoch 22.278), train_loss = 1.72489175, grad/param norm = 6.5347e-01, time/batch = 0.1638s	
1204/2700 (epoch 22.296), train_loss = 1.69015424, grad/param norm = 7.4966e-01, time/batch = 0.1482s	
1205/2700 (epoch 22.315), train_loss = 1.69699350, grad/param norm = 6.5240e-01, time/batch = 0.1838s	
1206/2700 (epoch 22.333), train_loss = 1.67163201, grad/param norm = 4.8073e-01, time/batch = 0.1843s	
1207/2700 (epoch 22.352), train_loss = 1.68353897, grad/param norm = 5.2174e-01, time/batch = 0.1852s	
1208/2700 (epoch 22.370), train_loss = 1.71521074, grad/param norm = 6.2542e-01, time/batch = 0.1825s	
1209/2700 (epoch 22.389), train_loss = 1.69230272, grad/param norm = 6.4322e-01, time/batch = 0.1833s	
1210/2700 (epoch 22.407), train_loss = 1.71587632, grad/param norm = 5.5508e-01, time/batch = 0.1774s	
1211/2700 (epoch 22.426), train_loss = 1.71806335, grad/param norm = 5.2015e-01, time/batch = 0.1744s	
1212/2700 (epoch 22.444), train_loss = 1.64238372, grad/param norm = 5.3905e-01, time/batch = 0.1734s	
1213/2700 (epoch 22.463), train_loss = 1.71329425, grad/param norm = 5.6009e-01, time/batch = 0.1820s	
1214/2700 (epoch 22.481), train_loss = 1.72176739, grad/param norm = 5.2043e-01, time/batch = 0.1715s	
1215/2700 (epoch 22.500), train_loss = 1.69829658, grad/param norm = 5.4845e-01, time/batch = 0.1715s	
1216/2700 (epoch 22.519), train_loss = 1.69018894, grad/param norm = 4.6029e-01, time/batch = 0.1706s	
1217/2700 (epoch 22.537), train_loss = 1.70183039, grad/param norm = 4.8993e-01, time/batch = 0.1782s	
1218/2700 (epoch 22.556), train_loss = 1.63784305, grad/param norm = 5.8004e-01, time/batch = 0.1890s	
1219/2700 (epoch 22.574), train_loss = 1.64760012, grad/param norm = 5.8919e-01, time/batch = 0.1847s	
1220/2700 (epoch 22.593), train_loss = 1.64999007, grad/param norm = 6.3894e-01, time/batch = 0.1857s	
1221/2700 (epoch 22.611), train_loss = 1.56274007, grad/param norm = 5.8859e-01, time/batch = 0.1732s	
1222/2700 (epoch 22.630), train_loss = 1.60674661, grad/param norm = 4.6747e-01, time/batch = 0.1603s	
1223/2700 (epoch 22.648), train_loss = 1.65866942, grad/param norm = 5.5384e-01, time/batch = 0.1454s	
1224/2700 (epoch 22.667), train_loss = 1.61697446, grad/param norm = 4.7845e-01, time/batch = 0.1752s	
1225/2700 (epoch 22.685), train_loss = 1.64632378, grad/param norm = 5.0568e-01, time/batch = 0.1798s	
1226/2700 (epoch 22.704), train_loss = 1.66196420, grad/param norm = 5.3871e-01, time/batch = 0.1828s	
1227/2700 (epoch 22.722), train_loss = 1.63200674, grad/param norm = 4.9299e-01, time/batch = 0.1794s	
1228/2700 (epoch 22.741), train_loss = 1.68254668, grad/param norm = 5.4991e-01, time/batch = 0.1751s	
1229/2700 (epoch 22.759), train_loss = 1.67791741, grad/param norm = 5.1981e-01, time/batch = 0.1624s	
1230/2700 (epoch 22.778), train_loss = 1.70565388, grad/param norm = 4.9714e-01, time/batch = 0.1808s	
1231/2700 (epoch 22.796), train_loss = 1.65834532, grad/param norm = 6.2994e-01, time/batch = 0.1740s	
1232/2700 (epoch 22.815), train_loss = 1.69684132, grad/param norm = 6.0730e-01, time/batch = 0.1684s	
1233/2700 (epoch 22.833), train_loss = 1.66692658, grad/param norm = 6.4145e-01, time/batch = 0.1623s	
1234/2700 (epoch 22.852), train_loss = 1.67925225, grad/param norm = 6.9126e-01, time/batch = 0.1855s	
1235/2700 (epoch 22.870), train_loss = 1.66854166, grad/param norm = 7.3154e-01, time/batch = 0.1845s	
1236/2700 (epoch 22.889), train_loss = 1.68574458, grad/param norm = 7.0195e-01, time/batch = 0.1867s	
1237/2700 (epoch 22.907), train_loss = 1.79177996, grad/param norm = 5.5999e-01, time/batch = 0.1860s	
1238/2700 (epoch 22.926), train_loss = 1.70227345, grad/param norm = 5.1690e-01, time/batch = 0.1790s	
1239/2700 (epoch 22.944), train_loss = 1.68652918, grad/param norm = 5.4857e-01, time/batch = 0.1852s	
1240/2700 (epoch 22.963), train_loss = 1.71750836, grad/param norm = 6.0845e-01, time/batch = 0.1808s	
1241/2700 (epoch 22.981), train_loss = 1.69223443, grad/param norm = 5.2898e-01, time/batch = 0.1606s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1242/2700 (epoch 23.000), train_loss = 1.73747184, grad/param norm = 5.1489e-01, time/batch = 0.1639s	
1243/2700 (epoch 23.019), train_loss = 1.73604715, grad/param norm = 5.9132e-01, time/batch = 0.1575s	
1244/2700 (epoch 23.037), train_loss = 1.73600446, grad/param norm = 5.5892e-01, time/batch = 0.1640s	
1245/2700 (epoch 23.056), train_loss = 1.63596638, grad/param norm = 5.4369e-01, time/batch = 0.1668s	
1246/2700 (epoch 23.074), train_loss = 1.65189906, grad/param norm = 5.5359e-01, time/batch = 0.1759s	
1247/2700 (epoch 23.093), train_loss = 1.65846040, grad/param norm = 5.0847e-01, time/batch = 0.1706s	
1248/2700 (epoch 23.111), train_loss = 1.61528507, grad/param norm = 6.7078e-01, time/batch = 0.1807s	
1249/2700 (epoch 23.130), train_loss = 1.68494415, grad/param norm = 7.5743e-01, time/batch = 0.1854s	
1250/2700 (epoch 23.148), train_loss = 1.60773405, grad/param norm = 5.7775e-01, time/batch = 0.1838s	
1251/2700 (epoch 23.167), train_loss = 1.68909216, grad/param norm = 4.4601e-01, time/batch = 0.1644s	
1252/2700 (epoch 23.185), train_loss = 1.59638064, grad/param norm = 4.1268e-01, time/batch = 0.1598s	
1253/2700 (epoch 23.204), train_loss = 1.66333467, grad/param norm = 4.9629e-01, time/batch = 0.1730s	
1254/2700 (epoch 23.222), train_loss = 1.60984620, grad/param norm = 4.9197e-01, time/batch = 0.1830s	
1255/2700 (epoch 23.241), train_loss = 1.53755255, grad/param norm = 4.7718e-01, time/batch = 0.1836s	
1256/2700 (epoch 23.259), train_loss = 1.60000063, grad/param norm = 4.7909e-01, time/batch = 0.1804s	
1257/2700 (epoch 23.278), train_loss = 1.69394850, grad/param norm = 4.9558e-01, time/batch = 0.1702s	
1258/2700 (epoch 23.296), train_loss = 1.65871527, grad/param norm = 5.2356e-01, time/batch = 0.1719s	
1259/2700 (epoch 23.315), train_loss = 1.66547569, grad/param norm = 5.6316e-01, time/batch = 0.1787s	
1260/2700 (epoch 23.333), train_loss = 1.65840952, grad/param norm = 5.7631e-01, time/batch = 0.1851s	
1261/2700 (epoch 23.352), train_loss = 1.68547937, grad/param norm = 1.0305e+00, time/batch = 0.1734s	
1262/2700 (epoch 23.370), train_loss = 1.71295506, grad/param norm = 8.1593e-01, time/batch = 0.1455s	
1263/2700 (epoch 23.389), train_loss = 1.68266160, grad/param norm = 6.9241e-01, time/batch = 0.1831s	
1264/2700 (epoch 23.407), train_loss = 1.69728489, grad/param norm = 6.6406e-01, time/batch = 0.1854s	
1265/2700 (epoch 23.426), train_loss = 1.69901061, grad/param norm = 5.8774e-01, time/batch = 0.1850s	
1266/2700 (epoch 23.444), train_loss = 1.62405706, grad/param norm = 4.9589e-01, time/batch = 0.1863s	
1267/2700 (epoch 23.463), train_loss = 1.69039995, grad/param norm = 4.9526e-01, time/batch = 0.1823s	
1268/2700 (epoch 23.481), train_loss = 1.69806805, grad/param norm = 5.2586e-01, time/batch = 0.1736s	
1269/2700 (epoch 23.500), train_loss = 1.67746086, grad/param norm = 6.4024e-01, time/batch = 0.1725s	
1270/2700 (epoch 23.519), train_loss = 1.67514967, grad/param norm = 5.0741e-01, time/batch = 0.1641s	
1271/2700 (epoch 23.537), train_loss = 1.68213589, grad/param norm = 4.7790e-01, time/batch = 0.1668s	
1272/2700 (epoch 23.556), train_loss = 1.61303403, grad/param norm = 5.2446e-01, time/batch = 0.1536s	
1273/2700 (epoch 23.574), train_loss = 1.62290140, grad/param norm = 5.5443e-01, time/batch = 0.1837s	
1274/2700 (epoch 23.593), train_loss = 1.62740308, grad/param norm = 5.7745e-01, time/batch = 0.1795s	
1275/2700 (epoch 23.611), train_loss = 1.54443990, grad/param norm = 5.4217e-01, time/batch = 0.1644s	
1276/2700 (epoch 23.630), train_loss = 1.59134183, grad/param norm = 5.2583e-01, time/batch = 0.1835s	
1277/2700 (epoch 23.648), train_loss = 1.64428574, grad/param norm = 6.0903e-01, time/batch = 0.1786s	
1278/2700 (epoch 23.667), train_loss = 1.59436329, grad/param norm = 4.5266e-01, time/batch = 0.1683s	
1279/2700 (epoch 23.685), train_loss = 1.62444966, grad/param norm = 4.4130e-01, time/batch = 0.1701s	
1280/2700 (epoch 23.704), train_loss = 1.64397920, grad/param norm = 4.9623e-01, time/batch = 0.1830s	
1281/2700 (epoch 23.722), train_loss = 1.61454195, grad/param norm = 5.1097e-01, time/batch = 0.1741s	
1282/2700 (epoch 23.741), train_loss = 1.65681653, grad/param norm = 4.6519e-01, time/batch = 0.1601s	
1283/2700 (epoch 23.759), train_loss = 1.65121194, grad/param norm = 4.5752e-01, time/batch = 0.1845s	
1284/2700 (epoch 23.778), train_loss = 1.68090151, grad/param norm = 4.6851e-01, time/batch = 0.1763s	
1285/2700 (epoch 23.796), train_loss = 1.63047190, grad/param norm = 5.1807e-01, time/batch = 0.1721s	
1286/2700 (epoch 23.815), train_loss = 1.66276429, grad/param norm = 5.3719e-01, time/batch = 0.1661s	
1287/2700 (epoch 23.833), train_loss = 1.63519730, grad/param norm = 6.4355e-01, time/batch = 0.1664s	
1288/2700 (epoch 23.852), train_loss = 1.65514363, grad/param norm = 6.6775e-01, time/batch = 0.1654s	
1289/2700 (epoch 23.870), train_loss = 1.64841652, grad/param norm = 5.7599e-01, time/batch = 0.1506s	
1290/2700 (epoch 23.889), train_loss = 1.65699779, grad/param norm = 5.5236e-01, time/batch = 0.1815s	
1291/2700 (epoch 23.907), train_loss = 1.77961470, grad/param norm = 7.1052e-01, time/batch = 0.1669s	
1292/2700 (epoch 23.926), train_loss = 1.70673801, grad/param norm = 8.4325e-01, time/batch = 0.1733s	
1293/2700 (epoch 23.944), train_loss = 1.68356758, grad/param norm = 7.8182e-01, time/batch = 0.1738s	
1294/2700 (epoch 23.963), train_loss = 1.70121048, grad/param norm = 6.0473e-01, time/batch = 0.1840s	
1295/2700 (epoch 23.981), train_loss = 1.66401293, grad/param norm = 4.4614e-01, time/batch = 0.1841s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1296/2700 (epoch 24.000), train_loss = 1.72588353, grad/param norm = 5.3509e-01, time/batch = 0.1848s	
1297/2700 (epoch 24.019), train_loss = 1.71727806, grad/param norm = 5.9519e-01, time/batch = 0.1834s	
1298/2700 (epoch 24.037), train_loss = 1.71887421, grad/param norm = 5.3914e-01, time/batch = 0.1780s	
1299/2700 (epoch 24.056), train_loss = 1.61485323, grad/param norm = 4.8572e-01, time/batch = 0.1821s	
1300/2700 (epoch 24.074), train_loss = 1.63370647, grad/param norm = 5.2975e-01, time/batch = 0.1734s	
1301/2700 (epoch 24.093), train_loss = 1.64057312, grad/param norm = 5.3221e-01, time/batch = 0.1636s	
1302/2700 (epoch 24.111), train_loss = 1.59349023, grad/param norm = 5.9425e-01, time/batch = 0.1804s	
1303/2700 (epoch 24.130), train_loss = 1.66039000, grad/param norm = 5.6766e-01, time/batch = 0.1848s	
1304/2700 (epoch 24.148), train_loss = 1.58821810, grad/param norm = 4.9602e-01, time/batch = 0.1866s	
1305/2700 (epoch 24.167), train_loss = 1.67539902, grad/param norm = 6.1255e-01, time/batch = 0.1793s	
1306/2700 (epoch 24.185), train_loss = 1.58339586, grad/param norm = 5.6014e-01, time/batch = 0.1673s	
1307/2700 (epoch 24.204), train_loss = 1.65740070, grad/param norm = 6.0262e-01, time/batch = 0.1696s	
1308/2700 (epoch 24.222), train_loss = 1.59813888, grad/param norm = 5.9546e-01, time/batch = 0.1625s	
1309/2700 (epoch 24.241), train_loss = 1.52134643, grad/param norm = 5.6012e-01, time/batch = 0.1585s	
1310/2700 (epoch 24.259), train_loss = 1.57979976, grad/param norm = 4.8628e-01, time/batch = 0.1574s	
1311/2700 (epoch 24.278), train_loss = 1.67502483, grad/param norm = 4.7979e-01, time/batch = 0.1643s	
1312/2700 (epoch 24.296), train_loss = 1.64153506, grad/param norm = 5.1492e-01, time/batch = 0.1533s	
1313/2700 (epoch 24.315), train_loss = 1.64375092, grad/param norm = 5.2669e-01, time/batch = 0.1622s	
1314/2700 (epoch 24.333), train_loss = 1.63592189, grad/param norm = 5.5114e-01, time/batch = 0.1665s	
1315/2700 (epoch 24.352), train_loss = 1.65709595, grad/param norm = 8.9724e-01, time/batch = 0.1773s	
1316/2700 (epoch 24.370), train_loss = 1.67741948, grad/param norm = 6.6913e-01, time/batch = 0.1854s	
1317/2700 (epoch 24.389), train_loss = 1.64986573, grad/param norm = 5.3795e-01, time/batch = 0.1754s	
1318/2700 (epoch 24.407), train_loss = 1.67252771, grad/param norm = 5.0438e-01, time/batch = 0.1838s	
1319/2700 (epoch 24.426), train_loss = 1.67352990, grad/param norm = 5.0158e-01, time/batch = 0.1838s	
1320/2700 (epoch 24.444), train_loss = 1.60430252, grad/param norm = 5.1066e-01, time/batch = 0.1804s	
1321/2700 (epoch 24.463), train_loss = 1.67111357, grad/param norm = 4.9714e-01, time/batch = 0.1520s	
1322/2700 (epoch 24.481), train_loss = 1.67637601, grad/param norm = 4.8230e-01, time/batch = 0.1736s	
1323/2700 (epoch 24.500), train_loss = 1.65627619, grad/param norm = 6.0606e-01, time/batch = 0.1784s	
1324/2700 (epoch 24.519), train_loss = 1.65628335, grad/param norm = 5.1009e-01, time/batch = 0.1814s	
1325/2700 (epoch 24.537), train_loss = 1.66109627, grad/param norm = 4.6547e-01, time/batch = 0.1838s	
1326/2700 (epoch 24.556), train_loss = 1.59109210, grad/param norm = 4.8825e-01, time/batch = 0.1791s	
1327/2700 (epoch 24.574), train_loss = 1.60119092, grad/param norm = 5.3393e-01, time/batch = 0.1810s	
1328/2700 (epoch 24.593), train_loss = 1.61103632, grad/param norm = 5.5600e-01, time/batch = 0.1847s	
1329/2700 (epoch 24.611), train_loss = 1.52688660, grad/param norm = 5.4611e-01, time/batch = 0.1837s	
1330/2700 (epoch 24.630), train_loss = 1.57690128, grad/param norm = 5.5331e-01, time/batch = 0.1766s	
1331/2700 (epoch 24.648), train_loss = 1.62259106, grad/param norm = 5.6456e-01, time/batch = 0.1771s	
1332/2700 (epoch 24.667), train_loss = 1.57462873, grad/param norm = 4.4543e-01, time/batch = 0.1652s	
1333/2700 (epoch 24.685), train_loss = 1.61524912, grad/param norm = 5.2340e-01, time/batch = 0.1590s	
1334/2700 (epoch 24.704), train_loss = 1.64098235, grad/param norm = 6.0037e-01, time/batch = 0.1601s	
1335/2700 (epoch 24.722), train_loss = 1.60695673, grad/param norm = 5.9341e-01, time/batch = 0.1703s	
1336/2700 (epoch 24.741), train_loss = 1.64358833, grad/param norm = 4.9212e-01, time/batch = 0.1649s	
1337/2700 (epoch 24.759), train_loss = 1.63530900, grad/param norm = 4.7996e-01, time/batch = 0.1694s	
1338/2700 (epoch 24.778), train_loss = 1.66502921, grad/param norm = 4.9605e-01, time/batch = 0.1783s	
1339/2700 (epoch 24.796), train_loss = 1.61268170, grad/param norm = 5.4568e-01, time/batch = 0.1881s	
1340/2700 (epoch 24.815), train_loss = 1.64827962, grad/param norm = 5.4656e-01, time/batch = 0.1879s	
1341/2700 (epoch 24.833), train_loss = 1.62779868, grad/param norm = 6.7986e-01, time/batch = 0.1812s	
1342/2700 (epoch 24.852), train_loss = 1.63823976, grad/param norm = 6.9002e-01, time/batch = 0.1826s	
1343/2700 (epoch 24.870), train_loss = 1.62877031, grad/param norm = 6.1927e-01, time/batch = 0.1825s	
1344/2700 (epoch 24.889), train_loss = 1.63730275, grad/param norm = 5.9802e-01, time/batch = 0.1794s	
1345/2700 (epoch 24.907), train_loss = 1.75627675, grad/param norm = 5.4703e-01, time/batch = 0.1644s	
1346/2700 (epoch 24.926), train_loss = 1.67015250, grad/param norm = 5.2679e-01, time/batch = 0.1704s	
1347/2700 (epoch 24.944), train_loss = 1.64915488, grad/param norm = 5.5393e-01, time/batch = 0.1760s	
1348/2700 (epoch 24.963), train_loss = 1.67760962, grad/param norm = 5.8539e-01, time/batch = 0.1716s	
1349/2700 (epoch 24.981), train_loss = 1.64984662, grad/param norm = 5.0726e-01, time/batch = 0.1594s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1350/2700 (epoch 25.000), train_loss = 1.70408275, grad/param norm = 5.0903e-01, time/batch = 0.1826s	
1351/2700 (epoch 25.019), train_loss = 1.69601760, grad/param norm = 5.4185e-01, time/batch = 0.1753s	
1352/2700 (epoch 25.037), train_loss = 1.69190161, grad/param norm = 4.5971e-01, time/batch = 0.1670s	
1353/2700 (epoch 25.056), train_loss = 1.59241404, grad/param norm = 4.7143e-01, time/batch = 0.1622s	
1354/2700 (epoch 25.074), train_loss = 1.61792839, grad/param norm = 5.6206e-01, time/batch = 0.1525s	
1355/2700 (epoch 25.093), train_loss = 1.61819960, grad/param norm = 4.7872e-01, time/batch = 0.1854s	
1356/2700 (epoch 25.111), train_loss = 1.56878429, grad/param norm = 5.2555e-01, time/batch = 0.1829s	
1357/2700 (epoch 25.130), train_loss = 1.64057415, grad/param norm = 5.8102e-01, time/batch = 0.1797s	
1358/2700 (epoch 25.148), train_loss = 1.57060658, grad/param norm = 5.0792e-01, time/batch = 0.1803s	
1359/2700 (epoch 25.167), train_loss = 1.64993486, grad/param norm = 4.5563e-01, time/batch = 0.1738s	
1360/2700 (epoch 25.185), train_loss = 1.55970757, grad/param norm = 4.2173e-01, time/batch = 0.1768s	
1361/2700 (epoch 25.204), train_loss = 1.63238766, grad/param norm = 4.9617e-01, time/batch = 0.1831s	
1362/2700 (epoch 25.222), train_loss = 1.57561726, grad/param norm = 4.9453e-01, time/batch = 0.1770s	
1363/2700 (epoch 25.241), train_loss = 1.50568784, grad/param norm = 4.7707e-01, time/batch = 0.1708s	
1364/2700 (epoch 25.259), train_loss = 1.56625642, grad/param norm = 4.7715e-01, time/batch = 0.1840s	
1365/2700 (epoch 25.278), train_loss = 1.65891954, grad/param norm = 4.8863e-01, time/batch = 0.1845s	
1366/2700 (epoch 25.296), train_loss = 1.62476378, grad/param norm = 5.0326e-01, time/batch = 0.1819s	
1367/2700 (epoch 25.315), train_loss = 1.62444806, grad/param norm = 5.3531e-01, time/batch = 0.1820s	
1368/2700 (epoch 25.333), train_loss = 1.61197583, grad/param norm = 4.8434e-01, time/batch = 0.1733s	
1369/2700 (epoch 25.352), train_loss = 1.62618165, grad/param norm = 5.0080e-01, time/batch = 0.1855s	
1370/2700 (epoch 25.370), train_loss = 1.66381817, grad/param norm = 6.0968e-01, time/batch = 0.1858s	
1371/2700 (epoch 25.389), train_loss = 1.64557999, grad/param norm = 6.7479e-01, time/batch = 0.1747s	
1372/2700 (epoch 25.407), train_loss = 1.67207795, grad/param norm = 6.1981e-01, time/batch = 0.1547s	
1373/2700 (epoch 25.426), train_loss = 1.66880279, grad/param norm = 6.1695e-01, time/batch = 0.1570s	
1374/2700 (epoch 25.444), train_loss = 1.59723828, grad/param norm = 6.2855e-01, time/batch = 0.1583s	
1375/2700 (epoch 25.463), train_loss = 1.66074799, grad/param norm = 5.6925e-01, time/batch = 0.1638s	
1376/2700 (epoch 25.481), train_loss = 1.66157842, grad/param norm = 5.2695e-01, time/batch = 0.1726s	
1377/2700 (epoch 25.500), train_loss = 1.63577804, grad/param norm = 5.0152e-01, time/batch = 0.1815s	
1378/2700 (epoch 25.519), train_loss = 1.63719496, grad/param norm = 4.5500e-01, time/batch = 0.1598s	
1379/2700 (epoch 25.537), train_loss = 1.64894543, grad/param norm = 6.0844e-01, time/batch = 0.1837s	
1380/2700 (epoch 25.556), train_loss = 1.58684205, grad/param norm = 7.8618e-01, time/batch = 0.1831s	
1381/2700 (epoch 25.574), train_loss = 1.59485988, grad/param norm = 6.9615e-01, time/batch = 0.1644s	
1382/2700 (epoch 25.593), train_loss = 1.59640187, grad/param norm = 5.8114e-01, time/batch = 0.1598s	
1383/2700 (epoch 25.611), train_loss = 1.50794027, grad/param norm = 5.1629e-01, time/batch = 0.1811s	
1384/2700 (epoch 25.630), train_loss = 1.55476345, grad/param norm = 5.2199e-01, time/batch = 0.1859s	
1385/2700 (epoch 25.648), train_loss = 1.60349113, grad/param norm = 5.6377e-01, time/batch = 0.1871s	
1386/2700 (epoch 25.667), train_loss = 1.55621875, grad/param norm = 4.2576e-01, time/batch = 0.1836s	
1387/2700 (epoch 25.685), train_loss = 1.58871685, grad/param norm = 4.3402e-01, time/batch = 0.1793s	
1388/2700 (epoch 25.704), train_loss = 1.61374627, grad/param norm = 4.8433e-01, time/batch = 0.1811s	
1389/2700 (epoch 25.722), train_loss = 1.58265566, grad/param norm = 4.4264e-01, time/batch = 0.1790s	
1390/2700 (epoch 25.741), train_loss = 1.62466155, grad/param norm = 4.7168e-01, time/batch = 0.1754s	
1391/2700 (epoch 25.759), train_loss = 1.62327246, grad/param norm = 5.2571e-01, time/batch = 0.1709s	
1392/2700 (epoch 25.778), train_loss = 1.65163203, grad/param norm = 5.1328e-01, time/batch = 0.1829s	
1393/2700 (epoch 25.796), train_loss = 1.60107317, grad/param norm = 5.8596e-01, time/batch = 0.1848s	
1394/2700 (epoch 25.815), train_loss = 1.63750529, grad/param norm = 5.9143e-01, time/batch = 0.1671s	
1395/2700 (epoch 25.833), train_loss = 1.60439881, grad/param norm = 6.8072e-01, time/batch = 0.1667s	
1396/2700 (epoch 25.852), train_loss = 1.60925683, grad/param norm = 5.6487e-01, time/batch = 0.1544s	
1397/2700 (epoch 25.870), train_loss = 1.60559205, grad/param norm = 4.6792e-01, time/batch = 0.1816s	
1398/2700 (epoch 25.889), train_loss = 1.61625529, grad/param norm = 4.8808e-01, time/batch = 0.1858s	
1399/2700 (epoch 25.907), train_loss = 1.75008492, grad/param norm = 6.9048e-01, time/batch = 0.1844s	
1400/2700 (epoch 25.926), train_loss = 1.67554700, grad/param norm = 8.7433e-01, time/batch = 0.1844s	
1401/2700 (epoch 25.944), train_loss = 1.65093258, grad/param norm = 8.1496e-01, time/batch = 0.1526s	
1402/2700 (epoch 25.963), train_loss = 1.66471910, grad/param norm = 5.9598e-01, time/batch = 0.1768s	
1403/2700 (epoch 25.981), train_loss = 1.62739286, grad/param norm = 4.4019e-01, time/batch = 0.1819s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1404/2700 (epoch 26.000), train_loss = 1.68346958, grad/param norm = 5.0526e-01, time/batch = 0.1828s	
1405/2700 (epoch 26.019), train_loss = 1.68025434, grad/param norm = 5.3472e-01, time/batch = 0.1788s	
1406/2700 (epoch 26.037), train_loss = 1.67698737, grad/param norm = 5.3667e-01, time/batch = 0.1644s	
1407/2700 (epoch 26.056), train_loss = 1.57549637, grad/param norm = 4.9528e-01, time/batch = 0.1471s	
1408/2700 (epoch 26.074), train_loss = 1.59692036, grad/param norm = 4.5867e-01, time/batch = 0.1740s	
1409/2700 (epoch 26.093), train_loss = 1.60183160, grad/param norm = 4.4073e-01, time/batch = 0.1737s	
1410/2700 (epoch 26.111), train_loss = 1.55394460, grad/param norm = 5.7215e-01, time/batch = 0.1817s	
1411/2700 (epoch 26.130), train_loss = 1.62163816, grad/param norm = 5.3464e-01, time/batch = 0.1656s	
1412/2700 (epoch 26.148), train_loss = 1.55288285, grad/param norm = 4.7601e-01, time/batch = 0.1635s	
1413/2700 (epoch 26.167), train_loss = 1.63690570, grad/param norm = 6.0070e-01, time/batch = 0.1675s	
1414/2700 (epoch 26.185), train_loss = 1.55714323, grad/param norm = 6.4575e-01, time/batch = 0.1652s	
1415/2700 (epoch 26.204), train_loss = 1.63898715, grad/param norm = 7.3004e-01, time/batch = 0.1627s	
1416/2700 (epoch 26.222), train_loss = 1.57113310, grad/param norm = 6.2999e-01, time/batch = 0.1778s	
1417/2700 (epoch 26.241), train_loss = 1.49599024, grad/param norm = 5.3803e-01, time/batch = 0.1587s	
1418/2700 (epoch 26.259), train_loss = 1.54978371, grad/param norm = 4.7745e-01, time/batch = 0.1659s	
1419/2700 (epoch 26.278), train_loss = 1.64340576, grad/param norm = 4.9659e-01, time/batch = 0.1629s	
1420/2700 (epoch 26.296), train_loss = 1.60562811, grad/param norm = 5.0574e-01, time/batch = 0.1612s	
1421/2700 (epoch 26.315), train_loss = 1.60276820, grad/param norm = 5.4175e-01, time/batch = 0.1868s	
1422/2700 (epoch 26.333), train_loss = 1.59241566, grad/param norm = 4.3919e-01, time/batch = 0.1843s	
1423/2700 (epoch 26.352), train_loss = 1.60836451, grad/param norm = 5.6481e-01, time/batch = 0.1683s	
1424/2700 (epoch 26.370), train_loss = 1.63059374, grad/param norm = 5.3617e-01, time/batch = 0.1562s	
1425/2700 (epoch 26.389), train_loss = 1.61432331, grad/param norm = 5.2764e-01, time/batch = 0.1685s	
1426/2700 (epoch 26.407), train_loss = 1.64368866, grad/param norm = 4.8798e-01, time/batch = 0.1569s	
1427/2700 (epoch 26.426), train_loss = 1.64435068, grad/param norm = 4.9278e-01, time/batch = 0.1708s	
1428/2700 (epoch 26.444), train_loss = 1.57762273, grad/param norm = 5.2948e-01, time/batch = 0.1807s	
1429/2700 (epoch 26.463), train_loss = 1.64522362, grad/param norm = 5.8448e-01, time/batch = 0.1861s	
1430/2700 (epoch 26.481), train_loss = 1.65000268, grad/param norm = 5.8350e-01, time/batch = 0.1847s	
1431/2700 (epoch 26.500), train_loss = 1.62377723, grad/param norm = 6.6430e-01, time/batch = 0.1742s	
1432/2700 (epoch 26.519), train_loss = 1.63104834, grad/param norm = 6.0142e-01, time/batch = 0.1637s	
1433/2700 (epoch 26.537), train_loss = 1.63133202, grad/param norm = 5.0430e-01, time/batch = 0.1471s	
1434/2700 (epoch 26.556), train_loss = 1.56039239, grad/param norm = 5.5506e-01, time/batch = 0.1654s	
1435/2700 (epoch 26.574), train_loss = 1.57161231, grad/param norm = 6.0648e-01, time/batch = 0.1679s	
1436/2700 (epoch 26.593), train_loss = 1.58000372, grad/param norm = 6.0257e-01, time/batch = 0.1500s	
1437/2700 (epoch 26.611), train_loss = 1.49489185, grad/param norm = 6.0768e-01, time/batch = 0.1797s	
1438/2700 (epoch 26.630), train_loss = 1.54210564, grad/param norm = 5.1069e-01, time/batch = 0.1748s	
1439/2700 (epoch 26.648), train_loss = 1.58863567, grad/param norm = 5.4749e-01, time/batch = 0.1609s	
1440/2700 (epoch 26.667), train_loss = 1.53989637, grad/param norm = 4.7890e-01, time/batch = 0.1706s	
1441/2700 (epoch 26.685), train_loss = 1.57855695, grad/param norm = 5.5655e-01, time/batch = 0.1813s	
1442/2700 (epoch 26.704), train_loss = 1.60315719, grad/param norm = 5.3547e-01, time/batch = 0.1505s	
1443/2700 (epoch 26.722), train_loss = 1.56974782, grad/param norm = 4.5625e-01, time/batch = 0.1744s	
1444/2700 (epoch 26.741), train_loss = 1.60912398, grad/param norm = 4.8180e-01, time/batch = 0.1770s	
1445/2700 (epoch 26.759), train_loss = 1.60266757, grad/param norm = 5.1160e-01, time/batch = 0.1696s	
1446/2700 (epoch 26.778), train_loss = 1.62751626, grad/param norm = 4.6493e-01, time/batch = 0.1844s	
1447/2700 (epoch 26.796), train_loss = 1.57733771, grad/param norm = 5.1163e-01, time/batch = 0.1826s	
1448/2700 (epoch 26.815), train_loss = 1.61466502, grad/param norm = 5.0104e-01, time/batch = 0.1719s	
1449/2700 (epoch 26.833), train_loss = 1.58792818, grad/param norm = 6.0216e-01, time/batch = 0.1860s	
1450/2700 (epoch 26.852), train_loss = 1.59550665, grad/param norm = 5.4676e-01, time/batch = 0.1880s	
1451/2700 (epoch 26.870), train_loss = 1.59586707, grad/param norm = 5.4418e-01, time/batch = 0.1761s	
1452/2700 (epoch 26.889), train_loss = 1.59969887, grad/param norm = 5.6949e-01, time/batch = 0.1649s	
1453/2700 (epoch 26.907), train_loss = 1.72159456, grad/param norm = 5.4247e-01, time/batch = 0.1632s	
1454/2700 (epoch 26.926), train_loss = 1.63653707, grad/param norm = 5.3026e-01, time/batch = 0.1660s	
1455/2700 (epoch 26.944), train_loss = 1.61846512, grad/param norm = 6.3747e-01, time/batch = 0.1523s	
1456/2700 (epoch 26.963), train_loss = 1.64531096, grad/param norm = 6.5916e-01, time/batch = 0.1842s	
1457/2700 (epoch 26.981), train_loss = 1.61634072, grad/param norm = 5.3497e-01, time/batch = 0.1857s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1458/2700 (epoch 27.000), train_loss = 1.66737474, grad/param norm = 5.0088e-01, time/batch = 0.1751s	
1459/2700 (epoch 27.019), train_loss = 1.66781388, grad/param norm = 5.2241e-01, time/batch = 0.1631s	
1460/2700 (epoch 27.037), train_loss = 1.65956428, grad/param norm = 5.0042e-01, time/batch = 0.1739s	
1461/2700 (epoch 27.056), train_loss = 1.55815390, grad/param norm = 4.9912e-01, time/batch = 0.1840s	
1462/2700 (epoch 27.074), train_loss = 1.58472622, grad/param norm = 5.3671e-01, time/batch = 0.1818s	
1463/2700 (epoch 27.093), train_loss = 1.58409555, grad/param norm = 4.6219e-01, time/batch = 0.1816s	
1464/2700 (epoch 27.111), train_loss = 1.53312317, grad/param norm = 4.9234e-01, time/batch = 0.1798s	
1465/2700 (epoch 27.130), train_loss = 1.60332772, grad/param norm = 4.5537e-01, time/batch = 0.1743s	
1466/2700 (epoch 27.148), train_loss = 1.53606055, grad/param norm = 4.6954e-01, time/batch = 0.1658s	
1467/2700 (epoch 27.167), train_loss = 1.61977441, grad/param norm = 6.0283e-01, time/batch = 0.1537s	
1468/2700 (epoch 27.185), train_loss = 1.53324089, grad/param norm = 5.7794e-01, time/batch = 0.1818s	
1469/2700 (epoch 27.204), train_loss = 1.61211406, grad/param norm = 6.5838e-01, time/batch = 0.1715s	
1470/2700 (epoch 27.222), train_loss = 1.55032819, grad/param norm = 6.2043e-01, time/batch = 0.1587s	
1471/2700 (epoch 27.241), train_loss = 1.47928602, grad/param norm = 5.8368e-01, time/batch = 0.1845s	
1472/2700 (epoch 27.259), train_loss = 1.53286317, grad/param norm = 5.1071e-01, time/batch = 0.1844s	
1473/2700 (epoch 27.278), train_loss = 1.62949046, grad/param norm = 5.0268e-01, time/batch = 0.1828s	
1474/2700 (epoch 27.296), train_loss = 1.59506551, grad/param norm = 5.5963e-01, time/batch = 0.1772s	
1475/2700 (epoch 27.315), train_loss = 1.59229779, grad/param norm = 5.9818e-01, time/batch = 0.1843s	
1476/2700 (epoch 27.333), train_loss = 1.58877818, grad/param norm = 5.5898e-01, time/batch = 0.1811s	
1477/2700 (epoch 27.352), train_loss = 1.60405128, grad/param norm = 7.3777e-01, time/batch = 0.1833s	
1478/2700 (epoch 27.370), train_loss = 1.61598889, grad/param norm = 5.6370e-01, time/batch = 0.1773s	
1479/2700 (epoch 27.389), train_loss = 1.59801399, grad/param norm = 5.1480e-01, time/batch = 0.1607s	
1480/2700 (epoch 27.407), train_loss = 1.62586345, grad/param norm = 4.6676e-01, time/batch = 0.1832s	
1481/2700 (epoch 27.426), train_loss = 1.62725838, grad/param norm = 4.8332e-01, time/batch = 0.1867s	
1482/2700 (epoch 27.444), train_loss = 1.55911438, grad/param norm = 5.0425e-01, time/batch = 0.1841s	
1483/2700 (epoch 27.463), train_loss = 1.62304718, grad/param norm = 4.8387e-01, time/batch = 0.1718s	
1484/2700 (epoch 27.481), train_loss = 1.62740264, grad/param norm = 4.9862e-01, time/batch = 0.1646s	
1485/2700 (epoch 27.500), train_loss = 1.60161159, grad/param norm = 6.1068e-01, time/batch = 0.1804s	
1486/2700 (epoch 27.519), train_loss = 1.60942006, grad/param norm = 5.1124e-01, time/batch = 0.1664s	
1487/2700 (epoch 27.537), train_loss = 1.61202774, grad/param norm = 4.6928e-01, time/batch = 0.1775s	
1488/2700 (epoch 27.556), train_loss = 1.53930857, grad/param norm = 4.5338e-01, time/batch = 0.1652s	
1489/2700 (epoch 27.574), train_loss = 1.55055677, grad/param norm = 5.3348e-01, time/batch = 0.1795s	
1490/2700 (epoch 27.593), train_loss = 1.56563782, grad/param norm = 5.5735e-01, time/batch = 0.1849s	
1491/2700 (epoch 27.611), train_loss = 1.48027934, grad/param norm = 5.5288e-01, time/batch = 0.1764s	
1492/2700 (epoch 27.630), train_loss = 1.52645664, grad/param norm = 5.1216e-01, time/batch = 0.1709s	
1493/2700 (epoch 27.648), train_loss = 1.57207076, grad/param norm = 5.2306e-01, time/batch = 0.1801s	
1494/2700 (epoch 27.667), train_loss = 1.52010077, grad/param norm = 4.2215e-01, time/batch = 0.1730s	
1495/2700 (epoch 27.685), train_loss = 1.56033941, grad/param norm = 5.0136e-01, time/batch = 0.1750s	
1496/2700 (epoch 27.704), train_loss = 1.58907225, grad/param norm = 5.3078e-01, time/batch = 0.1834s	
1497/2700 (epoch 27.722), train_loss = 1.55528525, grad/param norm = 4.6039e-01, time/batch = 0.1803s	
1498/2700 (epoch 27.741), train_loss = 1.59134159, grad/param norm = 4.4571e-01, time/batch = 0.1847s	
1499/2700 (epoch 27.759), train_loss = 1.58445092, grad/param norm = 4.6876e-01, time/batch = 0.1848s	
1500/2700 (epoch 27.778), train_loss = 1.61139442, grad/param norm = 4.5201e-01, time/batch = 0.1842s	
1501/2700 (epoch 27.796), train_loss = 1.55988391, grad/param norm = 4.9610e-01, time/batch = 0.1611s	
1502/2700 (epoch 27.815), train_loss = 1.59836115, grad/param norm = 4.6989e-01, time/batch = 0.1607s	
1503/2700 (epoch 27.833), train_loss = 1.56886929, grad/param norm = 5.9688e-01, time/batch = 0.1673s	
1504/2700 (epoch 27.852), train_loss = 1.58094282, grad/param norm = 5.5507e-01, time/batch = 0.1616s	
1505/2700 (epoch 27.870), train_loss = 1.58192594, grad/param norm = 4.9628e-01, time/batch = 0.1695s	
1506/2700 (epoch 27.889), train_loss = 1.58100314, grad/param norm = 4.9151e-01, time/batch = 0.1698s	
1507/2700 (epoch 27.907), train_loss = 1.71169662, grad/param norm = 6.5901e-01, time/batch = 0.1678s	
1508/2700 (epoch 27.926), train_loss = 1.63839600, grad/param norm = 8.4544e-01, time/batch = 0.1774s	
1509/2700 (epoch 27.944), train_loss = 1.61963153, grad/param norm = 7.9265e-01, time/batch = 0.1803s	
1510/2700 (epoch 27.963), train_loss = 1.63174977, grad/param norm = 5.9572e-01, time/batch = 0.1834s	
1511/2700 (epoch 27.981), train_loss = 1.59662509, grad/param norm = 4.6143e-01, time/batch = 0.1731s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1512/2700 (epoch 28.000), train_loss = 1.65190058, grad/param norm = 5.0536e-01, time/batch = 0.1821s	
1513/2700 (epoch 28.019), train_loss = 1.65370876, grad/param norm = 5.3919e-01, time/batch = 0.1851s	
1514/2700 (epoch 28.037), train_loss = 1.64925504, grad/param norm = 6.3363e-01, time/batch = 0.1561s	
1515/2700 (epoch 28.056), train_loss = 1.54389937, grad/param norm = 5.4586e-01, time/batch = 0.1859s	
1516/2700 (epoch 28.074), train_loss = 1.56728997, grad/param norm = 4.3875e-01, time/batch = 0.1826s	
1517/2700 (epoch 28.093), train_loss = 1.57014103, grad/param norm = 4.5126e-01, time/batch = 0.1854s	
1518/2700 (epoch 28.111), train_loss = 1.52206059, grad/param norm = 6.0077e-01, time/batch = 0.1848s	
1519/2700 (epoch 28.130), train_loss = 1.59067636, grad/param norm = 5.2470e-01, time/batch = 0.1865s	
1520/2700 (epoch 28.148), train_loss = 1.52435675, grad/param norm = 4.9100e-01, time/batch = 0.1812s	
1521/2700 (epoch 28.167), train_loss = 1.60330367, grad/param norm = 5.8257e-01, time/batch = 0.1646s	
1522/2700 (epoch 28.185), train_loss = 1.52331483, grad/param norm = 5.8432e-01, time/batch = 0.1659s	
1523/2700 (epoch 28.204), train_loss = 1.59998204, grad/param norm = 6.2178e-01, time/batch = 0.1655s	
1524/2700 (epoch 28.222), train_loss = 1.53321676, grad/param norm = 5.3347e-01, time/batch = 0.1508s	
1525/2700 (epoch 28.241), train_loss = 1.46732880, grad/param norm = 5.0966e-01, time/batch = 0.1722s	
1526/2700 (epoch 28.259), train_loss = 1.52219623, grad/param norm = 4.8309e-01, time/batch = 0.1642s	
1527/2700 (epoch 28.278), train_loss = 1.61370214, grad/param norm = 5.1792e-01, time/batch = 0.1781s	
1528/2700 (epoch 28.296), train_loss = 1.57557259, grad/param norm = 5.1847e-01, time/batch = 0.1683s	
1529/2700 (epoch 28.315), train_loss = 1.56757702, grad/param norm = 5.5636e-01, time/batch = 0.1707s	
1530/2700 (epoch 28.333), train_loss = 1.56154929, grad/param norm = 4.5993e-01, time/batch = 0.1823s	
1531/2700 (epoch 28.352), train_loss = 1.57463074, grad/param norm = 4.8996e-01, time/batch = 0.1740s	
1532/2700 (epoch 28.370), train_loss = 1.61320893, grad/param norm = 7.0516e-01, time/batch = 0.1766s	
1533/2700 (epoch 28.389), train_loss = 1.59997027, grad/param norm = 7.7716e-01, time/batch = 0.1720s	
1534/2700 (epoch 28.407), train_loss = 1.62650769, grad/param norm = 6.4790e-01, time/batch = 0.1585s	
1535/2700 (epoch 28.426), train_loss = 1.62405070, grad/param norm = 6.0319e-01, time/batch = 0.1684s	
1536/2700 (epoch 28.444), train_loss = 1.54916946, grad/param norm = 5.6829e-01, time/batch = 0.1684s	
1537/2700 (epoch 28.463), train_loss = 1.61047122, grad/param norm = 4.8251e-01, time/batch = 0.1706s	
1538/2700 (epoch 28.481), train_loss = 1.61227156, grad/param norm = 4.9432e-01, time/batch = 0.1737s	
1539/2700 (epoch 28.500), train_loss = 1.58462492, grad/param norm = 5.2904e-01, time/batch = 0.1784s	
1540/2700 (epoch 28.519), train_loss = 1.59279547, grad/param norm = 4.3000e-01, time/batch = 0.1717s	
1541/2700 (epoch 28.537), train_loss = 1.59781959, grad/param norm = 5.1841e-01, time/batch = 0.1821s	
1542/2700 (epoch 28.556), train_loss = 1.52911104, grad/param norm = 5.6005e-01, time/batch = 0.1866s	
1543/2700 (epoch 28.574), train_loss = 1.53729573, grad/param norm = 5.7688e-01, time/batch = 0.1674s	
1544/2700 (epoch 28.593), train_loss = 1.55320936, grad/param norm = 5.6343e-01, time/batch = 0.1757s	
1545/2700 (epoch 28.611), train_loss = 1.46566868, grad/param norm = 5.5145e-01, time/batch = 0.1807s	
1546/2700 (epoch 28.630), train_loss = 1.51118799, grad/param norm = 5.4833e-01, time/batch = 0.1798s	
1547/2700 (epoch 28.648), train_loss = 1.55807262, grad/param norm = 5.3744e-01, time/batch = 0.1812s	
1548/2700 (epoch 28.667), train_loss = 1.50627413, grad/param norm = 4.2274e-01, time/batch = 0.1854s	
1549/2700 (epoch 28.685), train_loss = 1.54299429, grad/param norm = 4.5511e-01, time/batch = 0.1857s	
1550/2700 (epoch 28.704), train_loss = 1.57120649, grad/param norm = 4.9567e-01, time/batch = 0.1844s	
1551/2700 (epoch 28.722), train_loss = 1.54208311, grad/param norm = 4.7215e-01, time/batch = 0.1868s	
1552/2700 (epoch 28.741), train_loss = 1.57892279, grad/param norm = 4.7461e-01, time/batch = 0.1687s	
1553/2700 (epoch 28.759), train_loss = 1.57133397, grad/param norm = 4.9129e-01, time/batch = 0.1728s	
1554/2700 (epoch 28.778), train_loss = 1.59786095, grad/param norm = 4.6597e-01, time/batch = 0.1755s	
1555/2700 (epoch 28.796), train_loss = 1.54061743, grad/param norm = 4.9735e-01, time/batch = 0.1786s	
1556/2700 (epoch 28.815), train_loss = 1.58242496, grad/param norm = 4.6293e-01, time/batch = 0.1715s	
1557/2700 (epoch 28.833), train_loss = 1.55419219, grad/param norm = 5.9561e-01, time/batch = 0.1744s	
1558/2700 (epoch 28.852), train_loss = 1.56248202, grad/param norm = 5.1106e-01, time/batch = 0.1768s	
1559/2700 (epoch 28.870), train_loss = 1.56508896, grad/param norm = 4.8526e-01, time/batch = 0.1810s	
1560/2700 (epoch 28.889), train_loss = 1.56913821, grad/param norm = 4.9310e-01, time/batch = 0.1829s	
1561/2700 (epoch 28.907), train_loss = 1.70011601, grad/param norm = 5.8184e-01, time/batch = 0.1659s	
1562/2700 (epoch 28.926), train_loss = 1.61439534, grad/param norm = 6.3835e-01, time/batch = 0.1693s	
1563/2700 (epoch 28.944), train_loss = 1.59270615, grad/param norm = 6.7917e-01, time/batch = 0.1491s	
1564/2700 (epoch 28.963), train_loss = 1.61139705, grad/param norm = 5.6761e-01, time/batch = 0.1766s	
1565/2700 (epoch 28.981), train_loss = 1.57856440, grad/param norm = 4.3776e-01, time/batch = 0.1849s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
1566/2700 (epoch 29.000), train_loss = 1.63656231, grad/param norm = 4.8402e-01, time/batch = 0.1866s	
1567/2700 (epoch 29.019), train_loss = 1.64063770, grad/param norm = 5.3767e-01, time/batch = 0.1860s	
1568/2700 (epoch 29.037), train_loss = 1.63563818, grad/param norm = 6.2054e-01, time/batch = 0.1841s	
1569/2700 (epoch 29.056), train_loss = 1.52852837, grad/param norm = 5.0888e-01, time/batch = 0.1871s	
1570/2700 (epoch 29.074), train_loss = 1.55310513, grad/param norm = 4.6145e-01, time/batch = 0.1858s	
1571/2700 (epoch 29.093), train_loss = 1.55633384, grad/param norm = 4.5613e-01, time/batch = 0.1469s	
1572/2700 (epoch 29.111), train_loss = 1.50362990, grad/param norm = 5.1300e-01, time/batch = 0.1570s	
1573/2700 (epoch 29.130), train_loss = 1.57372173, grad/param norm = 4.5199e-01, time/batch = 0.1467s	
1574/2700 (epoch 29.148), train_loss = 1.50920623, grad/param norm = 4.9456e-01, time/batch = 0.1802s	
1575/2700 (epoch 29.167), train_loss = 1.58914594, grad/param norm = 6.0027e-01, time/batch = 0.1834s	
1576/2700 (epoch 29.185), train_loss = 1.50573521, grad/param norm = 5.6390e-01, time/batch = 0.1867s	
1577/2700 (epoch 29.204), train_loss = 1.57941035, grad/param norm = 5.8190e-01, time/batch = 0.1866s	
1578/2700 (epoch 29.222), train_loss = 1.51540636, grad/param norm = 5.2306e-01, time/batch = 0.1784s	
1579/2700 (epoch 29.241), train_loss = 1.44880791, grad/param norm = 5.0023e-01, time/batch = 0.1679s	
1580/2700 (epoch 29.259), train_loss = 1.50378527, grad/param norm = 4.6983e-01, time/batch = 0.1736s	
1581/2700 (epoch 29.278), train_loss = 1.59928105, grad/param norm = 4.9504e-01, time/batch = 0.1745s	
1582/2700 (epoch 29.296), train_loss = 1.56229297, grad/param norm = 5.2566e-01, time/batch = 0.1826s	
1583/2700 (epoch 29.315), train_loss = 1.55259815, grad/param norm = 5.5301e-01, time/batch = 0.1712s	
1584/2700 (epoch 29.333), train_loss = 1.55210943, grad/param norm = 5.1988e-01, time/batch = 0.1763s	
1585/2700 (epoch 29.352), train_loss = 1.56725543, grad/param norm = 6.6741e-01, time/batch = 0.1777s	
1586/2700 (epoch 29.370), train_loss = 1.58298334, grad/param norm = 5.6077e-01, time/batch = 0.1763s	
1587/2700 (epoch 29.389), train_loss = 1.56760768, grad/param norm = 5.2747e-01, time/batch = 0.1713s	
1588/2700 (epoch 29.407), train_loss = 1.60036882, grad/param norm = 4.6289e-01, time/batch = 0.1640s	
1589/2700 (epoch 29.426), train_loss = 1.60549147, grad/param norm = 5.1625e-01, time/batch = 0.1773s	
1590/2700 (epoch 29.444), train_loss = 1.53590192, grad/param norm = 5.2486e-01, time/batch = 0.1782s	
1591/2700 (epoch 29.463), train_loss = 1.59647162, grad/param norm = 4.8979e-01, time/batch = 0.1822s	
1592/2700 (epoch 29.481), train_loss = 1.60049653, grad/param norm = 5.2231e-01, time/batch = 0.1641s	
1593/2700 (epoch 29.500), train_loss = 1.57114023, grad/param norm = 5.9213e-01, time/batch = 0.1763s	
1594/2700 (epoch 29.519), train_loss = 1.58319713, grad/param norm = 5.1915e-01, time/batch = 0.1786s	
1595/2700 (epoch 29.537), train_loss = 1.58411069, grad/param norm = 4.7842e-01, time/batch = 0.1808s	
1596/2700 (epoch 29.556), train_loss = 1.51152771, grad/param norm = 5.1559e-01, time/batch = 0.1810s	
1597/2700 (epoch 29.574), train_loss = 1.52376422, grad/param norm = 6.0769e-01, time/batch = 0.1764s	
1598/2700 (epoch 29.593), train_loss = 1.54214481, grad/param norm = 5.9960e-01, time/batch = 0.1957s	
1599/2700 (epoch 29.611), train_loss = 1.45143006, grad/param norm = 5.8592e-01, time/batch = 0.1767s	
1600/2700 (epoch 29.630), train_loss = 1.49533375, grad/param norm = 4.7316e-01, time/batch = 0.1767s	
1601/2700 (epoch 29.648), train_loss = 1.54513527, grad/param norm = 5.3467e-01, time/batch = 0.1704s	
1602/2700 (epoch 29.667), train_loss = 1.49480033, grad/param norm = 4.9932e-01, time/batch = 0.1570s	
1603/2700 (epoch 29.685), train_loss = 1.53475366, grad/param norm = 5.6708e-01, time/batch = 0.1876s	
1604/2700 (epoch 29.704), train_loss = 1.56159140, grad/param norm = 5.3182e-01, time/batch = 0.1887s	
1605/2700 (epoch 29.722), train_loss = 1.53160745, grad/param norm = 4.8591e-01, time/batch = 0.1695s	
1606/2700 (epoch 29.741), train_loss = 1.56852522, grad/param norm = 4.9793e-01, time/batch = 0.1613s	
1607/2700 (epoch 29.759), train_loss = 1.55580056, grad/param norm = 4.6994e-01, time/batch = 0.1628s	
1608/2700 (epoch 29.778), train_loss = 1.58044048, grad/param norm = 4.4685e-01, time/batch = 0.1685s	
1609/2700 (epoch 29.796), train_loss = 1.52874472, grad/param norm = 5.5458e-01, time/batch = 0.1701s	
1610/2700 (epoch 29.815), train_loss = 1.57287026, grad/param norm = 5.0346e-01, time/batch = 0.1795s	
1611/2700 (epoch 29.833), train_loss = 1.54536395, grad/param norm = 6.1510e-01, time/batch = 0.1744s	
1612/2700 (epoch 29.852), train_loss = 1.55306698, grad/param norm = 5.9496e-01, time/batch = 0.1812s	
1613/2700 (epoch 29.870), train_loss = 1.55806553, grad/param norm = 6.8459e-01, time/batch = 0.1716s	
1614/2700 (epoch 29.889), train_loss = 1.56196567, grad/param norm = 6.5854e-01, time/batch = 0.1749s	
1615/2700 (epoch 29.907), train_loss = 1.68318022, grad/param norm = 5.9845e-01, time/batch = 0.1735s	
1616/2700 (epoch 29.926), train_loss = 1.59157633, grad/param norm = 5.1736e-01, time/batch = 0.1788s	
1617/2700 (epoch 29.944), train_loss = 1.57389748, grad/param norm = 5.7303e-01, time/batch = 0.1777s	
1618/2700 (epoch 29.963), train_loss = 1.59758208, grad/param norm = 5.9673e-01, time/batch = 0.1636s	
1619/2700 (epoch 29.981), train_loss = 1.56921647, grad/param norm = 5.2131e-01, time/batch = 0.1807s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
1620/2700 (epoch 30.000), train_loss = 1.62148689, grad/param norm = 4.9807e-01, time/batch = 0.1752s	
1621/2700 (epoch 30.019), train_loss = 1.62828516, grad/param norm = 5.5453e-01, time/batch = 0.1690s	
1622/2700 (epoch 30.037), train_loss = 1.62068727, grad/param norm = 6.3185e-01, time/batch = 0.1709s	
1623/2700 (epoch 30.056), train_loss = 1.51646017, grad/param norm = 5.3738e-01, time/batch = 0.1798s	
1624/2700 (epoch 30.074), train_loss = 1.54239927, grad/param norm = 5.1502e-01, time/batch = 0.1846s	
1625/2700 (epoch 30.093), train_loss = 1.54081630, grad/param norm = 4.4143e-01, time/batch = 0.1852s	
1626/2700 (epoch 30.111), train_loss = 1.48719270, grad/param norm = 4.8926e-01, time/batch = 0.1840s	
1627/2700 (epoch 30.130), train_loss = 1.55953369, grad/param norm = 4.5304e-01, time/batch = 0.1722s	
1628/2700 (epoch 30.148), train_loss = 1.49549679, grad/param norm = 4.9290e-01, time/batch = 0.1809s	
1629/2700 (epoch 30.167), train_loss = 1.57248830, grad/param norm = 5.4198e-01, time/batch = 0.1771s	
1630/2700 (epoch 30.185), train_loss = 1.49134826, grad/param norm = 5.3720e-01, time/batch = 0.1678s	
1631/2700 (epoch 30.204), train_loss = 1.56443170, grad/param norm = 5.5167e-01, time/batch = 0.1641s	
1632/2700 (epoch 30.222), train_loss = 1.50135140, grad/param norm = 4.9785e-01, time/batch = 0.1689s	
1633/2700 (epoch 30.241), train_loss = 1.43940279, grad/param norm = 4.9181e-01, time/batch = 0.1702s	
1634/2700 (epoch 30.259), train_loss = 1.49322333, grad/param norm = 4.6859e-01, time/batch = 0.1849s	
1635/2700 (epoch 30.278), train_loss = 1.58663645, grad/param norm = 5.1976e-01, time/batch = 0.1856s	
1636/2700 (epoch 30.296), train_loss = 1.54726239, grad/param norm = 5.1017e-01, time/batch = 0.1777s	
1637/2700 (epoch 30.315), train_loss = 1.53504469, grad/param norm = 5.3500e-01, time/batch = 0.1872s	
1638/2700 (epoch 30.333), train_loss = 1.53321114, grad/param norm = 4.5429e-01, time/batch = 0.1862s	
1639/2700 (epoch 30.352), train_loss = 1.54450306, grad/param norm = 4.7050e-01, time/batch = 0.1857s	
1640/2700 (epoch 30.370), train_loss = 1.57480973, grad/param norm = 5.8040e-01, time/batch = 0.1811s	
1641/2700 (epoch 30.389), train_loss = 1.56081939, grad/param norm = 6.3246e-01, time/batch = 0.1710s	
1642/2700 (epoch 30.407), train_loss = 1.59213589, grad/param norm = 5.5719e-01, time/batch = 0.1635s	
1643/2700 (epoch 30.426), train_loss = 1.59421180, grad/param norm = 5.9157e-01, time/batch = 0.1710s	
1644/2700 (epoch 30.444), train_loss = 1.52282984, grad/param norm = 5.5623e-01, time/batch = 0.1790s	
1645/2700 (epoch 30.463), train_loss = 1.58476480, grad/param norm = 4.7212e-01, time/batch = 0.1878s	
1646/2700 (epoch 30.481), train_loss = 1.58630484, grad/param norm = 5.1854e-01, time/batch = 0.1760s	
1647/2700 (epoch 30.500), train_loss = 1.55700236, grad/param norm = 5.6890e-01, time/batch = 0.1796s	
1648/2700 (epoch 30.519), train_loss = 1.57088143, grad/param norm = 4.7157e-01, time/batch = 0.1835s	
1649/2700 (epoch 30.537), train_loss = 1.57173336, grad/param norm = 5.1863e-01, time/batch = 0.1847s	
1650/2700 (epoch 30.556), train_loss = 1.50050040, grad/param norm = 5.7194e-01, time/batch = 0.1758s	
1651/2700 (epoch 30.574), train_loss = 1.51108789, grad/param norm = 6.4129e-01, time/batch = 0.1739s	
1652/2700 (epoch 30.593), train_loss = 1.53156240, grad/param norm = 6.0111e-01, time/batch = 0.1781s	
1653/2700 (epoch 30.611), train_loss = 1.44274160, grad/param norm = 5.6188e-01, time/batch = 0.1869s	
1654/2700 (epoch 30.630), train_loss = 1.48626015, grad/param norm = 5.9134e-01, time/batch = 0.1716s	
1655/2700 (epoch 30.648), train_loss = 1.53113461, grad/param norm = 5.3641e-01, time/batch = 0.1614s	
1656/2700 (epoch 30.667), train_loss = 1.47819809, grad/param norm = 4.2809e-01, time/batch = 0.2234s	
1657/2700 (epoch 30.685), train_loss = 1.52021720, grad/param norm = 4.8269e-01, time/batch = 0.1770s	
1658/2700 (epoch 30.704), train_loss = 1.54949379, grad/param norm = 5.3170e-01, time/batch = 0.1793s	
1659/2700 (epoch 30.722), train_loss = 1.51854350, grad/param norm = 5.0653e-01, time/batch = 0.1735s	
1660/2700 (epoch 30.741), train_loss = 1.55076078, grad/param norm = 4.5586e-01, time/batch = 0.1860s	
1661/2700 (epoch 30.759), train_loss = 1.54061628, grad/param norm = 4.7127e-01, time/batch = 0.1878s	
1662/2700 (epoch 30.778), train_loss = 1.56791833, grad/param norm = 4.6797e-01, time/batch = 0.1829s	
1663/2700 (epoch 30.796), train_loss = 1.51153791, grad/param norm = 5.0599e-01, time/batch = 0.1859s	
1664/2700 (epoch 30.815), train_loss = 1.55788111, grad/param norm = 4.7647e-01, time/batch = 0.1713s	
1665/2700 (epoch 30.833), train_loss = 1.52731026, grad/param norm = 6.0026e-01, time/batch = 0.1744s	
1666/2700 (epoch 30.852), train_loss = 1.53717300, grad/param norm = 5.2885e-01, time/batch = 0.1666s	
1667/2700 (epoch 30.870), train_loss = 1.53939965, grad/param norm = 4.9456e-01, time/batch = 0.1662s	
1668/2700 (epoch 30.889), train_loss = 1.54123916, grad/param norm = 5.1195e-01, time/batch = 0.1685s	
1669/2700 (epoch 30.907), train_loss = 1.67141389, grad/param norm = 6.4662e-01, time/batch = 0.1570s	
1670/2700 (epoch 30.926), train_loss = 1.58904864, grad/param norm = 7.5129e-01, time/batch = 0.1839s	
1671/2700 (epoch 30.944), train_loss = 1.57339484, grad/param norm = 7.2923e-01, time/batch = 0.1578s	
1672/2700 (epoch 30.963), train_loss = 1.58464681, grad/param norm = 5.7671e-01, time/batch = 0.1594s	
1673/2700 (epoch 30.981), train_loss = 1.55456325, grad/param norm = 4.7482e-01, time/batch = 0.1708s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
1674/2700 (epoch 31.000), train_loss = 1.60940857, grad/param norm = 5.1591e-01, time/batch = 0.1650s	
1675/2700 (epoch 31.019), train_loss = 1.61528385, grad/param norm = 5.1104e-01, time/batch = 0.1720s	
1676/2700 (epoch 31.037), train_loss = 1.60626522, grad/param norm = 5.4351e-01, time/batch = 0.1823s	
1677/2700 (epoch 31.056), train_loss = 1.50223148, grad/param norm = 4.8122e-01, time/batch = 0.1848s	
1678/2700 (epoch 31.074), train_loss = 1.52819998, grad/param norm = 5.0938e-01, time/batch = 0.1849s	
1679/2700 (epoch 31.093), train_loss = 1.52678586, grad/param norm = 4.3405e-01, time/batch = 0.1714s	
1680/2700 (epoch 31.111), train_loss = 1.47551051, grad/param norm = 5.4813e-01, time/batch = 0.1751s	
1681/2700 (epoch 31.130), train_loss = 1.54833512, grad/param norm = 5.0663e-01, time/batch = 0.1855s	
1682/2700 (epoch 31.148), train_loss = 1.48124362, grad/param norm = 4.6063e-01, time/batch = 0.1721s	
1683/2700 (epoch 31.167), train_loss = 1.55677420, grad/param norm = 4.5197e-01, time/batch = 0.1586s	
1684/2700 (epoch 31.185), train_loss = 1.47963300, grad/param norm = 5.0617e-01, time/batch = 0.1839s	
1685/2700 (epoch 31.204), train_loss = 1.54875575, grad/param norm = 5.1079e-01, time/batch = 0.1820s	
1686/2700 (epoch 31.222), train_loss = 1.48949461, grad/param norm = 5.3714e-01, time/batch = 0.1821s	
1687/2700 (epoch 31.241), train_loss = 1.43129371, grad/param norm = 5.7423e-01, time/batch = 0.1847s	
1688/2700 (epoch 31.259), train_loss = 1.48469383, grad/param norm = 5.4241e-01, time/batch = 0.1740s	
1689/2700 (epoch 31.278), train_loss = 1.57872247, grad/param norm = 6.0249e-01, time/batch = 0.1723s	
1690/2700 (epoch 31.296), train_loss = 1.53645642, grad/param norm = 5.6992e-01, time/batch = 0.1758s	
1691/2700 (epoch 31.315), train_loss = 1.52238777, grad/param norm = 5.6978e-01, time/batch = 0.1657s	
1692/2700 (epoch 31.333), train_loss = 1.52123529, grad/param norm = 4.8292e-01, time/batch = 0.1784s	
1693/2700 (epoch 31.352), train_loss = 1.53182505, grad/param norm = 5.1014e-01, time/batch = 0.1841s	
1694/2700 (epoch 31.370), train_loss = 1.55271603, grad/param norm = 5.2515e-01, time/batch = 0.1772s	
1695/2700 (epoch 31.389), train_loss = 1.54027241, grad/param norm = 5.4857e-01, time/batch = 0.1704s	
1696/2700 (epoch 31.407), train_loss = 1.57535692, grad/param norm = 4.7400e-01, time/batch = 0.1797s	
1697/2700 (epoch 31.426), train_loss = 1.58085831, grad/param norm = 5.3566e-01, time/batch = 0.1822s	
1698/2700 (epoch 31.444), train_loss = 1.50929477, grad/param norm = 4.9287e-01, time/batch = 0.1740s	
1699/2700 (epoch 31.463), train_loss = 1.57015670, grad/param norm = 4.5315e-01, time/batch = 0.1890s	
1700/2700 (epoch 31.481), train_loss = 1.57375802, grad/param norm = 5.3416e-01, time/batch = 0.1800s	
1701/2700 (epoch 31.500), train_loss = 1.54149181, grad/param norm = 5.6087e-01, time/batch = 0.1721s	
1702/2700 (epoch 31.519), train_loss = 1.55847650, grad/param norm = 4.6868e-01, time/batch = 0.1448s	
1703/2700 (epoch 31.537), train_loss = 1.55669370, grad/param norm = 4.4676e-01, time/batch = 0.1646s	
1704/2700 (epoch 31.556), train_loss = 1.48341614, grad/param norm = 4.7497e-01, time/batch = 0.1691s	
1705/2700 (epoch 31.574), train_loss = 1.49260399, grad/param norm = 5.1210e-01, time/batch = 0.1758s	
1706/2700 (epoch 31.593), train_loss = 1.51487984, grad/param norm = 5.1811e-01, time/batch = 0.1760s	
1707/2700 (epoch 31.611), train_loss = 1.42562841, grad/param norm = 5.4006e-01, time/batch = 0.1721s	
1708/2700 (epoch 31.630), train_loss = 1.46810787, grad/param norm = 4.7012e-01, time/batch = 0.1611s	
1709/2700 (epoch 31.648), train_loss = 1.51734125, grad/param norm = 5.0539e-01, time/batch = 0.1638s	
1710/2700 (epoch 31.667), train_loss = 1.46632782, grad/param norm = 4.7449e-01, time/batch = 0.1707s	
1711/2700 (epoch 31.685), train_loss = 1.50807550, grad/param norm = 5.3765e-01, time/batch = 0.1816s	
1712/2700 (epoch 31.704), train_loss = 1.53701424, grad/param norm = 5.1619e-01, time/batch = 0.1828s	
1713/2700 (epoch 31.722), train_loss = 1.50749044, grad/param norm = 4.5564e-01, time/batch = 0.1799s	
1714/2700 (epoch 31.741), train_loss = 1.54254658, grad/param norm = 5.0309e-01, time/batch = 0.1714s	
1715/2700 (epoch 31.759), train_loss = 1.52722215, grad/param norm = 4.9904e-01, time/batch = 0.1796s	
1716/2700 (epoch 31.778), train_loss = 1.55304423, grad/param norm = 4.6457e-01, time/batch = 0.1830s	
1717/2700 (epoch 31.796), train_loss = 1.50144105, grad/param norm = 5.6019e-01, time/batch = 0.1722s	
1718/2700 (epoch 31.815), train_loss = 1.54870344, grad/param norm = 5.3213e-01, time/batch = 0.1820s	
1719/2700 (epoch 31.833), train_loss = 1.51625938, grad/param norm = 6.0685e-01, time/batch = 0.1854s	
1720/2700 (epoch 31.852), train_loss = 1.52023236, grad/param norm = 5.0311e-01, time/batch = 0.1854s	
1721/2700 (epoch 31.870), train_loss = 1.52808537, grad/param norm = 5.7668e-01, time/batch = 0.1489s	
1722/2700 (epoch 31.889), train_loss = 1.53318815, grad/param norm = 5.9721e-01, time/batch = 0.1654s	
1723/2700 (epoch 31.907), train_loss = 1.65605374, grad/param norm = 5.9348e-01, time/batch = 0.1700s	
1724/2700 (epoch 31.926), train_loss = 1.56275475, grad/param norm = 5.2902e-01, time/batch = 0.1713s	
1725/2700 (epoch 31.944), train_loss = 1.55007991, grad/param norm = 5.7062e-01, time/batch = 0.1740s	
1726/2700 (epoch 31.963), train_loss = 1.56847975, grad/param norm = 5.6563e-01, time/batch = 0.1768s	
1727/2700 (epoch 31.981), train_loss = 1.54223609, grad/param norm = 5.1295e-01, time/batch = 0.1649s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
1728/2700 (epoch 32.000), train_loss = 1.59759198, grad/param norm = 5.1482e-01, time/batch = 0.1614s	
1729/2700 (epoch 32.019), train_loss = 1.60553540, grad/param norm = 5.9072e-01, time/batch = 0.1664s	
1730/2700 (epoch 32.037), train_loss = 1.59821647, grad/param norm = 6.7300e-01, time/batch = 0.1688s	
1731/2700 (epoch 32.056), train_loss = 1.49271585, grad/param norm = 5.4009e-01, time/batch = 0.1786s	
1732/2700 (epoch 32.074), train_loss = 1.51759268, grad/param norm = 5.3378e-01, time/batch = 0.1809s	
1733/2700 (epoch 32.093), train_loss = 1.51750820, grad/param norm = 4.7002e-01, time/batch = 0.1814s	
1734/2700 (epoch 32.111), train_loss = 1.46258564, grad/param norm = 5.1661e-01, time/batch = 0.1869s	
1735/2700 (epoch 32.130), train_loss = 1.53511076, grad/param norm = 4.5951e-01, time/batch = 0.1883s	
1736/2700 (epoch 32.148), train_loss = 1.47215528, grad/param norm = 5.5362e-01, time/batch = 0.1825s	
1737/2700 (epoch 32.167), train_loss = 1.55057850, grad/param norm = 6.1226e-01, time/batch = 0.1803s	
1738/2700 (epoch 32.185), train_loss = 1.46928332, grad/param norm = 5.6742e-01, time/batch = 0.1857s	
1739/2700 (epoch 32.204), train_loss = 1.54131118, grad/param norm = 5.6694e-01, time/batch = 0.1857s	
1740/2700 (epoch 32.222), train_loss = 1.47487210, grad/param norm = 4.8899e-01, time/batch = 0.1785s	
1741/2700 (epoch 32.241), train_loss = 1.41274823, grad/param norm = 4.6392e-01, time/batch = 0.1652s	
1742/2700 (epoch 32.259), train_loss = 1.46769904, grad/param norm = 4.7660e-01, time/batch = 0.1725s	
1743/2700 (epoch 32.278), train_loss = 1.56372686, grad/param norm = 5.0081e-01, time/batch = 0.1710s	
1744/2700 (epoch 32.296), train_loss = 1.52156170, grad/param norm = 4.5214e-01, time/batch = 0.1754s	
1745/2700 (epoch 32.315), train_loss = 1.50433332, grad/param norm = 5.3899e-01, time/batch = 0.1852s	
1746/2700 (epoch 32.333), train_loss = 1.51423692, grad/param norm = 7.3893e-01, time/batch = 0.1620s	
1747/2700 (epoch 32.352), train_loss = 1.53486059, grad/param norm = 9.1842e-01, time/batch = 0.1665s	
1748/2700 (epoch 32.370), train_loss = 1.54723016, grad/param norm = 6.1398e-01, time/batch = 0.1687s	
1749/2700 (epoch 32.389), train_loss = 1.52856319, grad/param norm = 5.7070e-01, time/batch = 0.1636s	
1750/2700 (epoch 32.407), train_loss = 1.57096962, grad/param norm = 6.7067e-01, time/batch = 0.1723s	
1751/2700 (epoch 32.426), train_loss = 1.57629460, grad/param norm = 6.9177e-01, time/batch = 0.1847s	
1752/2700 (epoch 32.444), train_loss = 1.50080876, grad/param norm = 5.2880e-01, time/batch = 0.1706s	
1753/2700 (epoch 32.463), train_loss = 1.55717833, grad/param norm = 4.5214e-01, time/batch = 0.1676s	
1754/2700 (epoch 32.481), train_loss = 1.56126623, grad/param norm = 5.5344e-01, time/batch = 0.1708s	
1755/2700 (epoch 32.500), train_loss = 1.52694976, grad/param norm = 5.5777e-01, time/batch = 0.1676s	
1756/2700 (epoch 32.519), train_loss = 1.54678892, grad/param norm = 4.4821e-01, time/batch = 0.1853s	
1757/2700 (epoch 32.537), train_loss = 1.54381448, grad/param norm = 4.5956e-01, time/batch = 0.1854s	
1758/2700 (epoch 32.556), train_loss = 1.47091172, grad/param norm = 4.8086e-01, time/batch = 0.1863s	
1759/2700 (epoch 32.574), train_loss = 1.47978533, grad/param norm = 5.2350e-01, time/batch = 0.1813s	
1760/2700 (epoch 32.593), train_loss = 1.50210549, grad/param norm = 5.1293e-01, time/batch = 0.1812s	
1761/2700 (epoch 32.611), train_loss = 1.41403526, grad/param norm = 5.0912e-01, time/batch = 0.1701s	
1762/2700 (epoch 32.630), train_loss = 1.45604748, grad/param norm = 4.9103e-01, time/batch = 0.1641s	
1763/2700 (epoch 32.648), train_loss = 1.50315877, grad/param norm = 4.9312e-01, time/batch = 0.1645s	
1764/2700 (epoch 32.667), train_loss = 1.45285453, grad/param norm = 4.7176e-01, time/batch = 0.1659s	
1765/2700 (epoch 32.685), train_loss = 1.49826769, grad/param norm = 5.3011e-01, time/batch = 0.1506s	
1766/2700 (epoch 32.704), train_loss = 1.52816954, grad/param norm = 5.2913e-01, time/batch = 0.1852s	
1767/2700 (epoch 32.722), train_loss = 1.49559210, grad/param norm = 4.8789e-01, time/batch = 0.1843s	
1768/2700 (epoch 32.741), train_loss = 1.52788138, grad/param norm = 4.6942e-01, time/batch = 0.1771s	
1769/2700 (epoch 32.759), train_loss = 1.51342285, grad/param norm = 4.9163e-01, time/batch = 0.1797s	
1770/2700 (epoch 32.778), train_loss = 1.54106257, grad/param norm = 4.8241e-01, time/batch = 0.1704s	
1771/2700 (epoch 32.796), train_loss = 1.48830839, grad/param norm = 5.5706e-01, time/batch = 0.1739s	
1772/2700 (epoch 32.815), train_loss = 1.53538704, grad/param norm = 4.8981e-01, time/batch = 0.1654s	
1773/2700 (epoch 32.833), train_loss = 1.50300054, grad/param norm = 5.7153e-01, time/batch = 0.1741s	
1774/2700 (epoch 32.852), train_loss = 1.51165236, grad/param norm = 5.2591e-01, time/batch = 0.1651s	
1775/2700 (epoch 32.870), train_loss = 1.51479584, grad/param norm = 5.1283e-01, time/batch = 0.1880s	
1776/2700 (epoch 32.889), train_loss = 1.51676948, grad/param norm = 5.0312e-01, time/batch = 0.1857s	
1777/2700 (epoch 32.907), train_loss = 1.64209065, grad/param norm = 5.8777e-01, time/batch = 0.1863s	
1778/2700 (epoch 32.926), train_loss = 1.55527058, grad/param norm = 6.7116e-01, time/batch = 0.1846s	
1779/2700 (epoch 32.944), train_loss = 1.54539235, grad/param norm = 6.9697e-01, time/batch = 0.1841s	
1780/2700 (epoch 32.963), train_loss = 1.55568379, grad/param norm = 5.4792e-01, time/batch = 0.1830s	
1781/2700 (epoch 32.981), train_loss = 1.52816685, grad/param norm = 4.9136e-01, time/batch = 0.1689s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
1782/2700 (epoch 33.000), train_loss = 1.58616274, grad/param norm = 5.4988e-01, time/batch = 0.1781s	
1783/2700 (epoch 33.019), train_loss = 1.59271410, grad/param norm = 5.1260e-01, time/batch = 0.1716s	
1784/2700 (epoch 33.037), train_loss = 1.58079014, grad/param norm = 5.1626e-01, time/batch = 0.1595s	
1785/2700 (epoch 33.056), train_loss = 1.47950854, grad/param norm = 4.8447e-01, time/batch = 0.1763s	
1786/2700 (epoch 33.074), train_loss = 1.50454323, grad/param norm = 5.5440e-01, time/batch = 0.1735s	
1787/2700 (epoch 33.093), train_loss = 1.50285986, grad/param norm = 4.5099e-01, time/batch = 0.1599s	
1788/2700 (epoch 33.111), train_loss = 1.45181190, grad/param norm = 5.7255e-01, time/batch = 0.1828s	
1789/2700 (epoch 33.130), train_loss = 1.52563959, grad/param norm = 5.1388e-01, time/batch = 0.1847s	
1790/2700 (epoch 33.148), train_loss = 1.45729655, grad/param norm = 4.7554e-01, time/batch = 0.1840s	
1791/2700 (epoch 33.167), train_loss = 1.53340394, grad/param norm = 4.5557e-01, time/batch = 0.1797s	
1792/2700 (epoch 33.185), train_loss = 1.45721053, grad/param norm = 5.1173e-01, time/batch = 0.1568s	
1793/2700 (epoch 33.204), train_loss = 1.52630498, grad/param norm = 5.0337e-01, time/batch = 0.1701s	
1794/2700 (epoch 33.222), train_loss = 1.46654398, grad/param norm = 5.6628e-01, time/batch = 0.1529s	
1795/2700 (epoch 33.241), train_loss = 1.41148336, grad/param norm = 6.1143e-01, time/batch = 0.1854s	
1796/2700 (epoch 33.259), train_loss = 1.46325871, grad/param norm = 5.6356e-01, time/batch = 0.1835s	
1797/2700 (epoch 33.278), train_loss = 1.55709115, grad/param norm = 6.0647e-01, time/batch = 0.1693s	
1798/2700 (epoch 33.296), train_loss = 1.51116330, grad/param norm = 5.1718e-01, time/batch = 0.1803s	
1799/2700 (epoch 33.315), train_loss = 1.49161049, grad/param norm = 4.9505e-01, time/batch = 0.1807s	
1800/2700 (epoch 33.333), train_loss = 1.49548401, grad/param norm = 4.7122e-01, time/batch = 0.1736s	
1801/2700 (epoch 33.352), train_loss = 1.50750436, grad/param norm = 5.2632e-01, time/batch = 0.1790s	
1802/2700 (epoch 33.370), train_loss = 1.52971291, grad/param norm = 5.1873e-01, time/batch = 0.1785s	
1803/2700 (epoch 33.389), train_loss = 1.51455290, grad/param norm = 5.1815e-01, time/batch = 0.1627s	
1804/2700 (epoch 33.407), train_loss = 1.55278330, grad/param norm = 4.6933e-01, time/batch = 0.1776s	
1805/2700 (epoch 33.426), train_loss = 1.55530250, grad/param norm = 5.2173e-01, time/batch = 0.1865s	
1806/2700 (epoch 33.444), train_loss = 1.48521101, grad/param norm = 4.8371e-01, time/batch = 0.1702s	
1807/2700 (epoch 33.463), train_loss = 1.54793803, grad/param norm = 4.7712e-01, time/batch = 0.1665s	
1808/2700 (epoch 33.481), train_loss = 1.54833313, grad/param norm = 5.1719e-01, time/batch = 0.1766s	
1809/2700 (epoch 33.500), train_loss = 1.51435968, grad/param norm = 4.7687e-01, time/batch = 0.1857s	
1810/2700 (epoch 33.519), train_loss = 1.53680162, grad/param norm = 4.8499e-01, time/batch = 0.1847s	
1811/2700 (epoch 33.537), train_loss = 1.53689056, grad/param norm = 5.3422e-01, time/batch = 0.1862s	
1812/2700 (epoch 33.556), train_loss = 1.46368219, grad/param norm = 5.7947e-01, time/batch = 0.1619s	
1813/2700 (epoch 33.574), train_loss = 1.47109650, grad/param norm = 5.9428e-01, time/batch = 0.1549s	
1814/2700 (epoch 33.593), train_loss = 1.49464375, grad/param norm = 5.8273e-01, time/batch = 0.1597s	
1815/2700 (epoch 33.611), train_loss = 1.40567906, grad/param norm = 5.5436e-01, time/batch = 0.1424s	
1816/2700 (epoch 33.630), train_loss = 1.44483316, grad/param norm = 5.3027e-01, time/batch = 0.1723s	
1817/2700 (epoch 33.648), train_loss = 1.49291283, grad/param norm = 4.9732e-01, time/batch = 0.1697s	
1818/2700 (epoch 33.667), train_loss = 1.44056667, grad/param norm = 4.4513e-01, time/batch = 0.1831s	
1819/2700 (epoch 33.685), train_loss = 1.48419202, grad/param norm = 4.8444e-01, time/batch = 0.1844s	
1820/2700 (epoch 33.704), train_loss = 1.51463426, grad/param norm = 5.0251e-01, time/batch = 0.1871s	
1821/2700 (epoch 33.722), train_loss = 1.48556830, grad/param norm = 4.8258e-01, time/batch = 0.1884s	
1822/2700 (epoch 33.741), train_loss = 1.51748325, grad/param norm = 4.8651e-01, time/batch = 0.1709s	
1823/2700 (epoch 33.759), train_loss = 1.49987235, grad/param norm = 4.9420e-01, time/batch = 0.1630s	
1824/2700 (epoch 33.778), train_loss = 1.52915068, grad/param norm = 4.7983e-01, time/batch = 0.1494s	
1825/2700 (epoch 33.796), train_loss = 1.47378150, grad/param norm = 5.3576e-01, time/batch = 0.1421s	
1826/2700 (epoch 33.815), train_loss = 1.52248329, grad/param norm = 4.7738e-01, time/batch = 0.1757s	
1827/2700 (epoch 33.833), train_loss = 1.49004900, grad/param norm = 5.5832e-01, time/batch = 0.1776s	
1828/2700 (epoch 33.852), train_loss = 1.49495646, grad/param norm = 4.7991e-01, time/batch = 0.1749s	
1829/2700 (epoch 33.870), train_loss = 1.50258065, grad/param norm = 5.1430e-01, time/batch = 0.1846s	
1830/2700 (epoch 33.889), train_loss = 1.50780999, grad/param norm = 5.3205e-01, time/batch = 0.1845s	
1831/2700 (epoch 33.907), train_loss = 1.62741282, grad/param norm = 5.5099e-01, time/batch = 0.1747s	
1832/2700 (epoch 33.926), train_loss = 1.53619211, grad/param norm = 5.5245e-01, time/batch = 0.1700s	
1833/2700 (epoch 33.944), train_loss = 1.52835157, grad/param norm = 6.2362e-01, time/batch = 0.1601s	
1834/2700 (epoch 33.963), train_loss = 1.54002591, grad/param norm = 5.2533e-01, time/batch = 0.1663s	
1835/2700 (epoch 33.981), train_loss = 1.51513839, grad/param norm = 4.6590e-01, time/batch = 0.1565s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
1836/2700 (epoch 34.000), train_loss = 1.57374680, grad/param norm = 5.1959e-01, time/batch = 0.1852s	
1837/2700 (epoch 34.019), train_loss = 1.58181192, grad/param norm = 5.0955e-01, time/batch = 0.1807s	
1838/2700 (epoch 34.037), train_loss = 1.56964522, grad/param norm = 5.1029e-01, time/batch = 0.1860s	
1839/2700 (epoch 34.056), train_loss = 1.46958766, grad/param norm = 5.0605e-01, time/batch = 0.1798s	
1840/2700 (epoch 34.074), train_loss = 1.49478427, grad/param norm = 5.9659e-01, time/batch = 0.1666s	
1841/2700 (epoch 34.093), train_loss = 1.49309588, grad/param norm = 4.5399e-01, time/batch = 0.1826s	
1842/2700 (epoch 34.111), train_loss = 1.43835446, grad/param norm = 5.0146e-01, time/batch = 0.1679s	
1843/2700 (epoch 34.130), train_loss = 1.51290666, grad/param norm = 4.6099e-01, time/batch = 0.1719s	
1844/2700 (epoch 34.148), train_loss = 1.44757444, grad/param norm = 5.3010e-01, time/batch = 0.1727s	
1845/2700 (epoch 34.167), train_loss = 1.52611061, grad/param norm = 5.8326e-01, time/batch = 0.1858s	
1846/2700 (epoch 34.185), train_loss = 1.44599040, grad/param norm = 5.6547e-01, time/batch = 0.1844s	
1847/2700 (epoch 34.204), train_loss = 1.51883236, grad/param norm = 5.8259e-01, time/batch = 0.1824s	
1848/2700 (epoch 34.222), train_loss = 1.45199983, grad/param norm = 5.0186e-01, time/batch = 0.1858s	
1849/2700 (epoch 34.241), train_loss = 1.39236697, grad/param norm = 4.7597e-01, time/batch = 0.1846s	
1850/2700 (epoch 34.259), train_loss = 1.44828823, grad/param norm = 5.1937e-01, time/batch = 0.1831s	
1851/2700 (epoch 34.278), train_loss = 1.54463209, grad/param norm = 5.1705e-01, time/batch = 0.1614s	
1852/2700 (epoch 34.296), train_loss = 1.49918219, grad/param norm = 4.6044e-01, time/batch = 0.1467s	
1853/2700 (epoch 34.315), train_loss = 1.47836522, grad/param norm = 5.9933e-01, time/batch = 0.1658s	
1854/2700 (epoch 34.333), train_loss = 1.49318149, grad/param norm = 8.0185e-01, time/batch = 0.1580s	
1855/2700 (epoch 34.352), train_loss = 1.50862691, grad/param norm = 8.0814e-01, time/batch = 0.1828s	
1856/2700 (epoch 34.370), train_loss = 1.51934286, grad/param norm = 5.5481e-01, time/batch = 0.1550s	
1857/2700 (epoch 34.389), train_loss = 1.50272369, grad/param norm = 5.2202e-01, time/batch = 0.1637s	
1858/2700 (epoch 34.407), train_loss = 1.54689110, grad/param norm = 6.0089e-01, time/batch = 0.1681s	
1859/2700 (epoch 34.426), train_loss = 1.54983476, grad/param norm = 6.3437e-01, time/batch = 0.1736s	
1860/2700 (epoch 34.444), train_loss = 1.47689101, grad/param norm = 4.9028e-01, time/batch = 0.1802s	
1861/2700 (epoch 34.463), train_loss = 1.53537971, grad/param norm = 4.6435e-01, time/batch = 0.1785s	
1862/2700 (epoch 34.481), train_loss = 1.53729666, grad/param norm = 5.3661e-01, time/batch = 0.1835s	
1863/2700 (epoch 34.500), train_loss = 1.50189555, grad/param norm = 5.2012e-01, time/batch = 0.1774s	
1864/2700 (epoch 34.519), train_loss = 1.52542379, grad/param norm = 4.6744e-01, time/batch = 0.1866s	
1865/2700 (epoch 34.537), train_loss = 1.52219999, grad/param norm = 4.5343e-01, time/batch = 0.1804s	
1866/2700 (epoch 34.556), train_loss = 1.44761046, grad/param norm = 4.6937e-01, time/batch = 0.1845s	
1867/2700 (epoch 34.574), train_loss = 1.45794654, grad/param norm = 5.4496e-01, time/batch = 0.1844s	
1868/2700 (epoch 34.593), train_loss = 1.48053138, grad/param norm = 5.1650e-01, time/batch = 0.1846s	
1869/2700 (epoch 34.611), train_loss = 1.39134288, grad/param norm = 5.0273e-01, time/batch = 0.1843s	
1870/2700 (epoch 34.630), train_loss = 1.43161603, grad/param norm = 4.6596e-01, time/batch = 0.1836s	
1871/2700 (epoch 34.648), train_loss = 1.48243945, grad/param norm = 5.0894e-01, time/batch = 0.1460s	
1872/2700 (epoch 34.667), train_loss = 1.43096991, grad/param norm = 5.0718e-01, time/batch = 0.1648s	
1873/2700 (epoch 34.685), train_loss = 1.47467147, grad/param norm = 5.2554e-01, time/batch = 0.1607s	
1874/2700 (epoch 34.704), train_loss = 1.50396309, grad/param norm = 4.9795e-01, time/batch = 0.1828s	
1875/2700 (epoch 34.722), train_loss = 1.47510110, grad/param norm = 4.7424e-01, time/batch = 0.1624s	
1876/2700 (epoch 34.741), train_loss = 1.50774807, grad/param norm = 4.9707e-01, time/batch = 0.1619s	
1877/2700 (epoch 34.759), train_loss = 1.48730698, grad/param norm = 4.9215e-01, time/batch = 0.1660s	
1878/2700 (epoch 34.778), train_loss = 1.51730514, grad/param norm = 4.7623e-01, time/batch = 0.1687s	
1879/2700 (epoch 34.796), train_loss = 1.46389335, grad/param norm = 5.6252e-01, time/batch = 0.1788s	
1880/2700 (epoch 34.815), train_loss = 1.51215122, grad/param norm = 4.9129e-01, time/batch = 0.1854s	
1881/2700 (epoch 34.833), train_loss = 1.47916605, grad/param norm = 5.6437e-01, time/batch = 0.1850s	
1882/2700 (epoch 34.852), train_loss = 1.48461955, grad/param norm = 5.1849e-01, time/batch = 0.1771s	
1883/2700 (epoch 34.870), train_loss = 1.49324926, grad/param norm = 5.7777e-01, time/batch = 0.1856s	
1884/2700 (epoch 34.889), train_loss = 1.49774399, grad/param norm = 5.5199e-01, time/batch = 0.1790s	
1885/2700 (epoch 34.907), train_loss = 1.61465077, grad/param norm = 5.5442e-01, time/batch = 0.1860s	
1886/2700 (epoch 34.926), train_loss = 1.52200898, grad/param norm = 5.2405e-01, time/batch = 0.1813s	
1887/2700 (epoch 34.944), train_loss = 1.51691553, grad/param norm = 5.6699e-01, time/batch = 0.1710s	
1888/2700 (epoch 34.963), train_loss = 1.52798658, grad/param norm = 5.1023e-01, time/batch = 0.1760s	
1889/2700 (epoch 34.981), train_loss = 1.50536378, grad/param norm = 4.9207e-01, time/batch = 0.1785s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
1890/2700 (epoch 35.000), train_loss = 1.56330189, grad/param norm = 5.1895e-01, time/batch = 0.1663s	
1891/2700 (epoch 35.019), train_loss = 1.57289493, grad/param norm = 5.3389e-01, time/batch = 0.1599s	
1892/2700 (epoch 35.037), train_loss = 1.55973438, grad/param norm = 5.9074e-01, time/batch = 0.1388s	
1893/2700 (epoch 35.056), train_loss = 1.46002971, grad/param norm = 5.0985e-01, time/batch = 0.1828s	
1894/2700 (epoch 35.074), train_loss = 1.48072453, grad/param norm = 4.8835e-01, time/batch = 0.1710s	
1895/2700 (epoch 35.093), train_loss = 1.48273148, grad/param norm = 4.8793e-01, time/batch = 0.1786s	
1896/2700 (epoch 35.111), train_loss = 1.43093385, grad/param norm = 6.0479e-01, time/batch = 0.1848s	
1897/2700 (epoch 35.130), train_loss = 1.50314080, grad/param norm = 4.7586e-01, time/batch = 0.1852s	
1898/2700 (epoch 35.148), train_loss = 1.43709371, grad/param norm = 5.3899e-01, time/batch = 0.1855s	
1899/2700 (epoch 35.167), train_loss = 1.51628871, grad/param norm = 5.9756e-01, time/batch = 0.1806s	
1900/2700 (epoch 35.185), train_loss = 1.43800514, grad/param norm = 5.6498e-01, time/batch = 0.1855s	
1901/2700 (epoch 35.204), train_loss = 1.50961707, grad/param norm = 5.5356e-01, time/batch = 0.1625s	
1902/2700 (epoch 35.222), train_loss = 1.44189374, grad/param norm = 4.8763e-01, time/batch = 0.1498s	
1903/2700 (epoch 35.241), train_loss = 1.38496250, grad/param norm = 4.8889e-01, time/batch = 0.1703s	
1904/2700 (epoch 35.259), train_loss = 1.43796946, grad/param norm = 4.9729e-01, time/batch = 0.1727s	
1905/2700 (epoch 35.278), train_loss = 1.53459544, grad/param norm = 5.4336e-01, time/batch = 0.1818s	
1906/2700 (epoch 35.296), train_loss = 1.48767583, grad/param norm = 4.6204e-01, time/batch = 0.1889s	
1907/2700 (epoch 35.315), train_loss = 1.46437272, grad/param norm = 4.6606e-01, time/batch = 0.1850s	
1908/2700 (epoch 35.333), train_loss = 1.47217557, grad/param norm = 5.1534e-01, time/batch = 0.1878s	
1909/2700 (epoch 35.352), train_loss = 1.48638337, grad/param norm = 5.8562e-01, time/batch = 0.1648s	
1910/2700 (epoch 35.370), train_loss = 1.50728889, grad/param norm = 5.2943e-01, time/batch = 0.1695s	
1911/2700 (epoch 35.389), train_loss = 1.48984010, grad/param norm = 4.9524e-01, time/batch = 0.1687s	
1912/2700 (epoch 35.407), train_loss = 1.53308661, grad/param norm = 5.0370e-01, time/batch = 0.1519s	
1913/2700 (epoch 35.426), train_loss = 1.53345821, grad/param norm = 5.4238e-01, time/batch = 0.1815s	
1914/2700 (epoch 35.444), train_loss = 1.46485154, grad/param norm = 4.7295e-01, time/batch = 0.1851s	
1915/2700 (epoch 35.463), train_loss = 1.52800577, grad/param norm = 4.8266e-01, time/batch = 0.1859s	
1916/2700 (epoch 35.481), train_loss = 1.52587770, grad/param norm = 5.1486e-01, time/batch = 0.1846s	
1917/2700 (epoch 35.500), train_loss = 1.49211240, grad/param norm = 4.9473e-01, time/batch = 0.1826s	
1918/2700 (epoch 35.519), train_loss = 1.51638285, grad/param norm = 4.9168e-01, time/batch = 0.1665s	
1919/2700 (epoch 35.537), train_loss = 1.51486553, grad/param norm = 5.0753e-01, time/batch = 0.1806s	
1920/2700 (epoch 35.556), train_loss = 1.44081541, grad/param norm = 5.3513e-01, time/batch = 0.1842s	
1921/2700 (epoch 35.574), train_loss = 1.44921342, grad/param norm = 5.8434e-01, time/batch = 0.1695s	
1922/2700 (epoch 35.593), train_loss = 1.47160630, grad/param norm = 5.4463e-01, time/batch = 0.1872s	
1923/2700 (epoch 35.611), train_loss = 1.38383327, grad/param norm = 5.1099e-01, time/batch = 0.1818s	
1924/2700 (epoch 35.630), train_loss = 1.42266158, grad/param norm = 5.1656e-01, time/batch = 0.1646s	
1925/2700 (epoch 35.648), train_loss = 1.47107873, grad/param norm = 4.7892e-01, time/batch = 0.1619s	
1926/2700 (epoch 35.667), train_loss = 1.41836654, grad/param norm = 4.5737e-01, time/batch = 0.1619s	
1927/2700 (epoch 35.685), train_loss = 1.46546554, grad/param norm = 5.0608e-01, time/batch = 0.1693s	
1928/2700 (epoch 35.704), train_loss = 1.49545102, grad/param norm = 5.0747e-01, time/batch = 0.1693s	
1929/2700 (epoch 35.722), train_loss = 1.46403273, grad/param norm = 4.7030e-01, time/batch = 0.1790s	
1930/2700 (epoch 35.741), train_loss = 1.49412918, grad/param norm = 4.7828e-01, time/batch = 0.1868s	
1931/2700 (epoch 35.759), train_loss = 1.47475497, grad/param norm = 4.9485e-01, time/batch = 0.1679s	
1932/2700 (epoch 35.778), train_loss = 1.50697733, grad/param norm = 4.9101e-01, time/batch = 0.1762s	
1933/2700 (epoch 35.796), train_loss = 1.45424932, grad/param norm = 5.7326e-01, time/batch = 0.1720s	
1934/2700 (epoch 35.815), train_loss = 1.50212715, grad/param norm = 4.8857e-01, time/batch = 0.1740s	
1935/2700 (epoch 35.833), train_loss = 1.46669752, grad/param norm = 5.4825e-01, time/batch = 0.1783s	
1936/2700 (epoch 35.852), train_loss = 1.47340071, grad/param norm = 5.0132e-01, time/batch = 0.1827s	
1937/2700 (epoch 35.870), train_loss = 1.48093568, grad/param norm = 4.9982e-01, time/batch = 0.1726s	
1938/2700 (epoch 35.889), train_loss = 1.48595315, grad/param norm = 5.0170e-01, time/batch = 0.1758s	
1939/2700 (epoch 35.907), train_loss = 1.60271696, grad/param norm = 5.7255e-01, time/batch = 0.1803s	
1940/2700 (epoch 35.926), train_loss = 1.51508438, grad/param norm = 6.3975e-01, time/batch = 0.1637s	
1941/2700 (epoch 35.944), train_loss = 1.51166934, grad/param norm = 6.7259e-01, time/batch = 0.1831s	
1942/2700 (epoch 35.963), train_loss = 1.51677223, grad/param norm = 5.1488e-01, time/batch = 0.1762s	
1943/2700 (epoch 35.981), train_loss = 1.49341237, grad/param norm = 5.0396e-01, time/batch = 0.1652s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
1944/2700 (epoch 36.000), train_loss = 1.55405619, grad/param norm = 5.6965e-01, time/batch = 0.1641s	
1945/2700 (epoch 36.019), train_loss = 1.56226313, grad/param norm = 5.1037e-01, time/batch = 0.1730s	
1946/2700 (epoch 36.037), train_loss = 1.54744433, grad/param norm = 4.9449e-01, time/batch = 0.1631s	
1947/2700 (epoch 36.056), train_loss = 1.44984250, grad/param norm = 5.0182e-01, time/batch = 0.1810s	
1948/2700 (epoch 36.074), train_loss = 1.47180527, grad/param norm = 5.6538e-01, time/batch = 0.1814s	
1949/2700 (epoch 36.093), train_loss = 1.47170644, grad/param norm = 4.6572e-01, time/batch = 0.1739s	
1950/2700 (epoch 36.111), train_loss = 1.41803084, grad/param norm = 5.5974e-01, time/batch = 0.1599s	
1951/2700 (epoch 36.130), train_loss = 1.49322651, grad/param norm = 4.9857e-01, time/batch = 0.1825s	
1952/2700 (epoch 36.148), train_loss = 1.42490571, grad/param norm = 4.8459e-01, time/batch = 0.1768s	
1953/2700 (epoch 36.167), train_loss = 1.50153827, grad/param norm = 4.6363e-01, time/batch = 0.1753s	
1954/2700 (epoch 36.185), train_loss = 1.42375700, grad/param norm = 4.9397e-01, time/batch = 0.1813s	
1955/2700 (epoch 36.204), train_loss = 1.49294200, grad/param norm = 4.9065e-01, time/batch = 0.1877s	
1956/2700 (epoch 36.222), train_loss = 1.43209035, grad/param norm = 5.6361e-01, time/batch = 0.1675s	
1957/2700 (epoch 36.241), train_loss = 1.37985950, grad/param norm = 6.0554e-01, time/batch = 0.1673s	
1958/2700 (epoch 36.259), train_loss = 1.43274090, grad/param norm = 5.7343e-01, time/batch = 0.1838s	
1959/2700 (epoch 36.278), train_loss = 1.52873515, grad/param norm = 6.0968e-01, time/batch = 0.1680s	
1960/2700 (epoch 36.296), train_loss = 1.47938738, grad/param norm = 5.1616e-01, time/batch = 0.1854s	
1961/2700 (epoch 36.315), train_loss = 1.45505698, grad/param norm = 4.8183e-01, time/batch = 0.1902s	
1962/2700 (epoch 36.333), train_loss = 1.46192749, grad/param norm = 4.8583e-01, time/batch = 0.1824s	
1963/2700 (epoch 36.352), train_loss = 1.47379944, grad/param norm = 5.0065e-01, time/batch = 0.1637s	
1964/2700 (epoch 36.370), train_loss = 1.49553355, grad/param norm = 5.8822e-01, time/batch = 0.1631s	
1965/2700 (epoch 36.389), train_loss = 1.48109340, grad/param norm = 6.1768e-01, time/batch = 0.1615s	
1966/2700 (epoch 36.407), train_loss = 1.52739192, grad/param norm = 5.6262e-01, time/batch = 0.1629s	
1967/2700 (epoch 36.426), train_loss = 1.52712726, grad/param norm = 6.1689e-01, time/batch = 0.1685s	
1968/2700 (epoch 36.444), train_loss = 1.45748437, grad/param norm = 5.4639e-01, time/batch = 0.1742s	
1969/2700 (epoch 36.463), train_loss = 1.51900130, grad/param norm = 5.3816e-01, time/batch = 0.1597s	
1970/2700 (epoch 36.481), train_loss = 1.51534935, grad/param norm = 5.3243e-01, time/batch = 0.1844s	
1971/2700 (epoch 36.500), train_loss = 1.47936571, grad/param norm = 4.4811e-01, time/batch = 0.1727s	
1972/2700 (epoch 36.519), train_loss = 1.50506165, grad/param norm = 5.1569e-01, time/batch = 0.1725s	
1973/2700 (epoch 36.537), train_loss = 1.50554804, grad/param norm = 5.2732e-01, time/batch = 0.1704s	
1974/2700 (epoch 36.556), train_loss = 1.43018149, grad/param norm = 5.1926e-01, time/batch = 0.1509s	
1975/2700 (epoch 36.574), train_loss = 1.43748186, grad/param norm = 5.3686e-01, time/batch = 0.1792s	
1976/2700 (epoch 36.593), train_loss = 1.46081825, grad/param norm = 5.0946e-01, time/batch = 0.1854s	
1977/2700 (epoch 36.611), train_loss = 1.37265158, grad/param norm = 4.9456e-01, time/batch = 0.1844s	
1978/2700 (epoch 36.630), train_loss = 1.41088941, grad/param norm = 4.7471e-01, time/batch = 0.1837s	
1979/2700 (epoch 36.648), train_loss = 1.46196358, grad/param norm = 4.9790e-01, time/batch = 0.1745s	
1980/2700 (epoch 36.667), train_loss = 1.40948495, grad/param norm = 5.0617e-01, time/batch = 0.1732s	
1981/2700 (epoch 36.685), train_loss = 1.45474581, grad/param norm = 5.1680e-01, time/batch = 0.1743s	
1982/2700 (epoch 36.704), train_loss = 1.48386089, grad/param norm = 4.9502e-01, time/batch = 0.1752s	
1983/2700 (epoch 36.722), train_loss = 1.45557354, grad/param norm = 4.7052e-01, time/batch = 0.1745s	
1984/2700 (epoch 36.741), train_loss = 1.48509159, grad/param norm = 4.9766e-01, time/batch = 0.1837s	
1985/2700 (epoch 36.759), train_loss = 1.46263075, grad/param norm = 4.9066e-01, time/batch = 0.1818s	
1986/2700 (epoch 36.778), train_loss = 1.49588868, grad/param norm = 4.8118e-01, time/batch = 0.1828s	
1987/2700 (epoch 36.796), train_loss = 1.44276233, grad/param norm = 5.7716e-01, time/batch = 0.1828s	
1988/2700 (epoch 36.815), train_loss = 1.49189492, grad/param norm = 5.0183e-01, time/batch = 0.1751s	
1989/2700 (epoch 36.833), train_loss = 1.45678281, grad/param norm = 5.6541e-01, time/batch = 0.1843s	
1990/2700 (epoch 36.852), train_loss = 1.46176236, grad/param norm = 5.1626e-01, time/batch = 0.1859s	
1991/2700 (epoch 36.870), train_loss = 1.47288035, grad/param norm = 5.4973e-01, time/batch = 0.1685s	
1992/2700 (epoch 36.889), train_loss = 1.47755823, grad/param norm = 5.2914e-01, time/batch = 0.1634s	
1993/2700 (epoch 36.907), train_loss = 1.58940419, grad/param norm = 5.4968e-01, time/batch = 0.1506s	
1994/2700 (epoch 36.926), train_loss = 1.49877361, grad/param norm = 5.3549e-01, time/batch = 0.1658s	
1995/2700 (epoch 36.944), train_loss = 1.49628182, grad/param norm = 5.5576e-01, time/batch = 0.1506s	
1996/2700 (epoch 36.963), train_loss = 1.50374526, grad/param norm = 4.8264e-01, time/batch = 0.1800s	
1997/2700 (epoch 36.981), train_loss = 1.48360961, grad/param norm = 5.0527e-01, time/batch = 0.1856s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
1998/2700 (epoch 37.000), train_loss = 1.54335397, grad/param norm = 5.2881e-01, time/batch = 0.1721s	
1999/2700 (epoch 37.019), train_loss = 1.55340031, grad/param norm = 5.2605e-01, time/batch = 0.1728s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch37.04_1.7371.t7	
2000/2700 (epoch 37.037), train_loss = 1.53884775, grad/param norm = 5.6551e-01, time/batch = 0.1735s	
2001/2700 (epoch 37.056), train_loss = 1.57628152, grad/param norm = 5.6644e-01, time/batch = 0.1670s	
2002/2700 (epoch 37.074), train_loss = 1.46321387, grad/param norm = 5.3294e-01, time/batch = 0.1610s	
2003/2700 (epoch 37.093), train_loss = 1.46307454, grad/param norm = 5.2055e-01, time/batch = 0.1829s	
2004/2700 (epoch 37.111), train_loss = 1.40905675, grad/param norm = 5.7706e-01, time/batch = 0.1778s	
2005/2700 (epoch 37.130), train_loss = 1.48371856, grad/param norm = 4.9345e-01, time/batch = 0.1796s	
2006/2700 (epoch 37.148), train_loss = 1.41962965, grad/param norm = 6.1602e-01, time/batch = 0.1771s	
2007/2700 (epoch 37.167), train_loss = 1.49816577, grad/param norm = 6.2281e-01, time/batch = 0.1806s	
2008/2700 (epoch 37.185), train_loss = 1.41589504, grad/param norm = 5.3574e-01, time/batch = 0.1815s	
2009/2700 (epoch 37.204), train_loss = 1.48711780, grad/param norm = 5.3444e-01, time/batch = 0.1828s	
2010/2700 (epoch 37.222), train_loss = 1.42003771, grad/param norm = 4.7370e-01, time/batch = 0.1847s	
2011/2700 (epoch 37.241), train_loss = 1.36594379, grad/param norm = 4.7989e-01, time/batch = 0.1516s	
2012/2700 (epoch 37.259), train_loss = 1.42088829, grad/param norm = 5.1940e-01, time/batch = 0.1731s	
2013/2700 (epoch 37.278), train_loss = 1.51695206, grad/param norm = 5.2675e-01, time/batch = 0.1657s	
2014/2700 (epoch 37.296), train_loss = 1.46781884, grad/param norm = 4.6495e-01, time/batch = 0.1552s	
2015/2700 (epoch 37.315), train_loss = 1.44232805, grad/param norm = 5.0937e-01, time/batch = 0.1842s	
2016/2700 (epoch 37.333), train_loss = 1.45325214, grad/param norm = 6.3638e-01, time/batch = 0.1784s	
2017/2700 (epoch 37.352), train_loss = 1.46782916, grad/param norm = 6.5865e-01, time/batch = 0.1689s	
2018/2700 (epoch 37.370), train_loss = 1.48469020, grad/param norm = 5.4400e-01, time/batch = 0.1761s	
2019/2700 (epoch 37.389), train_loss = 1.46727438, grad/param norm = 4.9897e-01, time/batch = 0.1809s	
2020/2700 (epoch 37.407), train_loss = 1.51721244, grad/param norm = 5.9507e-01, time/batch = 0.1809s	
2021/2700 (epoch 37.426), train_loss = 1.51472518, grad/param norm = 6.1025e-01, time/batch = 0.1626s	
2022/2700 (epoch 37.444), train_loss = 1.44608616, grad/param norm = 4.7809e-01, time/batch = 0.1713s	
2023/2700 (epoch 37.463), train_loss = 1.50822141, grad/param norm = 4.9410e-01, time/batch = 0.1753s	
2024/2700 (epoch 37.481), train_loss = 1.50442887, grad/param norm = 5.2934e-01, time/batch = 0.1595s	
2025/2700 (epoch 37.500), train_loss = 1.47046508, grad/param norm = 5.3549e-01, time/batch = 0.1850s	
2026/2700 (epoch 37.519), train_loss = 1.49594550, grad/param norm = 5.0019e-01, time/batch = 0.1842s	
2027/2700 (epoch 37.537), train_loss = 1.49243742, grad/param norm = 4.5299e-01, time/batch = 0.1871s	
2028/2700 (epoch 37.556), train_loss = 1.41868115, grad/param norm = 4.7526e-01, time/batch = 0.1690s	
2029/2700 (epoch 37.574), train_loss = 1.42845029, grad/param norm = 5.7114e-01, time/batch = 0.1633s	
2030/2700 (epoch 37.593), train_loss = 1.45022159, grad/param norm = 5.0814e-01, time/batch = 0.1644s	
2031/2700 (epoch 37.611), train_loss = 1.36378598, grad/param norm = 4.7673e-01, time/batch = 0.1853s	
2032/2700 (epoch 37.630), train_loss = 1.40206739, grad/param norm = 4.9474e-01, time/batch = 0.1833s	
2033/2700 (epoch 37.648), train_loss = 1.45189933, grad/param norm = 4.9852e-01, time/batch = 0.1718s	
2034/2700 (epoch 37.667), train_loss = 1.39987782, grad/param norm = 5.1574e-01, time/batch = 0.1689s	
2035/2700 (epoch 37.685), train_loss = 1.44679990, grad/param norm = 5.2944e-01, time/batch = 0.1766s	
2036/2700 (epoch 37.704), train_loss = 1.47545664, grad/param norm = 5.0140e-01, time/batch = 0.1840s	
2037/2700 (epoch 37.722), train_loss = 1.44464195, grad/param norm = 4.6250e-01, time/batch = 0.1830s	
2038/2700 (epoch 37.741), train_loss = 1.47394890, grad/param norm = 4.9427e-01, time/batch = 0.1828s	
2039/2700 (epoch 37.759), train_loss = 1.45288270, grad/param norm = 5.0358e-01, time/batch = 0.1702s	
2040/2700 (epoch 37.778), train_loss = 1.48647434, grad/param norm = 4.9510e-01, time/batch = 0.1586s	
2041/2700 (epoch 37.796), train_loss = 1.43400025, grad/param norm = 5.8344e-01, time/batch = 0.1454s	
2042/2700 (epoch 37.815), train_loss = 1.48205200, grad/param norm = 5.0158e-01, time/batch = 0.1264s	
2043/2700 (epoch 37.833), train_loss = 1.44570095, grad/param norm = 5.4976e-01, time/batch = 0.0921s	
2044/2700 (epoch 37.852), train_loss = 1.45274675, grad/param norm = 5.1776e-01, time/batch = 0.1270s	
2045/2700 (epoch 37.870), train_loss = 1.46286358, grad/param norm = 5.0222e-01, time/batch = 0.1314s	
2046/2700 (epoch 37.889), train_loss = 1.46664282, grad/param norm = 4.9471e-01, time/batch = 0.1333s	
2047/2700 (epoch 37.907), train_loss = 1.57936957, grad/param norm = 5.8421e-01, time/batch = 0.1353s	
2048/2700 (epoch 37.926), train_loss = 1.49185193, grad/param norm = 6.3014e-01, time/batch = 0.1338s	
2049/2700 (epoch 37.944), train_loss = 1.48974980, grad/param norm = 6.1706e-01, time/batch = 0.1328s	
2050/2700 (epoch 37.963), train_loss = 1.49387948, grad/param norm = 4.8480e-01, time/batch = 0.1365s	
2051/2700 (epoch 37.981), train_loss = 1.47328920, grad/param norm = 5.1822e-01, time/batch = 0.1290s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2052/2700 (epoch 38.000), train_loss = 1.53372115, grad/param norm = 5.4340e-01, time/batch = 0.1193s	
2053/2700 (epoch 38.019), train_loss = 1.54325548, grad/param norm = 5.0045e-01, time/batch = 0.0964s	
2054/2700 (epoch 38.037), train_loss = 1.52812618, grad/param norm = 5.1766e-01, time/batch = 0.1263s	
2055/2700 (epoch 38.056), train_loss = 1.43329010, grad/param norm = 4.9694e-01, time/batch = 0.1293s	
2056/2700 (epoch 38.074), train_loss = 1.45109240, grad/param norm = 5.0451e-01, time/batch = 0.1329s	
2057/2700 (epoch 38.093), train_loss = 1.45297583, grad/param norm = 4.9193e-01, time/batch = 0.1354s	
2058/2700 (epoch 38.111), train_loss = 1.39880332, grad/param norm = 5.7096e-01, time/batch = 0.1340s	
2059/2700 (epoch 38.130), train_loss = 1.47391335, grad/param norm = 4.8758e-01, time/batch = 0.1288s	
2060/2700 (epoch 38.148), train_loss = 1.40594160, grad/param norm = 4.8494e-01, time/batch = 0.1328s	
2061/2700 (epoch 38.167), train_loss = 1.48337147, grad/param norm = 4.8005e-01, time/batch = 0.1353s	
2062/2700 (epoch 38.185), train_loss = 1.40493077, grad/param norm = 4.8543e-01, time/batch = 0.1347s	
2063/2700 (epoch 38.204), train_loss = 1.47468344, grad/param norm = 4.9119e-01, time/batch = 0.1229s	
2064/2700 (epoch 38.222), train_loss = 1.41216215, grad/param norm = 5.2573e-01, time/batch = 0.1271s	
2065/2700 (epoch 38.241), train_loss = 1.36059627, grad/param norm = 5.5601e-01, time/batch = 0.1277s	
2066/2700 (epoch 38.259), train_loss = 1.41330183, grad/param norm = 5.4756e-01, time/batch = 0.1286s	
2067/2700 (epoch 38.278), train_loss = 1.50982501, grad/param norm = 5.8022e-01, time/batch = 0.1366s	
2068/2700 (epoch 38.296), train_loss = 1.45902450, grad/param norm = 4.9368e-01, time/batch = 0.1365s	
2069/2700 (epoch 38.315), train_loss = 1.43250814, grad/param norm = 4.5823e-01, time/batch = 0.1416s	
2070/2700 (epoch 38.333), train_loss = 1.44029492, grad/param norm = 4.7458e-01, time/batch = 0.1415s	
2071/2700 (epoch 38.352), train_loss = 1.45299054, grad/param norm = 4.8881e-01, time/batch = 0.1333s	
2072/2700 (epoch 38.370), train_loss = 1.47704252, grad/param norm = 6.2012e-01, time/batch = 0.1424s	
2073/2700 (epoch 38.389), train_loss = 1.46004743, grad/param norm = 6.2062e-01, time/batch = 0.1464s	
2074/2700 (epoch 38.407), train_loss = 1.50878540, grad/param norm = 5.6215e-01, time/batch = 0.1504s	
2075/2700 (epoch 38.426), train_loss = 1.50368387, grad/param norm = 6.0270e-01, time/batch = 0.1492s	
2076/2700 (epoch 38.444), train_loss = 1.43939574, grad/param norm = 5.6254e-01, time/batch = 0.1503s	
2077/2700 (epoch 38.463), train_loss = 1.50254412, grad/param norm = 5.6387e-01, time/batch = 0.1317s	
2078/2700 (epoch 38.481), train_loss = 1.49462816, grad/param norm = 5.2614e-01, time/batch = 0.1504s	
2079/2700 (epoch 38.500), train_loss = 1.45974464, grad/param norm = 4.5307e-01, time/batch = 0.1380s	
2080/2700 (epoch 38.519), train_loss = 1.48645746, grad/param norm = 5.3592e-01, time/batch = 0.1352s	
2081/2700 (epoch 38.537), train_loss = 1.48635778, grad/param norm = 5.3433e-01, time/batch = 0.1509s	
2082/2700 (epoch 38.556), train_loss = 1.41216667, grad/param norm = 5.2722e-01, time/batch = 0.1229s	
2083/2700 (epoch 38.574), train_loss = 1.41844371, grad/param norm = 5.3755e-01, time/batch = 0.1170s	
2084/2700 (epoch 38.593), train_loss = 1.44192919, grad/param norm = 4.9835e-01, time/batch = 0.1520s	
2085/2700 (epoch 38.611), train_loss = 1.35555690, grad/param norm = 4.8787e-01, time/batch = 0.1479s	
2086/2700 (epoch 38.630), train_loss = 1.39313801, grad/param norm = 4.9656e-01, time/batch = 0.1496s	
2087/2700 (epoch 38.648), train_loss = 1.44259627, grad/param norm = 4.7118e-01, time/batch = 0.1509s	
2088/2700 (epoch 38.667), train_loss = 1.38924285, grad/param norm = 4.9167e-01, time/batch = 0.1545s	
2089/2700 (epoch 38.685), train_loss = 1.43600831, grad/param norm = 4.9804e-01, time/batch = 0.1308s	
2090/2700 (epoch 38.704), train_loss = 1.46505396, grad/param norm = 4.9171e-01, time/batch = 0.1295s	
2091/2700 (epoch 38.722), train_loss = 1.43620887, grad/param norm = 4.6288e-01, time/batch = 0.1472s	
2092/2700 (epoch 38.741), train_loss = 1.46347413, grad/param norm = 4.9559e-01, time/batch = 0.1307s	
2093/2700 (epoch 38.759), train_loss = 1.44145153, grad/param norm = 5.0091e-01, time/batch = 0.1297s	
2094/2700 (epoch 38.778), train_loss = 1.47634649, grad/param norm = 4.8841e-01, time/batch = 0.1273s	
2095/2700 (epoch 38.796), train_loss = 1.42257903, grad/param norm = 5.6389e-01, time/batch = 0.1265s	
2096/2700 (epoch 38.815), train_loss = 1.47226115, grad/param norm = 5.0219e-01, time/batch = 0.1324s	
2097/2700 (epoch 38.833), train_loss = 1.43577622, grad/param norm = 5.5183e-01, time/batch = 0.1348s	
2098/2700 (epoch 38.852), train_loss = 1.44163937, grad/param norm = 5.0316e-01, time/batch = 0.1368s	
2099/2700 (epoch 38.870), train_loss = 1.45429626, grad/param norm = 4.9750e-01, time/batch = 0.1345s	
2100/2700 (epoch 38.889), train_loss = 1.45807001, grad/param norm = 4.9754e-01, time/batch = 0.1354s	
2101/2700 (epoch 38.907), train_loss = 1.56714977, grad/param norm = 5.6837e-01, time/batch = 0.1363s	
2102/2700 (epoch 38.926), train_loss = 1.47918244, grad/param norm = 5.8466e-01, time/batch = 0.1195s	
2103/2700 (epoch 38.944), train_loss = 1.47813450, grad/param norm = 5.7660e-01, time/batch = 0.1095s	
2104/2700 (epoch 38.963), train_loss = 1.48283007, grad/param norm = 4.7097e-01, time/batch = 0.1285s	
2105/2700 (epoch 38.981), train_loss = 1.46353299, grad/param norm = 5.1657e-01, time/batch = 0.1285s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2106/2700 (epoch 39.000), train_loss = 1.52419783, grad/param norm = 5.3676e-01, time/batch = 0.1286s	
2107/2700 (epoch 39.019), train_loss = 1.53472264, grad/param norm = 5.0391e-01, time/batch = 0.1286s	
2108/2700 (epoch 39.037), train_loss = 1.51944964, grad/param norm = 5.1638e-01, time/batch = 0.1292s	
2109/2700 (epoch 39.056), train_loss = 1.42509801, grad/param norm = 5.1172e-01, time/batch = 0.1285s	
2110/2700 (epoch 39.074), train_loss = 1.44265436, grad/param norm = 5.2186e-01, time/batch = 0.1299s	
2111/2700 (epoch 39.093), train_loss = 1.44405002, grad/param norm = 4.8871e-01, time/batch = 0.1361s	
2112/2700 (epoch 39.111), train_loss = 1.38797939, grad/param norm = 5.3337e-01, time/batch = 0.1229s	
2113/2700 (epoch 39.130), train_loss = 1.46430185, grad/param norm = 4.8016e-01, time/batch = 0.1154s	
2114/2700 (epoch 39.148), train_loss = 1.39771993, grad/param norm = 5.2606e-01, time/batch = 0.1291s	
2115/2700 (epoch 39.167), train_loss = 1.47586600, grad/param norm = 5.3748e-01, time/batch = 0.1306s	
2116/2700 (epoch 39.185), train_loss = 1.39591391, grad/param norm = 5.0096e-01, time/batch = 0.1297s	
2117/2700 (epoch 39.204), train_loss = 1.46702179, grad/param norm = 5.2419e-01, time/batch = 0.1278s	
2118/2700 (epoch 39.222), train_loss = 1.40186206, grad/param norm = 4.8223e-01, time/batch = 0.1309s	
2119/2700 (epoch 39.241), train_loss = 1.34989309, grad/param norm = 4.8846e-01, time/batch = 0.1302s	
2120/2700 (epoch 39.259), train_loss = 1.40433296, grad/param norm = 5.2751e-01, time/batch = 0.1326s	
2121/2700 (epoch 39.278), train_loss = 1.50038667, grad/param norm = 5.2352e-01, time/batch = 0.1355s	
2122/2700 (epoch 39.296), train_loss = 1.44979841, grad/param norm = 4.7589e-01, time/batch = 0.1221s	
2123/2700 (epoch 39.315), train_loss = 1.42243596, grad/param norm = 5.1537e-01, time/batch = 0.1149s	
2124/2700 (epoch 39.333), train_loss = 1.43413854, grad/param norm = 6.5377e-01, time/batch = 0.1302s	
2125/2700 (epoch 39.352), train_loss = 1.44816442, grad/param norm = 6.5978e-01, time/batch = 0.1296s	
2126/2700 (epoch 39.370), train_loss = 1.46518929, grad/param norm = 5.6141e-01, time/batch = 0.1332s	
2127/2700 (epoch 39.389), train_loss = 1.44714661, grad/param norm = 5.0285e-01, time/batch = 0.1337s	
2128/2700 (epoch 39.407), train_loss = 1.50150946, grad/param norm = 6.2753e-01, time/batch = 0.1351s	
2129/2700 (epoch 39.426), train_loss = 1.49416946, grad/param norm = 6.2294e-01, time/batch = 0.1357s	
2130/2700 (epoch 39.444), train_loss = 1.42818829, grad/param norm = 4.8840e-01, time/batch = 0.1347s	
2131/2700 (epoch 39.463), train_loss = 1.49128663, grad/param norm = 5.1863e-01, time/batch = 0.1347s	
2132/2700 (epoch 39.481), train_loss = 1.48425024, grad/param norm = 5.3155e-01, time/batch = 0.1196s	
2133/2700 (epoch 39.500), train_loss = 1.45130431, grad/param norm = 5.4909e-01, time/batch = 0.1138s	
2134/2700 (epoch 39.519), train_loss = 1.47779763, grad/param norm = 5.1345e-01, time/batch = 0.1298s	
2135/2700 (epoch 39.537), train_loss = 1.47412560, grad/param norm = 4.5721e-01, time/batch = 0.1297s	
2136/2700 (epoch 39.556), train_loss = 1.40227488, grad/param norm = 4.8529e-01, time/batch = 0.1326s	
2137/2700 (epoch 39.574), train_loss = 1.41057124, grad/param norm = 5.7980e-01, time/batch = 0.1335s	
2138/2700 (epoch 39.593), train_loss = 1.43332543, grad/param norm = 5.0430e-01, time/batch = 0.1353s	
2139/2700 (epoch 39.611), train_loss = 1.34684064, grad/param norm = 4.8102e-01, time/batch = 0.1359s	
2140/2700 (epoch 39.630), train_loss = 1.38468273, grad/param norm = 4.9745e-01, time/batch = 0.1331s	
2141/2700 (epoch 39.648), train_loss = 1.43431796, grad/param norm = 4.7823e-01, time/batch = 0.1370s	
2142/2700 (epoch 39.667), train_loss = 1.38080714, grad/param norm = 5.1163e-01, time/batch = 0.1203s	
2143/2700 (epoch 39.685), train_loss = 1.42729010, grad/param norm = 5.0696e-01, time/batch = 0.1135s	
2144/2700 (epoch 39.704), train_loss = 1.45573801, grad/param norm = 4.8871e-01, time/batch = 0.1287s	
2145/2700 (epoch 39.722), train_loss = 1.42708154, grad/param norm = 4.6289e-01, time/batch = 0.1294s	
2146/2700 (epoch 39.741), train_loss = 1.45430744, grad/param norm = 5.0254e-01, time/batch = 0.1332s	
2147/2700 (epoch 39.759), train_loss = 1.43197777, grad/param norm = 5.0242e-01, time/batch = 0.1350s	
2148/2700 (epoch 39.778), train_loss = 1.46711506, grad/param norm = 4.9487e-01, time/batch = 0.1503s	
2149/2700 (epoch 39.796), train_loss = 1.41357778, grad/param norm = 5.6874e-01, time/batch = 0.1541s	
2150/2700 (epoch 39.815), train_loss = 1.46317676, grad/param norm = 5.1073e-01, time/batch = 0.1526s	
2151/2700 (epoch 39.833), train_loss = 1.42643707, grad/param norm = 5.5201e-01, time/batch = 0.1480s	
2152/2700 (epoch 39.852), train_loss = 1.43312060, grad/param norm = 5.1652e-01, time/batch = 0.1220s	
2153/2700 (epoch 39.870), train_loss = 1.44606375, grad/param norm = 4.9725e-01, time/batch = 0.1488s	
2154/2700 (epoch 39.889), train_loss = 1.44911195, grad/param norm = 4.9402e-01, time/batch = 0.1503s	
2155/2700 (epoch 39.907), train_loss = 1.55713269, grad/param norm = 5.7844e-01, time/batch = 0.1536s	
2156/2700 (epoch 39.926), train_loss = 1.46903995, grad/param norm = 5.9008e-01, time/batch = 0.1496s	
2157/2700 (epoch 39.944), train_loss = 1.46922702, grad/param norm = 5.6684e-01, time/batch = 0.1285s	
2158/2700 (epoch 39.963), train_loss = 1.47362801, grad/param norm = 4.7504e-01, time/batch = 0.1312s	
2159/2700 (epoch 39.981), train_loss = 1.45420872, grad/param norm = 5.2303e-01, time/batch = 0.1387s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2160/2700 (epoch 40.000), train_loss = 1.51459668, grad/param norm = 5.2859e-01, time/batch = 0.1405s	
2161/2700 (epoch 40.019), train_loss = 1.52635713, grad/param norm = 5.0585e-01, time/batch = 0.1271s	
2162/2700 (epoch 40.037), train_loss = 1.51101080, grad/param norm = 5.3073e-01, time/batch = 0.1315s	
2163/2700 (epoch 40.056), train_loss = 1.41698211, grad/param norm = 5.0941e-01, time/batch = 0.1397s	
2164/2700 (epoch 40.074), train_loss = 1.43309427, grad/param norm = 4.9773e-01, time/batch = 0.1476s	
2165/2700 (epoch 40.093), train_loss = 1.43555408, grad/param norm = 5.1155e-01, time/batch = 0.1539s	
2166/2700 (epoch 40.111), train_loss = 1.37974985, grad/param norm = 5.5501e-01, time/batch = 0.1519s	
2167/2700 (epoch 40.130), train_loss = 1.45586051, grad/param norm = 4.8702e-01, time/batch = 0.1504s	
2168/2700 (epoch 40.148), train_loss = 1.38865029, grad/param norm = 5.1331e-01, time/batch = 0.1494s	
2169/2700 (epoch 40.167), train_loss = 1.46698523, grad/param norm = 5.2828e-01, time/batch = 0.1363s	
2170/2700 (epoch 40.185), train_loss = 1.38764575, grad/param norm = 4.9107e-01, time/batch = 0.1292s	
2171/2700 (epoch 40.204), train_loss = 1.45756100, grad/param norm = 5.0892e-01, time/batch = 0.1341s	
2172/2700 (epoch 40.222), train_loss = 1.39354038, grad/param norm = 4.9797e-01, time/batch = 0.1496s	
2173/2700 (epoch 40.241), train_loss = 1.34317929, grad/param norm = 5.1495e-01, time/batch = 0.1333s	
2174/2700 (epoch 40.259), train_loss = 1.39645759, grad/param norm = 5.3418e-01, time/batch = 0.1431s	
2175/2700 (epoch 40.278), train_loss = 1.49278018, grad/param norm = 5.4727e-01, time/batch = 0.1472s	
2176/2700 (epoch 40.296), train_loss = 1.44143393, grad/param norm = 4.8689e-01, time/batch = 0.1486s	
2177/2700 (epoch 40.315), train_loss = 1.41307942, grad/param norm = 4.5839e-01, time/batch = 0.1515s	
2178/2700 (epoch 40.333), train_loss = 1.42171781, grad/param norm = 4.9733e-01, time/batch = 0.1328s	
2179/2700 (epoch 40.352), train_loss = 1.43423555, grad/param norm = 5.0420e-01, time/batch = 0.1430s	
2180/2700 (epoch 40.370), train_loss = 1.45657751, grad/param norm = 5.8682e-01, time/batch = 0.1464s	
2181/2700 (epoch 40.389), train_loss = 1.43836654, grad/param norm = 5.7265e-01, time/batch = 0.1511s	
2182/2700 (epoch 40.407), train_loss = 1.49096793, grad/param norm = 5.3595e-01, time/batch = 0.1523s	
2183/2700 (epoch 40.426), train_loss = 1.48202910, grad/param norm = 5.6649e-01, time/batch = 0.1516s	
2184/2700 (epoch 40.444), train_loss = 1.42248858, grad/param norm = 5.7157e-01, time/batch = 0.1526s	
2185/2700 (epoch 40.463), train_loss = 1.48599878, grad/param norm = 5.8275e-01, time/batch = 0.1511s	
2186/2700 (epoch 40.481), train_loss = 1.47491438, grad/param norm = 5.2515e-01, time/batch = 0.1354s	
2187/2700 (epoch 40.500), train_loss = 1.44112334, grad/param norm = 4.5993e-01, time/batch = 0.1301s	
2188/2700 (epoch 40.519), train_loss = 1.46880844, grad/param norm = 5.4615e-01, time/batch = 0.1337s	
2189/2700 (epoch 40.537), train_loss = 1.46834518, grad/param norm = 5.4282e-01, time/batch = 0.1434s	
2190/2700 (epoch 40.556), train_loss = 1.39599969, grad/param norm = 5.3370e-01, time/batch = 0.1427s	
2191/2700 (epoch 40.574), train_loss = 1.40080156, grad/param norm = 5.3843e-01, time/batch = 0.1364s	
2192/2700 (epoch 40.593), train_loss = 1.42548106, grad/param norm = 4.9498e-01, time/batch = 0.1423s	
2193/2700 (epoch 40.611), train_loss = 1.33993515, grad/param norm = 4.9121e-01, time/batch = 0.1490s	
2194/2700 (epoch 40.630), train_loss = 1.37706705, grad/param norm = 5.0940e-01, time/batch = 0.1509s	
2195/2700 (epoch 40.648), train_loss = 1.42588640, grad/param norm = 4.5963e-01, time/batch = 0.1489s	
2196/2700 (epoch 40.667), train_loss = 1.37150920, grad/param norm = 4.9862e-01, time/batch = 0.1518s	
2197/2700 (epoch 40.685), train_loss = 1.41845967, grad/param norm = 4.9488e-01, time/batch = 0.1449s	
2198/2700 (epoch 40.704), train_loss = 1.44688418, grad/param norm = 4.9095e-01, time/batch = 0.1404s	
2199/2700 (epoch 40.722), train_loss = 1.41903297, grad/param norm = 4.6833e-01, time/batch = 0.1397s	
2200/2700 (epoch 40.741), train_loss = 1.44436335, grad/param norm = 4.9455e-01, time/batch = 0.1102s	
2201/2700 (epoch 40.759), train_loss = 1.42210303, grad/param norm = 4.9837e-01, time/batch = 0.1214s	
2202/2700 (epoch 40.778), train_loss = 1.45804188, grad/param norm = 4.9585e-01, time/batch = 0.1260s	
2203/2700 (epoch 40.796), train_loss = 1.40411529, grad/param norm = 5.6309e-01, time/batch = 0.1222s	
2204/2700 (epoch 40.815), train_loss = 1.45437440, grad/param norm = 5.0936e-01, time/batch = 0.1195s	
2205/2700 (epoch 40.833), train_loss = 1.41703048, grad/param norm = 5.4744e-01, time/batch = 0.1273s	
2206/2700 (epoch 40.852), train_loss = 1.42370019, grad/param norm = 5.0932e-01, time/batch = 0.1294s	
2207/2700 (epoch 40.870), train_loss = 1.43804654, grad/param norm = 4.8454e-01, time/batch = 0.1300s	
2208/2700 (epoch 40.889), train_loss = 1.44090422, grad/param norm = 5.0162e-01, time/batch = 0.1288s	
2209/2700 (epoch 40.907), train_loss = 1.54721640, grad/param norm = 6.0090e-01, time/batch = 0.1292s	
2210/2700 (epoch 40.926), train_loss = 1.46047292, grad/param norm = 6.1203e-01, time/batch = 0.1011s	
2211/2700 (epoch 40.944), train_loss = 1.46051615, grad/param norm = 5.6606e-01, time/batch = 0.1230s	
2212/2700 (epoch 40.963), train_loss = 1.46439695, grad/param norm = 4.7378e-01, time/batch = 0.1329s	
2213/2700 (epoch 40.981), train_loss = 1.44488367, grad/param norm = 5.2410e-01, time/batch = 0.1304s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2214/2700 (epoch 41.000), train_loss = 1.50532163, grad/param norm = 5.2733e-01, time/batch = 0.1240s	
2215/2700 (epoch 41.019), train_loss = 1.51828516, grad/param norm = 5.0121e-01, time/batch = 0.1260s	
2216/2700 (epoch 41.037), train_loss = 1.50282452, grad/param norm = 5.2177e-01, time/batch = 0.1255s	
2217/2700 (epoch 41.056), train_loss = 1.40925160, grad/param norm = 5.1045e-01, time/batch = 0.1262s	
2218/2700 (epoch 41.074), train_loss = 1.42495764, grad/param norm = 5.0803e-01, time/batch = 0.1316s	
2219/2700 (epoch 41.093), train_loss = 1.42705745, grad/param norm = 5.0610e-01, time/batch = 0.1344s	
2220/2700 (epoch 41.111), train_loss = 1.37053823, grad/param norm = 5.3522e-01, time/batch = 0.1344s	
2221/2700 (epoch 41.130), train_loss = 1.44745347, grad/param norm = 4.9594e-01, time/batch = 0.1308s	
2222/2700 (epoch 41.148), train_loss = 1.38029603, grad/param norm = 5.1174e-01, time/batch = 0.1314s	
2223/2700 (epoch 41.167), train_loss = 1.45809077, grad/param norm = 5.1820e-01, time/batch = 0.1325s	
2224/2700 (epoch 41.185), train_loss = 1.37872673, grad/param norm = 4.7880e-01, time/batch = 0.1131s	
2225/2700 (epoch 41.204), train_loss = 1.44814566, grad/param norm = 5.0540e-01, time/batch = 0.1296s	
2226/2700 (epoch 41.222), train_loss = 1.38541943, grad/param norm = 5.0946e-01, time/batch = 0.1318s	
2227/2700 (epoch 41.241), train_loss = 1.33611274, grad/param norm = 5.2652e-01, time/batch = 0.1339s	
2228/2700 (epoch 41.259), train_loss = 1.38927326, grad/param norm = 5.4023e-01, time/batch = 0.1541s	
2229/2700 (epoch 41.278), train_loss = 1.48505159, grad/param norm = 5.4601e-01, time/batch = 0.1537s	
2230/2700 (epoch 41.296), train_loss = 1.43328212, grad/param norm = 4.9190e-01, time/batch = 0.1439s	
2231/2700 (epoch 41.315), train_loss = 1.40426036, grad/param norm = 4.6131e-01, time/batch = 0.1556s	
2232/2700 (epoch 41.333), train_loss = 1.41295612, grad/param norm = 5.0771e-01, time/batch = 0.1249s	
2233/2700 (epoch 41.352), train_loss = 1.42533879, grad/param norm = 5.1489e-01, time/batch = 0.1286s	
2234/2700 (epoch 41.370), train_loss = 1.44631954, grad/param norm = 5.6376e-01, time/batch = 0.1352s	
2235/2700 (epoch 41.389), train_loss = 1.42786763, grad/param norm = 5.2676e-01, time/batch = 0.1420s	
2236/2700 (epoch 41.407), train_loss = 1.48226272, grad/param norm = 5.1778e-01, time/batch = 0.1488s	
2237/2700 (epoch 41.426), train_loss = 1.47139930, grad/param norm = 5.0279e-01, time/batch = 0.1481s	
2238/2700 (epoch 41.444), train_loss = 1.41141830, grad/param norm = 4.6979e-01, time/batch = 0.1486s	
2239/2700 (epoch 41.463), train_loss = 1.47544914, grad/param norm = 5.2162e-01, time/batch = 0.1515s	
2240/2700 (epoch 41.481), train_loss = 1.46389696, grad/param norm = 5.0111e-01, time/batch = 0.1303s	
2241/2700 (epoch 41.500), train_loss = 1.43235120, grad/param norm = 5.0180e-01, time/batch = 0.1497s	
2242/2700 (epoch 41.519), train_loss = 1.45959671, grad/param norm = 5.0770e-01, time/batch = 0.1405s	
2243/2700 (epoch 41.537), train_loss = 1.45798956, grad/param norm = 4.8031e-01, time/batch = 0.1367s	
2244/2700 (epoch 41.556), train_loss = 1.38740992, grad/param norm = 5.0603e-01, time/batch = 0.1392s	
2245/2700 (epoch 41.574), train_loss = 1.39355017, grad/param norm = 5.7419e-01, time/batch = 0.1361s	
2246/2700 (epoch 41.593), train_loss = 1.41756921, grad/param norm = 4.9683e-01, time/batch = 0.1272s	
2247/2700 (epoch 41.611), train_loss = 1.33211038, grad/param norm = 4.7157e-01, time/batch = 0.1324s	
2248/2700 (epoch 41.630), train_loss = 1.36883404, grad/param norm = 5.0079e-01, time/batch = 0.1495s	
2249/2700 (epoch 41.648), train_loss = 1.41851857, grad/param norm = 4.6885e-01, time/batch = 0.1319s	
2250/2700 (epoch 41.667), train_loss = 1.36404571, grad/param norm = 5.2246e-01, time/batch = 0.1366s	
2251/2700 (epoch 41.685), train_loss = 1.41086270, grad/param norm = 5.1812e-01, time/batch = 0.1387s	
2252/2700 (epoch 41.704), train_loss = 1.43839988, grad/param norm = 4.9611e-01, time/batch = 0.1362s	
2253/2700 (epoch 41.722), train_loss = 1.41153813, grad/param norm = 4.8215e-01, time/batch = 0.1276s	
2254/2700 (epoch 41.741), train_loss = 1.43590590, grad/param norm = 4.9549e-01, time/batch = 0.1270s	
2255/2700 (epoch 41.759), train_loss = 1.41283350, grad/param norm = 4.8985e-01, time/batch = 0.1264s	
2256/2700 (epoch 41.778), train_loss = 1.44955117, grad/param norm = 5.0513e-01, time/batch = 0.1322s	
2257/2700 (epoch 41.796), train_loss = 1.39611254, grad/param norm = 5.8280e-01, time/batch = 0.1353s	
2258/2700 (epoch 41.815), train_loss = 1.44609260, grad/param norm = 5.1718e-01, time/batch = 0.1343s	
2259/2700 (epoch 41.833), train_loss = 1.40818797, grad/param norm = 5.4900e-01, time/batch = 0.1214s	
2260/2700 (epoch 41.852), train_loss = 1.41519129, grad/param norm = 5.1383e-01, time/batch = 0.1301s	
2261/2700 (epoch 41.870), train_loss = 1.43078887, grad/param norm = 4.9231e-01, time/batch = 0.1369s	
2262/2700 (epoch 41.889), train_loss = 1.43289676, grad/param norm = 4.9376e-01, time/batch = 0.1350s	
2263/2700 (epoch 41.907), train_loss = 1.53679159, grad/param norm = 5.7526e-01, time/batch = 0.1350s	
2264/2700 (epoch 41.926), train_loss = 1.44939760, grad/param norm = 5.7035e-01, time/batch = 0.1364s	
2265/2700 (epoch 41.944), train_loss = 1.45162110, grad/param norm = 5.4668e-01, time/batch = 0.1354s	
2266/2700 (epoch 41.963), train_loss = 1.45598306, grad/param norm = 4.7919e-01, time/batch = 0.1349s	
2267/2700 (epoch 41.981), train_loss = 1.43603943, grad/param norm = 5.1982e-01, time/batch = 0.1349s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2268/2700 (epoch 42.000), train_loss = 1.49635655, grad/param norm = 5.2146e-01, time/batch = 0.1209s	
2269/2700 (epoch 42.019), train_loss = 1.51084100, grad/param norm = 5.0461e-01, time/batch = 0.1146s	
2270/2700 (epoch 42.037), train_loss = 1.49498760, grad/param norm = 5.2818e-01, time/batch = 0.1286s	
2271/2700 (epoch 42.056), train_loss = 1.40206157, grad/param norm = 5.1232e-01, time/batch = 0.1371s	
2272/2700 (epoch 42.074), train_loss = 1.41658222, grad/param norm = 5.0163e-01, time/batch = 0.1354s	
2273/2700 (epoch 42.093), train_loss = 1.41910624, grad/param norm = 5.1721e-01, time/batch = 0.1349s	
2274/2700 (epoch 42.111), train_loss = 1.36244993, grad/param norm = 5.3409e-01, time/batch = 0.1349s	
2275/2700 (epoch 42.130), train_loss = 1.43948244, grad/param norm = 4.9994e-01, time/batch = 0.1353s	
2276/2700 (epoch 42.148), train_loss = 1.37266382, grad/param norm = 5.2568e-01, time/batch = 0.1346s	
2277/2700 (epoch 42.167), train_loss = 1.45069697, grad/param norm = 5.4285e-01, time/batch = 0.1354s	
2278/2700 (epoch 42.185), train_loss = 1.37125881, grad/param norm = 4.8823e-01, time/batch = 0.1207s	
2279/2700 (epoch 42.204), train_loss = 1.44034294, grad/param norm = 5.1798e-01, time/batch = 0.1136s	
2280/2700 (epoch 42.222), train_loss = 1.37716449, grad/param norm = 5.0067e-01, time/batch = 0.1301s	
2281/2700 (epoch 42.241), train_loss = 1.32873411, grad/param norm = 5.1232e-01, time/batch = 0.1489s	
2282/2700 (epoch 42.259), train_loss = 1.38183369, grad/param norm = 5.3592e-01, time/batch = 0.1268s	
2283/2700 (epoch 42.278), train_loss = 1.47729105, grad/param norm = 5.3478e-01, time/batch = 0.1294s	
2284/2700 (epoch 42.296), train_loss = 1.42560400, grad/param norm = 4.9687e-01, time/batch = 0.1380s	
2285/2700 (epoch 42.315), train_loss = 1.39592911, grad/param norm = 4.7374e-01, time/batch = 0.1307s	
2286/2700 (epoch 42.333), train_loss = 1.40504356, grad/param norm = 5.3511e-01, time/batch = 0.1324s	
2287/2700 (epoch 42.352), train_loss = 1.41703303, grad/param norm = 5.3902e-01, time/batch = 0.1346s	
2288/2700 (epoch 42.370), train_loss = 1.43714628, grad/param norm = 5.5089e-01, time/batch = 0.1097s	
2289/2700 (epoch 42.389), train_loss = 1.41842407, grad/param norm = 4.9932e-01, time/batch = 0.1216s	
2290/2700 (epoch 42.407), train_loss = 1.47426111, grad/param norm = 5.3143e-01, time/batch = 0.1218s	
2291/2700 (epoch 42.426), train_loss = 1.46185404, grad/param norm = 5.0912e-01, time/batch = 0.1275s	
2292/2700 (epoch 42.444), train_loss = 1.40375060, grad/param norm = 4.6399e-01, time/batch = 0.1282s	
2293/2700 (epoch 42.463), train_loss = 1.46748530, grad/param norm = 5.2564e-01, time/batch = 0.1278s	
2294/2700 (epoch 42.481), train_loss = 1.45493043, grad/param norm = 5.1348e-01, time/batch = 0.1281s	
2295/2700 (epoch 42.500), train_loss = 1.42508922, grad/param norm = 5.5852e-01, time/batch = 0.1285s	
2296/2700 (epoch 42.519), train_loss = 1.45192737, grad/param norm = 5.2054e-01, time/batch = 0.1285s	
2297/2700 (epoch 42.537), train_loss = 1.44964769, grad/param norm = 4.6964e-01, time/batch = 0.1290s	
2298/2700 (epoch 42.556), train_loss = 1.37988596, grad/param norm = 5.0346e-01, time/batch = 0.1022s	
2299/2700 (epoch 42.574), train_loss = 1.38637297, grad/param norm = 5.9313e-01, time/batch = 0.1234s	
2300/2700 (epoch 42.593), train_loss = 1.41016066, grad/param norm = 5.0372e-01, time/batch = 0.1266s	
2301/2700 (epoch 42.611), train_loss = 1.32538893, grad/param norm = 4.8269e-01, time/batch = 0.1322s	
2302/2700 (epoch 42.630), train_loss = 1.36174602, grad/param norm = 5.0985e-01, time/batch = 0.1324s	
2303/2700 (epoch 42.648), train_loss = 1.41115302, grad/param norm = 4.6908e-01, time/batch = 0.1344s	
2304/2700 (epoch 42.667), train_loss = 1.35613184, grad/param norm = 5.2326e-01, time/batch = 0.1356s	
2305/2700 (epoch 42.685), train_loss = 1.40244337, grad/param norm = 5.0921e-01, time/batch = 0.1361s	
2306/2700 (epoch 42.704), train_loss = 1.42979897, grad/param norm = 4.9294e-01, time/batch = 0.1355s	
2307/2700 (epoch 42.722), train_loss = 1.40333485, grad/param norm = 4.7560e-01, time/batch = 0.1348s	
2308/2700 (epoch 42.741), train_loss = 1.42706015, grad/param norm = 4.9539e-01, time/batch = 0.1378s	
2309/2700 (epoch 42.759), train_loss = 1.40435578, grad/param norm = 4.9723e-01, time/batch = 0.1506s	
2310/2700 (epoch 42.778), train_loss = 1.44090973, grad/param norm = 4.9918e-01, time/batch = 0.1356s	
2311/2700 (epoch 42.796), train_loss = 1.38679458, grad/param norm = 5.5194e-01, time/batch = 0.1523s	
2312/2700 (epoch 42.815), train_loss = 1.43758379, grad/param norm = 5.2455e-01, time/batch = 0.1269s	
2313/2700 (epoch 42.833), train_loss = 1.39961585, grad/param norm = 5.4878e-01, time/batch = 0.1376s	
2314/2700 (epoch 42.852), train_loss = 1.40694434, grad/param norm = 5.1235e-01, time/batch = 0.1417s	
2315/2700 (epoch 42.870), train_loss = 1.42343240, grad/param norm = 4.8630e-01, time/batch = 0.1387s	
2316/2700 (epoch 42.889), train_loss = 1.42531144, grad/param norm = 5.1106e-01, time/batch = 0.1372s	
2317/2700 (epoch 42.907), train_loss = 1.52869074, grad/param norm = 6.1306e-01, time/batch = 0.1437s	
2318/2700 (epoch 42.926), train_loss = 1.44193960, grad/param norm = 6.0671e-01, time/batch = 0.1216s	
2319/2700 (epoch 42.944), train_loss = 1.44354426, grad/param norm = 5.5249e-01, time/batch = 0.1503s	
2320/2700 (epoch 42.963), train_loss = 1.44777486, grad/param norm = 4.8197e-01, time/batch = 0.1516s	
2321/2700 (epoch 42.981), train_loss = 1.42725542, grad/param norm = 5.2091e-01, time/batch = 0.1359s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
2322/2700 (epoch 43.000), train_loss = 1.48757180, grad/param norm = 5.1742e-01, time/batch = 0.1486s	
2323/2700 (epoch 43.019), train_loss = 1.50327257, grad/param norm = 5.0134e-01, time/batch = 0.1511s	
2324/2700 (epoch 43.037), train_loss = 1.48742153, grad/param norm = 5.2712e-01, time/batch = 0.1524s	
2325/2700 (epoch 43.056), train_loss = 1.39492267, grad/param norm = 5.1082e-01, time/batch = 0.1470s	
2326/2700 (epoch 43.074), train_loss = 1.40866391, grad/param norm = 5.0767e-01, time/batch = 0.1535s	
2327/2700 (epoch 43.093), train_loss = 1.41138559, grad/param norm = 5.1900e-01, time/batch = 0.1409s	
2328/2700 (epoch 43.111), train_loss = 1.35438878, grad/param norm = 5.2290e-01, time/batch = 0.1366s	
2329/2700 (epoch 43.130), train_loss = 1.43180903, grad/param norm = 5.1368e-01, time/batch = 0.1535s	
2330/2700 (epoch 43.148), train_loss = 1.36473298, grad/param norm = 5.1112e-01, time/batch = 0.1534s	
2331/2700 (epoch 43.167), train_loss = 1.44195400, grad/param norm = 5.1844e-01, time/batch = 0.1325s	
2332/2700 (epoch 43.185), train_loss = 1.36329379, grad/param norm = 4.7166e-01, time/batch = 0.1363s	
2333/2700 (epoch 43.204), train_loss = 1.43133282, grad/param norm = 5.0880e-01, time/batch = 0.1390s	
2334/2700 (epoch 43.222), train_loss = 1.37020869, grad/param norm = 5.3280e-01, time/batch = 0.1411s	
2335/2700 (epoch 43.241), train_loss = 1.32297526, grad/param norm = 5.4609e-01, time/batch = 0.1342s	
2336/2700 (epoch 43.259), train_loss = 1.37525132, grad/param norm = 5.4874e-01, time/batch = 0.1359s	
2337/2700 (epoch 43.278), train_loss = 1.47015818, grad/param norm = 5.4798e-01, time/batch = 0.1114s	
2338/2700 (epoch 43.296), train_loss = 1.41826751, grad/param norm = 5.0602e-01, time/batch = 0.1249s	
2339/2700 (epoch 43.315), train_loss = 1.38797041, grad/param norm = 4.6527e-01, time/batch = 0.1378s	
2340/2700 (epoch 43.333), train_loss = 1.39643539, grad/param norm = 5.0558e-01, time/batch = 0.1384s	
2341/2700 (epoch 43.352), train_loss = 1.40784093, grad/param norm = 5.0333e-01, time/batch = 0.1371s	
2342/2700 (epoch 43.370), train_loss = 1.42995579, grad/param norm = 6.1093e-01, time/batch = 0.1429s	
2343/2700 (epoch 43.389), train_loss = 1.41189117, grad/param norm = 5.9706e-01, time/batch = 0.1395s	
2344/2700 (epoch 43.407), train_loss = 1.46688107, grad/param norm = 5.3871e-01, time/batch = 0.1508s	
2345/2700 (epoch 43.426), train_loss = 1.45332773, grad/param norm = 5.2184e-01, time/batch = 0.1512s	
2346/2700 (epoch 43.444), train_loss = 1.39853765, grad/param norm = 5.4976e-01, time/batch = 0.1437s	
2347/2700 (epoch 43.463), train_loss = 1.46079305, grad/param norm = 5.6801e-01, time/batch = 0.1499s	
2348/2700 (epoch 43.481), train_loss = 1.44666046, grad/param norm = 5.0652e-01, time/batch = 0.1316s	
2349/2700 (epoch 43.500), train_loss = 1.41548674, grad/param norm = 4.7538e-01, time/batch = 0.1406s	
2350/2700 (epoch 43.519), train_loss = 1.44336683, grad/param norm = 5.4041e-01, time/batch = 0.1484s	
2351/2700 (epoch 43.537), train_loss = 1.44346444, grad/param norm = 5.3436e-01, time/batch = 0.1482s	
2352/2700 (epoch 43.556), train_loss = 1.37262782, grad/param norm = 5.2713e-01, time/batch = 0.1339s	
2353/2700 (epoch 43.574), train_loss = 1.37745959, grad/param norm = 5.4473e-01, time/batch = 0.1297s	
2354/2700 (epoch 43.593), train_loss = 1.40332205, grad/param norm = 4.9468e-01, time/batch = 0.1384s	
2355/2700 (epoch 43.611), train_loss = 1.31911136, grad/param norm = 4.9742e-01, time/batch = 0.1470s	
2356/2700 (epoch 43.630), train_loss = 1.35472271, grad/param norm = 5.1705e-01, time/batch = 0.1296s	
2357/2700 (epoch 43.648), train_loss = 1.40370232, grad/param norm = 4.5000e-01, time/batch = 0.1483s	
2358/2700 (epoch 43.667), train_loss = 1.34796103, grad/param norm = 5.1198e-01, time/batch = 0.1391s	
2359/2700 (epoch 43.685), train_loss = 1.39428200, grad/param norm = 4.9225e-01, time/batch = 0.1390s	
2360/2700 (epoch 43.704), train_loss = 1.42149864, grad/param norm = 4.9368e-01, time/batch = 0.1212s	
2361/2700 (epoch 43.722), train_loss = 1.39571251, grad/param norm = 4.7554e-01, time/batch = 0.1495s	
2362/2700 (epoch 43.741), train_loss = 1.41857422, grad/param norm = 4.9784e-01, time/batch = 0.1267s	
2363/2700 (epoch 43.759), train_loss = 1.39622610, grad/param norm = 5.0276e-01, time/batch = 0.1313s	
2364/2700 (epoch 43.778), train_loss = 1.43275939, grad/param norm = 5.0245e-01, time/batch = 0.1361s	
2365/2700 (epoch 43.796), train_loss = 1.37828268, grad/param norm = 5.3984e-01, time/batch = 0.1227s	
2366/2700 (epoch 43.815), train_loss = 1.42957969, grad/param norm = 5.2829e-01, time/batch = 0.1272s	
2367/2700 (epoch 43.833), train_loss = 1.39121981, grad/param norm = 5.4638e-01, time/batch = 0.1311s	
2368/2700 (epoch 43.852), train_loss = 1.39911293, grad/param norm = 5.2022e-01, time/batch = 0.1401s	
2369/2700 (epoch 43.870), train_loss = 1.41641194, grad/param norm = 4.8875e-01, time/batch = 0.1497s	
2370/2700 (epoch 43.889), train_loss = 1.41797722, grad/param norm = 5.3028e-01, time/batch = 0.1436s	
2371/2700 (epoch 43.907), train_loss = 1.52000279, grad/param norm = 6.2324e-01, time/batch = 0.1382s	
2372/2700 (epoch 43.926), train_loss = 1.43331371, grad/param norm = 5.9080e-01, time/batch = 0.1384s	
2373/2700 (epoch 43.944), train_loss = 1.43508117, grad/param norm = 5.2988e-01, time/batch = 0.1422s	
2374/2700 (epoch 43.963), train_loss = 1.43979113, grad/param norm = 4.9271e-01, time/batch = 0.1309s	
2375/2700 (epoch 43.981), train_loss = 1.41910481, grad/param norm = 5.2432e-01, time/batch = 0.1420s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
2376/2700 (epoch 44.000), train_loss = 1.47892518, grad/param norm = 5.1316e-01, time/batch = 0.1449s	
2377/2700 (epoch 44.019), train_loss = 1.49644910, grad/param norm = 5.0359e-01, time/batch = 0.1511s	
2378/2700 (epoch 44.037), train_loss = 1.48010828, grad/param norm = 5.3505e-01, time/batch = 0.1476s	
2379/2700 (epoch 44.056), train_loss = 1.38815620, grad/param norm = 5.1035e-01, time/batch = 0.1437s	
2380/2700 (epoch 44.074), train_loss = 1.40102189, grad/param norm = 5.0627e-01, time/batch = 0.1518s	
2381/2700 (epoch 44.093), train_loss = 1.40393317, grad/param norm = 5.2619e-01, time/batch = 0.1258s	
2382/2700 (epoch 44.111), train_loss = 1.34686889, grad/param norm = 5.1674e-01, time/batch = 0.1311s	
2383/2700 (epoch 44.130), train_loss = 1.42439769, grad/param norm = 5.2238e-01, time/batch = 0.1194s	
2384/2700 (epoch 44.148), train_loss = 1.35758034, grad/param norm = 5.1491e-01, time/batch = 0.1407s	
2385/2700 (epoch 44.167), train_loss = 1.43424083, grad/param norm = 5.2285e-01, time/batch = 0.1315s	
2386/2700 (epoch 44.185), train_loss = 1.35596645, grad/param norm = 4.6939e-01, time/batch = 0.1357s	
2387/2700 (epoch 44.204), train_loss = 1.42328767, grad/param norm = 5.1248e-01, time/batch = 0.1411s	
2388/2700 (epoch 44.222), train_loss = 1.36276236, grad/param norm = 5.3737e-01, time/batch = 0.1373s	
2389/2700 (epoch 44.241), train_loss = 1.31632583, grad/param norm = 5.4053e-01, time/batch = 0.1433s	
2390/2700 (epoch 44.259), train_loss = 1.36822227, grad/param norm = 5.4294e-01, time/batch = 0.1444s	
2391/2700 (epoch 44.278), train_loss = 1.46265871, grad/param norm = 5.3780e-01, time/batch = 0.1397s	
2392/2700 (epoch 44.296), train_loss = 1.41103279, grad/param norm = 5.1192e-01, time/batch = 0.1297s	
2393/2700 (epoch 44.315), train_loss = 1.38013767, grad/param norm = 4.7761e-01, time/batch = 0.1516s	
2394/2700 (epoch 44.333), train_loss = 1.38910690, grad/param norm = 5.2886e-01, time/batch = 0.1536s	
2395/2700 (epoch 44.352), train_loss = 1.40002594, grad/param norm = 5.1777e-01, time/batch = 0.1529s	
2396/2700 (epoch 44.370), train_loss = 1.42074689, grad/param norm = 5.7451e-01, time/batch = 0.1528s	
2397/2700 (epoch 44.389), train_loss = 1.40206493, grad/param norm = 5.2448e-01, time/batch = 0.1438s	
2398/2700 (epoch 44.407), train_loss = 1.45856583, grad/param norm = 5.2590e-01, time/batch = 0.1462s	
2399/2700 (epoch 44.426), train_loss = 1.44397184, grad/param norm = 4.8369e-01, time/batch = 0.1284s	
2400/2700 (epoch 44.444), train_loss = 1.38980483, grad/param norm = 4.7197e-01, time/batch = 0.1347s	
2401/2700 (epoch 44.463), train_loss = 1.45193744, grad/param norm = 5.2542e-01, time/batch = 0.1490s	
2402/2700 (epoch 44.481), train_loss = 1.43767520, grad/param norm = 5.1005e-01, time/batch = 0.1538s	
2403/2700 (epoch 44.500), train_loss = 1.40892693, grad/param norm = 5.4662e-01, time/batch = 0.1523s	
2404/2700 (epoch 44.519), train_loss = 1.43561571, grad/param norm = 5.1541e-01, time/batch = 0.1532s	
2405/2700 (epoch 44.537), train_loss = 1.43497365, grad/param norm = 4.8553e-01, time/batch = 0.1515s	
2406/2700 (epoch 44.556), train_loss = 1.36530513, grad/param norm = 5.1243e-01, time/batch = 0.1497s	
2407/2700 (epoch 44.574), train_loss = 1.37183591, grad/param norm = 5.9725e-01, time/batch = 0.1373s	
2408/2700 (epoch 44.593), train_loss = 1.39624277, grad/param norm = 4.9869e-01, time/batch = 0.1279s	
2409/2700 (epoch 44.611), train_loss = 1.31245710, grad/param norm = 4.7953e-01, time/batch = 0.1348s	
2410/2700 (epoch 44.630), train_loss = 1.34755425, grad/param norm = 5.1374e-01, time/batch = 0.1439s	
2411/2700 (epoch 44.648), train_loss = 1.39730698, grad/param norm = 4.5889e-01, time/batch = 0.1422s	
2412/2700 (epoch 44.667), train_loss = 1.34129999, grad/param norm = 5.2775e-01, time/batch = 0.1531s	
2413/2700 (epoch 44.685), train_loss = 1.38748117, grad/param norm = 5.0676e-01, time/batch = 0.1502s	
2414/2700 (epoch 44.704), train_loss = 1.41373304, grad/param norm = 4.9541e-01, time/batch = 0.1512s	
2415/2700 (epoch 44.722), train_loss = 1.38886775, grad/param norm = 4.8310e-01, time/batch = 0.1513s	
2416/2700 (epoch 44.741), train_loss = 1.41086878, grad/param norm = 4.9655e-01, time/batch = 0.1566s	
2417/2700 (epoch 44.759), train_loss = 1.38795953, grad/param norm = 4.9381e-01, time/batch = 0.1296s	
2418/2700 (epoch 44.778), train_loss = 1.42505480, grad/param norm = 5.1131e-01, time/batch = 0.1275s	
2419/2700 (epoch 44.796), train_loss = 1.37092055, grad/param norm = 5.5077e-01, time/batch = 0.1398s	
2420/2700 (epoch 44.815), train_loss = 1.42179692, grad/param norm = 5.3225e-01, time/batch = 0.1205s	
2421/2700 (epoch 44.833), train_loss = 1.38305156, grad/param norm = 5.4262e-01, time/batch = 0.1364s	
2422/2700 (epoch 44.852), train_loss = 1.39145155, grad/param norm = 5.2065e-01, time/batch = 0.1153s	
2423/2700 (epoch 44.870), train_loss = 1.40954470, grad/param norm = 4.8862e-01, time/batch = 0.1392s	
2424/2700 (epoch 44.889), train_loss = 1.41044028, grad/param norm = 5.1326e-01, time/batch = 0.1426s	
2425/2700 (epoch 44.907), train_loss = 1.51051142, grad/param norm = 5.9117e-01, time/batch = 0.1427s	
2426/2700 (epoch 44.926), train_loss = 1.42389086, grad/param norm = 5.6189e-01, time/batch = 0.1342s	
2427/2700 (epoch 44.944), train_loss = 1.42718570, grad/param norm = 5.2673e-01, time/batch = 0.1325s	
2428/2700 (epoch 44.963), train_loss = 1.43210945, grad/param norm = 4.9634e-01, time/batch = 0.1389s	
2429/2700 (epoch 44.981), train_loss = 1.41103939, grad/param norm = 5.1780e-01, time/batch = 0.1457s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
2430/2700 (epoch 45.000), train_loss = 1.47074024, grad/param norm = 5.0924e-01, time/batch = 0.1278s	
2431/2700 (epoch 45.019), train_loss = 1.48984867, grad/param norm = 5.0339e-01, time/batch = 0.1258s	
2432/2700 (epoch 45.037), train_loss = 1.47310455, grad/param norm = 5.3452e-01, time/batch = 0.1417s	
2433/2700 (epoch 45.056), train_loss = 1.38174855, grad/param norm = 5.1191e-01, time/batch = 0.1402s	
2434/2700 (epoch 45.074), train_loss = 1.39355878, grad/param norm = 5.1315e-01, time/batch = 0.1429s	
2435/2700 (epoch 45.093), train_loss = 1.39664248, grad/param norm = 5.2472e-01, time/batch = 0.1382s	
2436/2700 (epoch 45.111), train_loss = 1.33941185, grad/param norm = 5.0439e-01, time/batch = 0.1309s	
2437/2700 (epoch 45.130), train_loss = 1.41736463, grad/param norm = 5.3207e-01, time/batch = 0.1338s	
2438/2700 (epoch 45.148), train_loss = 1.35062199, grad/param norm = 5.1543e-01, time/batch = 0.1473s	
2439/2700 (epoch 45.167), train_loss = 1.42678025, grad/param norm = 5.2458e-01, time/batch = 0.1502s	
2440/2700 (epoch 45.185), train_loss = 1.34901101, grad/param norm = 4.6967e-01, time/batch = 0.1435s	
2441/2700 (epoch 45.204), train_loss = 1.41570396, grad/param norm = 5.1633e-01, time/batch = 0.1455s	
2442/2700 (epoch 45.222), train_loss = 1.35544852, grad/param norm = 5.3476e-01, time/batch = 0.1254s	
2443/2700 (epoch 45.241), train_loss = 1.30997500, grad/param norm = 5.3480e-01, time/batch = 0.1318s	
2444/2700 (epoch 45.259), train_loss = 1.36159320, grad/param norm = 5.4273e-01, time/batch = 0.1431s	
2445/2700 (epoch 45.278), train_loss = 1.45555479, grad/param norm = 5.3755e-01, time/batch = 0.1520s	
2446/2700 (epoch 45.296), train_loss = 1.40418301, grad/param norm = 5.1577e-01, time/batch = 0.1507s	
2447/2700 (epoch 45.315), train_loss = 1.37265393, grad/param norm = 4.8011e-01, time/batch = 0.1525s	
2448/2700 (epoch 45.333), train_loss = 1.38161556, grad/param norm = 5.2954e-01, time/batch = 0.1454s	
2449/2700 (epoch 45.352), train_loss = 1.39202321, grad/param norm = 5.1510e-01, time/batch = 0.1429s	
2450/2700 (epoch 45.370), train_loss = 1.41295330, grad/param norm = 5.8155e-01, time/batch = 0.1528s	
2451/2700 (epoch 45.389), train_loss = 1.39438881, grad/param norm = 5.4000e-01, time/batch = 0.1269s	
2452/2700 (epoch 45.407), train_loss = 1.45086285, grad/param norm = 5.1980e-01, time/batch = 0.1313s	
2453/2700 (epoch 45.426), train_loss = 1.43559988, grad/param norm = 4.6998e-01, time/batch = 0.1361s	
2454/2700 (epoch 45.444), train_loss = 1.38347584, grad/param norm = 4.8481e-01, time/batch = 0.1462s	
2455/2700 (epoch 45.463), train_loss = 1.44444876, grad/param norm = 5.3047e-01, time/batch = 0.1516s	
2456/2700 (epoch 45.481), train_loss = 1.42966004, grad/param norm = 5.0147e-01, time/batch = 0.1514s	
2457/2700 (epoch 45.500), train_loss = 1.40060791, grad/param norm = 5.0461e-01, time/batch = 0.1446s	
2458/2700 (epoch 45.519), train_loss = 1.42789666, grad/param norm = 5.2616e-01, time/batch = 0.1437s	
2459/2700 (epoch 45.537), train_loss = 1.42848107, grad/param norm = 5.1905e-01, time/batch = 0.1505s	
2460/2700 (epoch 45.556), train_loss = 1.35826632, grad/param norm = 5.2576e-01, time/batch = 0.1521s	
2461/2700 (epoch 45.574), train_loss = 1.36398914, grad/param norm = 5.6267e-01, time/batch = 0.1297s	
2462/2700 (epoch 45.593), train_loss = 1.38984515, grad/param norm = 4.9458e-01, time/batch = 0.1314s	
2463/2700 (epoch 45.611), train_loss = 1.30668668, grad/param norm = 4.9738e-01, time/batch = 0.1378s	
2464/2700 (epoch 45.630), train_loss = 1.34085486, grad/param norm = 5.1653e-01, time/batch = 0.1467s	
2465/2700 (epoch 45.648), train_loss = 1.39069073, grad/param norm = 4.4804e-01, time/batch = 0.1511s	
2466/2700 (epoch 45.667), train_loss = 1.33395802, grad/param norm = 5.2081e-01, time/batch = 0.1491s	
2467/2700 (epoch 45.685), train_loss = 1.38019391, grad/param norm = 4.9775e-01, time/batch = 0.1433s	
2468/2700 (epoch 45.704), train_loss = 1.40598608, grad/param norm = 4.9580e-01, time/batch = 0.1520s	
2469/2700 (epoch 45.722), train_loss = 1.38177478, grad/param norm = 4.8446e-01, time/batch = 0.1513s	
2470/2700 (epoch 45.741), train_loss = 1.40326504, grad/param norm = 4.9716e-01, time/batch = 0.1515s	
2471/2700 (epoch 45.759), train_loss = 1.38056742, grad/param norm = 5.0004e-01, time/batch = 0.1274s	
2472/2700 (epoch 45.778), train_loss = 1.41739014, grad/param norm = 5.1076e-01, time/batch = 0.1313s	
2473/2700 (epoch 45.796), train_loss = 1.36311330, grad/param norm = 5.3737e-01, time/batch = 0.1377s	
2474/2700 (epoch 45.815), train_loss = 1.41419922, grad/param norm = 5.3641e-01, time/batch = 0.1493s	
2475/2700 (epoch 45.833), train_loss = 1.37526359, grad/param norm = 5.4309e-01, time/batch = 0.1512s	
2476/2700 (epoch 45.852), train_loss = 1.38435861, grad/param norm = 5.2903e-01, time/batch = 0.1429s	
2477/2700 (epoch 45.870), train_loss = 1.40298797, grad/param norm = 4.9400e-01, time/batch = 0.1509s	
2478/2700 (epoch 45.889), train_loss = 1.40353786, grad/param norm = 5.2702e-01, time/batch = 0.1526s	
2479/2700 (epoch 45.907), train_loss = 1.50243299, grad/param norm = 6.0061e-01, time/batch = 0.1516s	
2480/2700 (epoch 45.926), train_loss = 1.41641755, grad/param norm = 5.6633e-01, time/batch = 0.1499s	
2481/2700 (epoch 45.944), train_loss = 1.41963976, grad/param norm = 5.2693e-01, time/batch = 0.1416s	
2482/2700 (epoch 45.963), train_loss = 1.42443523, grad/param norm = 5.0109e-01, time/batch = 0.1487s	
2483/2700 (epoch 45.981), train_loss = 1.40325446, grad/param norm = 5.1620e-01, time/batch = 0.1521s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
2484/2700 (epoch 46.000), train_loss = 1.46266623, grad/param norm = 5.0665e-01, time/batch = 0.1503s	
2485/2700 (epoch 46.019), train_loss = 1.48349961, grad/param norm = 4.9985e-01, time/batch = 0.1213s	
2486/2700 (epoch 46.037), train_loss = 1.46621110, grad/param norm = 5.3591e-01, time/batch = 0.1240s	
2487/2700 (epoch 46.056), train_loss = 1.37562483, grad/param norm = 5.1452e-01, time/batch = 0.1103s	
2488/2700 (epoch 46.074), train_loss = 1.38642447, grad/param norm = 5.1898e-01, time/batch = 0.0919s	
2489/2700 (epoch 46.093), train_loss = 1.38951351, grad/param norm = 5.2550e-01, time/batch = 0.0928s	
2490/2700 (epoch 46.111), train_loss = 1.33250500, grad/param norm = 4.9819e-01, time/batch = 0.0928s	
2491/2700 (epoch 46.130), train_loss = 1.41057194, grad/param norm = 5.4261e-01, time/batch = 0.0935s	
2492/2700 (epoch 46.148), train_loss = 1.34389743, grad/param norm = 5.1278e-01, time/batch = 0.0919s	
2493/2700 (epoch 46.167), train_loss = 1.41932693, grad/param norm = 5.2183e-01, time/batch = 0.0926s	
2494/2700 (epoch 46.185), train_loss = 1.34230235, grad/param norm = 4.6804e-01, time/batch = 0.0877s	
2495/2700 (epoch 46.204), train_loss = 1.40812107, grad/param norm = 5.1947e-01, time/batch = 0.0907s	
2496/2700 (epoch 46.222), train_loss = 1.34871474, grad/param norm = 5.4779e-01, time/batch = 0.0916s	
2497/2700 (epoch 46.241), train_loss = 1.30410087, grad/param norm = 5.4026e-01, time/batch = 0.0933s	
2498/2700 (epoch 46.259), train_loss = 1.35518907, grad/param norm = 5.4300e-01, time/batch = 0.0927s	
2499/2700 (epoch 46.278), train_loss = 1.44857800, grad/param norm = 5.3681e-01, time/batch = 0.0927s	
2500/2700 (epoch 46.296), train_loss = 1.39746645, grad/param norm = 5.2150e-01, time/batch = 0.0915s	
2501/2700 (epoch 46.315), train_loss = 1.36541362, grad/param norm = 4.8482e-01, time/batch = 0.0870s	
2502/2700 (epoch 46.333), train_loss = 1.37449449, grad/param norm = 5.3226e-01, time/batch = 0.0858s	
2503/2700 (epoch 46.352), train_loss = 1.38438734, grad/param norm = 5.1285e-01, time/batch = 0.0909s	
2504/2700 (epoch 46.370), train_loss = 1.40556324, grad/param norm = 5.9696e-01, time/batch = 0.0857s	
2505/2700 (epoch 46.389), train_loss = 1.38681115, grad/param norm = 5.4630e-01, time/batch = 0.0891s	
2506/2700 (epoch 46.407), train_loss = 1.44340618, grad/param norm = 5.2075e-01, time/batch = 0.0927s	
2507/2700 (epoch 46.426), train_loss = 1.42784721, grad/param norm = 4.6787e-01, time/batch = 0.0921s	
2508/2700 (epoch 46.444), train_loss = 1.37709476, grad/param norm = 4.8823e-01, time/batch = 0.0925s	
2509/2700 (epoch 46.463), train_loss = 1.43687486, grad/param norm = 5.2726e-01, time/batch = 0.0927s	
2510/2700 (epoch 46.481), train_loss = 1.42206498, grad/param norm = 5.0507e-01, time/batch = 0.0926s	
2511/2700 (epoch 46.500), train_loss = 1.39345468, grad/param norm = 5.1251e-01, time/batch = 0.0829s	
2512/2700 (epoch 46.519), train_loss = 1.42048965, grad/param norm = 5.2395e-01, time/batch = 0.0860s	
2513/2700 (epoch 46.537), train_loss = 1.42158062, grad/param norm = 5.1409e-01, time/batch = 0.0682s	
2514/2700 (epoch 46.556), train_loss = 1.35106548, grad/param norm = 5.2020e-01, time/batch = 0.0921s	
2515/2700 (epoch 46.574), train_loss = 1.35790192, grad/param norm = 5.7972e-01, time/batch = 0.0917s	
2516/2700 (epoch 46.593), train_loss = 1.38350931, grad/param norm = 4.9685e-01, time/batch = 0.0891s	
2517/2700 (epoch 46.611), train_loss = 1.30065734, grad/param norm = 4.8774e-01, time/batch = 0.0832s	
2518/2700 (epoch 46.630), train_loss = 1.33418476, grad/param norm = 5.1676e-01, time/batch = 0.0861s	
2519/2700 (epoch 46.648), train_loss = 1.38473471, grad/param norm = 4.5619e-01, time/batch = 0.0858s	
2520/2700 (epoch 46.667), train_loss = 1.32763345, grad/param norm = 5.3058e-01, time/batch = 0.0928s	
2521/2700 (epoch 46.685), train_loss = 1.37367214, grad/param norm = 5.0533e-01, time/batch = 0.0837s	
2522/2700 (epoch 46.704), train_loss = 1.39863494, grad/param norm = 4.9732e-01, time/batch = 0.0575s	
2523/2700 (epoch 46.722), train_loss = 1.37528343, grad/param norm = 4.8829e-01, time/batch = 0.0916s	
2524/2700 (epoch 46.741), train_loss = 1.39612077, grad/param norm = 4.9694e-01, time/batch = 0.0931s	
2525/2700 (epoch 46.759), train_loss = 1.37300712, grad/param norm = 4.9345e-01, time/batch = 0.0923s	
2526/2700 (epoch 46.778), train_loss = 1.41027487, grad/param norm = 5.2109e-01, time/batch = 0.0973s	
2527/2700 (epoch 46.796), train_loss = 1.35618641, grad/param norm = 5.4279e-01, time/batch = 0.0918s	
2528/2700 (epoch 46.815), train_loss = 1.40702142, grad/param norm = 5.4418e-01, time/batch = 0.0922s	
2529/2700 (epoch 46.833), train_loss = 1.36762055, grad/param norm = 5.4083e-01, time/batch = 0.0916s	
2530/2700 (epoch 46.852), train_loss = 1.37728924, grad/param norm = 5.3190e-01, time/batch = 0.0924s	
2531/2700 (epoch 46.870), train_loss = 1.39648398, grad/param norm = 4.9344e-01, time/batch = 0.0897s	
2532/2700 (epoch 46.889), train_loss = 1.39654316, grad/param norm = 5.1660e-01, time/batch = 0.0886s	
2533/2700 (epoch 46.907), train_loss = 1.49368608, grad/param norm = 5.7594e-01, time/batch = 0.0930s	
2534/2700 (epoch 46.926), train_loss = 1.40811076, grad/param norm = 5.4299e-01, time/batch = 0.0924s	
2535/2700 (epoch 46.944), train_loss = 1.41221541, grad/param norm = 5.2056e-01, time/batch = 0.0930s	
2536/2700 (epoch 46.963), train_loss = 1.41700360, grad/param norm = 5.0751e-01, time/batch = 0.0925s	
2537/2700 (epoch 46.981), train_loss = 1.39587723, grad/param norm = 5.1532e-01, time/batch = 0.0916s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
2538/2700 (epoch 47.000), train_loss = 1.45492164, grad/param norm = 5.0455e-01, time/batch = 0.0915s	
2539/2700 (epoch 47.019), train_loss = 1.47756394, grad/param norm = 5.0151e-01, time/batch = 0.0929s	
2540/2700 (epoch 47.037), train_loss = 1.45969374, grad/param norm = 5.4118e-01, time/batch = 0.0923s	
2541/2700 (epoch 47.056), train_loss = 1.36960879, grad/param norm = 5.1573e-01, time/batch = 0.0575s	
2542/2700 (epoch 47.074), train_loss = 1.37939037, grad/param norm = 5.2187e-01, time/batch = 0.0914s	
2543/2700 (epoch 47.093), train_loss = 1.38274170, grad/param norm = 5.2845e-01, time/batch = 0.0925s	
2544/2700 (epoch 47.111), train_loss = 1.32578695, grad/param norm = 4.9156e-01, time/batch = 0.0930s	
2545/2700 (epoch 47.130), train_loss = 1.40408360, grad/param norm = 5.5221e-01, time/batch = 0.0917s	
2546/2700 (epoch 47.148), train_loss = 1.33746675, grad/param norm = 5.1382e-01, time/batch = 0.0914s	
2547/2700 (epoch 47.167), train_loss = 1.41218811, grad/param norm = 5.2365e-01, time/batch = 0.0924s	
2548/2700 (epoch 47.185), train_loss = 1.33582924, grad/param norm = 4.6862e-01, time/batch = 0.0924s	
2549/2700 (epoch 47.204), train_loss = 1.40090587, grad/param norm = 5.2251e-01, time/batch = 0.0924s	
2550/2700 (epoch 47.222), train_loss = 1.34196892, grad/param norm = 5.4974e-01, time/batch = 0.0915s	
2551/2700 (epoch 47.241), train_loss = 1.29825329, grad/param norm = 5.3645e-01, time/batch = 0.0634s	
2552/2700 (epoch 47.259), train_loss = 1.34895215, grad/param norm = 5.4221e-01, time/batch = 0.0928s	
2553/2700 (epoch 47.278), train_loss = 1.44173702, grad/param norm = 5.3573e-01, time/batch = 0.0921s	
2554/2700 (epoch 47.296), train_loss = 1.39100247, grad/param norm = 5.2570e-01, time/batch = 0.0915s	
2555/2700 (epoch 47.315), train_loss = 1.35832520, grad/param norm = 4.9035e-01, time/batch = 0.0923s	
2556/2700 (epoch 47.333), train_loss = 1.36762554, grad/param norm = 5.3708e-01, time/batch = 0.0922s	
2557/2700 (epoch 47.352), train_loss = 1.37701171, grad/param norm = 5.1334e-01, time/batch = 0.0921s	
2558/2700 (epoch 47.370), train_loss = 1.39826288, grad/param norm = 6.0286e-01, time/batch = 0.0914s	
2559/2700 (epoch 47.389), train_loss = 1.37927940, grad/param norm = 5.4248e-01, time/batch = 0.0924s	
2560/2700 (epoch 47.407), train_loss = 1.43612278, grad/param norm = 5.2363e-01, time/batch = 0.0858s	
2561/2700 (epoch 47.426), train_loss = 1.42052780, grad/param norm = 4.7136e-01, time/batch = 0.0862s	
2562/2700 (epoch 47.444), train_loss = 1.37092849, grad/param norm = 4.9048e-01, time/batch = 0.0914s	
2563/2700 (epoch 47.463), train_loss = 1.42955446, grad/param norm = 5.2370e-01, time/batch = 0.0930s	
2564/2700 (epoch 47.481), train_loss = 1.41480344, grad/param norm = 5.0976e-01, time/batch = 0.0916s	
2565/2700 (epoch 47.500), train_loss = 1.38643529, grad/param norm = 5.1816e-01, time/batch = 0.0915s	
2566/2700 (epoch 47.519), train_loss = 1.41342148, grad/param norm = 5.2558e-01, time/batch = 0.0922s	
2567/2700 (epoch 47.537), train_loss = 1.41502311, grad/param norm = 5.1663e-01, time/batch = 0.0932s	
2568/2700 (epoch 47.556), train_loss = 1.34415352, grad/param norm = 5.2089e-01, time/batch = 0.0920s	
2569/2700 (epoch 47.574), train_loss = 1.35185822, grad/param norm = 5.8815e-01, time/batch = 0.0916s	
2570/2700 (epoch 47.593), train_loss = 1.37754316, grad/param norm = 5.0026e-01, time/batch = 0.0830s	
2571/2700 (epoch 47.611), train_loss = 1.29501978, grad/param norm = 4.8822e-01, time/batch = 0.0843s	
2572/2700 (epoch 47.630), train_loss = 1.32781876, grad/param norm = 5.1946e-01, time/batch = 0.0833s	
2573/2700 (epoch 47.648), train_loss = 1.37884220, grad/param norm = 4.5845e-01, time/batch = 0.0856s	
2574/2700 (epoch 47.667), train_loss = 1.32128616, grad/param norm = 5.3238e-01, time/batch = 0.0914s	
2575/2700 (epoch 47.685), train_loss = 1.36725435, grad/param norm = 5.0571e-01, time/batch = 0.0918s	
2576/2700 (epoch 47.704), train_loss = 1.39144562, grad/param norm = 4.9807e-01, time/batch = 0.0924s	
2577/2700 (epoch 47.722), train_loss = 1.36875585, grad/param norm = 4.8975e-01, time/batch = 0.0915s	
2578/2700 (epoch 47.741), train_loss = 1.38924016, grad/param norm = 4.9877e-01, time/batch = 0.0924s	
2579/2700 (epoch 47.759), train_loss = 1.36608797, grad/param norm = 4.9476e-01, time/batch = 0.0858s	
2580/2700 (epoch 47.778), train_loss = 1.40329017, grad/param norm = 5.2444e-01, time/batch = 0.0883s	
2581/2700 (epoch 47.796), train_loss = 1.34928889, grad/param norm = 5.3584e-01, time/batch = 0.0841s	
2582/2700 (epoch 47.815), train_loss = 1.40002123, grad/param norm = 5.5317e-01, time/batch = 0.0832s	
2583/2700 (epoch 47.833), train_loss = 1.36032696, grad/param norm = 5.4094e-01, time/batch = 0.0857s	
2584/2700 (epoch 47.852), train_loss = 1.37064472, grad/param norm = 5.3941e-01, time/batch = 0.0919s	
2585/2700 (epoch 47.870), train_loss = 1.39018956, grad/param norm = 4.9595e-01, time/batch = 0.0933s	
2586/2700 (epoch 47.889), train_loss = 1.38991494, grad/param norm = 5.1863e-01, time/batch = 0.0918s	
2587/2700 (epoch 47.907), train_loss = 1.48576570, grad/param norm = 5.7090e-01, time/batch = 0.0932s	
2588/2700 (epoch 47.926), train_loss = 1.40079652, grad/param norm = 5.4011e-01, time/batch = 0.0872s	
2589/2700 (epoch 47.944), train_loss = 1.40509206, grad/param norm = 5.2132e-01, time/batch = 0.0894s	
2590/2700 (epoch 47.963), train_loss = 1.40964112, grad/param norm = 5.1057e-01, time/batch = 0.0925s	
2591/2700 (epoch 47.981), train_loss = 1.38866264, grad/param norm = 5.1420e-01, time/batch = 0.0841s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
2592/2700 (epoch 48.000), train_loss = 1.44743224, grad/param norm = 5.0248e-01, time/batch = 0.0859s	
2593/2700 (epoch 48.019), train_loss = 1.47172614, grad/param norm = 4.9964e-01, time/batch = 0.0868s	
2594/2700 (epoch 48.037), train_loss = 1.45331665, grad/param norm = 5.4403e-01, time/batch = 0.0942s	
2595/2700 (epoch 48.056), train_loss = 1.36385196, grad/param norm = 5.1927e-01, time/batch = 0.0923s	
2596/2700 (epoch 48.074), train_loss = 1.37261784, grad/param norm = 5.2850e-01, time/batch = 0.0923s	
2597/2700 (epoch 48.093), train_loss = 1.37606150, grad/param norm = 5.2883e-01, time/batch = 0.0882s	
2598/2700 (epoch 48.111), train_loss = 1.31936261, grad/param norm = 4.8550e-01, time/batch = 0.0881s	
2599/2700 (epoch 48.130), train_loss = 1.39786869, grad/param norm = 5.6372e-01, time/batch = 0.0919s	
2600/2700 (epoch 48.148), train_loss = 1.33119061, grad/param norm = 5.1236e-01, time/batch = 0.0928s	
2601/2700 (epoch 48.167), train_loss = 1.40511665, grad/param norm = 5.2206e-01, time/batch = 0.0823s	
2602/2700 (epoch 48.185), train_loss = 1.32958681, grad/param norm = 4.6932e-01, time/batch = 0.0859s	
2603/2700 (epoch 48.204), train_loss = 1.39386572, grad/param norm = 5.2591e-01, time/batch = 0.0854s	
2604/2700 (epoch 48.222), train_loss = 1.33560057, grad/param norm = 5.5881e-01, time/batch = 0.0934s	
2605/2700 (epoch 48.241), train_loss = 1.29269867, grad/param norm = 5.3691e-01, time/batch = 0.0922s	
2606/2700 (epoch 48.259), train_loss = 1.34291603, grad/param norm = 5.4177e-01, time/batch = 0.0884s	
2607/2700 (epoch 48.278), train_loss = 1.43509709, grad/param norm = 5.3507e-01, time/batch = 0.0854s	
2608/2700 (epoch 48.296), train_loss = 1.38471937, grad/param norm = 5.3021e-01, time/batch = 0.0937s	
2609/2700 (epoch 48.315), train_loss = 1.35144710, grad/param norm = 4.9588e-01, time/batch = 0.0921s	
2610/2700 (epoch 48.333), train_loss = 1.36097730, grad/param norm = 5.3942e-01, time/batch = 0.0914s	
2611/2700 (epoch 48.352), train_loss = 1.36987790, grad/param norm = 5.1314e-01, time/batch = 0.0828s	
2612/2700 (epoch 48.370), train_loss = 1.39141838, grad/param norm = 6.1781e-01, time/batch = 0.0865s	
2613/2700 (epoch 48.389), train_loss = 1.37207736, grad/param norm = 5.4279e-01, time/batch = 0.0856s	
2614/2700 (epoch 48.407), train_loss = 1.42907555, grad/param norm = 5.2832e-01, time/batch = 0.0917s	
2615/2700 (epoch 48.426), train_loss = 1.41357505, grad/param norm = 4.7607e-01, time/batch = 0.0907s	
2616/2700 (epoch 48.444), train_loss = 1.36493914, grad/param norm = 4.9462e-01, time/batch = 0.0865s	
2617/2700 (epoch 48.463), train_loss = 1.42247882, grad/param norm = 5.2199e-01, time/batch = 0.0920s	
2618/2700 (epoch 48.481), train_loss = 1.40792294, grad/param norm = 5.1507e-01, time/batch = 0.0916s	
2619/2700 (epoch 48.500), train_loss = 1.37947630, grad/param norm = 5.1744e-01, time/batch = 0.0919s	
2620/2700 (epoch 48.519), train_loss = 1.40662838, grad/param norm = 5.3070e-01, time/batch = 0.0933s	
2621/2700 (epoch 48.537), train_loss = 1.40874259, grad/param norm = 5.2385e-01, time/batch = 0.0845s	
2622/2700 (epoch 48.556), train_loss = 1.33734756, grad/param norm = 5.2238e-01, time/batch = 0.0857s	
2623/2700 (epoch 48.574), train_loss = 1.34588998, grad/param norm = 5.9082e-01, time/batch = 0.0893s	
2624/2700 (epoch 48.593), train_loss = 1.37185084, grad/param norm = 5.0403e-01, time/batch = 0.0921s	
2625/2700 (epoch 48.611), train_loss = 1.28963728, grad/param norm = 4.8963e-01, time/batch = 0.0947s	
2626/2700 (epoch 48.630), train_loss = 1.32162974, grad/param norm = 5.2253e-01, time/batch = 0.0918s	
2627/2700 (epoch 48.648), train_loss = 1.37312558, grad/param norm = 4.6049e-01, time/batch = 0.0931s	
2628/2700 (epoch 48.667), train_loss = 1.31511916, grad/param norm = 5.3277e-01, time/batch = 0.0933s	
2629/2700 (epoch 48.685), train_loss = 1.36110515, grad/param norm = 5.0573e-01, time/batch = 0.0915s	
2630/2700 (epoch 48.704), train_loss = 1.38447502, grad/param norm = 4.9900e-01, time/batch = 0.0914s	
2631/2700 (epoch 48.722), train_loss = 1.36244466, grad/param norm = 4.9146e-01, time/batch = 0.0865s	
2632/2700 (epoch 48.741), train_loss = 1.38266732, grad/param norm = 5.0106e-01, time/batch = 0.0855s	
2633/2700 (epoch 48.759), train_loss = 1.35945980, grad/param norm = 4.9528e-01, time/batch = 0.0912s	
2634/2700 (epoch 48.778), train_loss = 1.39663845, grad/param norm = 5.2954e-01, time/batch = 0.0857s	
2635/2700 (epoch 48.796), train_loss = 1.34275409, grad/param norm = 5.3156e-01, time/batch = 0.0886s	
2636/2700 (epoch 48.815), train_loss = 1.39324687, grad/param norm = 5.6174e-01, time/batch = 0.0916s	
2637/2700 (epoch 48.833), train_loss = 1.35326965, grad/param norm = 5.4031e-01, time/batch = 0.0923s	
2638/2700 (epoch 48.852), train_loss = 1.36420554, grad/param norm = 5.4620e-01, time/batch = 0.0926s	
2639/2700 (epoch 48.870), train_loss = 1.38404696, grad/param norm = 4.9730e-01, time/batch = 0.0919s	
2640/2700 (epoch 48.889), train_loss = 1.38346236, grad/param norm = 5.1756e-01, time/batch = 0.0915s	
2641/2700 (epoch 48.907), train_loss = 1.47797685, grad/param norm = 5.6207e-01, time/batch = 0.0839s	
2642/2700 (epoch 48.926), train_loss = 1.39364010, grad/param norm = 5.3433e-01, time/batch = 0.0862s	
2643/2700 (epoch 48.944), train_loss = 1.39818626, grad/param norm = 5.2057e-01, time/batch = 0.0747s	
2644/2700 (epoch 48.963), train_loss = 1.40243158, grad/param norm = 5.1427e-01, time/batch = 0.0736s	
2645/2700 (epoch 48.981), train_loss = 1.38173952, grad/param norm = 5.1455e-01, time/batch = 0.0635s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
2646/2700 (epoch 49.000), train_loss = 1.44022229, grad/param norm = 5.0096e-01, time/batch = 0.0598s	
2647/2700 (epoch 49.019), train_loss = 1.46614954, grad/param norm = 4.9954e-01, time/batch = 0.0729s	
2648/2700 (epoch 49.037), train_loss = 1.44716921, grad/param norm = 5.4781e-01, time/batch = 0.0535s	
2649/2700 (epoch 49.056), train_loss = 1.35821185, grad/param norm = 5.2135e-01, time/batch = 0.0529s	
2650/2700 (epoch 49.074), train_loss = 1.36601895, grad/param norm = 5.3299e-01, time/batch = 0.0530s	
2651/2700 (epoch 49.093), train_loss = 1.36963805, grad/param norm = 5.3054e-01, time/batch = 0.0538s	
2652/2700 (epoch 49.111), train_loss = 1.31321179, grad/param norm = 4.8087e-01, time/batch = 0.0541s	
2653/2700 (epoch 49.130), train_loss = 1.39186715, grad/param norm = 5.7342e-01, time/batch = 0.0550s	
2654/2700 (epoch 49.148), train_loss = 1.32515926, grad/param norm = 5.1288e-01, time/batch = 0.0535s	
2655/2700 (epoch 49.167), train_loss = 1.39827288, grad/param norm = 5.2250e-01, time/batch = 0.0543s	
2656/2700 (epoch 49.185), train_loss = 1.32355433, grad/param norm = 4.7094e-01, time/batch = 0.0530s	
2657/2700 (epoch 49.204), train_loss = 1.38705757, grad/param norm = 5.2895e-01, time/batch = 0.0530s	
2658/2700 (epoch 49.222), train_loss = 1.32934243, grad/param norm = 5.6310e-01, time/batch = 0.0529s	
2659/2700 (epoch 49.241), train_loss = 1.28721644, grad/param norm = 5.3269e-01, time/batch = 0.0537s	
2660/2700 (epoch 49.259), train_loss = 1.33704959, grad/param norm = 5.4048e-01, time/batch = 0.0548s	
2661/2700 (epoch 49.278), train_loss = 1.42862239, grad/param norm = 5.3377e-01, time/batch = 0.0541s	
2662/2700 (epoch 49.296), train_loss = 1.37862664, grad/param norm = 5.3470e-01, time/batch = 0.0528s	
2663/2700 (epoch 49.315), train_loss = 1.34474088, grad/param norm = 5.0258e-01, time/batch = 0.0530s	
2664/2700 (epoch 49.333), train_loss = 1.35454090, grad/param norm = 5.4210e-01, time/batch = 0.0546s	
2665/2700 (epoch 49.352), train_loss = 1.36299417, grad/param norm = 5.1459e-01, time/batch = 0.0533s	
2666/2700 (epoch 49.370), train_loss = 1.38467345, grad/param norm = 6.2671e-01, time/batch = 0.0569s	
2667/2700 (epoch 49.389), train_loss = 1.36490522, grad/param norm = 5.3472e-01, time/batch = 0.0540s	
2668/2700 (epoch 49.407), train_loss = 1.42231409, grad/param norm = 5.3933e-01, time/batch = 0.0533s	
2669/2700 (epoch 49.426), train_loss = 1.40701772, grad/param norm = 4.8765e-01, time/batch = 0.0529s	
2670/2700 (epoch 49.444), train_loss = 1.35909649, grad/param norm = 4.9777e-01, time/batch = 0.0529s	
2671/2700 (epoch 49.463), train_loss = 1.41563411, grad/param norm = 5.1981e-01, time/batch = 0.0536s	
2672/2700 (epoch 49.481), train_loss = 1.40131093, grad/param norm = 5.2105e-01, time/batch = 0.0535s	
2673/2700 (epoch 49.500), train_loss = 1.37272113, grad/param norm = 5.1924e-01, time/batch = 0.0548s	
2674/2700 (epoch 49.519), train_loss = 1.40007120, grad/param norm = 5.3400e-01, time/batch = 0.0537s	
2675/2700 (epoch 49.537), train_loss = 1.40256671, grad/param norm = 5.2858e-01, time/batch = 0.0530s	
2676/2700 (epoch 49.556), train_loss = 1.33072750, grad/param norm = 5.2434e-01, time/batch = 0.0529s	
2677/2700 (epoch 49.574), train_loss = 1.34019136, grad/param norm = 5.9524e-01, time/batch = 0.0529s	
2678/2700 (epoch 49.593), train_loss = 1.36638536, grad/param norm = 5.0827e-01, time/batch = 0.0529s	
2679/2700 (epoch 49.611), train_loss = 1.28442919, grad/param norm = 4.8961e-01, time/batch = 0.0537s	
2680/2700 (epoch 49.630), train_loss = 1.31563482, grad/param norm = 5.2594e-01, time/batch = 0.0544s	
2681/2700 (epoch 49.648), train_loss = 1.36760107, grad/param norm = 4.6354e-01, time/batch = 0.0542s	
2682/2700 (epoch 49.667), train_loss = 1.30917772, grad/param norm = 5.3309e-01, time/batch = 0.0527s	
2683/2700 (epoch 49.685), train_loss = 1.35522122, grad/param norm = 5.0648e-01, time/batch = 0.0526s	
2684/2700 (epoch 49.704), train_loss = 1.37772138, grad/param norm = 4.9976e-01, time/batch = 0.0527s	
2685/2700 (epoch 49.722), train_loss = 1.35634336, grad/param norm = 4.9352e-01, time/batch = 0.0529s	
2686/2700 (epoch 49.741), train_loss = 1.37635954, grad/param norm = 5.0346e-01, time/batch = 0.0538s	
2687/2700 (epoch 49.759), train_loss = 1.35310029, grad/param norm = 4.9517e-01, time/batch = 0.0556s	
2688/2700 (epoch 49.778), train_loss = 1.39030322, grad/param norm = 5.3536e-01, time/batch = 0.0537s	
2689/2700 (epoch 49.796), train_loss = 1.33654900, grad/param norm = 5.2875e-01, time/batch = 0.0529s	
2690/2700 (epoch 49.815), train_loss = 1.38666194, grad/param norm = 5.6998e-01, time/batch = 0.0529s	
2691/2700 (epoch 49.833), train_loss = 1.34648583, grad/param norm = 5.3932e-01, time/batch = 0.0536s	
2692/2700 (epoch 49.852), train_loss = 1.35794642, grad/param norm = 5.5220e-01, time/batch = 0.0545s	
2693/2700 (epoch 49.870), train_loss = 1.37806283, grad/param norm = 4.9826e-01, time/batch = 0.0543s	
2694/2700 (epoch 49.889), train_loss = 1.37720268, grad/param norm = 5.1632e-01, time/batch = 0.0542s	
2695/2700 (epoch 49.907), train_loss = 1.47047454, grad/param norm = 5.5472e-01, time/batch = 0.0534s	
2696/2700 (epoch 49.926), train_loss = 1.38678899, grad/param norm = 5.3136e-01, time/batch = 0.0530s	
2697/2700 (epoch 49.944), train_loss = 1.39152074, grad/param norm = 5.2084e-01, time/batch = 0.0529s	
2698/2700 (epoch 49.963), train_loss = 1.39536584, grad/param norm = 5.1707e-01, time/batch = 0.0529s	
2699/2700 (epoch 49.981), train_loss = 1.37502615, grad/param norm = 5.1516e-01, time/batch = 0.0538s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch50.00_1.7357.t7	
2700/2700 (epoch 50.000), train_loss = 1.43328536, grad/param norm = 4.9959e-01, time/batch = 0.0546s	
