using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 54, val: 3, test: 0	
vocab size: 91	
creating an lstm with 3 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
setting forget gate biases to 1 in LSTM layer 3	
number of parameters in the model: 389083	
cloning rnn	
cloning criterion	
1/2700 (epoch 0.019), train_loss = 4.50726858, grad/param norm = 4.9111e-01, time/batch = 0.4488s	
2/2700 (epoch 0.037), train_loss = 4.02619222, grad/param norm = 1.5264e+00, time/batch = 0.1472s	
3/2700 (epoch 0.056), train_loss = 3.42138392, grad/param norm = 9.4699e-01, time/batch = 0.1507s	
4/2700 (epoch 0.074), train_loss = 3.34399490, grad/param norm = 6.8434e-01, time/batch = 0.1508s	
5/2700 (epoch 0.093), train_loss = 3.32447491, grad/param norm = 5.3079e-01, time/batch = 0.1459s	
6/2700 (epoch 0.111), train_loss = 3.28052157, grad/param norm = 3.3573e-01, time/batch = 0.1491s	
7/2700 (epoch 0.130), train_loss = 3.29354316, grad/param norm = 3.1467e-01, time/batch = 0.1485s	
8/2700 (epoch 0.148), train_loss = 3.26137237, grad/param norm = 4.3305e-01, time/batch = 0.1498s	
9/2700 (epoch 0.167), train_loss = 3.26386091, grad/param norm = 4.5093e-01, time/batch = 0.1495s	
10/2700 (epoch 0.185), train_loss = 3.24668370, grad/param norm = 2.8269e-01, time/batch = 0.1482s	
11/2700 (epoch 0.204), train_loss = 3.18223197, grad/param norm = 2.7492e-01, time/batch = 0.1500s	
12/2700 (epoch 0.222), train_loss = 3.15540052, grad/param norm = 4.0109e-01, time/batch = 0.1446s	
13/2700 (epoch 0.241), train_loss = 3.17549927, grad/param norm = 3.1217e-01, time/batch = 0.1448s	
14/2700 (epoch 0.259), train_loss = 3.20559530, grad/param norm = 2.9008e-01, time/batch = 0.1424s	
15/2700 (epoch 0.278), train_loss = 3.27775447, grad/param norm = 3.2239e-01, time/batch = 0.1442s	
16/2700 (epoch 0.296), train_loss = 3.28191073, grad/param norm = 3.5214e-01, time/batch = 0.1447s	
17/2700 (epoch 0.315), train_loss = 3.25542858, grad/param norm = 3.0035e-01, time/batch = 0.1439s	
18/2700 (epoch 0.333), train_loss = 3.33718186, grad/param norm = 2.9830e-01, time/batch = 0.1506s	
19/2700 (epoch 0.352), train_loss = 3.34040339, grad/param norm = 3.4996e-01, time/batch = 0.1496s	
20/2700 (epoch 0.370), train_loss = 3.28450962, grad/param norm = 3.3775e-01, time/batch = 0.1491s	
21/2700 (epoch 0.389), train_loss = 3.25285946, grad/param norm = 2.7105e-01, time/batch = 0.1491s	
22/2700 (epoch 0.407), train_loss = 3.27746776, grad/param norm = 3.0278e-01, time/batch = 0.1441s	
23/2700 (epoch 0.426), train_loss = 3.27924497, grad/param norm = 2.8268e-01, time/batch = 0.1445s	
24/2700 (epoch 0.444), train_loss = 3.21077188, grad/param norm = 2.8423e-01, time/batch = 0.1266s	
25/2700 (epoch 0.463), train_loss = 3.24967535, grad/param norm = 3.7119e-01, time/batch = 0.1506s	
26/2700 (epoch 0.481), train_loss = 3.32709580, grad/param norm = 3.9847e-01, time/batch = 0.1450s	
27/2700 (epoch 0.500), train_loss = 3.36944048, grad/param norm = 4.7856e-01, time/batch = 0.1427s	
28/2700 (epoch 0.519), train_loss = 3.32317864, grad/param norm = 3.6964e-01, time/batch = 0.1481s	
29/2700 (epoch 0.537), train_loss = 3.32562103, grad/param norm = 3.6476e-01, time/batch = 0.1511s	
30/2700 (epoch 0.556), train_loss = 3.26150949, grad/param norm = 2.6563e-01, time/batch = 0.1497s	
31/2700 (epoch 0.574), train_loss = 3.23188904, grad/param norm = 3.1856e-01, time/batch = 0.1485s	
32/2700 (epoch 0.593), train_loss = 3.22948311, grad/param norm = 3.5908e-01, time/batch = 0.1446s	
33/2700 (epoch 0.611), train_loss = 3.17133025, grad/param norm = 2.3011e-01, time/batch = 0.1148s	
34/2700 (epoch 0.630), train_loss = 3.21243803, grad/param norm = 2.8606e-01, time/batch = 0.1490s	
35/2700 (epoch 0.648), train_loss = 3.27888659, grad/param norm = 3.0142e-01, time/batch = 0.1499s	
36/2700 (epoch 0.667), train_loss = 3.21232862, grad/param norm = 2.4712e-01, time/batch = 0.1522s	
37/2700 (epoch 0.685), train_loss = 3.21186651, grad/param norm = 3.1989e-01, time/batch = 0.1447s	
38/2700 (epoch 0.704), train_loss = 3.18313147, grad/param norm = 4.0906e-01, time/batch = 0.1457s	
39/2700 (epoch 0.722), train_loss = 3.17227183, grad/param norm = 2.9600e-01, time/batch = 0.1428s	
40/2700 (epoch 0.741), train_loss = 3.30749807, grad/param norm = 4.4252e-01, time/batch = 0.1509s	
41/2700 (epoch 0.759), train_loss = 3.25469206, grad/param norm = 4.3072e-01, time/batch = 0.1471s	
42/2700 (epoch 0.778), train_loss = 3.24653308, grad/param norm = 3.4932e-01, time/batch = 0.1094s	
43/2700 (epoch 0.796), train_loss = 3.23838036, grad/param norm = 3.3019e-01, time/batch = 0.1506s	
44/2700 (epoch 0.815), train_loss = 3.19105762, grad/param norm = 2.4688e-01, time/batch = 0.1485s	
45/2700 (epoch 0.833), train_loss = 3.22860795, grad/param norm = 2.7110e-01, time/batch = 0.1506s	
46/2700 (epoch 0.852), train_loss = 3.21661044, grad/param norm = 2.8269e-01, time/batch = 0.1490s	
47/2700 (epoch 0.870), train_loss = 3.21016376, grad/param norm = 1.8573e-01, time/batch = 0.1490s	
48/2700 (epoch 0.889), train_loss = 3.24936433, grad/param norm = 2.5555e-01, time/batch = 0.1496s	
49/2700 (epoch 0.907), train_loss = 3.30150797, grad/param norm = 3.7610e-01, time/batch = 0.1503s	
50/2700 (epoch 0.926), train_loss = 3.24970372, grad/param norm = 3.5633e-01, time/batch = 0.1520s	
51/2700 (epoch 0.944), train_loss = 3.25910769, grad/param norm = 3.1768e-01, time/batch = 0.1318s	
52/2700 (epoch 0.963), train_loss = 3.33868289, grad/param norm = 3.0036e-01, time/batch = 0.1506s	
53/2700 (epoch 0.981), train_loss = 3.40049041, grad/param norm = 3.5371e-01, time/batch = 0.1495s	
54/2700 (epoch 1.000), train_loss = 3.29744758, grad/param norm = 3.3127e-01, time/batch = 0.1476s	
55/2700 (epoch 1.019), train_loss = 3.23103497, grad/param norm = 3.7897e-01, time/batch = 0.1494s	
56/2700 (epoch 1.037), train_loss = 3.25178853, grad/param norm = 3.0154e-01, time/batch = 0.1485s	
57/2700 (epoch 1.056), train_loss = 3.25968231, grad/param norm = 2.9787e-01, time/batch = 0.1490s	
58/2700 (epoch 1.074), train_loss = 3.28945564, grad/param norm = 4.1133e-01, time/batch = 0.1501s	
59/2700 (epoch 1.093), train_loss = 3.29270137, grad/param norm = 4.2283e-01, time/batch = 0.1488s	
60/2700 (epoch 1.111), train_loss = 3.26456028, grad/param norm = 3.2092e-01, time/batch = 0.1537s	
61/2700 (epoch 1.130), train_loss = 3.27916708, grad/param norm = 2.8790e-01, time/batch = 0.1509s	
62/2700 (epoch 1.148), train_loss = 3.24362257, grad/param norm = 3.0732e-01, time/batch = 0.1502s	
63/2700 (epoch 1.167), train_loss = 3.25183197, grad/param norm = 3.7851e-01, time/batch = 0.1485s	
64/2700 (epoch 1.185), train_loss = 3.23713160, grad/param norm = 2.3828e-01, time/batch = 0.1491s	
65/2700 (epoch 1.204), train_loss = 3.17426843, grad/param norm = 2.8130e-01, time/batch = 0.1495s	
66/2700 (epoch 1.222), train_loss = 3.14851183, grad/param norm = 3.9863e-01, time/batch = 0.1480s	
67/2700 (epoch 1.241), train_loss = 3.16829910, grad/param norm = 3.0654e-01, time/batch = 0.1508s	
68/2700 (epoch 1.259), train_loss = 3.20142598, grad/param norm = 3.1856e-01, time/batch = 0.1640s	
69/2700 (epoch 1.278), train_loss = 3.27480490, grad/param norm = 3.2283e-01, time/batch = 0.2001s	
70/2700 (epoch 1.296), train_loss = 3.27732606, grad/param norm = 3.4442e-01, time/batch = 0.2036s	
71/2700 (epoch 1.315), train_loss = 3.25338549, grad/param norm = 3.3778e-01, time/batch = 0.1484s	
72/2700 (epoch 1.333), train_loss = 3.33524006, grad/param norm = 3.4533e-01, time/batch = 0.1485s	
73/2700 (epoch 1.352), train_loss = 3.33829368, grad/param norm = 3.8349e-01, time/batch = 0.1520s	
74/2700 (epoch 1.370), train_loss = 3.28245016, grad/param norm = 2.9763e-01, time/batch = 0.1566s	
75/2700 (epoch 1.389), train_loss = 3.25083613, grad/param norm = 2.2458e-01, time/batch = 0.1570s	
76/2700 (epoch 1.407), train_loss = 3.27246836, grad/param norm = 2.4165e-01, time/batch = 0.1549s	
77/2700 (epoch 1.426), train_loss = 3.27425190, grad/param norm = 2.4181e-01, time/batch = 0.1568s	
78/2700 (epoch 1.444), train_loss = 3.20749290, grad/param norm = 2.4510e-01, time/batch = 0.1584s	
79/2700 (epoch 1.463), train_loss = 3.24862484, grad/param norm = 3.7758e-01, time/batch = 0.1501s	
80/2700 (epoch 1.481), train_loss = 3.32615509, grad/param norm = 3.8867e-01, time/batch = 0.1137s	
81/2700 (epoch 1.500), train_loss = 3.36649203, grad/param norm = 4.4501e-01, time/batch = 0.1370s	
82/2700 (epoch 1.519), train_loss = 3.32276818, grad/param norm = 3.7560e-01, time/batch = 0.1387s	
83/2700 (epoch 1.537), train_loss = 3.32406981, grad/param norm = 3.8589e-01, time/batch = 0.1442s	
84/2700 (epoch 1.556), train_loss = 3.26004233, grad/param norm = 2.8008e-01, time/batch = 0.1478s	
85/2700 (epoch 1.574), train_loss = 3.22994186, grad/param norm = 3.1084e-01, time/batch = 0.1471s	
86/2700 (epoch 1.593), train_loss = 3.22671443, grad/param norm = 3.2875e-01, time/batch = 0.1484s	
87/2700 (epoch 1.611), train_loss = 3.16895141, grad/param norm = 2.0498e-01, time/batch = 0.1475s	
88/2700 (epoch 1.630), train_loss = 3.21066556, grad/param norm = 2.6482e-01, time/batch = 0.1491s	
89/2700 (epoch 1.648), train_loss = 3.27692634, grad/param norm = 2.7346e-01, time/batch = 0.1484s	
90/2700 (epoch 1.667), train_loss = 3.21047091, grad/param norm = 2.0403e-01, time/batch = 0.1484s	
91/2700 (epoch 1.685), train_loss = 3.20935244, grad/param norm = 2.6487e-01, time/batch = 0.1491s	
92/2700 (epoch 1.704), train_loss = 3.18110872, grad/param norm = 3.4241e-01, time/batch = 0.1471s	
93/2700 (epoch 1.722), train_loss = 3.17111875, grad/param norm = 2.2555e-01, time/batch = 0.1486s	
94/2700 (epoch 1.741), train_loss = 3.30535473, grad/param norm = 3.3044e-01, time/batch = 0.1473s	
95/2700 (epoch 1.759), train_loss = 3.25602560, grad/param norm = 4.0460e-01, time/batch = 0.1483s	
96/2700 (epoch 1.778), train_loss = 3.24592094, grad/param norm = 3.5888e-01, time/batch = 0.1488s	
97/2700 (epoch 1.796), train_loss = 3.23662128, grad/param norm = 3.0214e-01, time/batch = 0.1486s	
98/2700 (epoch 1.815), train_loss = 3.18920918, grad/param norm = 2.1048e-01, time/batch = 0.1497s	
99/2700 (epoch 1.833), train_loss = 3.22659846, grad/param norm = 2.3461e-01, time/batch = 0.1486s	
100/2700 (epoch 1.852), train_loss = 3.21380082, grad/param norm = 2.4462e-01, time/batch = 0.1495s	
101/2700 (epoch 1.870), train_loss = 3.20801485, grad/param norm = 1.6124e-01, time/batch = 0.1537s	
102/2700 (epoch 1.889), train_loss = 3.24583640, grad/param norm = 2.2934e-01, time/batch = 0.1561s	
103/2700 (epoch 1.907), train_loss = 3.29158821, grad/param norm = 2.9815e-01, time/batch = 0.1680s	
104/2700 (epoch 1.926), train_loss = 3.25924358, grad/param norm = 3.2104e-01, time/batch = 0.1762s	
105/2700 (epoch 1.944), train_loss = 3.26290092, grad/param norm = 3.3801e-01, time/batch = 0.2079s	
106/2700 (epoch 1.963), train_loss = 3.34080244, grad/param norm = 2.9662e-01, time/batch = 0.1879s	
107/2700 (epoch 1.981), train_loss = 3.39759918, grad/param norm = 3.0362e-01, time/batch = 0.2143s	
108/2700 (epoch 2.000), train_loss = 3.29960605, grad/param norm = 3.0117e-01, time/batch = 0.2340s	
109/2700 (epoch 2.019), train_loss = 3.23388547, grad/param norm = 3.7784e-01, time/batch = 0.2109s	
110/2700 (epoch 2.037), train_loss = 3.25122809, grad/param norm = 2.8918e-01, time/batch = 0.1966s	
111/2700 (epoch 2.056), train_loss = 3.25603897, grad/param norm = 2.2380e-01, time/batch = 0.2084s	
112/2700 (epoch 2.074), train_loss = 3.28329786, grad/param norm = 2.5076e-01, time/batch = 0.2356s	
113/2700 (epoch 2.093), train_loss = 3.28676465, grad/param norm = 2.6286e-01, time/batch = 0.2002s	
114/2700 (epoch 2.111), train_loss = 3.26012589, grad/param norm = 2.2697e-01, time/batch = 0.2000s	
115/2700 (epoch 2.130), train_loss = 3.27447643, grad/param norm = 2.5697e-01, time/batch = 0.2284s	
116/2700 (epoch 2.148), train_loss = 3.24409719, grad/param norm = 3.4335e-01, time/batch = 0.2348s	
117/2700 (epoch 2.167), train_loss = 3.25259903, grad/param norm = 4.7114e-01, time/batch = 0.1816s	
118/2700 (epoch 2.185), train_loss = 3.23729641, grad/param norm = 3.4954e-01, time/batch = 0.2018s	
119/2700 (epoch 2.204), train_loss = 3.17015869, grad/param norm = 2.3742e-01, time/batch = 0.2010s	
120/2700 (epoch 2.222), train_loss = 3.14542939, grad/param norm = 3.3487e-01, time/batch = 0.2048s	
121/2700 (epoch 2.241), train_loss = 3.16303103, grad/param norm = 2.1279e-01, time/batch = 0.2113s	
122/2700 (epoch 2.259), train_loss = 3.19695013, grad/param norm = 2.1815e-01, time/batch = 0.2354s	
123/2700 (epoch 2.278), train_loss = 3.26716094, grad/param norm = 2.5657e-01, time/batch = 0.2062s	
124/2700 (epoch 2.296), train_loss = 3.26875101, grad/param norm = 3.0419e-01, time/batch = 0.2022s	
125/2700 (epoch 2.315), train_loss = 3.25569563, grad/param norm = 4.1151e-01, time/batch = 0.2217s	
126/2700 (epoch 2.333), train_loss = 3.32496583, grad/param norm = 3.0186e-01, time/batch = 0.2350s	
127/2700 (epoch 2.352), train_loss = 3.31685415, grad/param norm = 2.5263e-01, time/batch = 0.1829s	
128/2700 (epoch 2.370), train_loss = 3.26542531, grad/param norm = 2.6302e-01, time/batch = 0.2429s	
129/2700 (epoch 2.389), train_loss = 3.39001314, grad/param norm = 5.6617e-01, time/batch = 0.2842s	
130/2700 (epoch 2.407), train_loss = 3.27881761, grad/param norm = 4.7652e-01, time/batch = 0.2901s	
131/2700 (epoch 2.426), train_loss = 3.26961230, grad/param norm = 2.5031e-01, time/batch = 0.2585s	
132/2700 (epoch 2.444), train_loss = 3.19859072, grad/param norm = 1.8604e-01, time/batch = 0.2662s	
133/2700 (epoch 2.463), train_loss = 3.23515568, grad/param norm = 2.2145e-01, time/batch = 0.2588s	
134/2700 (epoch 2.481), train_loss = 3.31186118, grad/param norm = 2.2371e-01, time/batch = 0.2501s	
135/2700 (epoch 2.500), train_loss = 3.34305117, grad/param norm = 2.5363e-01, time/batch = 0.2577s	
136/2700 (epoch 2.519), train_loss = 3.59316217, grad/param norm = 1.4965e+00, time/batch = 0.2639s	
137/2700 (epoch 2.537), train_loss = 3.34049417, grad/param norm = 4.6464e-01, time/batch = 0.2566s	
138/2700 (epoch 2.556), train_loss = 3.24887491, grad/param norm = 1.6636e-01, time/batch = 0.2583s	
139/2700 (epoch 2.574), train_loss = 3.22101657, grad/param norm = 2.3065e-01, time/batch = 0.2603s	
140/2700 (epoch 2.593), train_loss = 3.21699381, grad/param norm = 2.4580e-01, time/batch = 0.2686s	
141/2700 (epoch 2.611), train_loss = 3.16227772, grad/param norm = 1.5991e-01, time/batch = 0.2431s	
142/2700 (epoch 2.630), train_loss = 3.20271271, grad/param norm = 2.0858e-01, time/batch = 0.2437s	
143/2700 (epoch 2.648), train_loss = 3.26575999, grad/param norm = 2.3488e-01, time/batch = 0.2548s	
144/2700 (epoch 2.667), train_loss = 3.20288062, grad/param norm = 1.9408e-01, time/batch = 0.2439s	
145/2700 (epoch 2.685), train_loss = 3.20092452, grad/param norm = 2.4727e-01, time/batch = 0.2528s	
146/2700 (epoch 2.704), train_loss = 3.17374452, grad/param norm = 2.8419e-01, time/batch = 0.2862s	
147/2700 (epoch 2.722), train_loss = 3.16312970, grad/param norm = 1.7592e-01, time/batch = 0.3039s	
148/2700 (epoch 2.741), train_loss = 3.29276650, grad/param norm = 2.5911e-01, time/batch = 0.3060s	
149/2700 (epoch 2.759), train_loss = 3.24920995, grad/param norm = 3.4216e-01, time/batch = 0.3099s	
150/2700 (epoch 2.778), train_loss = 3.23707220, grad/param norm = 3.3880e-01, time/batch = 0.3139s	
151/2700 (epoch 2.796), train_loss = 3.22168577, grad/param norm = 2.3542e-01, time/batch = 0.3472s	
152/2700 (epoch 2.815), train_loss = 3.17847384, grad/param norm = 1.5555e-01, time/batch = 0.3324s	
153/2700 (epoch 2.833), train_loss = 3.21126312, grad/param norm = 1.7912e-01, time/batch = 0.3147s	
154/2700 (epoch 2.852), train_loss = 3.19844320, grad/param norm = 1.8717e-01, time/batch = 0.3293s	
155/2700 (epoch 2.870), train_loss = 3.19602082, grad/param norm = 1.1565e-01, time/batch = 0.3082s	
156/2700 (epoch 2.889), train_loss = 3.23045844, grad/param norm = 1.9492e-01, time/batch = 0.3100s	
157/2700 (epoch 2.907), train_loss = 3.28227119, grad/param norm = 2.7716e-01, time/batch = 0.3077s	
158/2700 (epoch 2.926), train_loss = 3.23225868, grad/param norm = 2.6796e-01, time/batch = 0.3146s	
159/2700 (epoch 2.944), train_loss = 3.22924710, grad/param norm = 2.7096e-01, time/batch = 0.3251s	
160/2700 (epoch 2.963), train_loss = 3.30638992, grad/param norm = 2.1801e-01, time/batch = 0.3280s	
161/2700 (epoch 2.981), train_loss = 3.36717131, grad/param norm = 3.8519e-01, time/batch = 0.3231s	
162/2700 (epoch 3.000), train_loss = 3.28966466, grad/param norm = 4.7315e-01, time/batch = 0.3069s	
163/2700 (epoch 3.019), train_loss = 3.22047025, grad/param norm = 3.5370e-01, time/batch = 0.3148s	
164/2700 (epoch 3.037), train_loss = 3.22835647, grad/param norm = 2.3044e-01, time/batch = 0.3046s	
165/2700 (epoch 3.056), train_loss = 3.23453442, grad/param norm = 2.7721e-01, time/batch = 0.3161s	
166/2700 (epoch 3.074), train_loss = 3.25025756, grad/param norm = 2.8543e-01, time/batch = 0.3186s	
167/2700 (epoch 3.093), train_loss = 3.26274741, grad/param norm = 2.4189e-01, time/batch = 0.3113s	
168/2700 (epoch 3.111), train_loss = 3.23875978, grad/param norm = 2.0394e-01, time/batch = 0.3126s	
169/2700 (epoch 3.130), train_loss = 3.25102333, grad/param norm = 2.5420e-01, time/batch = 0.3154s	
170/2700 (epoch 3.148), train_loss = 3.22319872, grad/param norm = 2.7826e-01, time/batch = 0.3188s	
171/2700 (epoch 3.167), train_loss = 3.23092490, grad/param norm = 3.3440e-01, time/batch = 0.3187s	
172/2700 (epoch 3.185), train_loss = 3.21909021, grad/param norm = 2.9169e-01, time/batch = 0.3167s	
173/2700 (epoch 3.204), train_loss = 3.15229877, grad/param norm = 3.0844e-01, time/batch = 0.3030s	
174/2700 (epoch 3.222), train_loss = 3.12241342, grad/param norm = 3.1537e-01, time/batch = 0.3146s	
175/2700 (epoch 3.241), train_loss = 3.13341511, grad/param norm = 2.6465e-01, time/batch = 0.2953s	
176/2700 (epoch 3.259), train_loss = 3.16973995, grad/param norm = 2.2509e-01, time/batch = 0.3303s	
177/2700 (epoch 3.278), train_loss = 3.22452955, grad/param norm = 2.3553e-01, time/batch = 0.3268s	
178/2700 (epoch 3.296), train_loss = 3.22312500, grad/param norm = 2.3717e-01, time/batch = 0.3177s	
179/2700 (epoch 3.315), train_loss = 3.22906272, grad/param norm = 3.4406e-01, time/batch = 0.3087s	
180/2700 (epoch 3.333), train_loss = 3.32555300, grad/param norm = 4.7772e-01, time/batch = 0.3130s	
181/2700 (epoch 3.352), train_loss = 3.30394876, grad/param norm = 3.5255e-01, time/batch = 0.3258s	
182/2700 (epoch 3.370), train_loss = 3.24809011, grad/param norm = 1.7026e-01, time/batch = 0.3145s	
183/2700 (epoch 3.389), train_loss = 3.21861863, grad/param norm = 1.9571e-01, time/batch = 0.3129s	
184/2700 (epoch 3.407), train_loss = 3.24122929, grad/param norm = 1.9301e-01, time/batch = 0.3046s	
185/2700 (epoch 3.426), train_loss = 3.23959637, grad/param norm = 1.5894e-01, time/batch = 0.2961s	
186/2700 (epoch 3.444), train_loss = 3.17457530, grad/param norm = 1.8333e-01, time/batch = 0.2997s	
187/2700 (epoch 3.463), train_loss = 3.20764190, grad/param norm = 2.0846e-01, time/batch = 0.3500s	
188/2700 (epoch 3.481), train_loss = 3.27995820, grad/param norm = 1.9634e-01, time/batch = 0.3468s	
189/2700 (epoch 3.500), train_loss = 3.30718918, grad/param norm = 2.0388e-01, time/batch = 0.3434s	
190/2700 (epoch 3.519), train_loss = 3.26586977, grad/param norm = 1.8782e-01, time/batch = 0.3323s	
191/2700 (epoch 3.537), train_loss = 3.28288161, grad/param norm = 3.2710e-01, time/batch = 0.3280s	
192/2700 (epoch 3.556), train_loss = 3.32903166, grad/param norm = 5.7062e-01, time/batch = 0.3197s	
193/2700 (epoch 3.574), train_loss = 3.21918512, grad/param norm = 4.2397e-01, time/batch = 0.3162s	
194/2700 (epoch 3.593), train_loss = 3.18741498, grad/param norm = 2.6591e-01, time/batch = 0.3034s	
195/2700 (epoch 3.611), train_loss = 3.12925922, grad/param norm = 1.3956e-01, time/batch = 0.2872s	
196/2700 (epoch 3.630), train_loss = 3.16174458, grad/param norm = 1.5809e-01, time/batch = 0.3052s	
197/2700 (epoch 3.648), train_loss = 3.21921008, grad/param norm = 1.6868e-01, time/batch = 0.3054s	
198/2700 (epoch 3.667), train_loss = 3.15709420, grad/param norm = 1.2731e-01, time/batch = 0.3527s	
199/2700 (epoch 3.685), train_loss = 3.15853257, grad/param norm = 1.8209e-01, time/batch = 0.3512s	
200/2700 (epoch 3.704), train_loss = 3.12635950, grad/param norm = 2.1216e-01, time/batch = 0.3483s	
201/2700 (epoch 3.722), train_loss = 3.10928687, grad/param norm = 1.5293e-01, time/batch = 0.3146s	
202/2700 (epoch 3.741), train_loss = 3.24044487, grad/param norm = 2.3386e-01, time/batch = 0.3152s	
203/2700 (epoch 3.759), train_loss = 3.19455487, grad/param norm = 3.1230e-01, time/batch = 0.3132s	
204/2700 (epoch 3.778), train_loss = 3.18996949, grad/param norm = 3.4171e-01, time/batch = 0.3133s	
205/2700 (epoch 3.796), train_loss = 3.17099536, grad/param norm = 3.3421e-01, time/batch = 0.2823s	
206/2700 (epoch 3.815), train_loss = 3.12423499, grad/param norm = 2.6615e-01, time/batch = 0.3047s	
207/2700 (epoch 3.833), train_loss = 3.14913278, grad/param norm = 2.6083e-01, time/batch = 0.3111s	
208/2700 (epoch 3.852), train_loss = 3.13683364, grad/param norm = 1.9265e-01, time/batch = 0.3046s	
209/2700 (epoch 3.870), train_loss = 3.12653275, grad/param norm = 2.5698e-01, time/batch = 0.3583s	
210/2700 (epoch 3.889), train_loss = 3.18410493, grad/param norm = 3.7189e-01, time/batch = 0.3547s	
211/2700 (epoch 3.907), train_loss = 3.22000436, grad/param norm = 3.7772e-01, time/batch = 0.3134s	
212/2700 (epoch 3.926), train_loss = 3.16791222, grad/param norm = 2.8811e-01, time/batch = 0.3133s	
213/2700 (epoch 3.944), train_loss = 3.15408185, grad/param norm = 2.3518e-01, time/batch = 0.3141s	
214/2700 (epoch 3.963), train_loss = 3.21673268, grad/param norm = 1.6974e-01, time/batch = 0.3182s	
215/2700 (epoch 3.981), train_loss = 3.24707899, grad/param norm = 3.0766e-01, time/batch = 0.2816s	
216/2700 (epoch 4.000), train_loss = 3.17758327, grad/param norm = 3.4398e-01, time/batch = 0.3094s	
217/2700 (epoch 4.019), train_loss = 3.20859430, grad/param norm = 6.0930e-01, time/batch = 0.3038s	
218/2700 (epoch 4.037), train_loss = 3.26908377, grad/param norm = 7.6820e-01, time/batch = 0.3090s	
219/2700 (epoch 4.056), train_loss = 3.16848323, grad/param norm = 3.1376e-01, time/batch = 0.3013s	
220/2700 (epoch 4.074), train_loss = 3.17001441, grad/param norm = 1.6601e-01, time/batch = 0.3537s	
221/2700 (epoch 4.093), train_loss = 3.16576042, grad/param norm = 1.8718e-01, time/batch = 0.3095s	
222/2700 (epoch 4.111), train_loss = 3.13192717, grad/param norm = 1.4869e-01, time/batch = 0.3238s	
223/2700 (epoch 4.130), train_loss = 3.13418206, grad/param norm = 1.6272e-01, time/batch = 0.3341s	
224/2700 (epoch 4.148), train_loss = 3.09222520, grad/param norm = 1.5808e-01, time/batch = 0.3258s	
225/2700 (epoch 4.167), train_loss = 3.08920847, grad/param norm = 1.9044e-01, time/batch = 0.2828s	
226/2700 (epoch 4.185), train_loss = 3.07276362, grad/param norm = 1.3879e-01, time/batch = 0.3274s	
227/2700 (epoch 4.204), train_loss = 3.01711331, grad/param norm = 2.3791e-01, time/batch = 0.3250s	
228/2700 (epoch 4.222), train_loss = 2.97796838, grad/param norm = 2.7590e-01, time/batch = 0.3146s	
229/2700 (epoch 4.241), train_loss = 2.98682526, grad/param norm = 2.5262e-01, time/batch = 0.3033s	
230/2700 (epoch 4.259), train_loss = 3.00822927, grad/param norm = 1.8328e-01, time/batch = 0.2876s	
231/2700 (epoch 4.278), train_loss = 3.08426893, grad/param norm = 2.2367e-01, time/batch = 0.3096s	
232/2700 (epoch 4.296), train_loss = 3.19838389, grad/param norm = 6.7532e-01, time/batch = 0.3215s	
233/2700 (epoch 4.315), train_loss = 3.29209748, grad/param norm = 9.5912e-01, time/batch = 0.3193s	
234/2700 (epoch 4.333), train_loss = 3.17450105, grad/param norm = 3.4387e-01, time/batch = 0.3182s	
235/2700 (epoch 4.352), train_loss = 3.15853345, grad/param norm = 1.8459e-01, time/batch = 0.2738s	
236/2700 (epoch 4.370), train_loss = 3.07477492, grad/param norm = 1.8283e-01, time/batch = 0.3166s	
237/2700 (epoch 4.389), train_loss = 3.05088887, grad/param norm = 1.2867e-01, time/batch = 0.3080s	
238/2700 (epoch 4.407), train_loss = 3.07813473, grad/param norm = 1.6062e-01, time/batch = 0.3217s	
239/2700 (epoch 4.426), train_loss = 3.07014729, grad/param norm = 1.4093e-01, time/batch = 0.3207s	
240/2700 (epoch 4.444), train_loss = 2.97872931, grad/param norm = 2.5666e-01, time/batch = 0.2994s	
241/2700 (epoch 4.463), train_loss = 3.04033299, grad/param norm = 3.1339e-01, time/batch = 0.2523s	
242/2700 (epoch 4.481), train_loss = 3.12860167, grad/param norm = 4.0076e-01, time/batch = 0.3169s	
243/2700 (epoch 4.500), train_loss = 3.20740756, grad/param norm = 6.0422e-01, time/batch = 0.3175s	
244/2700 (epoch 4.519), train_loss = 3.17929085, grad/param norm = 5.9937e-01, time/batch = 0.3063s	
245/2700 (epoch 4.537), train_loss = 3.17784360, grad/param norm = 5.0774e-01, time/batch = 0.2654s	
246/2700 (epoch 4.556), train_loss = 3.06856328, grad/param norm = 3.2368e-01, time/batch = 0.3074s	
247/2700 (epoch 4.574), train_loss = 3.00206074, grad/param norm = 2.0951e-01, time/batch = 0.3172s	
248/2700 (epoch 4.593), train_loss = 2.99893169, grad/param norm = 2.0865e-01, time/batch = 0.3272s	
249/2700 (epoch 4.611), train_loss = 2.96244275, grad/param norm = 1.5200e-01, time/batch = 0.3223s	
250/2700 (epoch 4.630), train_loss = 2.97395143, grad/param norm = 1.4350e-01, time/batch = 0.3326s	
251/2700 (epoch 4.648), train_loss = 3.01882635, grad/param norm = 2.0537e-01, time/batch = 0.3078s	
252/2700 (epoch 4.667), train_loss = 2.95639491, grad/param norm = 1.5291e-01, time/batch = 0.2813s	
253/2700 (epoch 4.685), train_loss = 2.99692582, grad/param norm = 1.8916e-01, time/batch = 0.3097s	
254/2700 (epoch 4.704), train_loss = 2.96199558, grad/param norm = 2.6614e-01, time/batch = 0.3095s	
255/2700 (epoch 4.722), train_loss = 2.98213995, grad/param norm = 3.2687e-01, time/batch = 0.2752s	
256/2700 (epoch 4.741), train_loss = 3.12280677, grad/param norm = 3.0915e-01, time/batch = 0.3167s	
257/2700 (epoch 4.759), train_loss = 3.04746169, grad/param norm = 3.9772e-01, time/batch = 0.3058s	
258/2700 (epoch 4.778), train_loss = 3.04506542, grad/param norm = 4.0284e-01, time/batch = 0.3130s	
259/2700 (epoch 4.796), train_loss = 3.02716039, grad/param norm = 3.3305e-01, time/batch = 0.3167s	
260/2700 (epoch 4.815), train_loss = 2.97375196, grad/param norm = 2.9784e-01, time/batch = 0.3352s	
261/2700 (epoch 4.833), train_loss = 2.99505499, grad/param norm = 3.3686e-01, time/batch = 0.3237s	
262/2700 (epoch 4.852), train_loss = 3.00831854, grad/param norm = 3.5718e-01, time/batch = 0.3240s	
263/2700 (epoch 4.870), train_loss = 2.96621536, grad/param norm = 3.2506e-01, time/batch = 0.3144s	
264/2700 (epoch 4.889), train_loss = 2.99799030, grad/param norm = 3.1981e-01, time/batch = 0.3102s	
265/2700 (epoch 4.907), train_loss = 3.05784766, grad/param norm = 3.1184e-01, time/batch = 0.2651s	
266/2700 (epoch 4.926), train_loss = 3.04072268, grad/param norm = 5.0988e-01, time/batch = 0.3094s	
267/2700 (epoch 4.944), train_loss = 3.18584517, grad/param norm = 7.9864e-01, time/batch = 0.3261s	
268/2700 (epoch 4.963), train_loss = 3.10827761, grad/param norm = 4.0618e-01, time/batch = 0.3055s	
269/2700 (epoch 4.981), train_loss = 3.09177091, grad/param norm = 2.2362e-01, time/batch = 0.3174s	
270/2700 (epoch 5.000), train_loss = 3.04740645, grad/param norm = 2.3182e-01, time/batch = 0.3115s	
271/2700 (epoch 5.019), train_loss = 2.98222987, grad/param norm = 2.0604e-01, time/batch = 0.2962s	
272/2700 (epoch 5.037), train_loss = 2.98856513, grad/param norm = 1.3523e-01, time/batch = 0.3082s	
273/2700 (epoch 5.056), train_loss = 2.95983242, grad/param norm = 2.0767e-01, time/batch = 0.3161s	
274/2700 (epoch 5.074), train_loss = 2.97694635, grad/param norm = 1.9795e-01, time/batch = 0.3135s	
275/2700 (epoch 5.093), train_loss = 3.01147974, grad/param norm = 1.5929e-01, time/batch = 0.2617s	
276/2700 (epoch 5.111), train_loss = 2.97926741, grad/param norm = 1.6995e-01, time/batch = 0.3048s	
277/2700 (epoch 5.130), train_loss = 2.99992882, grad/param norm = 2.4071e-01, time/batch = 0.3034s	
278/2700 (epoch 5.148), train_loss = 2.99859126, grad/param norm = 3.8499e-01, time/batch = 0.3144s	
279/2700 (epoch 5.167), train_loss = 3.05071379, grad/param norm = 5.9789e-01, time/batch = 0.3272s	
280/2700 (epoch 5.185), train_loss = 2.98350246, grad/param norm = 4.4295e-01, time/batch = 0.3298s	
281/2700 (epoch 5.204), train_loss = 2.90269057, grad/param norm = 2.3249e-01, time/batch = 0.3006s	
282/2700 (epoch 5.222), train_loss = 2.84951430, grad/param norm = 2.5292e-01, time/batch = 0.3007s	
283/2700 (epoch 5.241), train_loss = 2.85093898, grad/param norm = 1.6726e-01, time/batch = 0.3078s	
284/2700 (epoch 5.259), train_loss = 2.86844549, grad/param norm = 1.7692e-01, time/batch = 0.3226s	
285/2700 (epoch 5.278), train_loss = 2.94034634, grad/param norm = 1.6775e-01, time/batch = 0.3087s	
286/2700 (epoch 5.296), train_loss = 2.93356696, grad/param norm = 1.6317e-01, time/batch = 0.3178s	
287/2700 (epoch 5.315), train_loss = 2.96044834, grad/param norm = 1.9213e-01, time/batch = 0.2963s	
288/2700 (epoch 5.333), train_loss = 3.00190438, grad/param norm = 2.9775e-01, time/batch = 0.3036s	
289/2700 (epoch 5.352), train_loss = 3.12136584, grad/param norm = 4.6225e-01, time/batch = 0.2992s	
290/2700 (epoch 5.370), train_loss = 3.02980865, grad/param norm = 6.6208e-01, time/batch = 0.2971s	
291/2700 (epoch 5.389), train_loss = 3.07325624, grad/param norm = 6.9201e-01, time/batch = 0.2962s	
292/2700 (epoch 5.407), train_loss = 3.01791603, grad/param norm = 4.6504e-01, time/batch = 0.3073s	
293/2700 (epoch 5.426), train_loss = 2.97228580, grad/param norm = 1.8369e-01, time/batch = 0.3201s	
294/2700 (epoch 5.444), train_loss = 2.85434547, grad/param norm = 2.2584e-01, time/batch = 0.3262s	
295/2700 (epoch 5.463), train_loss = 2.92198195, grad/param norm = 1.5962e-01, time/batch = 0.3024s	
296/2700 (epoch 5.481), train_loss = 2.97729934, grad/param norm = 1.7796e-01, time/batch = 0.3077s	
297/2700 (epoch 5.500), train_loss = 3.00620699, grad/param norm = 2.2116e-01, time/batch = 0.2889s	
298/2700 (epoch 5.519), train_loss = 2.94756345, grad/param norm = 2.4573e-01, time/batch = 0.3090s	
299/2700 (epoch 5.537), train_loss = 2.94088944, grad/param norm = 3.0332e-01, time/batch = 0.3105s	
300/2700 (epoch 5.556), train_loss = 2.92751260, grad/param norm = 3.7777e-01, time/batch = 0.3137s	
301/2700 (epoch 5.574), train_loss = 2.93007701, grad/param norm = 4.6305e-01, time/batch = 0.3103s	
302/2700 (epoch 5.593), train_loss = 2.92322404, grad/param norm = 4.0176e-01, time/batch = 0.3102s	
303/2700 (epoch 5.611), train_loss = 2.84828893, grad/param norm = 3.1751e-01, time/batch = 0.3167s	
304/2700 (epoch 5.630), train_loss = 2.85542298, grad/param norm = 2.4838e-01, time/batch = 0.3252s	
305/2700 (epoch 5.648), train_loss = 2.88335843, grad/param norm = 1.6084e-01, time/batch = 0.2976s	
306/2700 (epoch 5.667), train_loss = 2.83165353, grad/param norm = 1.9340e-01, time/batch = 0.3149s	
307/2700 (epoch 5.685), train_loss = 2.88160033, grad/param norm = 2.2360e-01, time/batch = 0.3173s	
308/2700 (epoch 5.704), train_loss = 2.84771030, grad/param norm = 2.3207e-01, time/batch = 0.2695s	
309/2700 (epoch 5.722), train_loss = 2.82866410, grad/param norm = 1.7486e-01, time/batch = 0.3196s	
310/2700 (epoch 5.741), train_loss = 2.99155143, grad/param norm = 1.6138e-01, time/batch = 0.3222s	
311/2700 (epoch 5.759), train_loss = 2.91089931, grad/param norm = 2.3313e-01, time/batch = 0.3229s	
312/2700 (epoch 5.778), train_loss = 2.90051262, grad/param norm = 3.1830e-01, time/batch = 0.3300s	
313/2700 (epoch 5.796), train_loss = 2.88221527, grad/param norm = 2.9882e-01, time/batch = 0.3185s	
314/2700 (epoch 5.815), train_loss = 2.83869075, grad/param norm = 2.1777e-01, time/batch = 0.3140s	
315/2700 (epoch 5.833), train_loss = 2.83532626, grad/param norm = 2.0713e-01, time/batch = 0.2972s	
316/2700 (epoch 5.852), train_loss = 2.87886170, grad/param norm = 2.5469e-01, time/batch = 0.3304s	
317/2700 (epoch 5.870), train_loss = 2.85267855, grad/param norm = 3.8119e-01, time/batch = 0.3302s	
318/2700 (epoch 5.889), train_loss = 2.92351035, grad/param norm = 4.9523e-01, time/batch = 0.3328s	
319/2700 (epoch 5.907), train_loss = 3.05734464, grad/param norm = 6.4807e-01, time/batch = 0.2633s	
320/2700 (epoch 5.926), train_loss = 2.95521105, grad/param norm = 4.5660e-01, time/batch = 0.3380s	
321/2700 (epoch 5.944), train_loss = 2.92275992, grad/param norm = 3.0143e-01, time/batch = 0.3487s	
322/2700 (epoch 5.963), train_loss = 2.94786144, grad/param norm = 2.3199e-01, time/batch = 0.3350s	
323/2700 (epoch 5.981), train_loss = 2.93843726, grad/param norm = 2.4904e-01, time/batch = 0.3285s	
324/2700 (epoch 6.000), train_loss = 2.95684263, grad/param norm = 4.4587e-01, time/batch = 0.2902s	
325/2700 (epoch 6.019), train_loss = 2.92874086, grad/param norm = 3.8099e-01, time/batch = 0.3229s	
326/2700 (epoch 6.037), train_loss = 2.89819074, grad/param norm = 2.2562e-01, time/batch = 0.3048s	
327/2700 (epoch 6.056), train_loss = 2.85920714, grad/param norm = 2.1729e-01, time/batch = 0.3060s	
328/2700 (epoch 6.074), train_loss = 2.85454203, grad/param norm = 1.9165e-01, time/batch = 0.3079s	
329/2700 (epoch 6.093), train_loss = 2.89538651, grad/param norm = 1.5282e-01, time/batch = 0.3268s	
330/2700 (epoch 6.111), train_loss = 2.85439156, grad/param norm = 1.1878e-01, time/batch = 0.3274s	
331/2700 (epoch 6.130), train_loss = 2.87696659, grad/param norm = 1.3033e-01, time/batch = 0.3375s	
332/2700 (epoch 6.148), train_loss = 2.84507457, grad/param norm = 1.7459e-01, time/batch = 0.3236s	
333/2700 (epoch 6.167), train_loss = 2.85781112, grad/param norm = 2.0384e-01, time/batch = 0.3086s	
334/2700 (epoch 6.185), train_loss = 2.81720092, grad/param norm = 1.6229e-01, time/batch = 0.2804s	
335/2700 (epoch 6.204), train_loss = 2.77045296, grad/param norm = 1.7574e-01, time/batch = 0.3306s	
336/2700 (epoch 6.222), train_loss = 2.73297993, grad/param norm = 2.5422e-01, time/batch = 0.3242s	
337/2700 (epoch 6.241), train_loss = 2.75043082, grad/param norm = 2.9910e-01, time/batch = 0.3102s	
338/2700 (epoch 6.259), train_loss = 2.83210610, grad/param norm = 4.7858e-01, time/batch = 0.3060s	
339/2700 (epoch 6.278), train_loss = 2.98107539, grad/param norm = 6.6134e-01, time/batch = 0.3104s	
340/2700 (epoch 6.296), train_loss = 3.00859065, grad/param norm = 7.0987e-01, time/batch = 0.3218s	
341/2700 (epoch 6.315), train_loss = 2.91259567, grad/param norm = 4.1491e-01, time/batch = 0.2663s	
342/2700 (epoch 6.333), train_loss = 2.92888974, grad/param norm = 2.8497e-01, time/batch = 0.3245s	
343/2700 (epoch 6.352), train_loss = 2.94392668, grad/param norm = 2.5513e-01, time/batch = 0.3267s	
344/2700 (epoch 6.370), train_loss = 2.84288233, grad/param norm = 1.8303e-01, time/batch = 0.3112s	
345/2700 (epoch 6.389), train_loss = 2.82750856, grad/param norm = 1.6592e-01, time/batch = 0.3468s	
346/2700 (epoch 6.407), train_loss = 2.84910676, grad/param norm = 1.6721e-01, time/batch = 0.3261s	
347/2700 (epoch 6.426), train_loss = 2.83192939, grad/param norm = 1.4862e-01, time/batch = 0.3214s	
348/2700 (epoch 6.444), train_loss = 2.72415720, grad/param norm = 1.9033e-01, time/batch = 0.3086s	
349/2700 (epoch 6.463), train_loss = 2.82227115, grad/param norm = 2.0078e-01, time/batch = 0.2978s	
350/2700 (epoch 6.481), train_loss = 2.87835889, grad/param norm = 2.4141e-01, time/batch = 0.2953s	
351/2700 (epoch 6.500), train_loss = 2.93353775, grad/param norm = 4.1935e-01, time/batch = 0.3099s	
352/2700 (epoch 6.519), train_loss = 2.94487396, grad/param norm = 6.8059e-01, time/batch = 0.2496s	
353/2700 (epoch 6.537), train_loss = 2.99064021, grad/param norm = 5.5550e-01, time/batch = 0.3229s	
354/2700 (epoch 6.556), train_loss = 2.83208150, grad/param norm = 2.8836e-01, time/batch = 0.2813s	
355/2700 (epoch 6.574), train_loss = 2.77443864, grad/param norm = 1.8094e-01, time/batch = 0.3179s	
356/2700 (epoch 6.593), train_loss = 2.77202814, grad/param norm = 1.8453e-01, time/batch = 0.3073s	
357/2700 (epoch 6.611), train_loss = 2.72350069, grad/param norm = 1.7291e-01, time/batch = 0.3050s	
358/2700 (epoch 6.630), train_loss = 2.75545870, grad/param norm = 1.7830e-01, time/batch = 0.3115s	
359/2700 (epoch 6.648), train_loss = 2.78180037, grad/param norm = 1.4242e-01, time/batch = 0.3254s	
360/2700 (epoch 6.667), train_loss = 2.72327954, grad/param norm = 1.2907e-01, time/batch = 0.3287s	
361/2700 (epoch 6.685), train_loss = 2.78155747, grad/param norm = 1.6613e-01, time/batch = 0.2909s	
362/2700 (epoch 6.704), train_loss = 2.75138133, grad/param norm = 1.8129e-01, time/batch = 0.3045s	
363/2700 (epoch 6.722), train_loss = 2.72920751, grad/param norm = 1.6495e-01, time/batch = 0.2824s	
364/2700 (epoch 6.741), train_loss = 2.90423229, grad/param norm = 2.3165e-01, time/batch = 0.2805s	
365/2700 (epoch 6.759), train_loss = 2.82888146, grad/param norm = 2.2706e-01, time/batch = 0.3192s	
366/2700 (epoch 6.778), train_loss = 2.82757276, grad/param norm = 3.2277e-01, time/batch = 0.3106s	
367/2700 (epoch 6.796), train_loss = 2.85358708, grad/param norm = 4.6954e-01, time/batch = 0.3095s	
368/2700 (epoch 6.815), train_loss = 2.85215994, grad/param norm = 5.6039e-01, time/batch = 0.3202s	
369/2700 (epoch 6.833), train_loss = 2.80584529, grad/param norm = 3.6535e-01, time/batch = 0.3235s	
370/2700 (epoch 6.852), train_loss = 2.80832810, grad/param norm = 1.8888e-01, time/batch = 0.3190s	
371/2700 (epoch 6.870), train_loss = 2.74835817, grad/param norm = 1.2019e-01, time/batch = 0.2998s	
372/2700 (epoch 6.889), train_loss = 2.78331717, grad/param norm = 1.7026e-01, time/batch = 0.3011s	
373/2700 (epoch 6.907), train_loss = 2.87018281, grad/param norm = 2.2721e-01, time/batch = 0.3218s	
374/2700 (epoch 6.926), train_loss = 2.81267475, grad/param norm = 2.7210e-01, time/batch = 0.2812s	
375/2700 (epoch 6.944), train_loss = 2.80716492, grad/param norm = 2.9495e-01, time/batch = 0.3332s	
376/2700 (epoch 6.963), train_loss = 2.86628551, grad/param norm = 2.6234e-01, time/batch = 0.3244s	
377/2700 (epoch 6.981), train_loss = 2.83989889, grad/param norm = 2.0096e-01, time/batch = 0.3091s	
378/2700 (epoch 7.000), train_loss = 2.83858418, grad/param norm = 2.4235e-01, time/batch = 0.3035s	
379/2700 (epoch 7.019), train_loss = 2.80364627, grad/param norm = 2.9594e-01, time/batch = 0.3092s	
380/2700 (epoch 7.037), train_loss = 2.84496821, grad/param norm = 3.1219e-01, time/batch = 0.3143s	
381/2700 (epoch 7.056), train_loss = 2.82864765, grad/param norm = 4.1208e-01, time/batch = 0.2965s	
382/2700 (epoch 7.074), train_loss = 2.83789732, grad/param norm = 3.9592e-01, time/batch = 0.3016s	
383/2700 (epoch 7.093), train_loss = 2.87484551, grad/param norm = 3.2003e-01, time/batch = 0.3008s	
384/2700 (epoch 7.111), train_loss = 2.81310319, grad/param norm = 2.9365e-01, time/batch = 0.2868s	
385/2700 (epoch 7.130), train_loss = 2.84020569, grad/param norm = 3.1551e-01, time/batch = 0.3149s	
386/2700 (epoch 7.148), train_loss = 2.79213047, grad/param norm = 2.9420e-01, time/batch = 0.3314s	
387/2700 (epoch 7.167), train_loss = 2.79221746, grad/param norm = 2.3724e-01, time/batch = 0.3141s	
388/2700 (epoch 7.185), train_loss = 2.75156043, grad/param norm = 1.9105e-01, time/batch = 0.3037s	
389/2700 (epoch 7.204), train_loss = 2.69317576, grad/param norm = 1.6613e-01, time/batch = 0.2955s	
390/2700 (epoch 7.222), train_loss = 2.65995124, grad/param norm = 1.9837e-01, time/batch = 0.3003s	
391/2700 (epoch 7.241), train_loss = 2.66101110, grad/param norm = 1.4075e-01, time/batch = 0.3276s	
392/2700 (epoch 7.259), train_loss = 2.68774299, grad/param norm = 1.7622e-01, time/batch = 0.3128s	
393/2700 (epoch 7.278), train_loss = 2.76935869, grad/param norm = 2.0766e-01, time/batch = 0.3052s	
394/2700 (epoch 7.296), train_loss = 2.77074185, grad/param norm = 2.3412e-01, time/batch = 0.2923s	
395/2700 (epoch 7.315), train_loss = 2.78647940, grad/param norm = 1.9994e-01, time/batch = 0.2980s	
396/2700 (epoch 7.333), train_loss = 2.81355626, grad/param norm = 2.7973e-01, time/batch = 0.2826s	
397/2700 (epoch 7.352), train_loss = 2.92985447, grad/param norm = 7.7440e-01, time/batch = 0.3135s	
398/2700 (epoch 7.370), train_loss = 2.97977887, grad/param norm = 7.1060e-01, time/batch = 0.3115s	
399/2700 (epoch 7.389), train_loss = 2.84611072, grad/param norm = 4.9343e-01, time/batch = 0.3038s	
400/2700 (epoch 7.407), train_loss = 2.80056549, grad/param norm = 2.1830e-01, time/batch = 0.2929s	
401/2700 (epoch 7.426), train_loss = 2.78128947, grad/param norm = 1.7543e-01, time/batch = 0.3291s	
402/2700 (epoch 7.444), train_loss = 2.67101717, grad/param norm = 1.4636e-01, time/batch = 0.3151s	
403/2700 (epoch 7.463), train_loss = 2.76334275, grad/param norm = 1.5413e-01, time/batch = 0.2965s	
404/2700 (epoch 7.481), train_loss = 2.80124086, grad/param norm = 1.6288e-01, time/batch = 0.2993s	
405/2700 (epoch 7.500), train_loss = 2.82343964, grad/param norm = 2.1820e-01, time/batch = 0.3096s	
406/2700 (epoch 7.519), train_loss = 2.77645212, grad/param norm = 2.3280e-01, time/batch = 0.3206s	
407/2700 (epoch 7.537), train_loss = 2.76425552, grad/param norm = 2.7808e-01, time/batch = 0.3023s	
408/2700 (epoch 7.556), train_loss = 2.75958889, grad/param norm = 3.1221e-01, time/batch = 0.3326s	
409/2700 (epoch 7.574), train_loss = 2.75204070, grad/param norm = 3.8164e-01, time/batch = 0.3320s	
410/2700 (epoch 7.593), train_loss = 2.75738521, grad/param norm = 3.7144e-01, time/batch = 0.3197s	
411/2700 (epoch 7.611), train_loss = 2.69456989, grad/param norm = 3.4548e-01, time/batch = 0.3460s	
412/2700 (epoch 7.630), train_loss = 2.71306866, grad/param norm = 2.8340e-01, time/batch = 0.3285s	
413/2700 (epoch 7.648), train_loss = 2.72705101, grad/param norm = 1.8264e-01, time/batch = 0.3170s	
414/2700 (epoch 7.667), train_loss = 2.66822354, grad/param norm = 1.8504e-01, time/batch = 0.3167s	
415/2700 (epoch 7.685), train_loss = 2.72827698, grad/param norm = 2.2203e-01, time/batch = 0.3060s	
416/2700 (epoch 7.704), train_loss = 2.70741558, grad/param norm = 2.2099e-01, time/batch = 0.3067s	
417/2700 (epoch 7.722), train_loss = 2.67542544, grad/param norm = 1.3984e-01, time/batch = 0.3217s	
418/2700 (epoch 7.741), train_loss = 2.84277216, grad/param norm = 1.6705e-01, time/batch = 0.3170s	
419/2700 (epoch 7.759), train_loss = 2.76850721, grad/param norm = 1.8693e-01, time/batch = 0.3501s	
420/2700 (epoch 7.778), train_loss = 2.75195657, grad/param norm = 2.2652e-01, time/batch = 0.3511s	
421/2700 (epoch 7.796), train_loss = 2.72537983, grad/param norm = 2.4162e-01, time/batch = 0.3307s	
422/2700 (epoch 7.815), train_loss = 2.72191378, grad/param norm = 2.8934e-01, time/batch = 0.3277s	
423/2700 (epoch 7.833), train_loss = 2.75093900, grad/param norm = 3.7454e-01, time/batch = 0.2721s	
424/2700 (epoch 7.852), train_loss = 2.79852605, grad/param norm = 4.2406e-01, time/batch = 0.3268s	
425/2700 (epoch 7.870), train_loss = 2.74714153, grad/param norm = 3.4836e-01, time/batch = 0.3292s	
426/2700 (epoch 7.889), train_loss = 2.76202963, grad/param norm = 3.7213e-01, time/batch = 0.3175s	
427/2700 (epoch 7.907), train_loss = 2.83095434, grad/param norm = 3.4707e-01, time/batch = 0.3032s	
428/2700 (epoch 7.926), train_loss = 2.75297675, grad/param norm = 2.8492e-01, time/batch = 0.3035s	
429/2700 (epoch 7.944), train_loss = 2.74115078, grad/param norm = 1.7811e-01, time/batch = 0.2930s	
430/2700 (epoch 7.963), train_loss = 2.79794632, grad/param norm = 1.1754e-01, time/batch = 0.3541s	
431/2700 (epoch 7.981), train_loss = 2.77158678, grad/param norm = 1.7463e-01, time/batch = 0.3192s	
432/2700 (epoch 8.000), train_loss = 2.76697887, grad/param norm = 1.3655e-01, time/batch = 0.3228s	
433/2700 (epoch 8.019), train_loss = 2.72059264, grad/param norm = 1.7433e-01, time/batch = 0.2958s	
434/2700 (epoch 8.037), train_loss = 2.77522733, grad/param norm = 2.3930e-01, time/batch = 0.3206s	
435/2700 (epoch 8.056), train_loss = 2.74160953, grad/param norm = 3.1702e-01, time/batch = 0.3178s	
436/2700 (epoch 8.074), train_loss = 2.75731338, grad/param norm = 3.9934e-01, time/batch = 0.3060s	
437/2700 (epoch 8.093), train_loss = 2.82138471, grad/param norm = 3.9108e-01, time/batch = 0.3022s	
438/2700 (epoch 8.111), train_loss = 2.80474923, grad/param norm = 4.1653e-01, time/batch = 0.2966s	
439/2700 (epoch 8.130), train_loss = 2.81084425, grad/param norm = 3.5815e-01, time/batch = 0.3022s	
440/2700 (epoch 8.148), train_loss = 2.76493948, grad/param norm = 4.5961e-01, time/batch = 0.2815s	
441/2700 (epoch 8.167), train_loss = 2.79392160, grad/param norm = 4.6342e-01, time/batch = 0.3542s	
442/2700 (epoch 8.185), train_loss = 2.72647573, grad/param norm = 2.4800e-01, time/batch = 0.3391s	
443/2700 (epoch 8.204), train_loss = 2.64882640, grad/param norm = 2.5391e-01, time/batch = 0.3243s	
444/2700 (epoch 8.222), train_loss = 2.62381454, grad/param norm = 2.4440e-01, time/batch = 0.3345s	
445/2700 (epoch 8.241), train_loss = 2.62024143, grad/param norm = 2.0757e-01, time/batch = 0.3339s	
446/2700 (epoch 8.259), train_loss = 2.64418257, grad/param norm = 2.3322e-01, time/batch = 0.3330s	
447/2700 (epoch 8.278), train_loss = 2.73038912, grad/param norm = 3.3337e-01, time/batch = 0.3234s	
448/2700 (epoch 8.296), train_loss = 2.74780355, grad/param norm = 3.8033e-01, time/batch = 0.3060s	
449/2700 (epoch 8.315), train_loss = 2.76062537, grad/param norm = 3.1016e-01, time/batch = 0.3039s	
450/2700 (epoch 8.333), train_loss = 2.79559745, grad/param norm = 3.6516e-01, time/batch = 0.3074s	
451/2700 (epoch 8.352), train_loss = 2.83339392, grad/param norm = 4.7006e-01, time/batch = 0.2842s	
452/2700 (epoch 8.370), train_loss = 2.78124531, grad/param norm = 3.2164e-01, time/batch = 0.3348s	
453/2700 (epoch 8.389), train_loss = 2.70313543, grad/param norm = 1.7699e-01, time/batch = 0.3238s	
454/2700 (epoch 8.407), train_loss = 2.72379305, grad/param norm = 1.9638e-01, time/batch = 0.3329s	
455/2700 (epoch 8.426), train_loss = 2.72020306, grad/param norm = 2.1172e-01, time/batch = 0.3167s	
456/2700 (epoch 8.444), train_loss = 2.62287433, grad/param norm = 2.0514e-01, time/batch = 0.3301s	
457/2700 (epoch 8.463), train_loss = 2.71553556, grad/param norm = 2.0222e-01, time/batch = 0.3309s	
458/2700 (epoch 8.481), train_loss = 2.75078110, grad/param norm = 1.9513e-01, time/batch = 0.3225s	
459/2700 (epoch 8.500), train_loss = 2.76111032, grad/param norm = 1.7800e-01, time/batch = 0.3071s	
460/2700 (epoch 8.519), train_loss = 2.72078053, grad/param norm = 1.8257e-01, time/batch = 0.3116s	
461/2700 (epoch 8.537), train_loss = 2.71281233, grad/param norm = 2.8410e-01, time/batch = 0.3225s	
462/2700 (epoch 8.556), train_loss = 2.71630517, grad/param norm = 2.8733e-01, time/batch = 0.2678s	
463/2700 (epoch 8.574), train_loss = 2.69978033, grad/param norm = 3.2041e-01, time/batch = 0.3227s	
464/2700 (epoch 8.593), train_loss = 2.68354383, grad/param norm = 3.2379e-01, time/batch = 0.3018s	
465/2700 (epoch 8.611), train_loss = 2.63204513, grad/param norm = 3.0502e-01, time/batch = 0.3360s	
466/2700 (epoch 8.630), train_loss = 2.66084712, grad/param norm = 2.6709e-01, time/batch = 0.3309s	
467/2700 (epoch 8.648), train_loss = 2.69445421, grad/param norm = 2.9165e-01, time/batch = 0.3385s	
468/2700 (epoch 8.667), train_loss = 2.63344973, grad/param norm = 2.7888e-01, time/batch = 0.3371s	
469/2700 (epoch 8.685), train_loss = 2.68011718, grad/param norm = 2.7017e-01, time/batch = 0.3324s	
470/2700 (epoch 8.704), train_loss = 2.65815137, grad/param norm = 2.5289e-01, time/batch = 0.3206s	
471/2700 (epoch 8.722), train_loss = 2.63545134, grad/param norm = 1.7042e-01, time/batch = 0.3253s	
472/2700 (epoch 8.741), train_loss = 2.78833647, grad/param norm = 1.9853e-01, time/batch = 0.3174s	
473/2700 (epoch 8.759), train_loss = 2.72211195, grad/param norm = 2.5214e-01, time/batch = 0.2414s	
474/2700 (epoch 8.778), train_loss = 2.71983202, grad/param norm = 3.0847e-01, time/batch = 0.3501s	
475/2700 (epoch 8.796), train_loss = 2.68888771, grad/param norm = 2.7230e-01, time/batch = 0.3378s	
476/2700 (epoch 8.815), train_loss = 2.67521190, grad/param norm = 2.7947e-01, time/batch = 0.3300s	
477/2700 (epoch 8.833), train_loss = 2.68882328, grad/param norm = 3.7117e-01, time/batch = 0.3319s	
478/2700 (epoch 8.852), train_loss = 2.75407454, grad/param norm = 5.2260e-01, time/batch = 0.3408s	
479/2700 (epoch 8.870), train_loss = 2.71177127, grad/param norm = 4.9492e-01, time/batch = 0.3495s	
480/2700 (epoch 8.889), train_loss = 2.71062907, grad/param norm = 3.7921e-01, time/batch = 0.3395s	
481/2700 (epoch 8.907), train_loss = 2.77080606, grad/param norm = 2.0726e-01, time/batch = 0.3111s	
482/2700 (epoch 8.926), train_loss = 2.70519675, grad/param norm = 2.2003e-01, time/batch = 0.2569s	
483/2700 (epoch 8.944), train_loss = 2.72755439, grad/param norm = 2.9732e-01, time/batch = 0.3072s	
484/2700 (epoch 8.963), train_loss = 2.78669356, grad/param norm = 2.9222e-01, time/batch = 0.2798s	
485/2700 (epoch 8.981), train_loss = 2.73755929, grad/param norm = 2.6189e-01, time/batch = 0.3477s	
486/2700 (epoch 9.000), train_loss = 2.74634038, grad/param norm = 2.4690e-01, time/batch = 0.3430s	
487/2700 (epoch 9.019), train_loss = 2.69137760, grad/param norm = 2.4020e-01, time/batch = 0.3337s	
488/2700 (epoch 9.037), train_loss = 2.72287020, grad/param norm = 1.6377e-01, time/batch = 0.3356s	
489/2700 (epoch 9.056), train_loss = 2.67244124, grad/param norm = 1.5660e-01, time/batch = 0.3161s	
490/2700 (epoch 9.074), train_loss = 2.66933275, grad/param norm = 1.6702e-01, time/batch = 0.3159s	
491/2700 (epoch 9.093), train_loss = 2.70603303, grad/param norm = 1.8890e-01, time/batch = 0.3457s	
492/2700 (epoch 9.111), train_loss = 2.69879476, grad/param norm = 4.5524e-01, time/batch = 0.3405s	
493/2700 (epoch 9.130), train_loss = 2.75354875, grad/param norm = 3.8590e-01, time/batch = 0.3466s	
494/2700 (epoch 9.148), train_loss = 2.68890596, grad/param norm = 3.5211e-01, time/batch = 0.3289s	
495/2700 (epoch 9.167), train_loss = 2.70409182, grad/param norm = 2.7133e-01, time/batch = 0.3209s	
496/2700 (epoch 9.185), train_loss = 2.64933536, grad/param norm = 1.5508e-01, time/batch = 0.3060s	
497/2700 (epoch 9.204), train_loss = 2.59140762, grad/param norm = 1.7977e-01, time/batch = 0.3107s	
498/2700 (epoch 9.222), train_loss = 2.57597856, grad/param norm = 2.5860e-01, time/batch = 0.3166s	
499/2700 (epoch 9.241), train_loss = 2.60594935, grad/param norm = 4.0683e-01, time/batch = 0.3249s	
500/2700 (epoch 9.259), train_loss = 2.70287615, grad/param norm = 6.3308e-01, time/batch = 0.3226s	
501/2700 (epoch 9.278), train_loss = 2.82809908, grad/param norm = 5.9721e-01, time/batch = 0.2991s	
502/2700 (epoch 9.296), train_loss = 2.72278593, grad/param norm = 3.8564e-01, time/batch = 0.3247s	
503/2700 (epoch 9.315), train_loss = 2.68989682, grad/param norm = 1.9466e-01, time/batch = 0.3128s	
504/2700 (epoch 9.333), train_loss = 2.70139961, grad/param norm = 2.2776e-01, time/batch = 0.3147s	
505/2700 (epoch 9.352), train_loss = 2.74397797, grad/param norm = 5.8171e-01, time/batch = 0.3110s	
506/2700 (epoch 9.370), train_loss = 2.72690635, grad/param norm = 3.9192e-01, time/batch = 0.3278s	
507/2700 (epoch 9.389), train_loss = 2.63887842, grad/param norm = 1.5040e-01, time/batch = 0.3226s	
508/2700 (epoch 9.407), train_loss = 2.66214953, grad/param norm = 1.3275e-01, time/batch = 0.3106s	
509/2700 (epoch 9.426), train_loss = 2.65868725, grad/param norm = 1.2398e-01, time/batch = 0.3071s	
510/2700 (epoch 9.444), train_loss = 2.56785172, grad/param norm = 1.7206e-01, time/batch = 0.3042s	
511/2700 (epoch 9.463), train_loss = 2.67144606, grad/param norm = 1.9525e-01, time/batch = 0.3017s	
512/2700 (epoch 9.481), train_loss = 2.70004288, grad/param norm = 2.0618e-01, time/batch = 0.3093s	
513/2700 (epoch 9.500), train_loss = 2.70876572, grad/param norm = 2.2129e-01, time/batch = 0.3127s	
514/2700 (epoch 9.519), train_loss = 2.66941843, grad/param norm = 2.3885e-01, time/batch = 0.3200s	
515/2700 (epoch 9.537), train_loss = 2.64416587, grad/param norm = 2.5006e-01, time/batch = 0.3230s	
516/2700 (epoch 9.556), train_loss = 2.63156374, grad/param norm = 2.0351e-01, time/batch = 0.2919s	
517/2700 (epoch 9.574), train_loss = 2.61951364, grad/param norm = 2.3582e-01, time/batch = 0.3268s	
518/2700 (epoch 9.593), train_loss = 2.62244150, grad/param norm = 2.7872e-01, time/batch = 0.3252s	
519/2700 (epoch 9.611), train_loss = 2.60745970, grad/param norm = 4.0913e-01, time/batch = 0.3166s	
520/2700 (epoch 9.630), train_loss = 2.66559508, grad/param norm = 4.5853e-01, time/batch = 0.3048s	
521/2700 (epoch 9.648), train_loss = 2.65609182, grad/param norm = 2.9258e-01, time/batch = 0.2852s	
522/2700 (epoch 9.667), train_loss = 2.57948261, grad/param norm = 1.8523e-01, time/batch = 0.3105s	
523/2700 (epoch 9.685), train_loss = 2.61849437, grad/param norm = 2.0593e-01, time/batch = 0.3112s	
524/2700 (epoch 9.704), train_loss = 2.61367066, grad/param norm = 2.8612e-01, time/batch = 0.3199s	
525/2700 (epoch 9.722), train_loss = 2.61306896, grad/param norm = 2.5749e-01, time/batch = 0.3324s	
526/2700 (epoch 9.741), train_loss = 2.74178275, grad/param norm = 2.3850e-01, time/batch = 0.3139s	
527/2700 (epoch 9.759), train_loss = 2.67128035, grad/param norm = 2.5481e-01, time/batch = 0.2967s	
528/2700 (epoch 9.778), train_loss = 2.66187222, grad/param norm = 3.0308e-01, time/batch = 0.3077s	
529/2700 (epoch 9.796), train_loss = 2.62771482, grad/param norm = 2.8382e-01, time/batch = 0.3189s	
530/2700 (epoch 9.815), train_loss = 2.61891874, grad/param norm = 4.3158e-01, time/batch = 0.3053s	
531/2700 (epoch 9.833), train_loss = 2.64548373, grad/param norm = 4.0475e-01, time/batch = 0.2880s	
532/2700 (epoch 9.852), train_loss = 2.64634145, grad/param norm = 2.4267e-01, time/batch = 0.3127s	
533/2700 (epoch 9.870), train_loss = 2.60466022, grad/param norm = 2.0792e-01, time/batch = 0.3089s	
534/2700 (epoch 9.889), train_loss = 2.61047831, grad/param norm = 2.1881e-01, time/batch = 0.3177s	
535/2700 (epoch 9.907), train_loss = 2.70857959, grad/param norm = 2.3736e-01, time/batch = 0.3229s	
536/2700 (epoch 9.926), train_loss = 2.66166470, grad/param norm = 3.3962e-01, time/batch = 0.3268s	
537/2700 (epoch 9.944), train_loss = 2.73419442, grad/param norm = 4.6704e-01, time/batch = 0.3073s	
538/2700 (epoch 9.963), train_loss = 2.77474020, grad/param norm = 3.7435e-01, time/batch = 0.3134s	
539/2700 (epoch 9.981), train_loss = 2.68816661, grad/param norm = 3.3979e-01, time/batch = 0.3259s	
decayed learning rate by a factor 0.97 to 0.00194	
540/2700 (epoch 10.000), train_loss = 2.71281205, grad/param norm = 3.8100e-01, time/batch = 0.3209s	
541/2700 (epoch 10.019), train_loss = 2.66212293, grad/param norm = 3.7674e-01, time/batch = 0.2894s	
542/2700 (epoch 10.037), train_loss = 2.69137232, grad/param norm = 2.8514e-01, time/batch = 0.3196s	
543/2700 (epoch 10.056), train_loss = 2.62302107, grad/param norm = 2.2086e-01, time/batch = 0.3130s	
544/2700 (epoch 10.074), train_loss = 2.61351644, grad/param norm = 1.7071e-01, time/batch = 0.3132s	
545/2700 (epoch 10.093), train_loss = 2.64136474, grad/param norm = 1.3522e-01, time/batch = 0.3170s	
546/2700 (epoch 10.111), train_loss = 2.63400540, grad/param norm = 1.1653e-01, time/batch = 0.3050s	
547/2700 (epoch 10.130), train_loss = 2.64883733, grad/param norm = 1.2838e-01, time/batch = 0.3327s	
548/2700 (epoch 10.148), train_loss = 2.59246067, grad/param norm = 1.6386e-01, time/batch = 0.3271s	
549/2700 (epoch 10.167), train_loss = 2.63118004, grad/param norm = 1.8078e-01, time/batch = 0.3120s	
550/2700 (epoch 10.185), train_loss = 2.58774799, grad/param norm = 1.4877e-01, time/batch = 0.3301s	
551/2700 (epoch 10.204), train_loss = 2.53041993, grad/param norm = 1.5059e-01, time/batch = 0.2928s	
552/2700 (epoch 10.222), train_loss = 2.51738392, grad/param norm = 1.9298e-01, time/batch = 0.3272s	
553/2700 (epoch 10.241), train_loss = 2.52583934, grad/param norm = 2.3717e-01, time/batch = 0.3201s	
554/2700 (epoch 10.259), train_loss = 2.55251863, grad/param norm = 2.8334e-01, time/batch = 0.3083s	
555/2700 (epoch 10.278), train_loss = 2.64042837, grad/param norm = 3.9958e-01, time/batch = 0.2954s	
556/2700 (epoch 10.296), train_loss = 2.66714869, grad/param norm = 4.5888e-01, time/batch = 0.3232s	
557/2700 (epoch 10.315), train_loss = 2.68134824, grad/param norm = 3.5734e-01, time/batch = 0.3249s	
558/2700 (epoch 10.333), train_loss = 2.68186866, grad/param norm = 4.0038e-01, time/batch = 0.3147s	
559/2700 (epoch 10.352), train_loss = 2.82528270, grad/param norm = 1.1833e+00, time/batch = 0.3321s	
560/2700 (epoch 10.370), train_loss = 2.75844932, grad/param norm = 4.9882e-01, time/batch = 0.3109s	
561/2700 (epoch 10.389), train_loss = 2.61050311, grad/param norm = 2.1432e-01, time/batch = 0.2988s	
562/2700 (epoch 10.407), train_loss = 2.63451247, grad/param norm = 1.9601e-01, time/batch = 0.3406s	
563/2700 (epoch 10.426), train_loss = 2.61781856, grad/param norm = 1.9422e-01, time/batch = 0.3242s	
564/2700 (epoch 10.444), train_loss = 2.52061732, grad/param norm = 1.6463e-01, time/batch = 0.2993s	
565/2700 (epoch 10.463), train_loss = 2.61238163, grad/param norm = 1.9342e-01, time/batch = 0.2956s	
566/2700 (epoch 10.481), train_loss = 2.63441249, grad/param norm = 2.0199e-01, time/batch = 0.3081s	
567/2700 (epoch 10.500), train_loss = 2.65440405, grad/param norm = 1.9862e-01, time/batch = 0.3141s	
568/2700 (epoch 10.519), train_loss = 2.61758159, grad/param norm = 2.2222e-01, time/batch = 0.3196s	
569/2700 (epoch 10.537), train_loss = 2.59285358, grad/param norm = 2.2958e-01, time/batch = 0.3266s	
570/2700 (epoch 10.556), train_loss = 2.58801507, grad/param norm = 1.7245e-01, time/batch = 0.3162s	
571/2700 (epoch 10.574), train_loss = 2.56945682, grad/param norm = 2.1762e-01, time/batch = 0.2561s	
572/2700 (epoch 10.593), train_loss = 2.55931165, grad/param norm = 2.4646e-01, time/batch = 0.3218s	
573/2700 (epoch 10.611), train_loss = 2.51960543, grad/param norm = 2.5651e-01, time/batch = 0.3051s	
574/2700 (epoch 10.630), train_loss = 2.54664721, grad/param norm = 2.6803e-01, time/batch = 0.3008s	
575/2700 (epoch 10.648), train_loss = 2.58283007, grad/param norm = 3.1125e-01, time/batch = 0.2987s	
576/2700 (epoch 10.667), train_loss = 2.54013098, grad/param norm = 3.6447e-01, time/batch = 0.2960s	
577/2700 (epoch 10.685), train_loss = 2.58375784, grad/param norm = 3.2007e-01, time/batch = 0.3027s	
578/2700 (epoch 10.704), train_loss = 2.56032838, grad/param norm = 2.7156e-01, time/batch = 0.3152s	
579/2700 (epoch 10.722), train_loss = 2.54929320, grad/param norm = 2.1833e-01, time/batch = 0.3152s	
580/2700 (epoch 10.741), train_loss = 2.68378070, grad/param norm = 1.9067e-01, time/batch = 0.3217s	
581/2700 (epoch 10.759), train_loss = 2.60515287, grad/param norm = 1.9994e-01, time/batch = 0.3238s	
582/2700 (epoch 10.778), train_loss = 2.61139460, grad/param norm = 2.4833e-01, time/batch = 0.3089s	
583/2700 (epoch 10.796), train_loss = 2.58389603, grad/param norm = 3.2041e-01, time/batch = 0.2903s	
584/2700 (epoch 10.815), train_loss = 2.59270594, grad/param norm = 4.4412e-01, time/batch = 0.3127s	
585/2700 (epoch 10.833), train_loss = 2.60231601, grad/param norm = 4.1819e-01, time/batch = 0.3101s	
586/2700 (epoch 10.852), train_loss = 2.59447039, grad/param norm = 2.7157e-01, time/batch = 0.3152s	
587/2700 (epoch 10.870), train_loss = 2.55413412, grad/param norm = 2.6041e-01, time/batch = 0.3097s	
588/2700 (epoch 10.889), train_loss = 2.56659702, grad/param norm = 3.1373e-01, time/batch = 0.3107s	
589/2700 (epoch 10.907), train_loss = 2.69470447, grad/param norm = 3.9266e-01, time/batch = 0.3141s	
590/2700 (epoch 10.926), train_loss = 2.62026600, grad/param norm = 4.1004e-01, time/batch = 0.3174s	
591/2700 (epoch 10.944), train_loss = 2.64061321, grad/param norm = 3.2799e-01, time/batch = 0.3287s	
592/2700 (epoch 10.963), train_loss = 2.65884723, grad/param norm = 2.2166e-01, time/batch = 0.2848s	
593/2700 (epoch 10.981), train_loss = 2.58364937, grad/param norm = 1.5635e-01, time/batch = 0.3237s	
decayed learning rate by a factor 0.97 to 0.0018818	
594/2700 (epoch 11.000), train_loss = 2.62041154, grad/param norm = 1.8371e-01, time/batch = 0.2844s	
595/2700 (epoch 11.019), train_loss = 2.58792226, grad/param norm = 1.9686e-01, time/batch = 0.3055s	
596/2700 (epoch 11.037), train_loss = 2.61821801, grad/param norm = 1.8372e-01, time/batch = 0.3194s	
597/2700 (epoch 11.056), train_loss = 2.57123429, grad/param norm = 2.7394e-01, time/batch = 0.3284s	
598/2700 (epoch 11.074), train_loss = 2.56831832, grad/param norm = 2.8520e-01, time/batch = 0.3220s	
599/2700 (epoch 11.093), train_loss = 2.59503942, grad/param norm = 2.3670e-01, time/batch = 0.3250s	
600/2700 (epoch 11.111), train_loss = 2.60060256, grad/param norm = 2.6594e-01, time/batch = 0.3311s	
601/2700 (epoch 11.130), train_loss = 2.61216455, grad/param norm = 3.3902e-01, time/batch = 0.3028s	
602/2700 (epoch 11.148), train_loss = 2.55440571, grad/param norm = 3.0291e-01, time/batch = 0.3289s	
603/2700 (epoch 11.167), train_loss = 2.58930367, grad/param norm = 2.4682e-01, time/batch = 0.3284s	
604/2700 (epoch 11.185), train_loss = 2.54920114, grad/param norm = 2.5907e-01, time/batch = 0.3200s	
605/2700 (epoch 11.204), train_loss = 2.49777979, grad/param norm = 2.4500e-01, time/batch = 0.2563s	
606/2700 (epoch 11.222), train_loss = 2.49025492, grad/param norm = 2.4247e-01, time/batch = 0.3327s	
607/2700 (epoch 11.241), train_loss = 2.50664744, grad/param norm = 3.3145e-01, time/batch = 0.3291s	
608/2700 (epoch 11.259), train_loss = 2.53681290, grad/param norm = 3.4283e-01, time/batch = 0.3300s	
609/2700 (epoch 11.278), train_loss = 2.57405111, grad/param norm = 2.8528e-01, time/batch = 0.3275s	
610/2700 (epoch 11.296), train_loss = 2.55962934, grad/param norm = 2.4869e-01, time/batch = 0.3119s	
611/2700 (epoch 11.315), train_loss = 2.58210142, grad/param norm = 2.1302e-01, time/batch = 0.3086s	
612/2700 (epoch 11.333), train_loss = 2.58657825, grad/param norm = 1.7276e-01, time/batch = 0.3255s	
613/2700 (epoch 11.352), train_loss = 2.60271717, grad/param norm = 1.7300e-01, time/batch = 0.3119s	
614/2700 (epoch 11.370), train_loss = 2.55416820, grad/param norm = 1.5363e-01, time/batch = 0.3008s	
615/2700 (epoch 11.389), train_loss = 2.52692943, grad/param norm = 1.9954e-01, time/batch = 0.3164s	
616/2700 (epoch 11.407), train_loss = 2.56858832, grad/param norm = 3.5988e-01, time/batch = 0.2878s	
617/2700 (epoch 11.426), train_loss = 2.60589738, grad/param norm = 4.8428e-01, time/batch = 0.3283s	
618/2700 (epoch 11.444), train_loss = 2.52973521, grad/param norm = 5.9207e-01, time/batch = 0.3393s	
619/2700 (epoch 11.463), train_loss = 2.61537692, grad/param norm = 4.9124e-01, time/batch = 0.3455s	
620/2700 (epoch 11.481), train_loss = 2.58248515, grad/param norm = 2.6297e-01, time/batch = 0.3317s	
621/2700 (epoch 11.500), train_loss = 2.60332532, grad/param norm = 2.5124e-01, time/batch = 0.3480s	
622/2700 (epoch 11.519), train_loss = 2.58373412, grad/param norm = 3.0503e-01, time/batch = 0.3259s	
623/2700 (epoch 11.537), train_loss = 2.57150574, grad/param norm = 3.5480e-01, time/batch = 0.3116s	
624/2700 (epoch 11.556), train_loss = 2.57733382, grad/param norm = 3.1030e-01, time/batch = 0.3190s	
625/2700 (epoch 11.574), train_loss = 2.53992070, grad/param norm = 2.5959e-01, time/batch = 0.3081s	
626/2700 (epoch 11.593), train_loss = 2.51192492, grad/param norm = 2.3394e-01, time/batch = 0.2977s	
627/2700 (epoch 11.611), train_loss = 2.47332907, grad/param norm = 2.5719e-01, time/batch = 0.2640s	
628/2700 (epoch 11.630), train_loss = 2.48991987, grad/param norm = 2.5161e-01, time/batch = 0.3366s	
629/2700 (epoch 11.648), train_loss = 2.50526852, grad/param norm = 1.6145e-01, time/batch = 0.3155s	
630/2700 (epoch 11.667), train_loss = 2.45762809, grad/param norm = 1.1312e-01, time/batch = 0.2955s	
631/2700 (epoch 11.685), train_loss = 2.50380177, grad/param norm = 1.4450e-01, time/batch = 0.3240s	
632/2700 (epoch 11.704), train_loss = 2.49804746, grad/param norm = 1.5298e-01, time/batch = 0.3164s	
633/2700 (epoch 11.722), train_loss = 2.49474170, grad/param norm = 1.6571e-01, time/batch = 0.3095s	
634/2700 (epoch 11.741), train_loss = 2.62999306, grad/param norm = 2.4164e-01, time/batch = 0.3085s	
635/2700 (epoch 11.759), train_loss = 2.56744654, grad/param norm = 3.3652e-01, time/batch = 0.2986s	
636/2700 (epoch 11.778), train_loss = 2.58212247, grad/param norm = 3.3757e-01, time/batch = 0.3005s	
637/2700 (epoch 11.796), train_loss = 2.52757308, grad/param norm = 2.6737e-01, time/batch = 0.3180s	
638/2700 (epoch 11.815), train_loss = 2.52505069, grad/param norm = 2.9488e-01, time/batch = 0.2957s	
639/2700 (epoch 11.833), train_loss = 2.53320610, grad/param norm = 3.5320e-01, time/batch = 0.3170s	
640/2700 (epoch 11.852), train_loss = 2.57038411, grad/param norm = 3.4464e-01, time/batch = 0.2747s	
641/2700 (epoch 11.870), train_loss = 2.51943507, grad/param norm = 2.4782e-01, time/batch = 0.3111s	
642/2700 (epoch 11.889), train_loss = 2.50996538, grad/param norm = 1.6750e-01, time/batch = 0.3101s	
643/2700 (epoch 11.907), train_loss = 2.61400443, grad/param norm = 2.2716e-01, time/batch = 0.2992s	
644/2700 (epoch 11.926), train_loss = 2.55238223, grad/param norm = 3.9655e-01, time/batch = 0.2977s	
645/2700 (epoch 11.944), train_loss = 2.58500101, grad/param norm = 4.6876e-01, time/batch = 0.3054s	
646/2700 (epoch 11.963), train_loss = 2.64130241, grad/param norm = 4.5664e-01, time/batch = 0.3078s	
647/2700 (epoch 11.981), train_loss = 2.57149135, grad/param norm = 3.4251e-01, time/batch = 0.3206s	
decayed learning rate by a factor 0.97 to 0.001825346	
648/2700 (epoch 12.000), train_loss = 2.60094409, grad/param norm = 2.4968e-01, time/batch = 0.3111s	
649/2700 (epoch 12.019), train_loss = 2.56876604, grad/param norm = 2.4789e-01, time/batch = 0.3069s	
650/2700 (epoch 12.037), train_loss = 2.60142465, grad/param norm = 2.7733e-01, time/batch = 0.2713s	
651/2700 (epoch 12.056), train_loss = 2.54837040, grad/param norm = 2.6241e-01, time/batch = 0.3232s	
652/2700 (epoch 12.074), train_loss = 2.52735795, grad/param norm = 2.2900e-01, time/batch = 0.3092s	
653/2700 (epoch 12.093), train_loss = 2.57220493, grad/param norm = 2.3206e-01, time/batch = 0.2998s	
654/2700 (epoch 12.111), train_loss = 2.56194283, grad/param norm = 2.0237e-01, time/batch = 0.2997s	
655/2700 (epoch 12.130), train_loss = 2.55356429, grad/param norm = 1.6893e-01, time/batch = 0.2987s	
656/2700 (epoch 12.148), train_loss = 2.49978781, grad/param norm = 2.2752e-01, time/batch = 0.3173s	
657/2700 (epoch 12.167), train_loss = 2.54576351, grad/param norm = 2.9108e-01, time/batch = 0.3183s	
658/2700 (epoch 12.185), train_loss = 2.50012678, grad/param norm = 2.8694e-01, time/batch = 0.3111s	
659/2700 (epoch 12.204), train_loss = 2.45654527, grad/param norm = 2.4345e-01, time/batch = 0.3228s	
660/2700 (epoch 12.222), train_loss = 2.43761210, grad/param norm = 2.5292e-01, time/batch = 0.3006s	
661/2700 (epoch 12.241), train_loss = 2.42888219, grad/param norm = 2.2101e-01, time/batch = 0.3143s	
662/2700 (epoch 12.259), train_loss = 2.43983247, grad/param norm = 2.0169e-01, time/batch = 0.3199s	
663/2700 (epoch 12.278), train_loss = 2.50636567, grad/param norm = 2.2371e-01, time/batch = 0.3078s	
664/2700 (epoch 12.296), train_loss = 2.50123195, grad/param norm = 2.3686e-01, time/batch = 0.3016s	
665/2700 (epoch 12.315), train_loss = 2.53517126, grad/param norm = 1.9141e-01, time/batch = 0.3002s	
666/2700 (epoch 12.333), train_loss = 2.53275177, grad/param norm = 1.4403e-01, time/batch = 0.3034s	
667/2700 (epoch 12.352), train_loss = 2.55906299, grad/param norm = 1.9100e-01, time/batch = 0.3160s	
668/2700 (epoch 12.370), train_loss = 2.53586506, grad/param norm = 2.8413e-01, time/batch = 0.3178s	
669/2700 (epoch 12.389), train_loss = 2.52539794, grad/param norm = 3.7164e-01, time/batch = 0.3172s	
670/2700 (epoch 12.407), train_loss = 2.54016054, grad/param norm = 4.4531e-01, time/batch = 0.2787s	
671/2700 (epoch 12.426), train_loss = 2.54935704, grad/param norm = 3.9542e-01, time/batch = 0.3174s	
672/2700 (epoch 12.444), train_loss = 2.44639807, grad/param norm = 2.9193e-01, time/batch = 0.3015s	
673/2700 (epoch 12.463), train_loss = 2.51530896, grad/param norm = 2.8525e-01, time/batch = 0.3087s	
674/2700 (epoch 12.481), train_loss = 2.55083320, grad/param norm = 3.0991e-01, time/batch = 0.3082s	
675/2700 (epoch 12.500), train_loss = 2.60733837, grad/param norm = 4.3658e-01, time/batch = 0.3123s	
676/2700 (epoch 12.519), train_loss = 2.59012509, grad/param norm = 4.0520e-01, time/batch = 0.2687s	
677/2700 (epoch 12.537), train_loss = 2.51631752, grad/param norm = 2.5368e-01, time/batch = 0.3276s	
678/2700 (epoch 12.556), train_loss = 2.48855169, grad/param norm = 1.3872e-01, time/batch = 0.3166s	
679/2700 (epoch 12.574), train_loss = 2.46021650, grad/param norm = 1.3226e-01, time/batch = 0.3152s	
680/2700 (epoch 12.593), train_loss = 2.44797542, grad/param norm = 1.4687e-01, time/batch = 0.2745s	
681/2700 (epoch 12.611), train_loss = 2.41643634, grad/param norm = 2.0935e-01, time/batch = 0.3226s	
682/2700 (epoch 12.630), train_loss = 2.44126729, grad/param norm = 2.3472e-01, time/batch = 0.3133s	
683/2700 (epoch 12.648), train_loss = 2.46027525, grad/param norm = 1.9549e-01, time/batch = 0.2603s	
684/2700 (epoch 12.667), train_loss = 2.41568519, grad/param norm = 1.6202e-01, time/batch = 0.3251s	
685/2700 (epoch 12.685), train_loss = 2.46204154, grad/param norm = 2.0238e-01, time/batch = 0.3148s	
686/2700 (epoch 12.704), train_loss = 2.46807961, grad/param norm = 2.4314e-01, time/batch = 0.3226s	
687/2700 (epoch 12.722), train_loss = 2.46654087, grad/param norm = 3.1894e-01, time/batch = 0.3140s	
688/2700 (epoch 12.741), train_loss = 2.61248444, grad/param norm = 4.3017e-01, time/batch = 0.3114s	
689/2700 (epoch 12.759), train_loss = 2.56276436, grad/param norm = 5.9562e-01, time/batch = 0.3080s	
690/2700 (epoch 12.778), train_loss = 2.57415449, grad/param norm = 3.8148e-01, time/batch = 0.2587s	
691/2700 (epoch 12.796), train_loss = 2.49162557, grad/param norm = 2.9765e-01, time/batch = 0.3145s	
692/2700 (epoch 12.815), train_loss = 2.50896957, grad/param norm = 3.4030e-01, time/batch = 0.3030s	
693/2700 (epoch 12.833), train_loss = 2.50377308, grad/param norm = 3.8567e-01, time/batch = 0.2965s	
694/2700 (epoch 12.852), train_loss = 2.52900846, grad/param norm = 2.6643e-01, time/batch = 0.2681s	
695/2700 (epoch 12.870), train_loss = 2.46718637, grad/param norm = 1.6285e-01, time/batch = 0.3153s	
696/2700 (epoch 12.889), train_loss = 2.45980891, grad/param norm = 1.6692e-01, time/batch = 0.3220s	
697/2700 (epoch 12.907), train_loss = 2.58129864, grad/param norm = 2.3151e-01, time/batch = 0.3020s	
698/2700 (epoch 12.926), train_loss = 2.50363611, grad/param norm = 2.8658e-01, time/batch = 0.3042s	
699/2700 (epoch 12.944), train_loss = 2.51932661, grad/param norm = 2.5348e-01, time/batch = 0.3036s	
700/2700 (epoch 12.963), train_loss = 2.55499956, grad/param norm = 2.2744e-01, time/batch = 0.2742s	
701/2700 (epoch 12.981), train_loss = 2.48312708, grad/param norm = 1.7113e-01, time/batch = 0.3016s	
decayed learning rate by a factor 0.97 to 0.00177058562	
702/2700 (epoch 13.000), train_loss = 2.52319283, grad/param norm = 1.2388e-01, time/batch = 0.3064s	
703/2700 (epoch 13.019), train_loss = 2.50465235, grad/param norm = 1.6419e-01, time/batch = 0.3086s	
704/2700 (epoch 13.037), train_loss = 2.51858268, grad/param norm = 1.5454e-01, time/batch = 0.3096s	
705/2700 (epoch 13.056), train_loss = 2.47906270, grad/param norm = 1.7084e-01, time/batch = 0.3049s	
706/2700 (epoch 13.074), train_loss = 2.46816355, grad/param norm = 2.3866e-01, time/batch = 0.3116s	
707/2700 (epoch 13.093), train_loss = 2.52301236, grad/param norm = 3.3860e-01, time/batch = 0.3066s	
708/2700 (epoch 13.111), train_loss = 2.55150624, grad/param norm = 4.0009e-01, time/batch = 0.2992s	
709/2700 (epoch 13.130), train_loss = 2.56198296, grad/param norm = 3.5965e-01, time/batch = 0.2945s	
710/2700 (epoch 13.148), train_loss = 2.49886896, grad/param norm = 3.5326e-01, time/batch = 0.2884s	
711/2700 (epoch 13.167), train_loss = 2.53060382, grad/param norm = 3.3346e-01, time/batch = 0.3083s	
712/2700 (epoch 13.185), train_loss = 2.46168125, grad/param norm = 2.4800e-01, time/batch = 0.2996s	
713/2700 (epoch 13.204), train_loss = 2.41832529, grad/param norm = 2.1038e-01, time/batch = 0.2975s	
714/2700 (epoch 13.222), train_loss = 2.40095854, grad/param norm = 2.3916e-01, time/batch = 0.3130s	
715/2700 (epoch 13.241), train_loss = 2.38828879, grad/param norm = 2.3637e-01, time/batch = 0.3193s	
716/2700 (epoch 13.259), train_loss = 2.40669345, grad/param norm = 2.6088e-01, time/batch = 0.3225s	
717/2700 (epoch 13.278), train_loss = 2.47705158, grad/param norm = 2.9665e-01, time/batch = 0.3116s	
718/2700 (epoch 13.296), train_loss = 2.47153930, grad/param norm = 2.7455e-01, time/batch = 0.3064s	
719/2700 (epoch 13.315), train_loss = 2.49941465, grad/param norm = 2.2754e-01, time/batch = 0.2986s	
720/2700 (epoch 13.333), train_loss = 2.49836532, grad/param norm = 1.8383e-01, time/batch = 0.2769s	
721/2700 (epoch 13.352), train_loss = 2.51267198, grad/param norm = 1.8505e-01, time/batch = 0.3003s	
722/2700 (epoch 13.370), train_loss = 2.47717386, grad/param norm = 1.6293e-01, time/batch = 0.3013s	
723/2700 (epoch 13.389), train_loss = 2.45440199, grad/param norm = 1.8887e-01, time/batch = 0.2939s	
724/2700 (epoch 13.407), train_loss = 2.47280061, grad/param norm = 2.4421e-01, time/batch = 0.3034s	
725/2700 (epoch 13.426), train_loss = 2.49514223, grad/param norm = 2.7842e-01, time/batch = 0.3146s	
726/2700 (epoch 13.444), train_loss = 2.42392493, grad/param norm = 3.4220e-01, time/batch = 0.3198s	
727/2700 (epoch 13.463), train_loss = 2.49033181, grad/param norm = 3.6263e-01, time/batch = 0.3130s	
728/2700 (epoch 13.481), train_loss = 2.50341165, grad/param norm = 2.9096e-01, time/batch = 0.3070s	
729/2700 (epoch 13.500), train_loss = 2.52922026, grad/param norm = 2.6390e-01, time/batch = 0.2991s	
730/2700 (epoch 13.519), train_loss = 2.48270755, grad/param norm = 2.4409e-01, time/batch = 0.2619s	
731/2700 (epoch 13.537), train_loss = 2.46006285, grad/param norm = 2.5219e-01, time/batch = 0.3106s	
732/2700 (epoch 13.556), train_loss = 2.45855429, grad/param norm = 2.6971e-01, time/batch = 0.3164s	
733/2700 (epoch 13.574), train_loss = 2.44517464, grad/param norm = 3.1035e-01, time/batch = 0.3009s	
734/2700 (epoch 13.593), train_loss = 2.43771957, grad/param norm = 3.3732e-01, time/batch = 0.2986s	
735/2700 (epoch 13.611), train_loss = 2.40468019, grad/param norm = 3.8592e-01, time/batch = 0.3085s	
736/2700 (epoch 13.630), train_loss = 2.42212080, grad/param norm = 3.5559e-01, time/batch = 0.3092s	
737/2700 (epoch 13.648), train_loss = 2.43167448, grad/param norm = 2.1857e-01, time/batch = 0.3212s	
738/2700 (epoch 13.667), train_loss = 2.38127229, grad/param norm = 1.5113e-01, time/batch = 0.3223s	
739/2700 (epoch 13.685), train_loss = 2.42476246, grad/param norm = 1.9602e-01, time/batch = 0.2996s	
740/2700 (epoch 13.704), train_loss = 2.43119149, grad/param norm = 2.0266e-01, time/batch = 0.2545s	
741/2700 (epoch 13.722), train_loss = 2.42247389, grad/param norm = 1.8933e-01, time/batch = 0.3061s	
742/2700 (epoch 13.741), train_loss = 2.55141047, grad/param norm = 2.2312e-01, time/batch = 0.2970s	
743/2700 (epoch 13.759), train_loss = 2.49696837, grad/param norm = 2.7124e-01, time/batch = 0.3039s	
744/2700 (epoch 13.778), train_loss = 2.50133719, grad/param norm = 3.3472e-01, time/batch = 0.3033s	
745/2700 (epoch 13.796), train_loss = 2.45718207, grad/param norm = 3.4726e-01, time/batch = 0.3034s	
746/2700 (epoch 13.815), train_loss = 2.45512881, grad/param norm = 2.8775e-01, time/batch = 0.3103s	
747/2700 (epoch 13.833), train_loss = 2.43516191, grad/param norm = 2.2296e-01, time/batch = 0.3170s	
748/2700 (epoch 13.852), train_loss = 2.47222853, grad/param norm = 1.7824e-01, time/batch = 0.3241s	
749/2700 (epoch 13.870), train_loss = 2.42670843, grad/param norm = 1.8078e-01, time/batch = 0.3157s	
750/2700 (epoch 13.889), train_loss = 2.42699458, grad/param norm = 2.1835e-01, time/batch = 0.2633s	
751/2700 (epoch 13.907), train_loss = 2.55179330, grad/param norm = 2.6667e-01, time/batch = 0.3223s	
752/2700 (epoch 13.926), train_loss = 2.48949055, grad/param norm = 3.0528e-01, time/batch = 0.2768s	
753/2700 (epoch 13.944), train_loss = 2.53314791, grad/param norm = 3.4070e-01, time/batch = 0.2990s	
754/2700 (epoch 13.963), train_loss = 2.56004160, grad/param norm = 3.3146e-01, time/batch = 0.3046s	
755/2700 (epoch 13.981), train_loss = 2.47219525, grad/param norm = 3.5367e-01, time/batch = 0.3058s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
756/2700 (epoch 14.000), train_loss = 2.51548455, grad/param norm = 3.6346e-01, time/batch = 0.3125s	
757/2700 (epoch 14.019), train_loss = 2.48932744, grad/param norm = 3.0921e-01, time/batch = 0.3213s	
758/2700 (epoch 14.037), train_loss = 2.50045909, grad/param norm = 2.5699e-01, time/batch = 0.3140s	
759/2700 (epoch 14.056), train_loss = 2.45324867, grad/param norm = 2.4560e-01, time/batch = 0.3144s	
760/2700 (epoch 14.074), train_loss = 2.42511082, grad/param norm = 1.7523e-01, time/batch = 0.2852s	
761/2700 (epoch 14.093), train_loss = 2.46261576, grad/param norm = 1.3231e-01, time/batch = 0.3014s	
762/2700 (epoch 14.111), train_loss = 2.45851285, grad/param norm = 1.2990e-01, time/batch = 0.2991s	
763/2700 (epoch 14.130), train_loss = 2.46873591, grad/param norm = 1.3056e-01, time/batch = 0.2962s	
764/2700 (epoch 14.148), train_loss = 2.40628380, grad/param norm = 1.4260e-01, time/batch = 0.2973s	
765/2700 (epoch 14.167), train_loss = 2.46261824, grad/param norm = 1.9745e-01, time/batch = 0.3012s	
766/2700 (epoch 14.185), train_loss = 2.41934262, grad/param norm = 2.1437e-01, time/batch = 0.3124s	
767/2700 (epoch 14.204), train_loss = 2.38883661, grad/param norm = 2.0933e-01, time/batch = 0.3201s	
768/2700 (epoch 14.222), train_loss = 2.37173595, grad/param norm = 2.4456e-01, time/batch = 0.3173s	
769/2700 (epoch 14.241), train_loss = 2.35507260, grad/param norm = 2.6965e-01, time/batch = 0.3103s	
770/2700 (epoch 14.259), train_loss = 2.37840476, grad/param norm = 2.8078e-01, time/batch = 0.2743s	
771/2700 (epoch 14.278), train_loss = 2.43935299, grad/param norm = 2.9010e-01, time/batch = 0.2819s	
772/2700 (epoch 14.296), train_loss = 2.43411852, grad/param norm = 2.6070e-01, time/batch = 0.2691s	
773/2700 (epoch 14.315), train_loss = 2.46227912, grad/param norm = 2.2752e-01, time/batch = 0.3231s	
774/2700 (epoch 14.333), train_loss = 2.47651926, grad/param norm = 2.8864e-01, time/batch = 0.3303s	
775/2700 (epoch 14.352), train_loss = 2.52134851, grad/param norm = 3.8858e-01, time/batch = 0.3299s	
776/2700 (epoch 14.370), train_loss = 2.51869360, grad/param norm = 4.2653e-01, time/batch = 0.3211s	
777/2700 (epoch 14.389), train_loss = 2.46604145, grad/param norm = 3.5681e-01, time/batch = 0.3166s	
778/2700 (epoch 14.407), train_loss = 2.44903455, grad/param norm = 2.6851e-01, time/batch = 0.3195s	
779/2700 (epoch 14.426), train_loss = 2.44681328, grad/param norm = 1.9171e-01, time/batch = 0.3142s	
780/2700 (epoch 14.444), train_loss = 2.36665596, grad/param norm = 1.9909e-01, time/batch = 0.2505s	
781/2700 (epoch 14.463), train_loss = 2.42723711, grad/param norm = 2.4074e-01, time/batch = 0.3124s	
782/2700 (epoch 14.481), train_loss = 2.45297390, grad/param norm = 2.2084e-01, time/batch = 0.3093s	
783/2700 (epoch 14.500), train_loss = 2.47874204, grad/param norm = 2.1504e-01, time/batch = 0.2578s	
784/2700 (epoch 14.519), train_loss = 2.43589313, grad/param norm = 2.0064e-01, time/batch = 0.3289s	
785/2700 (epoch 14.537), train_loss = 2.42102989, grad/param norm = 1.8570e-01, time/batch = 0.3274s	
786/2700 (epoch 14.556), train_loss = 2.40965015, grad/param norm = 1.4226e-01, time/batch = 0.3109s	
787/2700 (epoch 14.574), train_loss = 2.38684699, grad/param norm = 1.7273e-01, time/batch = 0.3182s	
788/2700 (epoch 14.593), train_loss = 2.38003037, grad/param norm = 2.3003e-01, time/batch = 0.3154s	
789/2700 (epoch 14.611), train_loss = 2.35593181, grad/param norm = 4.1977e-01, time/batch = 0.2981s	
790/2700 (epoch 14.630), train_loss = 2.41105622, grad/param norm = 4.6293e-01, time/batch = 0.2688s	
791/2700 (epoch 14.648), train_loss = 2.40729293, grad/param norm = 3.3356e-01, time/batch = 0.3143s	
792/2700 (epoch 14.667), train_loss = 2.36106596, grad/param norm = 2.5052e-01, time/batch = 0.3013s	
793/2700 (epoch 14.685), train_loss = 2.40068662, grad/param norm = 2.2023e-01, time/batch = 0.3054s	
794/2700 (epoch 14.704), train_loss = 2.41672385, grad/param norm = 2.4192e-01, time/batch = 0.2830s	
795/2700 (epoch 14.722), train_loss = 2.40444567, grad/param norm = 2.5505e-01, time/batch = 0.3277s	
796/2700 (epoch 14.741), train_loss = 2.52573962, grad/param norm = 2.7609e-01, time/batch = 0.3328s	
797/2700 (epoch 14.759), train_loss = 2.46564671, grad/param norm = 2.4587e-01, time/batch = 0.3174s	
798/2700 (epoch 14.778), train_loss = 2.46641514, grad/param norm = 2.4972e-01, time/batch = 0.3086s	
799/2700 (epoch 14.796), train_loss = 2.41579745, grad/param norm = 2.8824e-01, time/batch = 0.3029s	
800/2700 (epoch 14.815), train_loss = 2.43729615, grad/param norm = 2.7645e-01, time/batch = 0.2793s	
801/2700 (epoch 14.833), train_loss = 2.41434066, grad/param norm = 2.5253e-01, time/batch = 0.3006s	
802/2700 (epoch 14.852), train_loss = 2.44238272, grad/param norm = 1.7698e-01, time/batch = 0.3035s	
803/2700 (epoch 14.870), train_loss = 2.38926918, grad/param norm = 1.2418e-01, time/batch = 0.3123s	
804/2700 (epoch 14.889), train_loss = 2.38371128, grad/param norm = 1.3604e-01, time/batch = 0.3217s	
805/2700 (epoch 14.907), train_loss = 2.50747707, grad/param norm = 1.5907e-01, time/batch = 0.3156s	
806/2700 (epoch 14.926), train_loss = 2.43144698, grad/param norm = 1.9066e-01, time/batch = 0.3105s	
807/2700 (epoch 14.944), train_loss = 2.44737049, grad/param norm = 1.6254e-01, time/batch = 0.2959s	
808/2700 (epoch 14.963), train_loss = 2.48005644, grad/param norm = 1.3073e-01, time/batch = 0.2994s	
809/2700 (epoch 14.981), train_loss = 2.40939433, grad/param norm = 1.3204e-01, time/batch = 0.2873s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
810/2700 (epoch 15.000), train_loss = 2.44856286, grad/param norm = 1.1876e-01, time/batch = 0.2763s	
811/2700 (epoch 15.019), train_loss = 2.44456163, grad/param norm = 1.7578e-01, time/batch = 0.3018s	
812/2700 (epoch 15.037), train_loss = 2.45687680, grad/param norm = 2.1954e-01, time/batch = 0.3107s	
813/2700 (epoch 15.056), train_loss = 2.42337410, grad/param norm = 2.4005e-01, time/batch = 0.3197s	
814/2700 (epoch 15.074), train_loss = 2.40762251, grad/param norm = 3.1471e-01, time/batch = 0.3178s	
815/2700 (epoch 15.093), train_loss = 2.48126996, grad/param norm = 4.3240e-01, time/batch = 0.3091s	
816/2700 (epoch 15.111), train_loss = 2.48000397, grad/param norm = 3.7897e-01, time/batch = 0.3257s	
817/2700 (epoch 15.130), train_loss = 2.46584939, grad/param norm = 2.6046e-01, time/batch = 0.2790s	
818/2700 (epoch 15.148), train_loss = 2.39372657, grad/param norm = 2.5036e-01, time/batch = 0.3090s	
819/2700 (epoch 15.167), train_loss = 2.44331900, grad/param norm = 2.6851e-01, time/batch = 0.3180s	
820/2700 (epoch 15.185), train_loss = 2.38917004, grad/param norm = 2.5072e-01, time/batch = 0.2789s	
821/2700 (epoch 15.204), train_loss = 2.36246341, grad/param norm = 2.4620e-01, time/batch = 0.3291s	
822/2700 (epoch 15.222), train_loss = 2.34557374, grad/param norm = 2.6291e-01, time/batch = 0.3196s	
823/2700 (epoch 15.241), train_loss = 2.32538712, grad/param norm = 2.7320e-01, time/batch = 0.3083s	
824/2700 (epoch 15.259), train_loss = 2.35387220, grad/param norm = 2.8497e-01, time/batch = 0.3154s	
825/2700 (epoch 15.278), train_loss = 2.41137291, grad/param norm = 2.5836e-01, time/batch = 0.2997s	
826/2700 (epoch 15.296), train_loss = 2.39791893, grad/param norm = 2.0273e-01, time/batch = 0.2947s	
827/2700 (epoch 15.315), train_loss = 2.42284818, grad/param norm = 1.7829e-01, time/batch = 0.2986s	
828/2700 (epoch 15.333), train_loss = 2.42460557, grad/param norm = 1.4425e-01, time/batch = 0.2854s	
829/2700 (epoch 15.352), train_loss = 2.42579657, grad/param norm = 1.3987e-01, time/batch = 0.3315s	
830/2700 (epoch 15.370), train_loss = 2.41045186, grad/param norm = 1.4152e-01, time/batch = 0.2799s	
831/2700 (epoch 15.389), train_loss = 2.38632432, grad/param norm = 1.9179e-01, time/batch = 0.3315s	
832/2700 (epoch 15.407), train_loss = 2.40191881, grad/param norm = 2.4438e-01, time/batch = 0.3296s	
833/2700 (epoch 15.426), train_loss = 2.42023474, grad/param norm = 2.4235e-01, time/batch = 0.3255s	
834/2700 (epoch 15.444), train_loss = 2.34438833, grad/param norm = 2.8390e-01, time/batch = 0.3098s	
835/2700 (epoch 15.463), train_loss = 2.40382288, grad/param norm = 3.2280e-01, time/batch = 0.3079s	
836/2700 (epoch 15.481), train_loss = 2.42324116, grad/param norm = 2.5335e-01, time/batch = 0.3160s	
837/2700 (epoch 15.500), train_loss = 2.44206409, grad/param norm = 2.4211e-01, time/batch = 0.3109s	
838/2700 (epoch 15.519), train_loss = 2.41607615, grad/param norm = 2.8256e-01, time/batch = 0.2805s	
839/2700 (epoch 15.537), train_loss = 2.41838959, grad/param norm = 2.8684e-01, time/batch = 0.3073s	
840/2700 (epoch 15.556), train_loss = 2.40037332, grad/param norm = 2.3882e-01, time/batch = 0.3212s	
841/2700 (epoch 15.574), train_loss = 2.38255407, grad/param norm = 2.3321e-01, time/batch = 0.3498s	
842/2700 (epoch 15.593), train_loss = 2.36614625, grad/param norm = 2.3501e-01, time/batch = 0.3391s	
843/2700 (epoch 15.611), train_loss = 2.32407034, grad/param norm = 2.9719e-01, time/batch = 0.3245s	
844/2700 (epoch 15.630), train_loss = 2.34775720, grad/param norm = 3.1165e-01, time/batch = 0.3192s	
845/2700 (epoch 15.648), train_loss = 2.36269450, grad/param norm = 2.2672e-01, time/batch = 0.3077s	
846/2700 (epoch 15.667), train_loss = 2.31580730, grad/param norm = 1.3076e-01, time/batch = 0.3022s	
847/2700 (epoch 15.685), train_loss = 2.35235145, grad/param norm = 1.5074e-01, time/batch = 0.3064s	
848/2700 (epoch 15.704), train_loss = 2.37214454, grad/param norm = 1.3684e-01, time/batch = 0.3146s	
849/2700 (epoch 15.722), train_loss = 2.35068252, grad/param norm = 1.0558e-01, time/batch = 0.3203s	
850/2700 (epoch 15.741), train_loss = 2.46869957, grad/param norm = 1.3020e-01, time/batch = 0.3324s	
851/2700 (epoch 15.759), train_loss = 2.41821124, grad/param norm = 1.5931e-01, time/batch = 0.3396s	
852/2700 (epoch 15.778), train_loss = 2.42752329, grad/param norm = 2.3205e-01, time/batch = 0.3223s	
853/2700 (epoch 15.796), train_loss = 2.38452664, grad/param norm = 3.1493e-01, time/batch = 0.3096s	
854/2700 (epoch 15.815), train_loss = 2.41262738, grad/param norm = 3.5539e-01, time/batch = 0.3155s	
855/2700 (epoch 15.833), train_loss = 2.39428410, grad/param norm = 3.0795e-01, time/batch = 0.3147s	
856/2700 (epoch 15.852), train_loss = 2.41695108, grad/param norm = 2.2589e-01, time/batch = 0.3152s	
857/2700 (epoch 15.870), train_loss = 2.37989318, grad/param norm = 2.7141e-01, time/batch = 0.2984s	
858/2700 (epoch 15.889), train_loss = 2.39413517, grad/param norm = 3.5786e-01, time/batch = 0.3045s	
859/2700 (epoch 15.907), train_loss = 2.52008246, grad/param norm = 3.2717e-01, time/batch = 0.2797s	
860/2700 (epoch 15.926), train_loss = 2.41979688, grad/param norm = 2.3550e-01, time/batch = 0.3264s	
861/2700 (epoch 15.944), train_loss = 2.43085721, grad/param norm = 1.9825e-01, time/batch = 0.2789s	
862/2700 (epoch 15.963), train_loss = 2.45457027, grad/param norm = 1.4485e-01, time/batch = 0.3373s	
863/2700 (epoch 15.981), train_loss = 2.37813544, grad/param norm = 1.2285e-01, time/batch = 0.3131s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
864/2700 (epoch 16.000), train_loss = 2.41653445, grad/param norm = 1.2331e-01, time/batch = 0.3103s	
865/2700 (epoch 16.019), train_loss = 2.41475919, grad/param norm = 1.4105e-01, time/batch = 0.3167s	
866/2700 (epoch 16.037), train_loss = 2.42068563, grad/param norm = 1.5955e-01, time/batch = 0.3163s	
867/2700 (epoch 16.056), train_loss = 2.39123036, grad/param norm = 2.4838e-01, time/batch = 0.3040s	
868/2700 (epoch 16.074), train_loss = 2.36779892, grad/param norm = 2.4826e-01, time/batch = 0.2996s	
869/2700 (epoch 16.093), train_loss = 2.40548512, grad/param norm = 2.0748e-01, time/batch = 0.2781s	
870/2700 (epoch 16.111), train_loss = 2.40356043, grad/param norm = 2.3750e-01, time/batch = 0.3216s	
871/2700 (epoch 16.130), train_loss = 2.43721767, grad/param norm = 2.9053e-01, time/batch = 0.3025s	
872/2700 (epoch 16.148), train_loss = 2.36019672, grad/param norm = 2.6292e-01, time/batch = 0.2839s	
873/2700 (epoch 16.167), train_loss = 2.42025022, grad/param norm = 2.5643e-01, time/batch = 0.3231s	
874/2700 (epoch 16.185), train_loss = 2.36965413, grad/param norm = 2.4666e-01, time/batch = 0.2838s	
875/2700 (epoch 16.204), train_loss = 2.33742473, grad/param norm = 1.7470e-01, time/batch = 0.3212s	
876/2700 (epoch 16.222), train_loss = 2.31337174, grad/param norm = 1.4547e-01, time/batch = 0.3060s	
877/2700 (epoch 16.241), train_loss = 2.28088757, grad/param norm = 1.5377e-01, time/batch = 0.2988s	
878/2700 (epoch 16.259), train_loss = 2.31549737, grad/param norm = 2.0775e-01, time/batch = 0.2978s	
879/2700 (epoch 16.278), train_loss = 2.37539714, grad/param norm = 2.3154e-01, time/batch = 0.2847s	
880/2700 (epoch 16.296), train_loss = 2.36699565, grad/param norm = 2.5327e-01, time/batch = 0.3323s	
881/2700 (epoch 16.315), train_loss = 2.39595086, grad/param norm = 2.5451e-01, time/batch = 0.3115s	
882/2700 (epoch 16.333), train_loss = 2.39556848, grad/param norm = 2.1171e-01, time/batch = 0.3148s	
883/2700 (epoch 16.352), train_loss = 2.39843049, grad/param norm = 2.3254e-01, time/batch = 0.3086s	
884/2700 (epoch 16.370), train_loss = 2.40116607, grad/param norm = 3.3028e-01, time/batch = 0.2879s	
885/2700 (epoch 16.389), train_loss = 2.39511294, grad/param norm = 4.1599e-01, time/batch = 0.2652s	
886/2700 (epoch 16.407), train_loss = 2.41219619, grad/param norm = 3.9788e-01, time/batch = 0.3009s	
887/2700 (epoch 16.426), train_loss = 2.41556055, grad/param norm = 2.4143e-01, time/batch = 0.2974s	
888/2700 (epoch 16.444), train_loss = 2.32072306, grad/param norm = 1.8895e-01, time/batch = 0.2943s	
889/2700 (epoch 16.463), train_loss = 2.36702728, grad/param norm = 2.2936e-01, time/batch = 0.2948s	
890/2700 (epoch 16.481), train_loss = 2.39598260, grad/param norm = 2.2023e-01, time/batch = 0.3334s	
891/2700 (epoch 16.500), train_loss = 2.40428878, grad/param norm = 2.1475e-01, time/batch = 0.3003s	
892/2700 (epoch 16.519), train_loss = 2.36718485, grad/param norm = 1.9445e-01, time/batch = 0.3192s	
893/2700 (epoch 16.537), train_loss = 2.35779663, grad/param norm = 1.6835e-01, time/batch = 0.3205s	
894/2700 (epoch 16.556), train_loss = 2.34752213, grad/param norm = 1.0875e-01, time/batch = 0.3067s	
895/2700 (epoch 16.574), train_loss = 2.33522907, grad/param norm = 1.3186e-01, time/batch = 0.2960s	
896/2700 (epoch 16.593), train_loss = 2.32912886, grad/param norm = 1.3616e-01, time/batch = 0.3061s	
897/2700 (epoch 16.611), train_loss = 2.27463998, grad/param norm = 1.7603e-01, time/batch = 0.3024s	
898/2700 (epoch 16.630), train_loss = 2.30485464, grad/param norm = 1.9843e-01, time/batch = 0.2985s	
899/2700 (epoch 16.648), train_loss = 2.32515685, grad/param norm = 2.0520e-01, time/batch = 0.2879s	
900/2700 (epoch 16.667), train_loss = 2.29336162, grad/param norm = 2.1824e-01, time/batch = 0.3312s	
901/2700 (epoch 16.685), train_loss = 2.33595015, grad/param norm = 2.8152e-01, time/batch = 0.3076s	
902/2700 (epoch 16.704), train_loss = 2.39180499, grad/param norm = 3.9886e-01, time/batch = 0.3122s	
903/2700 (epoch 16.722), train_loss = 2.38423839, grad/param norm = 4.0244e-01, time/batch = 0.3157s	
904/2700 (epoch 16.741), train_loss = 2.48203543, grad/param norm = 3.0573e-01, time/batch = 0.3168s	
905/2700 (epoch 16.759), train_loss = 2.43179687, grad/param norm = 3.0472e-01, time/batch = 0.3202s	
906/2700 (epoch 16.778), train_loss = 2.43048187, grad/param norm = 3.2823e-01, time/batch = 0.3096s	
907/2700 (epoch 16.796), train_loss = 2.35749822, grad/param norm = 2.7850e-01, time/batch = 0.3037s	
908/2700 (epoch 16.815), train_loss = 2.36489398, grad/param norm = 1.8553e-01, time/batch = 0.3021s	
909/2700 (epoch 16.833), train_loss = 2.33407810, grad/param norm = 1.4382e-01, time/batch = 0.2932s	
910/2700 (epoch 16.852), train_loss = 2.37162964, grad/param norm = 1.0711e-01, time/batch = 0.3288s	
911/2700 (epoch 16.870), train_loss = 2.33382135, grad/param norm = 1.0141e-01, time/batch = 0.3345s	
912/2700 (epoch 16.889), train_loss = 2.32438443, grad/param norm = 1.4760e-01, time/batch = 0.3252s	
913/2700 (epoch 16.907), train_loss = 2.45878635, grad/param norm = 1.7718e-01, time/batch = 0.3229s	
914/2700 (epoch 16.926), train_loss = 2.37901847, grad/param norm = 2.2041e-01, time/batch = 0.3143s	
915/2700 (epoch 16.944), train_loss = 2.39258259, grad/param norm = 2.3483e-01, time/batch = 0.3381s	
916/2700 (epoch 16.963), train_loss = 2.42463121, grad/param norm = 2.7384e-01, time/batch = 0.3325s	
917/2700 (epoch 16.981), train_loss = 2.36732374, grad/param norm = 3.0175e-01, time/batch = 0.3140s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
918/2700 (epoch 17.000), train_loss = 2.40579062, grad/param norm = 2.4746e-01, time/batch = 0.3013s	
919/2700 (epoch 17.019), train_loss = 2.40911200, grad/param norm = 2.6928e-01, time/batch = 0.3126s	
920/2700 (epoch 17.037), train_loss = 2.41787790, grad/param norm = 2.5710e-01, time/batch = 0.3181s	
921/2700 (epoch 17.056), train_loss = 2.37248065, grad/param norm = 2.3931e-01, time/batch = 0.3062s	
922/2700 (epoch 17.074), train_loss = 2.33076149, grad/param norm = 2.0403e-01, time/batch = 0.3198s	
923/2700 (epoch 17.093), train_loss = 2.37641129, grad/param norm = 1.9452e-01, time/batch = 0.2953s	
924/2700 (epoch 17.111), train_loss = 2.34488880, grad/param norm = 1.5992e-01, time/batch = 0.3257s	
925/2700 (epoch 17.130), train_loss = 2.36864882, grad/param norm = 1.4449e-01, time/batch = 0.3182s	
926/2700 (epoch 17.148), train_loss = 2.32028124, grad/param norm = 2.4492e-01, time/batch = 0.3283s	
927/2700 (epoch 17.167), train_loss = 2.38941704, grad/param norm = 3.2103e-01, time/batch = 0.3170s	
928/2700 (epoch 17.185), train_loss = 2.33645848, grad/param norm = 2.8322e-01, time/batch = 0.3209s	
929/2700 (epoch 17.204), train_loss = 2.31068994, grad/param norm = 2.2078e-01, time/batch = 0.3249s	
930/2700 (epoch 17.222), train_loss = 2.29116250, grad/param norm = 1.9498e-01, time/batch = 0.3056s	
931/2700 (epoch 17.241), train_loss = 2.25326953, grad/param norm = 1.8475e-01, time/batch = 0.3286s	
932/2700 (epoch 17.259), train_loss = 2.27990633, grad/param norm = 1.7399e-01, time/batch = 0.2962s	
933/2700 (epoch 17.278), train_loss = 2.33326539, grad/param norm = 1.4225e-01, time/batch = 0.3123s	
934/2700 (epoch 17.296), train_loss = 2.32280707, grad/param norm = 9.2344e-02, time/batch = 0.3199s	
935/2700 (epoch 17.315), train_loss = 2.34700092, grad/param norm = 1.0924e-01, time/batch = 0.3033s	
936/2700 (epoch 17.333), train_loss = 2.36983065, grad/param norm = 1.7509e-01, time/batch = 0.3044s	
937/2700 (epoch 17.352), train_loss = 2.38479625, grad/param norm = 2.9073e-01, time/batch = 0.3168s	
938/2700 (epoch 17.370), train_loss = 2.41445518, grad/param norm = 3.4378e-01, time/batch = 0.2977s	
939/2700 (epoch 17.389), train_loss = 2.37459326, grad/param norm = 3.5371e-01, time/batch = 0.3301s	
940/2700 (epoch 17.407), train_loss = 2.36819915, grad/param norm = 3.1643e-01, time/batch = 0.3189s	
941/2700 (epoch 17.426), train_loss = 2.37347104, grad/param norm = 2.2394e-01, time/batch = 0.3041s	
942/2700 (epoch 17.444), train_loss = 2.28594274, grad/param norm = 1.8324e-01, time/batch = 0.3143s	
943/2700 (epoch 17.463), train_loss = 2.32573405, grad/param norm = 2.0504e-01, time/batch = 0.3043s	
944/2700 (epoch 17.481), train_loss = 2.35098444, grad/param norm = 1.9153e-01, time/batch = 0.3003s	
945/2700 (epoch 17.500), train_loss = 2.36635160, grad/param norm = 2.0401e-01, time/batch = 0.3053s	
946/2700 (epoch 17.519), train_loss = 2.33663229, grad/param norm = 2.1223e-01, time/batch = 0.3078s	
947/2700 (epoch 17.537), train_loss = 2.33819497, grad/param norm = 1.9083e-01, time/batch = 0.3178s	
948/2700 (epoch 17.556), train_loss = 2.31806613, grad/param norm = 1.2418e-01, time/batch = 0.2965s	
949/2700 (epoch 17.574), train_loss = 2.30700863, grad/param norm = 1.3811e-01, time/batch = 0.3089s	
950/2700 (epoch 17.593), train_loss = 2.29231721, grad/param norm = 1.2967e-01, time/batch = 0.3223s	
951/2700 (epoch 17.611), train_loss = 2.23619912, grad/param norm = 1.1938e-01, time/batch = 0.3226s	
952/2700 (epoch 17.630), train_loss = 2.26436720, grad/param norm = 1.3156e-01, time/batch = 0.3243s	
953/2700 (epoch 17.648), train_loss = 2.29197798, grad/param norm = 1.4248e-01, time/batch = 0.3188s	
954/2700 (epoch 17.667), train_loss = 2.27206882, grad/param norm = 1.7460e-01, time/batch = 0.3015s	
955/2700 (epoch 17.685), train_loss = 2.31872912, grad/param norm = 2.3448e-01, time/batch = 0.2981s	
956/2700 (epoch 17.704), train_loss = 2.34840408, grad/param norm = 2.2306e-01, time/batch = 0.2963s	
957/2700 (epoch 17.722), train_loss = 2.31805052, grad/param norm = 1.7811e-01, time/batch = 0.3060s	
958/2700 (epoch 17.741), train_loss = 2.41461571, grad/param norm = 1.9165e-01, time/batch = 0.3031s	
959/2700 (epoch 17.759), train_loss = 2.38131673, grad/param norm = 2.0766e-01, time/batch = 0.3479s	
960/2700 (epoch 17.778), train_loss = 2.37679618, grad/param norm = 1.9237e-01, time/batch = 0.3041s	
961/2700 (epoch 17.796), train_loss = 2.31790863, grad/param norm = 2.3962e-01, time/batch = 0.3322s	
962/2700 (epoch 17.815), train_loss = 2.36585517, grad/param norm = 2.9668e-01, time/batch = 0.3356s	
963/2700 (epoch 17.833), train_loss = 2.34087213, grad/param norm = 3.4229e-01, time/batch = 0.3336s	
964/2700 (epoch 17.852), train_loss = 2.40027723, grad/param norm = 4.0930e-01, time/batch = 0.3255s	
965/2700 (epoch 17.870), train_loss = 2.36217609, grad/param norm = 4.0467e-01, time/batch = 0.3115s	
966/2700 (epoch 17.889), train_loss = 2.32042521, grad/param norm = 2.9839e-01, time/batch = 0.3089s	
967/2700 (epoch 17.907), train_loss = 2.43187237, grad/param norm = 2.1395e-01, time/batch = 0.3177s	
968/2700 (epoch 17.926), train_loss = 2.35353437, grad/param norm = 1.8180e-01, time/batch = 0.3086s	
969/2700 (epoch 17.944), train_loss = 2.35871809, grad/param norm = 1.6648e-01, time/batch = 0.3054s	
970/2700 (epoch 17.963), train_loss = 2.39149066, grad/param norm = 1.6714e-01, time/batch = 0.3225s	
971/2700 (epoch 17.981), train_loss = 2.34251172, grad/param norm = 2.4232e-01, time/batch = 0.3118s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
972/2700 (epoch 18.000), train_loss = 2.38451874, grad/param norm = 2.9248e-01, time/batch = 0.3331s	
973/2700 (epoch 18.019), train_loss = 2.38170531, grad/param norm = 3.2475e-01, time/batch = 0.3364s	
974/2700 (epoch 18.037), train_loss = 2.38463645, grad/param norm = 3.1872e-01, time/batch = 0.3495s	
975/2700 (epoch 18.056), train_loss = 2.35157416, grad/param norm = 2.8291e-01, time/batch = 0.3379s	
976/2700 (epoch 18.074), train_loss = 2.29893654, grad/param norm = 1.7079e-01, time/batch = 0.3183s	
977/2700 (epoch 18.093), train_loss = 2.34173259, grad/param norm = 1.4986e-01, time/batch = 0.3021s	
978/2700 (epoch 18.111), train_loss = 2.32052181, grad/param norm = 1.6516e-01, time/batch = 0.3034s	
979/2700 (epoch 18.130), train_loss = 2.35186348, grad/param norm = 1.7606e-01, time/batch = 0.3127s	
980/2700 (epoch 18.148), train_loss = 2.29866701, grad/param norm = 2.3010e-01, time/batch = 0.3171s	
981/2700 (epoch 18.167), train_loss = 2.35728536, grad/param norm = 2.6334e-01, time/batch = 0.2994s	
982/2700 (epoch 18.185), train_loss = 2.30983254, grad/param norm = 2.3565e-01, time/batch = 0.2938s	
983/2700 (epoch 18.204), train_loss = 2.28412102, grad/param norm = 2.1960e-01, time/batch = 0.3286s	
984/2700 (epoch 18.222), train_loss = 2.27490161, grad/param norm = 2.3802e-01, time/batch = 0.3114s	
985/2700 (epoch 18.241), train_loss = 2.23971917, grad/param norm = 2.4612e-01, time/batch = 0.3188s	
986/2700 (epoch 18.259), train_loss = 2.26125442, grad/param norm = 2.1028e-01, time/batch = 0.3184s	
987/2700 (epoch 18.278), train_loss = 2.31474040, grad/param norm = 1.7521e-01, time/batch = 0.2841s	
988/2700 (epoch 18.296), train_loss = 2.31809083, grad/param norm = 1.9800e-01, time/batch = 0.3072s	
989/2700 (epoch 18.315), train_loss = 2.34216662, grad/param norm = 2.9317e-01, time/batch = 0.3056s	
990/2700 (epoch 18.333), train_loss = 2.37947055, grad/param norm = 3.6843e-01, time/batch = 0.3151s	
991/2700 (epoch 18.352), train_loss = 2.36428934, grad/param norm = 3.9096e-01, time/batch = 0.2975s	
992/2700 (epoch 18.370), train_loss = 2.36757034, grad/param norm = 2.7635e-01, time/batch = 0.3076s	
993/2700 (epoch 18.389), train_loss = 2.31808722, grad/param norm = 2.4747e-01, time/batch = 0.2999s	
994/2700 (epoch 18.407), train_loss = 2.32526332, grad/param norm = 2.0582e-01, time/batch = 0.3369s	
995/2700 (epoch 18.426), train_loss = 2.33559124, grad/param norm = 1.4910e-01, time/batch = 0.3199s	
996/2700 (epoch 18.444), train_loss = 2.25918357, grad/param norm = 1.3897e-01, time/batch = 0.3112s	
997/2700 (epoch 18.463), train_loss = 2.29832752, grad/param norm = 1.6180e-01, time/batch = 0.2794s	
998/2700 (epoch 18.481), train_loss = 2.31954057, grad/param norm = 1.3304e-01, time/batch = 0.3056s	
999/2700 (epoch 18.500), train_loss = 2.32590346, grad/param norm = 1.5409e-01, time/batch = 0.3078s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch18.52_2.3678.t7	
1000/2700 (epoch 18.519), train_loss = 2.29953641, grad/param norm = 1.6936e-01, time/batch = 0.3216s	
1001/2700 (epoch 18.537), train_loss = 2.37081817, grad/param norm = 1.9725e-01, time/batch = 0.3044s	
1002/2700 (epoch 18.556), train_loss = 2.32020760, grad/param norm = 2.2177e-01, time/batch = 0.2524s	
1003/2700 (epoch 18.574), train_loss = 2.30983895, grad/param norm = 3.0040e-01, time/batch = 0.3242s	
1004/2700 (epoch 18.593), train_loss = 2.31192111, grad/param norm = 3.3184e-01, time/batch = 0.3294s	
1005/2700 (epoch 18.611), train_loss = 2.26127029, grad/param norm = 3.1074e-01, time/batch = 0.2674s	
1006/2700 (epoch 18.630), train_loss = 2.28716235, grad/param norm = 3.5255e-01, time/batch = 0.3066s	
1007/2700 (epoch 18.648), train_loss = 2.33050452, grad/param norm = 3.4350e-01, time/batch = 0.3082s	
1008/2700 (epoch 18.667), train_loss = 2.30478026, grad/param norm = 3.4399e-01, time/batch = 0.3144s	
1009/2700 (epoch 18.685), train_loss = 2.31729269, grad/param norm = 3.5049e-01, time/batch = 0.3178s	
1010/2700 (epoch 18.704), train_loss = 2.33454065, grad/param norm = 2.9834e-01, time/batch = 0.3248s	
1011/2700 (epoch 18.722), train_loss = 2.27255840, grad/param norm = 2.1623e-01, time/batch = 0.3040s	
1012/2700 (epoch 18.741), train_loss = 2.39529567, grad/param norm = 3.7227e+00, time/batch = 0.3015s	
1013/2700 (epoch 18.759), train_loss = 2.35956138, grad/param norm = 1.3780e-01, time/batch = 0.2801s	
1014/2700 (epoch 18.778), train_loss = 2.33649075, grad/param norm = 1.3286e-01, time/batch = 0.3297s	
1015/2700 (epoch 18.796), train_loss = 2.28801555, grad/param norm = 1.2603e-01, time/batch = 0.2786s	
1016/2700 (epoch 18.815), train_loss = 2.31859859, grad/param norm = 9.4169e-02, time/batch = 0.3067s	
1017/2700 (epoch 18.833), train_loss = 2.28233387, grad/param norm = 9.7559e-02, time/batch = 0.3051s	
1018/2700 (epoch 18.852), train_loss = 2.32178180, grad/param norm = 8.9755e-02, time/batch = 0.3097s	
1019/2700 (epoch 18.870), train_loss = 2.28079685, grad/param norm = 1.0390e-01, time/batch = 0.3174s	
1020/2700 (epoch 18.889), train_loss = 2.27525568, grad/param norm = 1.5684e-01, time/batch = 0.3237s	
1021/2700 (epoch 18.907), train_loss = 2.41886162, grad/param norm = 2.3247e-01, time/batch = 0.3049s	
1022/2700 (epoch 18.926), train_loss = 2.35077296, grad/param norm = 3.8036e-01, time/batch = 0.3143s	
1023/2700 (epoch 18.944), train_loss = 2.36786046, grad/param norm = 3.9921e-01, time/batch = 0.2700s	
1024/2700 (epoch 18.963), train_loss = 2.38127557, grad/param norm = 3.6380e-01, time/batch = 0.3046s	
1025/2700 (epoch 18.981), train_loss = 2.33289078, grad/param norm = 3.5974e-01, time/batch = 0.2762s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1026/2700 (epoch 19.000), train_loss = 2.36684050, grad/param norm = 2.6918e-01, time/batch = 0.3139s	
1027/2700 (epoch 19.019), train_loss = 2.36613552, grad/param norm = 2.7931e-01, time/batch = 0.3070s	
1028/2700 (epoch 19.037), train_loss = 2.35989320, grad/param norm = 2.5850e-01, time/batch = 0.3024s	
1029/2700 (epoch 19.056), train_loss = 2.33311638, grad/param norm = 2.9000e-01, time/batch = 0.3134s	
1030/2700 (epoch 19.074), train_loss = 2.28605800, grad/param norm = 2.6729e-01, time/batch = 0.3303s	
1031/2700 (epoch 19.093), train_loss = 2.32758445, grad/param norm = 2.1985e-01, time/batch = 0.3072s	
1032/2700 (epoch 19.111), train_loss = 2.29384550, grad/param norm = 1.4949e-01, time/batch = 0.3045s	
1033/2700 (epoch 19.130), train_loss = 2.31838572, grad/param norm = 1.2471e-01, time/batch = 0.3104s	
1034/2700 (epoch 19.148), train_loss = 2.27011054, grad/param norm = 1.8583e-01, time/batch = 0.3129s	
1035/2700 (epoch 19.167), train_loss = 2.33142120, grad/param norm = 2.0559e-01, time/batch = 0.2836s	
1036/2700 (epoch 19.185), train_loss = 2.27875421, grad/param norm = 1.8268e-01, time/batch = 0.3143s	
1037/2700 (epoch 19.204), train_loss = 2.26244229, grad/param norm = 1.5787e-01, time/batch = 0.3034s	
1038/2700 (epoch 19.222), train_loss = 2.24062246, grad/param norm = 1.6403e-01, time/batch = 0.2950s	
1039/2700 (epoch 19.241), train_loss = 2.20956445, grad/param norm = 2.0035e-01, time/batch = 0.3072s	
1040/2700 (epoch 19.259), train_loss = 2.23679962, grad/param norm = 2.2653e-01, time/batch = 0.3126s	
1041/2700 (epoch 19.278), train_loss = 2.29912193, grad/param norm = 2.3381e-01, time/batch = 0.3028s	
1042/2700 (epoch 19.296), train_loss = 2.28653371, grad/param norm = 2.2605e-01, time/batch = 0.2894s	
1043/2700 (epoch 19.315), train_loss = 2.31702002, grad/param norm = 2.5101e-01, time/batch = 0.2972s	
1044/2700 (epoch 19.333), train_loss = 2.32539735, grad/param norm = 2.6523e-01, time/batch = 0.3037s	
1045/2700 (epoch 19.352), train_loss = 2.32552508, grad/param norm = 2.8343e-01, time/batch = 0.2947s	
1046/2700 (epoch 19.370), train_loss = 2.35830047, grad/param norm = 3.6646e-01, time/batch = 0.3413s	
1047/2700 (epoch 19.389), train_loss = 2.33450933, grad/param norm = 3.4204e-01, time/batch = 0.3269s	
1048/2700 (epoch 19.407), train_loss = 2.31240953, grad/param norm = 2.7119e-01, time/batch = 0.3056s	
1049/2700 (epoch 19.426), train_loss = 2.32711882, grad/param norm = 2.2120e-01, time/batch = 0.3018s	
1050/2700 (epoch 19.444), train_loss = 2.24699853, grad/param norm = 2.1923e-01, time/batch = 0.2999s	
1051/2700 (epoch 19.463), train_loss = 2.28906051, grad/param norm = 2.5552e-01, time/batch = 0.2945s	
1052/2700 (epoch 19.481), train_loss = 2.30570477, grad/param norm = 2.2195e-01, time/batch = 0.3056s	
1053/2700 (epoch 19.500), train_loss = 2.30690421, grad/param norm = 2.1541e-01, time/batch = 0.3159s	
1054/2700 (epoch 19.519), train_loss = 2.27573880, grad/param norm = 2.4998e-01, time/batch = 0.3255s	
1055/2700 (epoch 19.537), train_loss = 2.30349121, grad/param norm = 2.5002e-01, time/batch = 0.3206s	
1056/2700 (epoch 19.556), train_loss = 2.28894229, grad/param norm = 2.6984e-01, time/batch = 0.3218s	
1057/2700 (epoch 19.574), train_loss = 2.28927956, grad/param norm = 3.7075e-01, time/batch = 0.3122s	
1058/2700 (epoch 19.593), train_loss = 2.28843829, grad/param norm = 3.6422e-01, time/batch = 0.3080s	
1059/2700 (epoch 19.611), train_loss = 2.21350595, grad/param norm = 2.7727e-01, time/batch = 0.2986s	
1060/2700 (epoch 19.630), train_loss = 2.24058697, grad/param norm = 2.3052e-01, time/batch = 0.3010s	
1061/2700 (epoch 19.648), train_loss = 2.26259096, grad/param norm = 2.4188e-01, time/batch = 0.2734s	
1062/2700 (epoch 19.667), train_loss = 2.24438702, grad/param norm = 3.0537e-01, time/batch = 0.3014s	
1063/2700 (epoch 19.685), train_loss = 2.27803542, grad/param norm = 4.0177e-01, time/batch = 0.3040s	
1064/2700 (epoch 19.704), train_loss = 2.31937502, grad/param norm = 3.9270e-01, time/batch = 0.3223s	
1065/2700 (epoch 19.722), train_loss = 2.25715805, grad/param norm = 2.6031e-01, time/batch = 0.3143s	
1066/2700 (epoch 19.741), train_loss = 2.35156203, grad/param norm = 1.9667e-01, time/batch = 0.3243s	
1067/2700 (epoch 19.759), train_loss = 2.33057113, grad/param norm = 1.8563e-01, time/batch = 0.3207s	
1068/2700 (epoch 19.778), train_loss = 2.31955643, grad/param norm = 1.9353e-01, time/batch = 0.3135s	
1069/2700 (epoch 19.796), train_loss = 2.26904548, grad/param norm = 1.7856e-01, time/batch = 0.2691s	
1070/2700 (epoch 19.815), train_loss = 2.30330721, grad/param norm = 1.5643e-01, time/batch = 0.3024s	
1071/2700 (epoch 19.833), train_loss = 2.26455251, grad/param norm = 1.3503e-01, time/batch = 0.3074s	
1072/2700 (epoch 19.852), train_loss = 2.29895573, grad/param norm = 1.1019e-01, time/batch = 0.3160s	
1073/2700 (epoch 19.870), train_loss = 2.25391079, grad/param norm = 1.2501e-01, time/batch = 0.3266s	
1074/2700 (epoch 19.889), train_loss = 2.24078975, grad/param norm = 1.5035e-01, time/batch = 0.3410s	
1075/2700 (epoch 19.907), train_loss = 2.37549773, grad/param norm = 1.4267e-01, time/batch = 0.3244s	
1076/2700 (epoch 19.926), train_loss = 2.29818799, grad/param norm = 1.6264e-01, time/batch = 0.3100s	
1077/2700 (epoch 19.944), train_loss = 2.31318742, grad/param norm = 2.0631e-01, time/batch = 0.3217s	
1078/2700 (epoch 19.963), train_loss = 2.34370973, grad/param norm = 2.8972e-01, time/batch = 0.3187s	
1079/2700 (epoch 19.981), train_loss = 2.30356486, grad/param norm = 3.0539e-01, time/batch = 0.3018s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1080/2700 (epoch 20.000), train_loss = 2.33275908, grad/param norm = 2.6716e-01, time/batch = 0.2525s	
1081/2700 (epoch 20.019), train_loss = 2.33488299, grad/param norm = 2.8995e-01, time/batch = 0.3551s	
1082/2700 (epoch 20.037), train_loss = 2.32100486, grad/param norm = 2.4899e-01, time/batch = 0.3385s	
1083/2700 (epoch 20.056), train_loss = 2.29179737, grad/param norm = 2.1807e-01, time/batch = 0.3316s	
1084/2700 (epoch 20.074), train_loss = 2.26111146, grad/param norm = 2.9767e-01, time/batch = 0.3251s	
1085/2700 (epoch 20.093), train_loss = 2.32672966, grad/param norm = 3.9398e-01, time/batch = 0.3416s	
1086/2700 (epoch 20.111), train_loss = 2.30759286, grad/param norm = 3.5692e-01, time/batch = 0.3509s	
1087/2700 (epoch 20.130), train_loss = 2.32390051, grad/param norm = 2.8795e-01, time/batch = 0.3520s	
1088/2700 (epoch 20.148), train_loss = 2.26585071, grad/param norm = 2.9634e-01, time/batch = 0.3361s	
1089/2700 (epoch 20.167), train_loss = 2.31852830, grad/param norm = 2.6311e-01, time/batch = 0.3271s	
1090/2700 (epoch 20.185), train_loss = 2.25564336, grad/param norm = 1.7362e-01, time/batch = 0.3170s	
1091/2700 (epoch 20.204), train_loss = 2.23900569, grad/param norm = 1.3844e-01, time/batch = 0.2923s	
1092/2700 (epoch 20.222), train_loss = 2.21203784, grad/param norm = 1.5622e-01, time/batch = 0.3021s	
1093/2700 (epoch 20.241), train_loss = 2.18306408, grad/param norm = 1.8095e-01, time/batch = 0.3020s	
1094/2700 (epoch 20.259), train_loss = 2.20993920, grad/param norm = 2.3710e-01, time/batch = 0.3030s	
1095/2700 (epoch 20.278), train_loss = 2.28800152, grad/param norm = 3.1463e-01, time/batch = 0.3416s	
1096/2700 (epoch 20.296), train_loss = 2.29001463, grad/param norm = 3.7707e-01, time/batch = 0.3482s	
1097/2700 (epoch 20.315), train_loss = 2.33116635, grad/param norm = 3.7251e-01, time/batch = 0.3442s	
1098/2700 (epoch 20.333), train_loss = 2.30649188, grad/param norm = 2.6920e-01, time/batch = 0.3303s	
1099/2700 (epoch 20.352), train_loss = 2.28154825, grad/param norm = 1.9638e-01, time/batch = 0.3296s	
1100/2700 (epoch 20.370), train_loss = 2.29307966, grad/param norm = 1.7253e-01, time/batch = 0.3336s	
1101/2700 (epoch 20.389), train_loss = 2.26050768, grad/param norm = 2.1005e-01, time/batch = 0.3219s	
1102/2700 (epoch 20.407), train_loss = 2.27204932, grad/param norm = 2.5348e-01, time/batch = 0.3313s	
1103/2700 (epoch 20.426), train_loss = 2.29881375, grad/param norm = 2.3496e-01, time/batch = 0.3301s	
1104/2700 (epoch 20.444), train_loss = 2.21978974, grad/param norm = 2.2078e-01, time/batch = 0.3313s	
1105/2700 (epoch 20.463), train_loss = 2.25852020, grad/param norm = 2.2237e-01, time/batch = 0.3201s	
1106/2700 (epoch 20.481), train_loss = 2.27274209, grad/param norm = 1.8559e-01, time/batch = 0.3002s	
1107/2700 (epoch 20.500), train_loss = 2.27941885, grad/param norm = 1.9704e-01, time/batch = 0.3097s	
1108/2700 (epoch 20.519), train_loss = 2.24345702, grad/param norm = 2.1950e-01, time/batch = 0.3191s	
1109/2700 (epoch 20.537), train_loss = 2.26662403, grad/param norm = 2.0222e-01, time/batch = 0.3279s	
1110/2700 (epoch 20.556), train_loss = 2.25305760, grad/param norm = 1.8193e-01, time/batch = 0.3411s	
1111/2700 (epoch 20.574), train_loss = 2.24259864, grad/param norm = 2.1850e-01, time/batch = 0.3184s	
1112/2700 (epoch 20.593), train_loss = 2.24076846, grad/param norm = 2.2217e-01, time/batch = 0.2928s	
1113/2700 (epoch 20.611), train_loss = 2.18279297, grad/param norm = 1.8903e-01, time/batch = 0.3174s	
1114/2700 (epoch 20.630), train_loss = 2.21074850, grad/param norm = 2.3510e-01, time/batch = 0.3233s	
1115/2700 (epoch 20.648), train_loss = 2.24533252, grad/param norm = 2.8177e-01, time/batch = 0.3084s	
1116/2700 (epoch 20.667), train_loss = 2.22969980, grad/param norm = 3.3974e-01, time/batch = 0.3110s	
1117/2700 (epoch 20.685), train_loss = 2.25967584, grad/param norm = 3.7246e-01, time/batch = 0.3171s	
1118/2700 (epoch 20.704), train_loss = 2.28756501, grad/param norm = 3.3940e-01, time/batch = 0.3236s	
1119/2700 (epoch 20.722), train_loss = 2.23702397, grad/param norm = 2.6261e-01, time/batch = 0.3278s	
1120/2700 (epoch 20.741), train_loss = 2.32498497, grad/param norm = 2.1815e-01, time/batch = 0.3381s	
1121/2700 (epoch 20.759), train_loss = 2.30517257, grad/param norm = 1.7568e-01, time/batch = 0.3171s	
1122/2700 (epoch 20.778), train_loss = 2.28433859, grad/param norm = 1.7684e-01, time/batch = 0.3128s	
1123/2700 (epoch 20.796), train_loss = 2.23564365, grad/param norm = 1.8494e-01, time/batch = 0.2900s	
1124/2700 (epoch 20.815), train_loss = 2.27682402, grad/param norm = 1.7187e-01, time/batch = 0.3305s	
1125/2700 (epoch 20.833), train_loss = 2.23766278, grad/param norm = 1.7593e-01, time/batch = 0.3278s	
1126/2700 (epoch 20.852), train_loss = 2.27666430, grad/param norm = 1.9381e-01, time/batch = 0.3155s	
1127/2700 (epoch 20.870), train_loss = 2.24206486, grad/param norm = 2.6070e-01, time/batch = 0.3071s	
1128/2700 (epoch 20.889), train_loss = 2.24293278, grad/param norm = 3.3079e-01, time/batch = 0.3120s	
1129/2700 (epoch 20.907), train_loss = 2.38021215, grad/param norm = 3.5726e-01, time/batch = 0.3235s	
1130/2700 (epoch 20.926), train_loss = 2.30013833, grad/param norm = 3.6687e-01, time/batch = 0.3273s	
1131/2700 (epoch 20.944), train_loss = 2.31590586, grad/param norm = 3.4738e-01, time/batch = 0.3245s	
1132/2700 (epoch 20.963), train_loss = 2.31366201, grad/param norm = 3.0969e-01, time/batch = 0.3060s	
1133/2700 (epoch 20.981), train_loss = 2.27718616, grad/param norm = 3.3622e-01, time/batch = 0.3128s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1134/2700 (epoch 21.000), train_loss = 2.30732638, grad/param norm = 2.9101e-01, time/batch = 0.2534s	
1135/2700 (epoch 21.019), train_loss = 2.31248266, grad/param norm = 3.2356e-01, time/batch = 0.2681s	
1136/2700 (epoch 21.037), train_loss = 2.30772798, grad/param norm = 3.0771e-01, time/batch = 0.3148s	
1137/2700 (epoch 21.056), train_loss = 2.27621247, grad/param norm = 2.5615e-01, time/batch = 0.3086s	
1138/2700 (epoch 21.074), train_loss = 2.22387956, grad/param norm = 2.1904e-01, time/batch = 0.3051s	
1139/2700 (epoch 21.093), train_loss = 2.26869267, grad/param norm = 2.1201e-01, time/batch = 0.3084s	
1140/2700 (epoch 21.111), train_loss = 2.24186731, grad/param norm = 2.1000e-01, time/batch = 0.3187s	
1141/2700 (epoch 21.130), train_loss = 2.27630071, grad/param norm = 2.4765e-01, time/batch = 0.3311s	
1142/2700 (epoch 21.148), train_loss = 2.23124623, grad/param norm = 3.2055e-01, time/batch = 0.3243s	
1143/2700 (epoch 21.167), train_loss = 2.29258644, grad/param norm = 2.8060e-01, time/batch = 0.3097s	
1144/2700 (epoch 21.185), train_loss = 2.23354926, grad/param norm = 1.9583e-01, time/batch = 0.3354s	
1145/2700 (epoch 21.204), train_loss = 2.22592170, grad/param norm = 1.9798e-01, time/batch = 0.3091s	
1146/2700 (epoch 21.222), train_loss = 2.20663767, grad/param norm = 2.5078e-01, time/batch = 0.3288s	
1147/2700 (epoch 21.241), train_loss = 2.18869479, grad/param norm = 3.3910e-01, time/batch = 0.3165s	
1148/2700 (epoch 21.259), train_loss = 2.21266795, grad/param norm = 2.9021e-01, time/batch = 0.3101s	
1149/2700 (epoch 21.278), train_loss = 2.26660204, grad/param norm = 2.2616e-01, time/batch = 0.3131s	
1150/2700 (epoch 21.296), train_loss = 2.25168982, grad/param norm = 1.9688e-01, time/batch = 0.3207s	
1151/2700 (epoch 21.315), train_loss = 2.25687638, grad/param norm = 1.9292e-01, time/batch = 0.3083s	
1152/2700 (epoch 21.333), train_loss = 2.27267012, grad/param norm = 2.3169e-01, time/batch = 0.2943s	
1153/2700 (epoch 21.352), train_loss = 2.25491641, grad/param norm = 2.6107e-01, time/batch = 0.3222s	
1154/2700 (epoch 21.370), train_loss = 2.26733326, grad/param norm = 1.9609e-01, time/batch = 0.3208s	
1155/2700 (epoch 21.389), train_loss = 2.22888141, grad/param norm = 1.8189e-01, time/batch = 0.3040s	
1156/2700 (epoch 21.407), train_loss = 2.24048598, grad/param norm = 1.8522e-01, time/batch = 0.3091s	
1157/2700 (epoch 21.426), train_loss = 2.26640392, grad/param norm = 1.6271e-01, time/batch = 0.3436s	
1158/2700 (epoch 21.444), train_loss = 2.18866230, grad/param norm = 1.4818e-01, time/batch = 0.3349s	
1159/2700 (epoch 21.463), train_loss = 2.22677022, grad/param norm = 1.4834e-01, time/batch = 0.3261s	
1160/2700 (epoch 21.481), train_loss = 2.24178293, grad/param norm = 1.5276e-01, time/batch = 0.3135s	
1161/2700 (epoch 21.500), train_loss = 2.24740822, grad/param norm = 1.9274e-01, time/batch = 0.3149s	
1162/2700 (epoch 21.519), train_loss = 2.22107613, grad/param norm = 2.4213e-01, time/batch = 0.3203s	
1163/2700 (epoch 21.537), train_loss = 2.24703130, grad/param norm = 2.4109e-01, time/batch = 0.3048s	
1164/2700 (epoch 21.556), train_loss = 2.23097271, grad/param norm = 2.3149e-01, time/batch = 0.3267s	
1165/2700 (epoch 21.574), train_loss = 2.22088097, grad/param norm = 2.8363e-01, time/batch = 0.3045s	
1166/2700 (epoch 21.593), train_loss = 2.21975745, grad/param norm = 2.9809e-01, time/batch = 0.3082s	
1167/2700 (epoch 21.611), train_loss = 2.15594005, grad/param norm = 2.2579e-01, time/batch = 0.3132s	
1168/2700 (epoch 21.630), train_loss = 2.17267267, grad/param norm = 1.7778e-01, time/batch = 0.3523s	
1169/2700 (epoch 21.648), train_loss = 2.20030155, grad/param norm = 1.7846e-01, time/batch = 0.3499s	
1170/2700 (epoch 21.667), train_loss = 2.19136023, grad/param norm = 2.4290e-01, time/batch = 0.3349s	
1171/2700 (epoch 21.685), train_loss = 2.22838692, grad/param norm = 3.0853e-01, time/batch = 0.3298s	
1172/2700 (epoch 21.704), train_loss = 2.25433247, grad/param norm = 2.7195e-01, time/batch = 0.3151s	
1173/2700 (epoch 21.722), train_loss = 2.21563466, grad/param norm = 2.3806e-01, time/batch = 0.3187s	
1174/2700 (epoch 21.741), train_loss = 2.29948754, grad/param norm = 2.6230e-01, time/batch = 0.3072s	
1175/2700 (epoch 21.759), train_loss = 2.29149601, grad/param norm = 2.6817e-01, time/batch = 0.2771s	
1176/2700 (epoch 21.778), train_loss = 2.26529923, grad/param norm = 2.1870e-01, time/batch = 0.3047s	
1177/2700 (epoch 21.796), train_loss = 2.21437079, grad/param norm = 2.2595e-01, time/batch = 0.3154s	
1178/2700 (epoch 21.815), train_loss = 2.26045506, grad/param norm = 2.2141e-01, time/batch = 0.3107s	
1179/2700 (epoch 21.833), train_loss = 2.22295822, grad/param norm = 2.3160e-01, time/batch = 0.3464s	
1180/2700 (epoch 21.852), train_loss = 2.26654910, grad/param norm = 2.9505e-01, time/batch = 0.3451s	
1181/2700 (epoch 21.870), train_loss = 2.23259390, grad/param norm = 3.2149e-01, time/batch = 0.3249s	
1182/2700 (epoch 21.889), train_loss = 2.21538837, grad/param norm = 2.9179e-01, time/batch = 0.3288s	
1183/2700 (epoch 21.907), train_loss = 2.34363331, grad/param norm = 2.3414e-01, time/batch = 0.3241s	
1184/2700 (epoch 21.926), train_loss = 2.25902429, grad/param norm = 2.0635e-01, time/batch = 0.3265s	
1185/2700 (epoch 21.944), train_loss = 2.26960626, grad/param norm = 2.1118e-01, time/batch = 0.2733s	
1186/2700 (epoch 21.963), train_loss = 2.27660632, grad/param norm = 2.0083e-01, time/batch = 0.3313s	
1187/2700 (epoch 21.981), train_loss = 2.23462164, grad/param norm = 1.8747e-01, time/batch = 0.3258s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1188/2700 (epoch 22.000), train_loss = 2.26681499, grad/param norm = 1.4851e-01, time/batch = 0.3035s	
1189/2700 (epoch 22.019), train_loss = 2.26604512, grad/param norm = 1.6753e-01, time/batch = 0.2805s	
1190/2700 (epoch 22.037), train_loss = 2.26322186, grad/param norm = 1.8962e-01, time/batch = 0.3448s	
1191/2700 (epoch 22.056), train_loss = 2.24138395, grad/param norm = 2.0835e-01, time/batch = 0.3120s	
1192/2700 (epoch 22.074), train_loss = 2.20682524, grad/param norm = 2.7672e-01, time/batch = 0.3223s	
1193/2700 (epoch 22.093), train_loss = 2.27207594, grad/param norm = 4.0005e-01, time/batch = 0.3255s	
1194/2700 (epoch 22.111), train_loss = 2.25623854, grad/param norm = 4.4685e-01, time/batch = 0.3211s	
1195/2700 (epoch 22.130), train_loss = 2.29227228, grad/param norm = 4.1774e-01, time/batch = 0.2867s	
1196/2700 (epoch 22.148), train_loss = 2.20761231, grad/param norm = 3.1629e-01, time/batch = 0.3198s	
1197/2700 (epoch 22.167), train_loss = 2.25561399, grad/param norm = 1.9402e-01, time/batch = 0.3236s	
1198/2700 (epoch 22.185), train_loss = 2.20045839, grad/param norm = 1.1427e-01, time/batch = 0.2895s	
1199/2700 (epoch 22.204), train_loss = 2.19391565, grad/param norm = 1.1059e-01, time/batch = 0.3104s	
1200/2700 (epoch 22.222), train_loss = 2.16174799, grad/param norm = 1.2455e-01, time/batch = 0.2642s	
1201/2700 (epoch 22.241), train_loss = 2.13067387, grad/param norm = 1.5974e-01, time/batch = 0.3341s	
1202/2700 (epoch 22.259), train_loss = 2.15018210, grad/param norm = 1.9681e-01, time/batch = 0.3297s	
1203/2700 (epoch 22.278), train_loss = 2.22151735, grad/param norm = 2.0154e-01, time/batch = 0.3265s	
1204/2700 (epoch 22.296), train_loss = 2.20849425, grad/param norm = 1.7251e-01, time/batch = 0.3271s	
1205/2700 (epoch 22.315), train_loss = 2.22735108, grad/param norm = 1.4481e-01, time/batch = 0.2816s	
1206/2700 (epoch 22.333), train_loss = 2.22483299, grad/param norm = 1.2145e-01, time/batch = 0.3011s	
1207/2700 (epoch 22.352), train_loss = 2.21494633, grad/param norm = 1.1653e-01, time/batch = 0.2967s	
1208/2700 (epoch 22.370), train_loss = 2.24744207, grad/param norm = 2.4026e-01, time/batch = 0.3091s	
1209/2700 (epoch 22.389), train_loss = 2.23427963, grad/param norm = 3.9549e-01, time/batch = 0.3030s	
1210/2700 (epoch 22.407), train_loss = 2.25244324, grad/param norm = 4.1863e-01, time/batch = 0.3114s	
1211/2700 (epoch 22.426), train_loss = 2.27492564, grad/param norm = 3.1391e-01, time/batch = 0.2951s	
1212/2700 (epoch 22.444), train_loss = 2.18827016, grad/param norm = 2.7626e-01, time/batch = 0.2844s	
1213/2700 (epoch 22.463), train_loss = 2.25338381, grad/param norm = 3.4347e-01, time/batch = 0.2526s	
1214/2700 (epoch 22.481), train_loss = 2.26319265, grad/param norm = 3.4312e-01, time/batch = 0.3192s	
1215/2700 (epoch 22.500), train_loss = 2.26943609, grad/param norm = 3.0814e-01, time/batch = 0.2769s	
1216/2700 (epoch 22.519), train_loss = 2.21834886, grad/param norm = 2.7908e-01, time/batch = 0.3002s	
1217/2700 (epoch 22.537), train_loss = 2.23093221, grad/param norm = 2.4124e-01, time/batch = 0.2994s	
1218/2700 (epoch 22.556), train_loss = 2.20688632, grad/param norm = 1.7781e-01, time/batch = 0.3074s	
1219/2700 (epoch 22.574), train_loss = 2.18566532, grad/param norm = 1.5283e-01, time/batch = 0.3151s	
1220/2700 (epoch 22.593), train_loss = 2.18771211, grad/param norm = 1.6491e-01, time/batch = 0.3166s	
1221/2700 (epoch 22.611), train_loss = 2.12885876, grad/param norm = 2.3124e-01, time/batch = 0.3454s	
1222/2700 (epoch 22.630), train_loss = 2.15262031, grad/param norm = 2.5683e-01, time/batch = 0.3350s	
1223/2700 (epoch 22.648), train_loss = 2.17774579, grad/param norm = 2.2310e-01, time/batch = 0.3277s	
1224/2700 (epoch 22.667), train_loss = 2.15525442, grad/param norm = 1.7900e-01, time/batch = 0.3155s	
1225/2700 (epoch 22.685), train_loss = 2.16377264, grad/param norm = 1.7675e-01, time/batch = 0.3283s	
1226/2700 (epoch 22.704), train_loss = 2.20263502, grad/param norm = 2.0737e-01, time/batch = 0.3223s	
1227/2700 (epoch 22.722), train_loss = 2.16636978, grad/param norm = 2.3155e-01, time/batch = 0.3106s	
1228/2700 (epoch 22.741), train_loss = 2.25808823, grad/param norm = 2.4579e-01, time/batch = 0.3036s	
1229/2700 (epoch 22.759), train_loss = 2.26250048, grad/param norm = 2.6654e-01, time/batch = 0.3107s	
1230/2700 (epoch 22.778), train_loss = 2.25578220, grad/param norm = 3.0200e-01, time/batch = 0.3163s	
1231/2700 (epoch 22.796), train_loss = 2.21767057, grad/param norm = 3.0493e-01, time/batch = 0.3247s	
1232/2700 (epoch 22.815), train_loss = 2.26151819, grad/param norm = 2.6833e-01, time/batch = 0.3186s	
1233/2700 (epoch 22.833), train_loss = 2.21228593, grad/param norm = 2.1186e-01, time/batch = 0.3240s	
1234/2700 (epoch 22.852), train_loss = 2.23056490, grad/param norm = 1.4299e-01, time/batch = 0.3240s	
1235/2700 (epoch 22.870), train_loss = 2.17989975, grad/param norm = 1.2729e-01, time/batch = 0.3112s	
1236/2700 (epoch 22.889), train_loss = 2.17094607, grad/param norm = 1.6622e-01, time/batch = 0.3323s	
1237/2700 (epoch 22.907), train_loss = 2.31378629, grad/param norm = 1.6450e-01, time/batch = 0.3234s	
1238/2700 (epoch 22.926), train_loss = 2.23069583, grad/param norm = 1.7497e-01, time/batch = 0.3109s	
1239/2700 (epoch 22.944), train_loss = 2.23887450, grad/param norm = 1.7037e-01, time/batch = 0.3132s	
1240/2700 (epoch 22.963), train_loss = 2.24999802, grad/param norm = 1.5834e-01, time/batch = 0.3153s	
1241/2700 (epoch 22.981), train_loss = 2.21504688, grad/param norm = 1.8487e-01, time/batch = 0.3143s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1242/2700 (epoch 23.000), train_loss = 2.25037272, grad/param norm = 1.9770e-01, time/batch = 0.3171s	
1243/2700 (epoch 23.019), train_loss = 2.25153705, grad/param norm = 2.3300e-01, time/batch = 0.3084s	
1244/2700 (epoch 23.037), train_loss = 2.25199028, grad/param norm = 2.5848e-01, time/batch = 0.2966s	
1245/2700 (epoch 23.056), train_loss = 2.23551987, grad/param norm = 3.1976e-01, time/batch = 0.3080s	
1246/2700 (epoch 23.074), train_loss = 2.18772031, grad/param norm = 3.1015e-01, time/batch = 0.3116s	
1247/2700 (epoch 23.093), train_loss = 2.22264222, grad/param norm = 2.3183e-01, time/batch = 0.3596s	
1248/2700 (epoch 23.111), train_loss = 2.18582257, grad/param norm = 2.0519e-01, time/batch = 0.3551s	
1249/2700 (epoch 23.130), train_loss = 2.21933697, grad/param norm = 2.1788e-01, time/batch = 0.3498s	
1250/2700 (epoch 23.148), train_loss = 2.15750146, grad/param norm = 2.0939e-01, time/batch = 0.3407s	
1251/2700 (epoch 23.167), train_loss = 2.22847321, grad/param norm = 2.2406e-01, time/batch = 0.3136s	
1252/2700 (epoch 23.185), train_loss = 2.18703981, grad/param norm = 2.1199e-01, time/batch = 0.3181s	
1253/2700 (epoch 23.204), train_loss = 2.17999881, grad/param norm = 1.9860e-01, time/batch = 0.3184s	
1254/2700 (epoch 23.222), train_loss = 2.14353327, grad/param norm = 2.0957e-01, time/batch = 0.2810s	
1255/2700 (epoch 23.241), train_loss = 2.11164104, grad/param norm = 2.4053e-01, time/batch = 0.2985s	
1256/2700 (epoch 23.259), train_loss = 2.13819495, grad/param norm = 2.5814e-01, time/batch = 0.3120s	
1257/2700 (epoch 23.278), train_loss = 2.21187567, grad/param norm = 2.7436e-01, time/batch = 0.3006s	
1258/2700 (epoch 23.296), train_loss = 2.21075478, grad/param norm = 3.3931e-01, time/batch = 0.3524s	
1259/2700 (epoch 23.315), train_loss = 2.23701456, grad/param norm = 4.0391e-01, time/batch = 0.3582s	
1260/2700 (epoch 23.333), train_loss = 2.23148854, grad/param norm = 3.7421e-01, time/batch = 0.3515s	
1261/2700 (epoch 23.352), train_loss = 2.20475194, grad/param norm = 2.7380e-01, time/batch = 0.3093s	
1262/2700 (epoch 23.370), train_loss = 2.22016497, grad/param norm = 1.5786e-01, time/batch = 0.3117s	
1263/2700 (epoch 23.389), train_loss = 2.18528992, grad/param norm = 1.6519e-01, time/batch = 0.3141s	
1264/2700 (epoch 23.407), train_loss = 2.20085584, grad/param norm = 1.8450e-01, time/batch = 0.2841s	
1265/2700 (epoch 23.426), train_loss = 2.22909583, grad/param norm = 1.6333e-01, time/batch = 0.3243s	
1266/2700 (epoch 23.444), train_loss = 2.14503249, grad/param norm = 1.7058e-01, time/batch = 0.3093s	
1267/2700 (epoch 23.463), train_loss = 2.19484536, grad/param norm = 2.1928e-01, time/batch = 0.3040s	
1268/2700 (epoch 23.481), train_loss = 2.20201793, grad/param norm = 1.9184e-01, time/batch = 0.2928s	
1269/2700 (epoch 23.500), train_loss = 2.20399676, grad/param norm = 1.8968e-01, time/batch = 0.3529s	
1270/2700 (epoch 23.519), train_loss = 2.17564243, grad/param norm = 1.9506e-01, time/batch = 0.3603s	
1271/2700 (epoch 23.537), train_loss = 2.19515838, grad/param norm = 1.8995e-01, time/batch = 0.2811s	
1272/2700 (epoch 23.556), train_loss = 2.18292665, grad/param norm = 1.8808e-01, time/batch = 0.3215s	
1273/2700 (epoch 23.574), train_loss = 2.16751444, grad/param norm = 2.0190e-01, time/batch = 0.3151s	
1274/2700 (epoch 23.593), train_loss = 2.17490134, grad/param norm = 2.2566e-01, time/batch = 0.2767s	
1275/2700 (epoch 23.611), train_loss = 2.12507707, grad/param norm = 3.1845e-01, time/batch = 0.3286s	
1276/2700 (epoch 23.630), train_loss = 2.15729115, grad/param norm = 4.1446e-01, time/batch = 0.3159s	
1277/2700 (epoch 23.648), train_loss = 2.18514884, grad/param norm = 3.7608e-01, time/batch = 0.3035s	
1278/2700 (epoch 23.667), train_loss = 2.14804118, grad/param norm = 2.4807e-01, time/batch = 0.3080s	
1279/2700 (epoch 23.685), train_loss = 2.14357745, grad/param norm = 1.8214e-01, time/batch = 0.3012s	
1280/2700 (epoch 23.704), train_loss = 2.18013177, grad/param norm = 1.9923e-01, time/batch = 0.3457s	
1281/2700 (epoch 23.722), train_loss = 2.14352874, grad/param norm = 2.3306e-01, time/batch = 0.3107s	
1282/2700 (epoch 23.741), train_loss = 2.23014249, grad/param norm = 2.3549e-01, time/batch = 0.3227s	
1283/2700 (epoch 23.759), train_loss = 2.24093304, grad/param norm = 2.8873e-01, time/batch = 0.3254s	
1284/2700 (epoch 23.778), train_loss = 2.23098132, grad/param norm = 3.1105e-01, time/batch = 0.2981s	
1285/2700 (epoch 23.796), train_loss = 2.18484709, grad/param norm = 2.6096e-01, time/batch = 0.3345s	
1286/2700 (epoch 23.815), train_loss = 2.22812416, grad/param norm = 2.1009e-01, time/batch = 0.3234s	
1287/2700 (epoch 23.833), train_loss = 2.18304237, grad/param norm = 1.7371e-01, time/batch = 0.3060s	
1288/2700 (epoch 23.852), train_loss = 2.20653692, grad/param norm = 1.5604e-01, time/batch = 0.2987s	
1289/2700 (epoch 23.870), train_loss = 2.15954569, grad/param norm = 2.0971e-01, time/batch = 0.2966s	
1290/2700 (epoch 23.889), train_loss = 2.15165655, grad/param norm = 2.2824e-01, time/batch = 0.2772s	
1291/2700 (epoch 23.907), train_loss = 2.28594362, grad/param norm = 1.7308e-01, time/batch = 0.3338s	
1292/2700 (epoch 23.926), train_loss = 2.20116736, grad/param norm = 1.5284e-01, time/batch = 0.3275s	
1293/2700 (epoch 23.944), train_loss = 2.21108412, grad/param norm = 1.4401e-01, time/batch = 0.3219s	
1294/2700 (epoch 23.963), train_loss = 2.22149018, grad/param norm = 1.2881e-01, time/batch = 0.2665s	
1295/2700 (epoch 23.981), train_loss = 2.19049782, grad/param norm = 1.7510e-01, time/batch = 0.3064s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1296/2700 (epoch 24.000), train_loss = 2.23039712, grad/param norm = 2.3327e-01, time/batch = 0.3159s	
1297/2700 (epoch 24.019), train_loss = 2.23369964, grad/param norm = 2.9300e-01, time/batch = 0.3253s	
1298/2700 (epoch 24.037), train_loss = 2.23381848, grad/param norm = 3.1286e-01, time/batch = 0.3102s	
1299/2700 (epoch 24.056), train_loss = 2.21143620, grad/param norm = 3.2992e-01, time/batch = 0.3058s	
1300/2700 (epoch 24.074), train_loss = 2.14941537, grad/param norm = 2.4151e-01, time/batch = 0.3203s	
1301/2700 (epoch 24.093), train_loss = 2.18301371, grad/param norm = 1.4362e-01, time/batch = 0.2781s	
1302/2700 (epoch 24.111), train_loss = 2.15165555, grad/param norm = 1.5093e-01, time/batch = 0.3261s	
1303/2700 (epoch 24.130), train_loss = 2.19314742, grad/param norm = 1.6707e-01, time/batch = 0.3251s	
1304/2700 (epoch 24.148), train_loss = 2.13195222, grad/param norm = 1.7074e-01, time/batch = 0.2597s	
1305/2700 (epoch 24.167), train_loss = 2.20260838, grad/param norm = 1.5006e-01, time/batch = 0.3015s	
1306/2700 (epoch 24.185), train_loss = 2.15898304, grad/param norm = 1.3542e-01, time/batch = 0.3114s	
1307/2700 (epoch 24.204), train_loss = 2.16008711, grad/param norm = 1.7978e-01, time/batch = 0.3157s	
1308/2700 (epoch 24.222), train_loss = 2.12905473, grad/param norm = 2.3813e-01, time/batch = 0.3238s	
1309/2700 (epoch 24.241), train_loss = 2.10531813, grad/param norm = 3.7922e-01, time/batch = 0.3220s	
1310/2700 (epoch 24.259), train_loss = 2.13195107, grad/param norm = 3.7712e-01, time/batch = 0.3252s	
1311/2700 (epoch 24.278), train_loss = 2.18897307, grad/param norm = 2.5915e-01, time/batch = 0.3032s	
1312/2700 (epoch 24.296), train_loss = 2.16880792, grad/param norm = 1.6564e-01, time/batch = 0.2722s	
1313/2700 (epoch 24.315), train_loss = 2.18239266, grad/param norm = 1.4368e-01, time/batch = 0.3183s	
1314/2700 (epoch 24.333), train_loss = 2.19456411, grad/param norm = 2.1625e-01, time/batch = 0.2699s	
1315/2700 (epoch 24.352), train_loss = 2.18991915, grad/param norm = 3.2252e-01, time/batch = 0.3124s	
1316/2700 (epoch 24.370), train_loss = 2.22324357, grad/param norm = 3.1653e-01, time/batch = 0.3096s	
1317/2700 (epoch 24.389), train_loss = 2.17596363, grad/param norm = 2.5445e-01, time/batch = 0.3149s	
1318/2700 (epoch 24.407), train_loss = 2.17765866, grad/param norm = 2.0487e-01, time/batch = 0.3148s	
1319/2700 (epoch 24.426), train_loss = 2.20313426, grad/param norm = 1.5740e-01, time/batch = 0.3351s	
1320/2700 (epoch 24.444), train_loss = 2.11519459, grad/param norm = 1.0265e-01, time/batch = 0.3267s	
1321/2700 (epoch 24.463), train_loss = 2.15798894, grad/param norm = 1.0532e-01, time/batch = 0.3008s	
1322/2700 (epoch 24.481), train_loss = 2.16728659, grad/param norm = 9.6178e-02, time/batch = 0.2960s	
1323/2700 (epoch 24.500), train_loss = 2.16730152, grad/param norm = 1.4193e-01, time/batch = 0.2786s	
1324/2700 (epoch 24.519), train_loss = 2.15243383, grad/param norm = 1.5889e-01, time/batch = 0.2923s	
1325/2700 (epoch 24.537), train_loss = 2.17363501, grad/param norm = 1.9470e-01, time/batch = 0.3271s	
1326/2700 (epoch 24.556), train_loss = 2.15661752, grad/param norm = 2.0161e-01, time/batch = 0.3112s	
1327/2700 (epoch 24.574), train_loss = 2.14347066, grad/param norm = 2.3709e-01, time/batch = 0.3018s	
1328/2700 (epoch 24.593), train_loss = 2.15757681, grad/param norm = 3.3256e-01, time/batch = 0.3007s	
1329/2700 (epoch 24.611), train_loss = 2.11733307, grad/param norm = 4.4614e-01, time/batch = 0.3109s	
1330/2700 (epoch 24.630), train_loss = 2.14045197, grad/param norm = 4.1518e-01, time/batch = 0.3230s	
1331/2700 (epoch 24.648), train_loss = 2.14671115, grad/param norm = 2.5372e-01, time/batch = 0.3075s	
1332/2700 (epoch 24.667), train_loss = 2.11563200, grad/param norm = 1.3857e-01, time/batch = 0.3195s	
1333/2700 (epoch 24.685), train_loss = 2.12397679, grad/param norm = 1.8360e-01, time/batch = 0.3220s	
1334/2700 (epoch 24.704), train_loss = 2.16234365, grad/param norm = 2.1889e-01, time/batch = 0.3002s	
1335/2700 (epoch 24.722), train_loss = 2.12175183, grad/param norm = 2.1883e-01, time/batch = 0.3209s	
1336/2700 (epoch 24.741), train_loss = 2.19585624, grad/param norm = 1.9837e-01, time/batch = 0.3081s	
1337/2700 (epoch 24.759), train_loss = 2.20365061, grad/param norm = 2.2620e-01, time/batch = 0.3009s	
1338/2700 (epoch 24.778), train_loss = 2.18825606, grad/param norm = 2.4295e-01, time/batch = 0.2997s	
1339/2700 (epoch 24.796), train_loss = 2.14456880, grad/param norm = 1.9585e-01, time/batch = 0.2994s	
1340/2700 (epoch 24.815), train_loss = 2.19658426, grad/param norm = 1.7922e-01, time/batch = 0.3127s	
1341/2700 (epoch 24.833), train_loss = 2.15675555, grad/param norm = 1.9686e-01, time/batch = 0.2964s	
1342/2700 (epoch 24.852), train_loss = 2.18813130, grad/param norm = 1.8973e-01, time/batch = 0.3225s	
1343/2700 (epoch 24.870), train_loss = 2.14074872, grad/param norm = 2.2177e-01, time/batch = 0.3268s	
1344/2700 (epoch 24.889), train_loss = 2.13520244, grad/param norm = 2.2911e-01, time/batch = 0.3032s	
1345/2700 (epoch 24.907), train_loss = 2.26983254, grad/param norm = 1.9956e-01, time/batch = 0.3225s	
1346/2700 (epoch 24.926), train_loss = 2.18798107, grad/param norm = 2.2382e-01, time/batch = 0.2917s	
1347/2700 (epoch 24.944), train_loss = 2.19654760, grad/param norm = 2.2828e-01, time/batch = 0.3009s	
1348/2700 (epoch 24.963), train_loss = 2.20910795, grad/param norm = 2.1322e-01, time/batch = 0.3019s	
1349/2700 (epoch 24.981), train_loss = 2.17485312, grad/param norm = 2.2992e-01, time/batch = 0.3188s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1350/2700 (epoch 25.000), train_loss = 2.20948959, grad/param norm = 2.2342e-01, time/batch = 0.3211s	
1351/2700 (epoch 25.019), train_loss = 2.20883160, grad/param norm = 2.3084e-01, time/batch = 0.3149s	
1352/2700 (epoch 25.037), train_loss = 2.21050572, grad/param norm = 2.4566e-01, time/batch = 0.3180s	
1353/2700 (epoch 25.056), train_loss = 2.18188295, grad/param norm = 2.6328e-01, time/batch = 0.3244s	
1354/2700 (epoch 25.074), train_loss = 2.13464068, grad/param norm = 2.3739e-01, time/batch = 0.2912s	
1355/2700 (epoch 25.093), train_loss = 2.16841802, grad/param norm = 1.7516e-01, time/batch = 0.3404s	
1356/2700 (epoch 25.111), train_loss = 2.13244110, grad/param norm = 1.7449e-01, time/batch = 0.3227s	
1357/2700 (epoch 25.130), train_loss = 2.17324035, grad/param norm = 1.9274e-01, time/batch = 0.2912s	
1358/2700 (epoch 25.148), train_loss = 2.10905630, grad/param norm = 1.8393e-01, time/batch = 0.3127s	
1359/2700 (epoch 25.167), train_loss = 2.18048079, grad/param norm = 1.7214e-01, time/batch = 0.3077s	
1360/2700 (epoch 25.185), train_loss = 2.13864520, grad/param norm = 1.6787e-01, time/batch = 0.3080s	
1361/2700 (epoch 25.204), train_loss = 2.13855165, grad/param norm = 1.6853e-01, time/batch = 0.2947s	
1362/2700 (epoch 25.222), train_loss = 2.09787082, grad/param norm = 1.7785e-01, time/batch = 0.3062s	
1363/2700 (epoch 25.241), train_loss = 2.06209386, grad/param norm = 2.4005e-01, time/batch = 0.3189s	
1364/2700 (epoch 25.259), train_loss = 2.08602325, grad/param norm = 2.9057e-01, time/batch = 0.3206s	
1365/2700 (epoch 25.278), train_loss = 2.15931214, grad/param norm = 2.7702e-01, time/batch = 0.2833s	
1366/2700 (epoch 25.296), train_loss = 2.14423558, grad/param norm = 2.2873e-01, time/batch = 0.3115s	
1367/2700 (epoch 25.315), train_loss = 2.15829678, grad/param norm = 1.8632e-01, time/batch = 0.3123s	
1368/2700 (epoch 25.333), train_loss = 2.15471779, grad/param norm = 1.7769e-01, time/batch = 0.2530s	
1369/2700 (epoch 25.352), train_loss = 2.15001327, grad/param norm = 2.2692e-01, time/batch = 0.3254s	
1370/2700 (epoch 25.370), train_loss = 2.20497577, grad/param norm = 3.9610e-01, time/batch = 0.3209s	
1371/2700 (epoch 25.389), train_loss = 2.18170296, grad/param norm = 4.3128e-01, time/batch = 0.3258s	
1372/2700 (epoch 25.407), train_loss = 2.16919318, grad/param norm = 2.7152e-01, time/batch = 0.3420s	
1373/2700 (epoch 25.426), train_loss = 2.18300111, grad/param norm = 1.4596e-01, time/batch = 0.3460s	
1374/2700 (epoch 25.444), train_loss = 2.09524032, grad/param norm = 1.4577e-01, time/batch = 0.3474s	
1375/2700 (epoch 25.463), train_loss = 2.14542001, grad/param norm = 1.9478e-01, time/batch = 0.3499s	
1376/2700 (epoch 25.481), train_loss = 2.15395298, grad/param norm = 1.7533e-01, time/batch = 0.3477s	
1377/2700 (epoch 25.500), train_loss = 2.15140699, grad/param norm = 1.8195e-01, time/batch = 0.3446s	
1378/2700 (epoch 25.519), train_loss = 2.13633774, grad/param norm = 2.0397e-01, time/batch = 0.3200s	
1379/2700 (epoch 25.537), train_loss = 2.15493598, grad/param norm = 2.0998e-01, time/batch = 0.2798s	
1380/2700 (epoch 25.556), train_loss = 2.14456937, grad/param norm = 2.4247e-01, time/batch = 0.3130s	
1381/2700 (epoch 25.574), train_loss = 2.14655379, grad/param norm = 2.8007e-01, time/batch = 0.3059s	
1382/2700 (epoch 25.593), train_loss = 2.15820180, grad/param norm = 3.0878e-01, time/batch = 0.3092s	
1383/2700 (epoch 25.611), train_loss = 2.09287952, grad/param norm = 3.5389e-01, time/batch = 0.2971s	
1384/2700 (epoch 25.630), train_loss = 2.10079307, grad/param norm = 3.0318e-01, time/batch = 0.3242s	
1385/2700 (epoch 25.648), train_loss = 2.11435565, grad/param norm = 1.9792e-01, time/batch = 0.3394s	
1386/2700 (epoch 25.667), train_loss = 2.09174494, grad/param norm = 1.4529e-01, time/batch = 0.3427s	
1387/2700 (epoch 25.685), train_loss = 2.09874796, grad/param norm = 1.7505e-01, time/batch = 0.3390s	
1388/2700 (epoch 25.704), train_loss = 2.13475672, grad/param norm = 2.0132e-01, time/batch = 0.3417s	
1389/2700 (epoch 25.722), train_loss = 2.09474539, grad/param norm = 2.1141e-01, time/batch = 0.3232s	
1390/2700 (epoch 25.741), train_loss = 2.16994529, grad/param norm = 1.9980e-01, time/batch = 0.3114s	
1391/2700 (epoch 25.759), train_loss = 2.18612947, grad/param norm = 2.3757e-01, time/batch = 0.3305s	
1392/2700 (epoch 25.778), train_loss = 2.17519098, grad/param norm = 2.6809e-01, time/batch = 0.3282s	
1393/2700 (epoch 25.796), train_loss = 2.13420059, grad/param norm = 2.3505e-01, time/batch = 0.2985s	
1394/2700 (epoch 25.815), train_loss = 2.18402231, grad/param norm = 1.9693e-01, time/batch = 0.3243s	
1395/2700 (epoch 25.833), train_loss = 2.13196427, grad/param norm = 1.5131e-01, time/batch = 0.3107s	
1396/2700 (epoch 25.852), train_loss = 2.15226619, grad/param norm = 1.0570e-01, time/batch = 0.3072s	
1397/2700 (epoch 25.870), train_loss = 2.10757772, grad/param norm = 1.1640e-01, time/batch = 0.3116s	
1398/2700 (epoch 25.889), train_loss = 2.10138827, grad/param norm = 1.3425e-01, time/batch = 0.3162s	
1399/2700 (epoch 25.907), train_loss = 2.24236095, grad/param norm = 1.3312e-01, time/batch = 0.3282s	
1400/2700 (epoch 25.926), train_loss = 2.16458184, grad/param norm = 1.7911e-01, time/batch = 0.3301s	
1401/2700 (epoch 25.944), train_loss = 2.17533503, grad/param norm = 2.1540e-01, time/batch = 0.3382s	
1402/2700 (epoch 25.963), train_loss = 2.18623125, grad/param norm = 2.3510e-01, time/batch = 0.3023s	
1403/2700 (epoch 25.981), train_loss = 2.15451288, grad/param norm = 2.2796e-01, time/batch = 0.3368s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1404/2700 (epoch 26.000), train_loss = 2.18141948, grad/param norm = 1.7469e-01, time/batch = 0.3267s	
1405/2700 (epoch 26.019), train_loss = 2.17962266, grad/param norm = 1.8675e-01, time/batch = 0.3300s	
1406/2700 (epoch 26.037), train_loss = 2.17972029, grad/param norm = 2.2540e-01, time/batch = 0.3192s	
1407/2700 (epoch 26.056), train_loss = 2.15628021, grad/param norm = 2.2116e-01, time/batch = 0.3093s	
1408/2700 (epoch 26.074), train_loss = 2.10775305, grad/param norm = 2.1657e-01, time/batch = 0.3087s	
1409/2700 (epoch 26.093), train_loss = 2.14532403, grad/param norm = 2.0858e-01, time/batch = 0.3183s	
1410/2700 (epoch 26.111), train_loss = 2.10781683, grad/param norm = 2.1467e-01, time/batch = 0.3231s	
1411/2700 (epoch 26.130), train_loss = 2.17038242, grad/param norm = 3.3016e-01, time/batch = 0.2740s	
1412/2700 (epoch 26.148), train_loss = 2.12763196, grad/param norm = 3.8834e-01, time/batch = 0.3354s	
1413/2700 (epoch 26.167), train_loss = 2.18732875, grad/param norm = 2.9905e-01, time/batch = 0.3400s	
1414/2700 (epoch 26.185), train_loss = 2.12716829, grad/param norm = 2.2058e-01, time/batch = 0.3314s	
1415/2700 (epoch 26.204), train_loss = 2.12039148, grad/param norm = 1.4591e-01, time/batch = 0.3307s	
1416/2700 (epoch 26.222), train_loss = 2.07443717, grad/param norm = 1.3729e-01, time/batch = 0.3332s	
1417/2700 (epoch 26.241), train_loss = 2.03018355, grad/param norm = 1.3287e-01, time/batch = 0.3451s	
1418/2700 (epoch 26.259), train_loss = 2.05490652, grad/param norm = 1.3711e-01, time/batch = 0.3417s	
1419/2700 (epoch 26.278), train_loss = 2.12660669, grad/param norm = 1.3506e-01, time/batch = 0.3279s	
1420/2700 (epoch 26.296), train_loss = 2.11803282, grad/param norm = 1.8073e-01, time/batch = 0.3040s	
1421/2700 (epoch 26.315), train_loss = 2.14383955, grad/param norm = 2.5691e-01, time/batch = 0.3088s	
1422/2700 (epoch 26.333), train_loss = 2.14610289, grad/param norm = 3.1929e-01, time/batch = 0.2324s	
1423/2700 (epoch 26.352), train_loss = 2.13453230, grad/param norm = 3.2374e-01, time/batch = 0.3468s	
1424/2700 (epoch 26.370), train_loss = 2.15944169, grad/param norm = 2.7928e-01, time/batch = 0.3526s	
1425/2700 (epoch 26.389), train_loss = 2.13060667, grad/param norm = 2.1426e-01, time/batch = 0.3362s	
1426/2700 (epoch 26.407), train_loss = 2.14442092, grad/param norm = 1.9787e-01, time/batch = 0.3233s	
1427/2700 (epoch 26.426), train_loss = 2.16573615, grad/param norm = 1.5200e-01, time/batch = 0.3171s	
1428/2700 (epoch 26.444), train_loss = 2.07322763, grad/param norm = 1.0687e-01, time/batch = 0.3264s	
1429/2700 (epoch 26.463), train_loss = 2.11960361, grad/param norm = 1.2450e-01, time/batch = 0.3310s	
1430/2700 (epoch 26.481), train_loss = 2.12477220, grad/param norm = 1.0232e-01, time/batch = 0.3165s	
1431/2700 (epoch 26.500), train_loss = 2.12345839, grad/param norm = 1.4143e-01, time/batch = 0.3269s	
1432/2700 (epoch 26.519), train_loss = 2.11208628, grad/param norm = 1.3639e-01, time/batch = 0.2791s	
1433/2700 (epoch 26.537), train_loss = 2.12475605, grad/param norm = 1.4861e-01, time/batch = 0.2760s	
1434/2700 (epoch 26.556), train_loss = 2.11320970, grad/param norm = 1.7947e-01, time/batch = 0.3400s	
1435/2700 (epoch 26.574), train_loss = 2.10354248, grad/param norm = 2.0847e-01, time/batch = 0.3355s	
1436/2700 (epoch 26.593), train_loss = 2.11634817, grad/param norm = 2.6591e-01, time/batch = 0.3285s	
1437/2700 (epoch 26.611), train_loss = 2.06579109, grad/param norm = 3.6489e-01, time/batch = 0.3128s	
1438/2700 (epoch 26.630), train_loss = 2.09162037, grad/param norm = 3.8563e-01, time/batch = 0.3132s	
1439/2700 (epoch 26.648), train_loss = 2.10437025, grad/param norm = 2.7935e-01, time/batch = 0.3145s	
1440/2700 (epoch 26.667), train_loss = 2.07206153, grad/param norm = 1.3686e-01, time/batch = 0.3055s	
1441/2700 (epoch 26.685), train_loss = 2.07746407, grad/param norm = 1.3629e-01, time/batch = 0.3451s	
1442/2700 (epoch 26.704), train_loss = 2.11300023, grad/param norm = 1.7078e-01, time/batch = 0.3395s	
1443/2700 (epoch 26.722), train_loss = 2.07534519, grad/param norm = 2.1742e-01, time/batch = 0.3320s	
1444/2700 (epoch 26.741), train_loss = 2.15182859, grad/param norm = 2.2960e-01, time/batch = 0.2767s	
1445/2700 (epoch 26.759), train_loss = 2.17335737, grad/param norm = 2.8062e-01, time/batch = 0.3277s	
1446/2700 (epoch 26.778), train_loss = 2.15743092, grad/param norm = 2.7888e-01, time/batch = 0.3184s	
1447/2700 (epoch 26.796), train_loss = 2.11257545, grad/param norm = 2.1622e-01, time/batch = 0.3242s	
1448/2700 (epoch 26.815), train_loss = 2.16547659, grad/param norm = 1.9104e-01, time/batch = 0.3131s	
1449/2700 (epoch 26.833), train_loss = 2.11330134, grad/param norm = 1.5908e-01, time/batch = 0.3317s	
1450/2700 (epoch 26.852), train_loss = 2.13456420, grad/param norm = 1.3673e-01, time/batch = 0.3355s	
1451/2700 (epoch 26.870), train_loss = 2.09165762, grad/param norm = 1.9794e-01, time/batch = 0.3327s	
1452/2700 (epoch 26.889), train_loss = 2.09057130, grad/param norm = 2.1706e-01, time/batch = 0.3506s	
1453/2700 (epoch 26.907), train_loss = 2.22172765, grad/param norm = 1.6647e-01, time/batch = 0.3301s	
1454/2700 (epoch 26.926), train_loss = 2.14102034, grad/param norm = 1.2114e-01, time/batch = 0.3012s	
1455/2700 (epoch 26.944), train_loss = 2.14483758, grad/param norm = 1.1197e-01, time/batch = 0.3146s	
1456/2700 (epoch 26.963), train_loss = 2.15529811, grad/param norm = 1.0305e-01, time/batch = 0.3035s	
1457/2700 (epoch 26.981), train_loss = 2.12469720, grad/param norm = 1.2287e-01, time/batch = 0.2969s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1458/2700 (epoch 27.000), train_loss = 2.15854977, grad/param norm = 1.4531e-01, time/batch = 0.3081s	
1459/2700 (epoch 27.019), train_loss = 2.15774648, grad/param norm = 2.0397e-01, time/batch = 0.3141s	
1460/2700 (epoch 27.037), train_loss = 2.16290253, grad/param norm = 2.5330e-01, time/batch = 0.3152s	
1461/2700 (epoch 27.056), train_loss = 2.14302506, grad/param norm = 3.3171e-01, time/batch = 0.2661s	
1462/2700 (epoch 27.074), train_loss = 2.09070529, grad/param norm = 2.9970e-01, time/batch = 0.3203s	
1463/2700 (epoch 27.093), train_loss = 2.11224225, grad/param norm = 1.6649e-01, time/batch = 0.3288s	
1464/2700 (epoch 27.111), train_loss = 2.07591353, grad/param norm = 1.6068e-01, time/batch = 0.3315s	
1465/2700 (epoch 27.130), train_loss = 2.12317811, grad/param norm = 1.7748e-01, time/batch = 0.3189s	
1466/2700 (epoch 27.148), train_loss = 2.06210817, grad/param norm = 1.6564e-01, time/batch = 0.2780s	
1467/2700 (epoch 27.167), train_loss = 2.13764223, grad/param norm = 1.6601e-01, time/batch = 0.3019s	
1468/2700 (epoch 27.185), train_loss = 2.09959715, grad/param norm = 1.5398e-01, time/batch = 0.3107s	
1469/2700 (epoch 27.204), train_loss = 2.10087296, grad/param norm = 1.5034e-01, time/batch = 0.3126s	
1470/2700 (epoch 27.222), train_loss = 2.06193024, grad/param norm = 1.6920e-01, time/batch = 0.3014s	
1471/2700 (epoch 27.241), train_loss = 2.02075671, grad/param norm = 2.4260e-01, time/batch = 0.3030s	
1472/2700 (epoch 27.259), train_loss = 2.05324852, grad/param norm = 2.7789e-01, time/batch = 0.2968s	
1473/2700 (epoch 27.278), train_loss = 2.12432745, grad/param norm = 2.4849e-01, time/batch = 0.3044s	
1474/2700 (epoch 27.296), train_loss = 2.11588697, grad/param norm = 1.9425e-01, time/batch = 0.3152s	
1475/2700 (epoch 27.315), train_loss = 2.11705404, grad/param norm = 1.5251e-01, time/batch = 0.3115s	
1476/2700 (epoch 27.333), train_loss = 2.12198885, grad/param norm = 1.6795e-01, time/batch = 0.3101s	
1477/2700 (epoch 27.352), train_loss = 2.10501369, grad/param norm = 1.6994e-01, time/batch = 0.3131s	
1478/2700 (epoch 27.370), train_loss = 2.13732572, grad/param norm = 2.2627e-01, time/batch = 0.2947s	
1479/2700 (epoch 27.389), train_loss = 2.11936639, grad/param norm = 3.7813e-01, time/batch = 0.2942s	
1480/2700 (epoch 27.407), train_loss = 2.13959076, grad/param norm = 3.7748e-01, time/batch = 0.3008s	
1481/2700 (epoch 27.426), train_loss = 2.15516521, grad/param norm = 2.5083e-01, time/batch = 0.3112s	
1482/2700 (epoch 27.444), train_loss = 2.05756356, grad/param norm = 1.8968e-01, time/batch = 0.3028s	
1483/2700 (epoch 27.463), train_loss = 2.10987273, grad/param norm = 2.0742e-01, time/batch = 0.3108s	
1484/2700 (epoch 27.481), train_loss = 2.11261283, grad/param norm = 1.7380e-01, time/batch = 0.3122s	
1485/2700 (epoch 27.500), train_loss = 2.10643738, grad/param norm = 1.8405e-01, time/batch = 0.3208s	
1486/2700 (epoch 27.519), train_loss = 2.09336454, grad/param norm = 1.6778e-01, time/batch = 0.3253s	
1487/2700 (epoch 27.537), train_loss = 2.10476087, grad/param norm = 1.3450e-01, time/batch = 0.3264s	
1488/2700 (epoch 27.556), train_loss = 2.08755480, grad/param norm = 1.4305e-01, time/batch = 0.2532s	
1489/2700 (epoch 27.574), train_loss = 2.07963142, grad/param norm = 1.7372e-01, time/batch = 0.3214s	
1490/2700 (epoch 27.593), train_loss = 2.08612436, grad/param norm = 1.7637e-01, time/batch = 0.3259s	
1491/2700 (epoch 27.611), train_loss = 2.01826153, grad/param norm = 1.5390e-01, time/batch = 0.3291s	
1492/2700 (epoch 27.630), train_loss = 2.03997885, grad/param norm = 1.3066e-01, time/batch = 0.3244s	
1493/2700 (epoch 27.648), train_loss = 2.06506293, grad/param norm = 1.1927e-01, time/batch = 0.3272s	
1494/2700 (epoch 27.667), train_loss = 2.05576483, grad/param norm = 1.4964e-01, time/batch = 0.3355s	
1495/2700 (epoch 27.685), train_loss = 2.07218787, grad/param norm = 2.3832e-01, time/batch = 0.3321s	
1496/2700 (epoch 27.704), train_loss = 2.10650871, grad/param norm = 2.6278e-01, time/batch = 0.3194s	
1497/2700 (epoch 27.722), train_loss = 2.06105085, grad/param norm = 2.6154e-01, time/batch = 0.3102s	
1498/2700 (epoch 27.741), train_loss = 2.12617180, grad/param norm = 2.3937e-01, time/batch = 0.3039s	
1499/2700 (epoch 27.759), train_loss = 2.14932547, grad/param norm = 2.8787e-01, time/batch = 0.2780s	
1500/2700 (epoch 27.778), train_loss = 2.13850691, grad/param norm = 3.2577e-01, time/batch = 0.3398s	
1501/2700 (epoch 27.796), train_loss = 2.10863037, grad/param norm = 3.0272e-01, time/batch = 0.3280s	
1502/2700 (epoch 27.815), train_loss = 2.16537075, grad/param norm = 2.7213e-01, time/batch = 0.3318s	
1503/2700 (epoch 27.833), train_loss = 2.10603673, grad/param norm = 2.1228e-01, time/batch = 0.3101s	
1504/2700 (epoch 27.852), train_loss = 2.11705789, grad/param norm = 1.3792e-01, time/batch = 0.3374s	
1505/2700 (epoch 27.870), train_loss = 2.06804378, grad/param norm = 1.3109e-01, time/batch = 0.3301s	
1506/2700 (epoch 27.889), train_loss = 2.06537344, grad/param norm = 1.2876e-01, time/batch = 0.3304s	
1507/2700 (epoch 27.907), train_loss = 2.20086464, grad/param norm = 1.1857e-01, time/batch = 0.3247s	
1508/2700 (epoch 27.926), train_loss = 2.12734893, grad/param norm = 1.6392e-01, time/batch = 0.3121s	
1509/2700 (epoch 27.944), train_loss = 2.12953460, grad/param norm = 1.7432e-01, time/batch = 0.3070s	
1510/2700 (epoch 27.963), train_loss = 2.13873625, grad/param norm = 1.7084e-01, time/batch = 0.2933s	
1511/2700 (epoch 27.981), train_loss = 2.10699492, grad/param norm = 1.6228e-01, time/batch = 0.3161s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1512/2700 (epoch 28.000), train_loss = 2.13595494, grad/param norm = 1.1936e-01, time/batch = 0.2985s	
1513/2700 (epoch 28.019), train_loss = 2.13225235, grad/param norm = 1.3222e-01, time/batch = 0.3379s	
1514/2700 (epoch 28.037), train_loss = 2.13708402, grad/param norm = 1.8028e-01, time/batch = 0.3347s	
1515/2700 (epoch 28.056), train_loss = 2.10806772, grad/param norm = 2.3727e-01, time/batch = 0.3279s	
1516/2700 (epoch 28.074), train_loss = 2.08083566, grad/param norm = 2.8957e-01, time/batch = 0.3320s	
1517/2700 (epoch 28.093), train_loss = 2.11757041, grad/param norm = 2.8849e-01, time/batch = 0.3357s	
1518/2700 (epoch 28.111), train_loss = 2.07644318, grad/param norm = 2.3050e-01, time/batch = 0.3311s	
1519/2700 (epoch 28.130), train_loss = 2.10894451, grad/param norm = 1.9122e-01, time/batch = 0.3219s	
1520/2700 (epoch 28.148), train_loss = 2.04489166, grad/param norm = 1.9718e-01, time/batch = 0.3010s	
1521/2700 (epoch 28.167), train_loss = 2.12484601, grad/param norm = 2.0360e-01, time/batch = 0.2634s	
1522/2700 (epoch 28.185), train_loss = 2.08088598, grad/param norm = 1.9690e-01, time/batch = 0.3206s	
1523/2700 (epoch 28.204), train_loss = 2.08045413, grad/param norm = 1.5350e-01, time/batch = 0.3210s	
1524/2700 (epoch 28.222), train_loss = 2.03598411, grad/param norm = 1.4255e-01, time/batch = 0.3096s	
1525/2700 (epoch 28.241), train_loss = 1.99066763, grad/param norm = 1.9480e-01, time/batch = 0.3188s	
1526/2700 (epoch 28.259), train_loss = 2.02289818, grad/param norm = 2.4905e-01, time/batch = 0.3218s	
1527/2700 (epoch 28.278), train_loss = 2.09633341, grad/param norm = 2.4384e-01, time/batch = 0.3277s	
1528/2700 (epoch 28.296), train_loss = 2.08612947, grad/param norm = 2.3006e-01, time/batch = 0.3402s	
1529/2700 (epoch 28.315), train_loss = 2.10523900, grad/param norm = 2.1247e-01, time/batch = 0.3253s	
1530/2700 (epoch 28.333), train_loss = 2.09919812, grad/param norm = 1.9448e-01, time/batch = 0.2811s	
1531/2700 (epoch 28.352), train_loss = 2.08645429, grad/param norm = 1.9248e-01, time/batch = 0.3141s	
1532/2700 (epoch 28.370), train_loss = 2.12312882, grad/param norm = 2.4002e-01, time/batch = 0.2987s	
1533/2700 (epoch 28.389), train_loss = 2.08729097, grad/param norm = 2.8972e-01, time/batch = 0.3048s	
1534/2700 (epoch 28.407), train_loss = 2.10099067, grad/param norm = 2.2031e-01, time/batch = 0.2980s	
1535/2700 (epoch 28.426), train_loss = 2.12215077, grad/param norm = 1.3177e-01, time/batch = 0.3092s	
1536/2700 (epoch 28.444), train_loss = 2.03287936, grad/param norm = 1.1779e-01, time/batch = 0.3234s	
1537/2700 (epoch 28.463), train_loss = 2.08577929, grad/param norm = 1.5535e-01, time/batch = 0.3230s	
1538/2700 (epoch 28.481), train_loss = 2.08927779, grad/param norm = 1.3732e-01, time/batch = 0.3133s	
1539/2700 (epoch 28.500), train_loss = 2.08208955, grad/param norm = 1.5658e-01, time/batch = 0.3104s	
1540/2700 (epoch 28.519), train_loss = 2.07782297, grad/param norm = 1.5732e-01, time/batch = 0.2837s	
1541/2700 (epoch 28.537), train_loss = 2.08789227, grad/param norm = 1.6525e-01, time/batch = 0.3314s	
1542/2700 (epoch 28.556), train_loss = 2.06759779, grad/param norm = 1.6043e-01, time/batch = 0.3144s	
1543/2700 (epoch 28.574), train_loss = 2.05842171, grad/param norm = 1.5600e-01, time/batch = 0.3007s	
1544/2700 (epoch 28.593), train_loss = 2.06505553, grad/param norm = 1.5825e-01, time/batch = 0.3001s	
1545/2700 (epoch 28.611), train_loss = 2.00177963, grad/param norm = 2.1903e-01, time/batch = 0.3022s	
1546/2700 (epoch 28.630), train_loss = 2.03966844, grad/param norm = 3.1968e-01, time/batch = 0.3084s	
1547/2700 (epoch 28.648), train_loss = 2.07465338, grad/param norm = 3.2173e-01, time/batch = 0.3173s	
1548/2700 (epoch 28.667), train_loss = 2.05654562, grad/param norm = 2.4479e-01, time/batch = 0.3273s	
1549/2700 (epoch 28.685), train_loss = 2.06615376, grad/param norm = 2.3165e-01, time/batch = 0.2791s	
1550/2700 (epoch 28.704), train_loss = 2.08349698, grad/param norm = 1.7747e-01, time/batch = 0.2843s	
1551/2700 (epoch 28.722), train_loss = 2.03593420, grad/param norm = 1.4233e-01, time/batch = 0.3204s	
1552/2700 (epoch 28.741), train_loss = 2.09741831, grad/param norm = 1.3529e-01, time/batch = 0.3131s	
1553/2700 (epoch 28.759), train_loss = 2.11691973, grad/param norm = 1.1826e-01, time/batch = 0.3089s	
1554/2700 (epoch 28.778), train_loss = 2.09894780, grad/param norm = 1.2595e-01, time/batch = 0.2414s	
1555/2700 (epoch 28.796), train_loss = 2.05939591, grad/param norm = 1.1980e-01, time/batch = 0.3146s	
1556/2700 (epoch 28.815), train_loss = 2.11554954, grad/param norm = 1.0484e-01, time/batch = 0.3194s	
1557/2700 (epoch 28.833), train_loss = 2.06907502, grad/param norm = 1.2182e-01, time/batch = 0.3171s	
1558/2700 (epoch 28.852), train_loss = 2.09308911, grad/param norm = 1.4921e-01, time/batch = 0.2993s	
1559/2700 (epoch 28.870), train_loss = 2.06432314, grad/param norm = 2.2104e-01, time/batch = 0.2968s	
1560/2700 (epoch 28.889), train_loss = 2.08231841, grad/param norm = 2.9312e-01, time/batch = 0.2696s	
1561/2700 (epoch 28.907), train_loss = 2.22423162, grad/param norm = 2.9849e-01, time/batch = 0.2994s	
1562/2700 (epoch 28.926), train_loss = 2.13941094, grad/param norm = 2.8979e-01, time/batch = 0.3000s	
1563/2700 (epoch 28.944), train_loss = 2.12833387, grad/param norm = 2.6875e-01, time/batch = 0.3101s	
1564/2700 (epoch 28.963), train_loss = 2.12398656, grad/param norm = 2.2935e-01, time/batch = 0.3070s	
1565/2700 (epoch 28.981), train_loss = 2.09576350, grad/param norm = 2.3372e-01, time/batch = 0.2958s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
1566/2700 (epoch 29.000), train_loss = 2.12255046, grad/param norm = 1.9729e-01, time/batch = 0.3186s	
1567/2700 (epoch 29.019), train_loss = 2.12365914, grad/param norm = 2.2218e-01, time/batch = 0.3162s	
1568/2700 (epoch 29.037), train_loss = 2.13203398, grad/param norm = 2.8253e-01, time/batch = 0.2675s	
1569/2700 (epoch 29.056), train_loss = 2.09026948, grad/param norm = 2.7456e-01, time/batch = 0.3035s	
1570/2700 (epoch 29.074), train_loss = 2.04586296, grad/param norm = 2.3860e-01, time/batch = 0.2867s	
1571/2700 (epoch 29.093), train_loss = 2.07592830, grad/param norm = 2.2286e-01, time/batch = 0.3121s	
1572/2700 (epoch 29.111), train_loss = 2.03697963, grad/param norm = 2.0065e-01, time/batch = 0.3035s	
1573/2700 (epoch 29.130), train_loss = 2.08758264, grad/param norm = 2.2888e-01, time/batch = 0.2993s	
1574/2700 (epoch 29.148), train_loss = 2.02881985, grad/param norm = 2.3819e-01, time/batch = 0.3066s	
1575/2700 (epoch 29.167), train_loss = 2.10640308, grad/param norm = 1.9678e-01, time/batch = 0.3080s	
1576/2700 (epoch 29.185), train_loss = 2.05898259, grad/param norm = 1.5794e-01, time/batch = 0.3220s	
1577/2700 (epoch 29.204), train_loss = 2.06052291, grad/param norm = 1.1727e-01, time/batch = 0.3017s	
1578/2700 (epoch 29.222), train_loss = 2.01724140, grad/param norm = 1.1115e-01, time/batch = 0.3003s	
1579/2700 (epoch 29.241), train_loss = 1.96977770, grad/param norm = 1.5495e-01, time/batch = 0.2959s	
1580/2700 (epoch 29.259), train_loss = 2.00218065, grad/param norm = 1.9681e-01, time/batch = 0.2724s	
1581/2700 (epoch 29.278), train_loss = 2.07204292, grad/param norm = 1.7938e-01, time/batch = 0.3001s	
1582/2700 (epoch 29.296), train_loss = 2.06545672, grad/param norm = 1.7049e-01, time/batch = 0.2997s	
1583/2700 (epoch 29.315), train_loss = 2.08290605, grad/param norm = 1.6152e-01, time/batch = 0.3052s	
1584/2700 (epoch 29.333), train_loss = 2.07823008, grad/param norm = 1.5460e-01, time/batch = 0.3134s	
1585/2700 (epoch 29.352), train_loss = 2.06425217, grad/param norm = 1.5358e-01, time/batch = 0.3189s	
1586/2700 (epoch 29.370), train_loss = 2.10298013, grad/param norm = 1.8670e-01, time/batch = 0.3167s	
1587/2700 (epoch 29.389), train_loss = 2.06522658, grad/param norm = 2.2713e-01, time/batch = 0.2932s	
1588/2700 (epoch 29.407), train_loss = 2.08343914, grad/param norm = 1.8907e-01, time/batch = 0.2972s	
1589/2700 (epoch 29.426), train_loss = 2.10645927, grad/param norm = 1.1473e-01, time/batch = 0.3001s	
1590/2700 (epoch 29.444), train_loss = 2.01306775, grad/param norm = 1.0865e-01, time/batch = 0.2768s	
1591/2700 (epoch 29.463), train_loss = 2.07048363, grad/param norm = 1.5327e-01, time/batch = 0.3026s	
1592/2700 (epoch 29.481), train_loss = 2.07156166, grad/param norm = 1.2808e-01, time/batch = 0.3109s	
1593/2700 (epoch 29.500), train_loss = 2.06267973, grad/param norm = 1.4144e-01, time/batch = 0.3155s	
1594/2700 (epoch 29.519), train_loss = 2.06069993, grad/param norm = 1.4733e-01, time/batch = 0.3154s	
1595/2700 (epoch 29.537), train_loss = 2.07411798, grad/param norm = 1.7901e-01, time/batch = 0.3151s	
1596/2700 (epoch 29.556), train_loss = 2.06273639, grad/param norm = 2.5911e-01, time/batch = 0.3223s	
1597/2700 (epoch 29.574), train_loss = 2.07063005, grad/param norm = 3.0220e-01, time/batch = 0.3281s	
1598/2700 (epoch 29.593), train_loss = 2.08244013, grad/param norm = 3.2229e-01, time/batch = 0.3257s	
1599/2700 (epoch 29.611), train_loss = 2.00713819, grad/param norm = 3.3922e-01, time/batch = 0.2488s	
1600/2700 (epoch 29.630), train_loss = 2.01997414, grad/param norm = 2.7719e-01, time/batch = 0.2978s	
1601/2700 (epoch 29.648), train_loss = 2.03509144, grad/param norm = 2.0258e-01, time/batch = 0.3289s	
1602/2700 (epoch 29.667), train_loss = 2.02076509, grad/param norm = 1.4956e-01, time/batch = 0.3239s	
1603/2700 (epoch 29.685), train_loss = 2.03239051, grad/param norm = 1.7590e-01, time/batch = 0.3284s	
1604/2700 (epoch 29.704), train_loss = 2.06229115, grad/param norm = 1.9551e-01, time/batch = 0.3325s	
1605/2700 (epoch 29.722), train_loss = 2.01981162, grad/param norm = 2.0362e-01, time/batch = 0.3319s	
1606/2700 (epoch 29.741), train_loss = 2.07953338, grad/param norm = 1.8633e-01, time/batch = 0.3211s	
1607/2700 (epoch 29.759), train_loss = 2.10677524, grad/param norm = 2.1857e-01, time/batch = 0.3079s	
1608/2700 (epoch 29.778), train_loss = 2.09193487, grad/param norm = 2.2581e-01, time/batch = 0.3113s	
1609/2700 (epoch 29.796), train_loss = 2.05409904, grad/param norm = 1.7817e-01, time/batch = 0.3034s	
1610/2700 (epoch 29.815), train_loss = 2.10883587, grad/param norm = 1.6818e-01, time/batch = 0.2739s	
1611/2700 (epoch 29.833), train_loss = 2.05544771, grad/param norm = 1.3889e-01, time/batch = 0.3481s	
1612/2700 (epoch 29.852), train_loss = 2.06929876, grad/param norm = 9.4481e-02, time/batch = 0.3362s	
1613/2700 (epoch 29.870), train_loss = 2.03051727, grad/param norm = 1.1179e-01, time/batch = 0.3311s	
1614/2700 (epoch 29.889), train_loss = 2.03347227, grad/param norm = 1.3797e-01, time/batch = 0.3330s	
1615/2700 (epoch 29.907), train_loss = 2.16678906, grad/param norm = 1.3600e-01, time/batch = 0.3192s	
1616/2700 (epoch 29.926), train_loss = 2.09688750, grad/param norm = 1.4470e-01, time/batch = 0.3252s	
1617/2700 (epoch 29.944), train_loss = 2.09717509, grad/param norm = 1.8010e-01, time/batch = 0.3187s	
1618/2700 (epoch 29.963), train_loss = 2.10676560, grad/param norm = 2.0139e-01, time/batch = 0.3087s	
1619/2700 (epoch 29.981), train_loss = 2.08008629, grad/param norm = 1.9507e-01, time/batch = 0.3061s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
1620/2700 (epoch 30.000), train_loss = 2.10482414, grad/param norm = 1.4951e-01, time/batch = 0.3265s	
1621/2700 (epoch 30.019), train_loss = 2.10015177, grad/param norm = 1.5557e-01, time/batch = 0.2995s	
1622/2700 (epoch 30.037), train_loss = 2.10651677, grad/param norm = 2.1042e-01, time/batch = 0.3202s	
1623/2700 (epoch 30.056), train_loss = 2.06900713, grad/param norm = 2.3747e-01, time/batch = 0.3244s	
1624/2700 (epoch 30.074), train_loss = 2.03107982, grad/param norm = 2.5223e-01, time/batch = 0.3240s	
1625/2700 (epoch 30.093), train_loss = 2.06125185, grad/param norm = 2.7496e-01, time/batch = 0.3243s	
1626/2700 (epoch 30.111), train_loss = 2.02498380, grad/param norm = 2.6878e-01, time/batch = 0.3214s	
1627/2700 (epoch 30.130), train_loss = 2.07541187, grad/param norm = 2.6983e-01, time/batch = 0.3306s	
1628/2700 (epoch 30.148), train_loss = 2.01599780, grad/param norm = 2.7920e-01, time/batch = 0.3327s	
1629/2700 (epoch 30.167), train_loss = 2.09551684, grad/param norm = 2.3418e-01, time/batch = 0.3150s	
1630/2700 (epoch 30.185), train_loss = 2.04321556, grad/param norm = 1.7624e-01, time/batch = 0.3169s	
1631/2700 (epoch 30.204), train_loss = 2.04550786, grad/param norm = 1.1912e-01, time/batch = 0.3162s	
1632/2700 (epoch 30.222), train_loss = 2.00161916, grad/param norm = 1.1387e-01, time/batch = 0.3070s	
1633/2700 (epoch 30.241), train_loss = 1.95197653, grad/param norm = 1.4520e-01, time/batch = 0.3025s	
1634/2700 (epoch 30.259), train_loss = 1.98907179, grad/param norm = 1.8685e-01, time/batch = 0.3015s	
1635/2700 (epoch 30.278), train_loss = 2.06487280, grad/param norm = 2.0621e-01, time/batch = 0.3025s	
1636/2700 (epoch 30.296), train_loss = 2.06622023, grad/param norm = 2.6557e-01, time/batch = 0.3182s	
1637/2700 (epoch 30.315), train_loss = 2.08702677, grad/param norm = 2.4699e-01, time/batch = 0.3205s	
1638/2700 (epoch 30.333), train_loss = 2.06688928, grad/param norm = 1.9861e-01, time/batch = 0.3237s	
1639/2700 (epoch 30.352), train_loss = 2.04579926, grad/param norm = 1.6760e-01, time/batch = 0.3099s	
1640/2700 (epoch 30.370), train_loss = 2.07744752, grad/param norm = 1.3170e-01, time/batch = 0.3369s	
1641/2700 (epoch 30.389), train_loss = 2.03929295, grad/param norm = 1.3296e-01, time/batch = 0.3173s	
1642/2700 (epoch 30.407), train_loss = 2.05989345, grad/param norm = 1.1905e-01, time/batch = 0.2793s	
1643/2700 (epoch 30.426), train_loss = 2.08934794, grad/param norm = 1.0128e-01, time/batch = 0.2592s	
1644/2700 (epoch 30.444), train_loss = 1.99588438, grad/param norm = 1.1231e-01, time/batch = 0.3295s	
1645/2700 (epoch 30.463), train_loss = 2.05424475, grad/param norm = 1.4687e-01, time/batch = 0.3238s	
1646/2700 (epoch 30.481), train_loss = 2.05541942, grad/param norm = 1.2601e-01, time/batch = 0.3151s	
1647/2700 (epoch 30.500), train_loss = 2.04279416, grad/param norm = 1.4166e-01, time/batch = 0.3171s	
1648/2700 (epoch 30.519), train_loss = 2.04559378, grad/param norm = 1.5682e-01, time/batch = 0.3173s	
1649/2700 (epoch 30.537), train_loss = 2.05862793, grad/param norm = 2.0076e-01, time/batch = 0.2696s	
1650/2700 (epoch 30.556), train_loss = 2.04254694, grad/param norm = 2.5039e-01, time/batch = 0.3088s	
1651/2700 (epoch 30.574), train_loss = 2.04144490, grad/param norm = 2.5518e-01, time/batch = 0.2962s	
1652/2700 (epoch 30.593), train_loss = 2.04972398, grad/param norm = 2.5760e-01, time/batch = 0.2984s	
1653/2700 (epoch 30.611), train_loss = 1.97808920, grad/param norm = 2.8727e-01, time/batch = 0.3018s	
1654/2700 (epoch 30.630), train_loss = 2.00021151, grad/param norm = 2.5304e-01, time/batch = 0.2761s	
1655/2700 (epoch 30.648), train_loss = 2.01781451, grad/param norm = 1.9978e-01, time/batch = 0.3319s	
1656/2700 (epoch 30.667), train_loss = 2.00733005, grad/param norm = 1.6095e-01, time/batch = 0.3161s	
1657/2700 (epoch 30.685), train_loss = 2.02150190, grad/param norm = 1.9906e-01, time/batch = 0.3122s	
1658/2700 (epoch 30.704), train_loss = 2.04923173, grad/param norm = 2.1433e-01, time/batch = 0.3054s	
1659/2700 (epoch 30.722), train_loss = 2.00589647, grad/param norm = 2.1843e-01, time/batch = 0.2710s	
1660/2700 (epoch 30.741), train_loss = 2.06105864, grad/param norm = 1.9379e-01, time/batch = 0.3221s	
1661/2700 (epoch 30.759), train_loss = 2.09125062, grad/param norm = 2.3507e-01, time/batch = 0.2812s	
1662/2700 (epoch 30.778), train_loss = 2.07588271, grad/param norm = 2.4128e-01, time/batch = 0.3154s	
1663/2700 (epoch 30.796), train_loss = 2.03835597, grad/param norm = 1.7748e-01, time/batch = 0.3266s	
1664/2700 (epoch 30.815), train_loss = 2.09372395, grad/param norm = 1.6899e-01, time/batch = 0.3066s	
1665/2700 (epoch 30.833), train_loss = 2.04111826, grad/param norm = 1.4560e-01, time/batch = 0.2786s	
1666/2700 (epoch 30.852), train_loss = 2.05336212, grad/param norm = 1.0762e-01, time/batch = 0.3161s	
1667/2700 (epoch 30.870), train_loss = 2.01710904, grad/param norm = 1.4171e-01, time/batch = 0.3160s	
1668/2700 (epoch 30.889), train_loss = 2.02165491, grad/param norm = 1.6635e-01, time/batch = 0.2991s	
1669/2700 (epoch 30.907), train_loss = 2.15124020, grad/param norm = 1.4856e-01, time/batch = 0.2860s	
1670/2700 (epoch 30.926), train_loss = 2.08162406, grad/param norm = 1.1932e-01, time/batch = 0.3202s	
1671/2700 (epoch 30.944), train_loss = 2.07620117, grad/param norm = 1.2060e-01, time/batch = 0.3009s	
1672/2700 (epoch 30.963), train_loss = 2.08416545, grad/param norm = 1.3551e-01, time/batch = 0.2997s	
1673/2700 (epoch 30.981), train_loss = 2.05847882, grad/param norm = 1.3766e-01, time/batch = 0.3106s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
1674/2700 (epoch 31.000), train_loss = 2.08613725, grad/param norm = 1.2680e-01, time/batch = 0.3108s	
1675/2700 (epoch 31.019), train_loss = 2.08243090, grad/param norm = 1.6787e-01, time/batch = 0.3088s	
1676/2700 (epoch 31.037), train_loss = 2.09351753, grad/param norm = 2.1868e-01, time/batch = 0.3026s	
1677/2700 (epoch 31.056), train_loss = 2.06840044, grad/param norm = 3.4079e-01, time/batch = 0.3197s	
1678/2700 (epoch 31.074), train_loss = 2.03916124, grad/param norm = 3.4882e-01, time/batch = 0.3075s	
1679/2700 (epoch 31.093), train_loss = 2.05619894, grad/param norm = 2.3543e-01, time/batch = 0.2594s	
1680/2700 (epoch 31.111), train_loss = 2.01595956, grad/param norm = 2.0104e-01, time/batch = 0.3043s	
1681/2700 (epoch 31.130), train_loss = 2.05461532, grad/param norm = 1.8100e-01, time/batch = 0.3046s	
1682/2700 (epoch 31.148), train_loss = 1.98898715, grad/param norm = 1.4655e-01, time/batch = 0.3064s	
1683/2700 (epoch 31.167), train_loss = 2.06950111, grad/param norm = 1.3859e-01, time/batch = 0.3112s	
1684/2700 (epoch 31.185), train_loss = 2.02515283, grad/param norm = 1.2084e-01, time/batch = 0.3085s	
1685/2700 (epoch 31.204), train_loss = 2.02904870, grad/param norm = 1.1832e-01, time/batch = 0.3142s	
1686/2700 (epoch 31.222), train_loss = 1.98604824, grad/param norm = 1.2661e-01, time/batch = 0.3165s	
1687/2700 (epoch 31.241), train_loss = 1.93254610, grad/param norm = 1.1882e-01, time/batch = 0.3166s	
1688/2700 (epoch 31.259), train_loss = 1.96439570, grad/param norm = 1.1685e-01, time/batch = 0.3221s	
1689/2700 (epoch 31.278), train_loss = 2.03190726, grad/param norm = 1.1866e-01, time/batch = 0.2243s	
1690/2700 (epoch 31.296), train_loss = 2.02862596, grad/param norm = 1.6260e-01, time/batch = 0.3191s	
1691/2700 (epoch 31.315), train_loss = 2.04457942, grad/param norm = 2.1694e-01, time/batch = 0.3263s	
1692/2700 (epoch 31.333), train_loss = 2.05118808, grad/param norm = 2.6820e-01, time/batch = 0.3083s	
1693/2700 (epoch 31.352), train_loss = 2.03473765, grad/param norm = 2.7582e-01, time/batch = 0.2984s	
1694/2700 (epoch 31.370), train_loss = 2.06717448, grad/param norm = 2.1997e-01, time/batch = 0.3033s	
1695/2700 (epoch 31.389), train_loss = 2.02660008, grad/param norm = 1.6087e-01, time/batch = 0.3086s	
1696/2700 (epoch 31.407), train_loss = 2.05272767, grad/param norm = 1.8253e-01, time/batch = 0.3079s	
1697/2700 (epoch 31.426), train_loss = 2.08381212, grad/param norm = 1.9447e-01, time/batch = 0.3105s	
1698/2700 (epoch 31.444), train_loss = 1.98175632, grad/param norm = 1.6606e-01, time/batch = 0.2930s	
1699/2700 (epoch 31.463), train_loss = 2.04170267, grad/param norm = 1.6315e-01, time/batch = 0.2707s	
1700/2700 (epoch 31.481), train_loss = 2.04396845, grad/param norm = 1.5458e-01, time/batch = 0.3137s	
1701/2700 (epoch 31.500), train_loss = 2.03266107, grad/param norm = 1.9088e-01, time/batch = 0.3198s	
1702/2700 (epoch 31.519), train_loss = 2.04452337, grad/param norm = 2.2604e-01, time/batch = 0.3097s	
1703/2700 (epoch 31.537), train_loss = 2.05601021, grad/param norm = 2.3608e-01, time/batch = 0.3001s	
1704/2700 (epoch 31.556), train_loss = 2.03750499, grad/param norm = 2.5238e-01, time/batch = 0.2967s	
1705/2700 (epoch 31.574), train_loss = 2.03438339, grad/param norm = 2.3636e-01, time/batch = 0.3080s	
1706/2700 (epoch 31.593), train_loss = 2.02898230, grad/param norm = 1.7956e-01, time/batch = 0.3146s	
1707/2700 (epoch 31.611), train_loss = 1.94647725, grad/param norm = 1.4997e-01, time/batch = 0.3271s	
1708/2700 (epoch 31.630), train_loss = 1.96985080, grad/param norm = 1.2188e-01, time/batch = 0.3104s	
1709/2700 (epoch 31.648), train_loss = 1.99476417, grad/param norm = 1.1358e-01, time/batch = 0.2933s	
1710/2700 (epoch 31.667), train_loss = 1.98896463, grad/param norm = 1.3215e-01, time/batch = 0.2929s	
1711/2700 (epoch 31.685), train_loss = 2.00658228, grad/param norm = 2.0780e-01, time/batch = 0.3023s	
1712/2700 (epoch 31.704), train_loss = 2.03715034, grad/param norm = 2.3682e-01, time/batch = 0.3106s	
1713/2700 (epoch 31.722), train_loss = 1.99500860, grad/param norm = 2.6189e-01, time/batch = 0.3173s	
1714/2700 (epoch 31.741), train_loss = 2.04795142, grad/param norm = 2.3420e-01, time/batch = 0.3197s	
1715/2700 (epoch 31.759), train_loss = 2.07959269, grad/param norm = 2.6134e-01, time/batch = 0.3107s	
1716/2700 (epoch 31.778), train_loss = 2.06013286, grad/param norm = 2.4940e-01, time/batch = 0.3103s	
1717/2700 (epoch 31.796), train_loss = 2.02324133, grad/param norm = 1.7443e-01, time/batch = 0.3102s	
1718/2700 (epoch 31.815), train_loss = 2.07688552, grad/param norm = 1.5258e-01, time/batch = 0.3150s	
1719/2700 (epoch 31.833), train_loss = 2.02338251, grad/param norm = 1.2542e-01, time/batch = 0.2864s	
1720/2700 (epoch 31.852), train_loss = 2.03540007, grad/param norm = 9.8438e-02, time/batch = 0.3193s	
1721/2700 (epoch 31.870), train_loss = 2.00134780, grad/param norm = 1.1723e-01, time/batch = 0.3129s	
1722/2700 (epoch 31.889), train_loss = 2.00576603, grad/param norm = 1.3776e-01, time/batch = 0.3141s	
1723/2700 (epoch 31.907), train_loss = 2.13852540, grad/param norm = 1.6343e-01, time/batch = 0.2983s	
1724/2700 (epoch 31.926), train_loss = 2.07862051, grad/param norm = 2.5057e-01, time/batch = 0.3024s	
1725/2700 (epoch 31.944), train_loss = 2.07770387, grad/param norm = 2.7833e-01, time/batch = 0.3051s	
1726/2700 (epoch 31.963), train_loss = 2.07532954, grad/param norm = 2.2930e-01, time/batch = 0.3154s	
1727/2700 (epoch 31.981), train_loss = 2.04714969, grad/param norm = 1.8029e-01, time/batch = 0.3141s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
1728/2700 (epoch 32.000), train_loss = 2.07050893, grad/param norm = 1.1496e-01, time/batch = 0.3182s	
1729/2700 (epoch 32.019), train_loss = 2.06660111, grad/param norm = 1.2522e-01, time/batch = 0.2846s	
1730/2700 (epoch 32.037), train_loss = 2.07603217, grad/param norm = 1.8295e-01, time/batch = 0.3184s	
1731/2700 (epoch 32.056), train_loss = 2.03664881, grad/param norm = 2.4414e-01, time/batch = 0.3117s	
1732/2700 (epoch 32.074), train_loss = 2.00674553, grad/param norm = 2.5362e-01, time/batch = 0.3122s	
1733/2700 (epoch 32.093), train_loss = 2.03017737, grad/param norm = 2.2363e-01, time/batch = 0.3137s	
1734/2700 (epoch 32.111), train_loss = 1.98811821, grad/param norm = 1.9800e-01, time/batch = 0.2998s	
1735/2700 (epoch 32.130), train_loss = 2.03895037, grad/param norm = 2.1391e-01, time/batch = 0.3023s	
1736/2700 (epoch 32.148), train_loss = 1.97706583, grad/param norm = 1.9460e-01, time/batch = 0.3146s	
1737/2700 (epoch 32.167), train_loss = 2.06033895, grad/param norm = 1.6665e-01, time/batch = 0.3064s	
1738/2700 (epoch 32.185), train_loss = 2.01063693, grad/param norm = 1.4001e-01, time/batch = 0.3217s	
1739/2700 (epoch 32.204), train_loss = 2.01412038, grad/param norm = 1.0949e-01, time/batch = 0.2978s	
1740/2700 (epoch 32.222), train_loss = 1.97160393, grad/param norm = 1.1318e-01, time/batch = 0.3288s	
1741/2700 (epoch 32.241), train_loss = 1.91851932, grad/param norm = 1.6003e-01, time/batch = 0.3164s	
1742/2700 (epoch 32.259), train_loss = 1.95584172, grad/param norm = 1.9620e-01, time/batch = 0.3227s	
1743/2700 (epoch 32.278), train_loss = 2.01883133, grad/param norm = 1.7721e-01, time/batch = 0.2462s	
1744/2700 (epoch 32.296), train_loss = 2.01410529, grad/param norm = 1.5346e-01, time/batch = 0.3114s	
1745/2700 (epoch 32.315), train_loss = 2.02558269, grad/param norm = 1.5207e-01, time/batch = 0.3133s	
1746/2700 (epoch 32.333), train_loss = 2.02889800, grad/param norm = 1.6357e-01, time/batch = 0.3176s	
1747/2700 (epoch 32.352), train_loss = 2.01529158, grad/param norm = 1.8642e-01, time/batch = 0.3076s	
1748/2700 (epoch 32.370), train_loss = 2.05984016, grad/param norm = 2.8585e-01, time/batch = 0.3001s	
1749/2700 (epoch 32.389), train_loss = 2.03886770, grad/param norm = 4.0888e-01, time/batch = 0.2815s	
1750/2700 (epoch 32.407), train_loss = 2.05288843, grad/param norm = 3.0948e-01, time/batch = 0.3328s	
1751/2700 (epoch 32.426), train_loss = 2.06453673, grad/param norm = 1.3082e-01, time/batch = 0.3102s	
1752/2700 (epoch 32.444), train_loss = 1.96559856, grad/param norm = 1.2380e-01, time/batch = 0.3164s	
1753/2700 (epoch 32.463), train_loss = 2.03131097, grad/param norm = 1.5802e-01, time/batch = 0.2907s	
1754/2700 (epoch 32.481), train_loss = 2.02952718, grad/param norm = 1.3512e-01, time/batch = 0.2876s	
1755/2700 (epoch 32.500), train_loss = 2.00628513, grad/param norm = 1.3795e-01, time/batch = 0.3158s	
1756/2700 (epoch 32.519), train_loss = 2.01393506, grad/param norm = 1.2228e-01, time/batch = 0.3131s	
1757/2700 (epoch 32.537), train_loss = 2.02536237, grad/param norm = 1.2698e-01, time/batch = 0.3037s	
1758/2700 (epoch 32.556), train_loss = 1.99787948, grad/param norm = 1.2181e-01, time/batch = 0.3062s	
1759/2700 (epoch 32.574), train_loss = 1.99281287, grad/param norm = 1.2571e-01, time/batch = 0.2725s	
1760/2700 (epoch 32.593), train_loss = 1.99931477, grad/param norm = 1.2803e-01, time/batch = 0.3343s	
1761/2700 (epoch 32.611), train_loss = 1.92771569, grad/param norm = 1.6066e-01, time/batch = 0.3071s	
1762/2700 (epoch 32.630), train_loss = 1.96847788, grad/param norm = 2.0186e-01, time/batch = 0.2798s	
1763/2700 (epoch 32.648), train_loss = 2.00170369, grad/param norm = 2.4203e-01, time/batch = 0.3019s	
1764/2700 (epoch 32.667), train_loss = 2.00769480, grad/param norm = 2.9308e-01, time/batch = 0.3093s	
1765/2700 (epoch 32.685), train_loss = 2.01418755, grad/param norm = 3.0579e-01, time/batch = 0.3015s	
1766/2700 (epoch 32.704), train_loss = 2.03440382, grad/param norm = 2.4657e-01, time/batch = 0.3136s	
1767/2700 (epoch 32.722), train_loss = 1.97623034, grad/param norm = 1.9543e-01, time/batch = 0.3061s	
1768/2700 (epoch 32.741), train_loss = 2.02568431, grad/param norm = 1.5541e-01, time/batch = 0.2984s	
1769/2700 (epoch 32.759), train_loss = 2.06210046, grad/param norm = 1.8419e-01, time/batch = 0.2707s	
1770/2700 (epoch 32.778), train_loss = 2.04421455, grad/param norm = 1.8364e-01, time/batch = 0.3280s	
1771/2700 (epoch 32.796), train_loss = 2.00899829, grad/param norm = 1.6359e-01, time/batch = 0.3113s	
1772/2700 (epoch 32.815), train_loss = 2.06350466, grad/param norm = 1.5381e-01, time/batch = 0.2867s	
1773/2700 (epoch 32.833), train_loss = 2.00946521, grad/param norm = 1.2021e-01, time/batch = 0.3080s	
1774/2700 (epoch 32.852), train_loss = 2.02105347, grad/param norm = 1.2175e-01, time/batch = 0.3122s	
1775/2700 (epoch 32.870), train_loss = 1.99092384, grad/param norm = 1.6283e-01, time/batch = 0.3145s	
1776/2700 (epoch 32.889), train_loss = 1.99558414, grad/param norm = 1.8016e-01, time/batch = 0.3191s	
1777/2700 (epoch 32.907), train_loss = 2.12296206, grad/param norm = 1.5025e-01, time/batch = 0.2646s	
1778/2700 (epoch 32.926), train_loss = 2.05616052, grad/param norm = 1.3579e-01, time/batch = 0.3023s	
1779/2700 (epoch 32.944), train_loss = 2.04958801, grad/param norm = 1.5747e-01, time/batch = 0.2874s	
1780/2700 (epoch 32.963), train_loss = 2.05351931, grad/param norm = 1.6107e-01, time/batch = 0.3491s	
1781/2700 (epoch 32.981), train_loss = 2.03114151, grad/param norm = 1.4967e-01, time/batch = 0.2938s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
1782/2700 (epoch 33.000), train_loss = 2.05607260, grad/param norm = 1.1567e-01, time/batch = 0.3109s	
1783/2700 (epoch 33.019), train_loss = 2.05329034, grad/param norm = 1.3775e-01, time/batch = 0.3117s	
1784/2700 (epoch 33.037), train_loss = 2.06369188, grad/param norm = 1.8280e-01, time/batch = 0.3137s	
1785/2700 (epoch 33.056), train_loss = 2.02082200, grad/param norm = 2.4668e-01, time/batch = 0.3086s	
1786/2700 (epoch 33.074), train_loss = 1.98503744, grad/param norm = 2.3524e-01, time/batch = 0.3025s	
1787/2700 (epoch 33.093), train_loss = 2.00552222, grad/param norm = 1.5741e-01, time/batch = 0.3004s	
1788/2700 (epoch 33.111), train_loss = 1.96843410, grad/param norm = 1.5449e-01, time/batch = 0.2813s	
1789/2700 (epoch 33.130), train_loss = 2.02245308, grad/param norm = 1.9258e-01, time/batch = 0.2767s	
1790/2700 (epoch 33.148), train_loss = 1.96188348, grad/param norm = 1.7711e-01, time/batch = 0.3241s	
1791/2700 (epoch 33.167), train_loss = 2.04721852, grad/param norm = 1.6331e-01, time/batch = 0.3218s	
1792/2700 (epoch 33.185), train_loss = 1.99636561, grad/param norm = 1.4432e-01, time/batch = 0.3130s	
1793/2700 (epoch 33.204), train_loss = 2.00127873, grad/param norm = 1.1561e-01, time/batch = 0.3119s	
1794/2700 (epoch 33.222), train_loss = 1.95882564, grad/param norm = 1.2499e-01, time/batch = 0.2986s	
1795/2700 (epoch 33.241), train_loss = 1.90421142, grad/param norm = 1.7655e-01, time/batch = 0.3069s	
1796/2700 (epoch 33.259), train_loss = 1.94529731, grad/param norm = 2.2696e-01, time/batch = 0.3048s	
1797/2700 (epoch 33.278), train_loss = 2.00788465, grad/param norm = 2.2796e-01, time/batch = 0.3112s	
1798/2700 (epoch 33.296), train_loss = 2.00465279, grad/param norm = 2.0093e-01, time/batch = 0.3148s	
1799/2700 (epoch 33.315), train_loss = 2.01186282, grad/param norm = 1.9232e-01, time/batch = 0.2603s	
1800/2700 (epoch 33.333), train_loss = 2.01697112, grad/param norm = 1.9301e-01, time/batch = 0.3151s	
1801/2700 (epoch 33.352), train_loss = 2.00050919, grad/param norm = 1.9836e-01, time/batch = 0.3194s	
1802/2700 (epoch 33.370), train_loss = 2.04562240, grad/param norm = 2.7469e-01, time/batch = 0.3181s	
1803/2700 (epoch 33.389), train_loss = 2.01930775, grad/param norm = 3.8621e-01, time/batch = 0.3101s	
1804/2700 (epoch 33.407), train_loss = 2.03823360, grad/param norm = 2.9007e-01, time/batch = 0.2967s	
1805/2700 (epoch 33.426), train_loss = 2.05235377, grad/param norm = 1.1650e-01, time/batch = 0.3000s	
1806/2700 (epoch 33.444), train_loss = 1.95097150, grad/param norm = 1.2420e-01, time/batch = 0.3011s	
1807/2700 (epoch 33.463), train_loss = 2.01877553, grad/param norm = 1.5904e-01, time/batch = 0.2999s	
1808/2700 (epoch 33.481), train_loss = 2.01555228, grad/param norm = 1.3334e-01, time/batch = 0.3150s	
1809/2700 (epoch 33.500), train_loss = 1.99042502, grad/param norm = 1.3419e-01, time/batch = 0.3050s	
1810/2700 (epoch 33.519), train_loss = 2.00101245, grad/param norm = 1.1760e-01, time/batch = 0.2848s	
1811/2700 (epoch 33.537), train_loss = 2.01024400, grad/param norm = 1.2148e-01, time/batch = 0.3101s	
1812/2700 (epoch 33.556), train_loss = 1.98031588, grad/param norm = 1.0774e-01, time/batch = 0.3499s	
1813/2700 (epoch 33.574), train_loss = 1.97659893, grad/param norm = 1.1503e-01, time/batch = 0.3456s	
1814/2700 (epoch 33.593), train_loss = 1.98374891, grad/param norm = 1.0532e-01, time/batch = 0.3239s	
1815/2700 (epoch 33.611), train_loss = 1.90890772, grad/param norm = 1.1409e-01, time/batch = 0.3256s	
1816/2700 (epoch 33.630), train_loss = 1.94243673, grad/param norm = 1.2303e-01, time/batch = 0.3170s	
1817/2700 (epoch 33.648), train_loss = 1.96785463, grad/param norm = 1.2335e-01, time/batch = 0.3052s	
1818/2700 (epoch 33.667), train_loss = 1.96777478, grad/param norm = 1.6003e-01, time/batch = 0.2916s	
1819/2700 (epoch 33.685), train_loss = 1.98983069, grad/param norm = 2.3607e-01, time/batch = 0.3271s	
1820/2700 (epoch 33.704), train_loss = 2.01845098, grad/param norm = 2.3592e-01, time/batch = 0.3334s	
1821/2700 (epoch 33.722), train_loss = 1.97102970, grad/param norm = 1.9574e-01, time/batch = 0.2905s	
1822/2700 (epoch 33.741), train_loss = 2.01074122, grad/param norm = 1.5380e-01, time/batch = 0.3435s	
1823/2700 (epoch 33.759), train_loss = 2.04928672, grad/param norm = 1.7676e-01, time/batch = 0.3354s	
1824/2700 (epoch 33.778), train_loss = 2.03393986, grad/param norm = 2.0193e-01, time/batch = 0.3103s	
1825/2700 (epoch 33.796), train_loss = 2.00257144, grad/param norm = 2.1737e-01, time/batch = 0.3115s	
1826/2700 (epoch 33.815), train_loss = 2.05438887, grad/param norm = 2.3090e-01, time/batch = 0.3161s	
1827/2700 (epoch 33.833), train_loss = 2.01076408, grad/param norm = 2.4429e-01, time/batch = 0.3190s	
1828/2700 (epoch 33.852), train_loss = 2.03322011, grad/param norm = 2.8908e-01, time/batch = 0.2788s	
1829/2700 (epoch 33.870), train_loss = 2.00349804, grad/param norm = 2.8714e-01, time/batch = 0.3087s	
1830/2700 (epoch 33.889), train_loss = 1.99788295, grad/param norm = 2.3458e-01, time/batch = 0.3123s	
1831/2700 (epoch 33.907), train_loss = 2.11288213, grad/param norm = 1.5501e-01, time/batch = 0.3059s	
1832/2700 (epoch 33.926), train_loss = 2.04708231, grad/param norm = 1.5674e-01, time/batch = 0.2744s	
1833/2700 (epoch 33.944), train_loss = 2.03603805, grad/param norm = 1.5522e-01, time/batch = 0.3296s	
1834/2700 (epoch 33.963), train_loss = 2.03781679, grad/param norm = 1.3896e-01, time/batch = 0.3199s	
1835/2700 (epoch 33.981), train_loss = 2.01590604, grad/param norm = 1.3125e-01, time/batch = 0.3154s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
1836/2700 (epoch 34.000), train_loss = 2.04251594, grad/param norm = 1.1130e-01, time/batch = 0.3262s	
1837/2700 (epoch 34.019), train_loss = 2.03989901, grad/param norm = 1.3904e-01, time/batch = 0.3120s	
1838/2700 (epoch 34.037), train_loss = 2.04932607, grad/param norm = 1.6764e-01, time/batch = 0.2598s	
1839/2700 (epoch 34.056), train_loss = 2.00072016, grad/param norm = 2.0504e-01, time/batch = 0.3101s	
1840/2700 (epoch 34.074), train_loss = 1.96082510, grad/param norm = 1.8950e-01, time/batch = 0.3108s	
1841/2700 (epoch 34.093), train_loss = 1.98127976, grad/param norm = 1.1266e-01, time/batch = 0.3049s	
1842/2700 (epoch 34.111), train_loss = 1.94643991, grad/param norm = 1.2024e-01, time/batch = 0.3121s	
1843/2700 (epoch 34.130), train_loss = 2.00375399, grad/param norm = 1.6440e-01, time/batch = 0.2807s	
1844/2700 (epoch 34.148), train_loss = 1.94390224, grad/param norm = 1.5875e-01, time/batch = 0.3251s	
1845/2700 (epoch 34.167), train_loss = 2.03061229, grad/param norm = 1.4941e-01, time/batch = 0.3105s	
1846/2700 (epoch 34.185), train_loss = 1.98102830, grad/param norm = 1.4292e-01, time/batch = 0.3072s	
1847/2700 (epoch 34.204), train_loss = 1.98862341, grad/param norm = 1.1255e-01, time/batch = 0.3006s	
1848/2700 (epoch 34.222), train_loss = 1.94540207, grad/param norm = 1.1785e-01, time/batch = 0.2654s	
1849/2700 (epoch 34.241), train_loss = 1.89005877, grad/param norm = 1.6674e-01, time/batch = 0.3247s	
1850/2700 (epoch 34.259), train_loss = 1.93240234, grad/param norm = 2.1170e-01, time/batch = 0.3319s	
1851/2700 (epoch 34.278), train_loss = 1.99400835, grad/param norm = 2.1193e-01, time/batch = 0.3002s	
1852/2700 (epoch 34.296), train_loss = 1.99132866, grad/param norm = 1.8491e-01, time/batch = 0.3050s	
1853/2700 (epoch 34.315), train_loss = 1.99651920, grad/param norm = 1.6775e-01, time/batch = 0.3141s	
1854/2700 (epoch 34.333), train_loss = 2.00025208, grad/param norm = 1.5100e-01, time/batch = 0.2883s	
1855/2700 (epoch 34.352), train_loss = 1.98157257, grad/param norm = 1.4687e-01, time/batch = 0.3184s	
1856/2700 (epoch 34.370), train_loss = 2.02439377, grad/param norm = 2.1599e-01, time/batch = 0.3116s	
1857/2700 (epoch 34.389), train_loss = 1.99773128, grad/param norm = 3.3741e-01, time/batch = 0.3002s	
1858/2700 (epoch 34.407), train_loss = 2.02230253, grad/param norm = 2.8536e-01, time/batch = 0.2590s	
1859/2700 (epoch 34.426), train_loss = 2.04018439, grad/param norm = 1.4092e-01, time/batch = 0.3247s	
1860/2700 (epoch 34.444), train_loss = 1.93876484, grad/param norm = 1.4210e-01, time/batch = 0.3289s	
1861/2700 (epoch 34.463), train_loss = 2.00888712, grad/param norm = 1.7770e-01, time/batch = 0.3082s	
1862/2700 (epoch 34.481), train_loss = 2.00427997, grad/param norm = 1.4738e-01, time/batch = 0.3014s	
1863/2700 (epoch 34.500), train_loss = 1.97550208, grad/param norm = 1.4443e-01, time/batch = 0.3062s	
1864/2700 (epoch 34.519), train_loss = 1.98929196, grad/param norm = 1.2426e-01, time/batch = 0.3123s	
1865/2700 (epoch 34.537), train_loss = 1.99775771, grad/param norm = 1.2275e-01, time/batch = 0.3086s	
1866/2700 (epoch 34.556), train_loss = 1.96774476, grad/param norm = 1.0941e-01, time/batch = 0.3230s	
1867/2700 (epoch 34.574), train_loss = 1.96315396, grad/param norm = 1.1999e-01, time/batch = 0.2597s	
1868/2700 (epoch 34.593), train_loss = 1.97116777, grad/param norm = 1.1368e-01, time/batch = 0.2760s	
1869/2700 (epoch 34.611), train_loss = 1.89427753, grad/param norm = 1.2331e-01, time/batch = 0.3187s	
1870/2700 (epoch 34.630), train_loss = 1.92993686, grad/param norm = 1.3625e-01, time/batch = 0.3237s	
1871/2700 (epoch 34.648), train_loss = 1.95553290, grad/param norm = 1.4791e-01, time/batch = 0.3024s	
1872/2700 (epoch 34.667), train_loss = 1.95734733, grad/param norm = 1.9915e-01, time/batch = 0.2973s	
1873/2700 (epoch 34.685), train_loss = 1.97645371, grad/param norm = 2.6034e-01, time/batch = 0.3009s	
1874/2700 (epoch 34.704), train_loss = 2.00770955, grad/param norm = 2.6307e-01, time/batch = 0.3106s	
1875/2700 (epoch 34.722), train_loss = 1.96348873, grad/param norm = 2.7710e-01, time/batch = 0.3147s	
1876/2700 (epoch 34.741), train_loss = 2.01458030, grad/param norm = 2.5501e-01, time/batch = 0.3051s	
1877/2700 (epoch 34.759), train_loss = 2.06970367, grad/param norm = 2.9853e-01, time/batch = 0.3092s	
1878/2700 (epoch 34.778), train_loss = 2.04391329, grad/param norm = 2.5335e-01, time/batch = 0.2594s	
1879/2700 (epoch 34.796), train_loss = 1.99565358, grad/param norm = 1.9857e-01, time/batch = 0.3188s	
1880/2700 (epoch 34.815), train_loss = 2.03930273, grad/param norm = 1.6939e-01, time/batch = 0.3281s	
1881/2700 (epoch 34.833), train_loss = 1.98379038, grad/param norm = 1.2114e-01, time/batch = 0.2971s	
1882/2700 (epoch 34.852), train_loss = 1.99208607, grad/param norm = 1.1655e-01, time/batch = 0.3028s	
1883/2700 (epoch 34.870), train_loss = 1.96398073, grad/param norm = 1.4438e-01, time/batch = 0.3095s	
1884/2700 (epoch 34.889), train_loss = 1.96827045, grad/param norm = 1.3876e-01, time/batch = 0.3167s	
1885/2700 (epoch 34.907), train_loss = 2.09212655, grad/param norm = 1.1814e-01, time/batch = 0.3194s	
1886/2700 (epoch 34.926), train_loss = 2.03084841, grad/param norm = 1.5596e-01, time/batch = 0.3112s	
1887/2700 (epoch 34.944), train_loss = 2.02248134, grad/param norm = 1.6997e-01, time/batch = 0.2969s	
1888/2700 (epoch 34.963), train_loss = 2.02547000, grad/param norm = 1.5885e-01, time/batch = 0.2791s	
1889/2700 (epoch 34.981), train_loss = 2.00474416, grad/param norm = 1.4962e-01, time/batch = 0.3105s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
1890/2700 (epoch 35.000), train_loss = 2.03027397, grad/param norm = 1.2010e-01, time/batch = 0.3129s	
1891/2700 (epoch 35.019), train_loss = 2.02931579, grad/param norm = 1.5237e-01, time/batch = 0.3151s	
1892/2700 (epoch 35.037), train_loss = 2.04132172, grad/param norm = 1.9759e-01, time/batch = 0.3030s	
1893/2700 (epoch 35.056), train_loss = 1.99112679, grad/param norm = 2.3374e-01, time/batch = 0.3046s	
1894/2700 (epoch 35.074), train_loss = 1.95155021, grad/param norm = 2.0263e-01, time/batch = 0.3102s	
1895/2700 (epoch 35.093), train_loss = 1.97077290, grad/param norm = 1.3782e-01, time/batch = 0.2915s	
1896/2700 (epoch 35.111), train_loss = 1.93310168, grad/param norm = 1.3883e-01, time/batch = 0.3087s	
1897/2700 (epoch 35.130), train_loss = 1.99109866, grad/param norm = 1.8009e-01, time/batch = 0.3212s	
1898/2700 (epoch 35.148), train_loss = 1.93169948, grad/param norm = 1.7609e-01, time/batch = 0.3145s	
1899/2700 (epoch 35.167), train_loss = 2.02063720, grad/param norm = 1.6779e-01, time/batch = 0.3200s	
1900/2700 (epoch 35.185), train_loss = 1.96988935, grad/param norm = 1.6138e-01, time/batch = 0.3065s	
1901/2700 (epoch 35.204), train_loss = 1.97737596, grad/param norm = 1.2316e-01, time/batch = 0.3445s	
1902/2700 (epoch 35.222), train_loss = 1.93335492, grad/param norm = 1.2491e-01, time/batch = 0.3352s	
1903/2700 (epoch 35.241), train_loss = 1.87790380, grad/param norm = 1.8575e-01, time/batch = 0.3281s	
1904/2700 (epoch 35.259), train_loss = 1.92198003, grad/param norm = 2.1729e-01, time/batch = 0.3074s	
1905/2700 (epoch 35.278), train_loss = 1.97992902, grad/param norm = 1.9322e-01, time/batch = 0.3109s	
1906/2700 (epoch 35.296), train_loss = 1.97804848, grad/param norm = 1.5793e-01, time/batch = 0.3156s	
1907/2700 (epoch 35.315), train_loss = 1.98065464, grad/param norm = 1.2921e-01, time/batch = 0.3248s	
1908/2700 (epoch 35.333), train_loss = 1.98400144, grad/param norm = 1.1040e-01, time/batch = 0.3079s	
1909/2700 (epoch 35.352), train_loss = 1.96541930, grad/param norm = 1.0666e-01, time/batch = 0.2883s	
1910/2700 (epoch 35.370), train_loss = 2.00511770, grad/param norm = 1.3517e-01, time/batch = 0.3308s	
1911/2700 (epoch 35.389), train_loss = 1.97176215, grad/param norm = 1.9704e-01, time/batch = 0.3537s	
1912/2700 (epoch 35.407), train_loss = 1.99551200, grad/param norm = 1.6022e-01, time/batch = 0.3489s	
1913/2700 (epoch 35.426), train_loss = 2.02347633, grad/param norm = 9.0603e-02, time/batch = 0.3406s	
1914/2700 (epoch 35.444), train_loss = 1.92173987, grad/param norm = 9.6306e-02, time/batch = 0.3339s	
1915/2700 (epoch 35.463), train_loss = 1.99411268, grad/param norm = 1.5707e-01, time/batch = 0.3218s	
1916/2700 (epoch 35.481), train_loss = 1.99532503, grad/param norm = 1.6006e-01, time/batch = 0.3100s	
1917/2700 (epoch 35.500), train_loss = 1.97200284, grad/param norm = 2.1315e-01, time/batch = 0.2813s	
1918/2700 (epoch 35.519), train_loss = 2.00210463, grad/param norm = 2.5609e-01, time/batch = 0.3078s	
1919/2700 (epoch 35.537), train_loss = 2.01032189, grad/param norm = 2.2444e-01, time/batch = 0.3186s	
1920/2700 (epoch 35.556), train_loss = 1.97672225, grad/param norm = 2.3701e-01, time/batch = 0.3143s	
1921/2700 (epoch 35.574), train_loss = 1.97311755, grad/param norm = 2.1496e-01, time/batch = 0.3259s	
1922/2700 (epoch 35.593), train_loss = 1.96651362, grad/param norm = 1.4911e-01, time/batch = 0.3078s	
1923/2700 (epoch 35.611), train_loss = 1.88625703, grad/param norm = 1.8940e-01, time/batch = 0.3240s	
1924/2700 (epoch 35.630), train_loss = 1.92124573, grad/param norm = 2.2585e-01, time/batch = 0.3267s	
1925/2700 (epoch 35.648), train_loss = 1.94634483, grad/param norm = 2.2926e-01, time/batch = 0.3148s	
1926/2700 (epoch 35.667), train_loss = 1.94243524, grad/param norm = 1.6836e-01, time/batch = 0.3197s	
1927/2700 (epoch 35.685), train_loss = 1.95564193, grad/param norm = 1.7671e-01, time/batch = 0.2652s	
1928/2700 (epoch 35.704), train_loss = 1.97778534, grad/param norm = 1.5457e-01, time/batch = 0.3092s	
1929/2700 (epoch 35.722), train_loss = 1.93471195, grad/param norm = 1.2508e-01, time/batch = 0.3174s	
1930/2700 (epoch 35.741), train_loss = 1.97621634, grad/param norm = 1.1005e-01, time/batch = 0.3223s	
1931/2700 (epoch 35.759), train_loss = 2.01517589, grad/param norm = 1.0687e-01, time/batch = 0.2595s	
1932/2700 (epoch 35.778), train_loss = 1.99629063, grad/param norm = 1.1377e-01, time/batch = 0.3194s	
1933/2700 (epoch 35.796), train_loss = 1.96518608, grad/param norm = 1.7873e-01, time/batch = 0.3232s	
1934/2700 (epoch 35.815), train_loss = 2.02405680, grad/param norm = 1.8622e-01, time/batch = 0.3209s	
1935/2700 (epoch 35.833), train_loss = 1.97069697, grad/param norm = 1.4684e-01, time/batch = 0.3117s	
1936/2700 (epoch 35.852), train_loss = 1.98081999, grad/param norm = 1.5277e-01, time/batch = 0.3081s	
1937/2700 (epoch 35.870), train_loss = 1.95580964, grad/param norm = 2.0441e-01, time/batch = 0.2693s	
1938/2700 (epoch 35.889), train_loss = 1.96347227, grad/param norm = 2.3229e-01, time/batch = 0.3218s	
1939/2700 (epoch 35.907), train_loss = 2.08846590, grad/param norm = 1.8800e-01, time/batch = 0.3303s	
1940/2700 (epoch 35.926), train_loss = 2.02144658, grad/param norm = 1.3478e-01, time/batch = 0.3169s	
1941/2700 (epoch 35.944), train_loss = 2.01423844, grad/param norm = 1.6280e-01, time/batch = 0.3035s	
1942/2700 (epoch 35.963), train_loss = 2.01942110, grad/param norm = 1.6826e-01, time/batch = 0.2576s	
1943/2700 (epoch 35.981), train_loss = 2.00007601, grad/param norm = 1.8412e-01, time/batch = 0.3189s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
1944/2700 (epoch 36.000), train_loss = 2.02424666, grad/param norm = 1.8793e-01, time/batch = 0.3174s	
1945/2700 (epoch 36.019), train_loss = 2.01790176, grad/param norm = 1.9789e-01, time/batch = 0.3036s	
1946/2700 (epoch 36.037), train_loss = 2.02345597, grad/param norm = 1.8159e-01, time/batch = 0.2977s	
1947/2700 (epoch 36.056), train_loss = 1.97760710, grad/param norm = 2.3968e-01, time/batch = 0.2832s	
1948/2700 (epoch 36.074), train_loss = 1.93866380, grad/param norm = 2.2637e-01, time/batch = 0.3287s	
1949/2700 (epoch 36.093), train_loss = 1.95239194, grad/param norm = 1.2014e-01, time/batch = 0.3398s	
1950/2700 (epoch 36.111), train_loss = 1.91884212, grad/param norm = 1.2203e-01, time/batch = 0.3305s	
1951/2700 (epoch 36.130), train_loss = 1.97842959, grad/param norm = 1.6164e-01, time/batch = 0.3047s	
1952/2700 (epoch 36.148), train_loss = 1.91869936, grad/param norm = 1.6605e-01, time/batch = 0.3011s	
1953/2700 (epoch 36.167), train_loss = 2.00871087, grad/param norm = 1.6743e-01, time/batch = 0.2938s	
1954/2700 (epoch 36.185), train_loss = 1.95817384, grad/param norm = 1.5633e-01, time/batch = 0.3252s	
1955/2700 (epoch 36.204), train_loss = 1.96803966, grad/param norm = 1.3944e-01, time/batch = 0.3095s	
1956/2700 (epoch 36.222), train_loss = 1.92225092, grad/param norm = 1.2792e-01, time/batch = 0.3160s	
1957/2700 (epoch 36.241), train_loss = 1.86288006, grad/param norm = 1.3195e-01, time/batch = 0.2641s	
1958/2700 (epoch 36.259), train_loss = 1.90643595, grad/param norm = 1.4751e-01, time/batch = 0.3287s	
1959/2700 (epoch 36.278), train_loss = 1.96627583, grad/param norm = 1.5140e-01, time/batch = 0.3218s	
1960/2700 (epoch 36.296), train_loss = 1.97094646, grad/param norm = 1.8639e-01, time/batch = 0.3009s	
1961/2700 (epoch 36.315), train_loss = 1.97879319, grad/param norm = 1.8973e-01, time/batch = 0.2975s	
1962/2700 (epoch 36.333), train_loss = 1.97707358, grad/param norm = 1.6599e-01, time/batch = 0.3031s	
1963/2700 (epoch 36.352), train_loss = 1.95548328, grad/param norm = 1.5848e-01, time/batch = 0.3212s	
1964/2700 (epoch 36.370), train_loss = 1.99466364, grad/param norm = 1.3774e-01, time/batch = 0.3124s	
1965/2700 (epoch 36.389), train_loss = 1.95670134, grad/param norm = 1.2301e-01, time/batch = 0.3320s	
1966/2700 (epoch 36.407), train_loss = 1.98680388, grad/param norm = 1.4296e-01, time/batch = 0.3197s	
1967/2700 (epoch 36.426), train_loss = 2.02217888, grad/param norm = 1.7775e-01, time/batch = 0.2918s	
1968/2700 (epoch 36.444), train_loss = 1.91705663, grad/param norm = 1.8639e-01, time/batch = 0.3122s	
1969/2700 (epoch 36.463), train_loss = 1.98757995, grad/param norm = 1.9188e-01, time/batch = 0.2800s	
1970/2700 (epoch 36.481), train_loss = 1.98666891, grad/param norm = 1.5796e-01, time/batch = 0.3019s	
1971/2700 (epoch 36.500), train_loss = 1.95273991, grad/param norm = 1.6871e-01, time/batch = 0.3121s	
1972/2700 (epoch 36.519), train_loss = 1.97655895, grad/param norm = 1.8508e-01, time/batch = 0.3064s	
1973/2700 (epoch 36.537), train_loss = 1.97942778, grad/param norm = 1.7872e-01, time/batch = 0.3188s	
1974/2700 (epoch 36.556), train_loss = 1.94783388, grad/param norm = 1.7995e-01, time/batch = 0.3243s	
1975/2700 (epoch 36.574), train_loss = 1.94562703, grad/param norm = 1.5967e-01, time/batch = 0.3285s	
1976/2700 (epoch 36.593), train_loss = 1.95260225, grad/param norm = 1.3912e-01, time/batch = 0.3101s	
1977/2700 (epoch 36.611), train_loss = 1.87389597, grad/param norm = 1.6932e-01, time/batch = 0.2969s	
1978/2700 (epoch 36.630), train_loss = 1.90891162, grad/param norm = 1.8912e-01, time/batch = 0.2894s	
1979/2700 (epoch 36.648), train_loss = 1.93364306, grad/param norm = 2.0523e-01, time/batch = 0.2947s	
1980/2700 (epoch 36.667), train_loss = 1.93310558, grad/param norm = 1.8558e-01, time/batch = 0.3058s	
1981/2700 (epoch 36.685), train_loss = 1.94796417, grad/param norm = 1.9494e-01, time/batch = 0.3279s	
1982/2700 (epoch 36.704), train_loss = 1.96749099, grad/param norm = 1.6039e-01, time/batch = 0.3269s	
1983/2700 (epoch 36.722), train_loss = 1.92413594, grad/param norm = 1.3452e-01, time/batch = 0.3245s	
1984/2700 (epoch 36.741), train_loss = 1.96287167, grad/param norm = 1.0745e-01, time/batch = 0.3316s	
1985/2700 (epoch 36.759), train_loss = 2.00428033, grad/param norm = 1.3697e-01, time/batch = 0.3393s	
1986/2700 (epoch 36.778), train_loss = 1.98617121, grad/param norm = 1.5921e-01, time/batch = 0.3411s	
1987/2700 (epoch 36.796), train_loss = 1.95238683, grad/param norm = 1.2496e-01, time/batch = 0.3073s	
1988/2700 (epoch 36.815), train_loss = 2.00825442, grad/param norm = 1.3886e-01, time/batch = 0.3112s	
1989/2700 (epoch 36.833), train_loss = 1.96135637, grad/param norm = 1.5443e-01, time/batch = 0.3185s	
1990/2700 (epoch 36.852), train_loss = 1.96912623, grad/param norm = 1.6386e-01, time/batch = 0.3232s	
1991/2700 (epoch 36.870), train_loss = 1.94391019, grad/param norm = 1.8984e-01, time/batch = 0.3029s	
1992/2700 (epoch 36.889), train_loss = 1.95831504, grad/param norm = 2.7518e-01, time/batch = 0.3148s	
1993/2700 (epoch 36.907), train_loss = 2.10152188, grad/param norm = 3.7826e-01, time/batch = 0.3191s	
1994/2700 (epoch 36.926), train_loss = 2.03316440, grad/param norm = 3.9437e-01, time/batch = 0.2980s	
1995/2700 (epoch 36.944), train_loss = 2.00669677, grad/param norm = 2.3547e-01, time/batch = 0.3072s	
1996/2700 (epoch 36.963), train_loss = 2.00030841, grad/param norm = 1.2763e-01, time/batch = 0.3063s	
1997/2700 (epoch 36.981), train_loss = 1.98074818, grad/param norm = 1.3623e-01, time/batch = 0.3123s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
1998/2700 (epoch 37.000), train_loss = 2.00855769, grad/param norm = 1.3897e-01, time/batch = 0.3270s	
1999/2700 (epoch 37.019), train_loss = 2.01321623, grad/param norm = 2.0256e-01, time/batch = 0.3148s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch37.04_2.0562.t7	
2000/2700 (epoch 37.037), train_loss = 2.03414620, grad/param norm = 2.6823e-01, time/batch = 0.3092s	
2001/2700 (epoch 37.056), train_loss = 2.04976031, grad/param norm = 2.6101e-01, time/batch = 0.3490s	
2002/2700 (epoch 37.074), train_loss = 1.92661982, grad/param norm = 1.7762e-01, time/batch = 0.3479s	
2003/2700 (epoch 37.093), train_loss = 1.94172519, grad/param norm = 1.2513e-01, time/batch = 0.3244s	
2004/2700 (epoch 37.111), train_loss = 1.90750237, grad/param norm = 1.2540e-01, time/batch = 0.3489s	
2005/2700 (epoch 37.130), train_loss = 1.96499210, grad/param norm = 1.5327e-01, time/batch = 0.3273s	
2006/2700 (epoch 37.148), train_loss = 1.90326370, grad/param norm = 1.1785e-01, time/batch = 0.3067s	
2007/2700 (epoch 37.167), train_loss = 1.99524488, grad/param norm = 1.2026e-01, time/batch = 0.3137s	
2008/2700 (epoch 37.185), train_loss = 1.94299424, grad/param norm = 1.0792e-01, time/batch = 0.3114s	
2009/2700 (epoch 37.204), train_loss = 1.95285550, grad/param norm = 1.1387e-01, time/batch = 0.3007s	
2010/2700 (epoch 37.222), train_loss = 1.91003667, grad/param norm = 1.1937e-01, time/batch = 0.3047s	
2011/2700 (epoch 37.241), train_loss = 1.85012112, grad/param norm = 1.6264e-01, time/batch = 0.3081s	
2012/2700 (epoch 37.259), train_loss = 1.89403716, grad/param norm = 1.6849e-01, time/batch = 0.3284s	
2013/2700 (epoch 37.278), train_loss = 1.95003443, grad/param norm = 1.3530e-01, time/batch = 0.3141s	
2014/2700 (epoch 37.296), train_loss = 1.95236462, grad/param norm = 1.0684e-01, time/batch = 0.3251s	
2015/2700 (epoch 37.315), train_loss = 1.95176506, grad/param norm = 1.0425e-01, time/batch = 0.3234s	
2016/2700 (epoch 37.333), train_loss = 1.96113680, grad/param norm = 1.1878e-01, time/batch = 0.3099s	
2017/2700 (epoch 37.352), train_loss = 1.94432644, grad/param norm = 1.4198e-01, time/batch = 0.3132s	
2018/2700 (epoch 37.370), train_loss = 1.99110476, grad/param norm = 1.8331e-01, time/batch = 0.3041s	
2019/2700 (epoch 37.389), train_loss = 1.96458447, grad/param norm = 2.8155e-01, time/batch = 0.3051s	
2020/2700 (epoch 37.407), train_loss = 1.98638367, grad/param norm = 2.1291e-01, time/batch = 0.3051s	
2021/2700 (epoch 37.426), train_loss = 2.00577696, grad/param norm = 1.0826e-01, time/batch = 0.3145s	
2022/2700 (epoch 37.444), train_loss = 1.89759111, grad/param norm = 1.0342e-01, time/batch = 0.3195s	
2023/2700 (epoch 37.463), train_loss = 1.97192136, grad/param norm = 1.5176e-01, time/batch = 0.3120s	
2024/2700 (epoch 37.481), train_loss = 1.96968415, grad/param norm = 1.3840e-01, time/batch = 0.3161s	
2025/2700 (epoch 37.500), train_loss = 1.93214507, grad/param norm = 1.3759e-01, time/batch = 0.3282s	
2026/2700 (epoch 37.519), train_loss = 1.95561877, grad/param norm = 1.1635e-01, time/batch = 0.3321s	
2027/2700 (epoch 37.537), train_loss = 1.96186204, grad/param norm = 1.0507e-01, time/batch = 0.3267s	
2028/2700 (epoch 37.556), train_loss = 1.93047264, grad/param norm = 1.1921e-01, time/batch = 0.3259s	
2029/2700 (epoch 37.574), train_loss = 1.93126078, grad/param norm = 1.5016e-01, time/batch = 0.3134s	
2030/2700 (epoch 37.593), train_loss = 1.94036245, grad/param norm = 1.4223e-01, time/batch = 0.3040s	
2031/2700 (epoch 37.611), train_loss = 1.86066993, grad/param norm = 1.3270e-01, time/batch = 0.2854s	
2032/2700 (epoch 37.630), train_loss = 1.89420494, grad/param norm = 1.2030e-01, time/batch = 0.3086s	
2033/2700 (epoch 37.648), train_loss = 1.91815235, grad/param norm = 1.2342e-01, time/batch = 0.3059s	
2034/2700 (epoch 37.667), train_loss = 1.92240469, grad/param norm = 1.6552e-01, time/batch = 0.3098s	
2035/2700 (epoch 37.685), train_loss = 1.94279296, grad/param norm = 2.3230e-01, time/batch = 0.3132s	
2036/2700 (epoch 37.704), train_loss = 1.96431956, grad/param norm = 2.2675e-01, time/batch = 0.3190s	
2037/2700 (epoch 37.722), train_loss = 1.92140625, grad/param norm = 2.2400e-01, time/batch = 0.3213s	
2038/2700 (epoch 37.741), train_loss = 1.95512009, grad/param norm = 2.0343e-01, time/batch = 0.3217s	
2039/2700 (epoch 37.759), train_loss = 2.00094941, grad/param norm = 2.4427e-01, time/batch = 0.3346s	
2040/2700 (epoch 37.778), train_loss = 1.98428403, grad/param norm = 2.5393e-01, time/batch = 0.3225s	
2041/2700 (epoch 37.796), train_loss = 1.95584054, grad/param norm = 1.9953e-01, time/batch = 0.3528s	
2042/2700 (epoch 37.815), train_loss = 2.01047529, grad/param norm = 2.0197e-01, time/batch = 0.3123s	
2043/2700 (epoch 37.833), train_loss = 1.95520984, grad/param norm = 1.7796e-01, time/batch = 0.3202s	
2044/2700 (epoch 37.852), train_loss = 1.95637775, grad/param norm = 1.4301e-01, time/batch = 0.3089s	
2045/2700 (epoch 37.870), train_loss = 1.92803315, grad/param norm = 1.2015e-01, time/batch = 0.3069s	
2046/2700 (epoch 37.889), train_loss = 1.93650494, grad/param norm = 1.4993e-01, time/batch = 0.3217s	
2047/2700 (epoch 37.907), train_loss = 2.06541861, grad/param norm = 2.1181e-01, time/batch = 0.3243s	
2048/2700 (epoch 37.926), train_loss = 2.00168997, grad/param norm = 2.5378e-01, time/batch = 0.3314s	
2049/2700 (epoch 37.944), train_loss = 1.99053102, grad/param norm = 2.0091e-01, time/batch = 0.3228s	
2050/2700 (epoch 37.963), train_loss = 1.98910453, grad/param norm = 1.4095e-01, time/batch = 0.3198s	
2051/2700 (epoch 37.981), train_loss = 1.96850136, grad/param norm = 1.2799e-01, time/batch = 0.3163s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2052/2700 (epoch 38.000), train_loss = 1.99708339, grad/param norm = 1.2161e-01, time/batch = 0.2716s	
2053/2700 (epoch 38.019), train_loss = 1.99887159, grad/param norm = 1.7095e-01, time/batch = 0.3176s	
2054/2700 (epoch 38.037), train_loss = 2.01425230, grad/param norm = 2.3174e-01, time/batch = 0.3237s	
2055/2700 (epoch 38.056), train_loss = 1.96171822, grad/param norm = 2.7535e-01, time/batch = 0.3160s	
2056/2700 (epoch 38.074), train_loss = 1.92043454, grad/param norm = 2.1577e-01, time/batch = 0.3058s	
2057/2700 (epoch 38.093), train_loss = 1.93127437, grad/param norm = 1.5558e-01, time/batch = 0.3176s	
2058/2700 (epoch 38.111), train_loss = 1.89628922, grad/param norm = 1.3672e-01, time/batch = 0.3322s	
2059/2700 (epoch 38.130), train_loss = 1.95295675, grad/param norm = 1.5324e-01, time/batch = 0.3191s	
2060/2700 (epoch 38.148), train_loss = 1.89159463, grad/param norm = 1.2126e-01, time/batch = 0.3057s	
2061/2700 (epoch 38.167), train_loss = 1.98458208, grad/param norm = 1.2222e-01, time/batch = 0.3327s	
2062/2700 (epoch 38.185), train_loss = 1.93301403, grad/param norm = 1.2153e-01, time/batch = 0.2946s	
2063/2700 (epoch 38.204), train_loss = 1.94283677, grad/param norm = 1.1591e-01, time/batch = 0.3132s	
2064/2700 (epoch 38.222), train_loss = 1.90026597, grad/param norm = 1.2248e-01, time/batch = 0.3039s	
2065/2700 (epoch 38.241), train_loss = 1.84010387, grad/param norm = 1.8226e-01, time/batch = 0.2974s	
2066/2700 (epoch 38.259), train_loss = 1.88649513, grad/param norm = 1.9444e-01, time/batch = 0.3169s	
2067/2700 (epoch 38.278), train_loss = 1.94070491, grad/param norm = 1.6470e-01, time/batch = 0.3155s	
2068/2700 (epoch 38.296), train_loss = 1.94282487, grad/param norm = 1.2720e-01, time/batch = 0.2850s	
2069/2700 (epoch 38.315), train_loss = 1.94138702, grad/param norm = 1.0289e-01, time/batch = 0.3203s	
2070/2700 (epoch 38.333), train_loss = 1.94886059, grad/param norm = 1.0106e-01, time/batch = 0.3110s	
2071/2700 (epoch 38.352), train_loss = 1.92938905, grad/param norm = 1.0979e-01, time/batch = 0.3120s	
2072/2700 (epoch 38.370), train_loss = 1.97297397, grad/param norm = 1.6116e-01, time/batch = 0.3339s	
2073/2700 (epoch 38.389), train_loss = 1.94331171, grad/param norm = 2.6173e-01, time/batch = 0.3290s	
2074/2700 (epoch 38.407), train_loss = 1.96878721, grad/param norm = 2.0652e-01, time/batch = 0.3338s	
2075/2700 (epoch 38.426), train_loss = 1.99251417, grad/param norm = 1.0599e-01, time/batch = 0.3322s	
2076/2700 (epoch 38.444), train_loss = 1.88664258, grad/param norm = 1.1776e-01, time/batch = 0.3251s	
2077/2700 (epoch 38.463), train_loss = 1.96433525, grad/param norm = 1.7558e-01, time/batch = 0.3146s	
2078/2700 (epoch 38.481), train_loss = 1.96089849, grad/param norm = 1.5985e-01, time/batch = 0.3118s	
2079/2700 (epoch 38.500), train_loss = 1.92256258, grad/param norm = 1.6705e-01, time/batch = 0.3219s	
2080/2700 (epoch 38.519), train_loss = 1.95030418, grad/param norm = 1.6082e-01, time/batch = 0.3276s	
2081/2700 (epoch 38.537), train_loss = 1.95475956, grad/param norm = 1.3822e-01, time/batch = 0.3051s	
2082/2700 (epoch 38.556), train_loss = 1.92664928, grad/param norm = 1.8169e-01, time/batch = 0.2801s	
2083/2700 (epoch 38.574), train_loss = 1.93316796, grad/param norm = 2.1359e-01, time/batch = 0.3399s	
2084/2700 (epoch 38.593), train_loss = 1.93676129, grad/param norm = 1.6563e-01, time/batch = 0.3406s	
2085/2700 (epoch 38.611), train_loss = 1.85331195, grad/param norm = 1.4960e-01, time/batch = 0.3342s	
2086/2700 (epoch 38.630), train_loss = 1.88475065, grad/param norm = 1.4721e-01, time/batch = 0.3251s	
2087/2700 (epoch 38.648), train_loss = 1.90656080, grad/param norm = 1.3530e-01, time/batch = 0.3159s	
2088/2700 (epoch 38.667), train_loss = 1.90628871, grad/param norm = 1.1205e-01, time/batch = 0.3160s	
2089/2700 (epoch 38.685), train_loss = 1.92279865, grad/param norm = 1.4981e-01, time/batch = 0.3182s	
2090/2700 (epoch 38.704), train_loss = 1.94320028, grad/param norm = 1.3077e-01, time/batch = 0.3224s	
2091/2700 (epoch 38.722), train_loss = 1.90379621, grad/param norm = 1.1888e-01, time/batch = 0.3099s	
2092/2700 (epoch 38.741), train_loss = 1.93657016, grad/param norm = 9.3463e-02, time/batch = 0.3004s	
2093/2700 (epoch 38.759), train_loss = 1.98160259, grad/param norm = 1.1386e-01, time/batch = 0.2940s	
2094/2700 (epoch 38.778), train_loss = 1.96409035, grad/param norm = 1.2539e-01, time/batch = 0.3481s	
2095/2700 (epoch 38.796), train_loss = 1.93505767, grad/param norm = 1.5208e-01, time/batch = 0.3350s	
2096/2700 (epoch 38.815), train_loss = 1.99285626, grad/param norm = 1.7254e-01, time/batch = 0.3376s	
2097/2700 (epoch 38.833), train_loss = 1.93927187, grad/param norm = 1.2767e-01, time/batch = 0.3304s	
2098/2700 (epoch 38.852), train_loss = 1.94175143, grad/param norm = 9.5577e-02, time/batch = 0.3168s	
2099/2700 (epoch 38.870), train_loss = 1.91639225, grad/param norm = 9.0174e-02, time/batch = 0.3148s	
2100/2700 (epoch 38.889), train_loss = 1.92371859, grad/param norm = 1.0772e-01, time/batch = 0.3190s	
2101/2700 (epoch 38.907), train_loss = 2.05063518, grad/param norm = 1.7412e-01, time/batch = 0.3057s	
2102/2700 (epoch 38.926), train_loss = 1.99311289, grad/param norm = 2.6508e-01, time/batch = 0.3170s	
2103/2700 (epoch 38.944), train_loss = 1.98840163, grad/param norm = 2.7881e-01, time/batch = 0.3039s	
2104/2700 (epoch 38.963), train_loss = 1.98549095, grad/param norm = 2.2754e-01, time/batch = 0.2772s	
2105/2700 (epoch 38.981), train_loss = 1.96471750, grad/param norm = 2.0236e-01, time/batch = 0.3386s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2106/2700 (epoch 39.000), train_loss = 1.99468493, grad/param norm = 1.7760e-01, time/batch = 0.3412s	
2107/2700 (epoch 39.019), train_loss = 1.99967709, grad/param norm = 2.4444e-01, time/batch = 0.3390s	
2108/2700 (epoch 39.037), train_loss = 2.01687197, grad/param norm = 2.9705e-01, time/batch = 0.3284s	
2109/2700 (epoch 39.056), train_loss = 1.94944929, grad/param norm = 2.6432e-01, time/batch = 0.3178s	
2110/2700 (epoch 39.074), train_loss = 1.90543094, grad/param norm = 1.8871e-01, time/batch = 0.3119s	
2111/2700 (epoch 39.093), train_loss = 1.91743542, grad/param norm = 1.4462e-01, time/batch = 0.3080s	
2112/2700 (epoch 39.111), train_loss = 1.88372068, grad/param norm = 1.3301e-01, time/batch = 0.3179s	
2113/2700 (epoch 39.130), train_loss = 1.94289051, grad/param norm = 1.5865e-01, time/batch = 0.2690s	
2114/2700 (epoch 39.148), train_loss = 1.88161077, grad/param norm = 1.3214e-01, time/batch = 0.3222s	
2115/2700 (epoch 39.167), train_loss = 1.97455802, grad/param norm = 1.2574e-01, time/batch = 0.3018s	
2116/2700 (epoch 39.185), train_loss = 1.92299174, grad/param norm = 1.3131e-01, time/batch = 0.3339s	
2117/2700 (epoch 39.204), train_loss = 1.93306376, grad/param norm = 1.1957e-01, time/batch = 0.3348s	
2118/2700 (epoch 39.222), train_loss = 1.89074078, grad/param norm = 1.2471e-01, time/batch = 0.3357s	
2119/2700 (epoch 39.241), train_loss = 1.82911650, grad/param norm = 1.8232e-01, time/batch = 0.3345s	
2120/2700 (epoch 39.259), train_loss = 1.87644941, grad/param norm = 1.8600e-01, time/batch = 0.3225s	
2121/2700 (epoch 39.278), train_loss = 1.93001867, grad/param norm = 1.5502e-01, time/batch = 0.3248s	
2122/2700 (epoch 39.296), train_loss = 1.93284450, grad/param norm = 1.2776e-01, time/batch = 0.2506s	
2123/2700 (epoch 39.315), train_loss = 1.93215015, grad/param norm = 1.1134e-01, time/batch = 0.2600s	
2124/2700 (epoch 39.333), train_loss = 1.93782867, grad/param norm = 1.0388e-01, time/batch = 0.3058s	
2125/2700 (epoch 39.352), train_loss = 1.91796729, grad/param norm = 1.0782e-01, time/batch = 0.3029s	
2126/2700 (epoch 39.370), train_loss = 1.96021673, grad/param norm = 1.3312e-01, time/batch = 0.2815s	
2127/2700 (epoch 39.389), train_loss = 1.92589216, grad/param norm = 1.8429e-01, time/batch = 0.3260s	
2128/2700 (epoch 39.407), train_loss = 1.95113519, grad/param norm = 1.4025e-01, time/batch = 0.3238s	
2129/2700 (epoch 39.426), train_loss = 1.98209703, grad/param norm = 9.0945e-02, time/batch = 0.3267s	
2130/2700 (epoch 39.444), train_loss = 1.87619083, grad/param norm = 1.0060e-01, time/batch = 0.3131s	
2131/2700 (epoch 39.463), train_loss = 1.95313181, grad/param norm = 1.5960e-01, time/batch = 0.3379s	
2132/2700 (epoch 39.481), train_loss = 1.95363575, grad/param norm = 1.5449e-01, time/batch = 0.3301s	
2133/2700 (epoch 39.500), train_loss = 1.91555296, grad/param norm = 1.7825e-01, time/batch = 0.3101s	
2134/2700 (epoch 39.519), train_loss = 1.94820748, grad/param norm = 1.9287e-01, time/batch = 0.3078s	
2135/2700 (epoch 39.537), train_loss = 1.94918378, grad/param norm = 1.6185e-01, time/batch = 0.3095s	
2136/2700 (epoch 39.556), train_loss = 1.91452700, grad/param norm = 1.7798e-01, time/batch = 0.3173s	
2137/2700 (epoch 39.574), train_loss = 1.91456446, grad/param norm = 1.7330e-01, time/batch = 0.3118s	
2138/2700 (epoch 39.593), train_loss = 1.92045612, grad/param norm = 1.3110e-01, time/batch = 0.3269s	
2139/2700 (epoch 39.611), train_loss = 1.83877983, grad/param norm = 1.7212e-01, time/batch = 0.3368s	
2140/2700 (epoch 39.630), train_loss = 1.87610155, grad/param norm = 1.9971e-01, time/batch = 0.3228s	
2141/2700 (epoch 39.648), train_loss = 1.89901618, grad/param norm = 1.9921e-01, time/batch = 0.3470s	
2142/2700 (epoch 39.667), train_loss = 1.89789800, grad/param norm = 1.4543e-01, time/batch = 0.3321s	
2143/2700 (epoch 39.685), train_loss = 1.91267129, grad/param norm = 1.5921e-01, time/batch = 0.3064s	
2144/2700 (epoch 39.704), train_loss = 1.93240038, grad/param norm = 1.3321e-01, time/batch = 0.3308s	
2145/2700 (epoch 39.722), train_loss = 1.89430735, grad/param norm = 1.0800e-01, time/batch = 0.3194s	
2146/2700 (epoch 39.741), train_loss = 1.92472331, grad/param norm = 9.2176e-02, time/batch = 0.3136s	
2147/2700 (epoch 39.759), train_loss = 1.97283836, grad/param norm = 1.1810e-01, time/batch = 0.3167s	
2148/2700 (epoch 39.778), train_loss = 1.95599987, grad/param norm = 1.4308e-01, time/batch = 0.2829s	
2149/2700 (epoch 39.796), train_loss = 1.92856215, grad/param norm = 2.2013e-01, time/batch = 0.3314s	
2150/2700 (epoch 39.815), train_loss = 1.98726475, grad/param norm = 2.3721e-01, time/batch = 0.3251s	
2151/2700 (epoch 39.833), train_loss = 1.93070894, grad/param norm = 1.6492e-01, time/batch = 0.3176s	
2152/2700 (epoch 39.852), train_loss = 1.93292159, grad/param norm = 1.3868e-01, time/batch = 0.3186s	
2153/2700 (epoch 39.870), train_loss = 1.90997986, grad/param norm = 1.6031e-01, time/batch = 0.2740s	
2154/2700 (epoch 39.889), train_loss = 1.91958175, grad/param norm = 1.7854e-01, time/batch = 0.3124s	
2155/2700 (epoch 39.907), train_loss = 2.03963342, grad/param norm = 1.6196e-01, time/batch = 0.3179s	
2156/2700 (epoch 39.926), train_loss = 1.97680230, grad/param norm = 1.3257e-01, time/batch = 0.3266s	
2157/2700 (epoch 39.944), train_loss = 1.96719081, grad/param norm = 1.3436e-01, time/batch = 0.3281s	
2158/2700 (epoch 39.963), train_loss = 1.96919077, grad/param norm = 1.5013e-01, time/batch = 0.3166s	
2159/2700 (epoch 39.981), train_loss = 1.95251216, grad/param norm = 1.7758e-01, time/batch = 0.2978s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2160/2700 (epoch 40.000), train_loss = 1.98217337, grad/param norm = 2.0053e-01, time/batch = 0.3257s	
2161/2700 (epoch 40.019), train_loss = 1.97753751, grad/param norm = 1.9924e-01, time/batch = 0.3161s	
2162/2700 (epoch 40.037), train_loss = 1.98130936, grad/param norm = 1.6212e-01, time/batch = 0.3185s	
2163/2700 (epoch 40.056), train_loss = 1.92974273, grad/param norm = 2.1218e-01, time/batch = 0.2643s	
2164/2700 (epoch 40.074), train_loss = 1.89425229, grad/param norm = 1.9555e-01, time/batch = 0.3175s	
2165/2700 (epoch 40.093), train_loss = 1.90193275, grad/param norm = 1.1646e-01, time/batch = 0.3302s	
2166/2700 (epoch 40.111), train_loss = 1.87402127, grad/param norm = 1.3293e-01, time/batch = 0.3251s	
2167/2700 (epoch 40.130), train_loss = 1.93796186, grad/param norm = 1.8521e-01, time/batch = 0.3224s	
2168/2700 (epoch 40.148), train_loss = 1.87902232, grad/param norm = 1.9712e-01, time/batch = 0.3055s	
2169/2700 (epoch 40.167), train_loss = 1.97289524, grad/param norm = 1.7906e-01, time/batch = 0.3210s	
2170/2700 (epoch 40.185), train_loss = 1.91979214, grad/param norm = 1.7033e-01, time/batch = 0.3047s	
2171/2700 (epoch 40.204), train_loss = 1.92842506, grad/param norm = 1.4311e-01, time/batch = 0.3191s	
2172/2700 (epoch 40.222), train_loss = 1.88175911, grad/param norm = 1.1692e-01, time/batch = 0.3151s	
2173/2700 (epoch 40.241), train_loss = 1.81618082, grad/param norm = 1.4456e-01, time/batch = 0.2707s	
2174/2700 (epoch 40.259), train_loss = 1.86471453, grad/param norm = 1.5473e-01, time/batch = 0.3150s	
2175/2700 (epoch 40.278), train_loss = 1.91950421, grad/param norm = 1.4422e-01, time/batch = 0.3170s	
2176/2700 (epoch 40.296), train_loss = 1.92228670, grad/param norm = 1.2707e-01, time/batch = 0.3241s	
2177/2700 (epoch 40.315), train_loss = 1.92242288, grad/param norm = 1.1980e-01, time/batch = 0.3161s	
2178/2700 (epoch 40.333), train_loss = 1.92840452, grad/param norm = 1.0890e-01, time/batch = 0.3379s	
2179/2700 (epoch 40.352), train_loss = 1.90681105, grad/param norm = 1.0695e-01, time/batch = 0.3286s	
2180/2700 (epoch 40.370), train_loss = 1.94886791, grad/param norm = 1.2343e-01, time/batch = 0.3226s	
2181/2700 (epoch 40.389), train_loss = 1.91305927, grad/param norm = 1.6841e-01, time/batch = 0.2735s	
2182/2700 (epoch 40.407), train_loss = 1.94200794, grad/param norm = 1.4041e-01, time/batch = 0.3182s	
2183/2700 (epoch 40.426), train_loss = 1.97338180, grad/param norm = 9.9151e-02, time/batch = 0.2794s	
2184/2700 (epoch 40.444), train_loss = 1.86657964, grad/param norm = 1.0892e-01, time/batch = 0.3139s	
2185/2700 (epoch 40.463), train_loss = 1.94512678, grad/param norm = 1.6859e-01, time/batch = 0.3125s	
2186/2700 (epoch 40.481), train_loss = 1.94426622, grad/param norm = 1.6052e-01, time/batch = 0.3135s	
2187/2700 (epoch 40.500), train_loss = 1.90350009, grad/param norm = 1.7567e-01, time/batch = 0.3208s	
2188/2700 (epoch 40.519), train_loss = 1.93615157, grad/param norm = 1.8095e-01, time/batch = 0.3298s	
2189/2700 (epoch 40.537), train_loss = 1.93656262, grad/param norm = 1.5459e-01, time/batch = 0.3355s	
2190/2700 (epoch 40.556), train_loss = 1.90177267, grad/param norm = 1.7538e-01, time/batch = 0.3357s	
2191/2700 (epoch 40.574), train_loss = 1.90243252, grad/param norm = 1.7137e-01, time/batch = 0.3045s	
2192/2700 (epoch 40.593), train_loss = 1.91231269, grad/param norm = 1.5682e-01, time/batch = 0.2743s	
2193/2700 (epoch 40.611), train_loss = 1.83313905, grad/param norm = 2.1476e-01, time/batch = 0.2790s	
2194/2700 (epoch 40.630), train_loss = 1.87003899, grad/param norm = 2.3567e-01, time/batch = 0.3183s	
2195/2700 (epoch 40.648), train_loss = 1.88999178, grad/param norm = 2.0762e-01, time/batch = 0.3059s	
2196/2700 (epoch 40.667), train_loss = 1.88686784, grad/param norm = 1.3445e-01, time/batch = 0.3069s	
2197/2700 (epoch 40.685), train_loss = 1.90236580, grad/param norm = 1.4725e-01, time/batch = 0.3095s	
2198/2700 (epoch 40.704), train_loss = 1.92235606, grad/param norm = 1.2498e-01, time/batch = 0.3234s	
2199/2700 (epoch 40.722), train_loss = 1.88538087, grad/param norm = 1.1004e-01, time/batch = 0.3428s	
2200/2700 (epoch 40.741), train_loss = 1.91327913, grad/param norm = 8.7382e-02, time/batch = 0.3382s	
2201/2700 (epoch 40.759), train_loss = 1.96131257, grad/param norm = 1.1492e-01, time/batch = 0.2999s	
2202/2700 (epoch 40.778), train_loss = 1.94496336, grad/param norm = 1.2726e-01, time/batch = 0.3050s	
2203/2700 (epoch 40.796), train_loss = 1.91613373, grad/param norm = 1.6419e-01, time/batch = 0.2892s	
2204/2700 (epoch 40.815), train_loss = 1.97414203, grad/param norm = 1.8530e-01, time/batch = 0.3217s	
2205/2700 (epoch 40.833), train_loss = 1.91971743, grad/param norm = 1.2222e-01, time/batch = 0.2674s	
2206/2700 (epoch 40.852), train_loss = 1.91978452, grad/param norm = 9.0360e-02, time/batch = 0.3183s	
2207/2700 (epoch 40.870), train_loss = 1.89808960, grad/param norm = 9.8952e-02, time/batch = 0.3098s	
2208/2700 (epoch 40.889), train_loss = 1.90590590, grad/param norm = 1.1532e-01, time/batch = 0.2988s	
2209/2700 (epoch 40.907), train_loss = 2.03010633, grad/param norm = 1.8620e-01, time/batch = 0.3071s	
2210/2700 (epoch 40.926), train_loss = 1.97226367, grad/param norm = 2.6742e-01, time/batch = 0.3123s	
2211/2700 (epoch 40.944), train_loss = 1.96484423, grad/param norm = 2.5557e-01, time/batch = 0.3327s	
2212/2700 (epoch 40.963), train_loss = 1.96270284, grad/param norm = 1.9265e-01, time/batch = 0.3320s	
2213/2700 (epoch 40.981), train_loss = 1.94238603, grad/param norm = 1.7571e-01, time/batch = 0.3200s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2214/2700 (epoch 41.000), train_loss = 1.97272674, grad/param norm = 1.6284e-01, time/batch = 0.2929s	
2215/2700 (epoch 41.019), train_loss = 1.97860005, grad/param norm = 2.2828e-01, time/batch = 0.3326s	
2216/2700 (epoch 41.037), train_loss = 1.99326292, grad/param norm = 2.7774e-01, time/batch = 0.3165s	
2217/2700 (epoch 41.056), train_loss = 1.92466816, grad/param norm = 2.4891e-01, time/batch = 0.3117s	
2218/2700 (epoch 41.074), train_loss = 1.88470590, grad/param norm = 1.8142e-01, time/batch = 0.3097s	
2219/2700 (epoch 41.093), train_loss = 1.89421891, grad/param norm = 1.4487e-01, time/batch = 0.3153s	
2220/2700 (epoch 41.111), train_loss = 1.86276823, grad/param norm = 1.2843e-01, time/batch = 0.3316s	
2221/2700 (epoch 41.130), train_loss = 1.92215767, grad/param norm = 1.4684e-01, time/batch = 0.3259s	
2222/2700 (epoch 41.148), train_loss = 1.85980545, grad/param norm = 1.1936e-01, time/batch = 0.3060s	
2223/2700 (epoch 41.167), train_loss = 1.95566914, grad/param norm = 1.2065e-01, time/batch = 0.2977s	
2224/2700 (epoch 41.185), train_loss = 1.90286117, grad/param norm = 1.2530e-01, time/batch = 0.3343s	
2225/2700 (epoch 41.204), train_loss = 1.91428958, grad/param norm = 1.2197e-01, time/batch = 0.3234s	
2226/2700 (epoch 41.222), train_loss = 1.87285499, grad/param norm = 1.2775e-01, time/batch = 0.3207s	
2227/2700 (epoch 41.241), train_loss = 1.80763292, grad/param norm = 1.8342e-01, time/batch = 0.3133s	
2228/2700 (epoch 41.259), train_loss = 1.85697581, grad/param norm = 1.8117e-01, time/batch = 0.3166s	
2229/2700 (epoch 41.278), train_loss = 1.91001768, grad/param norm = 1.4943e-01, time/batch = 0.3236s	
2230/2700 (epoch 41.296), train_loss = 1.91349305, grad/param norm = 1.2166e-01, time/batch = 0.3257s	
2231/2700 (epoch 41.315), train_loss = 1.91091335, grad/param norm = 1.0848e-01, time/batch = 0.3174s	
2232/2700 (epoch 41.333), train_loss = 1.91917468, grad/param norm = 1.1232e-01, time/batch = 0.2838s	
2233/2700 (epoch 41.352), train_loss = 1.90009671, grad/param norm = 1.2302e-01, time/batch = 0.3171s	
2234/2700 (epoch 41.370), train_loss = 1.94448417, grad/param norm = 1.5425e-01, time/batch = 0.3129s	
2235/2700 (epoch 41.389), train_loss = 1.90864021, grad/param norm = 2.1439e-01, time/batch = 0.3295s	
2236/2700 (epoch 41.407), train_loss = 1.93545651, grad/param norm = 1.5920e-01, time/batch = 0.3417s	
2237/2700 (epoch 41.426), train_loss = 1.96414554, grad/param norm = 9.2792e-02, time/batch = 0.3287s	
2238/2700 (epoch 41.444), train_loss = 1.85488282, grad/param norm = 1.0550e-01, time/batch = 0.3182s	
2239/2700 (epoch 41.463), train_loss = 1.93469120, grad/param norm = 1.5754e-01, time/batch = 0.3100s	
2240/2700 (epoch 41.481), train_loss = 1.93174524, grad/param norm = 1.3504e-01, time/batch = 0.3232s	
2241/2700 (epoch 41.500), train_loss = 1.88458285, grad/param norm = 1.1942e-01, time/batch = 0.2856s	
2242/2700 (epoch 41.519), train_loss = 1.91713851, grad/param norm = 1.0860e-01, time/batch = 0.3061s	
2243/2700 (epoch 41.537), train_loss = 1.91978694, grad/param norm = 1.2738e-01, time/batch = 0.3167s	
2244/2700 (epoch 41.556), train_loss = 1.88355056, grad/param norm = 1.2512e-01, time/batch = 0.3039s	
2245/2700 (epoch 41.574), train_loss = 1.88284333, grad/param norm = 1.1993e-01, time/batch = 0.3227s	
2246/2700 (epoch 41.593), train_loss = 1.89699992, grad/param norm = 1.3488e-01, time/batch = 0.3553s	
2247/2700 (epoch 41.611), train_loss = 1.82002003, grad/param norm = 2.0518e-01, time/batch = 0.3436s	
2248/2700 (epoch 41.630), train_loss = 1.86103037, grad/param norm = 2.3671e-01, time/batch = 0.3234s	
2249/2700 (epoch 41.648), train_loss = 1.88190128, grad/param norm = 2.2562e-01, time/batch = 0.3174s	
2250/2700 (epoch 41.667), train_loss = 1.88037659, grad/param norm = 1.6833e-01, time/batch = 0.2824s	
2251/2700 (epoch 41.685), train_loss = 1.89364740, grad/param norm = 1.5813e-01, time/batch = 0.3068s	
2252/2700 (epoch 41.704), train_loss = 1.91430310, grad/param norm = 1.3803e-01, time/batch = 0.2850s	
2253/2700 (epoch 41.722), train_loss = 1.88008057, grad/param norm = 1.4955e-01, time/batch = 0.3100s	
2254/2700 (epoch 41.741), train_loss = 1.91021634, grad/param norm = 1.4612e-01, time/batch = 0.3217s	
2255/2700 (epoch 41.759), train_loss = 1.97167045, grad/param norm = 2.2704e-01, time/batch = 0.3436s	
2256/2700 (epoch 41.778), train_loss = 1.95994195, grad/param norm = 2.3607e-01, time/batch = 0.3497s	
2257/2700 (epoch 41.796), train_loss = 1.92387520, grad/param norm = 1.9951e-01, time/batch = 0.3508s	
2258/2700 (epoch 41.815), train_loss = 1.96738543, grad/param norm = 1.7158e-01, time/batch = 0.3430s	
2259/2700 (epoch 41.833), train_loss = 1.90926753, grad/param norm = 1.1308e-01, time/batch = 0.2752s	
2260/2700 (epoch 41.852), train_loss = 1.91215193, grad/param norm = 1.2529e-01, time/batch = 0.3144s	
2261/2700 (epoch 41.870), train_loss = 1.89268277, grad/param norm = 1.4585e-01, time/batch = 0.3053s	
2262/2700 (epoch 41.889), train_loss = 1.90345116, grad/param norm = 1.9141e-01, time/batch = 0.2614s	
2263/2700 (epoch 41.907), train_loss = 2.02840107, grad/param norm = 2.6222e-01, time/batch = 0.3150s	
2264/2700 (epoch 41.926), train_loss = 1.96488216, grad/param norm = 2.9317e-01, time/batch = 0.3251s	
2265/2700 (epoch 41.944), train_loss = 1.94832507, grad/param norm = 1.9832e-01, time/batch = 0.3326s	
2266/2700 (epoch 41.963), train_loss = 1.94746564, grad/param norm = 1.2031e-01, time/batch = 0.3342s	
2267/2700 (epoch 41.981), train_loss = 1.92598881, grad/param norm = 1.1454e-01, time/batch = 0.3382s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2268/2700 (epoch 42.000), train_loss = 1.95640720, grad/param norm = 1.1404e-01, time/batch = 0.3290s	
2269/2700 (epoch 42.019), train_loss = 1.95877010, grad/param norm = 1.4488e-01, time/batch = 0.3133s	
2270/2700 (epoch 42.037), train_loss = 1.96684427, grad/param norm = 1.8479e-01, time/batch = 0.3186s	
2271/2700 (epoch 42.056), train_loss = 1.90635212, grad/param norm = 1.9515e-01, time/batch = 0.3428s	
2272/2700 (epoch 42.074), train_loss = 1.87154502, grad/param norm = 1.5936e-01, time/batch = 0.3242s	
2273/2700 (epoch 42.093), train_loss = 1.88167951, grad/param norm = 1.4197e-01, time/batch = 0.3340s	
2274/2700 (epoch 42.111), train_loss = 1.85221845, grad/param norm = 1.2489e-01, time/batch = 0.3360s	
2275/2700 (epoch 42.130), train_loss = 1.91321432, grad/param norm = 1.4424e-01, time/batch = 0.3273s	
2276/2700 (epoch 42.148), train_loss = 1.84861993, grad/param norm = 1.0779e-01, time/batch = 0.3136s	
2277/2700 (epoch 42.167), train_loss = 1.94701996, grad/param norm = 1.1416e-01, time/batch = 0.2993s	
2278/2700 (epoch 42.185), train_loss = 1.89286448, grad/param norm = 1.1607e-01, time/batch = 0.3106s	
2279/2700 (epoch 42.204), train_loss = 1.90535108, grad/param norm = 1.2271e-01, time/batch = 0.3132s	
2280/2700 (epoch 42.222), train_loss = 1.86411523, grad/param norm = 1.2556e-01, time/batch = 0.3187s	
2281/2700 (epoch 42.241), train_loss = 1.79772394, grad/param norm = 1.7697e-01, time/batch = 0.3321s	
2282/2700 (epoch 42.259), train_loss = 1.84758927, grad/param norm = 1.7604e-01, time/batch = 0.3249s	
2283/2700 (epoch 42.278), train_loss = 1.90070054, grad/param norm = 1.4918e-01, time/batch = 0.3321s	
2284/2700 (epoch 42.296), train_loss = 1.90437949, grad/param norm = 1.2110e-01, time/batch = 0.3438s	
2285/2700 (epoch 42.315), train_loss = 1.90201758, grad/param norm = 1.0698e-01, time/batch = 0.3427s	
2286/2700 (epoch 42.333), train_loss = 1.91167463, grad/param norm = 1.1998e-01, time/batch = 0.3307s	
2287/2700 (epoch 42.352), train_loss = 1.89179830, grad/param norm = 1.3268e-01, time/batch = 0.3266s	
2288/2700 (epoch 42.370), train_loss = 1.93695884, grad/param norm = 1.7382e-01, time/batch = 0.3126s	
2289/2700 (epoch 42.389), train_loss = 1.90367266, grad/param norm = 2.6823e-01, time/batch = 0.3181s	
2290/2700 (epoch 42.407), train_loss = 1.93255710, grad/param norm = 2.0046e-01, time/batch = 0.3213s	
2291/2700 (epoch 42.426), train_loss = 1.95639977, grad/param norm = 1.0304e-01, time/batch = 0.2642s	
2292/2700 (epoch 42.444), train_loss = 1.84620217, grad/param norm = 1.1617e-01, time/batch = 0.3274s	
2293/2700 (epoch 42.463), train_loss = 1.92622060, grad/param norm = 1.6379e-01, time/batch = 0.3293s	
2294/2700 (epoch 42.481), train_loss = 1.92284511, grad/param norm = 1.3274e-01, time/batch = 0.3407s	
2295/2700 (epoch 42.500), train_loss = 1.87407371, grad/param norm = 1.1503e-01, time/batch = 0.3489s	
2296/2700 (epoch 42.519), train_loss = 1.90860485, grad/param norm = 1.0644e-01, time/batch = 0.3435s	
2297/2700 (epoch 42.537), train_loss = 1.91395481, grad/param norm = 1.4486e-01, time/batch = 0.3364s	
2298/2700 (epoch 42.556), train_loss = 1.87397020, grad/param norm = 1.2772e-01, time/batch = 0.3230s	
2299/2700 (epoch 42.574), train_loss = 1.87600203, grad/param norm = 1.2525e-01, time/batch = 0.3132s	
2300/2700 (epoch 42.593), train_loss = 1.88946829, grad/param norm = 1.3201e-01, time/batch = 0.3177s	
2301/2700 (epoch 42.611), train_loss = 1.81077388, grad/param norm = 1.6375e-01, time/batch = 0.3111s	
2302/2700 (epoch 42.630), train_loss = 1.84673735, grad/param norm = 1.5357e-01, time/batch = 0.2556s	
2303/2700 (epoch 42.648), train_loss = 1.86607830, grad/param norm = 1.2730e-01, time/batch = 0.3334s	
2304/2700 (epoch 42.667), train_loss = 1.86825534, grad/param norm = 1.2031e-01, time/batch = 0.3456s	
2305/2700 (epoch 42.685), train_loss = 1.88904860, grad/param norm = 1.7135e-01, time/batch = 0.3439s	
2306/2700 (epoch 42.704), train_loss = 1.91080778, grad/param norm = 1.7898e-01, time/batch = 0.3455s	
2307/2700 (epoch 42.722), train_loss = 1.87673148, grad/param norm = 1.8267e-01, time/batch = 0.3390s	
2308/2700 (epoch 42.741), train_loss = 1.89588418, grad/param norm = 1.5439e-01, time/batch = 0.3260s	
2309/2700 (epoch 42.759), train_loss = 1.94504575, grad/param norm = 1.7909e-01, time/batch = 0.3173s	
2310/2700 (epoch 42.778), train_loss = 1.92870782, grad/param norm = 1.8005e-01, time/batch = 0.3135s	
2311/2700 (epoch 42.796), train_loss = 1.89529717, grad/param norm = 1.3159e-01, time/batch = 0.3069s	
2312/2700 (epoch 42.815), train_loss = 1.94981931, grad/param norm = 1.4299e-01, time/batch = 0.3111s	
2313/2700 (epoch 42.833), train_loss = 1.90288606, grad/param norm = 1.6654e-01, time/batch = 0.2896s	
2314/2700 (epoch 42.852), train_loss = 1.90691565, grad/param norm = 1.9111e-01, time/batch = 0.2742s	
2315/2700 (epoch 42.870), train_loss = 1.88889736, grad/param norm = 2.1357e-01, time/batch = 0.2529s	
2316/2700 (epoch 42.889), train_loss = 1.90128637, grad/param norm = 2.5059e-01, time/batch = 0.3107s	
2317/2700 (epoch 42.907), train_loss = 2.02426964, grad/param norm = 2.8009e-01, time/batch = 0.3106s	
2318/2700 (epoch 42.926), train_loss = 1.95178627, grad/param norm = 2.4473e-01, time/batch = 0.3250s	
2319/2700 (epoch 42.944), train_loss = 1.93589674, grad/param norm = 1.5228e-01, time/batch = 0.3276s	
2320/2700 (epoch 42.963), train_loss = 1.93903476, grad/param norm = 1.1293e-01, time/batch = 0.3297s	
2321/2700 (epoch 42.981), train_loss = 1.91721984, grad/param norm = 1.1462e-01, time/batch = 0.3047s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
2322/2700 (epoch 43.000), train_loss = 1.94872336, grad/param norm = 1.2296e-01, time/batch = 0.3068s	
2323/2700 (epoch 43.019), train_loss = 1.95450742, grad/param norm = 1.7474e-01, time/batch = 0.3078s	
2324/2700 (epoch 43.037), train_loss = 1.97039605, grad/param norm = 2.4489e-01, time/batch = 0.3289s	
2325/2700 (epoch 43.056), train_loss = 1.90816859, grad/param norm = 2.6731e-01, time/batch = 0.3348s	
2326/2700 (epoch 43.074), train_loss = 1.86935519, grad/param norm = 1.9602e-01, time/batch = 0.3535s	
2327/2700 (epoch 43.093), train_loss = 1.87515853, grad/param norm = 1.4793e-01, time/batch = 0.3225s	
2328/2700 (epoch 43.111), train_loss = 1.84525381, grad/param norm = 1.2548e-01, time/batch = 0.3140s	
2329/2700 (epoch 43.130), train_loss = 1.90412863, grad/param norm = 1.3398e-01, time/batch = 0.3209s	
2330/2700 (epoch 43.148), train_loss = 1.83921033, grad/param norm = 9.8810e-02, time/batch = 0.3273s	
2331/2700 (epoch 43.167), train_loss = 1.93832117, grad/param norm = 1.1517e-01, time/batch = 0.2796s	
2332/2700 (epoch 43.185), train_loss = 1.88391976, grad/param norm = 1.1444e-01, time/batch = 0.3047s	
2333/2700 (epoch 43.204), train_loss = 1.89643030, grad/param norm = 1.2384e-01, time/batch = 0.3105s	
2334/2700 (epoch 43.222), train_loss = 1.85562316, grad/param norm = 1.2232e-01, time/batch = 0.3301s	
2335/2700 (epoch 43.241), train_loss = 1.78711285, grad/param norm = 1.6119e-01, time/batch = 0.3422s	
2336/2700 (epoch 43.259), train_loss = 1.83767835, grad/param norm = 1.5371e-01, time/batch = 0.3503s	
2337/2700 (epoch 43.278), train_loss = 1.89106991, grad/param norm = 1.2966e-01, time/batch = 0.3405s	
2338/2700 (epoch 43.296), train_loss = 1.89541500, grad/param norm = 1.1619e-01, time/batch = 0.3157s	
2339/2700 (epoch 43.315), train_loss = 1.89363700, grad/param norm = 1.2133e-01, time/batch = 0.3076s	
2340/2700 (epoch 43.333), train_loss = 1.90208751, grad/param norm = 1.3054e-01, time/batch = 0.2993s	
2341/2700 (epoch 43.352), train_loss = 1.88096440, grad/param norm = 1.2735e-01, time/batch = 0.2538s	
2342/2700 (epoch 43.370), train_loss = 1.92326697, grad/param norm = 1.3729e-01, time/batch = 0.3136s	
2343/2700 (epoch 43.389), train_loss = 1.88441183, grad/param norm = 1.5863e-01, time/batch = 0.3256s	
2344/2700 (epoch 43.407), train_loss = 1.91389238, grad/param norm = 1.1890e-01, time/batch = 0.3290s	
2345/2700 (epoch 43.426), train_loss = 1.94742913, grad/param norm = 1.0381e-01, time/batch = 0.3345s	
2346/2700 (epoch 43.444), train_loss = 1.83719177, grad/param norm = 1.0988e-01, time/batch = 0.3466s	
2347/2700 (epoch 43.463), train_loss = 1.91666912, grad/param norm = 1.4462e-01, time/batch = 0.3375s	
2348/2700 (epoch 43.481), train_loss = 1.91573827, grad/param norm = 1.2413e-01, time/batch = 0.3299s	
2349/2700 (epoch 43.500), train_loss = 1.86965953, grad/param norm = 1.5243e-01, time/batch = 0.3220s	
2350/2700 (epoch 43.519), train_loss = 1.90943454, grad/param norm = 1.8673e-01, time/batch = 0.3023s	
2351/2700 (epoch 43.537), train_loss = 1.91152614, grad/param norm = 1.8876e-01, time/batch = 0.2983s	
2352/2700 (epoch 43.556), train_loss = 1.86914551, grad/param norm = 1.8626e-01, time/batch = 0.3142s	
2353/2700 (epoch 43.574), train_loss = 1.87114965, grad/param norm = 1.6821e-01, time/batch = 0.3015s	
2354/2700 (epoch 43.593), train_loss = 1.88452596, grad/param norm = 1.6291e-01, time/batch = 0.3020s	
2355/2700 (epoch 43.611), train_loss = 1.80272558, grad/param norm = 1.8862e-01, time/batch = 0.3050s	
2356/2700 (epoch 43.630), train_loss = 1.83769839, grad/param norm = 1.6568e-01, time/batch = 0.3120s	
2357/2700 (epoch 43.648), train_loss = 1.85593027, grad/param norm = 1.2451e-01, time/batch = 0.3146s	
2358/2700 (epoch 43.667), train_loss = 1.85692249, grad/param norm = 1.0322e-01, time/batch = 0.3061s	
2359/2700 (epoch 43.685), train_loss = 1.87557282, grad/param norm = 1.4078e-01, time/batch = 0.3040s	
2360/2700 (epoch 43.704), train_loss = 1.89639548, grad/param norm = 1.3518e-01, time/batch = 0.3147s	
2361/2700 (epoch 43.722), train_loss = 1.86329556, grad/param norm = 1.3967e-01, time/batch = 0.3151s	
2362/2700 (epoch 43.741), train_loss = 1.88401613, grad/param norm = 1.1484e-01, time/batch = 0.3272s	
2363/2700 (epoch 43.759), train_loss = 1.93368140, grad/param norm = 1.4093e-01, time/batch = 0.3219s	
2364/2700 (epoch 43.778), train_loss = 1.92004991, grad/param norm = 1.4513e-01, time/batch = 0.3089s	
2365/2700 (epoch 43.796), train_loss = 1.89163444, grad/param norm = 1.4482e-01, time/batch = 0.3030s	
2366/2700 (epoch 43.815), train_loss = 1.94898452, grad/param norm = 1.7825e-01, time/batch = 0.2998s	
2367/2700 (epoch 43.833), train_loss = 1.89449464, grad/param norm = 1.2631e-01, time/batch = 0.2926s	
2368/2700 (epoch 43.852), train_loss = 1.89249229, grad/param norm = 1.0357e-01, time/batch = 0.3081s	
2369/2700 (epoch 43.870), train_loss = 1.87358088, grad/param norm = 1.1890e-01, time/batch = 0.3101s	
2370/2700 (epoch 43.889), train_loss = 1.88492463, grad/param norm = 1.7361e-01, time/batch = 0.3055s	
2371/2700 (epoch 43.907), train_loss = 2.01065253, grad/param norm = 2.5169e-01, time/batch = 0.3174s	
2372/2700 (epoch 43.926), train_loss = 1.94559590, grad/param norm = 2.7590e-01, time/batch = 0.3297s	
2373/2700 (epoch 43.944), train_loss = 1.93045246, grad/param norm = 2.0073e-01, time/batch = 0.3263s	
2374/2700 (epoch 43.963), train_loss = 1.93042413, grad/param norm = 1.2485e-01, time/batch = 0.3146s	
2375/2700 (epoch 43.981), train_loss = 1.90756022, grad/param norm = 1.1237e-01, time/batch = 0.3075s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
2376/2700 (epoch 44.000), train_loss = 1.93991100, grad/param norm = 1.1612e-01, time/batch = 0.3030s	
2377/2700 (epoch 44.019), train_loss = 1.94406547, grad/param norm = 1.5543e-01, time/batch = 0.3050s	
2378/2700 (epoch 44.037), train_loss = 1.95260755, grad/param norm = 1.9985e-01, time/batch = 0.3175s	
2379/2700 (epoch 44.056), train_loss = 1.89081831, grad/param norm = 2.1962e-01, time/batch = 0.3215s	
2380/2700 (epoch 44.074), train_loss = 1.85667865, grad/param norm = 1.7773e-01, time/batch = 0.3276s	
2381/2700 (epoch 44.093), train_loss = 1.86313417, grad/param norm = 1.4225e-01, time/batch = 0.3076s	
2382/2700 (epoch 44.111), train_loss = 1.83534711, grad/param norm = 1.2177e-01, time/batch = 0.3306s	
2383/2700 (epoch 44.130), train_loss = 1.89535969, grad/param norm = 1.3053e-01, time/batch = 0.3261s	
2384/2700 (epoch 44.148), train_loss = 1.82991931, grad/param norm = 1.0071e-01, time/batch = 0.3153s	
2385/2700 (epoch 44.167), train_loss = 1.92957563, grad/param norm = 1.1260e-01, time/batch = 0.3060s	
2386/2700 (epoch 44.185), train_loss = 1.87616357, grad/param norm = 1.2157e-01, time/batch = 0.3102s	
2387/2700 (epoch 44.204), train_loss = 1.88913533, grad/param norm = 1.2932e-01, time/batch = 0.3144s	
2388/2700 (epoch 44.222), train_loss = 1.84833692, grad/param norm = 1.2879e-01, time/batch = 0.3251s	
2389/2700 (epoch 44.241), train_loss = 1.78016802, grad/param norm = 1.8147e-01, time/batch = 0.3328s	
2390/2700 (epoch 44.259), train_loss = 1.83210783, grad/param norm = 1.8098e-01, time/batch = 0.3366s	
2391/2700 (epoch 44.278), train_loss = 1.88441242, grad/param norm = 1.5356e-01, time/batch = 0.3300s	
2392/2700 (epoch 44.296), train_loss = 1.88744750, grad/param norm = 1.1904e-01, time/batch = 0.3219s	
2393/2700 (epoch 44.315), train_loss = 1.88570894, grad/param norm = 1.0358e-01, time/batch = 0.3260s	
2394/2700 (epoch 44.333), train_loss = 1.89156680, grad/param norm = 1.0125e-01, time/batch = 0.3170s	
2395/2700 (epoch 44.352), train_loss = 1.87031528, grad/param norm = 1.0302e-01, time/batch = 0.3078s	
2396/2700 (epoch 44.370), train_loss = 1.91462713, grad/param norm = 1.6565e-01, time/batch = 0.3214s	
2397/2700 (epoch 44.389), train_loss = 1.87936080, grad/param norm = 2.4839e-01, time/batch = 0.3255s	
2398/2700 (epoch 44.407), train_loss = 1.91664410, grad/param norm = 2.2295e-01, time/batch = 0.3245s	
2399/2700 (epoch 44.426), train_loss = 1.94430489, grad/param norm = 1.4302e-01, time/batch = 0.3420s	
2400/2700 (epoch 44.444), train_loss = 1.83421874, grad/param norm = 1.5598e-01, time/batch = 0.3449s	
2401/2700 (epoch 44.463), train_loss = 1.91716919, grad/param norm = 1.8937e-01, time/batch = 0.3232s	
2402/2700 (epoch 44.481), train_loss = 1.91212384, grad/param norm = 1.4934e-01, time/batch = 0.3444s	
2403/2700 (epoch 44.500), train_loss = 1.86496222, grad/param norm = 1.7031e-01, time/batch = 0.3186s	
2404/2700 (epoch 44.519), train_loss = 1.90002394, grad/param norm = 1.7435e-01, time/batch = 0.3165s	
2405/2700 (epoch 44.537), train_loss = 1.89861141, grad/param norm = 1.5712e-01, time/batch = 0.3195s	
2406/2700 (epoch 44.556), train_loss = 1.85516211, grad/param norm = 1.3975e-01, time/batch = 0.3133s	
2407/2700 (epoch 44.574), train_loss = 1.85704802, grad/param norm = 1.2334e-01, time/batch = 0.2949s	
2408/2700 (epoch 44.593), train_loss = 1.87197797, grad/param norm = 1.1986e-01, time/batch = 0.3002s	
2409/2700 (epoch 44.611), train_loss = 1.79059564, grad/param norm = 1.4179e-01, time/batch = 0.3087s	
2410/2700 (epoch 44.630), train_loss = 1.82647622, grad/param norm = 1.2356e-01, time/batch = 0.2903s	
2411/2700 (epoch 44.648), train_loss = 1.84584041, grad/param norm = 9.4745e-02, time/batch = 0.3187s	
2412/2700 (epoch 44.667), train_loss = 1.84949538, grad/param norm = 1.2416e-01, time/batch = 0.3185s	
2413/2700 (epoch 44.685), train_loss = 1.86916499, grad/param norm = 1.6026e-01, time/batch = 0.2871s	
2414/2700 (epoch 44.704), train_loss = 1.88893204, grad/param norm = 1.5116e-01, time/batch = 0.2905s	
2415/2700 (epoch 44.722), train_loss = 1.85640900, grad/param norm = 1.5445e-01, time/batch = 0.3168s	
2416/2700 (epoch 44.741), train_loss = 1.87630246, grad/param norm = 1.2187e-01, time/batch = 0.3162s	
2417/2700 (epoch 44.759), train_loss = 1.92814504, grad/param norm = 1.6123e-01, time/batch = 0.3004s	
2418/2700 (epoch 44.778), train_loss = 1.91791285, grad/param norm = 1.7350e-01, time/batch = 0.3000s	
2419/2700 (epoch 44.796), train_loss = 1.88855162, grad/param norm = 1.6733e-01, time/batch = 0.2988s	
2420/2700 (epoch 44.815), train_loss = 1.94105555, grad/param norm = 1.7963e-01, time/batch = 0.2809s	
2421/2700 (epoch 44.833), train_loss = 1.88501354, grad/param norm = 1.2269e-01, time/batch = 0.3042s	
2422/2700 (epoch 44.852), train_loss = 1.88459666, grad/param norm = 1.2227e-01, time/batch = 0.2927s	
2423/2700 (epoch 44.870), train_loss = 1.86821727, grad/param norm = 1.4832e-01, time/batch = 0.3018s	
2424/2700 (epoch 44.889), train_loss = 1.87936890, grad/param norm = 1.9342e-01, time/batch = 0.3079s	
2425/2700 (epoch 44.907), train_loss = 2.00226323, grad/param norm = 2.4654e-01, time/batch = 0.3006s	
2426/2700 (epoch 44.926), train_loss = 1.93423224, grad/param norm = 2.4504e-01, time/batch = 0.3130s	
2427/2700 (epoch 44.944), train_loss = 1.91841820, grad/param norm = 1.6740e-01, time/batch = 0.3017s	
2428/2700 (epoch 44.963), train_loss = 1.92191130, grad/param norm = 1.1874e-01, time/batch = 0.3022s	
2429/2700 (epoch 44.981), train_loss = 1.89868391, grad/param norm = 1.1124e-01, time/batch = 0.3009s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
2430/2700 (epoch 45.000), train_loss = 1.93081132, grad/param norm = 1.1600e-01, time/batch = 0.2798s	
2431/2700 (epoch 45.019), train_loss = 1.93534856, grad/param norm = 1.4009e-01, time/batch = 0.3133s	
2432/2700 (epoch 45.037), train_loss = 1.94255270, grad/param norm = 1.8097e-01, time/batch = 0.2616s	
2433/2700 (epoch 45.056), train_loss = 1.87903011, grad/param norm = 1.9870e-01, time/batch = 0.3142s	
2434/2700 (epoch 45.074), train_loss = 1.84644740, grad/param norm = 1.6615e-01, time/batch = 0.3244s	
2435/2700 (epoch 45.093), train_loss = 1.85293421, grad/param norm = 1.3730e-01, time/batch = 0.3206s	
2436/2700 (epoch 45.111), train_loss = 1.82591654, grad/param norm = 1.1869e-01, time/batch = 0.3091s	
2437/2700 (epoch 45.130), train_loss = 1.88787028, grad/param norm = 1.3777e-01, time/batch = 0.3291s	
2438/2700 (epoch 45.148), train_loss = 1.82154483, grad/param norm = 1.0336e-01, time/batch = 0.3180s	
2439/2700 (epoch 45.167), train_loss = 1.92214387, grad/param norm = 1.1228e-01, time/batch = 0.3067s	
2440/2700 (epoch 45.185), train_loss = 1.86765355, grad/param norm = 1.1948e-01, time/batch = 0.2695s	
2441/2700 (epoch 45.204), train_loss = 1.88109219, grad/param norm = 1.2584e-01, time/batch = 0.2918s	
2442/2700 (epoch 45.222), train_loss = 1.83988498, grad/param norm = 1.2268e-01, time/batch = 0.2993s	
2443/2700 (epoch 45.241), train_loss = 1.77068548, grad/param norm = 1.6452e-01, time/batch = 0.2943s	
2444/2700 (epoch 45.259), train_loss = 1.82261746, grad/param norm = 1.6061e-01, time/batch = 0.2977s	
2445/2700 (epoch 45.278), train_loss = 1.87538727, grad/param norm = 1.4012e-01, time/batch = 0.3076s	
2446/2700 (epoch 45.296), train_loss = 1.87935650, grad/param norm = 1.2091e-01, time/batch = 0.3166s	
2447/2700 (epoch 45.315), train_loss = 1.87900600, grad/param norm = 1.1005e-01, time/batch = 0.3036s	
2448/2700 (epoch 45.333), train_loss = 1.88503949, grad/param norm = 1.1597e-01, time/batch = 0.3098s	
2449/2700 (epoch 45.352), train_loss = 1.86334590, grad/param norm = 1.1440e-01, time/batch = 0.3038s	
2450/2700 (epoch 45.370), train_loss = 1.90720256, grad/param norm = 1.5163e-01, time/batch = 0.2651s	
2451/2700 (epoch 45.389), train_loss = 1.87052938, grad/param norm = 1.9857e-01, time/batch = 0.2988s	
2452/2700 (epoch 45.407), train_loss = 1.90221520, grad/param norm = 1.4900e-01, time/batch = 0.2756s	
2453/2700 (epoch 45.426), train_loss = 1.93048591, grad/param norm = 9.2606e-02, time/batch = 0.2549s	
2454/2700 (epoch 45.444), train_loss = 1.81953990, grad/param norm = 1.0029e-01, time/batch = 0.2496s	
2455/2700 (epoch 45.463), train_loss = 1.90040038, grad/param norm = 1.4193e-01, time/batch = 0.2471s	
2456/2700 (epoch 45.481), train_loss = 1.89643744, grad/param norm = 1.1809e-01, time/batch = 0.2628s	
2457/2700 (epoch 45.500), train_loss = 1.84526105, grad/param norm = 1.0621e-01, time/batch = 0.2698s	
2458/2700 (epoch 45.519), train_loss = 1.88565275, grad/param norm = 1.1815e-01, time/batch = 0.2606s	
2459/2700 (epoch 45.537), train_loss = 1.88892107, grad/param norm = 1.5613e-01, time/batch = 0.2173s	
2460/2700 (epoch 45.556), train_loss = 1.84625664, grad/param norm = 1.3624e-01, time/batch = 0.2649s	
2461/2700 (epoch 45.574), train_loss = 1.84824263, grad/param norm = 1.2857e-01, time/batch = 0.2681s	
2462/2700 (epoch 45.593), train_loss = 1.86820676, grad/param norm = 1.8789e-01, time/batch = 0.2657s	
2463/2700 (epoch 45.611), train_loss = 1.79538907, grad/param norm = 2.5362e-01, time/batch = 0.2663s	
2464/2700 (epoch 45.630), train_loss = 1.83355328, grad/param norm = 2.2171e-01, time/batch = 0.2683s	
2465/2700 (epoch 45.648), train_loss = 1.84809283, grad/param norm = 1.8830e-01, time/batch = 0.2716s	
2466/2700 (epoch 45.667), train_loss = 1.84997719, grad/param norm = 1.8473e-01, time/batch = 0.2742s	
2467/2700 (epoch 45.685), train_loss = 1.86312359, grad/param norm = 1.8646e-01, time/batch = 0.2670s	
2468/2700 (epoch 45.704), train_loss = 1.88279266, grad/param norm = 1.6745e-01, time/batch = 0.2663s	
2469/2700 (epoch 45.722), train_loss = 1.85051183, grad/param norm = 1.6988e-01, time/batch = 0.2178s	
2470/2700 (epoch 45.741), train_loss = 1.87014012, grad/param norm = 1.3304e-01, time/batch = 0.2980s	
2471/2700 (epoch 45.759), train_loss = 1.92266487, grad/param norm = 1.6536e-01, time/batch = 0.2798s	
2472/2700 (epoch 45.778), train_loss = 1.90669266, grad/param norm = 1.4965e-01, time/batch = 0.2818s	
2473/2700 (epoch 45.796), train_loss = 1.87449466, grad/param norm = 1.4063e-01, time/batch = 0.2773s	
2474/2700 (epoch 45.815), train_loss = 1.92618199, grad/param norm = 1.4340e-01, time/batch = 0.2733s	
2475/2700 (epoch 45.833), train_loss = 1.87488753, grad/param norm = 1.0667e-01, time/batch = 0.2718s	
2476/2700 (epoch 45.852), train_loss = 1.87682923, grad/param norm = 1.1855e-01, time/batch = 0.2706s	
2477/2700 (epoch 45.870), train_loss = 1.86141153, grad/param norm = 1.3942e-01, time/batch = 0.2779s	
2478/2700 (epoch 45.889), train_loss = 1.87051243, grad/param norm = 1.6986e-01, time/batch = 0.2455s	
2479/2700 (epoch 45.907), train_loss = 1.99099721, grad/param norm = 2.1095e-01, time/batch = 0.2604s	
2480/2700 (epoch 45.926), train_loss = 1.92305411, grad/param norm = 2.0718e-01, time/batch = 0.2975s	
2481/2700 (epoch 45.944), train_loss = 1.91016302, grad/param norm = 1.5771e-01, time/batch = 0.2667s	
2482/2700 (epoch 45.963), train_loss = 1.91474745, grad/param norm = 1.1970e-01, time/batch = 0.2539s	
2483/2700 (epoch 45.981), train_loss = 1.88977895, grad/param norm = 1.1046e-01, time/batch = 0.2461s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
2484/2700 (epoch 46.000), train_loss = 1.92397187, grad/param norm = 1.1377e-01, time/batch = 0.2491s	
2485/2700 (epoch 46.019), train_loss = 1.92769296, grad/param norm = 1.4074e-01, time/batch = 0.2535s	
2486/2700 (epoch 46.037), train_loss = 1.93369408, grad/param norm = 1.7832e-01, time/batch = 0.2845s	
2487/2700 (epoch 46.056), train_loss = 1.86928249, grad/param norm = 1.8724e-01, time/batch = 0.2873s	
2488/2700 (epoch 46.074), train_loss = 1.83719651, grad/param norm = 1.5494e-01, time/batch = 0.2795s	
2489/2700 (epoch 46.093), train_loss = 1.84351405, grad/param norm = 1.4449e-01, time/batch = 0.2688s	
2490/2700 (epoch 46.111), train_loss = 1.81833590, grad/param norm = 1.2648e-01, time/batch = 0.2976s	
2491/2700 (epoch 46.130), train_loss = 1.88186752, grad/param norm = 1.4399e-01, time/batch = 0.2756s	
2492/2700 (epoch 46.148), train_loss = 1.81358181, grad/param norm = 1.0959e-01, time/batch = 0.2608s	
2493/2700 (epoch 46.167), train_loss = 1.91544209, grad/param norm = 1.1865e-01, time/batch = 0.2598s	
2494/2700 (epoch 46.185), train_loss = 1.86061203, grad/param norm = 1.2980e-01, time/batch = 0.2620s	
2495/2700 (epoch 46.204), train_loss = 1.87350619, grad/param norm = 1.2913e-01, time/batch = 0.2612s	
2496/2700 (epoch 46.222), train_loss = 1.83249660, grad/param norm = 1.2656e-01, time/batch = 0.2637s	
2497/2700 (epoch 46.241), train_loss = 1.76333030, grad/param norm = 1.7604e-01, time/batch = 0.2476s	
2498/2700 (epoch 46.259), train_loss = 1.81592537, grad/param norm = 1.7187e-01, time/batch = 0.2871s	
2499/2700 (epoch 46.278), train_loss = 1.86850619, grad/param norm = 1.4388e-01, time/batch = 0.2716s	
2500/2700 (epoch 46.296), train_loss = 1.87124407, grad/param norm = 1.1471e-01, time/batch = 0.2590s	
2501/2700 (epoch 46.315), train_loss = 1.87051111, grad/param norm = 1.0796e-01, time/batch = 0.2883s	
2502/2700 (epoch 46.333), train_loss = 1.87641637, grad/param norm = 1.1397e-01, time/batch = 0.2890s	
2503/2700 (epoch 46.352), train_loss = 1.85560005, grad/param norm = 1.0926e-01, time/batch = 0.2669s	
2504/2700 (epoch 46.370), train_loss = 1.89815917, grad/param norm = 1.5966e-01, time/batch = 0.2592s	
2505/2700 (epoch 46.389), train_loss = 1.86381440, grad/param norm = 2.5972e-01, time/batch = 0.2594s	
2506/2700 (epoch 46.407), train_loss = 1.90026453, grad/param norm = 2.0981e-01, time/batch = 0.2486s	
2507/2700 (epoch 46.426), train_loss = 1.92422088, grad/param norm = 1.0748e-01, time/batch = 0.2801s	
2508/2700 (epoch 46.444), train_loss = 1.81222867, grad/param norm = 1.1767e-01, time/batch = 0.2681s	
2509/2700 (epoch 46.463), train_loss = 1.89384569, grad/param norm = 1.5349e-01, time/batch = 0.2566s	
2510/2700 (epoch 46.481), train_loss = 1.88988649, grad/param norm = 1.1949e-01, time/batch = 0.2604s	
2511/2700 (epoch 46.500), train_loss = 1.83769033, grad/param norm = 1.0902e-01, time/batch = 0.2908s	
2512/2700 (epoch 46.519), train_loss = 1.87738495, grad/param norm = 1.1294e-01, time/batch = 0.2897s	
2513/2700 (epoch 46.537), train_loss = 1.87860833, grad/param norm = 1.3828e-01, time/batch = 0.2744s	
2514/2700 (epoch 46.556), train_loss = 1.83576872, grad/param norm = 1.1204e-01, time/batch = 0.2640s	
2515/2700 (epoch 46.574), train_loss = 1.83799147, grad/param norm = 1.0740e-01, time/batch = 0.2422s	
2516/2700 (epoch 46.593), train_loss = 1.85598479, grad/param norm = 1.3321e-01, time/batch = 0.2793s	
2517/2700 (epoch 46.611), train_loss = 1.77786519, grad/param norm = 1.5771e-01, time/batch = 0.2694s	
2518/2700 (epoch 46.630), train_loss = 1.81580481, grad/param norm = 1.5211e-01, time/batch = 0.2580s	
2519/2700 (epoch 46.648), train_loss = 1.83632422, grad/param norm = 1.6379e-01, time/batch = 0.2523s	
2520/2700 (epoch 46.667), train_loss = 1.84242374, grad/param norm = 1.9751e-01, time/batch = 0.2695s	
2521/2700 (epoch 46.685), train_loss = 1.85727172, grad/param norm = 2.0147e-01, time/batch = 0.2791s	
2522/2700 (epoch 46.704), train_loss = 1.87584409, grad/param norm = 1.7057e-01, time/batch = 0.2886s	
2523/2700 (epoch 46.722), train_loss = 1.84322881, grad/param norm = 1.6206e-01, time/batch = 0.2768s	
2524/2700 (epoch 46.741), train_loss = 1.86109921, grad/param norm = 1.2561e-01, time/batch = 0.2647s	
2525/2700 (epoch 46.759), train_loss = 1.91374593, grad/param norm = 1.5829e-01, time/batch = 0.2617s	
2526/2700 (epoch 46.778), train_loss = 1.90191354, grad/param norm = 1.5423e-01, time/batch = 0.2699s	
2527/2700 (epoch 46.796), train_loss = 1.87163532, grad/param norm = 1.7627e-01, time/batch = 0.2820s	
2528/2700 (epoch 46.815), train_loss = 1.92372343, grad/param norm = 1.7877e-01, time/batch = 0.2667s	
2529/2700 (epoch 46.833), train_loss = 1.86899364, grad/param norm = 1.0435e-01, time/batch = 0.2886s	
2530/2700 (epoch 46.852), train_loss = 1.86770100, grad/param norm = 9.5443e-02, time/batch = 0.2921s	
2531/2700 (epoch 46.870), train_loss = 1.85258767, grad/param norm = 1.1145e-01, time/batch = 0.2667s	
2532/2700 (epoch 46.889), train_loss = 1.86021944, grad/param norm = 1.2747e-01, time/batch = 0.2664s	
2533/2700 (epoch 46.907), train_loss = 1.97837919, grad/param norm = 1.6159e-01, time/batch = 0.2720s	
2534/2700 (epoch 46.926), train_loss = 1.91219765, grad/param norm = 1.6475e-01, time/batch = 0.2710s	
2535/2700 (epoch 46.944), train_loss = 1.90086069, grad/param norm = 1.4148e-01, time/batch = 0.2637s	
2536/2700 (epoch 46.963), train_loss = 1.90713220, grad/param norm = 1.2102e-01, time/batch = 0.2780s	
2537/2700 (epoch 46.981), train_loss = 1.88114964, grad/param norm = 1.0873e-01, time/batch = 0.3051s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
2538/2700 (epoch 47.000), train_loss = 1.91462734, grad/param norm = 1.1130e-01, time/batch = 0.2819s	
2539/2700 (epoch 47.019), train_loss = 1.92073099, grad/param norm = 1.3815e-01, time/batch = 0.2769s	
2540/2700 (epoch 47.037), train_loss = 1.92786773, grad/param norm = 1.7783e-01, time/batch = 0.2613s	
2541/2700 (epoch 47.056), train_loss = 1.86225026, grad/param norm = 1.9343e-01, time/batch = 0.3059s	
2542/2700 (epoch 47.074), train_loss = 1.82977441, grad/param norm = 1.6338e-01, time/batch = 0.2397s	
2543/2700 (epoch 47.093), train_loss = 1.83530338, grad/param norm = 1.4560e-01, time/batch = 0.3030s	
2544/2700 (epoch 47.111), train_loss = 1.81042958, grad/param norm = 1.2959e-01, time/batch = 0.2853s	
2545/2700 (epoch 47.130), train_loss = 1.87342414, grad/param norm = 1.4066e-01, time/batch = 0.2969s	
2546/2700 (epoch 47.148), train_loss = 1.80536975, grad/param norm = 1.0561e-01, time/batch = 0.2748s	
2547/2700 (epoch 47.167), train_loss = 1.90689499, grad/param norm = 1.1557e-01, time/batch = 0.2392s	
2548/2700 (epoch 47.185), train_loss = 1.85239220, grad/param norm = 1.2411e-01, time/batch = 0.2800s	
2549/2700 (epoch 47.204), train_loss = 1.86536544, grad/param norm = 1.2683e-01, time/batch = 0.2691s	
2550/2700 (epoch 47.222), train_loss = 1.82519303, grad/param norm = 1.2616e-01, time/batch = 0.2700s	
2551/2700 (epoch 47.241), train_loss = 1.75513253, grad/param norm = 1.6807e-01, time/batch = 0.2794s	
2552/2700 (epoch 47.259), train_loss = 1.80796820, grad/param norm = 1.6790e-01, time/batch = 0.2623s	
2553/2700 (epoch 47.278), train_loss = 1.86162234, grad/param norm = 1.5431e-01, time/batch = 0.2732s	
2554/2700 (epoch 47.296), train_loss = 1.86443609, grad/param norm = 1.2202e-01, time/batch = 0.2668s	
2555/2700 (epoch 47.315), train_loss = 1.86347970, grad/param norm = 1.0255e-01, time/batch = 0.1939s	
2556/2700 (epoch 47.333), train_loss = 1.86873581, grad/param norm = 1.0633e-01, time/batch = 0.2690s	
2557/2700 (epoch 47.352), train_loss = 1.84820507, grad/param norm = 1.1144e-01, time/batch = 0.2742s	
2558/2700 (epoch 47.370), train_loss = 1.89196722, grad/param norm = 1.7533e-01, time/batch = 0.2778s	
2559/2700 (epoch 47.389), train_loss = 1.85471121, grad/param norm = 2.3210e-01, time/batch = 0.3047s	
2560/2700 (epoch 47.407), train_loss = 1.88860637, grad/param norm = 1.7641e-01, time/batch = 0.2971s	
2561/2700 (epoch 47.426), train_loss = 1.91666712, grad/param norm = 1.0459e-01, time/batch = 0.2666s	
2562/2700 (epoch 47.444), train_loss = 1.80499645, grad/param norm = 1.1370e-01, time/batch = 0.2934s	
2563/2700 (epoch 47.463), train_loss = 1.88684845, grad/param norm = 1.5334e-01, time/batch = 0.2529s	
2564/2700 (epoch 47.481), train_loss = 1.88276359, grad/param norm = 1.2306e-01, time/batch = 0.2596s	
2565/2700 (epoch 47.500), train_loss = 1.83228228, grad/param norm = 1.3132e-01, time/batch = 0.2389s	
2566/2700 (epoch 47.519), train_loss = 1.87372866, grad/param norm = 1.4103e-01, time/batch = 0.2793s	
2567/2700 (epoch 47.537), train_loss = 1.87308817, grad/param norm = 1.3866e-01, time/batch = 0.2801s	
2568/2700 (epoch 47.556), train_loss = 1.83056208, grad/param norm = 1.4523e-01, time/batch = 0.2604s	
2569/2700 (epoch 47.574), train_loss = 1.83577832, grad/param norm = 1.4156e-01, time/batch = 0.2607s	
2570/2700 (epoch 47.593), train_loss = 1.85333746, grad/param norm = 1.3276e-01, time/batch = 0.2813s	
2571/2700 (epoch 47.611), train_loss = 1.77156328, grad/param norm = 1.3556e-01, time/batch = 0.2568s	
2572/2700 (epoch 47.630), train_loss = 1.80609281, grad/param norm = 1.2829e-01, time/batch = 0.2654s	
2573/2700 (epoch 47.648), train_loss = 1.82608162, grad/param norm = 1.2013e-01, time/batch = 0.2654s	
2574/2700 (epoch 47.667), train_loss = 1.83257000, grad/param norm = 1.7801e-01, time/batch = 0.2943s	
2575/2700 (epoch 47.685), train_loss = 1.85353062, grad/param norm = 2.1036e-01, time/batch = 0.2564s	
2576/2700 (epoch 47.704), train_loss = 1.86963212, grad/param norm = 1.8563e-01, time/batch = 0.2951s	
2577/2700 (epoch 47.722), train_loss = 1.83735090, grad/param norm = 1.6087e-01, time/batch = 0.2654s	
2578/2700 (epoch 47.741), train_loss = 1.84954408, grad/param norm = 1.0922e-01, time/batch = 0.2686s	
2579/2700 (epoch 47.759), train_loss = 1.89972344, grad/param norm = 1.2267e-01, time/batch = 0.2601s	
2580/2700 (epoch 47.778), train_loss = 1.88714289, grad/param norm = 1.1634e-01, time/batch = 0.2938s	
2581/2700 (epoch 47.796), train_loss = 1.85539219, grad/param norm = 1.2495e-01, time/batch = 0.2700s	
2582/2700 (epoch 47.815), train_loss = 1.90934430, grad/param norm = 1.2985e-01, time/batch = 0.2908s	
2583/2700 (epoch 47.833), train_loss = 1.86078198, grad/param norm = 1.0479e-01, time/batch = 0.2700s	
2584/2700 (epoch 47.852), train_loss = 1.86179583, grad/param norm = 1.1956e-01, time/batch = 0.2581s	
2585/2700 (epoch 47.870), train_loss = 1.84895930, grad/param norm = 1.5158e-01, time/batch = 0.2837s	
2586/2700 (epoch 47.889), train_loss = 1.85773451, grad/param norm = 1.8391e-01, time/batch = 0.2574s	
2587/2700 (epoch 47.907), train_loss = 1.97691869, grad/param norm = 2.2403e-01, time/batch = 0.2665s	
2588/2700 (epoch 47.926), train_loss = 1.90774060, grad/param norm = 2.1631e-01, time/batch = 0.2657s	
2589/2700 (epoch 47.944), train_loss = 1.89314272, grad/param norm = 1.5966e-01, time/batch = 0.2160s	
2590/2700 (epoch 47.963), train_loss = 1.90040169, grad/param norm = 1.2784e-01, time/batch = 0.2362s	
2591/2700 (epoch 47.981), train_loss = 1.87430342, grad/param norm = 1.1489e-01, time/batch = 0.2353s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
2592/2700 (epoch 48.000), train_loss = 1.90815679, grad/param norm = 1.1620e-01, time/batch = 0.2449s	
2593/2700 (epoch 48.019), train_loss = 1.91631971, grad/param norm = 1.7357e-01, time/batch = 0.2436s	
2594/2700 (epoch 48.037), train_loss = 1.92379279, grad/param norm = 2.2553e-01, time/batch = 0.2176s	
2595/2700 (epoch 48.056), train_loss = 1.85576138, grad/param norm = 2.1407e-01, time/batch = 0.2207s	
2596/2700 (epoch 48.074), train_loss = 1.82173775, grad/param norm = 1.6124e-01, time/batch = 0.2451s	
2597/2700 (epoch 48.093), train_loss = 1.82553534, grad/param norm = 1.3790e-01, time/batch = 0.2102s	
2598/2700 (epoch 48.111), train_loss = 1.80239693, grad/param norm = 1.1655e-01, time/batch = 0.2127s	
2599/2700 (epoch 48.130), train_loss = 1.86509749, grad/param norm = 1.2735e-01, time/batch = 0.2320s	
2600/2700 (epoch 48.148), train_loss = 1.79693661, grad/param norm = 9.7128e-02, time/batch = 0.2510s	
2601/2700 (epoch 48.167), train_loss = 1.89956713, grad/param norm = 1.1178e-01, time/batch = 0.2458s	
2602/2700 (epoch 48.185), train_loss = 1.84501626, grad/param norm = 1.2069e-01, time/batch = 0.1988s	
2603/2700 (epoch 48.204), train_loss = 1.85857071, grad/param norm = 1.2826e-01, time/batch = 0.2527s	
2604/2700 (epoch 48.222), train_loss = 1.81730455, grad/param norm = 1.1917e-01, time/batch = 0.2548s	
2605/2700 (epoch 48.241), train_loss = 1.74574929, grad/param norm = 1.4118e-01, time/batch = 0.2518s	
2606/2700 (epoch 48.259), train_loss = 1.79893211, grad/param norm = 1.3521e-01, time/batch = 0.2291s	
2607/2700 (epoch 48.278), train_loss = 1.85333303, grad/param norm = 1.2741e-01, time/batch = 0.2047s	
2608/2700 (epoch 48.296), train_loss = 1.85679645, grad/param norm = 1.2247e-01, time/batch = 0.2483s	
2609/2700 (epoch 48.315), train_loss = 1.85726421, grad/param norm = 1.2604e-01, time/batch = 0.2567s	
2610/2700 (epoch 48.333), train_loss = 1.86065082, grad/param norm = 1.2211e-01, time/batch = 0.2214s	
2611/2700 (epoch 48.352), train_loss = 1.83947594, grad/param norm = 1.0688e-01, time/batch = 0.2188s	
2612/2700 (epoch 48.370), train_loss = 1.87963591, grad/param norm = 1.2644e-01, time/batch = 0.2653s	
2613/2700 (epoch 48.389), train_loss = 1.84132200, grad/param norm = 1.5415e-01, time/batch = 0.2415s	
2614/2700 (epoch 48.407), train_loss = 1.88033232, grad/param norm = 1.3996e-01, time/batch = 0.2416s	
2615/2700 (epoch 48.426), train_loss = 1.91373628, grad/param norm = 1.4008e-01, time/batch = 0.2193s	
2616/2700 (epoch 48.444), train_loss = 1.80291078, grad/param norm = 1.6522e-01, time/batch = 0.2309s	
2617/2700 (epoch 48.463), train_loss = 1.88460214, grad/param norm = 1.7009e-01, time/batch = 0.2436s	
2618/2700 (epoch 48.481), train_loss = 1.87970988, grad/param norm = 1.4012e-01, time/batch = 0.2546s	
2619/2700 (epoch 48.500), train_loss = 1.82961798, grad/param norm = 1.8330e-01, time/batch = 0.2236s	
2620/2700 (epoch 48.519), train_loss = 1.87165328, grad/param norm = 1.9389e-01, time/batch = 0.2294s	
2621/2700 (epoch 48.537), train_loss = 1.86496251, grad/param norm = 1.7342e-01, time/batch = 0.2342s	
2622/2700 (epoch 48.556), train_loss = 1.82068120, grad/param norm = 1.4302e-01, time/batch = 0.2557s	
2623/2700 (epoch 48.574), train_loss = 1.82429914, grad/param norm = 1.1989e-01, time/batch = 0.2542s	
2624/2700 (epoch 48.593), train_loss = 1.84264208, grad/param norm = 1.2642e-01, time/batch = 0.2228s	
2625/2700 (epoch 48.611), train_loss = 1.76132741, grad/param norm = 1.3607e-01, time/batch = 0.2264s	
2626/2700 (epoch 48.630), train_loss = 1.79638935, grad/param norm = 1.1687e-01, time/batch = 0.2530s	
2627/2700 (epoch 48.648), train_loss = 1.81483353, grad/param norm = 9.2405e-02, time/batch = 0.2480s	
2628/2700 (epoch 48.667), train_loss = 1.81931128, grad/param norm = 1.1026e-01, time/batch = 0.1824s	
2629/2700 (epoch 48.685), train_loss = 1.83936663, grad/param norm = 1.4179e-01, time/batch = 0.2531s	
2630/2700 (epoch 48.704), train_loss = 1.85894477, grad/param norm = 1.4060e-01, time/batch = 0.2198s	
2631/2700 (epoch 48.722), train_loss = 1.82968010, grad/param norm = 1.3784e-01, time/batch = 0.2151s	
2632/2700 (epoch 48.741), train_loss = 1.84141083, grad/param norm = 1.0031e-01, time/batch = 0.2374s	
2633/2700 (epoch 48.759), train_loss = 1.89087316, grad/param norm = 1.0973e-01, time/batch = 0.2535s	
2634/2700 (epoch 48.778), train_loss = 1.88023828, grad/param norm = 1.1020e-01, time/batch = 0.2551s	
2635/2700 (epoch 48.796), train_loss = 1.84863337, grad/param norm = 1.2841e-01, time/batch = 0.2288s	
2636/2700 (epoch 48.815), train_loss = 1.90375881, grad/param norm = 1.4522e-01, time/batch = 0.2241s	
2637/2700 (epoch 48.833), train_loss = 1.85461164, grad/param norm = 1.0274e-01, time/batch = 0.2381s	
2638/2700 (epoch 48.852), train_loss = 1.85267467, grad/param norm = 9.4925e-02, time/batch = 0.2528s	
2639/2700 (epoch 48.870), train_loss = 1.83995005, grad/param norm = 1.2054e-01, time/batch = 0.2096s	
2640/2700 (epoch 48.889), train_loss = 1.84896539, grad/param norm = 1.5587e-01, time/batch = 0.2307s	
2641/2700 (epoch 48.907), train_loss = 1.96820031, grad/param norm = 2.0686e-01, time/batch = 0.2271s	
2642/2700 (epoch 48.926), train_loss = 1.90048485, grad/param norm = 2.1342e-01, time/batch = 0.2352s	
2643/2700 (epoch 48.944), train_loss = 1.88541200, grad/param norm = 1.6468e-01, time/batch = 0.2227s	
2644/2700 (epoch 48.963), train_loss = 1.89225089, grad/param norm = 1.2821e-01, time/batch = 0.2413s	
2645/2700 (epoch 48.981), train_loss = 1.86566180, grad/param norm = 1.1161e-01, time/batch = 0.2554s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
2646/2700 (epoch 49.000), train_loss = 1.90021518, grad/param norm = 1.1440e-01, time/batch = 0.2545s	
2647/2700 (epoch 49.019), train_loss = 1.91054450, grad/param norm = 1.7618e-01, time/batch = 0.2154s	
2648/2700 (epoch 49.037), train_loss = 1.91888095, grad/param norm = 2.3509e-01, time/batch = 0.2237s	
2649/2700 (epoch 49.056), train_loss = 1.85041880, grad/param norm = 2.2813e-01, time/batch = 0.2479s	
2650/2700 (epoch 49.074), train_loss = 1.81603494, grad/param norm = 1.7164e-01, time/batch = 0.2458s	
2651/2700 (epoch 49.093), train_loss = 1.81834398, grad/param norm = 1.3601e-01, time/batch = 0.2476s	
2652/2700 (epoch 49.111), train_loss = 1.79600079, grad/param norm = 1.2303e-01, time/batch = 0.2094s	
2653/2700 (epoch 49.130), train_loss = 1.85905507, grad/param norm = 1.3753e-01, time/batch = 0.2388s	
2654/2700 (epoch 49.148), train_loss = 1.79023926, grad/param norm = 1.0187e-01, time/batch = 0.2443s	
2655/2700 (epoch 49.167), train_loss = 1.89331807, grad/param norm = 1.1775e-01, time/batch = 0.2027s	
2656/2700 (epoch 49.185), train_loss = 1.83768887, grad/param norm = 1.1612e-01, time/batch = 0.2423s	
2657/2700 (epoch 49.204), train_loss = 1.85088007, grad/param norm = 1.2681e-01, time/batch = 0.2454s	
2658/2700 (epoch 49.222), train_loss = 1.81057133, grad/param norm = 1.1980e-01, time/batch = 0.2576s	
2659/2700 (epoch 49.241), train_loss = 1.73823669, grad/param norm = 1.3445e-01, time/batch = 0.2227s	
2660/2700 (epoch 49.259), train_loss = 1.79179723, grad/param norm = 1.2987e-01, time/batch = 0.2281s	
2661/2700 (epoch 49.278), train_loss = 1.84693205, grad/param norm = 1.3171e-01, time/batch = 0.2334s	
2662/2700 (epoch 49.296), train_loss = 1.85063779, grad/param norm = 1.2456e-01, time/batch = 0.2574s	
2663/2700 (epoch 49.315), train_loss = 1.85051886, grad/param norm = 1.2337e-01, time/batch = 0.2553s	
2664/2700 (epoch 49.333), train_loss = 1.85386193, grad/param norm = 1.2182e-01, time/batch = 0.2399s	
2665/2700 (epoch 49.352), train_loss = 1.83303065, grad/param norm = 1.0834e-01, time/batch = 0.2162s	
2666/2700 (epoch 49.370), train_loss = 1.87350250, grad/param norm = 1.3995e-01, time/batch = 0.2414s	
2667/2700 (epoch 49.389), train_loss = 1.83557772, grad/param norm = 1.9333e-01, time/batch = 0.2415s	
2668/2700 (epoch 49.407), train_loss = 1.87507137, grad/param norm = 1.6517e-01, time/batch = 0.1957s	
2669/2700 (epoch 49.426), train_loss = 1.90334908, grad/param norm = 1.0303e-01, time/batch = 0.2481s	
2670/2700 (epoch 49.444), train_loss = 1.79092361, grad/param norm = 1.1164e-01, time/batch = 0.2578s	
2671/2700 (epoch 49.463), train_loss = 1.87212910, grad/param norm = 1.3813e-01, time/batch = 0.2519s	
2672/2700 (epoch 49.481), train_loss = 1.86928316, grad/param norm = 1.2017e-01, time/batch = 0.2228s	
2673/2700 (epoch 49.500), train_loss = 1.81390226, grad/param norm = 1.0862e-01, time/batch = 0.2297s	
2674/2700 (epoch 49.519), train_loss = 1.85694099, grad/param norm = 1.1282e-01, time/batch = 0.2498s	
2675/2700 (epoch 49.537), train_loss = 1.85631778, grad/param norm = 1.3187e-01, time/batch = 0.2538s	
2676/2700 (epoch 49.556), train_loss = 1.81201081, grad/param norm = 1.2781e-01, time/batch = 0.2526s	
2677/2700 (epoch 49.574), train_loss = 1.81694520, grad/param norm = 1.2140e-01, time/batch = 0.1955s	
2678/2700 (epoch 49.593), train_loss = 1.83746887, grad/param norm = 1.3621e-01, time/batch = 0.2364s	
2679/2700 (epoch 49.611), train_loss = 1.75747929, grad/param norm = 1.5548e-01, time/batch = 0.2505s	
2680/2700 (epoch 49.630), train_loss = 1.79260881, grad/param norm = 1.4587e-01, time/batch = 0.2347s	
2681/2700 (epoch 49.648), train_loss = 1.81133286, grad/param norm = 1.2375e-01, time/batch = 0.1867s	
2682/2700 (epoch 49.667), train_loss = 1.81846748, grad/param norm = 1.4697e-01, time/batch = 0.2581s	
2683/2700 (epoch 49.685), train_loss = 1.84039806, grad/param norm = 1.7514e-01, time/batch = 0.2536s	
2684/2700 (epoch 49.704), train_loss = 1.85541988, grad/param norm = 1.6477e-01, time/batch = 0.2349s	
2685/2700 (epoch 49.722), train_loss = 1.82511386, grad/param norm = 1.4229e-01, time/batch = 0.2183s	
2686/2700 (epoch 49.741), train_loss = 1.83421702, grad/param norm = 9.9481e-02, time/batch = 0.2453s	
2687/2700 (epoch 49.759), train_loss = 1.88335606, grad/param norm = 1.0523e-01, time/batch = 0.2485s	
2688/2700 (epoch 49.778), train_loss = 1.87247459, grad/param norm = 1.1064e-01, time/batch = 0.2584s	
2689/2700 (epoch 49.796), train_loss = 1.84074844, grad/param norm = 1.2883e-01, time/batch = 0.2208s	
2690/2700 (epoch 49.815), train_loss = 1.89411651, grad/param norm = 1.2892e-01, time/batch = 0.2310s	
2691/2700 (epoch 49.833), train_loss = 1.84751673, grad/param norm = 1.0223e-01, time/batch = 0.2361s	
2692/2700 (epoch 49.852), train_loss = 1.84790760, grad/param norm = 1.1254e-01, time/batch = 0.2585s	
2693/2700 (epoch 49.870), train_loss = 1.83659940, grad/param norm = 1.3862e-01, time/batch = 0.2497s	
2694/2700 (epoch 49.889), train_loss = 1.84351279, grad/param norm = 1.5553e-01, time/batch = 0.1855s	
2695/2700 (epoch 49.907), train_loss = 1.95857064, grad/param norm = 1.7174e-01, time/batch = 0.2575s	
2696/2700 (epoch 49.926), train_loss = 1.89024008, grad/param norm = 1.4912e-01, time/batch = 0.2550s	
2697/2700 (epoch 49.944), train_loss = 1.87570496, grad/param norm = 1.1991e-01, time/batch = 0.2271s	
2698/2700 (epoch 49.963), train_loss = 1.88442652, grad/param norm = 1.1315e-01, time/batch = 0.2164s	
2699/2700 (epoch 49.981), train_loss = 1.85775841, grad/param norm = 1.0709e-01, time/batch = 0.2442s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch50.00_1.9534.t7	
2700/2700 (epoch 50.000), train_loss = 1.89239239, grad/param norm = 1.1193e-01, time/batch = 0.2558s	
