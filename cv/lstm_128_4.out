using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 54, val: 3, test: 0	
vocab size: 91	
creating an lstm with 4 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
setting forget gate biases to 1 in LSTM layer 3	
setting forget gate biases to 1 in LSTM layer 4	
number of parameters in the model: 521179	
cloning rnn	
cloning criterion	
1/2700 (epoch 0.019), train_loss = 4.52110434, grad/param norm = 4.2816e-01, time/batch = 0.8804s	
2/2700 (epoch 0.037), train_loss = 4.08720606, grad/param norm = 1.2788e+00, time/batch = 0.3179s	
3/2700 (epoch 0.056), train_loss = 3.46655166, grad/param norm = 8.9651e-01, time/batch = 0.3242s	
4/2700 (epoch 0.074), train_loss = 3.34862298, grad/param norm = 3.9183e-01, time/batch = 0.3065s	
5/2700 (epoch 0.093), train_loss = 3.32757370, grad/param norm = 3.5238e-01, time/batch = 0.3089s	
6/2700 (epoch 0.111), train_loss = 3.28613306, grad/param norm = 3.0708e-01, time/batch = 0.3161s	
7/2700 (epoch 0.130), train_loss = 3.29446305, grad/param norm = 2.6361e-01, time/batch = 0.3201s	
8/2700 (epoch 0.148), train_loss = 3.25798693, grad/param norm = 2.5451e-01, time/batch = 0.3178s	
9/2700 (epoch 0.167), train_loss = 3.26315789, grad/param norm = 3.0994e-01, time/batch = 0.3168s	
10/2700 (epoch 0.185), train_loss = 3.24659606, grad/param norm = 2.2183e-01, time/batch = 0.3097s	
11/2700 (epoch 0.204), train_loss = 3.18351011, grad/param norm = 2.3914e-01, time/batch = 0.3135s	
12/2700 (epoch 0.222), train_loss = 3.15644838, grad/param norm = 3.2091e-01, time/batch = 0.3107s	
13/2700 (epoch 0.241), train_loss = 3.17572250, grad/param norm = 2.3436e-01, time/batch = 0.3167s	
14/2700 (epoch 0.259), train_loss = 3.20508883, grad/param norm = 2.5425e-01, time/batch = 0.3030s	
15/2700 (epoch 0.278), train_loss = 3.27749347, grad/param norm = 2.6597e-01, time/batch = 0.3029s	
16/2700 (epoch 0.296), train_loss = 3.28004228, grad/param norm = 2.6712e-01, time/batch = 0.3317s	
17/2700 (epoch 0.315), train_loss = 3.25407879, grad/param norm = 2.5358e-01, time/batch = 0.3141s	
18/2700 (epoch 0.333), train_loss = 3.33666032, grad/param norm = 2.5620e-01, time/batch = 0.3134s	
19/2700 (epoch 0.352), train_loss = 3.33840696, grad/param norm = 3.0159e-01, time/batch = 0.2992s	
20/2700 (epoch 0.370), train_loss = 3.28347979, grad/param norm = 2.8038e-01, time/batch = 0.2874s	
21/2700 (epoch 0.389), train_loss = 3.25148483, grad/param norm = 1.9531e-01, time/batch = 0.3067s	
22/2700 (epoch 0.407), train_loss = 3.27650009, grad/param norm = 2.3169e-01, time/batch = 0.2856s	
23/2700 (epoch 0.426), train_loss = 3.27891387, grad/param norm = 2.2659e-01, time/batch = 0.2857s	
24/2700 (epoch 0.444), train_loss = 3.21022725, grad/param norm = 2.0663e-01, time/batch = 0.2881s	
25/2700 (epoch 0.463), train_loss = 3.24833947, grad/param norm = 2.5942e-01, time/batch = 0.2785s	
26/2700 (epoch 0.481), train_loss = 3.32599987, grad/param norm = 2.9191e-01, time/batch = 0.2823s	
27/2700 (epoch 0.500), train_loss = 3.36725935, grad/param norm = 3.7014e-01, time/batch = 0.2957s	
28/2700 (epoch 0.519), train_loss = 3.32248500, grad/param norm = 2.9438e-01, time/batch = 0.2735s	
29/2700 (epoch 0.537), train_loss = 3.32557158, grad/param norm = 3.0225e-01, time/batch = 0.3023s	
30/2700 (epoch 0.556), train_loss = 3.26083895, grad/param norm = 2.1650e-01, time/batch = 0.3096s	
31/2700 (epoch 0.574), train_loss = 3.23141692, grad/param norm = 2.5777e-01, time/batch = 0.2696s	
32/2700 (epoch 0.593), train_loss = 3.22884721, grad/param norm = 2.9249e-01, time/batch = 0.2793s	
33/2700 (epoch 0.611), train_loss = 3.17183317, grad/param norm = 1.9087e-01, time/batch = 0.2889s	
34/2700 (epoch 0.630), train_loss = 3.21251920, grad/param norm = 2.3096e-01, time/batch = 0.3485s	
35/2700 (epoch 0.648), train_loss = 3.27732837, grad/param norm = 2.4638e-01, time/batch = 0.3509s	
36/2700 (epoch 0.667), train_loss = 3.21194897, grad/param norm = 1.9968e-01, time/batch = 0.3591s	
37/2700 (epoch 0.685), train_loss = 3.21157218, grad/param norm = 2.6591e-01, time/batch = 0.3727s	
38/2700 (epoch 0.704), train_loss = 3.18234285, grad/param norm = 3.3845e-01, time/batch = 0.3729s	
39/2700 (epoch 0.722), train_loss = 3.17182953, grad/param norm = 2.4286e-01, time/batch = 0.3575s	
40/2700 (epoch 0.741), train_loss = 3.30667158, grad/param norm = 3.6556e-01, time/batch = 0.3520s	
41/2700 (epoch 0.759), train_loss = 3.25372473, grad/param norm = 3.4205e-01, time/batch = 0.3557s	
42/2700 (epoch 0.778), train_loss = 3.24560283, grad/param norm = 2.7479e-01, time/batch = 0.3332s	
43/2700 (epoch 0.796), train_loss = 3.23742597, grad/param norm = 2.5320e-01, time/batch = 0.3437s	
44/2700 (epoch 0.815), train_loss = 3.19040846, grad/param norm = 2.0155e-01, time/batch = 0.3428s	
45/2700 (epoch 0.833), train_loss = 3.22824254, grad/param norm = 2.2784e-01, time/batch = 0.3474s	
46/2700 (epoch 0.852), train_loss = 3.21621524, grad/param norm = 2.3786e-01, time/batch = 0.3568s	
47/2700 (epoch 0.870), train_loss = 3.20974013, grad/param norm = 1.6279e-01, time/batch = 0.3700s	
48/2700 (epoch 0.889), train_loss = 3.24929432, grad/param norm = 2.2344e-01, time/batch = 0.3524s	
49/2700 (epoch 0.907), train_loss = 3.30091099, grad/param norm = 3.1689e-01, time/batch = 0.3439s	
50/2700 (epoch 0.926), train_loss = 3.24913974, grad/param norm = 2.9284e-01, time/batch = 0.3433s	
51/2700 (epoch 0.944), train_loss = 3.25847587, grad/param norm = 2.5907e-01, time/batch = 0.3539s	
52/2700 (epoch 0.963), train_loss = 3.33823796, grad/param norm = 2.4350e-01, time/batch = 0.3450s	
53/2700 (epoch 0.981), train_loss = 3.40078382, grad/param norm = 2.9756e-01, time/batch = 0.3442s	
54/2700 (epoch 1.000), train_loss = 3.29688282, grad/param norm = 2.8182e-01, time/batch = 0.3447s	
55/2700 (epoch 1.019), train_loss = 3.23272568, grad/param norm = 3.2559e-01, time/batch = 0.3472s	
56/2700 (epoch 1.037), train_loss = 3.25142739, grad/param norm = 2.4705e-01, time/batch = 0.3501s	
57/2700 (epoch 1.056), train_loss = 3.25947278, grad/param norm = 2.4386e-01, time/batch = 0.3579s	
58/2700 (epoch 1.074), train_loss = 3.28859891, grad/param norm = 3.3062e-01, time/batch = 0.3462s	
59/2700 (epoch 1.093), train_loss = 3.29130817, grad/param norm = 3.3383e-01, time/batch = 0.3512s	
60/2700 (epoch 1.111), train_loss = 3.26376103, grad/param norm = 2.5038e-01, time/batch = 0.3457s	
61/2700 (epoch 1.130), train_loss = 3.27907463, grad/param norm = 2.4313e-01, time/batch = 0.3174s	
62/2700 (epoch 1.148), train_loss = 3.24326755, grad/param norm = 2.5221e-01, time/batch = 0.3552s	
63/2700 (epoch 1.167), train_loss = 3.25072846, grad/param norm = 3.0432e-01, time/batch = 0.3432s	
64/2700 (epoch 1.185), train_loss = 3.23632971, grad/param norm = 1.8783e-01, time/batch = 0.3465s	
65/2700 (epoch 1.204), train_loss = 3.17398567, grad/param norm = 2.3640e-01, time/batch = 0.3482s	
66/2700 (epoch 1.222), train_loss = 3.14788852, grad/param norm = 3.2353e-01, time/batch = 0.3307s	
67/2700 (epoch 1.241), train_loss = 3.16799595, grad/param norm = 2.5210e-01, time/batch = 0.3663s	
68/2700 (epoch 1.259), train_loss = 3.20117118, grad/param norm = 2.7445e-01, time/batch = 0.3483s	
69/2700 (epoch 1.278), train_loss = 3.27424045, grad/param norm = 2.6541e-01, time/batch = 0.3451s	
70/2700 (epoch 1.296), train_loss = 3.27680362, grad/param norm = 2.8758e-01, time/batch = 0.3313s	
71/2700 (epoch 1.315), train_loss = 3.25310911, grad/param norm = 2.9055e-01, time/batch = 0.3615s	
72/2700 (epoch 1.333), train_loss = 3.33534521, grad/param norm = 2.9633e-01, time/batch = 0.3509s	
73/2700 (epoch 1.352), train_loss = 3.33851750, grad/param norm = 3.1463e-01, time/batch = 0.3444s	
74/2700 (epoch 1.370), train_loss = 3.28157296, grad/param norm = 2.5823e-01, time/batch = 0.3497s	
75/2700 (epoch 1.389), train_loss = 3.25025844, grad/param norm = 1.8194e-01, time/batch = 0.3309s	
76/2700 (epoch 1.407), train_loss = 3.27264694, grad/param norm = 2.1135e-01, time/batch = 0.3865s	
77/2700 (epoch 1.426), train_loss = 3.27438167, grad/param norm = 2.1052e-01, time/batch = 0.3428s	
78/2700 (epoch 1.444), train_loss = 3.20735968, grad/param norm = 2.0213e-01, time/batch = 0.3480s	
79/2700 (epoch 1.463), train_loss = 3.24637813, grad/param norm = 2.5596e-01, time/batch = 0.3174s	
80/2700 (epoch 1.481), train_loss = 3.32519643, grad/param norm = 2.9821e-01, time/batch = 0.3492s	
81/2700 (epoch 1.500), train_loss = 3.36685123, grad/param norm = 3.7651e-01, time/batch = 0.3679s	
82/2700 (epoch 1.519), train_loss = 3.32160237, grad/param norm = 3.0517e-01, time/batch = 0.3455s	
83/2700 (epoch 1.537), train_loss = 3.32507098, grad/param norm = 3.2174e-01, time/batch = 0.3501s	
84/2700 (epoch 1.556), train_loss = 3.25956881, grad/param norm = 2.3189e-01, time/batch = 0.3528s	
85/2700 (epoch 1.574), train_loss = 3.23029879, grad/param norm = 2.5546e-01, time/batch = 0.3769s	
86/2700 (epoch 1.593), train_loss = 3.22662237, grad/param norm = 2.7958e-01, time/batch = 0.3717s	
87/2700 (epoch 1.611), train_loss = 3.16963014, grad/param norm = 1.8169e-01, time/batch = 0.3506s	
88/2700 (epoch 1.630), train_loss = 3.21095213, grad/param norm = 2.2716e-01, time/batch = 0.3233s	
89/2700 (epoch 1.648), train_loss = 3.27699938, grad/param norm = 2.3900e-01, time/batch = 0.3423s	
90/2700 (epoch 1.667), train_loss = 3.21119874, grad/param norm = 1.9141e-01, time/batch = 0.3429s	
91/2700 (epoch 1.685), train_loss = 3.20980335, grad/param norm = 2.4555e-01, time/batch = 0.3593s	
92/2700 (epoch 1.704), train_loss = 3.18151874, grad/param norm = 3.1345e-01, time/batch = 0.3491s	
93/2700 (epoch 1.722), train_loss = 3.17162940, grad/param norm = 2.1715e-01, time/batch = 0.3586s	
94/2700 (epoch 1.741), train_loss = 3.30738342, grad/param norm = 3.4452e-01, time/batch = 0.3711s	
95/2700 (epoch 1.759), train_loss = 3.25349690, grad/param norm = 3.3522e-01, time/batch = 0.3763s	
96/2700 (epoch 1.778), train_loss = 3.24483743, grad/param norm = 2.7084e-01, time/batch = 0.3757s	
97/2700 (epoch 1.796), train_loss = 3.23701197, grad/param norm = 2.4986e-01, time/batch = 0.3187s	
98/2700 (epoch 1.815), train_loss = 3.19053899, grad/param norm = 1.9578e-01, time/batch = 0.3390s	
99/2700 (epoch 1.833), train_loss = 3.22814779, grad/param norm = 2.2454e-01, time/batch = 0.3394s	
100/2700 (epoch 1.852), train_loss = 3.21558323, grad/param norm = 2.4013e-01, time/batch = 0.3433s	
101/2700 (epoch 1.870), train_loss = 3.20971710, grad/param norm = 1.7378e-01, time/batch = 0.3467s	
102/2700 (epoch 1.889), train_loss = 3.24982869, grad/param norm = 2.3048e-01, time/batch = 0.3436s	
103/2700 (epoch 1.907), train_loss = 3.30145692, grad/param norm = 3.1357e-01, time/batch = 0.3283s	
104/2700 (epoch 1.926), train_loss = 3.24905136, grad/param norm = 2.9112e-01, time/batch = 0.3533s	
105/2700 (epoch 1.944), train_loss = 3.25824440, grad/param norm = 2.5221e-01, time/batch = 0.3626s	
106/2700 (epoch 1.963), train_loss = 3.33791001, grad/param norm = 2.3173e-01, time/batch = 0.3731s	
107/2700 (epoch 1.981), train_loss = 3.39866347, grad/param norm = 2.7838e-01, time/batch = 0.3820s	
108/2700 (epoch 2.000), train_loss = 3.29824232, grad/param norm = 2.7927e-01, time/batch = 0.3497s	
109/2700 (epoch 2.019), train_loss = 3.23350739, grad/param norm = 3.3547e-01, time/batch = 0.3422s	
110/2700 (epoch 2.037), train_loss = 3.25228558, grad/param norm = 2.4803e-01, time/batch = 0.3396s	
111/2700 (epoch 2.056), train_loss = 3.25840386, grad/param norm = 2.1140e-01, time/batch = 0.3447s	
112/2700 (epoch 2.074), train_loss = 3.28703235, grad/param norm = 2.5880e-01, time/batch = 0.3762s	
113/2700 (epoch 2.093), train_loss = 3.29000742, grad/param norm = 2.7077e-01, time/batch = 0.3664s	
114/2700 (epoch 2.111), train_loss = 3.26288915, grad/param norm = 2.1991e-01, time/batch = 0.3636s	
115/2700 (epoch 2.130), train_loss = 3.27847049, grad/param norm = 2.2890e-01, time/batch = 0.3551s	
116/2700 (epoch 2.148), train_loss = 3.24343960, grad/param norm = 2.4386e-01, time/batch = 0.3514s	
117/2700 (epoch 2.167), train_loss = 3.25017735, grad/param norm = 2.9019e-01, time/batch = 0.3464s	
118/2700 (epoch 2.185), train_loss = 3.23628470, grad/param norm = 1.7949e-01, time/batch = 0.3614s	
119/2700 (epoch 2.204), train_loss = 3.17317985, grad/param norm = 2.2384e-01, time/batch = 0.3412s	
120/2700 (epoch 2.222), train_loss = 3.14727733, grad/param norm = 3.1918e-01, time/batch = 0.3402s	
121/2700 (epoch 2.241), train_loss = 3.16796225, grad/param norm = 2.6938e-01, time/batch = 0.3772s	
122/2700 (epoch 2.259), train_loss = 3.20222986, grad/param norm = 3.0299e-01, time/batch = 0.3526s	
123/2700 (epoch 2.278), train_loss = 3.27503812, grad/param norm = 2.7337e-01, time/batch = 0.3497s	
124/2700 (epoch 2.296), train_loss = 3.27626323, grad/param norm = 2.8068e-01, time/batch = 0.3014s	
125/2700 (epoch 2.315), train_loss = 3.25333169, grad/param norm = 2.8607e-01, time/batch = 0.3416s	
126/2700 (epoch 2.333), train_loss = 3.33529309, grad/param norm = 2.9287e-01, time/batch = 0.3471s	
127/2700 (epoch 2.352), train_loss = 3.33653330, grad/param norm = 3.0188e-01, time/batch = 0.3561s	
128/2700 (epoch 2.370), train_loss = 3.28410357, grad/param norm = 3.2502e-01, time/batch = 0.3292s	
129/2700 (epoch 2.389), train_loss = 3.25166188, grad/param norm = 3.2434e-01, time/batch = 0.3339s	
130/2700 (epoch 2.407), train_loss = 3.27424707, grad/param norm = 2.5224e-01, time/batch = 0.3424s	
131/2700 (epoch 2.426), train_loss = 3.27464537, grad/param norm = 2.0278e-01, time/batch = 0.3766s	
132/2700 (epoch 2.444), train_loss = 3.20667780, grad/param norm = 2.0050e-01, time/batch = 0.3661s	
133/2700 (epoch 2.463), train_loss = 3.24611831, grad/param norm = 2.3640e-01, time/batch = 0.3292s	
134/2700 (epoch 2.481), train_loss = 3.32432798, grad/param norm = 2.5070e-01, time/batch = 0.3466s	
135/2700 (epoch 2.500), train_loss = 3.36378088, grad/param norm = 3.0435e-01, time/batch = 0.3488s	
136/2700 (epoch 2.519), train_loss = 3.31783578, grad/param norm = 2.1200e-01, time/batch = 0.3575s	
137/2700 (epoch 2.537), train_loss = 3.31912494, grad/param norm = 2.6031e-01, time/batch = 0.3548s	
138/2700 (epoch 2.556), train_loss = 3.25462772, grad/param norm = 1.8773e-01, time/batch = 0.3395s	
139/2700 (epoch 2.574), train_loss = 3.22491477, grad/param norm = 2.2826e-01, time/batch = 0.3541s	
140/2700 (epoch 2.593), train_loss = 3.22653902, grad/param norm = 2.5533e-01, time/batch = 0.3716s	
141/2700 (epoch 2.611), train_loss = 3.16903823, grad/param norm = 1.6835e-01, time/batch = 0.3685s	
142/2700 (epoch 2.630), train_loss = 3.21099409, grad/param norm = 2.1661e-01, time/batch = 0.3068s	
143/2700 (epoch 2.648), train_loss = 3.27478056, grad/param norm = 2.2700e-01, time/batch = 0.3691s	
144/2700 (epoch 2.667), train_loss = 3.20739724, grad/param norm = 1.7591e-01, time/batch = 0.3517s	
145/2700 (epoch 2.685), train_loss = 3.21023178, grad/param norm = 2.4337e-01, time/batch = 0.3464s	
146/2700 (epoch 2.704), train_loss = 3.18053267, grad/param norm = 2.6849e-01, time/batch = 0.3466s	
147/2700 (epoch 2.722), train_loss = 3.17056256, grad/param norm = 1.5814e-01, time/batch = 0.3505s	
148/2700 (epoch 2.741), train_loss = 3.30605627, grad/param norm = 2.4019e-01, time/batch = 0.3553s	
149/2700 (epoch 2.759), train_loss = 3.25193628, grad/param norm = 2.7849e-01, time/batch = 0.3798s	
150/2700 (epoch 2.778), train_loss = 3.24319726, grad/param norm = 2.4497e-01, time/batch = 0.3716s	
151/2700 (epoch 2.796), train_loss = 3.23401768, grad/param norm = 2.3018e-01, time/batch = 0.3214s	
152/2700 (epoch 2.815), train_loss = 3.18848602, grad/param norm = 1.7989e-01, time/batch = 0.3417s	
153/2700 (epoch 2.833), train_loss = 3.22140604, grad/param norm = 2.0580e-01, time/batch = 0.3363s	
154/2700 (epoch 2.852), train_loss = 3.22160082, grad/param norm = 3.7028e-01, time/batch = 0.3394s	
155/2700 (epoch 2.870), train_loss = 3.21839657, grad/param norm = 4.3071e-01, time/batch = 0.3412s	
156/2700 (epoch 2.889), train_loss = 3.25330653, grad/param norm = 2.6575e-01, time/batch = 0.3354s	
157/2700 (epoch 2.907), train_loss = 3.30370919, grad/param norm = 2.8573e-01, time/batch = 0.3464s	
158/2700 (epoch 2.926), train_loss = 3.24940916, grad/param norm = 2.6978e-01, time/batch = 0.3534s	
159/2700 (epoch 2.944), train_loss = 3.25712942, grad/param norm = 2.4927e-01, time/batch = 0.3645s	
160/2700 (epoch 2.963), train_loss = 3.32765257, grad/param norm = 2.1975e-01, time/batch = 0.3580s	
161/2700 (epoch 2.981), train_loss = 3.34552512, grad/param norm = 2.4100e-01, time/batch = 0.4057s	
162/2700 (epoch 3.000), train_loss = 3.39514655, grad/param norm = 1.9482e+00, time/batch = 0.3518s	
163/2700 (epoch 3.019), train_loss = 3.23614451, grad/param norm = 3.5758e-01, time/batch = 0.3500s	
164/2700 (epoch 3.037), train_loss = 3.25580070, grad/param norm = 2.1944e-01, time/batch = 0.3502s	
165/2700 (epoch 3.056), train_loss = 3.25975354, grad/param norm = 2.3089e-01, time/batch = 0.3500s	
166/2700 (epoch 3.074), train_loss = 3.28044589, grad/param norm = 2.7351e-01, time/batch = 0.3546s	
167/2700 (epoch 3.093), train_loss = 3.28779406, grad/param norm = 2.3221e-01, time/batch = 0.3664s	
168/2700 (epoch 3.111), train_loss = 3.26010916, grad/param norm = 1.9047e-01, time/batch = 0.3735s	
169/2700 (epoch 3.130), train_loss = 3.26553299, grad/param norm = 2.0539e-01, time/batch = 0.3466s	
170/2700 (epoch 3.148), train_loss = 3.23918087, grad/param norm = 2.0660e-01, time/batch = 0.3710s	
171/2700 (epoch 3.167), train_loss = 3.24399661, grad/param norm = 2.3817e-01, time/batch = 0.3446s	
172/2700 (epoch 3.185), train_loss = 3.23095520, grad/param norm = 1.5806e-01, time/batch = 0.3405s	
173/2700 (epoch 3.204), train_loss = 3.16531670, grad/param norm = 1.9452e-01, time/batch = 0.3471s	
174/2700 (epoch 3.222), train_loss = 3.14455516, grad/param norm = 2.6432e-01, time/batch = 0.3554s	
175/2700 (epoch 3.241), train_loss = 3.16362551, grad/param norm = 1.9166e-01, time/batch = 0.3575s	
176/2700 (epoch 3.259), train_loss = 3.19134585, grad/param norm = 2.0737e-01, time/batch = 0.3559s	
177/2700 (epoch 3.278), train_loss = 3.24646094, grad/param norm = 1.8921e-01, time/batch = 0.3747s	
178/2700 (epoch 3.296), train_loss = 3.24885757, grad/param norm = 1.8381e-01, time/batch = 0.3690s	
179/2700 (epoch 3.315), train_loss = 3.24038713, grad/param norm = 1.8901e-01, time/batch = 0.3650s	
180/2700 (epoch 3.333), train_loss = 3.29251288, grad/param norm = 2.3041e-01, time/batch = 0.3523s	
181/2700 (epoch 3.352), train_loss = 3.29130586, grad/param norm = 2.9095e-01, time/batch = 0.3475s	
182/2700 (epoch 3.370), train_loss = 3.26158352, grad/param norm = 2.7475e-01, time/batch = 0.3497s	
183/2700 (epoch 3.389), train_loss = 3.23595902, grad/param norm = 1.8189e-01, time/batch = 0.3640s	
184/2700 (epoch 3.407), train_loss = 3.24648264, grad/param norm = 1.9446e-01, time/batch = 0.3524s	
185/2700 (epoch 3.426), train_loss = 3.23748440, grad/param norm = 3.1517e-01, time/batch = 0.3481s	
186/2700 (epoch 3.444), train_loss = 3.17773331, grad/param norm = 3.1013e-01, time/batch = 0.3651s	
187/2700 (epoch 3.463), train_loss = 3.23217391, grad/param norm = 2.3800e-01, time/batch = 0.3588s	
188/2700 (epoch 3.481), train_loss = 3.28005534, grad/param norm = 1.7229e-01, time/batch = 0.3641s	
189/2700 (epoch 3.500), train_loss = 3.29609360, grad/param norm = 2.4676e-01, time/batch = 0.3751s	
190/2700 (epoch 3.519), train_loss = 3.26306808, grad/param norm = 1.9415e-01, time/batch = 0.3605s	
191/2700 (epoch 3.537), train_loss = 3.23752846, grad/param norm = 3.2224e-01, time/batch = 0.3960s	
192/2700 (epoch 3.556), train_loss = 3.22122454, grad/param norm = 3.0534e-01, time/batch = 0.3520s	
193/2700 (epoch 3.574), train_loss = 3.19515254, grad/param norm = 2.8777e-01, time/batch = 0.3477s	
194/2700 (epoch 3.593), train_loss = 3.20075158, grad/param norm = 2.3587e-01, time/batch = 0.3571s	
195/2700 (epoch 3.611), train_loss = 3.15540305, grad/param norm = 1.6571e-01, time/batch = 0.3726s	
196/2700 (epoch 3.630), train_loss = 3.19018823, grad/param norm = 1.9113e-01, time/batch = 0.3989s	
197/2700 (epoch 3.648), train_loss = 3.21996314, grad/param norm = 2.5885e-01, time/batch = 0.3491s	
198/2700 (epoch 3.667), train_loss = 3.16686985, grad/param norm = 2.5066e-01, time/batch = 0.3450s	
199/2700 (epoch 3.685), train_loss = 3.19056430, grad/param norm = 3.1506e-01, time/batch = 0.3517s	
200/2700 (epoch 3.704), train_loss = 3.16982782, grad/param norm = 3.9427e-01, time/batch = 0.3591s	
201/2700 (epoch 3.722), train_loss = 3.15168756, grad/param norm = 2.9644e-01, time/batch = 0.3431s	
202/2700 (epoch 3.741), train_loss = 3.29257784, grad/param norm = 4.0155e-01, time/batch = 0.3585s	
203/2700 (epoch 3.759), train_loss = 3.27138883, grad/param norm = 6.7143e-01, time/batch = 0.3708s	
204/2700 (epoch 3.778), train_loss = 3.26076996, grad/param norm = 4.0514e-01, time/batch = 0.3693s	
205/2700 (epoch 3.796), train_loss = 3.22019087, grad/param norm = 2.0477e-01, time/batch = 0.3761s	
206/2700 (epoch 3.815), train_loss = 3.17056343, grad/param norm = 1.6521e-01, time/batch = 0.3431s	
207/2700 (epoch 3.833), train_loss = 3.18695974, grad/param norm = 1.8030e-01, time/batch = 0.3433s	
208/2700 (epoch 3.852), train_loss = 3.17955637, grad/param norm = 1.7601e-01, time/batch = 0.3414s	
209/2700 (epoch 3.870), train_loss = 3.16882723, grad/param norm = 1.0707e-01, time/batch = 0.3426s	
210/2700 (epoch 3.889), train_loss = 3.18656022, grad/param norm = 1.5204e-01, time/batch = 0.3428s	
211/2700 (epoch 3.907), train_loss = 3.21986731, grad/param norm = 2.1383e-01, time/batch = 0.3627s	
212/2700 (epoch 3.926), train_loss = 3.17446463, grad/param norm = 2.0645e-01, time/batch = 0.3462s	
213/2700 (epoch 3.944), train_loss = 3.16308242, grad/param norm = 2.1456e-01, time/batch = 0.3465s	
214/2700 (epoch 3.963), train_loss = 3.21220890, grad/param norm = 3.9655e-01, time/batch = 0.3635s	
215/2700 (epoch 3.981), train_loss = 3.29552679, grad/param norm = 5.7598e-01, time/batch = 0.3713s	
216/2700 (epoch 4.000), train_loss = 3.17677921, grad/param norm = 3.1441e-01, time/batch = 0.3732s	
217/2700 (epoch 4.019), train_loss = 3.14821123, grad/param norm = 2.5216e-01, time/batch = 0.3662s	
218/2700 (epoch 4.037), train_loss = 3.16459571, grad/param norm = 3.2260e-01, time/batch = 0.3444s	
219/2700 (epoch 4.056), train_loss = 3.19765351, grad/param norm = 4.7770e-01, time/batch = 0.3393s	
220/2700 (epoch 4.074), train_loss = 3.23900496, grad/param norm = 7.1888e-01, time/batch = 0.3404s	
221/2700 (epoch 4.093), train_loss = 3.28378394, grad/param norm = 5.9719e-01, time/batch = 0.3739s	
222/2700 (epoch 4.111), train_loss = 3.17515214, grad/param norm = 2.2390e-01, time/batch = 0.3287s	
223/2700 (epoch 4.130), train_loss = 3.15535190, grad/param norm = 1.8936e-01, time/batch = 0.3452s	
224/2700 (epoch 4.148), train_loss = 3.13852456, grad/param norm = 1.8308e-01, time/batch = 0.3399s	
225/2700 (epoch 4.167), train_loss = 3.13194890, grad/param norm = 2.1368e-01, time/batch = 0.3430s	
226/2700 (epoch 4.185), train_loss = 3.10655972, grad/param norm = 1.4539e-01, time/batch = 0.3411s	
227/2700 (epoch 4.204), train_loss = 3.05046082, grad/param norm = 2.0997e-01, time/batch = 0.3397s	
228/2700 (epoch 4.222), train_loss = 3.02705406, grad/param norm = 2.9951e-01, time/batch = 0.3509s	
229/2700 (epoch 4.241), train_loss = 3.03731765, grad/param norm = 4.0451e-01, time/batch = 0.3125s	
230/2700 (epoch 4.259), train_loss = 3.10062832, grad/param norm = 7.2842e-01, time/batch = 0.3454s	
231/2700 (epoch 4.278), train_loss = 3.19222940, grad/param norm = 8.2028e-01, time/batch = 0.3599s	
232/2700 (epoch 4.296), train_loss = 3.20198020, grad/param norm = 7.2342e-01, time/batch = 0.3547s	
233/2700 (epoch 4.315), train_loss = 3.11390731, grad/param norm = 2.4290e-01, time/batch = 0.3456s	
234/2700 (epoch 4.333), train_loss = 3.14279147, grad/param norm = 1.4885e-01, time/batch = 0.3536s	
235/2700 (epoch 4.352), train_loss = 3.14955891, grad/param norm = 2.0887e-01, time/batch = 0.3533s	
236/2700 (epoch 4.370), train_loss = 3.10334180, grad/param norm = 1.7664e-01, time/batch = 0.3440s	
237/2700 (epoch 4.389), train_loss = 3.07616996, grad/param norm = 1.9458e-01, time/batch = 0.3361s	
238/2700 (epoch 4.407), train_loss = 3.08568161, grad/param norm = 1.7284e-01, time/batch = 0.3464s	
239/2700 (epoch 4.426), train_loss = 3.06221148, grad/param norm = 1.5113e-01, time/batch = 0.3490s	
240/2700 (epoch 4.444), train_loss = 2.97621754, grad/param norm = 1.6755e-01, time/batch = 0.3572s	
241/2700 (epoch 4.463), train_loss = 3.02524047, grad/param norm = 1.8219e-01, time/batch = 0.3398s	
242/2700 (epoch 4.481), train_loss = 3.09171079, grad/param norm = 2.4830e-01, time/batch = 0.3426s	
243/2700 (epoch 4.500), train_loss = 3.12958165, grad/param norm = 5.6647e-01, time/batch = 0.3457s	
244/2700 (epoch 4.519), train_loss = 3.19333194, grad/param norm = 1.0524e+00, time/batch = 0.3389s	
245/2700 (epoch 4.537), train_loss = 3.20495460, grad/param norm = 1.0979e+00, time/batch = 0.3423s	
246/2700 (epoch 4.556), train_loss = 3.04551220, grad/param norm = 3.2596e-01, time/batch = 0.3269s	
247/2700 (epoch 4.574), train_loss = 2.99798346, grad/param norm = 1.9323e-01, time/batch = 0.3427s	
248/2700 (epoch 4.593), train_loss = 2.99027034, grad/param norm = 2.0150e-01, time/batch = 0.3411s	
249/2700 (epoch 4.611), train_loss = 2.97854264, grad/param norm = 1.2320e-01, time/batch = 0.3477s	
250/2700 (epoch 4.630), train_loss = 2.98869415, grad/param norm = 1.7336e-01, time/batch = 0.3210s	
251/2700 (epoch 4.648), train_loss = 3.00905216, grad/param norm = 1.8942e-01, time/batch = 0.3584s	
252/2700 (epoch 4.667), train_loss = 2.95606680, grad/param norm = 1.4125e-01, time/batch = 0.3560s	
253/2700 (epoch 4.685), train_loss = 3.00073253, grad/param norm = 2.3757e-01, time/batch = 0.3583s	
254/2700 (epoch 4.704), train_loss = 2.95666668, grad/param norm = 2.2764e-01, time/batch = 0.3407s	
255/2700 (epoch 4.722), train_loss = 2.95036383, grad/param norm = 2.5414e-01, time/batch = 0.3317s	
256/2700 (epoch 4.741), train_loss = 3.11319824, grad/param norm = 5.7264e-01, time/batch = 0.3275s	
257/2700 (epoch 4.759), train_loss = 3.12982462, grad/param norm = 8.1798e-01, time/batch = 0.3439s	
258/2700 (epoch 4.778), train_loss = 3.11674496, grad/param norm = 8.7736e-01, time/batch = 0.3434s	
259/2700 (epoch 4.796), train_loss = 3.02926201, grad/param norm = 4.7734e-01, time/batch = 0.3449s	
260/2700 (epoch 4.815), train_loss = 2.96845187, grad/param norm = 2.4085e-01, time/batch = 0.3519s	
261/2700 (epoch 4.833), train_loss = 2.96402205, grad/param norm = 1.9827e-01, time/batch = 0.3786s	
262/2700 (epoch 4.852), train_loss = 2.98119143, grad/param norm = 1.6388e-01, time/batch = 0.3655s	
263/2700 (epoch 4.870), train_loss = 2.93668791, grad/param norm = 1.1166e-01, time/batch = 0.3454s	
264/2700 (epoch 4.889), train_loss = 2.97196400, grad/param norm = 1.8162e-01, time/batch = 0.3415s	
265/2700 (epoch 4.907), train_loss = 3.02062615, grad/param norm = 2.2149e-01, time/batch = 0.3169s	
266/2700 (epoch 4.926), train_loss = 2.98025229, grad/param norm = 3.0314e-01, time/batch = 0.3482s	
267/2700 (epoch 4.944), train_loss = 2.98782468, grad/param norm = 4.9477e-01, time/batch = 0.3316s	
268/2700 (epoch 4.963), train_loss = 3.06474668, grad/param norm = 7.8250e-01, time/batch = 0.3476s	
269/2700 (epoch 4.981), train_loss = 3.09541879, grad/param norm = 8.5336e-01, time/batch = 0.3565s	
270/2700 (epoch 5.000), train_loss = 3.04626876, grad/param norm = 5.5364e-01, time/batch = 0.3527s	
271/2700 (epoch 5.019), train_loss = 2.99074328, grad/param norm = 4.3367e-01, time/batch = 0.3748s	
272/2700 (epoch 5.037), train_loss = 2.99178830, grad/param norm = 2.9617e-01, time/batch = 0.3593s	
273/2700 (epoch 5.056), train_loss = 2.94781771, grad/param norm = 2.6588e-01, time/batch = 0.3490s	
274/2700 (epoch 5.074), train_loss = 2.96679923, grad/param norm = 2.6556e-01, time/batch = 0.3183s	
275/2700 (epoch 5.093), train_loss = 3.00811843, grad/param norm = 2.9415e-01, time/batch = 0.3683s	
276/2700 (epoch 5.111), train_loss = 2.97330945, grad/param norm = 4.3530e-01, time/batch = 0.3752s	
277/2700 (epoch 5.130), train_loss = 3.00159153, grad/param norm = 6.0373e-01, time/batch = 0.3409s	
278/2700 (epoch 5.148), train_loss = 2.99776999, grad/param norm = 7.1843e-01, time/batch = 0.3439s	
279/2700 (epoch 5.167), train_loss = 3.01207688, grad/param norm = 7.4049e-01, time/batch = 0.3494s	
280/2700 (epoch 5.185), train_loss = 2.96125511, grad/param norm = 5.2039e-01, time/batch = 0.3559s	
281/2700 (epoch 5.204), train_loss = 2.89058549, grad/param norm = 3.7223e-01, time/batch = 0.3140s	
282/2700 (epoch 5.222), train_loss = 2.84439047, grad/param norm = 3.7358e-01, time/batch = 0.3450s	
283/2700 (epoch 5.241), train_loss = 2.84169702, grad/param norm = 2.6977e-01, time/batch = 0.3419s	
284/2700 (epoch 5.259), train_loss = 2.86270401, grad/param norm = 3.6284e-01, time/batch = 0.3576s	
285/2700 (epoch 5.278), train_loss = 2.93617800, grad/param norm = 4.1665e-01, time/batch = 0.3762s	
286/2700 (epoch 5.296), train_loss = 2.93944252, grad/param norm = 5.6188e-01, time/batch = 0.3783s	
287/2700 (epoch 5.315), train_loss = 2.99691675, grad/param norm = 6.8477e-01, time/batch = 0.3519s	
288/2700 (epoch 5.333), train_loss = 3.00985297, grad/param norm = 6.1905e-01, time/batch = 0.3460s	
289/2700 (epoch 5.352), train_loss = 3.01484043, grad/param norm = 6.1904e-01, time/batch = 0.3349s	
290/2700 (epoch 5.370), train_loss = 2.97869081, grad/param norm = 7.3374e-01, time/batch = 0.3444s	
291/2700 (epoch 5.389), train_loss = 3.00050184, grad/param norm = 7.1941e-01, time/batch = 0.3535s	
292/2700 (epoch 5.407), train_loss = 2.98822973, grad/param norm = 5.7926e-01, time/batch = 0.3590s	
293/2700 (epoch 5.426), train_loss = 2.95468585, grad/param norm = 3.7643e-01, time/batch = 0.3596s	
294/2700 (epoch 5.444), train_loss = 2.82975929, grad/param norm = 3.1944e-01, time/batch = 0.3657s	
295/2700 (epoch 5.463), train_loss = 2.89298321, grad/param norm = 2.1576e-01, time/batch = 0.3745s	
296/2700 (epoch 5.481), train_loss = 2.94825035, grad/param norm = 2.3675e-01, time/batch = 0.3971s	
297/2700 (epoch 5.500), train_loss = 2.96191371, grad/param norm = 3.2782e-01, time/batch = 0.3498s	
298/2700 (epoch 5.519), train_loss = 2.90678520, grad/param norm = 4.1040e-01, time/batch = 0.3470s	
299/2700 (epoch 5.537), train_loss = 2.88882596, grad/param norm = 4.8717e-01, time/batch = 0.3442s	
300/2700 (epoch 5.556), train_loss = 2.90626331, grad/param norm = 5.1289e-01, time/batch = 0.3488s	
301/2700 (epoch 5.574), train_loss = 2.88157769, grad/param norm = 5.2887e-01, time/batch = 0.3514s	
302/2700 (epoch 5.593), train_loss = 2.86408376, grad/param norm = 5.3285e-01, time/batch = 0.3630s	
303/2700 (epoch 5.611), train_loss = 2.86254751, grad/param norm = 6.4076e-01, time/batch = 0.3330s	
304/2700 (epoch 5.630), train_loss = 2.88616190, grad/param norm = 6.9166e-01, time/batch = 0.3763s	
305/2700 (epoch 5.648), train_loss = 2.89452183, grad/param norm = 5.5642e-01, time/batch = 0.3676s	
306/2700 (epoch 5.667), train_loss = 2.82584542, grad/param norm = 4.7087e-01, time/batch = 0.3464s	
307/2700 (epoch 5.685), train_loss = 2.85775515, grad/param norm = 3.8012e-01, time/batch = 0.3432s	
308/2700 (epoch 5.704), train_loss = 2.81854949, grad/param norm = 3.9293e-01, time/batch = 0.3441s	
309/2700 (epoch 5.722), train_loss = 2.84549408, grad/param norm = 6.2092e-01, time/batch = 0.3486s	
310/2700 (epoch 5.741), train_loss = 3.01765059, grad/param norm = 5.8951e-01, time/batch = 0.3577s	
311/2700 (epoch 5.759), train_loss = 2.94761395, grad/param norm = 5.4963e-01, time/batch = 0.3449s	
312/2700 (epoch 5.778), train_loss = 2.89312512, grad/param norm = 4.2025e-01, time/batch = 0.3230s	
313/2700 (epoch 5.796), train_loss = 2.86120063, grad/param norm = 2.9239e-01, time/batch = 0.3643s	
314/2700 (epoch 5.815), train_loss = 2.81744164, grad/param norm = 2.6059e-01, time/batch = 0.3469s	
315/2700 (epoch 5.833), train_loss = 2.81427538, grad/param norm = 3.5347e-01, time/batch = 0.3509s	
316/2700 (epoch 5.852), train_loss = 2.85179383, grad/param norm = 4.5216e-01, time/batch = 0.3593s	
317/2700 (epoch 5.870), train_loss = 2.82697406, grad/param norm = 6.2318e-01, time/batch = 0.3450s	
318/2700 (epoch 5.889), train_loss = 2.88606451, grad/param norm = 5.9912e-01, time/batch = 0.3470s	
319/2700 (epoch 5.907), train_loss = 2.90547558, grad/param norm = 4.6607e-01, time/batch = 0.3482s	
320/2700 (epoch 5.926), train_loss = 2.85654195, grad/param norm = 4.1604e-01, time/batch = 0.3270s	
321/2700 (epoch 5.944), train_loss = 2.83076001, grad/param norm = 3.9048e-01, time/batch = 0.3207s	
322/2700 (epoch 5.963), train_loss = 2.91104146, grad/param norm = 5.8646e-01, time/batch = 0.3720s	
323/2700 (epoch 5.981), train_loss = 2.93378806, grad/param norm = 7.0978e-01, time/batch = 0.3578s	
324/2700 (epoch 6.000), train_loss = 2.95385873, grad/param norm = 6.9916e-01, time/batch = 0.3552s	
325/2700 (epoch 6.019), train_loss = 2.86454578, grad/param norm = 6.4213e-01, time/batch = 0.3490s	
326/2700 (epoch 6.037), train_loss = 2.90232209, grad/param norm = 5.6375e-01, time/batch = 0.3627s	
327/2700 (epoch 6.056), train_loss = 2.82287746, grad/param norm = 4.2417e-01, time/batch = 0.3430s	
328/2700 (epoch 6.074), train_loss = 2.83439144, grad/param norm = 3.4901e-01, time/batch = 0.3526s	
329/2700 (epoch 6.093), train_loss = 2.86812814, grad/param norm = 2.8028e-01, time/batch = 0.3161s	
330/2700 (epoch 6.111), train_loss = 2.82284534, grad/param norm = 2.3550e-01, time/batch = 0.3745s	
331/2700 (epoch 6.130), train_loss = 2.83375090, grad/param norm = 2.3345e-01, time/batch = 0.3432s	
332/2700 (epoch 6.148), train_loss = 2.79836859, grad/param norm = 2.7580e-01, time/batch = 0.3449s	
333/2700 (epoch 6.167), train_loss = 2.82232947, grad/param norm = 4.7133e-01, time/batch = 0.3482s	
334/2700 (epoch 6.185), train_loss = 2.80048620, grad/param norm = 5.5399e-01, time/batch = 0.3506s	
335/2700 (epoch 6.204), train_loss = 2.79679418, grad/param norm = 7.8043e-01, time/batch = 0.3640s	
336/2700 (epoch 6.222), train_loss = 2.74751061, grad/param norm = 6.3372e-01, time/batch = 0.3575s	
337/2700 (epoch 6.241), train_loss = 2.89049654, grad/param norm = 2.2943e+00, time/batch = 0.3526s	
338/2700 (epoch 6.259), train_loss = 2.95518743, grad/param norm = 9.1664e-01, time/batch = 0.3501s	
339/2700 (epoch 6.278), train_loss = 2.89042772, grad/param norm = 5.5663e-01, time/batch = 0.3555s	
340/2700 (epoch 6.296), train_loss = 2.83527015, grad/param norm = 4.5295e-01, time/batch = 0.3445s	
341/2700 (epoch 6.315), train_loss = 2.86755081, grad/param norm = 4.1618e-01, time/batch = 0.3520s	
342/2700 (epoch 6.333), train_loss = 2.88528967, grad/param norm = 4.1793e-01, time/batch = 0.3527s	
343/2700 (epoch 6.352), train_loss = 2.87293313, grad/param norm = 3.1879e-01, time/batch = 0.3622s	
344/2700 (epoch 6.370), train_loss = 2.80768598, grad/param norm = 2.2097e-01, time/batch = 0.3780s	
345/2700 (epoch 6.389), train_loss = 2.78137995, grad/param norm = 1.7340e-01, time/batch = 0.4015s	
346/2700 (epoch 6.407), train_loss = 2.79164718, grad/param norm = 1.8915e-01, time/batch = 0.3536s	
347/2700 (epoch 6.426), train_loss = 2.78828557, grad/param norm = 1.4932e-01, time/batch = 0.2967s	
348/2700 (epoch 6.444), train_loss = 2.69405872, grad/param norm = 1.9309e-01, time/batch = 0.3210s	
349/2700 (epoch 6.463), train_loss = 2.76915597, grad/param norm = 1.9726e-01, time/batch = 0.3466s	
350/2700 (epoch 6.481), train_loss = 2.82813158, grad/param norm = 2.6782e-01, time/batch = 0.3446s	
351/2700 (epoch 6.500), train_loss = 2.85049863, grad/param norm = 3.7589e-01, time/batch = 0.3434s	
352/2700 (epoch 6.519), train_loss = 2.80991617, grad/param norm = 4.9591e-01, time/batch = 0.3420s	
353/2700 (epoch 6.537), train_loss = 2.79369132, grad/param norm = 6.6172e-01, time/batch = 0.3448s	
354/2700 (epoch 6.556), train_loss = 2.81127252, grad/param norm = 6.5287e-01, time/batch = 0.3491s	
355/2700 (epoch 6.574), train_loss = 2.78095858, grad/param norm = 5.7320e-01, time/batch = 0.3537s	
356/2700 (epoch 6.593), train_loss = 2.74764047, grad/param norm = 4.9735e-01, time/batch = 0.3587s	
357/2700 (epoch 6.611), train_loss = 2.71417701, grad/param norm = 4.5136e-01, time/batch = 0.3304s	
358/2700 (epoch 6.630), train_loss = 2.73987542, grad/param norm = 4.3338e-01, time/batch = 0.3467s	
359/2700 (epoch 6.648), train_loss = 2.75345983, grad/param norm = 3.3300e-01, time/batch = 0.3552s	
360/2700 (epoch 6.667), train_loss = 2.68452216, grad/param norm = 2.6594e-01, time/batch = 0.3710s	
361/2700 (epoch 6.685), train_loss = 2.73074887, grad/param norm = 2.3142e-01, time/batch = 0.3670s	
362/2700 (epoch 6.704), train_loss = 2.69712140, grad/param norm = 2.0396e-01, time/batch = 0.3423s	
363/2700 (epoch 6.722), train_loss = 2.69134956, grad/param norm = 1.4901e-01, time/batch = 0.3450s	
364/2700 (epoch 6.741), train_loss = 2.83522450, grad/param norm = 2.2237e-01, time/batch = 0.3380s	
365/2700 (epoch 6.759), train_loss = 2.77832593, grad/param norm = 2.5303e-01, time/batch = 0.3465s	
366/2700 (epoch 6.778), train_loss = 2.75355306, grad/param norm = 2.8679e-01, time/batch = 0.3276s	
367/2700 (epoch 6.796), train_loss = 2.73776734, grad/param norm = 3.4648e-01, time/batch = 0.3476s	
368/2700 (epoch 6.815), train_loss = 2.72300659, grad/param norm = 4.7129e-01, time/batch = 0.3509s	
369/2700 (epoch 6.833), train_loss = 2.75836105, grad/param norm = 8.4583e-01, time/batch = 0.3543s	
370/2700 (epoch 6.852), train_loss = 2.89571115, grad/param norm = 9.7110e-01, time/batch = 0.3455s	
371/2700 (epoch 6.870), train_loss = 2.91265354, grad/param norm = 9.6733e-01, time/batch = 0.3983s	
372/2700 (epoch 6.889), train_loss = 2.84420391, grad/param norm = 6.8933e-01, time/batch = 0.3364s	
373/2700 (epoch 6.907), train_loss = 2.85877057, grad/param norm = 4.3798e-01, time/batch = 0.3426s	
374/2700 (epoch 6.926), train_loss = 2.80301415, grad/param norm = 5.8398e-01, time/batch = 0.3412s	
375/2700 (epoch 6.944), train_loss = 2.76769429, grad/param norm = 4.8768e-01, time/batch = 0.3163s	
376/2700 (epoch 6.963), train_loss = 2.81417266, grad/param norm = 4.0726e-01, time/batch = 0.3482s	
377/2700 (epoch 6.981), train_loss = 2.76829468, grad/param norm = 3.7788e-01, time/batch = 0.3473s	
378/2700 (epoch 7.000), train_loss = 2.77818522, grad/param norm = 2.9038e-01, time/batch = 0.3592s	
379/2700 (epoch 7.019), train_loss = 2.72241580, grad/param norm = 3.0183e-01, time/batch = 0.3491s	
380/2700 (epoch 7.037), train_loss = 2.78041966, grad/param norm = 3.2517e-01, time/batch = 0.3435s	
381/2700 (epoch 7.056), train_loss = 2.73009490, grad/param norm = 3.2899e-01, time/batch = 0.3556s	
382/2700 (epoch 7.074), train_loss = 2.73557556, grad/param norm = 2.9481e-01, time/batch = 0.3716s	
383/2700 (epoch 7.093), train_loss = 2.77678153, grad/param norm = 2.7105e-01, time/batch = 0.3437s	
384/2700 (epoch 7.111), train_loss = 2.73839815, grad/param norm = 2.6176e-01, time/batch = 0.3090s	
385/2700 (epoch 7.130), train_loss = 2.75225523, grad/param norm = 2.1592e-01, time/batch = 0.3495s	
386/2700 (epoch 7.148), train_loss = 2.72001999, grad/param norm = 2.7581e-01, time/batch = 0.3463s	
387/2700 (epoch 7.167), train_loss = 2.74975654, grad/param norm = 3.6757e-01, time/batch = 0.3513s	
388/2700 (epoch 7.185), train_loss = 2.70529399, grad/param norm = 4.2549e-01, time/batch = 0.3551s	
389/2700 (epoch 7.204), train_loss = 2.69306409, grad/param norm = 6.1279e-01, time/batch = 0.3475s	
390/2700 (epoch 7.222), train_loss = 2.67771111, grad/param norm = 7.4835e-01, time/batch = 0.3408s	
391/2700 (epoch 7.241), train_loss = 2.67933184, grad/param norm = 5.9424e-01, time/batch = 0.3873s	
392/2700 (epoch 7.259), train_loss = 2.67360933, grad/param norm = 4.3270e-01, time/batch = 0.3445s	
393/2700 (epoch 7.278), train_loss = 2.72096307, grad/param norm = 2.5866e-01, time/batch = 0.3057s	
394/2700 (epoch 7.296), train_loss = 2.69939607, grad/param norm = 1.8263e-01, time/batch = 0.3580s	
395/2700 (epoch 7.315), train_loss = 2.73151680, grad/param norm = 1.4366e-01, time/batch = 0.3460s	
396/2700 (epoch 7.333), train_loss = 2.74478671, grad/param norm = 1.7842e-01, time/batch = 0.3496s	
397/2700 (epoch 7.352), train_loss = 2.77016649, grad/param norm = 3.0894e-01, time/batch = 0.3616s	
398/2700 (epoch 7.370), train_loss = 2.73446270, grad/param norm = 3.0459e-01, time/batch = 0.3589s	
399/2700 (epoch 7.389), train_loss = 2.70408013, grad/param norm = 3.7820e-01, time/batch = 0.3461s	
400/2700 (epoch 7.407), train_loss = 2.73759479, grad/param norm = 4.9406e-01, time/batch = 0.3483s	
401/2700 (epoch 7.426), train_loss = 2.75445782, grad/param norm = 4.8245e-01, time/batch = 0.3602s	
402/2700 (epoch 7.444), train_loss = 2.63190268, grad/param norm = 3.8494e-01, time/batch = 0.3089s	
403/2700 (epoch 7.463), train_loss = 2.70939847, grad/param norm = 3.3357e-01, time/batch = 0.3629s	
404/2700 (epoch 7.481), train_loss = 2.76154689, grad/param norm = 3.7729e-01, time/batch = 0.3569s	
405/2700 (epoch 7.500), train_loss = 2.78262834, grad/param norm = 3.6769e-01, time/batch = 0.3579s	
406/2700 (epoch 7.519), train_loss = 2.76759962, grad/param norm = 4.3852e-01, time/batch = 0.3274s	
407/2700 (epoch 7.537), train_loss = 2.76877140, grad/param norm = 5.5418e-01, time/batch = 0.3594s	
408/2700 (epoch 7.556), train_loss = 2.76750507, grad/param norm = 5.7633e-01, time/batch = 0.3454s	
409/2700 (epoch 7.574), train_loss = 2.74134922, grad/param norm = 6.4107e-01, time/batch = 0.3479s	
410/2700 (epoch 7.593), train_loss = 2.73830224, grad/param norm = 8.4392e-01, time/batch = 0.3518s	
411/2700 (epoch 7.611), train_loss = 2.77072816, grad/param norm = 9.5846e-01, time/batch = 0.3235s	
412/2700 (epoch 7.630), train_loss = 2.75130074, grad/param norm = 6.7419e-01, time/batch = 0.3652s	
413/2700 (epoch 7.648), train_loss = 2.69869617, grad/param norm = 3.0854e-01, time/batch = 0.3690s	
414/2700 (epoch 7.667), train_loss = 2.61666956, grad/param norm = 1.7629e-01, time/batch = 0.3485s	
415/2700 (epoch 7.685), train_loss = 2.66738873, grad/param norm = 1.5808e-01, time/batch = 0.3429s	
416/2700 (epoch 7.704), train_loss = 2.64058421, grad/param norm = 1.6549e-01, time/batch = 0.3454s	
417/2700 (epoch 7.722), train_loss = 2.63493065, grad/param norm = 1.2109e-01, time/batch = 0.3509s	
418/2700 (epoch 7.741), train_loss = 2.76544665, grad/param norm = 1.4731e-01, time/batch = 0.3598s	
419/2700 (epoch 7.759), train_loss = 2.71562025, grad/param norm = 1.6170e-01, time/batch = 0.3549s	
420/2700 (epoch 7.778), train_loss = 2.69733287, grad/param norm = 2.4236e-01, time/batch = 0.3651s	
421/2700 (epoch 7.796), train_loss = 2.67640627, grad/param norm = 3.0368e-01, time/batch = 0.3605s	
422/2700 (epoch 7.815), train_loss = 2.66275144, grad/param norm = 3.3956e-01, time/batch = 0.3810s	
423/2700 (epoch 7.833), train_loss = 2.66334393, grad/param norm = 4.3273e-01, time/batch = 0.3507s	
424/2700 (epoch 7.852), train_loss = 2.70724207, grad/param norm = 5.2821e-01, time/batch = 0.3436s	
425/2700 (epoch 7.870), train_loss = 2.67456964, grad/param norm = 5.1624e-01, time/batch = 0.3458s	
426/2700 (epoch 7.889), train_loss = 2.70631988, grad/param norm = 4.5802e-01, time/batch = 0.3499s	
427/2700 (epoch 7.907), train_loss = 2.77257555, grad/param norm = 4.3788e-01, time/batch = 0.3621s	
428/2700 (epoch 7.926), train_loss = 2.71214808, grad/param norm = 3.8194e-01, time/batch = 0.3750s	
429/2700 (epoch 7.944), train_loss = 2.67536130, grad/param norm = 2.4527e-01, time/batch = 0.3547s	
430/2700 (epoch 7.963), train_loss = 2.73535995, grad/param norm = 2.1021e-01, time/batch = 0.3753s	
431/2700 (epoch 7.981), train_loss = 2.68970739, grad/param norm = 2.3550e-01, time/batch = 0.3578s	
432/2700 (epoch 8.000), train_loss = 2.70837743, grad/param norm = 2.2358e-01, time/batch = 0.3446s	
433/2700 (epoch 8.019), train_loss = 2.66977173, grad/param norm = 3.5436e-01, time/batch = 0.3554s	
434/2700 (epoch 8.037), train_loss = 2.74251156, grad/param norm = 5.2906e-01, time/batch = 0.3594s	
435/2700 (epoch 8.056), train_loss = 2.73555058, grad/param norm = 7.0356e-01, time/batch = 0.3591s	
436/2700 (epoch 8.074), train_loss = 2.75619539, grad/param norm = 6.8625e-01, time/batch = 0.3757s	
437/2700 (epoch 8.093), train_loss = 2.77656995, grad/param norm = 5.1051e-01, time/batch = 0.3766s	
438/2700 (epoch 8.111), train_loss = 2.70223207, grad/param norm = 2.8393e-01, time/batch = 0.3631s	
439/2700 (epoch 8.130), train_loss = 2.69027139, grad/param norm = 1.5670e-01, time/batch = 0.3792s	
440/2700 (epoch 8.148), train_loss = 2.65499776, grad/param norm = 1.9771e-01, time/batch = 0.3711s	
441/2700 (epoch 8.167), train_loss = 2.69247231, grad/param norm = 2.8616e-01, time/batch = 0.3488s	
442/2700 (epoch 8.185), train_loss = 2.64526124, grad/param norm = 3.1729e-01, time/batch = 0.3543s	
443/2700 (epoch 8.204), train_loss = 2.62995043, grad/param norm = 5.0094e-01, time/batch = 0.3606s	
444/2700 (epoch 8.222), train_loss = 2.62319967, grad/param norm = 7.0661e-01, time/batch = 0.3728s	
445/2700 (epoch 8.241), train_loss = 2.63748417, grad/param norm = 5.9006e-01, time/batch = 0.3788s	
446/2700 (epoch 8.259), train_loss = 2.64883020, grad/param norm = 5.2309e-01, time/batch = 0.3796s	
447/2700 (epoch 8.278), train_loss = 2.70305699, grad/param norm = 4.2092e-01, time/batch = 0.3160s	
448/2700 (epoch 8.296), train_loss = 2.66835215, grad/param norm = 2.8100e-01, time/batch = 0.3622s	
449/2700 (epoch 8.315), train_loss = 2.68528210, grad/param norm = 1.9588e-01, time/batch = 0.3487s	
450/2700 (epoch 8.333), train_loss = 2.68875741, grad/param norm = 1.8333e-01, time/batch = 0.3436s	
451/2700 (epoch 8.352), train_loss = 2.70526072, grad/param norm = 2.0895e-01, time/batch = 0.3608s	
452/2700 (epoch 8.370), train_loss = 2.66477632, grad/param norm = 1.9563e-01, time/batch = 0.3611s	
453/2700 (epoch 8.389), train_loss = 2.63282346, grad/param norm = 1.9688e-01, time/batch = 0.3542s	
454/2700 (epoch 8.407), train_loss = 2.65747166, grad/param norm = 2.8289e-01, time/batch = 0.3433s	
455/2700 (epoch 8.426), train_loss = 2.67383255, grad/param norm = 3.1306e-01, time/batch = 0.3389s	
456/2700 (epoch 8.444), train_loss = 2.57190957, grad/param norm = 3.1441e-01, time/batch = 0.2923s	
457/2700 (epoch 8.463), train_loss = 2.65214603, grad/param norm = 3.4505e-01, time/batch = 0.3524s	
458/2700 (epoch 8.481), train_loss = 2.69410798, grad/param norm = 4.2520e-01, time/batch = 0.3492s	
459/2700 (epoch 8.500), train_loss = 2.71821354, grad/param norm = 4.1978e-01, time/batch = 0.3455s	
460/2700 (epoch 8.519), train_loss = 2.68128029, grad/param norm = 3.8468e-01, time/batch = 0.3560s	
461/2700 (epoch 8.537), train_loss = 2.65354188, grad/param norm = 4.8063e-01, time/batch = 0.3510s	
462/2700 (epoch 8.556), train_loss = 2.68818262, grad/param norm = 5.6839e-01, time/batch = 0.3481s	
463/2700 (epoch 8.574), train_loss = 2.68650316, grad/param norm = 7.0584e-01, time/batch = 0.3568s	
464/2700 (epoch 8.593), train_loss = 2.74904559, grad/param norm = 9.2042e-01, time/batch = 0.3401s	
465/2700 (epoch 8.611), train_loss = 2.74471419, grad/param norm = 9.0659e-01, time/batch = 0.3320s	
466/2700 (epoch 8.630), train_loss = 2.72789195, grad/param norm = 5.9832e-01, time/batch = 0.3724s	
467/2700 (epoch 8.648), train_loss = 2.67999791, grad/param norm = 5.2193e-01, time/batch = 0.3775s	
468/2700 (epoch 8.667), train_loss = 2.59472660, grad/param norm = 3.6951e-01, time/batch = 0.3734s	
469/2700 (epoch 8.685), train_loss = 2.61931625, grad/param norm = 2.5732e-01, time/batch = 0.3495s	
470/2700 (epoch 8.704), train_loss = 2.59981392, grad/param norm = 1.6137e-01, time/batch = 0.3423s	
471/2700 (epoch 8.722), train_loss = 2.59063825, grad/param norm = 1.2393e-01, time/batch = 0.3719s	
472/2700 (epoch 8.741), train_loss = 2.71214972, grad/param norm = 1.4403e-01, time/batch = 0.3573s	
473/2700 (epoch 8.759), train_loss = 2.66433547, grad/param norm = 1.5711e-01, time/batch = 0.3342s	
474/2700 (epoch 8.778), train_loss = 2.64683772, grad/param norm = 1.8953e-01, time/batch = 0.3360s	
475/2700 (epoch 8.796), train_loss = 2.62002608, grad/param norm = 1.9472e-01, time/batch = 0.3670s	
476/2700 (epoch 8.815), train_loss = 2.60779059, grad/param norm = 1.5851e-01, time/batch = 0.3834s	
477/2700 (epoch 8.833), train_loss = 2.59267989, grad/param norm = 1.8962e-01, time/batch = 0.3583s	
478/2700 (epoch 8.852), train_loss = 2.62363887, grad/param norm = 2.5723e-01, time/batch = 0.3490s	
479/2700 (epoch 8.870), train_loss = 2.60177800, grad/param norm = 3.7667e-01, time/batch = 0.3514s	
480/2700 (epoch 8.889), train_loss = 2.64244445, grad/param norm = 5.2650e-01, time/batch = 0.3635s	
481/2700 (epoch 8.907), train_loss = 2.76389041, grad/param norm = 6.5746e-01, time/batch = 0.3650s	
482/2700 (epoch 8.926), train_loss = 2.70725637, grad/param norm = 5.5744e-01, time/batch = 0.3127s	
483/2700 (epoch 8.944), train_loss = 2.64140931, grad/param norm = 3.0552e-01, time/batch = 0.3132s	
484/2700 (epoch 8.963), train_loss = 2.68790004, grad/param norm = 2.3661e-01, time/batch = 0.3641s	
485/2700 (epoch 8.981), train_loss = 2.63147272, grad/param norm = 2.4376e-01, time/batch = 0.3462s	
486/2700 (epoch 9.000), train_loss = 2.66133652, grad/param norm = 2.2295e-01, time/batch = 0.3420s	
487/2700 (epoch 9.019), train_loss = 2.62706282, grad/param norm = 2.9614e-01, time/batch = 0.3465s	
488/2700 (epoch 9.037), train_loss = 2.68175659, grad/param norm = 3.9039e-01, time/batch = 0.3531s	
489/2700 (epoch 9.056), train_loss = 2.64834425, grad/param norm = 4.8032e-01, time/batch = 0.3535s	
490/2700 (epoch 9.074), train_loss = 2.64734964, grad/param norm = 4.6638e-01, time/batch = 0.3472s	
491/2700 (epoch 9.093), train_loss = 2.68582566, grad/param norm = 4.0648e-01, time/batch = 0.3422s	
492/2700 (epoch 9.111), train_loss = 2.64096380, grad/param norm = 3.3062e-01, time/batch = 0.3504s	
493/2700 (epoch 9.130), train_loss = 2.64481955, grad/param norm = 2.7238e-01, time/batch = 0.3707s	
494/2700 (epoch 9.148), train_loss = 2.61624401, grad/param norm = 3.2735e-01, time/batch = 0.3494s	
495/2700 (epoch 9.167), train_loss = 2.65828757, grad/param norm = 3.6424e-01, time/batch = 0.3473s	
496/2700 (epoch 9.185), train_loss = 2.60510181, grad/param norm = 3.3415e-01, time/batch = 0.3505s	
497/2700 (epoch 9.204), train_loss = 2.58310902, grad/param norm = 3.5538e-01, time/batch = 0.3580s	
498/2700 (epoch 9.222), train_loss = 2.54087785, grad/param norm = 3.4698e-01, time/batch = 0.3659s	
499/2700 (epoch 9.241), train_loss = 2.54118016, grad/param norm = 3.0701e-01, time/batch = 0.3796s	
500/2700 (epoch 9.259), train_loss = 2.54889998, grad/param norm = 2.8299e-01, time/batch = 0.3472s	
501/2700 (epoch 9.278), train_loss = 2.60714831, grad/param norm = 2.2059e-01, time/batch = 0.3372s	
502/2700 (epoch 9.296), train_loss = 2.58453914, grad/param norm = 2.2118e-01, time/batch = 0.3840s	
503/2700 (epoch 9.315), train_loss = 2.62389569, grad/param norm = 2.6513e-01, time/batch = 0.3526s	
504/2700 (epoch 9.333), train_loss = 2.65398097, grad/param norm = 4.2525e-01, time/batch = 0.3581s	
505/2700 (epoch 9.352), train_loss = 2.69599692, grad/param norm = 5.8692e-01, time/batch = 0.3598s	
506/2700 (epoch 9.370), train_loss = 2.69710286, grad/param norm = 6.7931e-01, time/batch = 0.3734s	
507/2700 (epoch 9.389), train_loss = 2.67764683, grad/param norm = 6.7907e-01, time/batch = 0.3837s	
508/2700 (epoch 9.407), train_loss = 2.67433369, grad/param norm = 5.2759e-01, time/batch = 0.3653s	
509/2700 (epoch 9.426), train_loss = 2.65038858, grad/param norm = 3.7670e-01, time/batch = 0.3298s	
510/2700 (epoch 9.444), train_loss = 2.55323520, grad/param norm = 3.3368e-01, time/batch = 0.3328s	
511/2700 (epoch 9.463), train_loss = 2.63196111, grad/param norm = 4.0444e-01, time/batch = 0.3486s	
512/2700 (epoch 9.481), train_loss = 2.70452430, grad/param norm = 5.3698e-01, time/batch = 0.3504s	
513/2700 (epoch 9.500), train_loss = 2.76440328, grad/param norm = 6.7682e-01, time/batch = 0.3595s	
514/2700 (epoch 9.519), train_loss = 2.69801182, grad/param norm = 5.2951e-01, time/batch = 0.3575s	
515/2700 (epoch 9.537), train_loss = 2.61336677, grad/param norm = 2.4157e-01, time/batch = 0.3574s	
516/2700 (epoch 9.556), train_loss = 2.58866221, grad/param norm = 2.0418e-01, time/batch = 0.3801s	
517/2700 (epoch 9.574), train_loss = 2.57265973, grad/param norm = 3.3974e-01, time/batch = 0.3836s	
518/2700 (epoch 9.593), train_loss = 2.57628878, grad/param norm = 4.6708e-01, time/batch = 0.3575s	
519/2700 (epoch 9.611), train_loss = 2.55821177, grad/param norm = 5.2711e-01, time/batch = 0.3153s	
520/2700 (epoch 9.630), train_loss = 2.58497502, grad/param norm = 4.6330e-01, time/batch = 0.3713s	
521/2700 (epoch 9.648), train_loss = 2.59618423, grad/param norm = 3.0692e-01, time/batch = 0.3696s	
522/2700 (epoch 9.667), train_loss = 2.51755361, grad/param norm = 1.9726e-01, time/batch = 0.3560s	
523/2700 (epoch 9.685), train_loss = 2.56135642, grad/param norm = 1.8886e-01, time/batch = 0.3545s	
524/2700 (epoch 9.704), train_loss = 2.56181748, grad/param norm = 1.7902e-01, time/batch = 0.3673s	
525/2700 (epoch 9.722), train_loss = 2.54560210, grad/param norm = 1.3847e-01, time/batch = 0.3781s	
526/2700 (epoch 9.741), train_loss = 2.66165637, grad/param norm = 1.4103e-01, time/batch = 0.3618s	
527/2700 (epoch 9.759), train_loss = 2.62603302, grad/param norm = 1.8279e-01, time/batch = 0.2944s	
528/2700 (epoch 9.778), train_loss = 2.60879107, grad/param norm = 2.3961e-01, time/batch = 0.3755s	
529/2700 (epoch 9.796), train_loss = 2.58574910, grad/param norm = 2.6316e-01, time/batch = 0.3515s	
530/2700 (epoch 9.815), train_loss = 2.56900671, grad/param norm = 2.1313e-01, time/batch = 0.3538s	
531/2700 (epoch 9.833), train_loss = 2.55337286, grad/param norm = 3.3378e-01, time/batch = 0.3844s	
532/2700 (epoch 9.852), train_loss = 2.60229261, grad/param norm = 4.9156e-01, time/batch = 0.3509s	
533/2700 (epoch 9.870), train_loss = 2.61102863, grad/param norm = 6.1330e-01, time/batch = 0.3484s	
534/2700 (epoch 9.889), train_loss = 2.64589185, grad/param norm = 5.9296e-01, time/batch = 0.3452s	
535/2700 (epoch 9.907), train_loss = 2.69485098, grad/param norm = 5.0190e-01, time/batch = 0.3480s	
536/2700 (epoch 9.926), train_loss = 2.63497383, grad/param norm = 4.1639e-01, time/batch = 0.3121s	
537/2700 (epoch 9.944), train_loss = 2.59219237, grad/param norm = 2.6689e-01, time/batch = 0.3439s	
538/2700 (epoch 9.963), train_loss = 2.64722371, grad/param norm = 2.5561e-01, time/batch = 0.3440s	
539/2700 (epoch 9.981), train_loss = 2.58809835, grad/param norm = 2.8040e-01, time/batch = 0.3590s	
decayed learning rate by a factor 0.97 to 0.00194	
540/2700 (epoch 10.000), train_loss = 2.61595075, grad/param norm = 2.7606e-01, time/batch = 0.3271s	
541/2700 (epoch 10.019), train_loss = 2.60196216, grad/param norm = 3.7117e-01, time/batch = 0.3823s	
542/2700 (epoch 10.037), train_loss = 2.68780450, grad/param norm = 6.5820e-01, time/batch = 0.3555s	
543/2700 (epoch 10.056), train_loss = 2.76827799, grad/param norm = 9.2979e-01, time/batch = 0.3426s	
544/2700 (epoch 10.074), train_loss = 2.79072643, grad/param norm = 7.3498e-01, time/batch = 0.3518s	
545/2700 (epoch 10.093), train_loss = 2.67244043, grad/param norm = 3.6580e-01, time/batch = 0.3555s	
546/2700 (epoch 10.111), train_loss = 2.58479427, grad/param norm = 1.7699e-01, time/batch = 0.3549s	
547/2700 (epoch 10.130), train_loss = 2.59419220, grad/param norm = 1.9312e-01, time/batch = 0.3561s	
548/2700 (epoch 10.148), train_loss = 2.55935964, grad/param norm = 1.7351e-01, time/batch = 0.3718s	
549/2700 (epoch 10.167), train_loss = 2.59557086, grad/param norm = 1.6983e-01, time/batch = 0.3768s	
550/2700 (epoch 10.185), train_loss = 2.53456385, grad/param norm = 1.4363e-01, time/batch = 0.3762s	
551/2700 (epoch 10.204), train_loss = 2.50890101, grad/param norm = 1.4917e-01, time/batch = 0.3570s	
552/2700 (epoch 10.222), train_loss = 2.48168153, grad/param norm = 1.6838e-01, time/batch = 0.3461s	
553/2700 (epoch 10.241), train_loss = 2.48819447, grad/param norm = 1.6337e-01, time/batch = 0.3501s	
554/2700 (epoch 10.259), train_loss = 2.49174486, grad/param norm = 2.6376e-01, time/batch = 0.3173s	
555/2700 (epoch 10.278), train_loss = 2.56641285, grad/param norm = 3.7605e-01, time/batch = 0.3459s	
556/2700 (epoch 10.296), train_loss = 2.56998771, grad/param norm = 5.6547e-01, time/batch = 0.3491s	
557/2700 (epoch 10.315), train_loss = 2.65993716, grad/param norm = 7.1497e-01, time/batch = 0.3277s	
558/2700 (epoch 10.333), train_loss = 2.67938604, grad/param norm = 5.5205e-01, time/batch = 0.3571s	
559/2700 (epoch 10.352), train_loss = 2.62700635, grad/param norm = 3.3112e-01, time/batch = 0.3811s	
560/2700 (epoch 10.370), train_loss = 2.57157503, grad/param norm = 1.9684e-01, time/batch = 0.3547s	
561/2700 (epoch 10.389), train_loss = 2.53935740, grad/param norm = 1.3838e-01, time/batch = 0.3678s	
562/2700 (epoch 10.407), train_loss = 2.56109863, grad/param norm = 1.5415e-01, time/batch = 0.3430s	
563/2700 (epoch 10.426), train_loss = 2.56888131, grad/param norm = 1.7009e-01, time/batch = 0.3110s	
564/2700 (epoch 10.444), train_loss = 2.48997814, grad/param norm = 2.6219e-01, time/batch = 0.3739s	
565/2700 (epoch 10.463), train_loss = 2.56240240, grad/param norm = 4.0404e-01, time/batch = 0.3497s	
566/2700 (epoch 10.481), train_loss = 2.61066369, grad/param norm = 5.2832e-01, time/batch = 0.3546s	
567/2700 (epoch 10.500), train_loss = 2.66122253, grad/param norm = 5.4211e-01, time/batch = 0.3573s	
568/2700 (epoch 10.519), train_loss = 2.61122616, grad/param norm = 4.6123e-01, time/batch = 0.3788s	
569/2700 (epoch 10.537), train_loss = 2.55762059, grad/param norm = 3.2626e-01, time/batch = 0.3788s	
570/2700 (epoch 10.556), train_loss = 2.54826399, grad/param norm = 2.1526e-01, time/batch = 0.3580s	
571/2700 (epoch 10.574), train_loss = 2.52086637, grad/param norm = 2.3982e-01, time/batch = 0.3536s	
572/2700 (epoch 10.593), train_loss = 2.51467828, grad/param norm = 2.6084e-01, time/batch = 0.2947s	
573/2700 (epoch 10.611), train_loss = 2.49260422, grad/param norm = 3.3657e-01, time/batch = 0.3349s	
574/2700 (epoch 10.630), train_loss = 2.52537183, grad/param norm = 3.8245e-01, time/batch = 0.3409s	
575/2700 (epoch 10.648), train_loss = 2.55406982, grad/param norm = 3.6808e-01, time/batch = 0.3424s	
576/2700 (epoch 10.667), train_loss = 2.48282326, grad/param norm = 3.3624e-01, time/batch = 0.3479s	
577/2700 (epoch 10.685), train_loss = 2.52513397, grad/param norm = 3.2318e-01, time/batch = 0.3519s	
578/2700 (epoch 10.704), train_loss = 2.53072557, grad/param norm = 3.2709e-01, time/batch = 0.3661s	
579/2700 (epoch 10.722), train_loss = 2.52245761, grad/param norm = 3.7994e-01, time/batch = 0.3741s	
580/2700 (epoch 10.741), train_loss = 2.65245576, grad/param norm = 4.9930e-01, time/batch = 0.3579s	
581/2700 (epoch 10.759), train_loss = 2.64651975, grad/param norm = 5.1266e-01, time/batch = 0.3212s	
582/2700 (epoch 10.778), train_loss = 2.62072881, grad/param norm = 4.5238e-01, time/batch = 0.3335s	
583/2700 (epoch 10.796), train_loss = 2.58744951, grad/param norm = 5.3917e-01, time/batch = 0.3474s	
584/2700 (epoch 10.815), train_loss = 2.60053644, grad/param norm = 5.6631e-01, time/batch = 0.3428s	
585/2700 (epoch 10.833), train_loss = 2.55414211, grad/param norm = 4.3837e-01, time/batch = 0.3452s	
586/2700 (epoch 10.852), train_loss = 2.56356683, grad/param norm = 3.2259e-01, time/batch = 0.3587s	
587/2700 (epoch 10.870), train_loss = 2.51429276, grad/param norm = 2.9356e-01, time/batch = 0.3556s	
588/2700 (epoch 10.889), train_loss = 2.51752234, grad/param norm = 3.2088e-01, time/batch = 0.3820s	
589/2700 (epoch 10.907), train_loss = 2.62416512, grad/param norm = 3.7795e-01, time/batch = 0.3806s	
590/2700 (epoch 10.926), train_loss = 2.59426441, grad/param norm = 4.9827e-01, time/batch = 0.3640s	
591/2700 (epoch 10.944), train_loss = 2.60263145, grad/param norm = 6.1622e-01, time/batch = 0.3388s	
592/2700 (epoch 10.963), train_loss = 2.66756218, grad/param norm = 5.4373e-01, time/batch = 0.3444s	
593/2700 (epoch 10.981), train_loss = 2.57168460, grad/param norm = 3.0182e-01, time/batch = 0.3507s	
decayed learning rate by a factor 0.97 to 0.0018818	
594/2700 (epoch 11.000), train_loss = 2.57496027, grad/param norm = 1.6233e-01, time/batch = 0.3538s	
595/2700 (epoch 11.019), train_loss = 2.54908861, grad/param norm = 1.7855e-01, time/batch = 0.3633s	
596/2700 (epoch 11.037), train_loss = 2.58361787, grad/param norm = 1.5478e-01, time/batch = 0.3733s	
597/2700 (epoch 11.056), train_loss = 2.53592053, grad/param norm = 1.7003e-01, time/batch = 0.3620s	
598/2700 (epoch 11.074), train_loss = 2.51108156, grad/param norm = 1.5279e-01, time/batch = 0.3726s	
599/2700 (epoch 11.093), train_loss = 2.56492189, grad/param norm = 1.3387e-01, time/batch = 0.3551s	
600/2700 (epoch 11.111), train_loss = 2.52885362, grad/param norm = 1.5713e-01, time/batch = 0.3260s	
601/2700 (epoch 11.130), train_loss = 2.54632718, grad/param norm = 1.9944e-01, time/batch = 0.3514s	
602/2700 (epoch 11.148), train_loss = 2.51589097, grad/param norm = 2.4577e-01, time/batch = 0.3571s	
603/2700 (epoch 11.167), train_loss = 2.56494176, grad/param norm = 2.4247e-01, time/batch = 0.3611s	
604/2700 (epoch 11.185), train_loss = 2.49777934, grad/param norm = 2.3918e-01, time/batch = 0.3739s	
605/2700 (epoch 11.204), train_loss = 2.47721397, grad/param norm = 3.2790e-01, time/batch = 0.3767s	
606/2700 (epoch 11.222), train_loss = 2.46525546, grad/param norm = 4.1386e-01, time/batch = 0.3931s	
607/2700 (epoch 11.241), train_loss = 2.49461489, grad/param norm = 5.1178e-01, time/batch = 0.3569s	
608/2700 (epoch 11.259), train_loss = 2.51360971, grad/param norm = 6.6382e-01, time/batch = 0.2863s	
609/2700 (epoch 11.278), train_loss = 2.59830731, grad/param norm = 6.1050e-01, time/batch = 0.3218s	
610/2700 (epoch 11.296), train_loss = 2.56744732, grad/param norm = 5.4259e-01, time/batch = 0.3699s	
611/2700 (epoch 11.315), train_loss = 2.58848361, grad/param norm = 5.5172e-01, time/batch = 0.3638s	
612/2700 (epoch 11.333), train_loss = 2.58130159, grad/param norm = 4.1355e-01, time/batch = 0.3586s	
613/2700 (epoch 11.352), train_loss = 2.58692628, grad/param norm = 2.9482e-01, time/batch = 0.3682s	
614/2700 (epoch 11.370), train_loss = 2.54509787, grad/param norm = 2.2892e-01, time/batch = 0.3722s	
615/2700 (epoch 11.389), train_loss = 2.50946487, grad/param norm = 1.5669e-01, time/batch = 0.3577s	
616/2700 (epoch 11.407), train_loss = 2.52489742, grad/param norm = 1.6555e-01, time/batch = 0.3471s	
617/2700 (epoch 11.426), train_loss = 2.52896466, grad/param norm = 1.7617e-01, time/batch = 0.3103s	
618/2700 (epoch 11.444), train_loss = 2.45185339, grad/param norm = 2.1284e-01, time/batch = 0.3403s	
619/2700 (epoch 11.463), train_loss = 2.51924066, grad/param norm = 2.9522e-01, time/batch = 0.3499s	
620/2700 (epoch 11.481), train_loss = 2.56455613, grad/param norm = 4.2572e-01, time/batch = 0.3531s	
621/2700 (epoch 11.500), train_loss = 2.63763914, grad/param norm = 5.6189e-01, time/batch = 0.3815s	
622/2700 (epoch 11.519), train_loss = 2.60930245, grad/param norm = 6.5132e-01, time/batch = 0.3873s	
623/2700 (epoch 11.537), train_loss = 2.59801951, grad/param norm = 6.0320e-01, time/batch = 0.3492s	
624/2700 (epoch 11.556), train_loss = 2.53677667, grad/param norm = 3.0238e-01, time/batch = 0.3515s	
625/2700 (epoch 11.574), train_loss = 2.48769465, grad/param norm = 2.0232e-01, time/batch = 0.3475s	
626/2700 (epoch 11.593), train_loss = 2.47522628, grad/param norm = 1.9021e-01, time/batch = 0.3483s	
627/2700 (epoch 11.611), train_loss = 2.44277681, grad/param norm = 2.1275e-01, time/batch = 0.3500s	
628/2700 (epoch 11.630), train_loss = 2.46442925, grad/param norm = 2.3585e-01, time/batch = 0.3697s	
629/2700 (epoch 11.648), train_loss = 2.50266464, grad/param norm = 2.7717e-01, time/batch = 0.3803s	
630/2700 (epoch 11.667), train_loss = 2.44428536, grad/param norm = 3.2667e-01, time/batch = 0.3630s	
631/2700 (epoch 11.685), train_loss = 2.49103133, grad/param norm = 3.4845e-01, time/batch = 0.3635s	
632/2700 (epoch 11.704), train_loss = 2.49800602, grad/param norm = 3.4759e-01, time/batch = 0.3475s	
633/2700 (epoch 11.722), train_loss = 2.47852220, grad/param norm = 3.6584e-01, time/batch = 0.3504s	
634/2700 (epoch 11.741), train_loss = 2.58787184, grad/param norm = 3.9826e-01, time/batch = 0.3358s	
635/2700 (epoch 11.759), train_loss = 2.56589388, grad/param norm = 4.3819e-01, time/batch = 0.3439s	
636/2700 (epoch 11.778), train_loss = 2.55573975, grad/param norm = 4.2354e-01, time/batch = 0.3596s	
637/2700 (epoch 11.796), train_loss = 2.51060147, grad/param norm = 4.2747e-01, time/batch = 0.3736s	
638/2700 (epoch 11.815), train_loss = 2.52185688, grad/param norm = 4.4147e-01, time/batch = 0.3677s	
639/2700 (epoch 11.833), train_loss = 2.49737496, grad/param norm = 4.8172e-01, time/batch = 0.3734s	
640/2700 (epoch 11.852), train_loss = 2.54486152, grad/param norm = 5.0104e-01, time/batch = 0.3817s	
641/2700 (epoch 11.870), train_loss = 2.50041397, grad/param norm = 4.6620e-01, time/batch = 0.3627s	
642/2700 (epoch 11.889), train_loss = 2.48278291, grad/param norm = 3.7190e-01, time/batch = 0.3719s	
643/2700 (epoch 11.907), train_loss = 2.58326523, grad/param norm = 2.8196e-01, time/batch = 0.3723s	
644/2700 (epoch 11.926), train_loss = 2.52904271, grad/param norm = 2.8524e-01, time/batch = 0.3653s	
645/2700 (epoch 11.944), train_loss = 2.52044931, grad/param norm = 3.7551e-01, time/batch = 0.3597s	
646/2700 (epoch 11.963), train_loss = 2.57400738, grad/param norm = 2.0245e-01, time/batch = 0.3705s	
647/2700 (epoch 11.981), train_loss = 2.50287951, grad/param norm = 2.2479e-01, time/batch = 0.3680s	
decayed learning rate by a factor 0.97 to 0.001825346	
648/2700 (epoch 12.000), train_loss = 2.53119153, grad/param norm = 1.8012e-01, time/batch = 0.3540s	
649/2700 (epoch 12.019), train_loss = 2.52708978, grad/param norm = 2.7107e-01, time/batch = 0.3495s	
650/2700 (epoch 12.037), train_loss = 2.55808338, grad/param norm = 3.3219e-01, time/batch = 0.3564s	
651/2700 (epoch 12.056), train_loss = 2.51428521, grad/param norm = 3.3044e-01, time/batch = 0.3506s	
652/2700 (epoch 12.074), train_loss = 2.47925622, grad/param norm = 3.7248e-01, time/batch = 0.3133s	
653/2700 (epoch 12.093), train_loss = 2.55681495, grad/param norm = 4.9711e-01, time/batch = 0.3161s	
654/2700 (epoch 12.111), train_loss = 2.55094995, grad/param norm = 5.0993e-01, time/batch = 0.3533s	
655/2700 (epoch 12.130), train_loss = 2.55962302, grad/param norm = 4.8969e-01, time/batch = 0.3435s	
656/2700 (epoch 12.148), train_loss = 2.54751904, grad/param norm = 5.2704e-01, time/batch = 0.3458s	
657/2700 (epoch 12.167), train_loss = 2.57395958, grad/param norm = 3.4595e-01, time/batch = 0.3543s	
658/2700 (epoch 12.185), train_loss = 2.47212235, grad/param norm = 1.7687e-01, time/batch = 0.3497s	
659/2700 (epoch 12.204), train_loss = 2.42948776, grad/param norm = 1.7069e-01, time/batch = 0.3631s	
660/2700 (epoch 12.222), train_loss = 2.40836518, grad/param norm = 2.0155e-01, time/batch = 0.3739s	
661/2700 (epoch 12.241), train_loss = 2.41404553, grad/param norm = 2.2308e-01, time/batch = 0.3818s	
662/2700 (epoch 12.259), train_loss = 2.40954027, grad/param norm = 2.4950e-01, time/batch = 0.3123s	
663/2700 (epoch 12.278), train_loss = 2.48024530, grad/param norm = 2.3579e-01, time/batch = 0.3662s	
664/2700 (epoch 12.296), train_loss = 2.47063107, grad/param norm = 2.7568e-01, time/batch = 0.3719s	
665/2700 (epoch 12.315), train_loss = 2.50397888, grad/param norm = 3.4444e-01, time/batch = 0.3755s	
666/2700 (epoch 12.333), train_loss = 2.53182158, grad/param norm = 4.4872e-01, time/batch = 0.3413s	
667/2700 (epoch 12.352), train_loss = 2.55600215, grad/param norm = 5.1727e-01, time/batch = 0.3440s	
668/2700 (epoch 12.370), train_loss = 2.55183348, grad/param norm = 4.6460e-01, time/batch = 0.3504s	
669/2700 (epoch 12.389), train_loss = 2.49394095, grad/param norm = 4.4685e-01, time/batch = 0.3480s	
670/2700 (epoch 12.407), train_loss = 2.51548888, grad/param norm = 4.6129e-01, time/batch = 0.3299s	
671/2700 (epoch 12.426), train_loss = 2.51386535, grad/param norm = 3.9780e-01, time/batch = 0.3530s	
672/2700 (epoch 12.444), train_loss = 2.43208592, grad/param norm = 3.6094e-01, time/batch = 0.3629s	
673/2700 (epoch 12.463), train_loss = 2.48030766, grad/param norm = 3.1007e-01, time/batch = 0.3725s	
674/2700 (epoch 12.481), train_loss = 2.51860191, grad/param norm = 3.1940e-01, time/batch = 0.3833s	
675/2700 (epoch 12.500), train_loss = 2.55500168, grad/param norm = 3.9309e-01, time/batch = 0.3452s	
676/2700 (epoch 12.519), train_loss = 2.53812581, grad/param norm = 4.1860e-01, time/batch = 0.3504s	
677/2700 (epoch 12.537), train_loss = 2.51671214, grad/param norm = 3.8114e-01, time/batch = 0.3498s	
678/2700 (epoch 12.556), train_loss = 2.48394971, grad/param norm = 2.9770e-01, time/batch = 0.3418s	
679/2700 (epoch 12.574), train_loss = 2.44350231, grad/param norm = 2.9159e-01, time/batch = 0.2962s	
680/2700 (epoch 12.593), train_loss = 2.43562156, grad/param norm = 3.1635e-01, time/batch = 0.3523s	
681/2700 (epoch 12.611), train_loss = 2.41267112, grad/param norm = 3.8790e-01, time/batch = 0.3579s	
682/2700 (epoch 12.630), train_loss = 2.43148736, grad/param norm = 3.8775e-01, time/batch = 0.3717s	
683/2700 (epoch 12.648), train_loss = 2.47155471, grad/param norm = 4.0608e-01, time/batch = 0.3753s	
684/2700 (epoch 12.667), train_loss = 2.42455605, grad/param norm = 4.5390e-01, time/batch = 0.3680s	
685/2700 (epoch 12.685), train_loss = 2.46587150, grad/param norm = 4.8248e-01, time/batch = 0.3542s	
686/2700 (epoch 12.704), train_loss = 2.49977805, grad/param norm = 4.8631e-01, time/batch = 0.3515s	
687/2700 (epoch 12.722), train_loss = 2.44921440, grad/param norm = 4.4146e-01, time/batch = 0.3443s	
688/2700 (epoch 12.741), train_loss = 2.54815085, grad/param norm = 4.0289e-01, time/batch = 0.2946s	
689/2700 (epoch 12.759), train_loss = 2.53105278, grad/param norm = 3.8480e-01, time/batch = 0.3535s	
690/2700 (epoch 12.778), train_loss = 2.51372008, grad/param norm = 3.6668e-01, time/batch = 0.3541s	
691/2700 (epoch 12.796), train_loss = 2.45906290, grad/param norm = 3.1839e-01, time/batch = 0.3755s	
692/2700 (epoch 12.815), train_loss = 2.47304965, grad/param norm = 2.7672e-01, time/batch = 0.3658s	
693/2700 (epoch 12.833), train_loss = 2.44411320, grad/param norm = 2.6750e-01, time/batch = 0.3930s	
694/2700 (epoch 12.852), train_loss = 2.47449816, grad/param norm = 2.6808e-01, time/batch = 0.3579s	
695/2700 (epoch 12.870), train_loss = 2.46537260, grad/param norm = 3.1401e-01, time/batch = 0.3478s	
696/2700 (epoch 12.889), train_loss = 2.48562689, grad/param norm = 4.0399e-01, time/batch = 0.3483s	
697/2700 (epoch 12.907), train_loss = 2.61554372, grad/param norm = 4.1414e-01, time/batch = 0.3168s	
698/2700 (epoch 12.926), train_loss = 2.51888510, grad/param norm = 2.9865e-01, time/batch = 0.3421s	
699/2700 (epoch 12.944), train_loss = 2.47908748, grad/param norm = 1.7341e-01, time/batch = 0.3462s	
700/2700 (epoch 12.963), train_loss = 2.52082322, grad/param norm = 1.8603e-01, time/batch = 0.3532s	
701/2700 (epoch 12.981), train_loss = 2.45687655, grad/param norm = 2.9609e-01, time/batch = 0.3498s	
decayed learning rate by a factor 0.97 to 0.00177058562	
702/2700 (epoch 13.000), train_loss = 2.50000570, grad/param norm = 3.4872e-01, time/batch = 0.3381s	
703/2700 (epoch 13.019), train_loss = 2.50569898, grad/param norm = 4.7854e-01, time/batch = 0.3468s	
704/2700 (epoch 13.037), train_loss = 2.55368567, grad/param norm = 5.6317e-01, time/batch = 0.3506s	
705/2700 (epoch 13.056), train_loss = 2.51321225, grad/param norm = 5.4863e-01, time/batch = 0.3523s	
706/2700 (epoch 13.074), train_loss = 2.46313031, grad/param norm = 4.0012e-01, time/batch = 0.3432s	
707/2700 (epoch 13.093), train_loss = 2.49314568, grad/param norm = 2.7096e-01, time/batch = 0.3570s	
708/2700 (epoch 13.111), train_loss = 2.45318727, grad/param norm = 2.3581e-01, time/batch = 0.3670s	
709/2700 (epoch 13.130), train_loss = 2.47135279, grad/param norm = 2.1744e-01, time/batch = 0.3596s	
710/2700 (epoch 13.148), train_loss = 2.44021523, grad/param norm = 2.9557e-01, time/batch = 0.3717s	
711/2700 (epoch 13.167), train_loss = 2.50856874, grad/param norm = 3.3075e-01, time/batch = 0.3613s	
712/2700 (epoch 13.185), train_loss = 2.44196894, grad/param norm = 3.0082e-01, time/batch = 0.3429s	
713/2700 (epoch 13.204), train_loss = 2.41086697, grad/param norm = 3.5788e-01, time/batch = 0.3504s	
714/2700 (epoch 13.222), train_loss = 2.39223063, grad/param norm = 4.4050e-01, time/batch = 0.3541s	
715/2700 (epoch 13.241), train_loss = 2.40169125, grad/param norm = 4.3149e-01, time/batch = 0.3535s	
716/2700 (epoch 13.259), train_loss = 2.39438847, grad/param norm = 3.7770e-01, time/batch = 0.3474s	
717/2700 (epoch 13.278), train_loss = 2.45072824, grad/param norm = 2.2623e-01, time/batch = 0.3600s	
718/2700 (epoch 13.296), train_loss = 2.43249986, grad/param norm = 1.7541e-01, time/batch = 0.3740s	
719/2700 (epoch 13.315), train_loss = 2.46319841, grad/param norm = 2.2224e-01, time/batch = 0.3828s	
720/2700 (epoch 13.333), train_loss = 2.47024726, grad/param norm = 2.9764e-01, time/batch = 0.3618s	
721/2700 (epoch 13.352), train_loss = 2.49301191, grad/param norm = 3.4187e-01, time/batch = 0.3474s	
722/2700 (epoch 13.370), train_loss = 2.48614207, grad/param norm = 2.7498e-01, time/batch = 0.3516s	
723/2700 (epoch 13.389), train_loss = 2.43060630, grad/param norm = 2.0734e-01, time/batch = 0.3555s	
724/2700 (epoch 13.407), train_loss = 2.45277925, grad/param norm = 1.9116e-01, time/batch = 0.3602s	
725/2700 (epoch 13.426), train_loss = 2.45928252, grad/param norm = 2.0322e-01, time/batch = 0.3754s	
726/2700 (epoch 13.444), train_loss = 2.41046629, grad/param norm = 2.8119e-01, time/batch = 0.3516s	
727/2700 (epoch 13.463), train_loss = 2.47537889, grad/param norm = 3.5858e-01, time/batch = 0.3713s	
728/2700 (epoch 13.481), train_loss = 2.51057706, grad/param norm = 3.5146e-01, time/batch = 0.3614s	
729/2700 (epoch 13.500), train_loss = 2.50213831, grad/param norm = 3.3923e-01, time/batch = 0.3483s	
730/2700 (epoch 13.519), train_loss = 2.45980893, grad/param norm = 3.9249e-01, time/batch = 0.3524s	
731/2700 (epoch 13.537), train_loss = 2.45356656, grad/param norm = 4.0242e-01, time/batch = 0.3436s	
732/2700 (epoch 13.556), train_loss = 2.45084188, grad/param norm = 4.7458e-01, time/batch = 0.3370s	
733/2700 (epoch 13.574), train_loss = 2.45388134, grad/param norm = 5.8061e-01, time/batch = 0.3496s	
734/2700 (epoch 13.593), train_loss = 2.44101420, grad/param norm = 5.2959e-01, time/batch = 0.3539s	
735/2700 (epoch 13.611), train_loss = 2.39385777, grad/param norm = 4.6443e-01, time/batch = 0.3489s	
736/2700 (epoch 13.630), train_loss = 2.39007885, grad/param norm = 3.3573e-01, time/batch = 0.3525s	
737/2700 (epoch 13.648), train_loss = 2.42273586, grad/param norm = 2.3440e-01, time/batch = 0.3387s	
738/2700 (epoch 13.667), train_loss = 2.35824193, grad/param norm = 1.4893e-01, time/batch = 0.3443s	
739/2700 (epoch 13.685), train_loss = 2.38872996, grad/param norm = 1.6400e-01, time/batch = 0.3505s	
740/2700 (epoch 13.704), train_loss = 2.41734659, grad/param norm = 1.4808e-01, time/batch = 0.3467s	
741/2700 (epoch 13.722), train_loss = 2.38226174, grad/param norm = 1.2044e-01, time/batch = 0.3450s	
742/2700 (epoch 13.741), train_loss = 2.48018775, grad/param norm = 1.5554e-01, time/batch = 0.3412s	
743/2700 (epoch 13.759), train_loss = 2.46512733, grad/param norm = 2.2434e-01, time/batch = 0.3538s	
744/2700 (epoch 13.778), train_loss = 2.46592444, grad/param norm = 3.0801e-01, time/batch = 0.3199s	
745/2700 (epoch 13.796), train_loss = 2.43197967, grad/param norm = 3.7669e-01, time/batch = 0.3514s	
746/2700 (epoch 13.815), train_loss = 2.46471999, grad/param norm = 4.3780e-01, time/batch = 0.3627s	
747/2700 (epoch 13.833), train_loss = 2.45370978, grad/param norm = 4.3729e-01, time/batch = 0.3565s	
748/2700 (epoch 13.852), train_loss = 2.47299751, grad/param norm = 5.0721e-01, time/batch = 0.3503s	
749/2700 (epoch 13.870), train_loss = 2.51761933, grad/param norm = 7.1630e-01, time/batch = 0.3419s	
750/2700 (epoch 13.889), train_loss = 2.54447122, grad/param norm = 6.9970e-01, time/batch = 0.3463s	
751/2700 (epoch 13.907), train_loss = 2.61164382, grad/param norm = 3.6150e-01, time/batch = 0.3484s	
752/2700 (epoch 13.926), train_loss = 2.47472579, grad/param norm = 2.0492e-01, time/batch = 0.3496s	
753/2700 (epoch 13.944), train_loss = 2.44875905, grad/param norm = 1.6560e-01, time/batch = 0.3177s	
754/2700 (epoch 13.963), train_loss = 2.48621064, grad/param norm = 1.7923e-01, time/batch = 0.3602s	
755/2700 (epoch 13.981), train_loss = 2.42015854, grad/param norm = 2.4086e-01, time/batch = 0.3514s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
756/2700 (epoch 14.000), train_loss = 2.45926116, grad/param norm = 2.1993e-01, time/batch = 0.3439s	
757/2700 (epoch 14.019), train_loss = 2.44964644, grad/param norm = 3.0395e-01, time/batch = 0.3432s	
758/2700 (epoch 14.037), train_loss = 2.48022609, grad/param norm = 3.3854e-01, time/batch = 0.3590s	
759/2700 (epoch 14.056), train_loss = 2.44346216, grad/param norm = 3.5111e-01, time/batch = 0.3553s	
760/2700 (epoch 14.074), train_loss = 2.39811701, grad/param norm = 2.9377e-01, time/batch = 0.3525s	
761/2700 (epoch 14.093), train_loss = 2.44753623, grad/param norm = 2.7004e-01, time/batch = 0.3659s	
762/2700 (epoch 14.111), train_loss = 2.40887755, grad/param norm = 2.3140e-01, time/batch = 0.3082s	
763/2700 (epoch 14.130), train_loss = 2.43093036, grad/param norm = 2.0884e-01, time/batch = 0.3691s	
764/2700 (epoch 14.148), train_loss = 2.39756579, grad/param norm = 2.6009e-01, time/batch = 0.3600s	
765/2700 (epoch 14.167), train_loss = 2.46617448, grad/param norm = 3.5781e-01, time/batch = 0.3492s	
766/2700 (epoch 14.185), train_loss = 2.40963675, grad/param norm = 3.4801e-01, time/batch = 0.3491s	
767/2700 (epoch 14.204), train_loss = 2.38210484, grad/param norm = 3.8805e-01, time/batch = 0.3556s	
768/2700 (epoch 14.222), train_loss = 2.35592294, grad/param norm = 4.1219e-01, time/batch = 0.3777s	
769/2700 (epoch 14.241), train_loss = 2.34793999, grad/param norm = 3.7339e-01, time/batch = 0.3538s	
770/2700 (epoch 14.259), train_loss = 2.35022803, grad/param norm = 3.3934e-01, time/batch = 0.3736s	
771/2700 (epoch 14.278), train_loss = 2.41083490, grad/param norm = 2.4072e-01, time/batch = 0.3262s	
772/2700 (epoch 14.296), train_loss = 2.39547181, grad/param norm = 2.2070e-01, time/batch = 0.3653s	
773/2700 (epoch 14.315), train_loss = 2.43457578, grad/param norm = 2.9676e-01, time/batch = 0.3485s	
774/2700 (epoch 14.333), train_loss = 2.44756196, grad/param norm = 4.2250e-01, time/batch = 0.3453s	
775/2700 (epoch 14.352), train_loss = 2.46440676, grad/param norm = 4.6120e-01, time/batch = 0.3431s	
776/2700 (epoch 14.370), train_loss = 2.46205852, grad/param norm = 3.5270e-01, time/batch = 0.3451s	
777/2700 (epoch 14.389), train_loss = 2.40504909, grad/param norm = 3.3091e-01, time/batch = 0.3378s	
778/2700 (epoch 14.407), train_loss = 2.42910351, grad/param norm = 3.9581e-01, time/batch = 0.3501s	
779/2700 (epoch 14.426), train_loss = 2.43975709, grad/param norm = 4.2733e-01, time/batch = 0.3533s	
780/2700 (epoch 14.444), train_loss = 2.38727585, grad/param norm = 4.1576e-01, time/batch = 0.3826s	
781/2700 (epoch 14.463), train_loss = 2.42345267, grad/param norm = 3.2851e-01, time/batch = 0.3541s	
782/2700 (epoch 14.481), train_loss = 2.47468621, grad/param norm = 3.2437e-01, time/batch = 0.3655s	
783/2700 (epoch 14.500), train_loss = 2.49401248, grad/param norm = 3.5254e-01, time/batch = 0.3676s	
784/2700 (epoch 14.519), train_loss = 2.42545632, grad/param norm = 3.4050e-01, time/batch = 0.3470s	
785/2700 (epoch 14.537), train_loss = 2.41883456, grad/param norm = 3.4447e-01, time/batch = 0.3602s	
786/2700 (epoch 14.556), train_loss = 2.40180286, grad/param norm = 3.1429e-01, time/batch = 0.3398s	
787/2700 (epoch 14.574), train_loss = 2.37159730, grad/param norm = 3.2787e-01, time/batch = 0.3421s	
788/2700 (epoch 14.593), train_loss = 2.35989261, grad/param norm = 3.1615e-01, time/batch = 0.3488s	
789/2700 (epoch 14.611), train_loss = 2.32971600, grad/param norm = 3.2678e-01, time/batch = 0.3496s	
790/2700 (epoch 14.630), train_loss = 2.34871012, grad/param norm = 3.6649e-01, time/batch = 0.3455s	
791/2700 (epoch 14.648), train_loss = 2.40437583, grad/param norm = 3.6058e-01, time/batch = 0.3678s	
792/2700 (epoch 14.667), train_loss = 2.35001907, grad/param norm = 3.1658e-01, time/batch = 0.3731s	
793/2700 (epoch 14.685), train_loss = 2.38027509, grad/param norm = 2.9039e-01, time/batch = 0.3869s	
794/2700 (epoch 14.704), train_loss = 2.40982410, grad/param norm = 3.3353e-01, time/batch = 0.3466s	
795/2700 (epoch 14.722), train_loss = 2.38251187, grad/param norm = 4.3745e-01, time/batch = 0.3221s	
796/2700 (epoch 14.741), train_loss = 2.48742577, grad/param norm = 4.8768e-01, time/batch = 0.3449s	
797/2700 (epoch 14.759), train_loss = 2.48305501, grad/param norm = 5.6916e-01, time/batch = 0.3459s	
798/2700 (epoch 14.778), train_loss = 2.46977554, grad/param norm = 4.8155e-01, time/batch = 0.3509s	
799/2700 (epoch 14.796), train_loss = 2.40779159, grad/param norm = 4.1324e-01, time/batch = 0.3418s	
800/2700 (epoch 14.815), train_loss = 2.40840851, grad/param norm = 3.1943e-01, time/batch = 0.3442s	
801/2700 (epoch 14.833), train_loss = 2.36738351, grad/param norm = 2.1564e-01, time/batch = 0.3787s	
802/2700 (epoch 14.852), train_loss = 2.39207139, grad/param norm = 1.6928e-01, time/batch = 0.3733s	
803/2700 (epoch 14.870), train_loss = 2.36002226, grad/param norm = 1.8085e-01, time/batch = 0.3819s	
804/2700 (epoch 14.889), train_loss = 2.36971914, grad/param norm = 2.7673e-01, time/batch = 0.3154s	
805/2700 (epoch 14.907), train_loss = 2.50475392, grad/param norm = 4.0837e-01, time/batch = 0.3455s	
806/2700 (epoch 14.926), train_loss = 2.45727255, grad/param norm = 3.9194e-01, time/batch = 0.3485s	
807/2700 (epoch 14.944), train_loss = 2.43770119, grad/param norm = 2.9482e-01, time/batch = 0.3557s	
808/2700 (epoch 14.963), train_loss = 2.45823888, grad/param norm = 2.3709e-01, time/batch = 0.3302s	
809/2700 (epoch 14.981), train_loss = 2.38547409, grad/param norm = 1.9471e-01, time/batch = 0.3287s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
810/2700 (epoch 15.000), train_loss = 2.42326318, grad/param norm = 1.6283e-01, time/batch = 0.3535s	
811/2700 (epoch 15.019), train_loss = 2.41106679, grad/param norm = 2.5910e-01, time/batch = 0.3963s	
812/2700 (epoch 15.037), train_loss = 2.44485899, grad/param norm = 2.6755e-01, time/batch = 0.3571s	
813/2700 (epoch 15.056), train_loss = 2.39103899, grad/param norm = 1.4286e-01, time/batch = 0.2976s	
814/2700 (epoch 15.074), train_loss = 2.34684544, grad/param norm = 1.4561e-01, time/batch = 0.3392s	
815/2700 (epoch 15.093), train_loss = 2.40277481, grad/param norm = 1.5124e-01, time/batch = 0.3412s	
816/2700 (epoch 15.111), train_loss = 2.36675382, grad/param norm = 2.4027e-01, time/batch = 0.3382s	
817/2700 (epoch 15.130), train_loss = 2.40491163, grad/param norm = 3.9267e-01, time/batch = 0.3393s	
818/2700 (epoch 15.148), train_loss = 2.40540143, grad/param norm = 5.4464e-01, time/batch = 0.3337s	
819/2700 (epoch 15.167), train_loss = 2.50233914, grad/param norm = 5.7834e-01, time/batch = 0.3466s	
820/2700 (epoch 15.185), train_loss = 2.40761650, grad/param norm = 4.5200e-01, time/batch = 0.3502s	
821/2700 (epoch 15.204), train_loss = 2.35042148, grad/param norm = 2.8935e-01, time/batch = 0.3500s	
822/2700 (epoch 15.222), train_loss = 2.31142568, grad/param norm = 2.2786e-01, time/batch = 0.3312s	
823/2700 (epoch 15.241), train_loss = 2.30104045, grad/param norm = 1.8374e-01, time/batch = 0.3585s	
824/2700 (epoch 15.259), train_loss = 2.31652360, grad/param norm = 2.1257e-01, time/batch = 0.3405s	
825/2700 (epoch 15.278), train_loss = 2.40043644, grad/param norm = 2.4490e-01, time/batch = 0.3385s	
826/2700 (epoch 15.296), train_loss = 2.38883608, grad/param norm = 2.5752e-01, time/batch = 0.3428s	
827/2700 (epoch 15.315), train_loss = 2.41851068, grad/param norm = 2.4905e-01, time/batch = 0.3371s	
828/2700 (epoch 15.333), train_loss = 2.39297473, grad/param norm = 2.5534e-01, time/batch = 0.3608s	
829/2700 (epoch 15.352), train_loss = 2.40707490, grad/param norm = 2.6431e-01, time/batch = 0.3564s	
830/2700 (epoch 15.370), train_loss = 2.41586951, grad/param norm = 2.6048e-01, time/batch = 0.3513s	
831/2700 (epoch 15.389), train_loss = 2.36945928, grad/param norm = 2.2807e-01, time/batch = 0.3620s	
832/2700 (epoch 15.407), train_loss = 2.37516364, grad/param norm = 2.1607e-01, time/batch = 0.3600s	
833/2700 (epoch 15.426), train_loss = 2.38611697, grad/param norm = 2.4341e-01, time/batch = 0.3449s	
834/2700 (epoch 15.444), train_loss = 2.32981956, grad/param norm = 3.5988e-01, time/batch = 0.3493s	
835/2700 (epoch 15.463), train_loss = 2.38373979, grad/param norm = 4.7353e-01, time/batch = 0.3466s	
836/2700 (epoch 15.481), train_loss = 2.43732963, grad/param norm = 4.8886e-01, time/batch = 0.3391s	
837/2700 (epoch 15.500), train_loss = 2.43775345, grad/param norm = 4.0470e-01, time/batch = 0.3412s	
838/2700 (epoch 15.519), train_loss = 2.38900100, grad/param norm = 3.3813e-01, time/batch = 0.3368s	
839/2700 (epoch 15.537), train_loss = 2.38663715, grad/param norm = 3.1960e-01, time/batch = 0.3491s	
840/2700 (epoch 15.556), train_loss = 2.37378237, grad/param norm = 3.0545e-01, time/batch = 0.3654s	
841/2700 (epoch 15.574), train_loss = 2.34924569, grad/param norm = 3.1437e-01, time/batch = 0.3553s	
842/2700 (epoch 15.593), train_loss = 2.33662102, grad/param norm = 3.2312e-01, time/batch = 0.3498s	
843/2700 (epoch 15.611), train_loss = 2.29528523, grad/param norm = 3.0793e-01, time/batch = 0.3425s	
844/2700 (epoch 15.630), train_loss = 2.31441197, grad/param norm = 3.3599e-01, time/batch = 0.3414s	
845/2700 (epoch 15.648), train_loss = 2.36161116, grad/param norm = 3.4819e-01, time/batch = 0.3366s	
846/2700 (epoch 15.667), train_loss = 2.31854846, grad/param norm = 3.7538e-01, time/batch = 0.3505s	
847/2700 (epoch 15.685), train_loss = 2.35204085, grad/param norm = 4.9898e-01, time/batch = 0.3217s	
848/2700 (epoch 15.704), train_loss = 2.42187470, grad/param norm = 4.9574e-01, time/batch = 0.3530s	
849/2700 (epoch 15.722), train_loss = 2.34487622, grad/param norm = 3.9456e-01, time/batch = 0.3828s	
850/2700 (epoch 15.741), train_loss = 2.42774668, grad/param norm = 3.7950e-01, time/batch = 0.3637s	
851/2700 (epoch 15.759), train_loss = 2.42407240, grad/param norm = 4.2692e-01, time/batch = 0.3941s	
852/2700 (epoch 15.778), train_loss = 2.39895639, grad/param norm = 3.2354e-01, time/batch = 0.3505s	
853/2700 (epoch 15.796), train_loss = 2.34813533, grad/param norm = 2.9051e-01, time/batch = 0.3477s	
854/2700 (epoch 15.815), train_loss = 2.37787985, grad/param norm = 3.1089e-01, time/batch = 0.3491s	
855/2700 (epoch 15.833), train_loss = 2.34753634, grad/param norm = 3.0916e-01, time/batch = 0.3432s	
856/2700 (epoch 15.852), train_loss = 2.36867806, grad/param norm = 2.3984e-01, time/batch = 0.3551s	
857/2700 (epoch 15.870), train_loss = 2.32655358, grad/param norm = 2.1406e-01, time/batch = 0.3602s	
858/2700 (epoch 15.889), train_loss = 2.33060768, grad/param norm = 3.1313e-01, time/batch = 0.3645s	
859/2700 (epoch 15.907), train_loss = 2.46415759, grad/param norm = 4.3047e-01, time/batch = 0.3586s	
860/2700 (epoch 15.926), train_loss = 2.41130803, grad/param norm = 4.1940e-01, time/batch = 0.3670s	
861/2700 (epoch 15.944), train_loss = 2.40750975, grad/param norm = 3.3866e-01, time/batch = 0.3624s	
862/2700 (epoch 15.963), train_loss = 2.42219161, grad/param norm = 2.7043e-01, time/batch = 0.3454s	
863/2700 (epoch 15.981), train_loss = 2.36091423, grad/param norm = 2.2157e-01, time/batch = 0.3511s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
864/2700 (epoch 16.000), train_loss = 2.39094771, grad/param norm = 1.6190e-01, time/batch = 0.3101s	
865/2700 (epoch 16.019), train_loss = 2.36838889, grad/param norm = 1.6941e-01, time/batch = 0.3468s	
866/2700 (epoch 16.037), train_loss = 2.39726169, grad/param norm = 1.4984e-01, time/batch = 0.3670s	
867/2700 (epoch 16.056), train_loss = 2.35604069, grad/param norm = 1.6813e-01, time/batch = 0.3526s	
868/2700 (epoch 16.074), train_loss = 2.31100407, grad/param norm = 1.5891e-01, time/batch = 0.3679s	
869/2700 (epoch 16.093), train_loss = 2.37517782, grad/param norm = 2.6108e-01, time/batch = 0.3757s	
870/2700 (epoch 16.111), train_loss = 2.35914269, grad/param norm = 3.0477e-01, time/batch = 0.3916s	
871/2700 (epoch 16.130), train_loss = 2.38942641, grad/param norm = 3.7723e-01, time/batch = 0.3529s	
872/2700 (epoch 16.148), train_loss = 2.40290864, grad/param norm = 4.2257e-01, time/batch = 0.3522s	
873/2700 (epoch 16.167), train_loss = 2.42977848, grad/param norm = 3.4353e-01, time/batch = 0.3506s	
874/2700 (epoch 16.185), train_loss = 2.34304954, grad/param norm = 2.2827e-01, time/batch = 0.3622s	
875/2700 (epoch 16.204), train_loss = 2.29879895, grad/param norm = 2.1927e-01, time/batch = 0.3707s	
876/2700 (epoch 16.222), train_loss = 2.27056375, grad/param norm = 2.5312e-01, time/batch = 0.3461s	
877/2700 (epoch 16.241), train_loss = 2.25880401, grad/param norm = 2.5656e-01, time/batch = 0.3756s	
878/2700 (epoch 16.259), train_loss = 2.27259588, grad/param norm = 2.9679e-01, time/batch = 0.3904s	
879/2700 (epoch 16.278), train_loss = 2.34193631, grad/param norm = 2.7238e-01, time/batch = 0.3988s	
880/2700 (epoch 16.296), train_loss = 2.32841715, grad/param norm = 2.2599e-01, time/batch = 0.3486s	
881/2700 (epoch 16.315), train_loss = 2.35957878, grad/param norm = 2.1412e-01, time/batch = 0.3922s	
882/2700 (epoch 16.333), train_loss = 2.33945523, grad/param norm = 2.2952e-01, time/batch = 0.3405s	
883/2700 (epoch 16.352), train_loss = 2.36526289, grad/param norm = 2.9436e-01, time/batch = 0.3445s	
884/2700 (epoch 16.370), train_loss = 2.39563641, grad/param norm = 4.3593e-01, time/batch = 0.3471s	
885/2700 (epoch 16.389), train_loss = 2.38693673, grad/param norm = 4.8527e-01, time/batch = 0.3368s	
886/2700 (epoch 16.407), train_loss = 2.38144587, grad/param norm = 4.5402e-01, time/batch = 0.3531s	
887/2700 (epoch 16.426), train_loss = 2.39302125, grad/param norm = 4.2791e-01, time/batch = 0.3496s	
888/2700 (epoch 16.444), train_loss = 2.32258366, grad/param norm = 4.5208e-01, time/batch = 0.3624s	
889/2700 (epoch 16.463), train_loss = 2.35411939, grad/param norm = 4.6287e-01, time/batch = 0.3645s	
890/2700 (epoch 16.481), train_loss = 2.38255582, grad/param norm = 3.8324e-01, time/batch = 0.3561s	
891/2700 (epoch 16.500), train_loss = 2.36954702, grad/param norm = 2.9799e-01, time/batch = 0.3521s	
892/2700 (epoch 16.519), train_loss = 2.33602234, grad/param norm = 2.4650e-01, time/batch = 0.3466s	
893/2700 (epoch 16.537), train_loss = 2.34219126, grad/param norm = 2.2038e-01, time/batch = 0.3497s	
894/2700 (epoch 16.556), train_loss = 2.32710176, grad/param norm = 1.8490e-01, time/batch = 0.3295s	
895/2700 (epoch 16.574), train_loss = 2.30171842, grad/param norm = 1.7381e-01, time/batch = 0.3383s	
896/2700 (epoch 16.593), train_loss = 2.29506498, grad/param norm = 1.8182e-01, time/batch = 0.3423s	
897/2700 (epoch 16.611), train_loss = 2.28123015, grad/param norm = 2.8034e-01, time/batch = 0.3401s	
898/2700 (epoch 16.630), train_loss = 2.31991769, grad/param norm = 3.6048e-01, time/batch = 0.3731s	
899/2700 (epoch 16.648), train_loss = 2.37283366, grad/param norm = 3.1856e-01, time/batch = 0.3620s	
900/2700 (epoch 16.667), train_loss = 2.28029311, grad/param norm = 2.2110e-01, time/batch = 0.3485s	
901/2700 (epoch 16.685), train_loss = 2.29011790, grad/param norm = 2.0371e-01, time/batch = 0.3515s	
902/2700 (epoch 16.704), train_loss = 2.32580200, grad/param norm = 2.1460e-01, time/batch = 0.3613s	
903/2700 (epoch 16.722), train_loss = 2.28053600, grad/param norm = 2.4876e-01, time/batch = 0.3485s	
904/2700 (epoch 16.741), train_loss = 2.37711515, grad/param norm = 2.8669e-01, time/batch = 0.3444s	
905/2700 (epoch 16.759), train_loss = 2.36666701, grad/param norm = 2.6653e-01, time/batch = 0.3380s	
906/2700 (epoch 16.778), train_loss = 2.36297666, grad/param norm = 2.7518e-01, time/batch = 0.3538s	
907/2700 (epoch 16.796), train_loss = 2.31915919, grad/param norm = 2.9087e-01, time/batch = 0.3598s	
908/2700 (epoch 16.815), train_loss = 2.34999337, grad/param norm = 3.3027e-01, time/batch = 0.3711s	
909/2700 (epoch 16.833), train_loss = 2.31552009, grad/param norm = 3.5419e-01, time/batch = 0.3543s	
910/2700 (epoch 16.852), train_loss = 2.33816191, grad/param norm = 3.4267e-01, time/batch = 0.3490s	
911/2700 (epoch 16.870), train_loss = 2.31404179, grad/param norm = 4.2696e-01, time/batch = 0.3777s	
912/2700 (epoch 16.889), train_loss = 2.34896908, grad/param norm = 5.0491e-01, time/batch = 0.3439s	
913/2700 (epoch 16.907), train_loss = 2.46180164, grad/param norm = 5.5952e-01, time/batch = 0.3409s	
914/2700 (epoch 16.926), train_loss = 2.41282584, grad/param norm = 5.0056e-01, time/batch = 0.3468s	
915/2700 (epoch 16.944), train_loss = 2.37108636, grad/param norm = 3.3546e-01, time/batch = 0.3496s	
916/2700 (epoch 16.963), train_loss = 2.38719963, grad/param norm = 2.9401e-01, time/batch = 0.3566s	
917/2700 (epoch 16.981), train_loss = 2.32973982, grad/param norm = 2.7169e-01, time/batch = 0.3663s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
918/2700 (epoch 17.000), train_loss = 2.35721617, grad/param norm = 1.8539e-01, time/batch = 0.3509s	
919/2700 (epoch 17.019), train_loss = 2.33714002, grad/param norm = 1.6439e-01, time/batch = 0.3444s	
920/2700 (epoch 17.037), train_loss = 2.35580611, grad/param norm = 1.5805e-01, time/batch = 0.3468s	
921/2700 (epoch 17.056), train_loss = 2.31710179, grad/param norm = 1.7977e-01, time/batch = 0.3598s	
922/2700 (epoch 17.074), train_loss = 2.28159420, grad/param norm = 1.9489e-01, time/batch = 0.3453s	
923/2700 (epoch 17.093), train_loss = 2.33680463, grad/param norm = 2.8950e-01, time/batch = 0.3456s	
924/2700 (epoch 17.111), train_loss = 2.30754528, grad/param norm = 3.1286e-01, time/batch = 0.3478s	
925/2700 (epoch 17.130), train_loss = 2.34154639, grad/param norm = 3.4537e-01, time/batch = 0.3504s	
926/2700 (epoch 17.148), train_loss = 2.32489438, grad/param norm = 4.3423e-01, time/batch = 0.3553s	
927/2700 (epoch 17.167), train_loss = 2.39872243, grad/param norm = 3.9482e-01, time/batch = 0.3658s	
928/2700 (epoch 17.185), train_loss = 2.30965236, grad/param norm = 2.7328e-01, time/batch = 0.3505s	
929/2700 (epoch 17.204), train_loss = 2.27469000, grad/param norm = 2.5301e-01, time/batch = 0.3567s	
930/2700 (epoch 17.222), train_loss = 2.24251549, grad/param norm = 2.5914e-01, time/batch = 0.3564s	
931/2700 (epoch 17.241), train_loss = 2.22339339, grad/param norm = 2.2244e-01, time/batch = 0.3303s	
932/2700 (epoch 17.259), train_loss = 2.23271259, grad/param norm = 2.2987e-01, time/batch = 0.3472s	
933/2700 (epoch 17.278), train_loss = 2.29733724, grad/param norm = 1.6510e-01, time/batch = 0.3502s	
934/2700 (epoch 17.296), train_loss = 2.28913877, grad/param norm = 1.2718e-01, time/batch = 0.3554s	
935/2700 (epoch 17.315), train_loss = 2.32206975, grad/param norm = 1.5404e-01, time/batch = 0.3678s	
936/2700 (epoch 17.333), train_loss = 2.30253412, grad/param norm = 1.7417e-01, time/batch = 0.3744s	
937/2700 (epoch 17.352), train_loss = 2.32244504, grad/param norm = 2.3414e-01, time/batch = 0.3552s	
938/2700 (epoch 17.370), train_loss = 2.34412477, grad/param norm = 2.5081e-01, time/batch = 0.3660s	
939/2700 (epoch 17.389), train_loss = 2.31700722, grad/param norm = 2.8484e-01, time/batch = 0.3427s	
940/2700 (epoch 17.407), train_loss = 2.33848400, grad/param norm = 3.7071e-01, time/batch = 0.3520s	
941/2700 (epoch 17.426), train_loss = 2.35801444, grad/param norm = 4.3570e-01, time/batch = 0.3458s	
942/2700 (epoch 17.444), train_loss = 2.30477299, grad/param norm = 4.2324e-01, time/batch = 0.3435s	
943/2700 (epoch 17.463), train_loss = 2.30932463, grad/param norm = 3.5788e-01, time/batch = 0.3460s	
944/2700 (epoch 17.481), train_loss = 2.35446346, grad/param norm = 3.3027e-01, time/batch = 0.3497s	
945/2700 (epoch 17.500), train_loss = 2.33152553, grad/param norm = 3.4899e-01, time/batch = 0.3537s	
946/2700 (epoch 17.519), train_loss = 2.31646087, grad/param norm = 3.7978e-01, time/batch = 0.3560s	
947/2700 (epoch 17.537), train_loss = 2.32594107, grad/param norm = 4.6020e-01, time/batch = 0.3135s	
948/2700 (epoch 17.556), train_loss = 2.32870324, grad/param norm = 4.1113e-01, time/batch = 0.3586s	
949/2700 (epoch 17.574), train_loss = 2.28999711, grad/param norm = 3.5987e-01, time/batch = 0.3464s	
950/2700 (epoch 17.593), train_loss = 2.28183438, grad/param norm = 3.1870e-01, time/batch = 0.3284s	
951/2700 (epoch 17.611), train_loss = 2.25405893, grad/param norm = 3.5377e-01, time/batch = 0.3603s	
952/2700 (epoch 17.630), train_loss = 2.27446783, grad/param norm = 3.3814e-01, time/batch = 0.3491s	
953/2700 (epoch 17.648), train_loss = 2.30692638, grad/param norm = 2.7137e-01, time/batch = 0.3504s	
954/2700 (epoch 17.667), train_loss = 2.24865050, grad/param norm = 3.0322e-01, time/batch = 0.3431s	
955/2700 (epoch 17.685), train_loss = 2.27756924, grad/param norm = 3.5730e-01, time/batch = 0.3192s	
956/2700 (epoch 17.704), train_loss = 2.31007712, grad/param norm = 3.3472e-01, time/batch = 0.3588s	
957/2700 (epoch 17.722), train_loss = 2.25365043, grad/param norm = 2.8116e-01, time/batch = 0.3553s	
958/2700 (epoch 17.741), train_loss = 2.33945156, grad/param norm = 2.8198e-01, time/batch = 0.3553s	
959/2700 (epoch 17.759), train_loss = 2.32435435, grad/param norm = 1.9092e-01, time/batch = 0.3249s	
960/2700 (epoch 17.778), train_loss = 2.31834261, grad/param norm = 1.4656e-01, time/batch = 0.3634s	
961/2700 (epoch 17.796), train_loss = 2.27575781, grad/param norm = 1.8743e-01, time/batch = 0.3668s	
962/2700 (epoch 17.815), train_loss = 2.31794138, grad/param norm = 2.6892e-01, time/batch = 0.3517s	
963/2700 (epoch 17.833), train_loss = 2.27715875, grad/param norm = 2.9284e-01, time/batch = 0.3525s	
964/2700 (epoch 17.852), train_loss = 2.29957776, grad/param norm = 2.6275e-01, time/batch = 0.3467s	
965/2700 (epoch 17.870), train_loss = 2.25999141, grad/param norm = 2.6994e-01, time/batch = 0.3776s	
966/2700 (epoch 17.889), train_loss = 2.27232000, grad/param norm = 3.4328e-01, time/batch = 0.3697s	
967/2700 (epoch 17.907), train_loss = 2.38932139, grad/param norm = 4.1285e-01, time/batch = 0.3513s	
968/2700 (epoch 17.926), train_loss = 2.34785788, grad/param norm = 4.0857e-01, time/batch = 0.3100s	
969/2700 (epoch 17.944), train_loss = 2.32911987, grad/param norm = 3.2041e-01, time/batch = 0.3461s	
970/2700 (epoch 17.963), train_loss = 2.35132992, grad/param norm = 3.1439e-01, time/batch = 0.3469s	
971/2700 (epoch 17.981), train_loss = 2.29845773, grad/param norm = 2.8355e-01, time/batch = 0.3567s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
972/2700 (epoch 18.000), train_loss = 2.32514381, grad/param norm = 2.0587e-01, time/batch = 0.3077s	
973/2700 (epoch 18.019), train_loss = 2.30435499, grad/param norm = 2.6527e-01, time/batch = 0.3455s	
974/2700 (epoch 18.037), train_loss = 2.33451922, grad/param norm = 3.0551e-01, time/batch = 0.3563s	
975/2700 (epoch 18.056), train_loss = 2.30621823, grad/param norm = 4.0303e-01, time/batch = 0.3646s	
976/2700 (epoch 18.074), train_loss = 2.28201524, grad/param norm = 4.1418e-01, time/batch = 0.3735s	
977/2700 (epoch 18.093), train_loss = 2.33036839, grad/param norm = 4.1866e-01, time/batch = 0.3685s	
978/2700 (epoch 18.111), train_loss = 2.30541925, grad/param norm = 3.7346e-01, time/batch = 0.3605s	
979/2700 (epoch 18.130), train_loss = 2.30818532, grad/param norm = 2.7796e-01, time/batch = 0.3390s	
980/2700 (epoch 18.148), train_loss = 2.27280849, grad/param norm = 2.7544e-01, time/batch = 0.3383s	
981/2700 (epoch 18.167), train_loss = 2.34250657, grad/param norm = 2.5139e-01, time/batch = 0.3467s	
982/2700 (epoch 18.185), train_loss = 2.27467393, grad/param norm = 2.0516e-01, time/batch = 0.3380s	
983/2700 (epoch 18.204), train_loss = 2.24474853, grad/param norm = 2.1194e-01, time/batch = 0.3572s	
984/2700 (epoch 18.222), train_loss = 2.21608601, grad/param norm = 2.5523e-01, time/batch = 0.3634s	
985/2700 (epoch 18.241), train_loss = 2.19508713, grad/param norm = 2.4575e-01, time/batch = 0.3592s	
986/2700 (epoch 18.259), train_loss = 2.21072113, grad/param norm = 2.9019e-01, time/batch = 0.3657s	
987/2700 (epoch 18.278), train_loss = 2.28003295, grad/param norm = 2.8736e-01, time/batch = 0.3695s	
988/2700 (epoch 18.296), train_loss = 2.26808223, grad/param norm = 2.5982e-01, time/batch = 0.3823s	
989/2700 (epoch 18.315), train_loss = 2.29508001, grad/param norm = 2.6883e-01, time/batch = 0.3449s	
990/2700 (epoch 18.333), train_loss = 2.27040605, grad/param norm = 2.2153e-01, time/batch = 0.3455s	
991/2700 (epoch 18.352), train_loss = 2.28906511, grad/param norm = 2.2562e-01, time/batch = 0.3769s	
992/2700 (epoch 18.370), train_loss = 2.30355374, grad/param norm = 2.4031e-01, time/batch = 0.3570s	
993/2700 (epoch 18.389), train_loss = 2.27471219, grad/param norm = 2.3534e-01, time/batch = 0.3671s	
994/2700 (epoch 18.407), train_loss = 2.28966967, grad/param norm = 2.9386e-01, time/batch = 0.3622s	
995/2700 (epoch 18.426), train_loss = 2.31567418, grad/param norm = 3.0742e-01, time/batch = 0.3127s	
996/2700 (epoch 18.444), train_loss = 2.24380280, grad/param norm = 3.3988e-01, time/batch = 0.3467s	
997/2700 (epoch 18.463), train_loss = 2.29338240, grad/param norm = 3.9208e-01, time/batch = 0.3315s	
998/2700 (epoch 18.481), train_loss = 2.34398241, grad/param norm = 3.9647e-01, time/batch = 0.3431s	
999/2700 (epoch 18.500), train_loss = 2.35301581, grad/param norm = 4.1954e-01, time/batch = 0.3467s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch18.52_2.3091.t7	
1000/2700 (epoch 18.519), train_loss = 2.31349802, grad/param norm = 3.4325e-01, time/batch = 0.3478s	
1001/2700 (epoch 18.537), train_loss = 2.35508393, grad/param norm = 2.0540e-01, time/batch = 0.3510s	
1002/2700 (epoch 18.556), train_loss = 2.26370171, grad/param norm = 1.3905e-01, time/batch = 0.3284s	
1003/2700 (epoch 18.574), train_loss = 2.23773766, grad/param norm = 1.7546e-01, time/batch = 0.3417s	
1004/2700 (epoch 18.593), train_loss = 2.23089064, grad/param norm = 2.4872e-01, time/batch = 0.3505s	
1005/2700 (epoch 18.611), train_loss = 2.20922082, grad/param norm = 3.9546e-01, time/batch = 0.3543s	
1006/2700 (epoch 18.630), train_loss = 2.24010885, grad/param norm = 4.8163e-01, time/batch = 0.3680s	
1007/2700 (epoch 18.648), train_loss = 2.30110683, grad/param norm = 4.6691e-01, time/batch = 0.3727s	
1008/2700 (epoch 18.667), train_loss = 2.23696496, grad/param norm = 4.0998e-01, time/batch = 0.3520s	
1009/2700 (epoch 18.685), train_loss = 2.25042704, grad/param norm = 3.9806e-01, time/batch = 0.3693s	
1010/2700 (epoch 18.704), train_loss = 2.28046042, grad/param norm = 3.7900e-01, time/batch = 0.3557s	
1011/2700 (epoch 18.722), train_loss = 2.23406085, grad/param norm = 3.3889e-01, time/batch = 0.3449s	
1012/2700 (epoch 18.741), train_loss = 2.30716634, grad/param norm = 3.0666e-01, time/batch = 0.3451s	
1013/2700 (epoch 18.759), train_loss = 2.32074853, grad/param norm = 3.2469e-01, time/batch = 0.3481s	
1014/2700 (epoch 18.778), train_loss = 2.31810913, grad/param norm = 3.6744e-01, time/batch = 0.3513s	
1015/2700 (epoch 18.796), train_loss = 2.27455599, grad/param norm = 3.4769e-01, time/batch = 0.3577s	
1016/2700 (epoch 18.815), train_loss = 2.30067160, grad/param norm = 2.8555e-01, time/batch = 0.3774s	
1017/2700 (epoch 18.833), train_loss = 2.25237319, grad/param norm = 2.3828e-01, time/batch = 0.3508s	
1018/2700 (epoch 18.852), train_loss = 2.26586718, grad/param norm = 2.0084e-01, time/batch = 0.3612s	
1019/2700 (epoch 18.870), train_loss = 2.23325994, grad/param norm = 2.4777e-01, time/batch = 0.3532s	
1020/2700 (epoch 18.889), train_loss = 2.24450528, grad/param norm = 3.1970e-01, time/batch = 0.3151s	
1021/2700 (epoch 18.907), train_loss = 2.36896762, grad/param norm = 3.1132e-01, time/batch = 0.3595s	
1022/2700 (epoch 18.926), train_loss = 2.31077034, grad/param norm = 2.8684e-01, time/batch = 0.3434s	
1023/2700 (epoch 18.944), train_loss = 2.29659881, grad/param norm = 2.2630e-01, time/batch = 0.3449s	
1024/2700 (epoch 18.963), train_loss = 2.31076602, grad/param norm = 1.8295e-01, time/batch = 0.3494s	
1025/2700 (epoch 18.981), train_loss = 2.26122121, grad/param norm = 2.1412e-01, time/batch = 0.3515s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1026/2700 (epoch 19.000), train_loss = 2.29755270, grad/param norm = 2.1092e-01, time/batch = 0.3520s	
1027/2700 (epoch 19.019), train_loss = 2.28141585, grad/param norm = 2.8205e-01, time/batch = 0.3559s	
1028/2700 (epoch 19.037), train_loss = 2.31105965, grad/param norm = 3.0021e-01, time/batch = 0.3460s	
1029/2700 (epoch 19.056), train_loss = 2.26904153, grad/param norm = 2.9755e-01, time/batch = 0.3254s	
1030/2700 (epoch 19.074), train_loss = 2.22958501, grad/param norm = 2.5318e-01, time/batch = 0.3623s	
1031/2700 (epoch 19.093), train_loss = 2.26743954, grad/param norm = 2.8613e-01, time/batch = 0.3626s	
1032/2700 (epoch 19.111), train_loss = 2.23302626, grad/param norm = 3.1566e-01, time/batch = 0.3470s	
1033/2700 (epoch 19.130), train_loss = 2.27629988, grad/param norm = 3.3604e-01, time/batch = 0.3532s	
1034/2700 (epoch 19.148), train_loss = 2.23440189, grad/param norm = 3.7655e-01, time/batch = 0.3629s	
1035/2700 (epoch 19.167), train_loss = 2.31513610, grad/param norm = 3.2005e-01, time/batch = 0.3514s	
1036/2700 (epoch 19.185), train_loss = 2.23428069, grad/param norm = 2.0773e-01, time/batch = 0.3741s	
1037/2700 (epoch 19.204), train_loss = 2.21168356, grad/param norm = 2.1387e-01, time/batch = 0.3576s	
1038/2700 (epoch 19.222), train_loss = 2.18280148, grad/param norm = 2.7181e-01, time/batch = 0.3204s	
1039/2700 (epoch 19.241), train_loss = 2.15784124, grad/param norm = 3.0794e-01, time/batch = 0.3420s	
1040/2700 (epoch 19.259), train_loss = 2.17722575, grad/param norm = 3.4702e-01, time/batch = 0.3449s	
1041/2700 (epoch 19.278), train_loss = 2.24330417, grad/param norm = 2.8625e-01, time/batch = 0.3493s	
1042/2700 (epoch 19.296), train_loss = 2.24032504, grad/param norm = 2.5463e-01, time/batch = 0.3527s	
1043/2700 (epoch 19.315), train_loss = 2.26861259, grad/param norm = 2.8331e-01, time/batch = 0.3499s	
1044/2700 (epoch 19.333), train_loss = 2.26479021, grad/param norm = 3.4640e-01, time/batch = 0.3597s	
1045/2700 (epoch 19.352), train_loss = 2.26724178, grad/param norm = 3.5072e-01, time/batch = 0.3700s	
1046/2700 (epoch 19.370), train_loss = 2.28334271, grad/param norm = 2.6788e-01, time/batch = 0.3822s	
1047/2700 (epoch 19.389), train_loss = 2.24560995, grad/param norm = 2.2153e-01, time/batch = 0.3460s	
1048/2700 (epoch 19.407), train_loss = 2.25390434, grad/param norm = 2.5368e-01, time/batch = 0.3411s	
1049/2700 (epoch 19.426), train_loss = 2.26974405, grad/param norm = 2.4648e-01, time/batch = 0.3463s	
1050/2700 (epoch 19.444), train_loss = 2.20350420, grad/param norm = 2.7373e-01, time/batch = 0.3413s	
1051/2700 (epoch 19.463), train_loss = 2.25669063, grad/param norm = 3.6991e-01, time/batch = 0.3514s	
1052/2700 (epoch 19.481), train_loss = 2.31874252, grad/param norm = 4.5751e-01, time/batch = 0.3497s	
1053/2700 (epoch 19.500), train_loss = 2.29361033, grad/param norm = 4.8608e-01, time/batch = 0.3498s	
1054/2700 (epoch 19.519), train_loss = 2.27558011, grad/param norm = 4.4176e-01, time/batch = 0.3751s	
1055/2700 (epoch 19.537), train_loss = 2.26678235, grad/param norm = 2.9879e-01, time/batch = 0.3774s	
1056/2700 (epoch 19.556), train_loss = 2.24050404, grad/param norm = 1.6379e-01, time/batch = 0.3807s	
1057/2700 (epoch 19.574), train_loss = 2.20943757, grad/param norm = 1.4637e-01, time/batch = 0.3415s	
1058/2700 (epoch 19.593), train_loss = 2.20533580, grad/param norm = 1.9041e-01, time/batch = 0.3390s	
1059/2700 (epoch 19.611), train_loss = 2.16781688, grad/param norm = 2.6947e-01, time/batch = 0.3390s	
1060/2700 (epoch 19.630), train_loss = 2.19500406, grad/param norm = 2.8202e-01, time/batch = 0.3443s	
1061/2700 (epoch 19.648), train_loss = 2.24286126, grad/param norm = 2.7374e-01, time/batch = 0.3489s	
1062/2700 (epoch 19.667), train_loss = 2.20006162, grad/param norm = 3.1648e-01, time/batch = 0.3171s	
1063/2700 (epoch 19.685), train_loss = 2.23502595, grad/param norm = 3.3856e-01, time/batch = 0.3765s	
1064/2700 (epoch 19.704), train_loss = 2.26396162, grad/param norm = 3.2824e-01, time/batch = 0.3549s	
1065/2700 (epoch 19.722), train_loss = 2.20780856, grad/param norm = 2.4182e-01, time/batch = 0.3608s	
1066/2700 (epoch 19.741), train_loss = 2.27238443, grad/param norm = 2.0745e-01, time/batch = 0.3690s	
1067/2700 (epoch 19.759), train_loss = 2.27460369, grad/param norm = 2.5274e-01, time/batch = 0.3781s	
1068/2700 (epoch 19.778), train_loss = 2.28141881, grad/param norm = 3.5885e-01, time/batch = 0.3704s	
1069/2700 (epoch 19.796), train_loss = 2.24625694, grad/param norm = 3.8775e-01, time/batch = 0.3479s	
1070/2700 (epoch 19.815), train_loss = 2.27563026, grad/param norm = 3.6299e-01, time/batch = 0.3390s	
1071/2700 (epoch 19.833), train_loss = 2.22960497, grad/param norm = 2.7328e-01, time/batch = 0.3618s	
1072/2700 (epoch 19.852), train_loss = 2.23749346, grad/param norm = 1.7051e-01, time/batch = 0.3639s	
1073/2700 (epoch 19.870), train_loss = 2.20380396, grad/param norm = 1.7253e-01, time/batch = 0.3774s	
1074/2700 (epoch 19.889), train_loss = 2.21025453, grad/param norm = 2.2524e-01, time/batch = 0.3105s	
1075/2700 (epoch 19.907), train_loss = 2.32562433, grad/param norm = 2.7236e-01, time/batch = 0.3430s	
1076/2700 (epoch 19.926), train_loss = 2.27718964, grad/param norm = 3.2505e-01, time/batch = 0.3683s	
1077/2700 (epoch 19.944), train_loss = 2.27408807, grad/param norm = 3.4830e-01, time/batch = 0.3544s	
1078/2700 (epoch 19.963), train_loss = 2.29653934, grad/param norm = 3.5487e-01, time/batch = 0.3422s	
1079/2700 (epoch 19.981), train_loss = 2.24359170, grad/param norm = 3.1155e-01, time/batch = 0.3470s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1080/2700 (epoch 20.000), train_loss = 2.27694411, grad/param norm = 3.0137e-01, time/batch = 0.3527s	
1081/2700 (epoch 20.019), train_loss = 2.24931984, grad/param norm = 2.9237e-01, time/batch = 0.3532s	
1082/2700 (epoch 20.037), train_loss = 2.27667628, grad/param norm = 3.1730e-01, time/batch = 0.3549s	
1083/2700 (epoch 20.056), train_loss = 2.24486314, grad/param norm = 3.7118e-01, time/batch = 0.3072s	
1084/2700 (epoch 20.074), train_loss = 2.20369547, grad/param norm = 3.3506e-01, time/batch = 0.3408s	
1085/2700 (epoch 20.093), train_loss = 2.24289122, grad/param norm = 3.3244e-01, time/batch = 0.3421s	
1086/2700 (epoch 20.111), train_loss = 2.20627455, grad/param norm = 3.6187e-01, time/batch = 0.3395s	
1087/2700 (epoch 20.130), train_loss = 2.26117286, grad/param norm = 3.9018e-01, time/batch = 0.3345s	
1088/2700 (epoch 20.148), train_loss = 2.20592930, grad/param norm = 3.7241e-01, time/batch = 0.3431s	
1089/2700 (epoch 20.167), train_loss = 2.27841324, grad/param norm = 3.2418e-01, time/batch = 0.3418s	
1090/2700 (epoch 20.185), train_loss = 2.20483927, grad/param norm = 2.4488e-01, time/batch = 0.3494s	
1091/2700 (epoch 20.204), train_loss = 2.17993259, grad/param norm = 1.3904e-01, time/batch = 0.3646s	
1092/2700 (epoch 20.222), train_loss = 2.14842464, grad/param norm = 1.3464e-01, time/batch = 0.3464s	
1093/2700 (epoch 20.241), train_loss = 2.10835086, grad/param norm = 1.1462e-01, time/batch = 0.3468s	
1094/2700 (epoch 20.259), train_loss = 2.13243977, grad/param norm = 1.4642e-01, time/batch = 0.3458s	
1095/2700 (epoch 20.278), train_loss = 2.20554492, grad/param norm = 2.1289e-01, time/batch = 0.3580s	
1096/2700 (epoch 20.296), train_loss = 2.22279846, grad/param norm = 3.0026e-01, time/batch = 0.3228s	
1097/2700 (epoch 20.315), train_loss = 2.26870369, grad/param norm = 3.6642e-01, time/batch = 0.3593s	
1098/2700 (epoch 20.333), train_loss = 2.25215589, grad/param norm = 3.8541e-01, time/batch = 0.3399s	
1099/2700 (epoch 20.352), train_loss = 2.26265333, grad/param norm = 3.6900e-01, time/batch = 0.3493s	
1100/2700 (epoch 20.370), train_loss = 2.25909367, grad/param norm = 2.6276e-01, time/batch = 0.3529s	
1101/2700 (epoch 20.389), train_loss = 2.22163339, grad/param norm = 1.7430e-01, time/batch = 0.3513s	
1102/2700 (epoch 20.407), train_loss = 2.22286563, grad/param norm = 1.7680e-01, time/batch = 0.3403s	
1103/2700 (epoch 20.426), train_loss = 2.24168263, grad/param norm = 1.6882e-01, time/batch = 0.3459s	
1104/2700 (epoch 20.444), train_loss = 2.16833130, grad/param norm = 1.8418e-01, time/batch = 0.3368s	
1105/2700 (epoch 20.463), train_loss = 2.20993175, grad/param norm = 2.5149e-01, time/batch = 0.3463s	
1106/2700 (epoch 20.481), train_loss = 2.25413344, grad/param norm = 3.0732e-01, time/batch = 0.3501s	
1107/2700 (epoch 20.500), train_loss = 2.24308185, grad/param norm = 3.9213e-01, time/batch = 0.3575s	
1108/2700 (epoch 20.519), train_loss = 2.24473574, grad/param norm = 3.7273e-01, time/batch = 0.3439s	
1109/2700 (epoch 20.537), train_loss = 2.23674844, grad/param norm = 2.8636e-01, time/batch = 0.3415s	
1110/2700 (epoch 20.556), train_loss = 2.20962062, grad/param norm = 2.0070e-01, time/batch = 0.3551s	
1111/2700 (epoch 20.574), train_loss = 2.18039829, grad/param norm = 1.5667e-01, time/batch = 0.3955s	
1112/2700 (epoch 20.593), train_loss = 2.16933106, grad/param norm = 1.6879e-01, time/batch = 0.3503s	
1113/2700 (epoch 20.611), train_loss = 2.13344470, grad/param norm = 2.6346e-01, time/batch = 0.3461s	
1114/2700 (epoch 20.630), train_loss = 2.16506388, grad/param norm = 3.5111e-01, time/batch = 0.3487s	
1115/2700 (epoch 20.648), train_loss = 2.21423787, grad/param norm = 4.3282e-01, time/batch = 0.3521s	
1116/2700 (epoch 20.667), train_loss = 2.18537527, grad/param norm = 4.4498e-01, time/batch = 0.3574s	
1117/2700 (epoch 20.685), train_loss = 2.20139773, grad/param norm = 3.9953e-01, time/batch = 0.3669s	
1118/2700 (epoch 20.704), train_loss = 2.22448304, grad/param norm = 3.5086e-01, time/batch = 0.3700s	
1119/2700 (epoch 20.722), train_loss = 2.16914088, grad/param norm = 3.3567e-01, time/batch = 0.3504s	
1120/2700 (epoch 20.741), train_loss = 2.24982125, grad/param norm = 3.5404e-01, time/batch = 0.3683s	
1121/2700 (epoch 20.759), train_loss = 2.24840991, grad/param norm = 3.6849e-01, time/batch = 0.3337s	
1122/2700 (epoch 20.778), train_loss = 2.26529227, grad/param norm = 4.4619e-01, time/batch = 0.3422s	
1123/2700 (epoch 20.796), train_loss = 2.23260112, grad/param norm = 4.3987e-01, time/batch = 0.3490s	
1124/2700 (epoch 20.815), train_loss = 2.25146973, grad/param norm = 3.9543e-01, time/batch = 0.3531s	
1125/2700 (epoch 20.833), train_loss = 2.20567859, grad/param norm = 2.6378e-01, time/batch = 0.3565s	
1126/2700 (epoch 20.852), train_loss = 2.20520840, grad/param norm = 1.2920e-01, time/batch = 0.3557s	
1127/2700 (epoch 20.870), train_loss = 2.17161838, grad/param norm = 1.3447e-01, time/batch = 0.3732s	
1128/2700 (epoch 20.889), train_loss = 2.17710628, grad/param norm = 2.0194e-01, time/batch = 0.3682s	
1129/2700 (epoch 20.907), train_loss = 2.29590243, grad/param norm = 2.4100e-01, time/batch = 0.3680s	
1130/2700 (epoch 20.926), train_loss = 2.23818994, grad/param norm = 2.3777e-01, time/batch = 0.3407s	
1131/2700 (epoch 20.944), train_loss = 2.22683329, grad/param norm = 1.9899e-01, time/batch = 0.3422s	
1132/2700 (epoch 20.963), train_loss = 2.25094065, grad/param norm = 1.8715e-01, time/batch = 0.3456s	
1133/2700 (epoch 20.981), train_loss = 2.20695605, grad/param norm = 2.4469e-01, time/batch = 0.3447s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1134/2700 (epoch 21.000), train_loss = 2.24522496, grad/param norm = 1.9733e-01, time/batch = 0.3447s	
1135/2700 (epoch 21.019), train_loss = 2.21843328, grad/param norm = 2.5643e-01, time/batch = 0.3533s	
1136/2700 (epoch 21.037), train_loss = 2.24742340, grad/param norm = 2.1991e-01, time/batch = 0.3589s	
1137/2700 (epoch 21.056), train_loss = 2.21361526, grad/param norm = 2.8154e-01, time/batch = 0.3537s	
1138/2700 (epoch 21.074), train_loss = 2.17986086, grad/param norm = 2.2243e-01, time/batch = 0.3758s	
1139/2700 (epoch 21.093), train_loss = 2.20252434, grad/param norm = 1.6393e-01, time/batch = 0.3690s	
1140/2700 (epoch 21.111), train_loss = 2.16643165, grad/param norm = 1.7054e-01, time/batch = 0.3744s	
1141/2700 (epoch 21.130), train_loss = 2.21874297, grad/param norm = 2.3474e-01, time/batch = 0.3602s	
1142/2700 (epoch 21.148), train_loss = 2.17234831, grad/param norm = 3.7200e-01, time/batch = 0.3597s	
1143/2700 (epoch 21.167), train_loss = 2.27464832, grad/param norm = 3.8701e-01, time/batch = 0.3686s	
1144/2700 (epoch 21.185), train_loss = 2.19725002, grad/param norm = 3.5646e-01, time/batch = 0.3576s	
1145/2700 (epoch 21.204), train_loss = 2.17892117, grad/param norm = 2.9065e-01, time/batch = 0.3673s	
1146/2700 (epoch 21.222), train_loss = 2.13576631, grad/param norm = 2.4386e-01, time/batch = 0.3166s	
1147/2700 (epoch 21.241), train_loss = 2.09375315, grad/param norm = 2.6940e-01, time/batch = 0.3446s	
1148/2700 (epoch 21.259), train_loss = 2.12231858, grad/param norm = 3.2582e-01, time/batch = 0.3447s	
1149/2700 (epoch 21.278), train_loss = 2.20190848, grad/param norm = 3.4440e-01, time/batch = 0.3520s	
1150/2700 (epoch 21.296), train_loss = 2.19707257, grad/param norm = 3.4153e-01, time/batch = 0.3686s	
1151/2700 (epoch 21.315), train_loss = 2.21158078, grad/param norm = 3.3318e-01, time/batch = 0.3546s	
1152/2700 (epoch 21.333), train_loss = 2.19367932, grad/param norm = 2.9583e-01, time/batch = 0.3560s	
1153/2700 (epoch 21.352), train_loss = 2.19816097, grad/param norm = 2.8912e-01, time/batch = 0.3421s	
1154/2700 (epoch 21.370), train_loss = 2.22540872, grad/param norm = 2.5172e-01, time/batch = 0.3406s	
1155/2700 (epoch 21.389), train_loss = 2.18570831, grad/param norm = 1.8185e-01, time/batch = 0.3008s	
1156/2700 (epoch 21.407), train_loss = 2.19179478, grad/param norm = 1.7104e-01, time/batch = 0.3397s	
1157/2700 (epoch 21.426), train_loss = 2.21549392, grad/param norm = 1.7738e-01, time/batch = 0.3380s	
1158/2700 (epoch 21.444), train_loss = 2.13972768, grad/param norm = 2.5794e-01, time/batch = 0.3391s	
1159/2700 (epoch 21.463), train_loss = 2.18370700, grad/param norm = 3.4523e-01, time/batch = 0.3507s	
1160/2700 (epoch 21.481), train_loss = 2.21649475, grad/param norm = 3.5587e-01, time/batch = 0.3640s	
1161/2700 (epoch 21.500), train_loss = 2.19120044, grad/param norm = 3.3869e-01, time/batch = 0.3708s	
1162/2700 (epoch 21.519), train_loss = 2.19583527, grad/param norm = 3.1883e-01, time/batch = 0.3063s	
1163/2700 (epoch 21.537), train_loss = 2.20639896, grad/param norm = 2.9501e-01, time/batch = 0.3592s	
1164/2700 (epoch 21.556), train_loss = 2.18424337, grad/param norm = 2.9325e-01, time/batch = 0.3119s	
1165/2700 (epoch 21.574), train_loss = 2.15876618, grad/param norm = 2.8458e-01, time/batch = 0.3665s	
1166/2700 (epoch 21.593), train_loss = 2.14836739, grad/param norm = 3.0228e-01, time/batch = 0.3475s	
1167/2700 (epoch 21.611), train_loss = 2.11771101, grad/param norm = 4.0418e-01, time/batch = 0.3530s	
1168/2700 (epoch 21.630), train_loss = 2.13959613, grad/param norm = 4.1108e-01, time/batch = 0.3643s	
1169/2700 (epoch 21.648), train_loss = 2.18355451, grad/param norm = 3.7387e-01, time/batch = 0.3720s	
1170/2700 (epoch 21.667), train_loss = 2.14507241, grad/param norm = 3.6073e-01, time/batch = 0.3737s	
1171/2700 (epoch 21.685), train_loss = 2.16738098, grad/param norm = 3.4890e-01, time/batch = 0.3136s	
1172/2700 (epoch 21.704), train_loss = 2.19074347, grad/param norm = 3.1048e-01, time/batch = 0.3509s	
1173/2700 (epoch 21.722), train_loss = 2.14581589, grad/param norm = 2.6987e-01, time/batch = 0.3455s	
1174/2700 (epoch 21.741), train_loss = 2.21818845, grad/param norm = 2.8168e-01, time/batch = 0.3566s	
1175/2700 (epoch 21.759), train_loss = 2.22655759, grad/param norm = 3.0065e-01, time/batch = 0.3832s	
1176/2700 (epoch 21.778), train_loss = 2.24809719, grad/param norm = 3.2196e-01, time/batch = 0.3467s	
1177/2700 (epoch 21.796), train_loss = 2.18524199, grad/param norm = 2.6493e-01, time/batch = 0.3417s	
1178/2700 (epoch 21.815), train_loss = 2.21711275, grad/param norm = 2.4829e-01, time/batch = 0.3448s	
1179/2700 (epoch 21.833), train_loss = 2.16805747, grad/param norm = 1.8074e-01, time/batch = 0.3521s	
1180/2700 (epoch 21.852), train_loss = 2.18056262, grad/param norm = 1.6231e-01, time/batch = 0.3592s	
1181/2700 (epoch 21.870), train_loss = 2.14518698, grad/param norm = 2.0161e-01, time/batch = 0.3461s	
1182/2700 (epoch 21.889), train_loss = 2.14876475, grad/param norm = 2.2491e-01, time/batch = 0.3280s	
1183/2700 (epoch 21.907), train_loss = 2.26290089, grad/param norm = 2.4899e-01, time/batch = 0.3448s	
1184/2700 (epoch 21.926), train_loss = 2.21664843, grad/param norm = 3.0279e-01, time/batch = 0.3523s	
1185/2700 (epoch 21.944), train_loss = 2.21027320, grad/param norm = 3.0722e-01, time/batch = 0.3545s	
1186/2700 (epoch 21.963), train_loss = 2.22835382, grad/param norm = 2.7153e-01, time/batch = 0.3695s	
1187/2700 (epoch 21.981), train_loss = 2.17613227, grad/param norm = 2.2967e-01, time/batch = 0.3484s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1188/2700 (epoch 22.000), train_loss = 2.21583656, grad/param norm = 1.7142e-01, time/batch = 0.3564s	
1189/2700 (epoch 22.019), train_loss = 2.18579057, grad/param norm = 1.7859e-01, time/batch = 0.3530s	
1190/2700 (epoch 22.037), train_loss = 2.21007147, grad/param norm = 1.4784e-01, time/batch = 0.3201s	
1191/2700 (epoch 22.056), train_loss = 2.16583699, grad/param norm = 1.8104e-01, time/batch = 0.3397s	
1192/2700 (epoch 22.074), train_loss = 2.13821104, grad/param norm = 1.5570e-01, time/batch = 0.3519s	
1193/2700 (epoch 22.093), train_loss = 2.16597375, grad/param norm = 1.7370e-01, time/batch = 0.3486s	
1194/2700 (epoch 22.111), train_loss = 2.13178246, grad/param norm = 2.1500e-01, time/batch = 0.3560s	
1195/2700 (epoch 22.130), train_loss = 2.19190179, grad/param norm = 2.8752e-01, time/batch = 0.3693s	
1196/2700 (epoch 22.148), train_loss = 2.13317771, grad/param norm = 3.4349e-01, time/batch = 0.3790s	
1197/2700 (epoch 22.167), train_loss = 2.22332818, grad/param norm = 2.9840e-01, time/batch = 0.3434s	
1198/2700 (epoch 22.185), train_loss = 2.14868392, grad/param norm = 2.2006e-01, time/batch = 0.3470s	
1199/2700 (epoch 22.204), train_loss = 2.14037255, grad/param norm = 2.6354e-01, time/batch = 0.3245s	
1200/2700 (epoch 22.222), train_loss = 2.11336184, grad/param norm = 3.6114e-01, time/batch = 0.3187s	
1201/2700 (epoch 22.241), train_loss = 2.07735061, grad/param norm = 4.3951e-01, time/batch = 0.3507s	
1202/2700 (epoch 22.259), train_loss = 2.11488154, grad/param norm = 4.3369e-01, time/batch = 0.3525s	
1203/2700 (epoch 22.278), train_loss = 2.16294538, grad/param norm = 3.1135e-01, time/batch = 0.3731s	
1204/2700 (epoch 22.296), train_loss = 2.15330551, grad/param norm = 2.5275e-01, time/batch = 0.3771s	
1205/2700 (epoch 22.315), train_loss = 2.17127552, grad/param norm = 2.5462e-01, time/batch = 0.3937s	
1206/2700 (epoch 22.333), train_loss = 2.16238050, grad/param norm = 3.1434e-01, time/batch = 0.3637s	
1207/2700 (epoch 22.352), train_loss = 2.16797140, grad/param norm = 2.7043e-01, time/batch = 0.3500s	
1208/2700 (epoch 22.370), train_loss = 2.20301196, grad/param norm = 2.1642e-01, time/batch = 0.3006s	
1209/2700 (epoch 22.389), train_loss = 2.17563969, grad/param norm = 2.4865e-01, time/batch = 0.3305s	
1210/2700 (epoch 22.407), train_loss = 2.18847186, grad/param norm = 2.6621e-01, time/batch = 0.3383s	
1211/2700 (epoch 22.426), train_loss = 2.21373338, grad/param norm = 2.3282e-01, time/batch = 0.3516s	
1212/2700 (epoch 22.444), train_loss = 2.13212315, grad/param norm = 2.8549e-01, time/batch = 0.3507s	
1213/2700 (epoch 22.463), train_loss = 2.18247906, grad/param norm = 3.5434e-01, time/batch = 0.3696s	
1214/2700 (epoch 22.481), train_loss = 2.21430825, grad/param norm = 3.7493e-01, time/batch = 0.3606s	
1215/2700 (epoch 22.500), train_loss = 2.19369423, grad/param norm = 3.3925e-01, time/batch = 0.3515s	
1216/2700 (epoch 22.519), train_loss = 2.18076925, grad/param norm = 2.5903e-01, time/batch = 0.3483s	
1217/2700 (epoch 22.537), train_loss = 2.17341982, grad/param norm = 1.8577e-01, time/batch = 0.3434s	
1218/2700 (epoch 22.556), train_loss = 2.14572291, grad/param norm = 1.2034e-01, time/batch = 0.3499s	
1219/2700 (epoch 22.574), train_loss = 2.12455149, grad/param norm = 1.5776e-01, time/batch = 0.3602s	
1220/2700 (epoch 22.593), train_loss = 2.11820843, grad/param norm = 2.0495e-01, time/batch = 0.3730s	
1221/2700 (epoch 22.611), train_loss = 2.08541546, grad/param norm = 3.0171e-01, time/batch = 0.3513s	
1222/2700 (epoch 22.630), train_loss = 2.11271871, grad/param norm = 3.1980e-01, time/batch = 0.3476s	
1223/2700 (epoch 22.648), train_loss = 2.15204754, grad/param norm = 3.3383e-01, time/batch = 0.3458s	
1224/2700 (epoch 22.667), train_loss = 2.11403617, grad/param norm = 3.2881e-01, time/batch = 0.3471s	
1225/2700 (epoch 22.685), train_loss = 2.12836898, grad/param norm = 2.7932e-01, time/batch = 0.3460s	
1226/2700 (epoch 22.704), train_loss = 2.15366847, grad/param norm = 2.5851e-01, time/batch = 0.3458s	
1227/2700 (epoch 22.722), train_loss = 2.10798109, grad/param norm = 2.9658e-01, time/batch = 0.3437s	
1228/2700 (epoch 22.741), train_loss = 2.18897412, grad/param norm = 3.4897e-01, time/batch = 0.3529s	
1229/2700 (epoch 22.759), train_loss = 2.19821951, grad/param norm = 4.1027e-01, time/batch = 0.3501s	
1230/2700 (epoch 22.778), train_loss = 2.21270156, grad/param norm = 4.6567e-01, time/batch = 0.3722s	
1231/2700 (epoch 22.796), train_loss = 2.18643590, grad/param norm = 4.4594e-01, time/batch = 0.3541s	
1232/2700 (epoch 22.815), train_loss = 2.20132613, grad/param norm = 4.0417e-01, time/batch = 0.3505s	
1233/2700 (epoch 22.833), train_loss = 2.15107831, grad/param norm = 2.7465e-01, time/batch = 0.3637s	
1234/2700 (epoch 22.852), train_loss = 2.15266762, grad/param norm = 1.3058e-01, time/batch = 0.3568s	
1235/2700 (epoch 22.870), train_loss = 2.12235268, grad/param norm = 1.3142e-01, time/batch = 0.3588s	
1236/2700 (epoch 22.889), train_loss = 2.12607352, grad/param norm = 1.7168e-01, time/batch = 0.3467s	
1237/2700 (epoch 22.907), train_loss = 2.24123020, grad/param norm = 2.1702e-01, time/batch = 0.3551s	
1238/2700 (epoch 22.926), train_loss = 2.18735114, grad/param norm = 2.1287e-01, time/batch = 0.3696s	
1239/2700 (epoch 22.944), train_loss = 2.17421078, grad/param norm = 1.5475e-01, time/batch = 0.3553s	
1240/2700 (epoch 22.963), train_loss = 2.19466341, grad/param norm = 1.4845e-01, time/batch = 0.3535s	
1241/2700 (epoch 22.981), train_loss = 2.15121683, grad/param norm = 2.0451e-01, time/batch = 0.3674s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1242/2700 (epoch 23.000), train_loss = 2.19278139, grad/param norm = 1.7408e-01, time/batch = 0.3511s	
1243/2700 (epoch 23.019), train_loss = 2.16004999, grad/param norm = 1.7674e-01, time/batch = 0.3585s	
1244/2700 (epoch 23.037), train_loss = 2.18492727, grad/param norm = 1.9451e-01, time/batch = 0.3515s	
1245/2700 (epoch 23.056), train_loss = 2.15282640, grad/param norm = 3.6346e-01, time/batch = 0.3551s	
1246/2700 (epoch 23.074), train_loss = 2.12650585, grad/param norm = 2.6945e-01, time/batch = 0.3662s	
1247/2700 (epoch 23.093), train_loss = 2.13551468, grad/param norm = 1.6694e-01, time/batch = 0.3726s	
1248/2700 (epoch 23.111), train_loss = 2.10069045, grad/param norm = 1.5474e-01, time/batch = 0.3704s	
1249/2700 (epoch 23.130), train_loss = 2.15664922, grad/param norm = 1.6325e-01, time/batch = 0.3874s	
1250/2700 (epoch 23.148), train_loss = 2.09535039, grad/param norm = 2.4203e-01, time/batch = 0.3516s	
1251/2700 (epoch 23.167), train_loss = 2.19095105, grad/param norm = 2.5015e-01, time/batch = 0.3831s	
1252/2700 (epoch 23.185), train_loss = 2.12879916, grad/param norm = 2.1768e-01, time/batch = 0.3535s	
1253/2700 (epoch 23.204), train_loss = 2.12032460, grad/param norm = 1.7935e-01, time/batch = 0.3435s	
1254/2700 (epoch 23.222), train_loss = 2.09016707, grad/param norm = 2.5062e-01, time/batch = 0.3729s	
1255/2700 (epoch 23.241), train_loss = 2.04493380, grad/param norm = 3.7413e-01, time/batch = 0.3803s	
1256/2700 (epoch 23.259), train_loss = 2.09162748, grad/param norm = 4.0090e-01, time/batch = 0.3761s	
1257/2700 (epoch 23.278), train_loss = 2.13705123, grad/param norm = 2.5766e-01, time/batch = 0.3485s	
1258/2700 (epoch 23.296), train_loss = 2.13074412, grad/param norm = 2.0925e-01, time/batch = 0.3454s	
1259/2700 (epoch 23.315), train_loss = 2.14134003, grad/param norm = 2.0433e-01, time/batch = 0.3456s	
1260/2700 (epoch 23.333), train_loss = 2.12884253, grad/param norm = 2.5123e-01, time/batch = 0.3487s	
1261/2700 (epoch 23.352), train_loss = 2.13508220, grad/param norm = 2.2760e-01, time/batch = 0.3538s	
1262/2700 (epoch 23.370), train_loss = 2.17312586, grad/param norm = 2.0759e-01, time/batch = 0.3345s	
1263/2700 (epoch 23.389), train_loss = 2.13043819, grad/param norm = 1.7518e-01, time/batch = 0.3561s	
1264/2700 (epoch 23.407), train_loss = 2.13939104, grad/param norm = 1.6270e-01, time/batch = 0.3412s	
1265/2700 (epoch 23.426), train_loss = 2.17188339, grad/param norm = 1.8883e-01, time/batch = 0.3451s	
1266/2700 (epoch 23.444), train_loss = 2.09727719, grad/param norm = 3.3012e-01, time/batch = 0.3543s	
1267/2700 (epoch 23.463), train_loss = 2.15310348, grad/param norm = 4.2497e-01, time/batch = 0.3703s	
1268/2700 (epoch 23.481), train_loss = 2.17356993, grad/param norm = 3.8711e-01, time/batch = 0.3441s	
1269/2700 (epoch 23.500), train_loss = 2.13232955, grad/param norm = 3.1050e-01, time/batch = 0.3433s	
1270/2700 (epoch 23.519), train_loss = 2.13501184, grad/param norm = 2.4644e-01, time/batch = 0.3449s	
1271/2700 (epoch 23.537), train_loss = 2.14746904, grad/param norm = 2.9535e-01, time/batch = 0.3315s	
1272/2700 (epoch 23.556), train_loss = 2.13484035, grad/param norm = 3.5057e-01, time/batch = 0.3687s	
1273/2700 (epoch 23.574), train_loss = 2.11844563, grad/param norm = 3.8406e-01, time/batch = 0.3517s	
1274/2700 (epoch 23.593), train_loss = 2.11804878, grad/param norm = 3.7024e-01, time/batch = 0.3426s	
1275/2700 (epoch 23.611), train_loss = 2.06694262, grad/param norm = 3.4236e-01, time/batch = 0.3522s	
1276/2700 (epoch 23.630), train_loss = 2.07750867, grad/param norm = 2.2502e-01, time/batch = 0.3552s	
1277/2700 (epoch 23.648), train_loss = 2.11218882, grad/param norm = 1.9020e-01, time/batch = 0.3670s	
1278/2700 (epoch 23.667), train_loss = 2.07983220, grad/param norm = 2.5988e-01, time/batch = 0.3433s	
1279/2700 (epoch 23.685), train_loss = 2.10986009, grad/param norm = 2.6391e-01, time/batch = 0.3507s	
1280/2700 (epoch 23.704), train_loss = 2.12337219, grad/param norm = 1.9969e-01, time/batch = 0.3408s	
1281/2700 (epoch 23.722), train_loss = 2.07334364, grad/param norm = 1.8699e-01, time/batch = 0.3246s	
1282/2700 (epoch 23.741), train_loss = 2.15353459, grad/param norm = 2.6037e-01, time/batch = 0.3603s	
1283/2700 (epoch 23.759), train_loss = 2.18358290, grad/param norm = 3.5624e-01, time/batch = 0.3490s	
1284/2700 (epoch 23.778), train_loss = 2.19287557, grad/param norm = 4.5896e-01, time/batch = 0.3527s	
1285/2700 (epoch 23.796), train_loss = 2.16341030, grad/param norm = 4.2245e-01, time/batch = 0.3594s	
1286/2700 (epoch 23.815), train_loss = 2.17546944, grad/param norm = 3.1253e-01, time/batch = 0.3707s	
1287/2700 (epoch 23.833), train_loss = 2.12840791, grad/param norm = 2.6532e-01, time/batch = 0.3685s	
1288/2700 (epoch 23.852), train_loss = 2.13725348, grad/param norm = 2.4973e-01, time/batch = 0.3558s	
1289/2700 (epoch 23.870), train_loss = 2.10456042, grad/param norm = 2.4562e-01, time/batch = 0.3519s	
1290/2700 (epoch 23.889), train_loss = 2.10308496, grad/param norm = 2.0366e-01, time/batch = 0.3220s	
1291/2700 (epoch 23.907), train_loss = 2.21036029, grad/param norm = 1.7169e-01, time/batch = 0.3462s	
1292/2700 (epoch 23.926), train_loss = 2.15720502, grad/param norm = 1.7263e-01, time/batch = 0.3423s	
1293/2700 (epoch 23.944), train_loss = 2.14707873, grad/param norm = 1.5829e-01, time/batch = 0.3530s	
1294/2700 (epoch 23.963), train_loss = 2.17174599, grad/param norm = 1.9681e-01, time/batch = 0.3563s	
1295/2700 (epoch 23.981), train_loss = 2.13622487, grad/param norm = 3.1999e-01, time/batch = 0.3614s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1296/2700 (epoch 24.000), train_loss = 2.18889791, grad/param norm = 3.3322e-01, time/batch = 0.3741s	
1297/2700 (epoch 24.019), train_loss = 2.14848067, grad/param norm = 3.2963e-01, time/batch = 0.3831s	
1298/2700 (epoch 24.037), train_loss = 2.17341477, grad/param norm = 3.3448e-01, time/batch = 0.3590s	
1299/2700 (epoch 24.056), train_loss = 2.12634090, grad/param norm = 3.6131e-01, time/batch = 0.3173s	
1300/2700 (epoch 24.074), train_loss = 2.09348530, grad/param norm = 2.6126e-01, time/batch = 0.3651s	
1301/2700 (epoch 24.093), train_loss = 2.11451626, grad/param norm = 2.6748e-01, time/batch = 0.3448s	
1302/2700 (epoch 24.111), train_loss = 2.08501830, grad/param norm = 2.7788e-01, time/batch = 0.3433s	
1303/2700 (epoch 24.130), train_loss = 2.13828051, grad/param norm = 2.7287e-01, time/batch = 0.3500s	
1304/2700 (epoch 24.148), train_loss = 2.07500627, grad/param norm = 3.3966e-01, time/batch = 0.3604s	
1305/2700 (epoch 24.167), train_loss = 2.17375566, grad/param norm = 3.1961e-01, time/batch = 0.3596s	
1306/2700 (epoch 24.185), train_loss = 2.10415600, grad/param norm = 2.5963e-01, time/batch = 0.3753s	
1307/2700 (epoch 24.204), train_loss = 2.10137656, grad/param norm = 3.0618e-01, time/batch = 0.3644s	
1308/2700 (epoch 24.222), train_loss = 2.06969129, grad/param norm = 3.0077e-01, time/batch = 0.3535s	
1309/2700 (epoch 24.241), train_loss = 2.00399677, grad/param norm = 2.5556e-01, time/batch = 0.4029s	
1310/2700 (epoch 24.259), train_loss = 2.02390777, grad/param norm = 1.7663e-01, time/batch = 0.3514s	
1311/2700 (epoch 24.278), train_loss = 2.09163279, grad/param norm = 1.0782e-01, time/batch = 0.3817s	
1312/2700 (epoch 24.296), train_loss = 2.09501530, grad/param norm = 1.4419e-01, time/batch = 0.3505s	
1313/2700 (epoch 24.315), train_loss = 2.10982495, grad/param norm = 1.5919e-01, time/batch = 0.3470s	
1314/2700 (epoch 24.333), train_loss = 2.09625958, grad/param norm = 1.7112e-01, time/batch = 0.3560s	
1315/2700 (epoch 24.352), train_loss = 2.09899556, grad/param norm = 1.6171e-01, time/batch = 0.3447s	
1316/2700 (epoch 24.370), train_loss = 2.14455088, grad/param norm = 1.7020e-01, time/batch = 0.2977s	
1317/2700 (epoch 24.389), train_loss = 2.12402610, grad/param norm = 2.6116e-01, time/batch = 0.3437s	
1318/2700 (epoch 24.407), train_loss = 2.14301545, grad/param norm = 3.5920e-01, time/batch = 0.3441s	
1319/2700 (epoch 24.426), train_loss = 2.17130408, grad/param norm = 3.1827e-01, time/batch = 0.3432s	
1320/2700 (epoch 24.444), train_loss = 2.08282904, grad/param norm = 2.9097e-01, time/batch = 0.3516s	
1321/2700 (epoch 24.463), train_loss = 2.12229221, grad/param norm = 3.0742e-01, time/batch = 0.3747s	
1322/2700 (epoch 24.481), train_loss = 2.14229236, grad/param norm = 2.6893e-01, time/batch = 0.3866s	
1323/2700 (epoch 24.500), train_loss = 2.11227398, grad/param norm = 2.7354e-01, time/batch = 0.3090s	
1324/2700 (epoch 24.519), train_loss = 2.12220999, grad/param norm = 2.5978e-01, time/batch = 0.3444s	
1325/2700 (epoch 24.537), train_loss = 2.12976514, grad/param norm = 2.0498e-01, time/batch = 0.3477s	
1326/2700 (epoch 24.556), train_loss = 2.09468903, grad/param norm = 1.4928e-01, time/batch = 0.3521s	
1327/2700 (epoch 24.574), train_loss = 2.07406513, grad/param norm = 1.5348e-01, time/batch = 0.3538s	
1328/2700 (epoch 24.593), train_loss = 2.06616603, grad/param norm = 1.6954e-01, time/batch = 0.3602s	
1329/2700 (epoch 24.611), train_loss = 2.03633764, grad/param norm = 2.3325e-01, time/batch = 0.3735s	
1330/2700 (epoch 24.630), train_loss = 2.05517320, grad/param norm = 2.3124e-01, time/batch = 0.3770s	
1331/2700 (epoch 24.648), train_loss = 2.09215464, grad/param norm = 2.3563e-01, time/batch = 0.3634s	
1332/2700 (epoch 24.667), train_loss = 2.05893021, grad/param norm = 2.8833e-01, time/batch = 0.3477s	
1333/2700 (epoch 24.685), train_loss = 2.08139012, grad/param norm = 3.3728e-01, time/batch = 0.3509s	
1334/2700 (epoch 24.704), train_loss = 2.10701760, grad/param norm = 3.3524e-01, time/batch = 0.3292s	
1335/2700 (epoch 24.722), train_loss = 2.06188202, grad/param norm = 3.4708e-01, time/batch = 0.3487s	
1336/2700 (epoch 24.741), train_loss = 2.13454577, grad/param norm = 3.6166e-01, time/batch = 0.3519s	
1337/2700 (epoch 24.759), train_loss = 2.14651018, grad/param norm = 3.4364e-01, time/batch = 0.3669s	
1338/2700 (epoch 24.778), train_loss = 2.14367583, grad/param norm = 3.7076e-01, time/batch = 0.3684s	
1339/2700 (epoch 24.796), train_loss = 2.11870479, grad/param norm = 3.8230e-01, time/batch = 0.3612s	
1340/2700 (epoch 24.815), train_loss = 2.15298943, grad/param norm = 3.5645e-01, time/batch = 0.3758s	
1341/2700 (epoch 24.833), train_loss = 2.11091949, grad/param norm = 3.4338e-01, time/batch = 0.3505s	
1342/2700 (epoch 24.852), train_loss = 2.11802484, grad/param norm = 2.9570e-01, time/batch = 0.3529s	
1343/2700 (epoch 24.870), train_loss = 2.07972362, grad/param norm = 2.6689e-01, time/batch = 0.3372s	
1344/2700 (epoch 24.889), train_loss = 2.07783090, grad/param norm = 2.2037e-01, time/batch = 0.3625s	
1345/2700 (epoch 24.907), train_loss = 2.18416167, grad/param norm = 1.8763e-01, time/batch = 0.3543s	
1346/2700 (epoch 24.926), train_loss = 2.13533273, grad/param norm = 1.7613e-01, time/batch = 0.3754s	
1347/2700 (epoch 24.944), train_loss = 2.11865998, grad/param norm = 1.4333e-01, time/batch = 0.3773s	
1348/2700 (epoch 24.963), train_loss = 2.13938769, grad/param norm = 1.6418e-01, time/batch = 0.3814s	
1349/2700 (epoch 24.981), train_loss = 2.10113684, grad/param norm = 2.6398e-01, time/batch = 0.3582s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1350/2700 (epoch 25.000), train_loss = 2.14670964, grad/param norm = 2.6030e-01, time/batch = 0.3503s	
1351/2700 (epoch 25.019), train_loss = 2.12072155, grad/param norm = 2.7508e-01, time/batch = 0.3669s	
1352/2700 (epoch 25.037), train_loss = 2.13884037, grad/param norm = 2.7254e-01, time/batch = 0.3441s	
1353/2700 (epoch 25.056), train_loss = 2.09001086, grad/param norm = 2.8381e-01, time/batch = 0.3717s	
1354/2700 (epoch 25.074), train_loss = 2.07400215, grad/param norm = 2.8921e-01, time/batch = 0.3716s	
1355/2700 (epoch 25.093), train_loss = 2.10877825, grad/param norm = 3.5465e-01, time/batch = 0.3990s	
1356/2700 (epoch 25.111), train_loss = 2.08569194, grad/param norm = 3.3353e-01, time/batch = 0.3437s	
1357/2700 (epoch 25.130), train_loss = 2.13613152, grad/param norm = 3.0776e-01, time/batch = 0.3463s	
1358/2700 (epoch 25.148), train_loss = 2.06815620, grad/param norm = 3.8787e-01, time/batch = 0.3479s	
1359/2700 (epoch 25.167), train_loss = 2.15750450, grad/param norm = 3.3439e-01, time/batch = 0.3514s	
1360/2700 (epoch 25.185), train_loss = 2.07175735, grad/param norm = 1.9077e-01, time/batch = 0.3642s	
1361/2700 (epoch 25.204), train_loss = 2.05946119, grad/param norm = 1.2114e-01, time/batch = 0.3570s	
1362/2700 (epoch 25.222), train_loss = 2.02921346, grad/param norm = 1.3375e-01, time/batch = 0.3492s	
1363/2700 (epoch 25.241), train_loss = 1.96568201, grad/param norm = 1.1817e-01, time/batch = 0.3496s	
1364/2700 (epoch 25.259), train_loss = 1.99449299, grad/param norm = 1.2650e-01, time/batch = 0.3523s	
1365/2700 (epoch 25.278), train_loss = 2.07249421, grad/param norm = 1.6096e-01, time/batch = 0.3562s	
1366/2700 (epoch 25.296), train_loss = 2.07785005, grad/param norm = 1.9091e-01, time/batch = 0.3883s	
1367/2700 (epoch 25.315), train_loss = 2.08735955, grad/param norm = 1.9080e-01, time/batch = 0.3434s	
1368/2700 (epoch 25.333), train_loss = 2.07269974, grad/param norm = 1.8000e-01, time/batch = 0.3417s	
1369/2700 (epoch 25.352), train_loss = 2.07559927, grad/param norm = 1.8995e-01, time/batch = 0.3404s	
1370/2700 (epoch 25.370), train_loss = 2.12101586, grad/param norm = 2.1000e-01, time/batch = 0.3633s	
1371/2700 (epoch 25.389), train_loss = 2.09321920, grad/param norm = 2.4728e-01, time/batch = 0.3508s	
1372/2700 (epoch 25.407), train_loss = 2.10812432, grad/param norm = 3.4462e-01, time/batch = 0.3457s	
1373/2700 (epoch 25.426), train_loss = 2.14407428, grad/param norm = 3.4200e-01, time/batch = 0.3423s	
1374/2700 (epoch 25.444), train_loss = 2.06356419, grad/param norm = 3.7856e-01, time/batch = 0.3557s	
1375/2700 (epoch 25.463), train_loss = 2.10547242, grad/param norm = 3.8343e-01, time/batch = 0.3688s	
1376/2700 (epoch 25.481), train_loss = 2.11494592, grad/param norm = 3.0177e-01, time/batch = 0.3754s	
1377/2700 (epoch 25.500), train_loss = 2.07928482, grad/param norm = 2.5946e-01, time/batch = 0.3458s	
1378/2700 (epoch 25.519), train_loss = 2.08892838, grad/param norm = 2.0553e-01, time/batch = 0.3406s	
1379/2700 (epoch 25.537), train_loss = 2.09708994, grad/param norm = 2.0638e-01, time/batch = 0.3564s	
1380/2700 (epoch 25.556), train_loss = 2.07225906, grad/param norm = 2.1952e-01, time/batch = 0.3260s	
1381/2700 (epoch 25.574), train_loss = 2.05257769, grad/param norm = 2.5312e-01, time/batch = 0.3552s	
1382/2700 (epoch 25.593), train_loss = 2.05079744, grad/param norm = 3.0972e-01, time/batch = 0.3472s	
1383/2700 (epoch 25.611), train_loss = 2.02459241, grad/param norm = 3.9454e-01, time/batch = 0.3499s	
1384/2700 (epoch 25.630), train_loss = 2.04030354, grad/param norm = 3.6903e-01, time/batch = 0.3509s	
1385/2700 (epoch 25.648), train_loss = 2.07452436, grad/param norm = 3.1256e-01, time/batch = 0.3621s	
1386/2700 (epoch 25.667), train_loss = 2.03566056, grad/param norm = 3.2363e-01, time/batch = 0.3707s	
1387/2700 (epoch 25.685), train_loss = 2.06046424, grad/param norm = 3.3938e-01, time/batch = 0.3548s	
1388/2700 (epoch 25.704), train_loss = 2.09753084, grad/param norm = 3.8846e-01, time/batch = 0.3792s	
1389/2700 (epoch 25.722), train_loss = 2.06695329, grad/param norm = 3.3226e-01, time/batch = 0.3521s	
1390/2700 (epoch 25.741), train_loss = 2.10976737, grad/param norm = 2.3677e-01, time/batch = 0.3745s	
1391/2700 (epoch 25.759), train_loss = 2.11472430, grad/param norm = 2.2597e-01, time/batch = 0.3532s	
1392/2700 (epoch 25.778), train_loss = 2.11531995, grad/param norm = 2.4100e-01, time/batch = 0.3740s	
1393/2700 (epoch 25.796), train_loss = 2.07499395, grad/param norm = 2.3020e-01, time/batch = 0.3815s	
1394/2700 (epoch 25.815), train_loss = 2.11356222, grad/param norm = 2.5564e-01, time/batch = 0.3966s	
1395/2700 (epoch 25.833), train_loss = 2.07168046, grad/param norm = 2.2853e-01, time/batch = 0.3518s	
1396/2700 (epoch 25.852), train_loss = 2.08125894, grad/param norm = 1.5321e-01, time/batch = 0.3040s	
1397/2700 (epoch 25.870), train_loss = 2.04978840, grad/param norm = 1.5268e-01, time/batch = 0.3451s	
1398/2700 (epoch 25.889), train_loss = 2.05120147, grad/param norm = 1.5521e-01, time/batch = 0.3332s	
1399/2700 (epoch 25.907), train_loss = 2.16101811, grad/param norm = 2.2199e-01, time/batch = 0.3450s	
1400/2700 (epoch 25.926), train_loss = 2.11728664, grad/param norm = 2.4897e-01, time/batch = 0.3423s	
1401/2700 (epoch 25.944), train_loss = 2.10676491, grad/param norm = 2.1682e-01, time/batch = 0.3540s	
1402/2700 (epoch 25.963), train_loss = 2.12160015, grad/param norm = 2.1007e-01, time/batch = 0.3598s	
1403/2700 (epoch 25.981), train_loss = 2.08192295, grad/param norm = 2.5470e-01, time/batch = 0.3741s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1404/2700 (epoch 26.000), train_loss = 2.12947973, grad/param norm = 2.3238e-01, time/batch = 0.3635s	
1405/2700 (epoch 26.019), train_loss = 2.09266134, grad/param norm = 2.1658e-01, time/batch = 0.3025s	
1406/2700 (epoch 26.037), train_loss = 2.11036983, grad/param norm = 1.9255e-01, time/batch = 0.3570s	
1407/2700 (epoch 26.056), train_loss = 2.05938082, grad/param norm = 2.2040e-01, time/batch = 0.3254s	
1408/2700 (epoch 26.074), train_loss = 2.03647202, grad/param norm = 2.0109e-01, time/batch = 0.3670s	
1409/2700 (epoch 26.093), train_loss = 2.06164171, grad/param norm = 2.7404e-01, time/batch = 0.3579s	
1410/2700 (epoch 26.111), train_loss = 2.03852280, grad/param norm = 3.0597e-01, time/batch = 0.3512s	
1411/2700 (epoch 26.130), train_loss = 2.09555904, grad/param norm = 3.1904e-01, time/batch = 0.3761s	
1412/2700 (epoch 26.148), train_loss = 2.02879976, grad/param norm = 3.6898e-01, time/batch = 0.3529s	
1413/2700 (epoch 26.167), train_loss = 2.13085275, grad/param norm = 3.4395e-01, time/batch = 0.3513s	
1414/2700 (epoch 26.185), train_loss = 2.05306530, grad/param norm = 2.7589e-01, time/batch = 0.3081s	
1415/2700 (epoch 26.204), train_loss = 2.05332085, grad/param norm = 3.2297e-01, time/batch = 0.3471s	
1416/2700 (epoch 26.222), train_loss = 2.02547789, grad/param norm = 3.3586e-01, time/batch = 0.3456s	
1417/2700 (epoch 26.241), train_loss = 1.95876719, grad/param norm = 3.2935e-01, time/batch = 0.3429s	
1418/2700 (epoch 26.259), train_loss = 1.98234317, grad/param norm = 2.5997e-01, time/batch = 0.3446s	
1419/2700 (epoch 26.278), train_loss = 2.05344087, grad/param norm = 1.8619e-01, time/batch = 0.3455s	
1420/2700 (epoch 26.296), train_loss = 2.05958335, grad/param norm = 2.1305e-01, time/batch = 0.3583s	
1421/2700 (epoch 26.315), train_loss = 2.06927918, grad/param norm = 2.5481e-01, time/batch = 0.3959s	
1422/2700 (epoch 26.333), train_loss = 2.06612356, grad/param norm = 2.9397e-01, time/batch = 0.3669s	
1423/2700 (epoch 26.352), train_loss = 2.06182556, grad/param norm = 2.5709e-01, time/batch = 0.2913s	
1424/2700 (epoch 26.370), train_loss = 2.11011092, grad/param norm = 2.4523e-01, time/batch = 0.3508s	
1425/2700 (epoch 26.389), train_loss = 2.07971418, grad/param norm = 3.2631e-01, time/batch = 0.3476s	
1426/2700 (epoch 26.407), train_loss = 2.08650048, grad/param norm = 3.1812e-01, time/batch = 0.3451s	
1427/2700 (epoch 26.426), train_loss = 2.10612798, grad/param norm = 2.0422e-01, time/batch = 0.3434s	
1428/2700 (epoch 26.444), train_loss = 2.01812417, grad/param norm = 1.8716e-01, time/batch = 0.3454s	
1429/2700 (epoch 26.463), train_loss = 2.05803718, grad/param norm = 1.9771e-01, time/batch = 0.3587s	
1430/2700 (epoch 26.481), train_loss = 2.08026375, grad/param norm = 1.5860e-01, time/batch = 0.3542s	
1431/2700 (epoch 26.500), train_loss = 2.05087481, grad/param norm = 2.3023e-01, time/batch = 0.4050s	
1432/2700 (epoch 26.519), train_loss = 2.06571994, grad/param norm = 2.3644e-01, time/batch = 0.2900s	
1433/2700 (epoch 26.537), train_loss = 2.07580181, grad/param norm = 1.8795e-01, time/batch = 0.3521s	
1434/2700 (epoch 26.556), train_loss = 2.04669330, grad/param norm = 1.6977e-01, time/batch = 0.3213s	
1435/2700 (epoch 26.574), train_loss = 2.02820744, grad/param norm = 1.6730e-01, time/batch = 0.3654s	
1436/2700 (epoch 26.593), train_loss = 2.02069918, grad/param norm = 1.7288e-01, time/batch = 0.3429s	
1437/2700 (epoch 26.611), train_loss = 1.99043635, grad/param norm = 2.3411e-01, time/batch = 0.3459s	
1438/2700 (epoch 26.630), train_loss = 2.01836014, grad/param norm = 2.9600e-01, time/batch = 0.3393s	
1439/2700 (epoch 26.648), train_loss = 2.05442759, grad/param norm = 2.8105e-01, time/batch = 0.3467s	
1440/2700 (epoch 26.667), train_loss = 2.01602634, grad/param norm = 2.3983e-01, time/batch = 0.3600s	
1441/2700 (epoch 26.685), train_loss = 2.03502998, grad/param norm = 2.5334e-01, time/batch = 0.3523s	
1442/2700 (epoch 26.704), train_loss = 2.06622457, grad/param norm = 2.8630e-01, time/batch = 0.3504s	
1443/2700 (epoch 26.722), train_loss = 2.01344727, grad/param norm = 2.7257e-01, time/batch = 0.3361s	
1444/2700 (epoch 26.741), train_loss = 2.08832885, grad/param norm = 2.9980e-01, time/batch = 0.3828s	
1445/2700 (epoch 26.759), train_loss = 2.11071749, grad/param norm = 3.9457e-01, time/batch = 0.3454s	
1446/2700 (epoch 26.778), train_loss = 2.11267392, grad/param norm = 4.3285e-01, time/batch = 0.3486s	
1447/2700 (epoch 26.796), train_loss = 2.08192791, grad/param norm = 4.1825e-01, time/batch = 0.3479s	
1448/2700 (epoch 26.815), train_loss = 2.10631818, grad/param norm = 3.9861e-01, time/batch = 0.3568s	
1449/2700 (epoch 26.833), train_loss = 2.06296581, grad/param norm = 3.3703e-01, time/batch = 0.3703s	
1450/2700 (epoch 26.852), train_loss = 2.06601992, grad/param norm = 2.1325e-01, time/batch = 0.3760s	
1451/2700 (epoch 26.870), train_loss = 2.03292100, grad/param norm = 1.9648e-01, time/batch = 0.3571s	
1452/2700 (epoch 26.889), train_loss = 2.03816238, grad/param norm = 2.0893e-01, time/batch = 0.3450s	
1453/2700 (epoch 26.907), train_loss = 2.14635562, grad/param norm = 2.8142e-01, time/batch = 0.3635s	
1454/2700 (epoch 26.926), train_loss = 2.09433533, grad/param norm = 2.8155e-01, time/batch = 0.3567s	
1455/2700 (epoch 26.944), train_loss = 2.08471006, grad/param norm = 2.5157e-01, time/batch = 0.3562s	
1456/2700 (epoch 26.963), train_loss = 2.10351128, grad/param norm = 2.6199e-01, time/batch = 0.3729s	
1457/2700 (epoch 26.981), train_loss = 2.05992198, grad/param norm = 2.8953e-01, time/batch = 0.3737s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1458/2700 (epoch 27.000), train_loss = 2.10322667, grad/param norm = 3.0868e-01, time/batch = 0.3912s	
1459/2700 (epoch 27.019), train_loss = 2.08621423, grad/param norm = 3.2874e-01, time/batch = 0.3264s	
1460/2700 (epoch 27.037), train_loss = 2.12156042, grad/param norm = 3.8908e-01, time/batch = 0.3454s	
1461/2700 (epoch 27.056), train_loss = 2.07525517, grad/param norm = 4.0926e-01, time/batch = 0.3675s	
1462/2700 (epoch 27.074), train_loss = 2.04461099, grad/param norm = 2.7941e-01, time/batch = 0.3520s	
1463/2700 (epoch 27.093), train_loss = 2.04997014, grad/param norm = 2.5736e-01, time/batch = 0.3554s	
1464/2700 (epoch 27.111), train_loss = 2.01406877, grad/param norm = 2.1226e-01, time/batch = 0.3614s	
1465/2700 (epoch 27.130), train_loss = 2.06896736, grad/param norm = 2.2562e-01, time/batch = 0.3692s	
1466/2700 (epoch 27.148), train_loss = 1.99304767, grad/param norm = 2.6457e-01, time/batch = 0.3739s	
1467/2700 (epoch 27.167), train_loss = 2.08592630, grad/param norm = 2.0758e-01, time/batch = 0.3584s	
1468/2700 (epoch 27.185), train_loss = 2.01916312, grad/param norm = 1.9356e-01, time/batch = 0.3356s	
1469/2700 (epoch 27.204), train_loss = 2.01785547, grad/param norm = 2.0015e-01, time/batch = 0.3589s	
1470/2700 (epoch 27.222), train_loss = 1.99519153, grad/param norm = 2.3722e-01, time/batch = 0.3232s	
1471/2700 (epoch 27.241), train_loss = 1.93127619, grad/param norm = 2.8430e-01, time/batch = 0.3664s	
1472/2700 (epoch 27.259), train_loss = 1.96865914, grad/param norm = 3.2872e-01, time/batch = 0.3512s	
1473/2700 (epoch 27.278), train_loss = 2.04991030, grad/param norm = 3.2686e-01, time/batch = 0.3510s	
1474/2700 (epoch 27.296), train_loss = 2.04664361, grad/param norm = 3.2265e-01, time/batch = 0.3646s	
1475/2700 (epoch 27.315), train_loss = 2.04701065, grad/param norm = 2.8602e-01, time/batch = 0.3771s	
1476/2700 (epoch 27.333), train_loss = 2.02902356, grad/param norm = 2.3251e-01, time/batch = 0.3717s	
1477/2700 (epoch 27.352), train_loss = 2.02623888, grad/param norm = 2.0529e-01, time/batch = 0.3435s	
1478/2700 (epoch 27.370), train_loss = 2.07280985, grad/param norm = 1.8521e-01, time/batch = 0.3653s	
1479/2700 (epoch 27.389), train_loss = 2.03466737, grad/param norm = 2.1008e-01, time/batch = 0.3442s	
1480/2700 (epoch 27.407), train_loss = 2.06275182, grad/param norm = 2.8957e-01, time/batch = 0.3924s	
1481/2700 (epoch 27.426), train_loss = 2.09375536, grad/param norm = 2.3386e-01, time/batch = 0.3745s	
1482/2700 (epoch 27.444), train_loss = 2.01430248, grad/param norm = 3.5052e-01, time/batch = 0.3785s	
1483/2700 (epoch 27.463), train_loss = 2.05957952, grad/param norm = 3.5988e-01, time/batch = 0.3639s	
1484/2700 (epoch 27.481), train_loss = 2.06970223, grad/param norm = 2.2139e-01, time/batch = 0.3547s	
1485/2700 (epoch 27.500), train_loss = 2.02061891, grad/param norm = 1.5582e-01, time/batch = 0.3444s	
1486/2700 (epoch 27.519), train_loss = 2.03598214, grad/param norm = 1.4742e-01, time/batch = 0.2964s	
1487/2700 (epoch 27.537), train_loss = 2.05647648, grad/param norm = 2.3575e-01, time/batch = 0.3515s	
1488/2700 (epoch 27.556), train_loss = 2.03398586, grad/param norm = 2.6794e-01, time/batch = 0.3614s	
1489/2700 (epoch 27.574), train_loss = 2.01753819, grad/param norm = 3.0381e-01, time/batch = 0.3609s	
1490/2700 (epoch 27.593), train_loss = 2.01582131, grad/param norm = 3.1168e-01, time/batch = 0.3509s	
1491/2700 (epoch 27.611), train_loss = 1.97624140, grad/param norm = 3.2273e-01, time/batch = 0.4027s	
1492/2700 (epoch 27.630), train_loss = 1.98837392, grad/param norm = 2.8031e-01, time/batch = 0.3576s	
1493/2700 (epoch 27.648), train_loss = 2.01763206, grad/param norm = 2.5637e-01, time/batch = 0.3471s	
1494/2700 (epoch 27.667), train_loss = 1.99390082, grad/param norm = 2.8998e-01, time/batch = 0.3492s	
1495/2700 (epoch 27.685), train_loss = 2.01429531, grad/param norm = 3.0710e-01, time/batch = 0.3126s	
1496/2700 (epoch 27.704), train_loss = 2.06161142, grad/param norm = 3.4810e-01, time/batch = 0.3345s	
1497/2700 (epoch 27.722), train_loss = 2.00321773, grad/param norm = 3.9318e-01, time/batch = 0.3435s	
1498/2700 (epoch 27.741), train_loss = 2.07299863, grad/param norm = 3.9915e-01, time/batch = 0.3430s	
1499/2700 (epoch 27.759), train_loss = 2.07525658, grad/param norm = 3.7817e-01, time/batch = 0.3577s	
1500/2700 (epoch 27.778), train_loss = 2.08148309, grad/param norm = 3.8301e-01, time/batch = 0.3731s	
1501/2700 (epoch 27.796), train_loss = 2.04166300, grad/param norm = 3.4052e-01, time/batch = 0.3831s	
1502/2700 (epoch 27.815), train_loss = 2.07195227, grad/param norm = 2.9440e-01, time/batch = 0.3528s	
1503/2700 (epoch 27.833), train_loss = 2.02816647, grad/param norm = 2.1168e-01, time/batch = 0.3500s	
1504/2700 (epoch 27.852), train_loss = 2.03668061, grad/param norm = 1.5647e-01, time/batch = 0.3369s	
1505/2700 (epoch 27.870), train_loss = 2.01182497, grad/param norm = 1.6729e-01, time/batch = 0.3559s	
1506/2700 (epoch 27.889), train_loss = 2.01515472, grad/param norm = 1.8888e-01, time/batch = 0.3540s	
1507/2700 (epoch 27.907), train_loss = 2.12454706, grad/param norm = 2.2881e-01, time/batch = 0.3618s	
1508/2700 (epoch 27.926), train_loss = 2.07210899, grad/param norm = 2.1858e-01, time/batch = 0.3845s	
1509/2700 (epoch 27.944), train_loss = 2.06240565, grad/param norm = 1.7275e-01, time/batch = 0.3836s	
1510/2700 (epoch 27.963), train_loss = 2.07607421, grad/param norm = 1.5445e-01, time/batch = 0.3681s	
1511/2700 (epoch 27.981), train_loss = 2.04064528, grad/param norm = 2.0343e-01, time/batch = 0.3569s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1512/2700 (epoch 28.000), train_loss = 2.07936990, grad/param norm = 1.8695e-01, time/batch = 0.3752s	
1513/2700 (epoch 28.019), train_loss = 2.05466646, grad/param norm = 2.2212e-01, time/batch = 0.3490s	
1514/2700 (epoch 28.037), train_loss = 2.07046259, grad/param norm = 1.6486e-01, time/batch = 0.3569s	
1515/2700 (epoch 28.056), train_loss = 2.01791731, grad/param norm = 2.3188e-01, time/batch = 0.3693s	
1516/2700 (epoch 28.074), train_loss = 1.99507037, grad/param norm = 1.7482e-01, time/batch = 0.3766s	
1517/2700 (epoch 28.093), train_loss = 2.00462993, grad/param norm = 1.2312e-01, time/batch = 0.3701s	
1518/2700 (epoch 28.111), train_loss = 1.97671627, grad/param norm = 1.4082e-01, time/batch = 0.3718s	
1519/2700 (epoch 28.130), train_loss = 2.04455768, grad/param norm = 2.1379e-01, time/batch = 0.3582s	
1520/2700 (epoch 28.148), train_loss = 1.97831980, grad/param norm = 3.2889e-01, time/batch = 0.3596s	
1521/2700 (epoch 28.167), train_loss = 2.08902553, grad/param norm = 3.4446e-01, time/batch = 0.3584s	
1522/2700 (epoch 28.185), train_loss = 2.02698277, grad/param norm = 3.4003e-01, time/batch = 0.3389s	
1523/2700 (epoch 28.204), train_loss = 2.02697141, grad/param norm = 3.1184e-01, time/batch = 0.3058s	
1524/2700 (epoch 28.222), train_loss = 1.99569213, grad/param norm = 3.1284e-01, time/batch = 0.3767s	
1525/2700 (epoch 28.241), train_loss = 1.92832365, grad/param norm = 3.1645e-01, time/batch = 0.3670s	
1526/2700 (epoch 28.259), train_loss = 1.95567713, grad/param norm = 2.6660e-01, time/batch = 0.3486s	
1527/2700 (epoch 28.278), train_loss = 2.02046494, grad/param norm = 1.8913e-01, time/batch = 0.3489s	
1528/2700 (epoch 28.296), train_loss = 2.01291082, grad/param norm = 1.5732e-01, time/batch = 0.3586s	
1529/2700 (epoch 28.315), train_loss = 2.01370262, grad/param norm = 1.4951e-01, time/batch = 0.3569s	
1530/2700 (epoch 28.333), train_loss = 2.00344169, grad/param norm = 2.0571e-01, time/batch = 0.3797s	
1531/2700 (epoch 28.352), train_loss = 2.00725013, grad/param norm = 2.4071e-01, time/batch = 0.3416s	
1532/2700 (epoch 28.370), train_loss = 2.06008309, grad/param norm = 2.6746e-01, time/batch = 0.3088s	
1533/2700 (epoch 28.389), train_loss = 2.02982416, grad/param norm = 3.8552e-01, time/batch = 0.3524s	
1534/2700 (epoch 28.407), train_loss = 2.05054798, grad/param norm = 3.8232e-01, time/batch = 0.3645s	
1535/2700 (epoch 28.426), train_loss = 2.06502366, grad/param norm = 2.3775e-01, time/batch = 0.3444s	
1536/2700 (epoch 28.444), train_loss = 1.97749046, grad/param norm = 1.5858e-01, time/batch = 0.3477s	
1537/2700 (epoch 28.463), train_loss = 2.01592340, grad/param norm = 1.6100e-01, time/batch = 0.3530s	
1538/2700 (epoch 28.481), train_loss = 2.03942111, grad/param norm = 1.7981e-01, time/batch = 0.3576s	
1539/2700 (epoch 28.500), train_loss = 2.00414438, grad/param norm = 2.7184e-01, time/batch = 0.3691s	
1540/2700 (epoch 28.519), train_loss = 2.02729355, grad/param norm = 2.9568e-01, time/batch = 0.3451s	
1541/2700 (epoch 28.537), train_loss = 2.03756068, grad/param norm = 2.9146e-01, time/batch = 0.2913s	
1542/2700 (epoch 28.556), train_loss = 2.01228755, grad/param norm = 2.8062e-01, time/batch = 0.3455s	
1543/2700 (epoch 28.574), train_loss = 2.00033100, grad/param norm = 3.9078e-01, time/batch = 0.3537s	
1544/2700 (epoch 28.593), train_loss = 2.00462088, grad/param norm = 3.8555e-01, time/batch = 0.3699s	
1545/2700 (epoch 28.611), train_loss = 1.95859791, grad/param norm = 3.7137e-01, time/batch = 0.3865s	
1546/2700 (epoch 28.630), train_loss = 1.97595567, grad/param norm = 3.2710e-01, time/batch = 0.3463s	
1547/2700 (epoch 28.648), train_loss = 1.99417242, grad/param norm = 2.1671e-01, time/batch = 0.3413s	
1548/2700 (epoch 28.667), train_loss = 1.96679017, grad/param norm = 1.9599e-01, time/batch = 0.3400s	
1549/2700 (epoch 28.685), train_loss = 1.98289582, grad/param norm = 1.8683e-01, time/batch = 0.3588s	
1550/2700 (epoch 28.704), train_loss = 2.02032102, grad/param norm = 2.2294e-01, time/batch = 0.3579s	
1551/2700 (epoch 28.722), train_loss = 1.96914736, grad/param norm = 2.9882e-01, time/batch = 0.3533s	
1552/2700 (epoch 28.741), train_loss = 2.03945815, grad/param norm = 3.3766e-01, time/batch = 0.3575s	
1553/2700 (epoch 28.759), train_loss = 2.04014635, grad/param norm = 3.1115e-01, time/batch = 0.3712s	
1554/2700 (epoch 28.778), train_loss = 2.05273329, grad/param norm = 2.9373e-01, time/batch = 0.3770s	
1555/2700 (epoch 28.796), train_loss = 2.01516034, grad/param norm = 2.7705e-01, time/batch = 0.3690s	
1556/2700 (epoch 28.815), train_loss = 2.05263819, grad/param norm = 2.7525e-01, time/batch = 0.3494s	
1557/2700 (epoch 28.833), train_loss = 2.01608994, grad/param norm = 2.3968e-01, time/batch = 0.3357s	
1558/2700 (epoch 28.852), train_loss = 2.02269582, grad/param norm = 1.4149e-01, time/batch = 0.3402s	
1559/2700 (epoch 28.870), train_loss = 1.99343850, grad/param norm = 1.4188e-01, time/batch = 0.3514s	
1560/2700 (epoch 28.889), train_loss = 1.99002312, grad/param norm = 1.1254e-01, time/batch = 0.3471s	
1561/2700 (epoch 28.907), train_loss = 2.09442242, grad/param norm = 1.4465e-01, time/batch = 0.3608s	
1562/2700 (epoch 28.926), train_loss = 2.04298824, grad/param norm = 1.8215e-01, time/batch = 0.3571s	
1563/2700 (epoch 28.944), train_loss = 2.03769823, grad/param norm = 1.8028e-01, time/batch = 0.3748s	
1564/2700 (epoch 28.963), train_loss = 2.05167089, grad/param norm = 1.8958e-01, time/batch = 0.3834s	
1565/2700 (epoch 28.981), train_loss = 2.01539687, grad/param norm = 2.4526e-01, time/batch = 0.3866s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
1566/2700 (epoch 29.000), train_loss = 2.05581165, grad/param norm = 2.7895e-01, time/batch = 0.2964s	
1567/2700 (epoch 29.019), train_loss = 2.05462675, grad/param norm = 3.5676e-01, time/batch = 0.3482s	
1568/2700 (epoch 29.037), train_loss = 2.08384316, grad/param norm = 3.2327e-01, time/batch = 0.3617s	
1569/2700 (epoch 29.056), train_loss = 2.02174972, grad/param norm = 2.9190e-01, time/batch = 0.3429s	
1570/2700 (epoch 29.074), train_loss = 2.01103525, grad/param norm = 2.8422e-01, time/batch = 0.3413s	
1571/2700 (epoch 29.093), train_loss = 2.00989758, grad/param norm = 2.4068e-01, time/batch = 0.3622s	
1572/2700 (epoch 29.111), train_loss = 1.96937416, grad/param norm = 2.0033e-01, time/batch = 0.3795s	
1573/2700 (epoch 29.130), train_loss = 2.03180773, grad/param norm = 3.0516e-01, time/batch = 0.3630s	
1574/2700 (epoch 29.148), train_loss = 1.95945925, grad/param norm = 3.4755e-01, time/batch = 0.3482s	
1575/2700 (epoch 29.167), train_loss = 2.05929805, grad/param norm = 2.8167e-01, time/batch = 0.2851s	
1576/2700 (epoch 29.185), train_loss = 1.98249261, grad/param norm = 1.9672e-01, time/batch = 0.3404s	
1577/2700 (epoch 29.204), train_loss = 1.97807363, grad/param norm = 1.6714e-01, time/batch = 0.3405s	
1578/2700 (epoch 29.222), train_loss = 1.95538537, grad/param norm = 1.6391e-01, time/batch = 0.3442s	
1579/2700 (epoch 29.241), train_loss = 1.88350406, grad/param norm = 1.7141e-01, time/batch = 0.3598s	
1580/2700 (epoch 29.259), train_loss = 1.92127077, grad/param norm = 2.5596e-01, time/batch = 0.3546s	
1581/2700 (epoch 29.278), train_loss = 2.01194839, grad/param norm = 3.2424e-01, time/batch = 0.4112s	
1582/2700 (epoch 29.296), train_loss = 2.00192653, grad/param norm = 2.8559e-01, time/batch = 0.3512s	
1583/2700 (epoch 29.315), train_loss = 2.00197779, grad/param norm = 2.6634e-01, time/batch = 0.3467s	
1584/2700 (epoch 29.333), train_loss = 1.98994954, grad/param norm = 2.4162e-01, time/batch = 0.3032s	
1585/2700 (epoch 29.352), train_loss = 1.98978284, grad/param norm = 2.3286e-01, time/batch = 0.3411s	
1586/2700 (epoch 29.370), train_loss = 2.04465603, grad/param norm = 2.8186e-01, time/batch = 0.3413s	
1587/2700 (epoch 29.389), train_loss = 2.01123941, grad/param norm = 3.1740e-01, time/batch = 0.3499s	
1588/2700 (epoch 29.407), train_loss = 2.01743679, grad/param norm = 2.6253e-01, time/batch = 0.3522s	
1589/2700 (epoch 29.426), train_loss = 2.04195380, grad/param norm = 1.3540e-01, time/batch = 0.3579s	
1590/2700 (epoch 29.444), train_loss = 1.95325171, grad/param norm = 1.5796e-01, time/batch = 0.3535s	
1591/2700 (epoch 29.463), train_loss = 1.99737676, grad/param norm = 2.1054e-01, time/batch = 0.3978s	
1592/2700 (epoch 29.481), train_loss = 2.01966579, grad/param norm = 1.7942e-01, time/batch = 0.3345s	
1593/2700 (epoch 29.500), train_loss = 1.97508890, grad/param norm = 1.9877e-01, time/batch = 0.3083s	
1594/2700 (epoch 29.519), train_loss = 1.99989239, grad/param norm = 2.2348e-01, time/batch = 0.3690s	
1595/2700 (epoch 29.537), train_loss = 2.02058923, grad/param norm = 3.0101e-01, time/batch = 0.3441s	
1596/2700 (epoch 29.556), train_loss = 1.99870162, grad/param norm = 4.0940e-01, time/batch = 0.3512s	
1597/2700 (epoch 29.574), train_loss = 1.99474564, grad/param norm = 4.1077e-01, time/batch = 0.3555s	
1598/2700 (epoch 29.593), train_loss = 1.97902334, grad/param norm = 3.7993e-01, time/batch = 0.3687s	
1599/2700 (epoch 29.611), train_loss = 1.94043832, grad/param norm = 3.7448e-01, time/batch = 0.3719s	
1600/2700 (epoch 29.630), train_loss = 1.94424038, grad/param norm = 2.8330e-01, time/batch = 0.3616s	
1601/2700 (epoch 29.648), train_loss = 1.97500424, grad/param norm = 2.0800e-01, time/batch = 0.3516s	
1602/2700 (epoch 29.667), train_loss = 1.94628516, grad/param norm = 1.7601e-01, time/batch = 0.2957s	
1603/2700 (epoch 29.685), train_loss = 1.96479244, grad/param norm = 1.8703e-01, time/batch = 0.3500s	
1604/2700 (epoch 29.704), train_loss = 1.99824846, grad/param norm = 1.7858e-01, time/batch = 0.3460s	
1605/2700 (epoch 29.722), train_loss = 1.94580117, grad/param norm = 1.7030e-01, time/batch = 0.3430s	
1606/2700 (epoch 29.741), train_loss = 2.01568359, grad/param norm = 1.9753e-01, time/batch = 0.3472s	
1607/2700 (epoch 29.759), train_loss = 2.02758590, grad/param norm = 2.4130e-01, time/batch = 0.3648s	
1608/2700 (epoch 29.778), train_loss = 2.04542272, grad/param norm = 2.8412e-01, time/batch = 0.3550s	
1609/2700 (epoch 29.796), train_loss = 2.00767905, grad/param norm = 3.0843e-01, time/batch = 0.3659s	
1610/2700 (epoch 29.815), train_loss = 2.04411015, grad/param norm = 3.1715e-01, time/batch = 0.3776s	
1611/2700 (epoch 29.833), train_loss = 2.00437263, grad/param norm = 2.9849e-01, time/batch = 0.3383s	
1612/2700 (epoch 29.852), train_loss = 2.00833239, grad/param norm = 2.4989e-01, time/batch = 0.3440s	
1613/2700 (epoch 29.870), train_loss = 1.98168362, grad/param norm = 2.5502e-01, time/batch = 0.3463s	
1614/2700 (epoch 29.889), train_loss = 1.98083847, grad/param norm = 2.6275e-01, time/batch = 0.3318s	
1615/2700 (epoch 29.907), train_loss = 2.08722807, grad/param norm = 2.3873e-01, time/batch = 0.3568s	
1616/2700 (epoch 29.926), train_loss = 2.03451946, grad/param norm = 2.2331e-01, time/batch = 0.3449s	
1617/2700 (epoch 29.944), train_loss = 2.02393615, grad/param norm = 1.8347e-01, time/batch = 0.3739s	
1618/2700 (epoch 29.963), train_loss = 2.03786286, grad/param norm = 1.7102e-01, time/batch = 0.3114s	
1619/2700 (epoch 29.981), train_loss = 2.00362994, grad/param norm = 2.0094e-01, time/batch = 0.3546s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
1620/2700 (epoch 30.000), train_loss = 2.03705554, grad/param norm = 1.7138e-01, time/batch = 0.3478s	
1621/2700 (epoch 30.019), train_loss = 2.01241693, grad/param norm = 1.7214e-01, time/batch = 0.4122s	
1622/2700 (epoch 30.037), train_loss = 2.03123659, grad/param norm = 1.4074e-01, time/batch = 0.3534s	
1623/2700 (epoch 30.056), train_loss = 1.97951320, grad/param norm = 2.4341e-01, time/batch = 0.2969s	
1624/2700 (epoch 30.074), train_loss = 1.95700446, grad/param norm = 2.1175e-01, time/batch = 0.3442s	
1625/2700 (epoch 30.093), train_loss = 1.96150595, grad/param norm = 1.6496e-01, time/batch = 0.3492s	
1626/2700 (epoch 30.111), train_loss = 1.93686688, grad/param norm = 2.0964e-01, time/batch = 0.3377s	
1627/2700 (epoch 30.130), train_loss = 2.01286494, grad/param norm = 3.0573e-01, time/batch = 0.3434s	
1628/2700 (epoch 30.148), train_loss = 1.94638798, grad/param norm = 3.7352e-01, time/batch = 0.3461s	
1629/2700 (epoch 30.167), train_loss = 2.05086541, grad/param norm = 3.5372e-01, time/batch = 0.3410s	
1630/2700 (epoch 30.185), train_loss = 1.98240380, grad/param norm = 3.0913e-01, time/batch = 0.3560s	
1631/2700 (epoch 30.204), train_loss = 1.97730389, grad/param norm = 2.4291e-01, time/batch = 0.3689s	
1632/2700 (epoch 30.222), train_loss = 1.94674455, grad/param norm = 2.4583e-01, time/batch = 0.3367s	
1633/2700 (epoch 30.241), train_loss = 1.87160110, grad/param norm = 2.5810e-01, time/batch = 0.3520s	
1634/2700 (epoch 30.259), train_loss = 1.90542423, grad/param norm = 2.3409e-01, time/batch = 0.3639s	
1635/2700 (epoch 30.278), train_loss = 1.98199340, grad/param norm = 2.0833e-01, time/batch = 0.3743s	
1636/2700 (epoch 30.296), train_loss = 1.97449220, grad/param norm = 2.1158e-01, time/batch = 0.3772s	
1637/2700 (epoch 30.315), train_loss = 1.97557098, grad/param norm = 1.9066e-01, time/batch = 0.3759s	
1638/2700 (epoch 30.333), train_loss = 1.96493760, grad/param norm = 1.8906e-01, time/batch = 0.3174s	
1639/2700 (epoch 30.352), train_loss = 1.96692413, grad/param norm = 2.1691e-01, time/batch = 0.3523s	
1640/2700 (epoch 30.370), train_loss = 2.01471433, grad/param norm = 1.9798e-01, time/batch = 0.3650s	
1641/2700 (epoch 30.389), train_loss = 1.97366748, grad/param norm = 2.0176e-01, time/batch = 0.3435s	
1642/2700 (epoch 30.407), train_loss = 2.00318725, grad/param norm = 2.0846e-01, time/batch = 0.3557s	
1643/2700 (epoch 30.426), train_loss = 2.03926748, grad/param norm = 2.7925e-01, time/batch = 0.3594s	
1644/2700 (epoch 30.444), train_loss = 1.96721755, grad/param norm = 4.0174e-01, time/batch = 0.3751s	
1645/2700 (epoch 30.463), train_loss = 2.00842852, grad/param norm = 4.2352e-01, time/batch = 0.3846s	
1646/2700 (epoch 30.481), train_loss = 2.01502418, grad/param norm = 2.6978e-01, time/batch = 0.3763s	
1647/2700 (epoch 30.500), train_loss = 1.95448518, grad/param norm = 1.6535e-01, time/batch = 0.3127s	
1648/2700 (epoch 30.519), train_loss = 1.97832020, grad/param norm = 1.4369e-01, time/batch = 0.3471s	
1649/2700 (epoch 30.537), train_loss = 1.99211539, grad/param norm = 2.0138e-01, time/batch = 0.3503s	
1650/2700 (epoch 30.556), train_loss = 1.96342343, grad/param norm = 2.1001e-01, time/batch = 0.3564s	
1651/2700 (epoch 30.574), train_loss = 1.94939808, grad/param norm = 2.2043e-01, time/batch = 0.3338s	
1652/2700 (epoch 30.593), train_loss = 1.94833055, grad/param norm = 2.4002e-01, time/batch = 0.3655s	
1653/2700 (epoch 30.611), train_loss = 1.90984492, grad/param norm = 2.7959e-01, time/batch = 0.3582s	
1654/2700 (epoch 30.630), train_loss = 1.92671451, grad/param norm = 2.7012e-01, time/batch = 0.3756s	
1655/2700 (epoch 30.648), train_loss = 1.95723966, grad/param norm = 2.8135e-01, time/batch = 0.3698s	
1656/2700 (epoch 30.667), train_loss = 1.94729920, grad/param norm = 3.3611e-01, time/batch = 0.3025s	
1657/2700 (epoch 30.685), train_loss = 1.96491782, grad/param norm = 3.5259e-01, time/batch = 0.3584s	
1658/2700 (epoch 30.704), train_loss = 2.00512287, grad/param norm = 3.4459e-01, time/batch = 0.3563s	
1659/2700 (epoch 30.722), train_loss = 1.93431868, grad/param norm = 3.3294e-01, time/batch = 0.3348s	
1660/2700 (epoch 30.741), train_loss = 1.99470460, grad/param norm = 3.1302e-01, time/batch = 0.3474s	
1661/2700 (epoch 30.759), train_loss = 1.99933111, grad/param norm = 2.8437e-01, time/batch = 0.3776s	
1662/2700 (epoch 30.778), train_loss = 2.01571027, grad/param norm = 3.1107e-01, time/batch = 0.3493s	
1663/2700 (epoch 30.796), train_loss = 1.98205649, grad/param norm = 2.9955e-01, time/batch = 0.3574s	
1664/2700 (epoch 30.815), train_loss = 2.01878661, grad/param norm = 3.0280e-01, time/batch = 0.3426s	
1665/2700 (epoch 30.833), train_loss = 1.97900262, grad/param norm = 2.4474e-01, time/batch = 0.3014s	
1666/2700 (epoch 30.852), train_loss = 1.98299293, grad/param norm = 1.6437e-01, time/batch = 0.3543s	
1667/2700 (epoch 30.870), train_loss = 1.96725534, grad/param norm = 1.8121e-01, time/batch = 0.3677s	
1668/2700 (epoch 30.889), train_loss = 1.97454785, grad/param norm = 2.4363e-01, time/batch = 0.3074s	
1669/2700 (epoch 30.907), train_loss = 2.08357346, grad/param norm = 2.5931e-01, time/batch = 0.3518s	
1670/2700 (epoch 30.926), train_loss = 2.02547796, grad/param norm = 2.4309e-01, time/batch = 0.3609s	
1671/2700 (epoch 30.944), train_loss = 2.00860225, grad/param norm = 1.7808e-01, time/batch = 0.3974s	
1672/2700 (epoch 30.963), train_loss = 2.01429011, grad/param norm = 1.4190e-01, time/batch = 0.3770s	
1673/2700 (epoch 30.981), train_loss = 1.97403260, grad/param norm = 1.4020e-01, time/batch = 0.3498s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
1674/2700 (epoch 31.000), train_loss = 2.00938327, grad/param norm = 1.5363e-01, time/batch = 0.3182s	
1675/2700 (epoch 31.019), train_loss = 1.99428861, grad/param norm = 1.8651e-01, time/batch = 0.3524s	
1676/2700 (epoch 31.037), train_loss = 2.01796383, grad/param norm = 2.6484e-01, time/batch = 0.3365s	
1677/2700 (epoch 31.056), train_loss = 1.97560217, grad/param norm = 3.8046e-01, time/batch = 0.3521s	
1678/2700 (epoch 31.074), train_loss = 1.94750914, grad/param norm = 2.8308e-01, time/batch = 0.3558s	
1679/2700 (epoch 31.093), train_loss = 1.94863364, grad/param norm = 1.9914e-01, time/batch = 0.3703s	
1680/2700 (epoch 31.111), train_loss = 1.92062284, grad/param norm = 1.8067e-01, time/batch = 0.3618s	
1681/2700 (epoch 31.130), train_loss = 1.98374309, grad/param norm = 1.4512e-01, time/batch = 0.3594s	
1682/2700 (epoch 31.148), train_loss = 1.90516327, grad/param norm = 1.3112e-01, time/batch = 0.3469s	
1683/2700 (epoch 31.167), train_loss = 2.01162274, grad/param norm = 1.8319e-01, time/batch = 0.3342s	
1684/2700 (epoch 31.185), train_loss = 1.94572001, grad/param norm = 1.9885e-01, time/batch = 0.3638s	
1685/2700 (epoch 31.204), train_loss = 1.95369939, grad/param norm = 2.6538e-01, time/batch = 0.3178s	
1686/2700 (epoch 31.222), train_loss = 1.92932964, grad/param norm = 2.8814e-01, time/batch = 0.3533s	
1687/2700 (epoch 31.241), train_loss = 1.85530847, grad/param norm = 3.1671e-01, time/batch = 0.3537s	
1688/2700 (epoch 31.259), train_loss = 1.89127482, grad/param norm = 2.7664e-01, time/batch = 0.3669s	
1689/2700 (epoch 31.278), train_loss = 1.96302571, grad/param norm = 2.0848e-01, time/batch = 0.3781s	
1690/2700 (epoch 31.296), train_loss = 1.95974350, grad/param norm = 2.3378e-01, time/batch = 0.3857s	
1691/2700 (epoch 31.315), train_loss = 1.95938424, grad/param norm = 2.3738e-01, time/batch = 0.3432s	
1692/2700 (epoch 31.333), train_loss = 1.95273535, grad/param norm = 2.9390e-01, time/batch = 0.3502s	
1693/2700 (epoch 31.352), train_loss = 1.95769175, grad/param norm = 3.3481e-01, time/batch = 0.3434s	
1694/2700 (epoch 31.370), train_loss = 2.01323173, grad/param norm = 3.4049e-01, time/batch = 0.3574s	
1695/2700 (epoch 31.389), train_loss = 1.97179641, grad/param norm = 3.4353e-01, time/batch = 0.3765s	
1696/2700 (epoch 31.407), train_loss = 1.98482944, grad/param norm = 2.9377e-01, time/batch = 0.3567s	
1697/2700 (epoch 31.426), train_loss = 2.01230761, grad/param norm = 1.8600e-01, time/batch = 0.3698s	
1698/2700 (epoch 31.444), train_loss = 1.92931862, grad/param norm = 1.8909e-01, time/batch = 0.3562s	
1699/2700 (epoch 31.463), train_loss = 1.96648927, grad/param norm = 2.0118e-01, time/batch = 0.3458s	
1700/2700 (epoch 31.481), train_loss = 1.98645470, grad/param norm = 1.6570e-01, time/batch = 0.3461s	
1701/2700 (epoch 31.500), train_loss = 1.93586439, grad/param norm = 1.9850e-01, time/batch = 0.3471s	
1702/2700 (epoch 31.519), train_loss = 1.96266625, grad/param norm = 2.1758e-01, time/batch = 0.3415s	
1703/2700 (epoch 31.537), train_loss = 1.97876689, grad/param norm = 2.5476e-01, time/batch = 0.3477s	
1704/2700 (epoch 31.556), train_loss = 1.95055634, grad/param norm = 2.5755e-01, time/batch = 0.3571s	
1705/2700 (epoch 31.574), train_loss = 1.94115520, grad/param norm = 3.6674e-01, time/batch = 0.3539s	
1706/2700 (epoch 31.593), train_loss = 1.94270350, grad/param norm = 3.4608e-01, time/batch = 0.3680s	
1707/2700 (epoch 31.611), train_loss = 1.89464929, grad/param norm = 3.0785e-01, time/batch = 0.3468s	
1708/2700 (epoch 31.630), train_loss = 1.90918582, grad/param norm = 2.8999e-01, time/batch = 0.3519s	
1709/2700 (epoch 31.648), train_loss = 1.93121333, grad/param norm = 2.3044e-01, time/batch = 0.3579s	
1710/2700 (epoch 31.667), train_loss = 1.91788524, grad/param norm = 2.1603e-01, time/batch = 0.3402s	
1711/2700 (epoch 31.685), train_loss = 1.92815035, grad/param norm = 1.8833e-01, time/batch = 0.3596s	
1712/2700 (epoch 31.704), train_loss = 1.96621387, grad/param norm = 2.1136e-01, time/batch = 0.3442s	
1713/2700 (epoch 31.722), train_loss = 1.90380079, grad/param norm = 2.2006e-01, time/batch = 0.3435s	
1714/2700 (epoch 31.741), train_loss = 1.96793367, grad/param norm = 2.4154e-01, time/batch = 0.3257s	
1715/2700 (epoch 31.759), train_loss = 1.98455929, grad/param norm = 3.0977e-01, time/batch = 0.3069s	
1716/2700 (epoch 31.778), train_loss = 2.01038297, grad/param norm = 3.7498e-01, time/batch = 0.2812s	
1717/2700 (epoch 31.796), train_loss = 1.98063228, grad/param norm = 4.0141e-01, time/batch = 0.3554s	
1718/2700 (epoch 31.815), train_loss = 2.01627938, grad/param norm = 3.5838e-01, time/batch = 0.3515s	
1719/2700 (epoch 31.833), train_loss = 1.97017479, grad/param norm = 2.7899e-01, time/batch = 0.3362s	
1720/2700 (epoch 31.852), train_loss = 1.97263635, grad/param norm = 2.4787e-01, time/batch = 0.3540s	
1721/2700 (epoch 31.870), train_loss = 1.95756677, grad/param norm = 2.5127e-01, time/batch = 0.3604s	
1722/2700 (epoch 31.889), train_loss = 1.95663690, grad/param norm = 2.6846e-01, time/batch = 0.3725s	
1723/2700 (epoch 31.907), train_loss = 2.06442663, grad/param norm = 2.2426e-01, time/batch = 0.3492s	
1724/2700 (epoch 31.926), train_loss = 2.00784625, grad/param norm = 2.0098e-01, time/batch = 0.3515s	
1725/2700 (epoch 31.944), train_loss = 1.99066488, grad/param norm = 1.5654e-01, time/batch = 0.3603s	
1726/2700 (epoch 31.963), train_loss = 1.99474379, grad/param norm = 1.3511e-01, time/batch = 0.3592s	
1727/2700 (epoch 31.981), train_loss = 1.95787569, grad/param norm = 1.4294e-01, time/batch = 0.3426s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
1728/2700 (epoch 32.000), train_loss = 1.99361830, grad/param norm = 1.5096e-01, time/batch = 0.3710s	
1729/2700 (epoch 32.019), train_loss = 1.97807442, grad/param norm = 1.9991e-01, time/batch = 0.3561s	
1730/2700 (epoch 32.037), train_loss = 2.00241322, grad/param norm = 2.5307e-01, time/batch = 0.3717s	
1731/2700 (epoch 32.056), train_loss = 1.95304257, grad/param norm = 3.3515e-01, time/batch = 0.3481s	
1732/2700 (epoch 32.074), train_loss = 1.92333129, grad/param norm = 2.2942e-01, time/batch = 0.3500s	
1733/2700 (epoch 32.093), train_loss = 1.92772089, grad/param norm = 1.5779e-01, time/batch = 0.3571s	
1734/2700 (epoch 32.111), train_loss = 1.90024822, grad/param norm = 1.7073e-01, time/batch = 0.3565s	
1735/2700 (epoch 32.130), train_loss = 1.96784320, grad/param norm = 1.9042e-01, time/batch = 0.3458s	
1736/2700 (epoch 32.148), train_loss = 1.89184782, grad/param norm = 2.2611e-01, time/batch = 0.3411s	
1737/2700 (epoch 32.167), train_loss = 1.99474126, grad/param norm = 2.0174e-01, time/batch = 0.3593s	
1738/2700 (epoch 32.185), train_loss = 1.92553317, grad/param norm = 1.8198e-01, time/batch = 0.3701s	
1739/2700 (epoch 32.204), train_loss = 1.92997478, grad/param norm = 1.6701e-01, time/batch = 0.3605s	
1740/2700 (epoch 32.222), train_loss = 1.90549048, grad/param norm = 1.8692e-01, time/batch = 0.3562s	
1741/2700 (epoch 32.241), train_loss = 1.83373076, grad/param norm = 2.5097e-01, time/batch = 0.3466s	
1742/2700 (epoch 32.259), train_loss = 1.87950928, grad/param norm = 3.3178e-01, time/batch = 0.3418s	
1743/2700 (epoch 32.278), train_loss = 1.97174901, grad/param norm = 3.6355e-01, time/batch = 0.3435s	
1744/2700 (epoch 32.296), train_loss = 1.95553487, grad/param norm = 3.4038e-01, time/batch = 0.3055s	
1745/2700 (epoch 32.315), train_loss = 1.94730884, grad/param norm = 2.6491e-01, time/batch = 0.3400s	
1746/2700 (epoch 32.333), train_loss = 1.92680723, grad/param norm = 1.7366e-01, time/batch = 0.3465s	
1747/2700 (epoch 32.352), train_loss = 1.92569401, grad/param norm = 1.5962e-01, time/batch = 0.3583s	
1748/2700 (epoch 32.370), train_loss = 1.97907645, grad/param norm = 1.5604e-01, time/batch = 0.3510s	
1749/2700 (epoch 32.389), train_loss = 1.93870118, grad/param norm = 1.9907e-01, time/batch = 0.3750s	
1750/2700 (epoch 32.407), train_loss = 1.96837168, grad/param norm = 2.5173e-01, time/batch = 0.3744s	
1751/2700 (epoch 32.426), train_loss = 1.99702801, grad/param norm = 2.2067e-01, time/batch = 0.3534s	
1752/2700 (epoch 32.444), train_loss = 1.90843313, grad/param norm = 2.6061e-01, time/batch = 0.3439s	
1753/2700 (epoch 32.463), train_loss = 1.95326076, grad/param norm = 2.8812e-01, time/batch = 0.3085s	
1754/2700 (epoch 32.481), train_loss = 1.97152492, grad/param norm = 2.1752e-01, time/batch = 0.3738s	
1755/2700 (epoch 32.500), train_loss = 1.92723134, grad/param norm = 2.4958e-01, time/batch = 0.3834s	
1756/2700 (epoch 32.519), train_loss = 1.96710298, grad/param norm = 2.5993e-01, time/batch = 0.3441s	
1757/2700 (epoch 32.537), train_loss = 1.96995165, grad/param norm = 2.1293e-01, time/batch = 0.3494s	
1758/2700 (epoch 32.556), train_loss = 1.92624383, grad/param norm = 1.8577e-01, time/batch = 0.3508s	
1759/2700 (epoch 32.574), train_loss = 1.91905237, grad/param norm = 1.7825e-01, time/batch = 0.3585s	
1760/2700 (epoch 32.593), train_loss = 1.91619185, grad/param norm = 1.9514e-01, time/batch = 0.3939s	
1761/2700 (epoch 32.611), train_loss = 1.87733914, grad/param norm = 2.3985e-01, time/batch = 0.3605s	
1762/2700 (epoch 32.630), train_loss = 1.88861013, grad/param norm = 2.0570e-01, time/batch = 0.3380s	
1763/2700 (epoch 32.648), train_loss = 1.91433144, grad/param norm = 1.7286e-01, time/batch = 0.3305s	
1764/2700 (epoch 32.667), train_loss = 1.90114883, grad/param norm = 1.7124e-01, time/batch = 0.3527s	
1765/2700 (epoch 32.685), train_loss = 1.91142344, grad/param norm = 1.8925e-01, time/batch = 0.3606s	
1766/2700 (epoch 32.704), train_loss = 1.94923924, grad/param norm = 2.1938e-01, time/batch = 0.3465s	
1767/2700 (epoch 32.722), train_loss = 1.89088533, grad/param norm = 2.6541e-01, time/batch = 0.3469s	
1768/2700 (epoch 32.741), train_loss = 1.95623486, grad/param norm = 3.0030e-01, time/batch = 0.3453s	
1769/2700 (epoch 32.759), train_loss = 1.97294183, grad/param norm = 3.4074e-01, time/batch = 0.3467s	
1770/2700 (epoch 32.778), train_loss = 2.00177483, grad/param norm = 4.1435e-01, time/batch = 0.3628s	
1771/2700 (epoch 32.796), train_loss = 1.96899323, grad/param norm = 4.1196e-01, time/batch = 0.3224s	
1772/2700 (epoch 32.815), train_loss = 1.99623443, grad/param norm = 3.3090e-01, time/batch = 0.3597s	
1773/2700 (epoch 32.833), train_loss = 1.94863330, grad/param norm = 2.6780e-01, time/batch = 0.3711s	
1774/2700 (epoch 32.852), train_loss = 1.95020991, grad/param norm = 1.8333e-01, time/batch = 0.3546s	
1775/2700 (epoch 32.870), train_loss = 1.92656430, grad/param norm = 1.7902e-01, time/batch = 0.3472s	
1776/2700 (epoch 32.889), train_loss = 1.92588486, grad/param norm = 1.7851e-01, time/batch = 0.3661s	
1777/2700 (epoch 32.907), train_loss = 2.02947525, grad/param norm = 1.6713e-01, time/batch = 0.3527s	
1778/2700 (epoch 32.926), train_loss = 1.98426053, grad/param norm = 2.0147e-01, time/batch = 0.3575s	
1779/2700 (epoch 32.944), train_loss = 1.96920253, grad/param norm = 1.9532e-01, time/batch = 0.3754s	
1780/2700 (epoch 32.963), train_loss = 1.97920176, grad/param norm = 1.8874e-01, time/batch = 0.3740s	
1781/2700 (epoch 32.981), train_loss = 1.94782396, grad/param norm = 2.3722e-01, time/batch = 0.3243s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
1782/2700 (epoch 33.000), train_loss = 1.98251932, grad/param norm = 2.2988e-01, time/batch = 0.3576s	
1783/2700 (epoch 33.019), train_loss = 1.97111495, grad/param norm = 2.7485e-01, time/batch = 0.3594s	
1784/2700 (epoch 33.037), train_loss = 1.99380527, grad/param norm = 2.6721e-01, time/batch = 0.3534s	
1785/2700 (epoch 33.056), train_loss = 1.93152990, grad/param norm = 2.3953e-01, time/batch = 0.3410s	
1786/2700 (epoch 33.074), train_loss = 1.91563253, grad/param norm = 2.2656e-01, time/batch = 0.3467s	
1787/2700 (epoch 33.093), train_loss = 1.92207695, grad/param norm = 2.4764e-01, time/batch = 0.3553s	
1788/2700 (epoch 33.111), train_loss = 1.88825245, grad/param norm = 2.3403e-01, time/batch = 0.3588s	
1789/2700 (epoch 33.130), train_loss = 1.95438730, grad/param norm = 2.5182e-01, time/batch = 0.3686s	
1790/2700 (epoch 33.148), train_loss = 1.88361328, grad/param norm = 3.2379e-01, time/batch = 0.3425s	
1791/2700 (epoch 33.167), train_loss = 1.99893925, grad/param norm = 3.5304e-01, time/batch = 0.3563s	
1792/2700 (epoch 33.185), train_loss = 1.92285672, grad/param norm = 3.1724e-01, time/batch = 0.3669s	
1793/2700 (epoch 33.204), train_loss = 1.92433107, grad/param norm = 3.1880e-01, time/batch = 0.3407s	
1794/2700 (epoch 33.222), train_loss = 1.89932382, grad/param norm = 2.8956e-01, time/batch = 0.3469s	
1795/2700 (epoch 33.241), train_loss = 1.81783144, grad/param norm = 2.4319e-01, time/batch = 0.3442s	
1796/2700 (epoch 33.259), train_loss = 1.85317718, grad/param norm = 2.0240e-01, time/batch = 0.3492s	
1797/2700 (epoch 33.278), train_loss = 1.92878560, grad/param norm = 1.8000e-01, time/batch = 0.3537s	
1798/2700 (epoch 33.296), train_loss = 1.91756680, grad/param norm = 1.6138e-01, time/batch = 0.3640s	
1799/2700 (epoch 33.315), train_loss = 1.92372330, grad/param norm = 1.8643e-01, time/batch = 0.3421s	
1800/2700 (epoch 33.333), train_loss = 1.91472819, grad/param norm = 2.2280e-01, time/batch = 0.3588s	
1801/2700 (epoch 33.352), train_loss = 1.91369926, grad/param norm = 2.5274e-01, time/batch = 0.3769s	
1802/2700 (epoch 33.370), train_loss = 1.97016104, grad/param norm = 2.3515e-01, time/batch = 0.3186s	
1803/2700 (epoch 33.389), train_loss = 1.92196133, grad/param norm = 2.4369e-01, time/batch = 0.3460s	
1804/2700 (epoch 33.407), train_loss = 1.94536319, grad/param norm = 2.3428e-01, time/batch = 0.3486s	
1805/2700 (epoch 33.426), train_loss = 1.97613500, grad/param norm = 1.5185e-01, time/batch = 0.3535s	
1806/2700 (epoch 33.444), train_loss = 1.88785619, grad/param norm = 1.7121e-01, time/batch = 0.3521s	
1807/2700 (epoch 33.463), train_loss = 1.92958132, grad/param norm = 2.0577e-01, time/batch = 0.3519s	
1808/2700 (epoch 33.481), train_loss = 1.95082570, grad/param norm = 1.5889e-01, time/batch = 0.3453s	
1809/2700 (epoch 33.500), train_loss = 1.89760806, grad/param norm = 1.7733e-01, time/batch = 0.3480s	
1810/2700 (epoch 33.519), train_loss = 1.92790184, grad/param norm = 1.6243e-01, time/batch = 0.3514s	
1811/2700 (epoch 33.537), train_loss = 1.93814774, grad/param norm = 1.5657e-01, time/batch = 0.3589s	
1812/2700 (epoch 33.556), train_loss = 1.90509075, grad/param norm = 1.4547e-01, time/batch = 0.3613s	
1813/2700 (epoch 33.574), train_loss = 1.89705451, grad/param norm = 1.8354e-01, time/batch = 0.3453s	
1814/2700 (epoch 33.593), train_loss = 1.90112761, grad/param norm = 2.0568e-01, time/batch = 0.3469s	
1815/2700 (epoch 33.611), train_loss = 1.85914827, grad/param norm = 2.4014e-01, time/batch = 0.3443s	
1816/2700 (epoch 33.630), train_loss = 1.87358591, grad/param norm = 2.0957e-01, time/batch = 0.3445s	
1817/2700 (epoch 33.648), train_loss = 1.89691525, grad/param norm = 1.8902e-01, time/batch = 0.3283s	
1818/2700 (epoch 33.667), train_loss = 1.89505978, grad/param norm = 2.4033e-01, time/batch = 0.3684s	
1819/2700 (epoch 33.685), train_loss = 1.91074253, grad/param norm = 2.6536e-01, time/batch = 0.3153s	
1820/2700 (epoch 33.704), train_loss = 1.95068434, grad/param norm = 2.7213e-01, time/batch = 0.3573s	
1821/2700 (epoch 33.722), train_loss = 1.88939686, grad/param norm = 2.7714e-01, time/batch = 0.3526s	
1822/2700 (epoch 33.741), train_loss = 1.94177834, grad/param norm = 2.5843e-01, time/batch = 0.3465s	
1823/2700 (epoch 33.759), train_loss = 1.94483262, grad/param norm = 2.2720e-01, time/batch = 0.3599s	
1824/2700 (epoch 33.778), train_loss = 1.96234669, grad/param norm = 2.1861e-01, time/batch = 0.3430s	
1825/2700 (epoch 33.796), train_loss = 1.91957800, grad/param norm = 2.0641e-01, time/batch = 0.3638s	
1826/2700 (epoch 33.815), train_loss = 1.96299794, grad/param norm = 2.4580e-01, time/batch = 0.3229s	
1827/2700 (epoch 33.833), train_loss = 1.92511507, grad/param norm = 2.3724e-01, time/batch = 0.3150s	
1828/2700 (epoch 33.852), train_loss = 1.93047919, grad/param norm = 1.4103e-01, time/batch = 0.3017s	
1829/2700 (epoch 33.870), train_loss = 1.91234234, grad/param norm = 1.3742e-01, time/batch = 0.3475s	
1830/2700 (epoch 33.889), train_loss = 1.91472520, grad/param norm = 2.2448e-01, time/batch = 0.3527s	
1831/2700 (epoch 33.907), train_loss = 2.02996599, grad/param norm = 3.1464e-01, time/batch = 0.3755s	
1832/2700 (epoch 33.926), train_loss = 1.98557768, grad/param norm = 3.9158e-01, time/batch = 0.3586s	
1833/2700 (epoch 33.944), train_loss = 1.96882925, grad/param norm = 3.4140e-01, time/batch = 0.3639s	
1834/2700 (epoch 33.963), train_loss = 1.97044201, grad/param norm = 2.7063e-01, time/batch = 0.3508s	
1835/2700 (epoch 33.981), train_loss = 1.93723263, grad/param norm = 2.9491e-01, time/batch = 0.3147s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
1836/2700 (epoch 34.000), train_loss = 1.97321316, grad/param norm = 2.5873e-01, time/batch = 0.3704s	
1837/2700 (epoch 34.019), train_loss = 1.95259944, grad/param norm = 2.5379e-01, time/batch = 0.3469s	
1838/2700 (epoch 34.037), train_loss = 1.96756331, grad/param norm = 2.3813e-01, time/batch = 0.3481s	
1839/2700 (epoch 34.056), train_loss = 1.91033108, grad/param norm = 2.7800e-01, time/batch = 0.3533s	
1840/2700 (epoch 34.074), train_loss = 1.89009794, grad/param norm = 2.1667e-01, time/batch = 0.3615s	
1841/2700 (epoch 34.093), train_loss = 1.89289384, grad/param norm = 2.5089e-01, time/batch = 0.3591s	
1842/2700 (epoch 34.111), train_loss = 1.86903920, grad/param norm = 2.5712e-01, time/batch = 0.3521s	
1843/2700 (epoch 34.130), train_loss = 1.93725102, grad/param norm = 2.2145e-01, time/batch = 0.3646s	
1844/2700 (epoch 34.148), train_loss = 1.86044388, grad/param norm = 2.1245e-01, time/batch = 0.2892s	
1845/2700 (epoch 34.167), train_loss = 1.97422156, grad/param norm = 2.7081e-01, time/batch = 0.3540s	
1846/2700 (epoch 34.185), train_loss = 1.90381513, grad/param norm = 2.5518e-01, time/batch = 0.3626s	
1847/2700 (epoch 34.204), train_loss = 1.90945981, grad/param norm = 2.6314e-01, time/batch = 0.3740s	
1848/2700 (epoch 34.222), train_loss = 1.88150142, grad/param norm = 2.4846e-01, time/batch = 0.3575s	
1849/2700 (epoch 34.241), train_loss = 1.80129026, grad/param norm = 2.2602e-01, time/batch = 0.3612s	
1850/2700 (epoch 34.259), train_loss = 1.83538215, grad/param norm = 1.5928e-01, time/batch = 0.3480s	
1851/2700 (epoch 34.278), train_loss = 1.91127466, grad/param norm = 1.2851e-01, time/batch = 0.3768s	
1852/2700 (epoch 34.296), train_loss = 1.90222504, grad/param norm = 1.5034e-01, time/batch = 0.3544s	
1853/2700 (epoch 34.315), train_loss = 1.90507811, grad/param norm = 1.4228e-01, time/batch = 0.3086s	
1854/2700 (epoch 34.333), train_loss = 1.89485385, grad/param norm = 1.6630e-01, time/batch = 0.3734s	
1855/2700 (epoch 34.352), train_loss = 1.89321211, grad/param norm = 1.8638e-01, time/batch = 0.3358s	
1856/2700 (epoch 34.370), train_loss = 1.94700477, grad/param norm = 1.5371e-01, time/batch = 0.3468s	
1857/2700 (epoch 34.389), train_loss = 1.90283230, grad/param norm = 1.8641e-01, time/batch = 0.3565s	
1858/2700 (epoch 34.407), train_loss = 1.93457945, grad/param norm = 2.5423e-01, time/batch = 0.3650s	
1859/2700 (epoch 34.426), train_loss = 1.96915925, grad/param norm = 2.8511e-01, time/batch = 0.3453s	
1860/2700 (epoch 34.444), train_loss = 1.88603467, grad/param norm = 3.6375e-01, time/batch = 0.3446s	
1861/2700 (epoch 34.463), train_loss = 1.93566766, grad/param norm = 4.0649e-01, time/batch = 0.3873s	
1862/2700 (epoch 34.481), train_loss = 1.94506520, grad/param norm = 2.8898e-01, time/batch = 0.3145s	
1863/2700 (epoch 34.500), train_loss = 1.88640135, grad/param norm = 2.2186e-01, time/batch = 0.3748s	
1864/2700 (epoch 34.519), train_loss = 1.92552042, grad/param norm = 2.2738e-01, time/batch = 0.3233s	
1865/2700 (epoch 34.537), train_loss = 1.92598609, grad/param norm = 2.3393e-01, time/batch = 0.3488s	
1866/2700 (epoch 34.556), train_loss = 1.89167847, grad/param norm = 2.2754e-01, time/batch = 0.3521s	
1867/2700 (epoch 34.574), train_loss = 1.88786047, grad/param norm = 2.5121e-01, time/batch = 0.3714s	
1868/2700 (epoch 34.593), train_loss = 1.88869346, grad/param norm = 2.4136e-01, time/batch = 0.3407s	
1869/2700 (epoch 34.611), train_loss = 1.84079561, grad/param norm = 2.4833e-01, time/batch = 0.3459s	
1870/2700 (epoch 34.630), train_loss = 1.85314487, grad/param norm = 1.8578e-01, time/batch = 0.3491s	
1871/2700 (epoch 34.648), train_loss = 1.87760409, grad/param norm = 1.4171e-01, time/batch = 0.3402s	
1872/2700 (epoch 34.667), train_loss = 1.87021928, grad/param norm = 1.6427e-01, time/batch = 0.3605s	
1873/2700 (epoch 34.685), train_loss = 1.88093073, grad/param norm = 1.8482e-01, time/batch = 0.3558s	
1874/2700 (epoch 34.704), train_loss = 1.91845573, grad/param norm = 1.7818e-01, time/batch = 0.3510s	
1875/2700 (epoch 34.722), train_loss = 1.85903635, grad/param norm = 1.8683e-01, time/batch = 0.3485s	
1876/2700 (epoch 34.741), train_loss = 1.92206985, grad/param norm = 2.0606e-01, time/batch = 0.3614s	
1877/2700 (epoch 34.759), train_loss = 1.93192284, grad/param norm = 1.8699e-01, time/batch = 0.3369s	
1878/2700 (epoch 34.778), train_loss = 1.95111039, grad/param norm = 2.0550e-01, time/batch = 0.3564s	
1879/2700 (epoch 34.796), train_loss = 1.91320786, grad/param norm = 2.3542e-01, time/batch = 0.3473s	
1880/2700 (epoch 34.815), train_loss = 1.95398303, grad/param norm = 2.6435e-01, time/batch = 0.3545s	
1881/2700 (epoch 34.833), train_loss = 1.91998960, grad/param norm = 2.8301e-01, time/batch = 0.3642s	
1882/2700 (epoch 34.852), train_loss = 1.92898486, grad/param norm = 3.0510e-01, time/batch = 0.3270s	
1883/2700 (epoch 34.870), train_loss = 1.91534424, grad/param norm = 3.2149e-01, time/batch = 0.3485s	
1884/2700 (epoch 34.889), train_loss = 1.90902686, grad/param norm = 3.2928e-01, time/batch = 0.3421s	
1885/2700 (epoch 34.907), train_loss = 2.01426069, grad/param norm = 2.6978e-01, time/batch = 0.3400s	
1886/2700 (epoch 34.926), train_loss = 1.95941564, grad/param norm = 2.2498e-01, time/batch = 0.3540s	
1887/2700 (epoch 34.944), train_loss = 1.93776703, grad/param norm = 1.5747e-01, time/batch = 0.3443s	
1888/2700 (epoch 34.963), train_loss = 1.94515174, grad/param norm = 1.4101e-01, time/batch = 0.3442s	
1889/2700 (epoch 34.981), train_loss = 1.91313154, grad/param norm = 1.8673e-01, time/batch = 0.3363s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
1890/2700 (epoch 35.000), train_loss = 1.95307005, grad/param norm = 2.1926e-01, time/batch = 0.3510s	
1891/2700 (epoch 35.019), train_loss = 1.93889774, grad/param norm = 2.5074e-01, time/batch = 0.3729s	
1892/2700 (epoch 35.037), train_loss = 1.95867326, grad/param norm = 3.3847e-01, time/batch = 0.3688s	
1893/2700 (epoch 35.056), train_loss = 1.91378839, grad/param norm = 4.2710e-01, time/batch = 0.3389s	
1894/2700 (epoch 35.074), train_loss = 1.89225606, grad/param norm = 3.8338e-01, time/batch = 0.3463s	
1895/2700 (epoch 35.093), train_loss = 1.89113842, grad/param norm = 3.2202e-01, time/batch = 0.3463s	
1896/2700 (epoch 35.111), train_loss = 1.85737363, grad/param norm = 2.9462e-01, time/batch = 0.3439s	
1897/2700 (epoch 35.130), train_loss = 1.92933485, grad/param norm = 3.1406e-01, time/batch = 0.3401s	
1898/2700 (epoch 35.148), train_loss = 1.85085473, grad/param norm = 3.1701e-01, time/batch = 0.3438s	
1899/2700 (epoch 35.167), train_loss = 1.95227456, grad/param norm = 2.2518e-01, time/batch = 0.3528s	
1900/2700 (epoch 35.185), train_loss = 1.87746634, grad/param norm = 1.5965e-01, time/batch = 0.3535s	
1901/2700 (epoch 35.204), train_loss = 1.88448845, grad/param norm = 1.3469e-01, time/batch = 0.3912s	
1902/2700 (epoch 35.222), train_loss = 1.85996932, grad/param norm = 1.3148e-01, time/batch = 0.3334s	
1903/2700 (epoch 35.241), train_loss = 1.78168645, grad/param norm = 1.4231e-01, time/batch = 0.3676s	
1904/2700 (epoch 35.259), train_loss = 1.82180091, grad/param norm = 1.7798e-01, time/batch = 0.3511s	
1905/2700 (epoch 35.278), train_loss = 1.90357441, grad/param norm = 2.3280e-01, time/batch = 0.3545s	
1906/2700 (epoch 35.296), train_loss = 1.88978088, grad/param norm = 2.0995e-01, time/batch = 0.3632s	
1907/2700 (epoch 35.315), train_loss = 1.89340576, grad/param norm = 1.9131e-01, time/batch = 0.3700s	
1908/2700 (epoch 35.333), train_loss = 1.87814031, grad/param norm = 1.5790e-01, time/batch = 0.3526s	
1909/2700 (epoch 35.352), train_loss = 1.87664994, grad/param norm = 1.6651e-01, time/batch = 0.3591s	
1910/2700 (epoch 35.370), train_loss = 1.93640336, grad/param norm = 2.1994e-01, time/batch = 0.3694s	
1911/2700 (epoch 35.389), train_loss = 1.89582842, grad/param norm = 2.7983e-01, time/batch = 0.3585s	
1912/2700 (epoch 35.407), train_loss = 1.91849738, grad/param norm = 2.7749e-01, time/batch = 0.3535s	
1913/2700 (epoch 35.426), train_loss = 1.94690410, grad/param norm = 1.9294e-01, time/batch = 0.3454s	
1914/2700 (epoch 35.444), train_loss = 1.85678833, grad/param norm = 1.7380e-01, time/batch = 0.3588s	
1915/2700 (epoch 35.463), train_loss = 1.89645533, grad/param norm = 1.8151e-01, time/batch = 0.3660s	
1916/2700 (epoch 35.481), train_loss = 1.91900916, grad/param norm = 1.8115e-01, time/batch = 0.3784s	
1917/2700 (epoch 35.500), train_loss = 1.86608708, grad/param norm = 2.2926e-01, time/batch = 0.3430s	
1918/2700 (epoch 35.519), train_loss = 1.90312734, grad/param norm = 2.4578e-01, time/batch = 0.3380s	
1919/2700 (epoch 35.537), train_loss = 1.90984681, grad/param norm = 2.4634e-01, time/batch = 0.3711s	
1920/2700 (epoch 35.556), train_loss = 1.87580227, grad/param norm = 2.5244e-01, time/batch = 0.3572s	
1921/2700 (epoch 35.574), train_loss = 1.87719882, grad/param norm = 3.5288e-01, time/batch = 0.3439s	
1922/2700 (epoch 35.593), train_loss = 1.88019591, grad/param norm = 3.4846e-01, time/batch = 0.3452s	
1923/2700 (epoch 35.611), train_loss = 1.82939881, grad/param norm = 3.4842e-01, time/batch = 0.3550s	
1924/2700 (epoch 35.630), train_loss = 1.84859852, grad/param norm = 3.4863e-01, time/batch = 0.3534s	
1925/2700 (epoch 35.648), train_loss = 1.86985665, grad/param norm = 3.0386e-01, time/batch = 0.3601s	
1926/2700 (epoch 35.667), train_loss = 1.86178236, grad/param norm = 2.6476e-01, time/batch = 0.3556s	
1927/2700 (epoch 35.685), train_loss = 1.87059435, grad/param norm = 2.4701e-01, time/batch = 0.3242s	
1928/2700 (epoch 35.704), train_loss = 1.90914629, grad/param norm = 2.6915e-01, time/batch = 0.3565s	
1929/2700 (epoch 35.722), train_loss = 1.84694474, grad/param norm = 2.4831e-01, time/batch = 0.3720s	
1930/2700 (epoch 35.741), train_loss = 1.90019704, grad/param norm = 2.3480e-01, time/batch = 0.3628s	
1931/2700 (epoch 35.759), train_loss = 1.91552022, grad/param norm = 2.6904e-01, time/batch = 0.3705s	
1932/2700 (epoch 35.778), train_loss = 1.94009296, grad/param norm = 3.1525e-01, time/batch = 0.3537s	
1933/2700 (epoch 35.796), train_loss = 1.90371762, grad/param norm = 3.0931e-01, time/batch = 0.3493s	
1934/2700 (epoch 35.815), train_loss = 1.94015083, grad/param norm = 2.7918e-01, time/batch = 0.3541s	
1935/2700 (epoch 35.833), train_loss = 1.90178710, grad/param norm = 2.2867e-01, time/batch = 0.3166s	
1936/2700 (epoch 35.852), train_loss = 1.90628627, grad/param norm = 2.0271e-01, time/batch = 0.3487s	
1937/2700 (epoch 35.870), train_loss = 1.88737045, grad/param norm = 1.9552e-01, time/batch = 0.3505s	
1938/2700 (epoch 35.889), train_loss = 1.87972798, grad/param norm = 1.6733e-01, time/batch = 0.3612s	
1939/2700 (epoch 35.907), train_loss = 1.98671976, grad/param norm = 1.6708e-01, time/batch = 0.3708s	
1940/2700 (epoch 35.926), train_loss = 1.94048886, grad/param norm = 1.9370e-01, time/batch = 0.3909s	
1941/2700 (epoch 35.944), train_loss = 1.92593631, grad/param norm = 1.7142e-01, time/batch = 0.3628s	
1942/2700 (epoch 35.963), train_loss = 1.93539283, grad/param norm = 1.8338e-01, time/batch = 0.3670s	
1943/2700 (epoch 35.981), train_loss = 1.90347360, grad/param norm = 2.2250e-01, time/batch = 0.3233s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
1944/2700 (epoch 36.000), train_loss = 1.94160638, grad/param norm = 2.4050e-01, time/batch = 0.3499s	
1945/2700 (epoch 36.019), train_loss = 1.93087929, grad/param norm = 2.5609e-01, time/batch = 0.3144s	
1946/2700 (epoch 36.037), train_loss = 1.95179036, grad/param norm = 3.1874e-01, time/batch = 0.3568s	
1947/2700 (epoch 36.056), train_loss = 1.89181364, grad/param norm = 3.4479e-01, time/batch = 0.3721s	
1948/2700 (epoch 36.074), train_loss = 1.86682116, grad/param norm = 2.2289e-01, time/batch = 0.3780s	
1949/2700 (epoch 36.093), train_loss = 1.86279498, grad/param norm = 2.2561e-01, time/batch = 0.3536s	
1950/2700 (epoch 36.111), train_loss = 1.83645113, grad/param norm = 2.1011e-01, time/batch = 0.3627s	
1951/2700 (epoch 36.130), train_loss = 1.90272330, grad/param norm = 1.7065e-01, time/batch = 0.3490s	
1952/2700 (epoch 36.148), train_loss = 1.82573014, grad/param norm = 2.0179e-01, time/batch = 0.3707s	
1953/2700 (epoch 36.167), train_loss = 1.93983799, grad/param norm = 2.4751e-01, time/batch = 0.3442s	
1954/2700 (epoch 36.185), train_loss = 1.86660928, grad/param norm = 2.3250e-01, time/batch = 0.2933s	
1955/2700 (epoch 36.204), train_loss = 1.87586247, grad/param norm = 2.6788e-01, time/batch = 0.3500s	
1956/2700 (epoch 36.222), train_loss = 1.85293211, grad/param norm = 2.6272e-01, time/batch = 0.3515s	
1957/2700 (epoch 36.241), train_loss = 1.77501554, grad/param norm = 2.4898e-01, time/batch = 0.3441s	
1958/2700 (epoch 36.259), train_loss = 1.81114813, grad/param norm = 2.0502e-01, time/batch = 0.3457s	
1959/2700 (epoch 36.278), train_loss = 1.88399122, grad/param norm = 1.6786e-01, time/batch = 0.3463s	
1960/2700 (epoch 36.296), train_loss = 1.87076707, grad/param norm = 1.6513e-01, time/batch = 0.3260s	
1961/2700 (epoch 36.315), train_loss = 1.87773129, grad/param norm = 1.8976e-01, time/batch = 0.3511s	
1962/2700 (epoch 36.333), train_loss = 1.86562799, grad/param norm = 2.2154e-01, time/batch = 0.3401s	
1963/2700 (epoch 36.352), train_loss = 1.86477894, grad/param norm = 2.4597e-01, time/batch = 0.3321s	
1964/2700 (epoch 36.370), train_loss = 1.92451951, grad/param norm = 2.7150e-01, time/batch = 0.3763s	
1965/2700 (epoch 36.389), train_loss = 1.87822958, grad/param norm = 2.9443e-01, time/batch = 0.3695s	
1966/2700 (epoch 36.407), train_loss = 1.90055610, grad/param norm = 2.6284e-01, time/batch = 0.3501s	
1967/2700 (epoch 36.426), train_loss = 1.93097988, grad/param norm = 1.7126e-01, time/batch = 0.3451s	
1968/2700 (epoch 36.444), train_loss = 1.84423674, grad/param norm = 1.5595e-01, time/batch = 0.3420s	
1969/2700 (epoch 36.463), train_loss = 1.88372475, grad/param norm = 1.7540e-01, time/batch = 0.3616s	
1970/2700 (epoch 36.481), train_loss = 1.90602470, grad/param norm = 1.9282e-01, time/batch = 0.3703s	
1971/2700 (epoch 36.500), train_loss = 1.85125053, grad/param norm = 2.2124e-01, time/batch = 0.3400s	
1972/2700 (epoch 36.519), train_loss = 1.88924118, grad/param norm = 2.5618e-01, time/batch = 0.3203s	
1973/2700 (epoch 36.537), train_loss = 1.90013271, grad/param norm = 2.7593e-01, time/batch = 0.3575s	
1974/2700 (epoch 36.556), train_loss = 1.86188035, grad/param norm = 2.5970e-01, time/batch = 0.3686s	
1975/2700 (epoch 36.574), train_loss = 1.86321254, grad/param norm = 3.4946e-01, time/batch = 0.3555s	
1976/2700 (epoch 36.593), train_loss = 1.86608304, grad/param norm = 3.2208e-01, time/batch = 0.3479s	
1977/2700 (epoch 36.611), train_loss = 1.81194388, grad/param norm = 2.7697e-01, time/batch = 0.3524s	
1978/2700 (epoch 36.630), train_loss = 1.82972997, grad/param norm = 2.4535e-01, time/batch = 0.3470s	
1979/2700 (epoch 36.648), train_loss = 1.85394642, grad/param norm = 2.1449e-01, time/batch = 0.3516s	
1980/2700 (epoch 36.667), train_loss = 1.85242968, grad/param norm = 2.2950e-01, time/batch = 0.3578s	
1981/2700 (epoch 36.685), train_loss = 1.86632157, grad/param norm = 2.4808e-01, time/batch = 0.3366s	
1982/2700 (epoch 36.704), train_loss = 1.89494780, grad/param norm = 2.2102e-01, time/batch = 0.3682s	
1983/2700 (epoch 36.722), train_loss = 1.83395155, grad/param norm = 2.1594e-01, time/batch = 0.3523s	
1984/2700 (epoch 36.741), train_loss = 1.88466879, grad/param norm = 2.0476e-01, time/batch = 0.3626s	
1985/2700 (epoch 36.759), train_loss = 1.89347391, grad/param norm = 1.8241e-01, time/batch = 0.3340s	
1986/2700 (epoch 36.778), train_loss = 1.91187637, grad/param norm = 1.7275e-01, time/batch = 0.3449s	
1987/2700 (epoch 36.796), train_loss = 1.87166470, grad/param norm = 1.8468e-01, time/batch = 0.3658s	
1988/2700 (epoch 36.815), train_loss = 1.91452641, grad/param norm = 1.8536e-01, time/batch = 0.3483s	
1989/2700 (epoch 36.833), train_loss = 1.88281269, grad/param norm = 2.3809e-01, time/batch = 0.3549s	
1990/2700 (epoch 36.852), train_loss = 1.89589936, grad/param norm = 3.2396e-01, time/batch = 0.3569s	
1991/2700 (epoch 36.870), train_loss = 1.88277438, grad/param norm = 3.4118e-01, time/batch = 0.3551s	
1992/2700 (epoch 36.889), train_loss = 1.87264170, grad/param norm = 2.6591e-01, time/batch = 0.3487s	
1993/2700 (epoch 36.907), train_loss = 1.97411934, grad/param norm = 2.0235e-01, time/batch = 0.3307s	
1994/2700 (epoch 36.926), train_loss = 1.92564809, grad/param norm = 2.0706e-01, time/batch = 0.3535s	
1995/2700 (epoch 36.944), train_loss = 1.91760308, grad/param norm = 2.4525e-01, time/batch = 0.3580s	
1996/2700 (epoch 36.963), train_loss = 1.92578686, grad/param norm = 2.5191e-01, time/batch = 0.3677s	
1997/2700 (epoch 36.981), train_loss = 1.88804837, grad/param norm = 2.3096e-01, time/batch = 0.3518s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
1998/2700 (epoch 37.000), train_loss = 1.92234473, grad/param norm = 2.1116e-01, time/batch = 0.3488s	
1999/2700 (epoch 37.019), train_loss = 1.90758541, grad/param norm = 2.0369e-01, time/batch = 0.3439s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch37.04_1.9975.t7	
2000/2700 (epoch 37.037), train_loss = 1.92713650, grad/param norm = 2.5165e-01, time/batch = 0.3457s	
2001/2700 (epoch 37.056), train_loss = 1.96415694, grad/param norm = 3.0644e-01, time/batch = 0.3496s	
2002/2700 (epoch 37.074), train_loss = 1.84493900, grad/param norm = 2.0056e-01, time/batch = 0.3475s	
2003/2700 (epoch 37.093), train_loss = 1.83921573, grad/param norm = 1.4091e-01, time/batch = 0.3552s	
2004/2700 (epoch 37.111), train_loss = 1.82004744, grad/param norm = 1.9037e-01, time/batch = 0.3605s	
2005/2700 (epoch 37.130), train_loss = 1.89736226, grad/param norm = 2.6719e-01, time/batch = 0.3790s	
2006/2700 (epoch 37.148), train_loss = 1.82356407, grad/param norm = 3.2256e-01, time/batch = 0.3242s	
2007/2700 (epoch 37.167), train_loss = 1.93101899, grad/param norm = 2.5890e-01, time/batch = 0.3634s	
2008/2700 (epoch 37.185), train_loss = 1.85344115, grad/param norm = 2.1594e-01, time/batch = 0.3716s	
2009/2700 (epoch 37.204), train_loss = 1.86245681, grad/param norm = 1.8047e-01, time/batch = 0.3577s	
2010/2700 (epoch 37.222), train_loss = 1.83788898, grad/param norm = 1.8004e-01, time/batch = 0.3531s	
2011/2700 (epoch 37.241), train_loss = 1.75961291, grad/param norm = 2.0697e-01, time/batch = 0.3525s	
2012/2700 (epoch 37.259), train_loss = 1.80295763, grad/param norm = 2.5390e-01, time/batch = 0.3486s	
2013/2700 (epoch 37.278), train_loss = 1.88608108, grad/param norm = 2.9632e-01, time/batch = 0.3525s	
2014/2700 (epoch 37.296), train_loss = 1.86492053, grad/param norm = 2.6981e-01, time/batch = 0.3523s	
2015/2700 (epoch 37.315), train_loss = 1.86915695, grad/param norm = 2.1330e-01, time/batch = 0.3119s	
2016/2700 (epoch 37.333), train_loss = 1.84922382, grad/param norm = 1.7358e-01, time/batch = 0.3517s	
2017/2700 (epoch 37.352), train_loss = 1.84681201, grad/param norm = 1.7009e-01, time/batch = 0.3635s	
2018/2700 (epoch 37.370), train_loss = 1.90422697, grad/param norm = 1.6951e-01, time/batch = 0.3657s	
2019/2700 (epoch 37.389), train_loss = 1.85817919, grad/param norm = 2.1090e-01, time/batch = 0.3532s	
2020/2700 (epoch 37.407), train_loss = 1.89070813, grad/param norm = 2.7121e-01, time/batch = 0.3627s	
2021/2700 (epoch 37.426), train_loss = 1.92007213, grad/param norm = 2.2895e-01, time/batch = 0.3746s	
2022/2700 (epoch 37.444), train_loss = 1.83221069, grad/param norm = 2.5279e-01, time/batch = 0.3623s	
2023/2700 (epoch 37.463), train_loss = 1.87620441, grad/param norm = 2.8450e-01, time/batch = 0.3429s	
2024/2700 (epoch 37.481), train_loss = 1.89034047, grad/param norm = 2.0221e-01, time/batch = 0.2924s	
2025/2700 (epoch 37.500), train_loss = 1.83367450, grad/param norm = 1.8950e-01, time/batch = 0.3513s	
2026/2700 (epoch 37.519), train_loss = 1.87818215, grad/param norm = 2.2775e-01, time/batch = 0.3511s	
2027/2700 (epoch 37.537), train_loss = 1.88410902, grad/param norm = 2.8595e-01, time/batch = 0.3488s	
2028/2700 (epoch 37.556), train_loss = 1.85318308, grad/param norm = 3.2547e-01, time/batch = 0.3439s	
2029/2700 (epoch 37.574), train_loss = 1.85377999, grad/param norm = 3.5161e-01, time/batch = 0.3536s	
2030/2700 (epoch 37.593), train_loss = 1.85384746, grad/param norm = 3.3444e-01, time/batch = 0.3528s	
2031/2700 (epoch 37.611), train_loss = 1.80473295, grad/param norm = 3.4211e-01, time/batch = 0.4096s	
2032/2700 (epoch 37.630), train_loss = 1.81383092, grad/param norm = 2.8888e-01, time/batch = 0.3600s	
2033/2700 (epoch 37.648), train_loss = 1.84037558, grad/param norm = 2.4699e-01, time/batch = 0.2755s	
2034/2700 (epoch 37.667), train_loss = 1.83367222, grad/param norm = 2.5090e-01, time/batch = 0.3733s	
2035/2700 (epoch 37.685), train_loss = 1.84454607, grad/param norm = 2.4508e-01, time/batch = 0.3534s	
2036/2700 (epoch 37.704), train_loss = 1.87783634, grad/param norm = 2.5177e-01, time/batch = 0.3492s	
2037/2700 (epoch 37.722), train_loss = 1.82276445, grad/param norm = 2.8427e-01, time/batch = 0.3597s	
2038/2700 (epoch 37.741), train_loss = 1.87556355, grad/param norm = 2.6028e-01, time/batch = 0.3577s	
2039/2700 (epoch 37.759), train_loss = 1.88951612, grad/param norm = 2.6480e-01, time/batch = 0.3779s	
2040/2700 (epoch 37.778), train_loss = 1.91562158, grad/param norm = 3.1869e-01, time/batch = 0.3776s	
2041/2700 (epoch 37.796), train_loss = 1.87927324, grad/param norm = 3.2766e-01, time/batch = 0.3656s	
2042/2700 (epoch 37.815), train_loss = 1.90928061, grad/param norm = 2.7467e-01, time/batch = 0.2781s	
2043/2700 (epoch 37.833), train_loss = 1.86925230, grad/param norm = 2.0403e-01, time/batch = 0.3828s	
2044/2700 (epoch 37.852), train_loss = 1.87594951, grad/param norm = 1.7734e-01, time/batch = 0.3948s	
2045/2700 (epoch 37.870), train_loss = 1.86091030, grad/param norm = 1.6889e-01, time/batch = 0.3500s	
2046/2700 (epoch 37.889), train_loss = 1.85771396, grad/param norm = 1.9850e-01, time/batch = 0.3519s	
2047/2700 (epoch 37.907), train_loss = 1.96525632, grad/param norm = 2.3686e-01, time/batch = 0.3539s	
2048/2700 (epoch 37.926), train_loss = 1.91425838, grad/param norm = 2.4510e-01, time/batch = 0.3556s	
2049/2700 (epoch 37.944), train_loss = 1.89514766, grad/param norm = 1.7547e-01, time/batch = 0.3758s	
2050/2700 (epoch 37.963), train_loss = 1.90357396, grad/param norm = 1.4227e-01, time/batch = 0.3742s	
2051/2700 (epoch 37.981), train_loss = 1.86720171, grad/param norm = 1.5221e-01, time/batch = 0.2864s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2052/2700 (epoch 38.000), train_loss = 1.90359927, grad/param norm = 1.5911e-01, time/batch = 0.3868s	
2053/2700 (epoch 38.019), train_loss = 1.89344468, grad/param norm = 2.0381e-01, time/batch = 0.3838s	
2054/2700 (epoch 38.037), train_loss = 1.90316577, grad/param norm = 1.9780e-01, time/batch = 0.3485s	
2055/2700 (epoch 38.056), train_loss = 1.84331882, grad/param norm = 2.0667e-01, time/batch = 0.3498s	
2056/2700 (epoch 38.074), train_loss = 1.83145996, grad/param norm = 1.8001e-01, time/batch = 0.3497s	
2057/2700 (epoch 38.093), train_loss = 1.83436702, grad/param norm = 2.4785e-01, time/batch = 0.3704s	
2058/2700 (epoch 38.111), train_loss = 1.81251570, grad/param norm = 2.5105e-01, time/batch = 0.3764s	
2059/2700 (epoch 38.130), train_loss = 1.87926550, grad/param norm = 2.3803e-01, time/batch = 0.3596s	
2060/2700 (epoch 38.148), train_loss = 1.80371284, grad/param norm = 2.8314e-01, time/batch = 0.3445s	
2061/2700 (epoch 38.167), train_loss = 1.91896988, grad/param norm = 3.0454e-01, time/batch = 0.3806s	
2062/2700 (epoch 38.185), train_loss = 1.84392079, grad/param norm = 2.6624e-01, time/batch = 0.3563s	
2063/2700 (epoch 38.204), train_loss = 1.85102426, grad/param norm = 2.6820e-01, time/batch = 0.3464s	
2064/2700 (epoch 38.222), train_loss = 1.82659350, grad/param norm = 2.4762e-01, time/batch = 0.3476s	
2065/2700 (epoch 38.241), train_loss = 1.75199088, grad/param norm = 2.4702e-01, time/batch = 0.3584s	
2066/2700 (epoch 38.259), train_loss = 1.78729711, grad/param norm = 2.0957e-01, time/batch = 0.3676s	
2067/2700 (epoch 38.278), train_loss = 1.85905683, grad/param norm = 1.4982e-01, time/batch = 0.3718s	
2068/2700 (epoch 38.296), train_loss = 1.84343357, grad/param norm = 1.5491e-01, time/batch = 0.3498s	
2069/2700 (epoch 38.315), train_loss = 1.85461423, grad/param norm = 2.0265e-01, time/batch = 0.3358s	
2070/2700 (epoch 38.333), train_loss = 1.84148072, grad/param norm = 2.6526e-01, time/batch = 0.3718s	
2071/2700 (epoch 38.352), train_loss = 1.83807228, grad/param norm = 2.7010e-01, time/batch = 0.3562s	
2072/2700 (epoch 38.370), train_loss = 1.89133353, grad/param norm = 2.3509e-01, time/batch = 0.3436s	
2073/2700 (epoch 38.389), train_loss = 1.84173814, grad/param norm = 2.4823e-01, time/batch = 0.3450s	
2074/2700 (epoch 38.407), train_loss = 1.87258040, grad/param norm = 2.3202e-01, time/batch = 0.3499s	
2075/2700 (epoch 38.426), train_loss = 1.90531145, grad/param norm = 1.5578e-01, time/batch = 0.3598s	
2076/2700 (epoch 38.444), train_loss = 1.82120923, grad/param norm = 1.6411e-01, time/batch = 0.3761s	
2077/2700 (epoch 38.463), train_loss = 1.86124593, grad/param norm = 1.9519e-01, time/batch = 0.3506s	
2078/2700 (epoch 38.481), train_loss = 1.88104213, grad/param norm = 2.2594e-01, time/batch = 0.3235s	
2079/2700 (epoch 38.500), train_loss = 1.82464044, grad/param norm = 2.5498e-01, time/batch = 0.3460s	
2080/2700 (epoch 38.519), train_loss = 1.86467968, grad/param norm = 2.7520e-01, time/batch = 0.3394s	
2081/2700 (epoch 38.537), train_loss = 1.86976998, grad/param norm = 2.5371e-01, time/batch = 0.3466s	
2082/2700 (epoch 38.556), train_loss = 1.83193951, grad/param norm = 2.1422e-01, time/batch = 0.3496s	
2083/2700 (epoch 38.574), train_loss = 1.83168684, grad/param norm = 2.5525e-01, time/batch = 0.3554s	
2084/2700 (epoch 38.593), train_loss = 1.83057459, grad/param norm = 2.4329e-01, time/batch = 0.3429s	
2085/2700 (epoch 38.611), train_loss = 1.77915565, grad/param norm = 2.4763e-01, time/batch = 0.3455s	
2086/2700 (epoch 38.630), train_loss = 1.79622976, grad/param norm = 2.4024e-01, time/batch = 0.3455s	
2087/2700 (epoch 38.648), train_loss = 1.82513921, grad/param norm = 2.4103e-01, time/batch = 0.3222s	
2088/2700 (epoch 38.667), train_loss = 1.82180489, grad/param norm = 2.5225e-01, time/batch = 0.3735s	
2089/2700 (epoch 38.685), train_loss = 1.83273593, grad/param norm = 2.7103e-01, time/batch = 0.3496s	
2090/2700 (epoch 38.704), train_loss = 1.87171952, grad/param norm = 2.6591e-01, time/batch = 0.3562s	
2091/2700 (epoch 38.722), train_loss = 1.81223741, grad/param norm = 2.5387e-01, time/batch = 0.4023s	
2092/2700 (epoch 38.741), train_loss = 1.87061757, grad/param norm = 2.8699e-01, time/batch = 0.3509s	
2093/2700 (epoch 38.759), train_loss = 1.87563100, grad/param norm = 2.7758e-01, time/batch = 0.3458s	
2094/2700 (epoch 38.778), train_loss = 1.88704018, grad/param norm = 2.2633e-01, time/batch = 0.3454s	
2095/2700 (epoch 38.796), train_loss = 1.84179895, grad/param norm = 2.1498e-01, time/batch = 0.3474s	
2096/2700 (epoch 38.815), train_loss = 1.88839414, grad/param norm = 2.1595e-01, time/batch = 0.3271s	
2097/2700 (epoch 38.833), train_loss = 1.85093860, grad/param norm = 1.8289e-01, time/batch = 0.3470s	
2098/2700 (epoch 38.852), train_loss = 1.86184891, grad/param norm = 2.1339e-01, time/batch = 0.3359s	
2099/2700 (epoch 38.870), train_loss = 1.85257768, grad/param norm = 2.2890e-01, time/batch = 0.3552s	
2100/2700 (epoch 38.889), train_loss = 1.84659745, grad/param norm = 2.1609e-01, time/batch = 0.3721s	
2101/2700 (epoch 38.907), train_loss = 1.94929581, grad/param norm = 2.3565e-01, time/batch = 0.3757s	
2102/2700 (epoch 38.926), train_loss = 1.90115202, grad/param norm = 2.3368e-01, time/batch = 0.3492s	
2103/2700 (epoch 38.944), train_loss = 1.88971525, grad/param norm = 2.3039e-01, time/batch = 0.3445s	
2104/2700 (epoch 38.963), train_loss = 1.89859030, grad/param norm = 2.2970e-01, time/batch = 0.3477s	
2105/2700 (epoch 38.981), train_loss = 1.86110199, grad/param norm = 2.3336e-01, time/batch = 0.3509s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2106/2700 (epoch 39.000), train_loss = 1.89468737, grad/param norm = 2.1105e-01, time/batch = 0.3519s	
2107/2700 (epoch 39.019), train_loss = 1.88843187, grad/param norm = 2.0017e-01, time/batch = 0.3427s	
2108/2700 (epoch 39.037), train_loss = 1.90084139, grad/param norm = 2.6276e-01, time/batch = 0.3562s	
2109/2700 (epoch 39.056), train_loss = 1.84058872, grad/param norm = 2.9368e-01, time/batch = 0.3778s	
2110/2700 (epoch 39.074), train_loss = 1.82278781, grad/param norm = 2.1266e-01, time/batch = 0.3765s	
2111/2700 (epoch 39.093), train_loss = 1.81959068, grad/param norm = 1.8764e-01, time/batch = 0.3544s	
2112/2700 (epoch 39.111), train_loss = 1.79375986, grad/param norm = 1.8571e-01, time/batch = 0.3503s	
2113/2700 (epoch 39.130), train_loss = 1.86154624, grad/param norm = 2.0682e-01, time/batch = 0.3450s	
2114/2700 (epoch 39.148), train_loss = 1.78510617, grad/param norm = 2.2758e-01, time/batch = 0.3218s	
2115/2700 (epoch 39.167), train_loss = 1.89669206, grad/param norm = 2.2684e-01, time/batch = 0.3354s	
2116/2700 (epoch 39.185), train_loss = 1.82525846, grad/param norm = 2.4606e-01, time/batch = 0.3478s	
2117/2700 (epoch 39.204), train_loss = 1.83947323, grad/param norm = 2.3153e-01, time/batch = 0.3523s	
2118/2700 (epoch 39.222), train_loss = 1.81492860, grad/param norm = 2.3126e-01, time/batch = 0.3603s	
2119/2700 (epoch 39.241), train_loss = 1.73701859, grad/param norm = 2.3523e-01, time/batch = 0.3751s	
2120/2700 (epoch 39.259), train_loss = 1.77405075, grad/param norm = 2.2826e-01, time/batch = 0.3550s	
2121/2700 (epoch 39.278), train_loss = 1.85476639, grad/param norm = 2.6825e-01, time/batch = 0.3749s	
2122/2700 (epoch 39.296), train_loss = 1.84046891, grad/param norm = 3.0314e-01, time/batch = 0.3454s	
2123/2700 (epoch 39.315), train_loss = 1.84666433, grad/param norm = 2.6036e-01, time/batch = 0.3141s	
2124/2700 (epoch 39.333), train_loss = 1.82564332, grad/param norm = 2.2460e-01, time/batch = 0.3389s	
2125/2700 (epoch 39.352), train_loss = 1.82406034, grad/param norm = 2.2878e-01, time/batch = 0.3166s	
2126/2700 (epoch 39.370), train_loss = 1.88584815, grad/param norm = 2.4901e-01, time/batch = 0.3065s	
2127/2700 (epoch 39.389), train_loss = 1.83826766, grad/param norm = 2.7255e-01, time/batch = 0.3235s	
2128/2700 (epoch 39.407), train_loss = 1.86596440, grad/param norm = 2.8103e-01, time/batch = 0.3155s	
2129/2700 (epoch 39.426), train_loss = 1.89222737, grad/param norm = 2.0270e-01, time/batch = 0.2937s	
2130/2700 (epoch 39.444), train_loss = 1.80659009, grad/param norm = 2.0424e-01, time/batch = 0.2812s	
2131/2700 (epoch 39.463), train_loss = 1.84619670, grad/param norm = 1.9233e-01, time/batch = 0.2642s	
2132/2700 (epoch 39.481), train_loss = 1.85965844, grad/param norm = 1.3242e-01, time/batch = 0.2647s	
2133/2700 (epoch 39.500), train_loss = 1.80261429, grad/param norm = 1.4255e-01, time/batch = 0.2730s	
2134/2700 (epoch 39.519), train_loss = 1.84641132, grad/param norm = 1.4707e-01, time/batch = 0.2733s	
2135/2700 (epoch 39.537), train_loss = 1.85099897, grad/param norm = 1.9143e-01, time/batch = 0.2722s	
2136/2700 (epoch 39.556), train_loss = 1.81498102, grad/param norm = 1.7857e-01, time/batch = 0.2757s	
2137/2700 (epoch 39.574), train_loss = 1.81822867, grad/param norm = 2.2102e-01, time/batch = 0.2797s	
2138/2700 (epoch 39.593), train_loss = 1.82303163, grad/param norm = 2.4803e-01, time/batch = 0.2805s	
2139/2700 (epoch 39.611), train_loss = 1.77248336, grad/param norm = 2.8436e-01, time/batch = 0.2811s	
2140/2700 (epoch 39.630), train_loss = 1.78758519, grad/param norm = 2.5728e-01, time/batch = 0.2762s	
2141/2700 (epoch 39.648), train_loss = 1.81562750, grad/param norm = 2.3891e-01, time/batch = 0.2688s	
2142/2700 (epoch 39.667), train_loss = 1.81083716, grad/param norm = 2.6644e-01, time/batch = 0.2587s	
2143/2700 (epoch 39.685), train_loss = 1.82069058, grad/param norm = 2.7109e-01, time/batch = 0.2720s	
2144/2700 (epoch 39.704), train_loss = 1.85300904, grad/param norm = 2.4665e-01, time/batch = 0.2702s	
2145/2700 (epoch 39.722), train_loss = 1.79615148, grad/param norm = 2.5481e-01, time/batch = 0.2709s	
2146/2700 (epoch 39.741), train_loss = 1.84769208, grad/param norm = 2.4424e-01, time/batch = 0.2718s	
2147/2700 (epoch 39.759), train_loss = 1.85093434, grad/param norm = 2.0747e-01, time/batch = 0.2760s	
2148/2700 (epoch 39.778), train_loss = 1.87595126, grad/param norm = 2.4664e-01, time/batch = 0.2817s	
2149/2700 (epoch 39.796), train_loss = 1.83841908, grad/param norm = 2.7663e-01, time/batch = 0.2835s	
2150/2700 (epoch 39.815), train_loss = 1.87841112, grad/param norm = 2.6599e-01, time/batch = 0.2121s	
2151/2700 (epoch 39.833), train_loss = 1.84745348, grad/param norm = 2.7744e-01, time/batch = 0.2718s	
2152/2700 (epoch 39.852), train_loss = 1.85450995, grad/param norm = 2.7876e-01, time/batch = 0.2670s	
2153/2700 (epoch 39.870), train_loss = 1.83831269, grad/param norm = 2.6218e-01, time/batch = 0.2773s	
2154/2700 (epoch 39.889), train_loss = 1.83299029, grad/param norm = 2.5019e-01, time/batch = 0.2770s	
2155/2700 (epoch 39.907), train_loss = 1.94132061, grad/param norm = 2.6237e-01, time/batch = 0.2757s	
2156/2700 (epoch 39.926), train_loss = 1.89444740, grad/param norm = 2.7080e-01, time/batch = 0.2758s	
2157/2700 (epoch 39.944), train_loss = 1.87130868, grad/param norm = 2.0866e-01, time/batch = 0.2759s	
2158/2700 (epoch 39.963), train_loss = 1.88056382, grad/param norm = 1.7616e-01, time/batch = 0.3216s	
2159/2700 (epoch 39.981), train_loss = 1.84295038, grad/param norm = 1.8796e-01, time/batch = 0.2256s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2160/2700 (epoch 40.000), train_loss = 1.87878520, grad/param norm = 1.6013e-01, time/batch = 0.2729s	
2161/2700 (epoch 40.019), train_loss = 1.87154845, grad/param norm = 1.8372e-01, time/batch = 0.2743s	
2162/2700 (epoch 40.037), train_loss = 1.87631082, grad/param norm = 1.6278e-01, time/batch = 0.2620s	
2163/2700 (epoch 40.056), train_loss = 1.81424155, grad/param norm = 1.5405e-01, time/batch = 0.2738s	
2164/2700 (epoch 40.074), train_loss = 1.80534599, grad/param norm = 1.9650e-01, time/batch = 0.2760s	
2165/2700 (epoch 40.093), train_loss = 1.80407257, grad/param norm = 2.3565e-01, time/batch = 0.2760s	
2166/2700 (epoch 40.111), train_loss = 1.78615089, grad/param norm = 2.3223e-01, time/batch = 0.2750s	
2167/2700 (epoch 40.130), train_loss = 1.85712787, grad/param norm = 2.5736e-01, time/batch = 0.2745s	
2168/2700 (epoch 40.148), train_loss = 1.78160857, grad/param norm = 2.5287e-01, time/batch = 0.2707s	
2169/2700 (epoch 40.167), train_loss = 1.88981770, grad/param norm = 2.1538e-01, time/batch = 0.2716s	
2170/2700 (epoch 40.185), train_loss = 1.81140412, grad/param norm = 1.6412e-01, time/batch = 0.2719s	
2171/2700 (epoch 40.204), train_loss = 1.82267877, grad/param norm = 1.8470e-01, time/batch = 0.2855s	
2172/2700 (epoch 40.222), train_loss = 1.79978222, grad/param norm = 1.8970e-01, time/batch = 0.2447s	
2173/2700 (epoch 40.241), train_loss = 1.72517873, grad/param norm = 2.0843e-01, time/batch = 0.2764s	
2174/2700 (epoch 40.259), train_loss = 1.76204592, grad/param norm = 2.0898e-01, time/batch = 0.2748s	
2175/2700 (epoch 40.278), train_loss = 1.83658914, grad/param norm = 2.0215e-01, time/batch = 0.2763s	
2176/2700 (epoch 40.296), train_loss = 1.81870859, grad/param norm = 1.9028e-01, time/batch = 0.2758s	
2177/2700 (epoch 40.315), train_loss = 1.83111998, grad/param norm = 2.4719e-01, time/batch = 0.2691s	
2178/2700 (epoch 40.333), train_loss = 1.81695924, grad/param norm = 3.0288e-01, time/batch = 0.2746s	
2179/2700 (epoch 40.352), train_loss = 1.81634050, grad/param norm = 3.2421e-01, time/batch = 0.2736s	
2180/2700 (epoch 40.370), train_loss = 1.87449319, grad/param norm = 3.2007e-01, time/batch = 0.2739s	
2181/2700 (epoch 40.389), train_loss = 1.81719477, grad/param norm = 2.8902e-01, time/batch = 0.2834s	
2182/2700 (epoch 40.407), train_loss = 1.84485063, grad/param norm = 2.1964e-01, time/batch = 0.2447s	
2183/2700 (epoch 40.426), train_loss = 1.87888323, grad/param norm = 1.4759e-01, time/batch = 0.2775s	
2184/2700 (epoch 40.444), train_loss = 1.79197806, grad/param norm = 1.3167e-01, time/batch = 0.2769s	
2185/2700 (epoch 40.463), train_loss = 1.83172970, grad/param norm = 1.5784e-01, time/batch = 0.2757s	
2186/2700 (epoch 40.481), train_loss = 1.85316618, grad/param norm = 2.2253e-01, time/batch = 0.2723s	
2187/2700 (epoch 40.500), train_loss = 1.79461695, grad/param norm = 2.4425e-01, time/batch = 0.2597s	
2188/2700 (epoch 40.519), train_loss = 1.83931292, grad/param norm = 2.4311e-01, time/batch = 0.2792s	
2189/2700 (epoch 40.537), train_loss = 1.84242141, grad/param norm = 2.2189e-01, time/batch = 0.2751s	
2190/2700 (epoch 40.556), train_loss = 1.80123101, grad/param norm = 1.7174e-01, time/batch = 0.2766s	
2191/2700 (epoch 40.574), train_loss = 1.80148843, grad/param norm = 2.1328e-01, time/batch = 0.2937s	
2192/2700 (epoch 40.593), train_loss = 1.80563437, grad/param norm = 2.2287e-01, time/batch = 0.3317s	
2193/2700 (epoch 40.611), train_loss = 1.75379984, grad/param norm = 2.3447e-01, time/batch = 0.3405s	
2194/2700 (epoch 40.630), train_loss = 1.77113978, grad/param norm = 2.2897e-01, time/batch = 0.3061s	
2195/2700 (epoch 40.648), train_loss = 1.80138556, grad/param norm = 2.3697e-01, time/batch = 0.3042s	
2196/2700 (epoch 40.667), train_loss = 1.79962556, grad/param norm = 2.5486e-01, time/batch = 0.2968s	
2197/2700 (epoch 40.685), train_loss = 1.80856027, grad/param norm = 2.7228e-01, time/batch = 0.3187s	
2198/2700 (epoch 40.704), train_loss = 1.84320525, grad/param norm = 2.4830e-01, time/batch = 0.3061s	
2199/2700 (epoch 40.722), train_loss = 1.78257034, grad/param norm = 2.4140e-01, time/batch = 0.3252s	
2200/2700 (epoch 40.741), train_loss = 1.83413502, grad/param norm = 2.8516e-01, time/batch = 0.3368s	
2201/2700 (epoch 40.759), train_loss = 1.84616575, grad/param norm = 3.5082e-01, time/batch = 0.3140s	
2202/2700 (epoch 40.778), train_loss = 1.87163203, grad/param norm = 3.4326e-01, time/batch = 0.3178s	
2203/2700 (epoch 40.796), train_loss = 1.82563362, grad/param norm = 2.8744e-01, time/batch = 0.3126s	
2204/2700 (epoch 40.815), train_loss = 1.86840453, grad/param norm = 2.6359e-01, time/batch = 0.3037s	
2205/2700 (epoch 40.833), train_loss = 1.83001195, grad/param norm = 2.0522e-01, time/batch = 0.3124s	
2206/2700 (epoch 40.852), train_loss = 1.83657162, grad/param norm = 1.6656e-01, time/batch = 0.3398s	
2207/2700 (epoch 40.870), train_loss = 1.82336304, grad/param norm = 1.5239e-01, time/batch = 0.3372s	
2208/2700 (epoch 40.889), train_loss = 1.81895867, grad/param norm = 1.8949e-01, time/batch = 0.3579s	
2209/2700 (epoch 40.907), train_loss = 1.92469441, grad/param norm = 2.1011e-01, time/batch = 0.3090s	
2210/2700 (epoch 40.926), train_loss = 1.87648997, grad/param norm = 1.8388e-01, time/batch = 0.3039s	
2211/2700 (epoch 40.944), train_loss = 1.85795568, grad/param norm = 1.4533e-01, time/batch = 0.3284s	
2212/2700 (epoch 40.963), train_loss = 1.86765258, grad/param norm = 1.4379e-01, time/batch = 0.3323s	
2213/2700 (epoch 40.981), train_loss = 1.82947596, grad/param norm = 1.6638e-01, time/batch = 0.3478s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2214/2700 (epoch 41.000), train_loss = 1.86598352, grad/param norm = 1.6958e-01, time/batch = 0.3233s	
2215/2700 (epoch 41.019), train_loss = 1.86101777, grad/param norm = 1.6345e-01, time/batch = 0.3055s	
2216/2700 (epoch 41.037), train_loss = 1.86589196, grad/param norm = 2.2737e-01, time/batch = 0.3291s	
2217/2700 (epoch 41.056), train_loss = 1.81041067, grad/param norm = 2.9555e-01, time/batch = 0.3047s	
2218/2700 (epoch 41.074), train_loss = 1.79691475, grad/param norm = 2.1788e-01, time/batch = 0.3221s	
2219/2700 (epoch 41.093), train_loss = 1.79218652, grad/param norm = 1.9421e-01, time/batch = 0.3127s	
2220/2700 (epoch 41.111), train_loss = 1.77261116, grad/param norm = 2.0712e-01, time/batch = 0.3229s	
2221/2700 (epoch 41.130), train_loss = 1.83968087, grad/param norm = 2.2925e-01, time/batch = 0.3217s	
2222/2700 (epoch 41.148), train_loss = 1.75955657, grad/param norm = 1.8280e-01, time/batch = 0.2525s	
2223/2700 (epoch 41.167), train_loss = 1.87399960, grad/param norm = 2.5215e-01, time/batch = 0.2722s	
2224/2700 (epoch 41.185), train_loss = 1.80497096, grad/param norm = 2.7133e-01, time/batch = 0.3078s	
2225/2700 (epoch 41.204), train_loss = 1.82332842, grad/param norm = 2.6242e-01, time/batch = 0.3271s	
2226/2700 (epoch 41.222), train_loss = 1.79425419, grad/param norm = 2.3565e-01, time/batch = 0.3388s	
2227/2700 (epoch 41.241), train_loss = 1.71942781, grad/param norm = 2.1900e-01, time/batch = 0.3339s	
2228/2700 (epoch 41.259), train_loss = 1.74742778, grad/param norm = 1.5321e-01, time/batch = 0.3402s	
2229/2700 (epoch 41.278), train_loss = 1.82372123, grad/param norm = 1.3121e-01, time/batch = 0.3406s	
2230/2700 (epoch 41.296), train_loss = 1.80739400, grad/param norm = 1.8070e-01, time/batch = 0.2953s	
2231/2700 (epoch 41.315), train_loss = 1.81670204, grad/param norm = 1.7204e-01, time/batch = 0.3411s	
2232/2700 (epoch 41.333), train_loss = 1.80043051, grad/param norm = 1.8031e-01, time/batch = 0.3221s	
2233/2700 (epoch 41.352), train_loss = 1.79226963, grad/param norm = 1.7245e-01, time/batch = 0.3141s	
2234/2700 (epoch 41.370), train_loss = 1.84517397, grad/param norm = 1.6420e-01, time/batch = 0.3067s	
2235/2700 (epoch 41.389), train_loss = 1.79916965, grad/param norm = 2.2372e-01, time/batch = 0.3170s	
2236/2700 (epoch 41.407), train_loss = 1.84223920, grad/param norm = 3.2914e-01, time/batch = 0.2935s	
2237/2700 (epoch 41.426), train_loss = 1.87699158, grad/param norm = 3.3471e-01, time/batch = 0.3033s	
2238/2700 (epoch 41.444), train_loss = 1.79503809, grad/param norm = 3.5772e-01, time/batch = 0.3354s	
2239/2700 (epoch 41.463), train_loss = 1.83539028, grad/param norm = 3.4333e-01, time/batch = 0.3342s	
2240/2700 (epoch 41.481), train_loss = 1.83879145, grad/param norm = 2.1854e-01, time/batch = 0.3433s	
2241/2700 (epoch 41.500), train_loss = 1.77638854, grad/param norm = 1.9535e-01, time/batch = 0.3232s	
2242/2700 (epoch 41.519), train_loss = 1.82843119, grad/param norm = 2.3770e-01, time/batch = 0.3239s	
2243/2700 (epoch 41.537), train_loss = 1.83456182, grad/param norm = 2.8440e-01, time/batch = 0.3284s	
2244/2700 (epoch 41.556), train_loss = 1.79432290, grad/param norm = 2.8461e-01, time/batch = 0.3220s	
2245/2700 (epoch 41.574), train_loss = 1.79784538, grad/param norm = 3.0051e-01, time/batch = 0.3320s	
2246/2700 (epoch 41.593), train_loss = 1.80090007, grad/param norm = 2.9289e-01, time/batch = 0.3305s	
2247/2700 (epoch 41.611), train_loss = 1.74840736, grad/param norm = 2.9515e-01, time/batch = 0.3021s	
2248/2700 (epoch 41.630), train_loss = 1.75841216, grad/param norm = 2.5390e-01, time/batch = 0.3287s	
2249/2700 (epoch 41.648), train_loss = 1.78853090, grad/param norm = 2.2110e-01, time/batch = 0.3158s	
2250/2700 (epoch 41.667), train_loss = 1.78231588, grad/param norm = 2.2039e-01, time/batch = 0.3260s	
2251/2700 (epoch 41.685), train_loss = 1.79382045, grad/param norm = 2.2257e-01, time/batch = 0.3154s	
2252/2700 (epoch 41.704), train_loss = 1.82879454, grad/param norm = 2.6039e-01, time/batch = 0.3194s	
2253/2700 (epoch 41.722), train_loss = 1.77764016, grad/param norm = 3.1182e-01, time/batch = 0.3125s	
2254/2700 (epoch 41.741), train_loss = 1.82505479, grad/param norm = 2.7640e-01, time/batch = 0.3259s	
2255/2700 (epoch 41.759), train_loss = 1.82857889, grad/param norm = 2.5757e-01, time/batch = 0.3250s	
2256/2700 (epoch 41.778), train_loss = 1.85730214, grad/param norm = 3.0714e-01, time/batch = 0.3217s	
2257/2700 (epoch 41.796), train_loss = 1.81656076, grad/param norm = 2.8741e-01, time/batch = 0.3298s	
2258/2700 (epoch 41.815), train_loss = 1.84814235, grad/param norm = 1.9597e-01, time/batch = 0.3096s	
2259/2700 (epoch 41.833), train_loss = 1.81565614, grad/param norm = 1.7308e-01, time/batch = 0.3275s	
2260/2700 (epoch 41.852), train_loss = 1.82410596, grad/param norm = 2.0801e-01, time/batch = 0.3179s	
2261/2700 (epoch 41.870), train_loss = 1.81318474, grad/param norm = 1.8961e-01, time/batch = 0.3250s	
2262/2700 (epoch 41.889), train_loss = 1.80629964, grad/param norm = 1.9447e-01, time/batch = 0.3111s	
2263/2700 (epoch 41.907), train_loss = 1.91310344, grad/param norm = 1.9769e-01, time/batch = 0.3244s	
2264/2700 (epoch 41.926), train_loss = 1.86347175, grad/param norm = 1.6855e-01, time/batch = 0.3045s	
2265/2700 (epoch 41.944), train_loss = 1.84402961, grad/param norm = 1.3940e-01, time/batch = 0.3185s	
2266/2700 (epoch 41.963), train_loss = 1.85602161, grad/param norm = 1.5132e-01, time/batch = 0.3478s	
2267/2700 (epoch 41.981), train_loss = 1.81794616, grad/param norm = 1.5629e-01, time/batch = 0.3161s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2268/2700 (epoch 42.000), train_loss = 1.85446127, grad/param norm = 1.5030e-01, time/batch = 0.3023s	
2269/2700 (epoch 42.019), train_loss = 1.84947357, grad/param norm = 1.5201e-01, time/batch = 0.2724s	
2270/2700 (epoch 42.037), train_loss = 1.85179792, grad/param norm = 1.6463e-01, time/batch = 0.3332s	
2271/2700 (epoch 42.056), train_loss = 1.78996536, grad/param norm = 1.8645e-01, time/batch = 0.3090s	
2272/2700 (epoch 42.074), train_loss = 1.78106334, grad/param norm = 1.8172e-01, time/batch = 0.3330s	
2273/2700 (epoch 42.093), train_loss = 1.77558066, grad/param norm = 2.0574e-01, time/batch = 0.2971s	
2274/2700 (epoch 42.111), train_loss = 1.75960397, grad/param norm = 2.1715e-01, time/batch = 0.3247s	
2275/2700 (epoch 42.130), train_loss = 1.83253631, grad/param norm = 2.6163e-01, time/batch = 0.3350s	
2276/2700 (epoch 42.148), train_loss = 1.75950067, grad/param norm = 2.8503e-01, time/batch = 0.3258s	
2277/2700 (epoch 42.167), train_loss = 1.86582249, grad/param norm = 2.1177e-01, time/batch = 0.3176s	
2278/2700 (epoch 42.185), train_loss = 1.78692567, grad/param norm = 1.5974e-01, time/batch = 0.3199s	
2279/2700 (epoch 42.204), train_loss = 1.79931500, grad/param norm = 1.7499e-01, time/batch = 0.3335s	
2280/2700 (epoch 42.222), train_loss = 1.77758559, grad/param norm = 1.8940e-01, time/batch = 0.3163s	
2281/2700 (epoch 42.241), train_loss = 1.70513952, grad/param norm = 2.1667e-01, time/batch = 0.3570s	
2282/2700 (epoch 42.259), train_loss = 1.74117493, grad/param norm = 2.2836e-01, time/batch = 0.3268s	
2283/2700 (epoch 42.278), train_loss = 1.81842223, grad/param norm = 2.3317e-01, time/batch = 0.3105s	
2284/2700 (epoch 42.296), train_loss = 1.79958682, grad/param norm = 2.1187e-01, time/batch = 0.3315s	
2285/2700 (epoch 42.315), train_loss = 1.80649673, grad/param norm = 2.0927e-01, time/batch = 0.3212s	
2286/2700 (epoch 42.333), train_loss = 1.78737911, grad/param norm = 2.2872e-01, time/batch = 0.3167s	
2287/2700 (epoch 42.352), train_loss = 1.78560226, grad/param norm = 2.2114e-01, time/batch = 0.3155s	
2288/2700 (epoch 42.370), train_loss = 1.84421758, grad/param norm = 2.6287e-01, time/batch = 0.3382s	
2289/2700 (epoch 42.389), train_loss = 1.79339242, grad/param norm = 2.9070e-01, time/batch = 0.3389s	
2290/2700 (epoch 42.407), train_loss = 1.82412280, grad/param norm = 2.3926e-01, time/batch = 0.3385s	
2291/2700 (epoch 42.426), train_loss = 1.85608121, grad/param norm = 1.5933e-01, time/batch = 0.3090s	
2292/2700 (epoch 42.444), train_loss = 1.77312883, grad/param norm = 1.7123e-01, time/batch = 0.3129s	
2293/2700 (epoch 42.463), train_loss = 1.81438774, grad/param norm = 2.1014e-01, time/batch = 0.3297s	
2294/2700 (epoch 42.481), train_loss = 1.83418773, grad/param norm = 2.7614e-01, time/batch = 0.3181s	
2295/2700 (epoch 42.500), train_loss = 1.77226099, grad/param norm = 2.7428e-01, time/batch = 0.3087s	
2296/2700 (epoch 42.519), train_loss = 1.81593983, grad/param norm = 2.5749e-01, time/batch = 0.3346s	
2297/2700 (epoch 42.537), train_loss = 1.82031507, grad/param norm = 2.6161e-01, time/batch = 0.3674s	
2298/2700 (epoch 42.556), train_loss = 1.77819983, grad/param norm = 2.1573e-01, time/batch = 0.2901s	
2299/2700 (epoch 42.574), train_loss = 1.78116426, grad/param norm = 2.6893e-01, time/batch = 0.3147s	
2300/2700 (epoch 42.593), train_loss = 1.78508594, grad/param norm = 2.8123e-01, time/batch = 0.3252s	
2301/2700 (epoch 42.611), train_loss = 1.73211859, grad/param norm = 2.8819e-01, time/batch = 0.3268s	
2302/2700 (epoch 42.630), train_loss = 1.75248285, grad/param norm = 2.8860e-01, time/batch = 0.3219s	
2303/2700 (epoch 42.648), train_loss = 1.78112670, grad/param norm = 2.8160e-01, time/batch = 0.3065s	
2304/2700 (epoch 42.667), train_loss = 1.77749183, grad/param norm = 2.7291e-01, time/batch = 0.3164s	
2305/2700 (epoch 42.685), train_loss = 1.78790672, grad/param norm = 2.7274e-01, time/batch = 0.3338s	
2306/2700 (epoch 42.704), train_loss = 1.81747616, grad/param norm = 2.2231e-01, time/batch = 0.3168s	
2307/2700 (epoch 42.722), train_loss = 1.75807160, grad/param norm = 1.9527e-01, time/batch = 0.3044s	
2308/2700 (epoch 42.741), train_loss = 1.80470185, grad/param norm = 2.1523e-01, time/batch = 0.3209s	
2309/2700 (epoch 42.759), train_loss = 1.80840789, grad/param norm = 2.3741e-01, time/batch = 0.3141s	
2310/2700 (epoch 42.778), train_loss = 1.83768438, grad/param norm = 2.4116e-01, time/batch = 0.3325s	
2311/2700 (epoch 42.796), train_loss = 1.79845977, grad/param norm = 2.2973e-01, time/batch = 0.3309s	
2312/2700 (epoch 42.815), train_loss = 1.83539550, grad/param norm = 2.0575e-01, time/batch = 0.3472s	
2313/2700 (epoch 42.833), train_loss = 1.80496928, grad/param norm = 1.7470e-01, time/batch = 0.2935s	
2314/2700 (epoch 42.852), train_loss = 1.81197130, grad/param norm = 1.7160e-01, time/batch = 0.3104s	
2315/2700 (epoch 42.870), train_loss = 1.80174069, grad/param norm = 1.6209e-01, time/batch = 0.3198s	
2316/2700 (epoch 42.889), train_loss = 1.79322004, grad/param norm = 1.8363e-01, time/batch = 0.3225s	
2317/2700 (epoch 42.907), train_loss = 1.89986185, grad/param norm = 2.0290e-01, time/batch = 0.3218s	
2318/2700 (epoch 42.926), train_loss = 1.85237077, grad/param norm = 1.9058e-01, time/batch = 0.3066s	
2319/2700 (epoch 42.944), train_loss = 1.83443779, grad/param norm = 1.5916e-01, time/batch = 0.3348s	
2320/2700 (epoch 42.963), train_loss = 1.84487610, grad/param norm = 1.6718e-01, time/batch = 0.3574s	
2321/2700 (epoch 42.981), train_loss = 1.80700991, grad/param norm = 2.0093e-01, time/batch = 0.3141s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
2322/2700 (epoch 43.000), train_loss = 1.84534555, grad/param norm = 2.0192e-01, time/batch = 0.3143s	
2323/2700 (epoch 43.019), train_loss = 1.84210918, grad/param norm = 1.8511e-01, time/batch = 0.3093s	
2324/2700 (epoch 43.037), train_loss = 1.84283509, grad/param norm = 2.5395e-01, time/batch = 0.3217s	
2325/2700 (epoch 43.056), train_loss = 1.78592569, grad/param norm = 3.0074e-01, time/batch = 0.3203s	
2326/2700 (epoch 43.074), train_loss = 1.77121665, grad/param norm = 1.9789e-01, time/batch = 0.3066s	
2327/2700 (epoch 43.093), train_loss = 1.76642328, grad/param norm = 1.7585e-01, time/batch = 0.3177s	
2328/2700 (epoch 43.111), train_loss = 1.74603291, grad/param norm = 1.8378e-01, time/batch = 0.3346s	
2329/2700 (epoch 43.130), train_loss = 1.81096401, grad/param norm = 1.6119e-01, time/batch = 0.3180s	
2330/2700 (epoch 43.148), train_loss = 1.73477495, grad/param norm = 1.4217e-01, time/batch = 0.3117s	
2331/2700 (epoch 43.167), train_loss = 1.84872794, grad/param norm = 2.1693e-01, time/batch = 0.3220s	
2332/2700 (epoch 43.185), train_loss = 1.77877912, grad/param norm = 2.2520e-01, time/batch = 0.3079s	
2333/2700 (epoch 43.204), train_loss = 1.79452729, grad/param norm = 2.2193e-01, time/batch = 0.3075s	
2334/2700 (epoch 43.222), train_loss = 1.76826933, grad/param norm = 2.0211e-01, time/batch = 0.3331s	
2335/2700 (epoch 43.241), train_loss = 1.69646510, grad/param norm = 2.0742e-01, time/batch = 0.3583s	
2336/2700 (epoch 43.259), train_loss = 1.72498226, grad/param norm = 1.6151e-01, time/batch = 0.2903s	
2337/2700 (epoch 43.278), train_loss = 1.80103402, grad/param norm = 1.2227e-01, time/batch = 0.2924s	
2338/2700 (epoch 43.296), train_loss = 1.78299383, grad/param norm = 1.6056e-01, time/batch = 0.2234s	
2339/2700 (epoch 43.315), train_loss = 1.79471344, grad/param norm = 1.7339e-01, time/batch = 0.1968s	
2340/2700 (epoch 43.333), train_loss = 1.77627660, grad/param norm = 2.0624e-01, time/batch = 0.1983s	
2341/2700 (epoch 43.352), train_loss = 1.77040595, grad/param norm = 1.9599e-01, time/batch = 0.1518s	
2342/2700 (epoch 43.370), train_loss = 1.82139922, grad/param norm = 1.5983e-01, time/batch = 0.1937s	
2343/2700 (epoch 43.389), train_loss = 1.77377806, grad/param norm = 1.7851e-01, time/batch = 0.1948s	
2344/2700 (epoch 43.407), train_loss = 1.81003474, grad/param norm = 1.7691e-01, time/batch = 0.1937s	
2345/2700 (epoch 43.426), train_loss = 1.84373046, grad/param norm = 1.9117e-01, time/batch = 0.1967s	
2346/2700 (epoch 43.444), train_loss = 1.76264357, grad/param norm = 2.2766e-01, time/batch = 0.1971s	
2347/2700 (epoch 43.463), train_loss = 1.80625044, grad/param norm = 2.6382e-01, time/batch = 0.1925s	
2348/2700 (epoch 43.481), train_loss = 1.81795043, grad/param norm = 2.4570e-01, time/batch = 0.1912s	
2349/2700 (epoch 43.500), train_loss = 1.75917764, grad/param norm = 2.7036e-01, time/batch = 0.1906s	
2350/2700 (epoch 43.519), train_loss = 1.81660213, grad/param norm = 3.3681e-01, time/batch = 0.1915s	
2351/2700 (epoch 43.537), train_loss = 1.82267410, grad/param norm = 3.7957e-01, time/batch = 0.1980s	
2352/2700 (epoch 43.556), train_loss = 1.78101386, grad/param norm = 3.7703e-01, time/batch = 0.1936s	
2353/2700 (epoch 43.574), train_loss = 1.77847394, grad/param norm = 3.5767e-01, time/batch = 0.1904s	
2354/2700 (epoch 43.593), train_loss = 1.77975103, grad/param norm = 3.2837e-01, time/batch = 0.1901s	
2355/2700 (epoch 43.611), train_loss = 1.72662035, grad/param norm = 3.2138e-01, time/batch = 0.1888s	
2356/2700 (epoch 43.630), train_loss = 1.73669902, grad/param norm = 2.7743e-01, time/batch = 0.1941s	
2357/2700 (epoch 43.648), train_loss = 1.76665820, grad/param norm = 2.2790e-01, time/batch = 0.1933s	
2358/2700 (epoch 43.667), train_loss = 1.75977808, grad/param norm = 2.1837e-01, time/batch = 0.1950s	
2359/2700 (epoch 43.685), train_loss = 1.77217953, grad/param norm = 2.1410e-01, time/batch = 0.1900s	
2360/2700 (epoch 43.704), train_loss = 1.80553535, grad/param norm = 2.4548e-01, time/batch = 0.1954s	
2361/2700 (epoch 43.722), train_loss = 1.75313258, grad/param norm = 2.7991e-01, time/batch = 0.1952s	
2362/2700 (epoch 43.741), train_loss = 1.79873862, grad/param norm = 2.3581e-01, time/batch = 0.1930s	
2363/2700 (epoch 43.759), train_loss = 1.79737417, grad/param norm = 2.0288e-01, time/batch = 0.1904s	
2364/2700 (epoch 43.778), train_loss = 1.82694283, grad/param norm = 2.3449e-01, time/batch = 0.1925s	
2365/2700 (epoch 43.796), train_loss = 1.78426444, grad/param norm = 2.3496e-01, time/batch = 0.1954s	
2366/2700 (epoch 43.815), train_loss = 1.82076006, grad/param norm = 1.7569e-01, time/batch = 0.1944s	
2367/2700 (epoch 43.833), train_loss = 1.79338911, grad/param norm = 1.9471e-01, time/batch = 0.1953s	
2368/2700 (epoch 43.852), train_loss = 1.80396577, grad/param norm = 2.4454e-01, time/batch = 0.1896s	
2369/2700 (epoch 43.870), train_loss = 1.79343120, grad/param norm = 2.1795e-01, time/batch = 0.1958s	
2370/2700 (epoch 43.889), train_loss = 1.78510627, grad/param norm = 2.0176e-01, time/batch = 0.1939s	
2371/2700 (epoch 43.907), train_loss = 1.89185256, grad/param norm = 2.0477e-01, time/batch = 0.1974s	
2372/2700 (epoch 43.926), train_loss = 1.84344882, grad/param norm = 1.8033e-01, time/batch = 0.1905s	
2373/2700 (epoch 43.944), train_loss = 1.82298954, grad/param norm = 1.6265e-01, time/batch = 0.1910s	
2374/2700 (epoch 43.963), train_loss = 1.83419677, grad/param norm = 1.6710e-01, time/batch = 0.1912s	
2375/2700 (epoch 43.981), train_loss = 1.79557645, grad/param norm = 1.6553e-01, time/batch = 0.1951s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
2376/2700 (epoch 44.000), train_loss = 1.83096803, grad/param norm = 1.6055e-01, time/batch = 0.1927s	
2377/2700 (epoch 44.019), train_loss = 1.83243912, grad/param norm = 1.9209e-01, time/batch = 0.1901s	
2378/2700 (epoch 44.037), train_loss = 1.82798174, grad/param norm = 1.7772e-01, time/batch = 0.1917s	
2379/2700 (epoch 44.056), train_loss = 1.76440341, grad/param norm = 1.7426e-01, time/batch = 0.1952s	
2380/2700 (epoch 44.074), train_loss = 1.76108408, grad/param norm = 2.4943e-01, time/batch = 0.1929s	
2381/2700 (epoch 44.093), train_loss = 1.75883587, grad/param norm = 2.7391e-01, time/batch = 0.1937s	
2382/2700 (epoch 44.111), train_loss = 1.73777005, grad/param norm = 2.4271e-01, time/batch = 0.1911s	
2383/2700 (epoch 44.130), train_loss = 1.80590634, grad/param norm = 2.6095e-01, time/batch = 0.1908s	
2384/2700 (epoch 44.148), train_loss = 1.73408465, grad/param norm = 2.4771e-01, time/batch = 0.1928s	
2385/2700 (epoch 44.167), train_loss = 1.83895208, grad/param norm = 1.8361e-01, time/batch = 0.1939s	
2386/2700 (epoch 44.185), train_loss = 1.76441331, grad/param norm = 1.4994e-01, time/batch = 0.1910s	
2387/2700 (epoch 44.204), train_loss = 1.77693747, grad/param norm = 1.7053e-01, time/batch = 0.1915s	
2388/2700 (epoch 44.222), train_loss = 1.75544154, grad/param norm = 1.7123e-01, time/batch = 0.1958s	
2389/2700 (epoch 44.241), train_loss = 1.68431344, grad/param norm = 1.9114e-01, time/batch = 0.1953s	
2390/2700 (epoch 44.259), train_loss = 1.71652451, grad/param norm = 1.8862e-01, time/batch = 0.1958s	
2391/2700 (epoch 44.278), train_loss = 1.79386499, grad/param norm = 1.9318e-01, time/batch = 0.1955s	
2392/2700 (epoch 44.296), train_loss = 1.77455040, grad/param norm = 1.7993e-01, time/batch = 0.1909s	
2393/2700 (epoch 44.315), train_loss = 1.78104055, grad/param norm = 1.6052e-01, time/batch = 0.1913s	
2394/2700 (epoch 44.333), train_loss = 1.76251481, grad/param norm = 1.8332e-01, time/batch = 0.1909s	
2395/2700 (epoch 44.352), train_loss = 1.75891254, grad/param norm = 1.6781e-01, time/batch = 0.1936s	
2396/2700 (epoch 44.370), train_loss = 1.81710889, grad/param norm = 2.4177e-01, time/batch = 0.1900s	
2397/2700 (epoch 44.389), train_loss = 1.77175504, grad/param norm = 3.1230e-01, time/batch = 0.1932s	
2398/2700 (epoch 44.407), train_loss = 1.80716264, grad/param norm = 2.8825e-01, time/batch = 0.1950s	
2399/2700 (epoch 44.426), train_loss = 1.83419248, grad/param norm = 1.7304e-01, time/batch = 0.1930s	
2400/2700 (epoch 44.444), train_loss = 1.75271056, grad/param norm = 2.0488e-01, time/batch = 0.1941s	
2401/2700 (epoch 44.463), train_loss = 1.79533212, grad/param norm = 2.3991e-01, time/batch = 0.1941s	
2402/2700 (epoch 44.481), train_loss = 1.80992161, grad/param norm = 2.6293e-01, time/batch = 0.1908s	
2403/2700 (epoch 44.500), train_loss = 1.74854414, grad/param norm = 2.7248e-01, time/batch = 0.1902s	
2404/2700 (epoch 44.519), train_loss = 1.79505656, grad/param norm = 2.5992e-01, time/batch = 0.1887s	
2405/2700 (epoch 44.537), train_loss = 1.79809999, grad/param norm = 2.5009e-01, time/batch = 0.1903s	
2406/2700 (epoch 44.556), train_loss = 1.75512520, grad/param norm = 2.0387e-01, time/batch = 0.1908s	
2407/2700 (epoch 44.574), train_loss = 1.75531965, grad/param norm = 2.3719e-01, time/batch = 0.1960s	
2408/2700 (epoch 44.593), train_loss = 1.76233421, grad/param norm = 2.7511e-01, time/batch = 0.1941s	
2409/2700 (epoch 44.611), train_loss = 1.70840799, grad/param norm = 2.8801e-01, time/batch = 0.1956s	
2410/2700 (epoch 44.630), train_loss = 1.72728539, grad/param norm = 2.8831e-01, time/batch = 0.1933s	
2411/2700 (epoch 44.648), train_loss = 1.75900836, grad/param norm = 2.8343e-01, time/batch = 0.1943s	
2412/2700 (epoch 44.667), train_loss = 1.75421450, grad/param norm = 2.6517e-01, time/batch = 0.1899s	
2413/2700 (epoch 44.685), train_loss = 1.76500723, grad/param norm = 2.6468e-01, time/batch = 0.1892s	
2414/2700 (epoch 44.704), train_loss = 1.79575411, grad/param norm = 2.3098e-01, time/batch = 0.1897s	
2415/2700 (epoch 44.722), train_loss = 1.73727936, grad/param norm = 2.0620e-01, time/batch = 0.1924s	
2416/2700 (epoch 44.741), train_loss = 1.78205860, grad/param norm = 2.2974e-01, time/batch = 0.1884s	
2417/2700 (epoch 44.759), train_loss = 1.78429926, grad/param norm = 2.5230e-01, time/batch = 0.1944s	
2418/2700 (epoch 44.778), train_loss = 1.81407777, grad/param norm = 2.3936e-01, time/batch = 0.1928s	
2419/2700 (epoch 44.796), train_loss = 1.77407924, grad/param norm = 2.0431e-01, time/batch = 0.1944s	
2420/2700 (epoch 44.815), train_loss = 1.81100423, grad/param norm = 1.8286e-01, time/batch = 0.1928s	
2421/2700 (epoch 44.833), train_loss = 1.78493565, grad/param norm = 1.8609e-01, time/batch = 0.1929s	
2422/2700 (epoch 44.852), train_loss = 1.79324512, grad/param norm = 2.1635e-01, time/batch = 0.1906s	
2423/2700 (epoch 44.870), train_loss = 1.78693015, grad/param norm = 2.0732e-01, time/batch = 0.1510s	
2424/2700 (epoch 44.889), train_loss = 1.77429034, grad/param norm = 2.1068e-01, time/batch = 0.1492s	
2425/2700 (epoch 44.907), train_loss = 1.88153623, grad/param norm = 1.9826e-01, time/batch = 0.1367s	
2426/2700 (epoch 44.926), train_loss = 1.83147301, grad/param norm = 1.7790e-01, time/batch = 0.1423s	
2427/2700 (epoch 44.944), train_loss = 1.81656830, grad/param norm = 1.8931e-01, time/batch = 0.1289s	
2428/2700 (epoch 44.963), train_loss = 1.82678151, grad/param norm = 2.1488e-01, time/batch = 0.1348s	
2429/2700 (epoch 44.981), train_loss = 1.78836602, grad/param norm = 2.4045e-01, time/batch = 0.1295s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
2430/2700 (epoch 45.000), train_loss = 1.82381031, grad/param norm = 2.1410e-01, time/batch = 0.1304s	
2431/2700 (epoch 45.019), train_loss = 1.82152745, grad/param norm = 1.7262e-01, time/batch = 0.1346s	
2432/2700 (epoch 45.037), train_loss = 1.82022849, grad/param norm = 2.5749e-01, time/batch = 0.1286s	
2433/2700 (epoch 45.056), train_loss = 1.76105833, grad/param norm = 2.8921e-01, time/batch = 0.1332s	
2434/2700 (epoch 45.074), train_loss = 1.75006992, grad/param norm = 1.9376e-01, time/batch = 0.1315s	
2435/2700 (epoch 45.093), train_loss = 1.74490457, grad/param norm = 1.7217e-01, time/batch = 0.1276s	
2436/2700 (epoch 45.111), train_loss = 1.72513517, grad/param norm = 1.8754e-01, time/batch = 0.1335s	
2437/2700 (epoch 45.130), train_loss = 1.78734620, grad/param norm = 1.4518e-01, time/batch = 0.1295s	
2438/2700 (epoch 45.148), train_loss = 1.71530508, grad/param norm = 1.6473e-01, time/batch = 0.1299s	
2439/2700 (epoch 45.167), train_loss = 1.83231410, grad/param norm = 2.6891e-01, time/batch = 0.1338s	
2440/2700 (epoch 45.185), train_loss = 1.75989086, grad/param norm = 2.5348e-01, time/batch = 0.1306s	
2441/2700 (epoch 45.204), train_loss = 1.77276526, grad/param norm = 2.3995e-01, time/batch = 0.1336s	
2442/2700 (epoch 45.222), train_loss = 1.74665652, grad/param norm = 2.1099e-01, time/batch = 0.1357s	
2443/2700 (epoch 45.241), train_loss = 1.67750119, grad/param norm = 2.2806e-01, time/batch = 0.1283s	
2444/2700 (epoch 45.259), train_loss = 1.70593620, grad/param norm = 1.9942e-01, time/batch = 0.1328s	
2445/2700 (epoch 45.278), train_loss = 1.78246795, grad/param norm = 1.5355e-01, time/batch = 0.1337s	
2446/2700 (epoch 45.296), train_loss = 1.76093953, grad/param norm = 1.5137e-01, time/batch = 0.1330s	
2447/2700 (epoch 45.315), train_loss = 1.77288540, grad/param norm = 1.6503e-01, time/batch = 0.1335s	
2448/2700 (epoch 45.333), train_loss = 1.75473454, grad/param norm = 2.1911e-01, time/batch = 0.1330s	
2449/2700 (epoch 45.352), train_loss = 1.74601537, grad/param norm = 2.1747e-01, time/batch = 0.1301s	
2450/2700 (epoch 45.370), train_loss = 1.80347655, grad/param norm = 2.1675e-01, time/batch = 0.1329s	
2451/2700 (epoch 45.389), train_loss = 1.75230741, grad/param norm = 2.2996e-01, time/batch = 0.1325s	
2452/2700 (epoch 45.407), train_loss = 1.78990137, grad/param norm = 1.9915e-01, time/batch = 0.1276s	
2453/2700 (epoch 45.426), train_loss = 1.82284208, grad/param norm = 1.5812e-01, time/batch = 0.1337s	
2454/2700 (epoch 45.444), train_loss = 1.74329707, grad/param norm = 1.6356e-01, time/batch = 0.1321s	
2455/2700 (epoch 45.463), train_loss = 1.78372002, grad/param norm = 2.0709e-01, time/batch = 0.1306s	
2456/2700 (epoch 45.481), train_loss = 1.79845434, grad/param norm = 2.6877e-01, time/batch = 0.1333s	
2457/2700 (epoch 45.500), train_loss = 1.73785944, grad/param norm = 2.7531e-01, time/batch = 0.1306s	
2458/2700 (epoch 45.519), train_loss = 1.78483896, grad/param norm = 2.5920e-01, time/batch = 0.1299s	
2459/2700 (epoch 45.537), train_loss = 1.78673033, grad/param norm = 2.1567e-01, time/batch = 0.1360s	
2460/2700 (epoch 45.556), train_loss = 1.74070357, grad/param norm = 1.4813e-01, time/batch = 0.1301s	
2461/2700 (epoch 45.574), train_loss = 1.74090409, grad/param norm = 1.4588e-01, time/batch = 0.1353s	
2462/2700 (epoch 45.593), train_loss = 1.74634844, grad/param norm = 1.6725e-01, time/batch = 0.1306s	
2463/2700 (epoch 45.611), train_loss = 1.69331978, grad/param norm = 1.8213e-01, time/batch = 0.1279s	
2464/2700 (epoch 45.630), train_loss = 1.71007781, grad/param norm = 1.5739e-01, time/batch = 0.1324s	
2465/2700 (epoch 45.648), train_loss = 1.74221504, grad/param norm = 1.5659e-01, time/batch = 0.1300s	
2466/2700 (epoch 45.667), train_loss = 1.74237958, grad/param norm = 2.0531e-01, time/batch = 0.1302s	
2467/2700 (epoch 45.685), train_loss = 1.75766271, grad/param norm = 2.6249e-01, time/batch = 0.1320s	
2468/2700 (epoch 45.704), train_loss = 1.78766845, grad/param norm = 2.2696e-01, time/batch = 0.1323s	
2469/2700 (epoch 45.722), train_loss = 1.73217144, grad/param norm = 2.3251e-01, time/batch = 0.1308s	
2470/2700 (epoch 45.741), train_loss = 1.77808869, grad/param norm = 2.5668e-01, time/batch = 0.1343s	
2471/2700 (epoch 45.759), train_loss = 1.77062110, grad/param norm = 2.1184e-01, time/batch = 0.1321s	
2472/2700 (epoch 45.778), train_loss = 1.79977869, grad/param norm = 1.8337e-01, time/batch = 0.1278s	
2473/2700 (epoch 45.796), train_loss = 1.76256705, grad/param norm = 2.0897e-01, time/batch = 0.1346s	
2474/2700 (epoch 45.815), train_loss = 1.80707066, grad/param norm = 2.6341e-01, time/batch = 0.1290s	
2475/2700 (epoch 45.833), train_loss = 1.78543919, grad/param norm = 3.1244e-01, time/batch = 0.1282s	
2476/2700 (epoch 45.852), train_loss = 1.79150715, grad/param norm = 3.2261e-01, time/batch = 0.1338s	
2477/2700 (epoch 45.870), train_loss = 1.77428130, grad/param norm = 2.3254e-01, time/batch = 0.1294s	
2478/2700 (epoch 45.889), train_loss = 1.76075934, grad/param norm = 1.6717e-01, time/batch = 0.1300s	
2479/2700 (epoch 45.907), train_loss = 1.86638252, grad/param norm = 1.6612e-01, time/batch = 0.1349s	
2480/2700 (epoch 45.926), train_loss = 1.81800999, grad/param norm = 1.4874e-01, time/batch = 0.1344s	
2481/2700 (epoch 45.944), train_loss = 1.80025417, grad/param norm = 1.3777e-01, time/batch = 0.1364s	
2482/2700 (epoch 45.963), train_loss = 1.81120674, grad/param norm = 1.3975e-01, time/batch = 0.1304s	
2483/2700 (epoch 45.981), train_loss = 1.77269977, grad/param norm = 1.5334e-01, time/batch = 0.1284s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
2484/2700 (epoch 46.000), train_loss = 1.80885990, grad/param norm = 1.4294e-01, time/batch = 0.1337s	
2485/2700 (epoch 46.019), train_loss = 1.81236764, grad/param norm = 1.6228e-01, time/batch = 0.1303s	
2486/2700 (epoch 46.037), train_loss = 1.80458302, grad/param norm = 1.7185e-01, time/batch = 0.1287s	
2487/2700 (epoch 46.056), train_loss = 1.74051314, grad/param norm = 1.6080e-01, time/batch = 0.1333s	
2488/2700 (epoch 46.074), train_loss = 1.73676070, grad/param norm = 1.6076e-01, time/batch = 0.1309s	
2489/2700 (epoch 46.093), train_loss = 1.73544002, grad/param norm = 2.3735e-01, time/batch = 0.1289s	
2490/2700 (epoch 46.111), train_loss = 1.71479551, grad/param norm = 2.1472e-01, time/batch = 0.1339s	
2491/2700 (epoch 46.130), train_loss = 1.77873154, grad/param norm = 1.9455e-01, time/batch = 0.1329s	
2492/2700 (epoch 46.148), train_loss = 1.71063800, grad/param norm = 2.4907e-01, time/batch = 0.1291s	
2493/2700 (epoch 46.167), train_loss = 1.82607017, grad/param norm = 3.2766e-01, time/batch = 0.1326s	
2494/2700 (epoch 46.185), train_loss = 1.75652343, grad/param norm = 3.1838e-01, time/batch = 0.1277s	
2495/2700 (epoch 46.204), train_loss = 1.76668568, grad/param norm = 2.9978e-01, time/batch = 0.1299s	
2496/2700 (epoch 46.222), train_loss = 1.74067226, grad/param norm = 2.6244e-01, time/batch = 0.1318s	
2497/2700 (epoch 46.241), train_loss = 1.67273422, grad/param norm = 2.7772e-01, time/batch = 0.1297s	
2498/2700 (epoch 46.259), train_loss = 1.69799177, grad/param norm = 2.3611e-01, time/batch = 0.1359s	
2499/2700 (epoch 46.278), train_loss = 1.77061545, grad/param norm = 1.5845e-01, time/batch = 0.1333s	
2500/2700 (epoch 46.296), train_loss = 1.75126163, grad/param norm = 1.4995e-01, time/batch = 0.1296s	
2501/2700 (epoch 46.315), train_loss = 1.76243423, grad/param norm = 1.6360e-01, time/batch = 0.1364s	
2502/2700 (epoch 46.333), train_loss = 1.74240848, grad/param norm = 2.1012e-01, time/batch = 0.1298s	
2503/2700 (epoch 46.352), train_loss = 1.73478904, grad/param norm = 1.8987e-01, time/batch = 0.1341s	
2504/2700 (epoch 46.370), train_loss = 1.78735924, grad/param norm = 1.4594e-01, time/batch = 0.1340s	
2505/2700 (epoch 46.389), train_loss = 1.73300186, grad/param norm = 1.4676e-01, time/batch = 0.1291s	
2506/2700 (epoch 46.407), train_loss = 1.77663485, grad/param norm = 1.7201e-01, time/batch = 0.1276s	
2507/2700 (epoch 46.426), train_loss = 1.81145059, grad/param norm = 1.9112e-01, time/batch = 0.1329s	
2508/2700 (epoch 46.444), train_loss = 1.73124830, grad/param norm = 1.7471e-01, time/batch = 0.1308s	
2509/2700 (epoch 46.463), train_loss = 1.76996006, grad/param norm = 1.5641e-01, time/batch = 0.1292s	
2510/2700 (epoch 46.481), train_loss = 1.78170845, grad/param norm = 1.6997e-01, time/batch = 0.1346s	
2511/2700 (epoch 46.500), train_loss = 1.72265373, grad/param norm = 2.0057e-01, time/batch = 0.1309s	
2512/2700 (epoch 46.519), train_loss = 1.77807025, grad/param norm = 2.4553e-01, time/batch = 0.1299s	
2513/2700 (epoch 46.537), train_loss = 1.78135814, grad/param norm = 3.1622e-01, time/batch = 0.1371s	
2514/2700 (epoch 46.556), train_loss = 1.74119016, grad/param norm = 3.0522e-01, time/batch = 0.1278s	
2515/2700 (epoch 46.574), train_loss = 1.74229470, grad/param norm = 3.1806e-01, time/batch = 0.1334s	
2516/2700 (epoch 46.593), train_loss = 1.74759636, grad/param norm = 2.8512e-01, time/batch = 0.1339s	
2517/2700 (epoch 46.611), train_loss = 1.69190471, grad/param norm = 2.7711e-01, time/batch = 0.1313s	
2518/2700 (epoch 46.630), train_loss = 1.70200714, grad/param norm = 2.4473e-01, time/batch = 0.1365s	
2519/2700 (epoch 46.648), train_loss = 1.73513048, grad/param norm = 2.2943e-01, time/batch = 0.1364s	
2520/2700 (epoch 46.667), train_loss = 1.72926007, grad/param norm = 2.3231e-01, time/batch = 0.1347s	
2521/2700 (epoch 46.685), train_loss = 1.74333560, grad/param norm = 2.4303e-01, time/batch = 0.1389s	
2522/2700 (epoch 46.704), train_loss = 1.77945592, grad/param norm = 2.7736e-01, time/batch = 0.1309s	
2523/2700 (epoch 46.722), train_loss = 1.73153055, grad/param norm = 3.2816e-01, time/batch = 0.1310s	
2524/2700 (epoch 46.741), train_loss = 1.77167103, grad/param norm = 2.9321e-01, time/batch = 0.1346s	
2525/2700 (epoch 46.759), train_loss = 1.76512508, grad/param norm = 2.3641e-01, time/batch = 0.1328s	
2526/2700 (epoch 46.778), train_loss = 1.79241264, grad/param norm = 2.3092e-01, time/batch = 0.1290s	
2527/2700 (epoch 46.796), train_loss = 1.75252298, grad/param norm = 2.4191e-01, time/batch = 0.1326s	
2528/2700 (epoch 46.815), train_loss = 1.78610539, grad/param norm = 1.8975e-01, time/batch = 0.1297s	
2529/2700 (epoch 46.833), train_loss = 1.76362125, grad/param norm = 2.0308e-01, time/batch = 0.1308s	
2530/2700 (epoch 46.852), train_loss = 1.77291402, grad/param norm = 1.9956e-01, time/batch = 0.1331s	
2531/2700 (epoch 46.870), train_loss = 1.76379441, grad/param norm = 1.9035e-01, time/batch = 0.1303s	
2532/2700 (epoch 46.889), train_loss = 1.75602299, grad/param norm = 2.4143e-01, time/batch = 0.1346s	
2533/2700 (epoch 46.907), train_loss = 1.86373672, grad/param norm = 2.8266e-01, time/batch = 0.1319s	
2534/2700 (epoch 46.926), train_loss = 1.81751572, grad/param norm = 2.4786e-01, time/batch = 0.1313s	
2535/2700 (epoch 46.944), train_loss = 1.79537054, grad/param norm = 2.0656e-01, time/batch = 0.1345s	
2536/2700 (epoch 46.963), train_loss = 1.80588596, grad/param norm = 1.8052e-01, time/batch = 0.1288s	
2537/2700 (epoch 46.981), train_loss = 1.76555374, grad/param norm = 1.7373e-01, time/batch = 0.1298s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
2538/2700 (epoch 47.000), train_loss = 1.79971613, grad/param norm = 1.6397e-01, time/batch = 0.1343s	
2539/2700 (epoch 47.019), train_loss = 1.80635228, grad/param norm = 1.9808e-01, time/batch = 0.1303s	
2540/2700 (epoch 47.037), train_loss = 1.79332815, grad/param norm = 1.7844e-01, time/batch = 0.1288s	
2541/2700 (epoch 47.056), train_loss = 1.73034275, grad/param norm = 1.7192e-01, time/batch = 0.1347s	
2542/2700 (epoch 47.074), train_loss = 1.73112947, grad/param norm = 2.4073e-01, time/batch = 0.1302s	
2543/2700 (epoch 47.093), train_loss = 1.72569754, grad/param norm = 2.3502e-01, time/batch = 0.1302s	
2544/2700 (epoch 47.111), train_loss = 1.70222065, grad/param norm = 1.8924e-01, time/batch = 0.1315s	
2545/2700 (epoch 47.130), train_loss = 1.76601534, grad/param norm = 1.9675e-01, time/batch = 0.1278s	
2546/2700 (epoch 47.148), train_loss = 1.69747816, grad/param norm = 1.7595e-01, time/batch = 0.1301s	
2547/2700 (epoch 47.167), train_loss = 1.80632555, grad/param norm = 1.7785e-01, time/batch = 0.1319s	
2548/2700 (epoch 47.185), train_loss = 1.73789821, grad/param norm = 2.2616e-01, time/batch = 0.1295s	
2549/2700 (epoch 47.204), train_loss = 1.75306023, grad/param norm = 2.1629e-01, time/batch = 0.1319s	
2550/2700 (epoch 47.222), train_loss = 1.73235790, grad/param norm = 2.7132e-01, time/batch = 0.1364s	
2551/2700 (epoch 47.241), train_loss = 1.66547391, grad/param norm = 3.0016e-01, time/batch = 0.1337s	
2552/2700 (epoch 47.259), train_loss = 1.69324649, grad/param norm = 2.9701e-01, time/batch = 0.1380s	
2553/2700 (epoch 47.278), train_loss = 1.77721745, grad/param norm = 3.3690e-01, time/batch = 0.1332s	
2554/2700 (epoch 47.296), train_loss = 1.75708352, grad/param norm = 3.5293e-01, time/batch = 0.1276s	
2555/2700 (epoch 47.315), train_loss = 1.75791828, grad/param norm = 2.4334e-01, time/batch = 0.1341s	
2556/2700 (epoch 47.333), train_loss = 1.73121684, grad/param norm = 1.8248e-01, time/batch = 0.1283s	
2557/2700 (epoch 47.352), train_loss = 1.72522364, grad/param norm = 1.8274e-01, time/batch = 0.1277s	
2558/2700 (epoch 47.370), train_loss = 1.78327993, grad/param norm = 2.3038e-01, time/batch = 0.1346s	
2559/2700 (epoch 47.389), train_loss = 1.73007258, grad/param norm = 2.6422e-01, time/batch = 0.1299s	
2560/2700 (epoch 47.407), train_loss = 1.77259316, grad/param norm = 2.6027e-01, time/batch = 0.1304s	
2561/2700 (epoch 47.426), train_loss = 1.80048099, grad/param norm = 1.6687e-01, time/batch = 0.1339s	
2562/2700 (epoch 47.444), train_loss = 1.72007549, grad/param norm = 1.5489e-01, time/batch = 0.1274s	
2563/2700 (epoch 47.463), train_loss = 1.76146184, grad/param norm = 1.5900e-01, time/batch = 0.1318s	
2564/2700 (epoch 47.481), train_loss = 1.77198456, grad/param norm = 1.8055e-01, time/batch = 0.1307s	
2565/2700 (epoch 47.500), train_loss = 1.71080736, grad/param norm = 1.7689e-01, time/batch = 0.1301s	
2566/2700 (epoch 47.519), train_loss = 1.76108964, grad/param norm = 1.4455e-01, time/batch = 0.1324s	
2567/2700 (epoch 47.537), train_loss = 1.75942371, grad/param norm = 1.6400e-01, time/batch = 0.1304s	
2568/2700 (epoch 47.556), train_loss = 1.72235624, grad/param norm = 2.0360e-01, time/batch = 0.1294s	
2569/2700 (epoch 47.574), train_loss = 1.72458372, grad/param norm = 2.2644e-01, time/batch = 0.1337s	
2570/2700 (epoch 47.593), train_loss = 1.73024498, grad/param norm = 2.3698e-01, time/batch = 0.1310s	
2571/2700 (epoch 47.611), train_loss = 1.67752906, grad/param norm = 2.4893e-01, time/batch = 0.1315s	
2572/2700 (epoch 47.630), train_loss = 1.68817480, grad/param norm = 2.0692e-01, time/batch = 0.1338s	
2573/2700 (epoch 47.648), train_loss = 1.72170006, grad/param norm = 1.6326e-01, time/batch = 0.1287s	
2574/2700 (epoch 47.667), train_loss = 1.71503733, grad/param norm = 1.5747e-01, time/batch = 0.1277s	
2575/2700 (epoch 47.685), train_loss = 1.72938707, grad/param norm = 1.6300e-01, time/batch = 0.1348s	
2576/2700 (epoch 47.704), train_loss = 1.76277486, grad/param norm = 1.7841e-01, time/batch = 0.1326s	
2577/2700 (epoch 47.722), train_loss = 1.71021381, grad/param norm = 2.1032e-01, time/batch = 0.1288s	
2578/2700 (epoch 47.741), train_loss = 1.74890962, grad/param norm = 2.0352e-01, time/batch = 0.1352s	
2579/2700 (epoch 47.759), train_loss = 1.74732706, grad/param norm = 2.1914e-01, time/batch = 0.1297s	
2580/2700 (epoch 47.778), train_loss = 1.78692367, grad/param norm = 3.2355e-01, time/batch = 0.1304s	
2581/2700 (epoch 47.796), train_loss = 1.75022066, grad/param norm = 3.1745e-01, time/batch = 0.1350s	
2582/2700 (epoch 47.815), train_loss = 1.78065121, grad/param norm = 2.6626e-01, time/batch = 0.1274s	
2583/2700 (epoch 47.833), train_loss = 1.75658890, grad/param norm = 2.3518e-01, time/batch = 0.1327s	
2584/2700 (epoch 47.852), train_loss = 1.76303787, grad/param norm = 1.7261e-01, time/batch = 0.1336s	
2585/2700 (epoch 47.870), train_loss = 1.75704415, grad/param norm = 2.2077e-01, time/batch = 0.1279s	
2586/2700 (epoch 47.889), train_loss = 1.75042895, grad/param norm = 2.9453e-01, time/batch = 0.1332s	
2587/2700 (epoch 47.907), train_loss = 1.85582742, grad/param norm = 2.9295e-01, time/batch = 0.1288s	
2588/2700 (epoch 47.926), train_loss = 1.80541256, grad/param norm = 2.2966e-01, time/batch = 0.1295s	
2589/2700 (epoch 47.944), train_loss = 1.78335599, grad/param norm = 1.7195e-01, time/batch = 0.1345s	
2590/2700 (epoch 47.963), train_loss = 1.79352952, grad/param norm = 1.4630e-01, time/batch = 0.1363s	
2591/2700 (epoch 47.981), train_loss = 1.75479244, grad/param norm = 1.6977e-01, time/batch = 0.1331s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
2592/2700 (epoch 48.000), train_loss = 1.79270546, grad/param norm = 1.8251e-01, time/batch = 0.1326s	
2593/2700 (epoch 48.019), train_loss = 1.79744854, grad/param norm = 1.9523e-01, time/batch = 0.1289s	
2594/2700 (epoch 48.037), train_loss = 1.78416468, grad/param norm = 2.3413e-01, time/batch = 0.1307s	
2595/2700 (epoch 48.056), train_loss = 1.72385678, grad/param norm = 2.3878e-01, time/batch = 0.1318s	
2596/2700 (epoch 48.074), train_loss = 1.72043238, grad/param norm = 1.7585e-01, time/batch = 0.1283s	
2597/2700 (epoch 48.093), train_loss = 1.71337710, grad/param norm = 2.3285e-01, time/batch = 0.1321s	
2598/2700 (epoch 48.111), train_loss = 1.69375100, grad/param norm = 2.0636e-01, time/batch = 0.1341s	
2599/2700 (epoch 48.130), train_loss = 1.75751736, grad/param norm = 1.8046e-01, time/batch = 0.1293s	
2600/2700 (epoch 48.148), train_loss = 1.69110208, grad/param norm = 2.3364e-01, time/batch = 0.1322s	
2601/2700 (epoch 48.167), train_loss = 1.80424803, grad/param norm = 3.0420e-01, time/batch = 0.1329s	
2602/2700 (epoch 48.185), train_loss = 1.73279038, grad/param norm = 2.6029e-01, time/batch = 0.1274s	
2603/2700 (epoch 48.204), train_loss = 1.74345917, grad/param norm = 2.2951e-01, time/batch = 0.1338s	
2604/2700 (epoch 48.222), train_loss = 1.71753799, grad/param norm = 1.7805e-01, time/batch = 0.1294s	
2605/2700 (epoch 48.241), train_loss = 1.64978565, grad/param norm = 1.8989e-01, time/batch = 0.1278s	
2606/2700 (epoch 48.259), train_loss = 1.67522391, grad/param norm = 1.7062e-01, time/batch = 0.1339s	
2607/2700 (epoch 48.278), train_loss = 1.75362818, grad/param norm = 1.5049e-01, time/batch = 0.1320s	
2608/2700 (epoch 48.296), train_loss = 1.73413116, grad/param norm = 1.5555e-01, time/batch = 0.1332s	
2609/2700 (epoch 48.315), train_loss = 1.74263647, grad/param norm = 1.6965e-01, time/batch = 0.1350s	
2610/2700 (epoch 48.333), train_loss = 1.72227932, grad/param norm = 2.2253e-01, time/batch = 0.1296s	
2611/2700 (epoch 48.352), train_loss = 1.71483615, grad/param norm = 1.9350e-01, time/batch = 0.1352s	
2612/2700 (epoch 48.370), train_loss = 1.76814455, grad/param norm = 2.0152e-01, time/batch = 0.1309s	
2613/2700 (epoch 48.389), train_loss = 1.71918056, grad/param norm = 2.4893e-01, time/batch = 0.1324s	
2614/2700 (epoch 48.407), train_loss = 1.76256522, grad/param norm = 2.3088e-01, time/batch = 0.1355s	
2615/2700 (epoch 48.426), train_loss = 1.79310907, grad/param norm = 1.7677e-01, time/batch = 0.1302s	
2616/2700 (epoch 48.444), train_loss = 1.71543305, grad/param norm = 2.0524e-01, time/batch = 0.1275s	
2617/2700 (epoch 48.463), train_loss = 1.75748812, grad/param norm = 2.5970e-01, time/batch = 0.1326s	
2618/2700 (epoch 48.481), train_loss = 1.76748176, grad/param norm = 2.7935e-01, time/batch = 0.1314s	
2619/2700 (epoch 48.500), train_loss = 1.70294793, grad/param norm = 2.4390e-01, time/batch = 0.1291s	
2620/2700 (epoch 48.519), train_loss = 1.75301112, grad/param norm = 1.9941e-01, time/batch = 0.1340s	
2621/2700 (epoch 48.537), train_loss = 1.75150803, grad/param norm = 1.9498e-01, time/batch = 0.1315s	
2622/2700 (epoch 48.556), train_loss = 1.71041823, grad/param norm = 1.5020e-01, time/batch = 0.1312s	
2623/2700 (epoch 48.574), train_loss = 1.71226768, grad/param norm = 1.8185e-01, time/batch = 0.1345s	
2624/2700 (epoch 48.593), train_loss = 1.71863457, grad/param norm = 2.0937e-01, time/batch = 0.1285s	
2625/2700 (epoch 48.611), train_loss = 1.66588219, grad/param norm = 2.2873e-01, time/batch = 0.1298s	
2626/2700 (epoch 48.630), train_loss = 1.68374422, grad/param norm = 2.5684e-01, time/batch = 0.1335s	
2627/2700 (epoch 48.648), train_loss = 1.72133646, grad/param norm = 3.0600e-01, time/batch = 0.1292s	
2628/2700 (epoch 48.667), train_loss = 1.72208796, grad/param norm = 3.1720e-01, time/batch = 0.1344s	
2629/2700 (epoch 48.685), train_loss = 1.73247684, grad/param norm = 3.0791e-01, time/batch = 0.1350s	
2630/2700 (epoch 48.704), train_loss = 1.75913049, grad/param norm = 2.3499e-01, time/batch = 0.1318s	
2631/2700 (epoch 48.722), train_loss = 1.69979510, grad/param norm = 2.1521e-01, time/batch = 0.1374s	
2632/2700 (epoch 48.741), train_loss = 1.73990365, grad/param norm = 2.4886e-01, time/batch = 0.1312s	
2633/2700 (epoch 48.759), train_loss = 1.73829337, grad/param norm = 2.4968e-01, time/batch = 0.1323s	
2634/2700 (epoch 48.778), train_loss = 1.77112273, grad/param norm = 2.1674e-01, time/batch = 0.1335s	
2635/2700 (epoch 48.796), train_loss = 1.73026465, grad/param norm = 1.9053e-01, time/batch = 0.1299s	
2636/2700 (epoch 48.815), train_loss = 1.76936317, grad/param norm = 2.1628e-01, time/batch = 0.1308s	
2637/2700 (epoch 48.833), train_loss = 1.75045627, grad/param norm = 2.6061e-01, time/batch = 0.1333s	
2638/2700 (epoch 48.852), train_loss = 1.76011594, grad/param norm = 3.0453e-01, time/batch = 0.1294s	
2639/2700 (epoch 48.870), train_loss = 1.74921191, grad/param norm = 2.4171e-01, time/batch = 0.1298s	
2640/2700 (epoch 48.889), train_loss = 1.73094039, grad/param norm = 1.7168e-01, time/batch = 0.1340s	
2641/2700 (epoch 48.907), train_loss = 1.83570784, grad/param norm = 1.5336e-01, time/batch = 0.1305s	
2642/2700 (epoch 48.926), train_loss = 1.78990731, grad/param norm = 1.6193e-01, time/batch = 0.1353s	
2643/2700 (epoch 48.944), train_loss = 1.77676620, grad/param norm = 2.0161e-01, time/batch = 0.1309s	
2644/2700 (epoch 48.963), train_loss = 1.78661941, grad/param norm = 2.1154e-01, time/batch = 0.1310s	
2645/2700 (epoch 48.981), train_loss = 1.74718227, grad/param norm = 2.2440e-01, time/batch = 0.1327s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
2646/2700 (epoch 49.000), train_loss = 1.78149276, grad/param norm = 1.9123e-01, time/batch = 0.1290s	
2647/2700 (epoch 49.019), train_loss = 1.79177251, grad/param norm = 2.0130e-01, time/batch = 0.1273s	
2648/2700 (epoch 49.037), train_loss = 1.77770942, grad/param norm = 2.4605e-01, time/batch = 0.1341s	
2649/2700 (epoch 49.056), train_loss = 1.71481783, grad/param norm = 2.8166e-01, time/batch = 0.1308s	
2650/2700 (epoch 49.074), train_loss = 1.71500292, grad/param norm = 2.8844e-01, time/batch = 0.1297s	
2651/2700 (epoch 49.093), train_loss = 1.70737310, grad/param norm = 2.2486e-01, time/batch = 0.1345s	
2652/2700 (epoch 49.111), train_loss = 1.68341813, grad/param norm = 2.4074e-01, time/batch = 0.1289s	
2653/2700 (epoch 49.130), train_loss = 1.75490633, grad/param norm = 2.6959e-01, time/batch = 0.1314s	
2654/2700 (epoch 49.148), train_loss = 1.68367730, grad/param norm = 2.0072e-01, time/batch = 0.1327s	
2655/2700 (epoch 49.167), train_loss = 1.78833879, grad/param norm = 1.7407e-01, time/batch = 0.1321s	
2656/2700 (epoch 49.185), train_loss = 1.71744628, grad/param norm = 1.9195e-01, time/batch = 0.1362s	
2657/2700 (epoch 49.204), train_loss = 1.73185029, grad/param norm = 1.7290e-01, time/batch = 0.1348s	
2658/2700 (epoch 49.222), train_loss = 1.71147567, grad/param norm = 1.9086e-01, time/batch = 0.1300s	
2659/2700 (epoch 49.241), train_loss = 1.64200183, grad/param norm = 2.0376e-01, time/batch = 0.1343s	
2660/2700 (epoch 49.259), train_loss = 1.66859841, grad/param norm = 1.9462e-01, time/batch = 0.1350s	
2661/2700 (epoch 49.278), train_loss = 1.75276764, grad/param norm = 2.4847e-01, time/batch = 0.1333s	
2662/2700 (epoch 49.296), train_loss = 1.73103620, grad/param norm = 2.4431e-01, time/batch = 0.1363s	
2663/2700 (epoch 49.315), train_loss = 1.73326737, grad/param norm = 1.6491e-01, time/batch = 0.1297s	
2664/2700 (epoch 49.333), train_loss = 1.71096499, grad/param norm = 1.7049e-01, time/batch = 0.1297s	
2665/2700 (epoch 49.352), train_loss = 1.70447784, grad/param norm = 1.8245e-01, time/batch = 0.1351s	
2666/2700 (epoch 49.370), train_loss = 1.76192977, grad/param norm = 2.3075e-01, time/batch = 0.1300s	
2667/2700 (epoch 49.389), train_loss = 1.70948163, grad/param norm = 2.6793e-01, time/batch = 0.1289s	
2668/2700 (epoch 49.407), train_loss = 1.75418048, grad/param norm = 2.7593e-01, time/batch = 0.1341s	
2669/2700 (epoch 49.426), train_loss = 1.78308139, grad/param norm = 2.0147e-01, time/batch = 0.1312s	
2670/2700 (epoch 49.444), train_loss = 1.70523281, grad/param norm = 1.9142e-01, time/batch = 0.1318s	
2671/2700 (epoch 49.463), train_loss = 1.74509411, grad/param norm = 1.7932e-01, time/batch = 0.1327s	
2672/2700 (epoch 49.481), train_loss = 1.75046071, grad/param norm = 1.5063e-01, time/batch = 0.1276s	
2673/2700 (epoch 49.500), train_loss = 1.69232412, grad/param norm = 2.0110e-01, time/batch = 0.1335s	
2674/2700 (epoch 49.519), train_loss = 1.74877897, grad/param norm = 2.3756e-01, time/batch = 0.1300s	
2675/2700 (epoch 49.537), train_loss = 1.75194521, grad/param norm = 3.2813e-01, time/batch = 0.1278s	
2676/2700 (epoch 49.556), train_loss = 1.71189400, grad/param norm = 3.3231e-01, time/batch = 0.1327s	
2677/2700 (epoch 49.574), train_loss = 1.71309410, grad/param norm = 3.2155e-01, time/batch = 0.1293s	
2678/2700 (epoch 49.593), train_loss = 1.71414599, grad/param norm = 2.5883e-01, time/batch = 0.1327s	
2679/2700 (epoch 49.611), train_loss = 1.65663664, grad/param norm = 2.2049e-01, time/batch = 0.1341s	
2680/2700 (epoch 49.630), train_loss = 1.66759416, grad/param norm = 1.6060e-01, time/batch = 0.1306s	
2681/2700 (epoch 49.648), train_loss = 1.70188995, grad/param norm = 1.4655e-01, time/batch = 0.1334s	
2682/2700 (epoch 49.667), train_loss = 1.69800774, grad/param norm = 1.5691e-01, time/batch = 0.1318s	
2683/2700 (epoch 49.685), train_loss = 1.71167617, grad/param norm = 1.7057e-01, time/batch = 0.1280s	
2684/2700 (epoch 49.704), train_loss = 1.74381864, grad/param norm = 1.7173e-01, time/batch = 0.1314s	
2685/2700 (epoch 49.722), train_loss = 1.69069220, grad/param norm = 1.9883e-01, time/batch = 0.1338s	
2686/2700 (epoch 49.741), train_loss = 1.72772365, grad/param norm = 1.9422e-01, time/batch = 0.1280s	
2687/2700 (epoch 49.759), train_loss = 1.72579904, grad/param norm = 1.9385e-01, time/batch = 0.1334s	
2688/2700 (epoch 49.778), train_loss = 1.76057686, grad/param norm = 2.1276e-01, time/batch = 0.1320s	
2689/2700 (epoch 49.796), train_loss = 1.72138345, grad/param norm = 2.2968e-01, time/batch = 0.1290s	
2690/2700 (epoch 49.815), train_loss = 1.75556989, grad/param norm = 2.2194e-01, time/batch = 0.1333s	
2691/2700 (epoch 49.833), train_loss = 1.73934914, grad/param norm = 2.7794e-01, time/batch = 0.1321s	
2692/2700 (epoch 49.852), train_loss = 1.75017217, grad/param norm = 2.9188e-01, time/batch = 0.1300s	
2693/2700 (epoch 49.870), train_loss = 1.74073523, grad/param norm = 2.4781e-01, time/batch = 0.1332s	
2694/2700 (epoch 49.889), train_loss = 1.72799262, grad/param norm = 2.4303e-01, time/batch = 0.1290s	
2695/2700 (epoch 49.907), train_loss = 1.83413391, grad/param norm = 2.6680e-01, time/batch = 0.1284s	
2696/2700 (epoch 49.926), train_loss = 1.78783925, grad/param norm = 2.6140e-01, time/batch = 0.1335s	
2697/2700 (epoch 49.944), train_loss = 1.76924402, grad/param norm = 2.3021e-01, time/batch = 0.1292s	
2698/2700 (epoch 49.963), train_loss = 1.77575997, grad/param norm = 1.8077e-01, time/batch = 0.1304s	
2699/2700 (epoch 49.981), train_loss = 1.73724435, grad/param norm = 1.7348e-01, time/batch = 0.1347s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch50.00_1.9313.t7	
2700/2700 (epoch 50.000), train_loss = 1.77241041, grad/param norm = 1.6991e-01, time/batch = 0.1352s	
