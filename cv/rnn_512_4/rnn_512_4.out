using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 54, val: 3, test: 0	
vocab size: 91	
creating an rnn with 4 layers	
number of parameters in the model: 1932379	
cloning rnn	
cloning criterion	
1/2700 (epoch 0.019), train_loss = 4.68590651, grad/param norm = 7.6003e+00, time/batch = 0.4298s	
2/2700 (epoch 0.037), train_loss = 4.23310994, grad/param norm = 9.4604e+00, time/batch = 0.1209s	
3/2700 (epoch 0.056), train_loss = 5.55782789, grad/param norm = 3.9739e+00, time/batch = 0.1159s	
4/2700 (epoch 0.074), train_loss = 5.51509370, grad/param norm = 2.9993e+00, time/batch = 0.1119s	
5/2700 (epoch 0.093), train_loss = 4.87776750, grad/param norm = 2.2550e+00, time/batch = 0.1063s	
6/2700 (epoch 0.111), train_loss = 3.99690780, grad/param norm = 2.2239e+00, time/batch = 0.1094s	
7/2700 (epoch 0.130), train_loss = 3.85829528, grad/param norm = 2.1570e+00, time/batch = 0.1076s	
8/2700 (epoch 0.148), train_loss = 3.83856716, grad/param norm = 1.8222e+00, time/batch = 0.1168s	
9/2700 (epoch 0.167), train_loss = 3.55240959, grad/param norm = 1.4568e+00, time/batch = 0.1289s	
10/2700 (epoch 0.185), train_loss = 3.49449184, grad/param norm = 1.5781e+00, time/batch = 0.1647s	
11/2700 (epoch 0.204), train_loss = 3.40739475, grad/param norm = 1.5565e+00, time/batch = 0.2799s	
12/2700 (epoch 0.222), train_loss = 3.32323160, grad/param norm = 1.6540e+00, time/batch = 0.3095s	
13/2700 (epoch 0.241), train_loss = 3.33640742, grad/param norm = 1.4230e+00, time/batch = 0.3686s	
14/2700 (epoch 0.259), train_loss = 3.27733115, grad/param norm = 8.7476e-01, time/batch = 0.4473s	
15/2700 (epoch 0.278), train_loss = 3.32365894, grad/param norm = 7.4024e-01, time/batch = 0.4276s	
16/2700 (epoch 0.296), train_loss = 3.34557739, grad/param norm = 8.3064e-01, time/batch = 0.4148s	
17/2700 (epoch 0.315), train_loss = 3.33877486, grad/param norm = 1.0203e+00, time/batch = 0.4416s	
18/2700 (epoch 0.333), train_loss = 3.41940454, grad/param norm = 8.2732e-01, time/batch = 0.4642s	
19/2700 (epoch 0.352), train_loss = 3.39769410, grad/param norm = 7.4003e-01, time/batch = 0.4411s	
20/2700 (epoch 0.370), train_loss = 3.34821944, grad/param norm = 7.2898e-01, time/batch = 0.4582s	
21/2700 (epoch 0.389), train_loss = 3.30837940, grad/param norm = 6.9721e-01, time/batch = 0.4459s	
22/2700 (epoch 0.407), train_loss = 3.32163029, grad/param norm = 6.2584e-01, time/batch = 0.3427s	
23/2700 (epoch 0.426), train_loss = 3.33745695, grad/param norm = 6.4132e-01, time/batch = 0.3349s	
24/2700 (epoch 0.444), train_loss = 3.24518530, grad/param norm = 1.6920e+00, time/batch = 0.3957s	
25/2700 (epoch 0.463), train_loss = 3.30639948, grad/param norm = 8.7302e-01, time/batch = 0.4463s	
26/2700 (epoch 0.481), train_loss = 3.40719451, grad/param norm = 9.8209e-01, time/batch = 0.4263s	
27/2700 (epoch 0.500), train_loss = 3.45260571, grad/param norm = 1.2237e+00, time/batch = 0.3946s	
28/2700 (epoch 0.519), train_loss = 3.44538724, grad/param norm = 1.2385e+00, time/batch = 0.4131s	
29/2700 (epoch 0.537), train_loss = 3.40149977, grad/param norm = 9.6757e-01, time/batch = 0.4358s	
30/2700 (epoch 0.556), train_loss = 3.34235074, grad/param norm = 8.5677e-01, time/batch = 0.4625s	
31/2700 (epoch 0.574), train_loss = 3.28733914, grad/param norm = 7.2757e-01, time/batch = 0.4585s	
32/2700 (epoch 0.593), train_loss = 3.29056880, grad/param norm = 8.7478e-01, time/batch = 0.4410s	
33/2700 (epoch 0.611), train_loss = 3.24296370, grad/param norm = 9.6197e-01, time/batch = 0.3907s	
34/2700 (epoch 0.630), train_loss = 3.27831678, grad/param norm = 8.2297e-01, time/batch = 0.3309s	
35/2700 (epoch 0.648), train_loss = 3.33162351, grad/param norm = 6.9487e-01, time/batch = 0.3723s	
36/2700 (epoch 0.667), train_loss = 3.25450826, grad/param norm = 6.6565e-01, time/batch = 0.4150s	
37/2700 (epoch 0.685), train_loss = 3.24368145, grad/param norm = 6.1648e-01, time/batch = 0.4397s	
38/2700 (epoch 0.704), train_loss = 3.22236097, grad/param norm = 6.7765e-01, time/batch = 0.3961s	
39/2700 (epoch 0.722), train_loss = 3.21286232, grad/param norm = 5.7104e-01, time/batch = 0.3524s	
40/2700 (epoch 0.741), train_loss = 3.34614855, grad/param norm = 5.6661e-01, time/batch = 0.4455s	
41/2700 (epoch 0.759), train_loss = 3.29560180, grad/param norm = 6.3224e-01, time/batch = 0.4432s	
42/2700 (epoch 0.778), train_loss = 3.30799356, grad/param norm = 1.1558e+00, time/batch = 0.4662s	
43/2700 (epoch 0.796), train_loss = 3.31834086, grad/param norm = 9.2207e-01, time/batch = 0.4548s	
44/2700 (epoch 0.815), train_loss = 3.28587920, grad/param norm = 1.1204e+00, time/batch = 0.4322s	
45/2700 (epoch 0.833), train_loss = 3.33760042, grad/param norm = 1.3508e+00, time/batch = 0.3433s	
46/2700 (epoch 0.852), train_loss = 3.32656569, grad/param norm = 1.2893e+00, time/batch = 0.3689s	
47/2700 (epoch 0.870), train_loss = 3.29685320, grad/param norm = 1.0863e+00, time/batch = 0.4229s	
48/2700 (epoch 0.889), train_loss = 3.34016501, grad/param norm = 1.0833e+00, time/batch = 0.4325s	
49/2700 (epoch 0.907), train_loss = 3.35723296, grad/param norm = 8.6672e-01, time/batch = 0.4003s	
50/2700 (epoch 0.926), train_loss = 3.30442283, grad/param norm = 8.3636e-01, time/batch = 0.3747s	
51/2700 (epoch 0.944), train_loss = 3.31655982, grad/param norm = 7.4864e-01, time/batch = 0.4241s	
52/2700 (epoch 0.963), train_loss = 3.38336247, grad/param norm = 6.4968e-01, time/batch = 0.4605s	
53/2700 (epoch 0.981), train_loss = 3.43824984, grad/param norm = 6.4543e-01, time/batch = 0.4658s	
54/2700 (epoch 1.000), train_loss = 3.33917173, grad/param norm = 6.2504e-01, time/batch = 0.4553s	
55/2700 (epoch 1.019), train_loss = 3.28281002, grad/param norm = 7.1562e-01, time/batch = 0.4084s	
56/2700 (epoch 1.037), train_loss = 3.30403470, grad/param norm = 7.5888e-01, time/batch = 0.3756s	
57/2700 (epoch 1.056), train_loss = 3.29813816, grad/param norm = 6.3276e-01, time/batch = 0.3673s	
58/2700 (epoch 1.074), train_loss = 3.33279109, grad/param norm = 6.6213e-01, time/batch = 0.4198s	
59/2700 (epoch 1.093), train_loss = 3.34183662, grad/param norm = 7.1630e-01, time/batch = 0.4188s	
60/2700 (epoch 1.111), train_loss = 3.31471696, grad/param norm = 7.2077e-01, time/batch = 0.4553s	
61/2700 (epoch 1.130), train_loss = 3.32649445, grad/param norm = 6.3944e-01, time/batch = 0.4101s	
62/2700 (epoch 1.148), train_loss = 3.28006767, grad/param norm = 7.4678e-01, time/batch = 0.3445s	
63/2700 (epoch 1.167), train_loss = 3.31424528, grad/param norm = 9.4446e-01, time/batch = 0.4391s	
64/2700 (epoch 1.185), train_loss = 3.30681002, grad/param norm = 9.6680e-01, time/batch = 0.4556s	
65/2700 (epoch 1.204), train_loss = 3.24013528, grad/param norm = 1.0516e+00, time/batch = 0.4564s	
66/2700 (epoch 1.222), train_loss = 3.22375951, grad/param norm = 1.1350e+00, time/batch = 0.4235s	
67/2700 (epoch 1.241), train_loss = 3.21274476, grad/param norm = 7.4248e-01, time/batch = 0.3810s	
68/2700 (epoch 1.259), train_loss = 3.25458554, grad/param norm = 7.7660e-01, time/batch = 0.3748s	
69/2700 (epoch 1.278), train_loss = 3.33764534, grad/param norm = 8.9264e-01, time/batch = 0.3668s	
70/2700 (epoch 1.296), train_loss = 3.33443782, grad/param norm = 8.4368e-01, time/batch = 0.4275s	
71/2700 (epoch 1.315), train_loss = 3.30907643, grad/param norm = 7.5322e-01, time/batch = 0.4354s	
72/2700 (epoch 1.333), train_loss = 3.38382365, grad/param norm = 7.2118e-01, time/batch = 0.4276s	
73/2700 (epoch 1.352), train_loss = 3.38948959, grad/param norm = 7.9467e-01, time/batch = 0.3821s	
74/2700 (epoch 1.370), train_loss = 3.35805344, grad/param norm = 8.9401e-01, time/batch = 0.3930s	
75/2700 (epoch 1.389), train_loss = 3.29995620, grad/param norm = 7.9075e-01, time/batch = 0.4623s	
76/2700 (epoch 1.407), train_loss = 3.32564398, grad/param norm = 7.7939e-01, time/batch = 0.4545s	
77/2700 (epoch 1.426), train_loss = 3.31981583, grad/param norm = 8.0120e-01, time/batch = 0.4612s	
78/2700 (epoch 1.444), train_loss = 3.25363046, grad/param norm = 9.3696e-01, time/batch = 0.3914s	
79/2700 (epoch 1.463), train_loss = 3.31255650, grad/param norm = 1.1348e+00, time/batch = 0.3153s	
80/2700 (epoch 1.481), train_loss = 3.38571051, grad/param norm = 1.0560e+00, time/batch = 0.4352s	
81/2700 (epoch 1.500), train_loss = 3.42975385, grad/param norm = 9.5582e-01, time/batch = 0.4259s	
82/2700 (epoch 1.519), train_loss = 3.38050499, grad/param norm = 9.6274e-01, time/batch = 0.4364s	
83/2700 (epoch 1.537), train_loss = 3.39437553, grad/param norm = 9.3479e-01, time/batch = 0.4288s	
84/2700 (epoch 1.556), train_loss = 3.32990270, grad/param norm = 7.9938e-01, time/batch = 0.3684s	
85/2700 (epoch 1.574), train_loss = 3.26874973, grad/param norm = 7.3720e-01, time/batch = 0.4074s	
86/2700 (epoch 1.593), train_loss = 3.27824611, grad/param norm = 7.6524e-01, time/batch = 0.4240s	
87/2700 (epoch 1.611), train_loss = 3.21375987, grad/param norm = 7.3054e-01, time/batch = 0.4540s	
88/2700 (epoch 1.630), train_loss = 3.26118650, grad/param norm = 7.7628e-01, time/batch = 0.4182s	
89/2700 (epoch 1.648), train_loss = 3.34983477, grad/param norm = 8.7668e-01, time/batch = 0.3424s	
90/2700 (epoch 1.667), train_loss = 3.28442798, grad/param norm = 8.8604e-01, time/batch = 0.4335s	
91/2700 (epoch 1.685), train_loss = 3.26530231, grad/param norm = 7.8824e-01, time/batch = 0.4425s	
92/2700 (epoch 1.704), train_loss = 3.23184127, grad/param norm = 8.0773e-01, time/batch = 0.4291s	
93/2700 (epoch 1.722), train_loss = 3.22398096, grad/param norm = 7.7621e-01, time/batch = 0.4184s	
94/2700 (epoch 1.741), train_loss = 3.35381637, grad/param norm = 8.5494e-01, time/batch = 0.3599s	
95/2700 (epoch 1.759), train_loss = 3.31707231, grad/param norm = 8.9043e-01, time/batch = 0.3571s	
96/2700 (epoch 1.778), train_loss = 3.30620970, grad/param norm = 9.0621e-01, time/batch = 0.4126s	
97/2700 (epoch 1.796), train_loss = 3.29899843, grad/param norm = 9.4257e-01, time/batch = 0.4559s	
98/2700 (epoch 1.815), train_loss = 3.26368429, grad/param norm = 8.4809e-01, time/batch = 0.4468s	
99/2700 (epoch 1.833), train_loss = 3.28436102, grad/param norm = 8.5396e-01, time/batch = 0.3702s	
100/2700 (epoch 1.852), train_loss = 3.26956264, grad/param norm = 6.9581e-01, time/batch = 0.4214s	
101/2700 (epoch 1.870), train_loss = 3.25732118, grad/param norm = 6.7315e-01, time/batch = 0.4248s	
102/2700 (epoch 1.889), train_loss = 3.31538566, grad/param norm = 8.1527e-01, time/batch = 0.4439s	
103/2700 (epoch 1.907), train_loss = 3.36468848, grad/param norm = 8.7564e-01, time/batch = 0.4395s	
104/2700 (epoch 1.926), train_loss = 3.31174406, grad/param norm = 9.4932e-01, time/batch = 0.4100s	
105/2700 (epoch 1.944), train_loss = 3.33004208, grad/param norm = 9.5685e-01, time/batch = 0.3250s	
106/2700 (epoch 1.963), train_loss = 3.40321485, grad/param norm = 9.6292e-01, time/batch = 0.3670s	
107/2700 (epoch 1.981), train_loss = 3.46068258, grad/param norm = 9.1389e-01, time/batch = 0.4230s	
108/2700 (epoch 2.000), train_loss = 3.35315386, grad/param norm = 8.8728e-01, time/batch = 0.4583s	
109/2700 (epoch 2.019), train_loss = 3.29610118, grad/param norm = 9.7587e-01, time/batch = 0.4386s	
110/2700 (epoch 2.037), train_loss = 3.32148814, grad/param norm = 1.0070e+00, time/batch = 0.4413s	
111/2700 (epoch 2.056), train_loss = 3.30450227, grad/param norm = 8.0375e-01, time/batch = 0.3687s	
112/2700 (epoch 2.074), train_loss = 3.33558583, grad/param norm = 7.4290e-01, time/batch = 0.4261s	
113/2700 (epoch 2.093), train_loss = 3.34718836, grad/param norm = 7.8724e-01, time/batch = 0.4612s	
114/2700 (epoch 2.111), train_loss = 3.32102209, grad/param norm = 8.1810e-01, time/batch = 0.4282s	
115/2700 (epoch 2.130), train_loss = 3.33499690, grad/param norm = 7.6306e-01, time/batch = 0.3416s	
116/2700 (epoch 2.148), train_loss = 3.28618108, grad/param norm = 8.4164e-01, time/batch = 0.3048s	
117/2700 (epoch 2.167), train_loss = 3.31284436, grad/param norm = 9.2507e-01, time/batch = 0.4064s	
118/2700 (epoch 2.185), train_loss = 3.29989206, grad/param norm = 8.8106e-01, time/batch = 0.4488s	
119/2700 (epoch 2.204), train_loss = 3.22629292, grad/param norm = 8.7323e-01, time/batch = 0.4381s	
120/2700 (epoch 2.222), train_loss = 3.20085903, grad/param norm = 9.1401e-01, time/batch = 0.4417s	
121/2700 (epoch 2.241), train_loss = 3.20262669, grad/param norm = 6.1241e-01, time/batch = 0.3987s	
122/2700 (epoch 2.259), train_loss = 3.24273713, grad/param norm = 5.9315e-01, time/batch = 0.3822s	
123/2700 (epoch 2.278), train_loss = 3.32053317, grad/param norm = 7.4090e-01, time/batch = 0.3737s	
124/2700 (epoch 2.296), train_loss = 3.33583416, grad/param norm = 7.7301e-01, time/batch = 0.3916s	
125/2700 (epoch 2.315), train_loss = 3.31400527, grad/param norm = 7.3277e-01, time/batch = 0.3121s	
126/2700 (epoch 2.333), train_loss = 3.39266643, grad/param norm = 7.2462e-01, time/batch = 0.3783s	
127/2700 (epoch 2.352), train_loss = 3.39743734, grad/param norm = 8.1745e-01, time/batch = 0.4549s	
128/2700 (epoch 2.370), train_loss = 3.35945775, grad/param norm = 8.3620e-01, time/batch = 0.4625s	
129/2700 (epoch 2.389), train_loss = 3.29591438, grad/param norm = 7.4229e-01, time/batch = 0.4363s	
130/2700 (epoch 2.407), train_loss = 3.32662897, grad/param norm = 7.2395e-01, time/batch = 0.4441s	
131/2700 (epoch 2.426), train_loss = 3.32054271, grad/param norm = 7.9845e-01, time/batch = 0.4047s	
132/2700 (epoch 2.444), train_loss = 3.25194078, grad/param norm = 8.9492e-01, time/batch = 0.3406s	
133/2700 (epoch 2.463), train_loss = 3.31391950, grad/param norm = 1.0133e+00, time/batch = 0.4088s	
134/2700 (epoch 2.481), train_loss = 3.36935577, grad/param norm = 9.6326e-01, time/batch = 0.4215s	
135/2700 (epoch 2.500), train_loss = 3.43427723, grad/param norm = 9.5727e-01, time/batch = 0.4101s	
136/2700 (epoch 2.519), train_loss = 3.38202708, grad/param norm = 9.4065e-01, time/batch = 0.3376s	
137/2700 (epoch 2.537), train_loss = 3.40589370, grad/param norm = 1.0337e+00, time/batch = 0.3663s	
138/2700 (epoch 2.556), train_loss = 3.33413967, grad/param norm = 9.1680e-01, time/batch = 0.4336s	
139/2700 (epoch 2.574), train_loss = 3.28354919, grad/param norm = 9.0369e-01, time/batch = 0.4470s	
140/2700 (epoch 2.593), train_loss = 3.28890946, grad/param norm = 8.8792e-01, time/batch = 0.4693s	
141/2700 (epoch 2.611), train_loss = 3.22077537, grad/param norm = 9.1009e-01, time/batch = 0.4606s	
142/2700 (epoch 2.630), train_loss = 3.27640849, grad/param norm = 9.1577e-01, time/batch = 0.4061s	
143/2700 (epoch 2.648), train_loss = 3.35584682, grad/param norm = 9.2733e-01, time/batch = 0.3823s	
144/2700 (epoch 2.667), train_loss = 3.28553174, grad/param norm = 9.3165e-01, time/batch = 0.3872s	
145/2700 (epoch 2.685), train_loss = 3.26674035, grad/param norm = 8.8282e-01, time/batch = 0.4097s	
146/2700 (epoch 2.704), train_loss = 3.22968034, grad/param norm = 8.7631e-01, time/batch = 0.4163s	
147/2700 (epoch 2.722), train_loss = 3.22659218, grad/param norm = 8.5627e-01, time/batch = 0.3911s	
148/2700 (epoch 2.741), train_loss = 3.35639952, grad/param norm = 9.2799e-01, time/batch = 0.3134s	
149/2700 (epoch 2.759), train_loss = 3.31538063, grad/param norm = 8.8563e-01, time/batch = 0.4218s	
150/2700 (epoch 2.778), train_loss = 3.30010243, grad/param norm = 8.0525e-01, time/batch = 0.4650s	
151/2700 (epoch 2.796), train_loss = 3.29130096, grad/param norm = 8.2952e-01, time/batch = 0.4620s	
152/2700 (epoch 2.815), train_loss = 3.26209267, grad/param norm = 8.1803e-01, time/batch = 0.4591s	
153/2700 (epoch 2.833), train_loss = 3.28712893, grad/param norm = 8.6041e-01, time/batch = 0.4078s	
154/2700 (epoch 2.852), train_loss = 3.27335609, grad/param norm = 7.8043e-01, time/batch = 0.3786s	
155/2700 (epoch 2.870), train_loss = 3.26752751, grad/param norm = 7.8643e-01, time/batch = 0.4057s	
156/2700 (epoch 2.889), train_loss = 3.31916611, grad/param norm = 9.0169e-01, time/batch = 0.4132s	
157/2700 (epoch 2.907), train_loss = 3.36828980, grad/param norm = 9.4615e-01, time/batch = 0.4176s	
158/2700 (epoch 2.926), train_loss = 3.31573199, grad/param norm = 9.8700e-01, time/batch = 0.3971s	
159/2700 (epoch 2.944), train_loss = 3.33054108, grad/param norm = 9.2533e-01, time/batch = 0.2872s	
160/2700 (epoch 2.963), train_loss = 3.40007189, grad/param norm = 8.8390e-01, time/batch = 0.4190s	
161/2700 (epoch 2.981), train_loss = 3.45643163, grad/param norm = 8.4153e-01, time/batch = 0.4492s	
162/2700 (epoch 3.000), train_loss = 3.34827964, grad/param norm = 8.0298e-01, time/batch = 0.4624s	
163/2700 (epoch 3.019), train_loss = 3.29180938, grad/param norm = 8.7703e-01, time/batch = 0.4634s	
164/2700 (epoch 3.037), train_loss = 3.31784314, grad/param norm = 9.2430e-01, time/batch = 0.4135s	
165/2700 (epoch 3.056), train_loss = 3.30256884, grad/param norm = 7.6798e-01, time/batch = 0.3651s	
166/2700 (epoch 3.074), train_loss = 3.33874353, grad/param norm = 7.4864e-01, time/batch = 0.3974s	
167/2700 (epoch 3.093), train_loss = 3.34964540, grad/param norm = 8.0103e-01, time/batch = 0.4149s	
168/2700 (epoch 3.111), train_loss = 3.32200694, grad/param norm = 8.2475e-01, time/batch = 0.4247s	
169/2700 (epoch 3.130), train_loss = 3.33461962, grad/param norm = 7.7718e-01, time/batch = 0.3214s	
170/2700 (epoch 3.148), train_loss = 3.28777573, grad/param norm = 8.7994e-01, time/batch = 0.3952s	
171/2700 (epoch 3.167), train_loss = 3.31923359, grad/param norm = 9.7600e-01, time/batch = 0.3894s	
172/2700 (epoch 3.185), train_loss = 3.30175194, grad/param norm = 9.0775e-01, time/batch = 0.4336s	
173/2700 (epoch 3.204), train_loss = 3.22636366, grad/param norm = 9.0755e-01, time/batch = 0.4470s	
174/2700 (epoch 3.222), train_loss = 3.20234258, grad/param norm = 9.2603e-01, time/batch = 0.4134s	
175/2700 (epoch 3.241), train_loss = 3.20152439, grad/param norm = 5.9455e-01, time/batch = 0.4043s	
176/2700 (epoch 3.259), train_loss = 3.24093405, grad/param norm = 5.7004e-01, time/batch = 0.4203s	
177/2700 (epoch 3.278), train_loss = 3.31825603, grad/param norm = 7.1417e-01, time/batch = 0.4283s	
178/2700 (epoch 3.296), train_loss = 3.33179150, grad/param norm = 7.4436e-01, time/batch = 0.4293s	
179/2700 (epoch 3.315), train_loss = 3.31268092, grad/param norm = 7.1907e-01, time/batch = 0.3053s	
180/2700 (epoch 3.333), train_loss = 3.39211859, grad/param norm = 7.0727e-01, time/batch = 0.4032s	
181/2700 (epoch 3.352), train_loss = 3.39810933, grad/param norm = 7.9998e-01, time/batch = 0.4147s	
182/2700 (epoch 3.370), train_loss = 3.36021525, grad/param norm = 8.0518e-01, time/batch = 0.4632s	
183/2700 (epoch 3.389), train_loss = 3.29166288, grad/param norm = 6.5850e-01, time/batch = 0.4665s	
184/2700 (epoch 3.407), train_loss = 3.32246598, grad/param norm = 6.1177e-01, time/batch = 0.4667s	
185/2700 (epoch 3.426), train_loss = 3.31274034, grad/param norm = 5.9224e-01, time/batch = 0.3988s	
186/2700 (epoch 3.444), train_loss = 3.23943762, grad/param norm = 5.8228e-01, time/batch = 0.4105s	
187/2700 (epoch 3.463), train_loss = 3.29365227, grad/param norm = 6.5515e-01, time/batch = 0.4236s	
188/2700 (epoch 3.481), train_loss = 3.35638661, grad/param norm = 5.9423e-01, time/batch = 0.4273s	
189/2700 (epoch 3.500), train_loss = 3.41709291, grad/param norm = 6.9159e-01, time/batch = 0.3807s	
190/2700 (epoch 3.519), train_loss = 3.37655229, grad/param norm = 8.6945e-01, time/batch = 0.3875s	
191/2700 (epoch 3.537), train_loss = 3.41182707, grad/param norm = 1.1121e+00, time/batch = 0.3333s	
192/2700 (epoch 3.556), train_loss = 3.35125165, grad/param norm = 1.2855e+00, time/batch = 0.4228s	
193/2700 (epoch 3.574), train_loss = 3.31519313, grad/param norm = 1.1899e+00, time/batch = 0.4605s	
194/2700 (epoch 3.593), train_loss = 3.29850247, grad/param norm = 1.0198e+00, time/batch = 0.4656s	
195/2700 (epoch 3.611), train_loss = 3.23001175, grad/param norm = 1.0036e+00, time/batch = 0.4636s	
196/2700 (epoch 3.630), train_loss = 3.27006293, grad/param norm = 9.2730e-01, time/batch = 0.4346s	
197/2700 (epoch 3.648), train_loss = 3.34703907, grad/param norm = 9.2124e-01, time/batch = 0.3474s	
198/2700 (epoch 3.667), train_loss = 3.28315127, grad/param norm = 9.0282e-01, time/batch = 0.4499s	
199/2700 (epoch 3.685), train_loss = 3.26876778, grad/param norm = 8.8065e-01, time/batch = 0.3533s	
200/2700 (epoch 3.704), train_loss = 3.22917081, grad/param norm = 8.7769e-01, time/batch = 0.3830s	
201/2700 (epoch 3.722), train_loss = 3.22775944, grad/param norm = 8.8623e-01, time/batch = 0.3563s	
202/2700 (epoch 3.741), train_loss = 3.35900089, grad/param norm = 9.6141e-01, time/batch = 0.3798s	
203/2700 (epoch 3.759), train_loss = 3.31697994, grad/param norm = 9.0225e-01, time/batch = 0.4445s	
204/2700 (epoch 3.778), train_loss = 3.29857185, grad/param norm = 8.2690e-01, time/batch = 0.4632s	
205/2700 (epoch 3.796), train_loss = 3.28893834, grad/param norm = 7.9269e-01, time/batch = 0.4685s	
206/2700 (epoch 3.815), train_loss = 3.25953395, grad/param norm = 8.1093e-01, time/batch = 0.4459s	
207/2700 (epoch 3.833), train_loss = 3.29209518, grad/param norm = 8.7472e-01, time/batch = 0.3994s	
208/2700 (epoch 3.852), train_loss = 3.27881052, grad/param norm = 8.1529e-01, time/batch = 0.4008s	
209/2700 (epoch 3.870), train_loss = 3.26777680, grad/param norm = 7.5960e-01, time/batch = 0.3781s	
210/2700 (epoch 3.889), train_loss = 3.31228703, grad/param norm = 7.4232e-01, time/batch = 0.4280s	
211/2700 (epoch 3.907), train_loss = 3.34788863, grad/param norm = 6.8846e-01, time/batch = 0.3767s	
212/2700 (epoch 3.926), train_loss = 3.30540173, grad/param norm = 8.2987e-01, time/batch = 0.3054s	
213/2700 (epoch 3.944), train_loss = 3.32560285, grad/param norm = 8.4936e-01, time/batch = 0.3883s	
214/2700 (epoch 3.963), train_loss = 3.39443203, grad/param norm = 7.6237e-01, time/batch = 0.4398s	
215/2700 (epoch 3.981), train_loss = 3.44642289, grad/param norm = 7.3365e-01, time/batch = 0.4521s	
216/2700 (epoch 4.000), train_loss = 3.34409223, grad/param norm = 6.7167e-01, time/batch = 0.4627s	
217/2700 (epoch 4.019), train_loss = 3.28238807, grad/param norm = 7.3604e-01, time/batch = 0.4289s	
218/2700 (epoch 4.037), train_loss = 3.31332607, grad/param norm = 8.1445e-01, time/batch = 0.4014s	
219/2700 (epoch 4.056), train_loss = 3.30815006, grad/param norm = 8.3794e-01, time/batch = 0.3586s	
220/2700 (epoch 4.074), train_loss = 3.35175243, grad/param norm = 1.0715e+00, time/batch = 0.4419s	
221/2700 (epoch 4.093), train_loss = 3.36831180, grad/param norm = 1.1263e+00, time/batch = 0.4436s	
222/2700 (epoch 4.111), train_loss = 3.33338945, grad/param norm = 9.9443e-01, time/batch = 0.4075s	
223/2700 (epoch 4.130), train_loss = 3.34543038, grad/param norm = 8.5831e-01, time/batch = 0.3371s	
224/2700 (epoch 4.148), train_loss = 3.28665358, grad/param norm = 7.2909e-01, time/batch = 0.3565s	
225/2700 (epoch 4.167), train_loss = 3.30053560, grad/param norm = 8.1615e-01, time/batch = 0.4041s	
226/2700 (epoch 4.185), train_loss = 3.29286344, grad/param norm = 8.3918e-01, time/batch = 0.4454s	
227/2700 (epoch 4.204), train_loss = 3.23547562, grad/param norm = 9.2523e-01, time/batch = 0.4566s	
228/2700 (epoch 4.222), train_loss = 3.20621449, grad/param norm = 1.0293e+00, time/batch = 0.4492s	
229/2700 (epoch 4.241), train_loss = 3.23329599, grad/param norm = 1.0109e+00, time/batch = 0.3781s	
230/2700 (epoch 4.259), train_loss = 3.26534761, grad/param norm = 9.1692e-01, time/batch = 0.3940s	
231/2700 (epoch 4.278), train_loss = 3.34875898, grad/param norm = 9.9978e-01, time/batch = 0.4176s	
232/2700 (epoch 4.296), train_loss = 3.38856373, grad/param norm = 1.2636e+00, time/batch = 0.4414s	
233/2700 (epoch 4.315), train_loss = 3.84395652, grad/param norm = 2.3803e+00, time/batch = 0.4336s	
234/2700 (epoch 4.333), train_loss = 3.82725658, grad/param norm = 1.9404e+00, time/batch = 0.3882s	
235/2700 (epoch 4.352), train_loss = 3.79887578, grad/param norm = 1.7725e+00, time/batch = 0.3303s	
236/2700 (epoch 4.370), train_loss = 3.60976949, grad/param norm = 1.4452e+00, time/batch = 0.3574s	
237/2700 (epoch 4.389), train_loss = 3.49443533, grad/param norm = 1.5262e+00, time/batch = 0.4373s	
238/2700 (epoch 4.407), train_loss = 3.44857275, grad/param norm = 1.0760e+00, time/batch = 0.4576s	
239/2700 (epoch 4.426), train_loss = 3.37345122, grad/param norm = 7.5443e-01, time/batch = 0.4398s	
240/2700 (epoch 4.444), train_loss = 3.27903244, grad/param norm = 7.1465e-01, time/batch = 0.4318s	
241/2700 (epoch 4.463), train_loss = 3.31607095, grad/param norm = 7.0709e-01, time/batch = 0.3791s	
242/2700 (epoch 4.481), train_loss = 3.37213710, grad/param norm = 6.8602e-01, time/batch = 0.3963s	
243/2700 (epoch 4.500), train_loss = 3.43187620, grad/param norm = 8.0013e-01, time/batch = 0.4213s	
244/2700 (epoch 4.519), train_loss = 3.37375051, grad/param norm = 7.8150e-01, time/batch = 0.4304s	
245/2700 (epoch 4.537), train_loss = 3.37082970, grad/param norm = 8.6459e-01, time/batch = 0.4100s	
246/2700 (epoch 4.556), train_loss = 3.32965136, grad/param norm = 8.6294e-01, time/batch = 0.3175s	
247/2700 (epoch 4.574), train_loss = 3.25983895, grad/param norm = 7.7874e-01, time/batch = 0.3665s	
248/2700 (epoch 4.593), train_loss = 3.27334292, grad/param norm = 8.8529e-01, time/batch = 0.4361s	
249/2700 (epoch 4.611), train_loss = 3.20704250, grad/param norm = 8.2154e-01, time/batch = 0.4481s	
250/2700 (epoch 4.630), train_loss = 3.25155705, grad/param norm = 8.3861e-01, time/batch = 0.4655s	
251/2700 (epoch 4.648), train_loss = 3.33519533, grad/param norm = 8.6365e-01, time/batch = 0.4589s	
252/2700 (epoch 4.667), train_loss = 3.27065124, grad/param norm = 8.6289e-01, time/batch = 0.4104s	
253/2700 (epoch 4.685), train_loss = 3.25316344, grad/param norm = 7.2285e-01, time/batch = 0.3856s	
254/2700 (epoch 4.704), train_loss = 3.22073541, grad/param norm = 7.7715e-01, time/batch = 0.3942s	
255/2700 (epoch 4.722), train_loss = 3.21891423, grad/param norm = 7.3282e-01, time/batch = 0.4101s	
256/2700 (epoch 4.741), train_loss = 3.35193726, grad/param norm = 6.5228e-01, time/batch = 0.4064s	
257/2700 (epoch 4.759), train_loss = 3.30953552, grad/param norm = 8.0106e-01, time/batch = 0.3861s	
258/2700 (epoch 4.778), train_loss = 3.30722980, grad/param norm = 9.0187e-01, time/batch = 0.3203s	
259/2700 (epoch 4.796), train_loss = 3.30098611, grad/param norm = 9.1608e-01, time/batch = 0.4190s	
260/2700 (epoch 4.815), train_loss = 3.25630413, grad/param norm = 8.6828e-01, time/batch = 0.4604s	
261/2700 (epoch 4.833), train_loss = 3.27973240, grad/param norm = 8.7823e-01, time/batch = 0.4571s	
262/2700 (epoch 4.852), train_loss = 3.27420988, grad/param norm = 8.8964e-01, time/batch = 0.4664s	
263/2700 (epoch 4.870), train_loss = 3.27014232, grad/param norm = 8.9787e-01, time/batch = 0.4135s	
264/2700 (epoch 4.889), train_loss = 3.31429619, grad/param norm = 9.0550e-01, time/batch = 0.3833s	
265/2700 (epoch 4.907), train_loss = 3.35195827, grad/param norm = 8.7454e-01, time/batch = 0.3994s	
266/2700 (epoch 4.926), train_loss = 3.30794288, grad/param norm = 9.3924e-01, time/batch = 0.4145s	
267/2700 (epoch 4.944), train_loss = 3.32424872, grad/param norm = 8.3783e-01, time/batch = 0.4186s	
268/2700 (epoch 4.963), train_loss = 3.39610151, grad/param norm = 7.7607e-01, time/batch = 0.3957s	
269/2700 (epoch 4.981), train_loss = 3.44278562, grad/param norm = 7.3402e-01, time/batch = 0.2991s	
270/2700 (epoch 5.000), train_loss = 3.34620464, grad/param norm = 6.9473e-01, time/batch = 0.4122s	
271/2700 (epoch 5.019), train_loss = 3.28526688, grad/param norm = 7.5986e-01, time/batch = 0.4362s	
272/2700 (epoch 5.037), train_loss = 3.30864526, grad/param norm = 8.0270e-01, time/batch = 0.4600s	
273/2700 (epoch 5.056), train_loss = 3.29795395, grad/param norm = 6.7337e-01, time/batch = 0.4635s	
274/2700 (epoch 5.074), train_loss = 3.33392077, grad/param norm = 6.9387e-01, time/batch = 0.4136s	
275/2700 (epoch 5.093), train_loss = 3.34612580, grad/param norm = 7.3102e-01, time/batch = 0.3819s	
276/2700 (epoch 5.111), train_loss = 3.31747412, grad/param norm = 7.6777e-01, time/batch = 0.3736s	
277/2700 (epoch 5.130), train_loss = 3.33397334, grad/param norm = 7.6302e-01, time/batch = 0.4094s	
278/2700 (epoch 5.148), train_loss = 3.29016232, grad/param norm = 9.0570e-01, time/batch = 0.4218s	
279/2700 (epoch 5.167), train_loss = 3.32031381, grad/param norm = 9.9923e-01, time/batch = 0.3261s	
280/2700 (epoch 5.185), train_loss = 3.30696566, grad/param norm = 9.6511e-01, time/batch = 0.4045s	
281/2700 (epoch 5.204), train_loss = 3.23158870, grad/param norm = 9.3122e-01, time/batch = 0.4045s	
282/2700 (epoch 5.222), train_loss = 3.20162199, grad/param norm = 9.8888e-01, time/batch = 0.4332s	
283/2700 (epoch 5.241), train_loss = 3.20810313, grad/param norm = 7.6201e-01, time/batch = 0.4485s	
284/2700 (epoch 5.259), train_loss = 3.25353316, grad/param norm = 8.1591e-01, time/batch = 0.4127s	
285/2700 (epoch 5.278), train_loss = 3.34334061, grad/param norm = 9.7646e-01, time/batch = 0.4024s	
286/2700 (epoch 5.296), train_loss = 3.34353261, grad/param norm = 9.0830e-01, time/batch = 0.4169s	
287/2700 (epoch 5.315), train_loss = 3.31610993, grad/param norm = 8.1792e-01, time/batch = 0.4141s	
288/2700 (epoch 5.333), train_loss = 3.39584853, grad/param norm = 7.8359e-01, time/batch = 0.4288s	
289/2700 (epoch 5.352), train_loss = 3.39721252, grad/param norm = 8.2792e-01, time/batch = 0.3354s	
290/2700 (epoch 5.370), train_loss = 3.35865442, grad/param norm = 8.6019e-01, time/batch = 0.4057s	
291/2700 (epoch 5.389), train_loss = 3.29503671, grad/param norm = 7.2337e-01, time/batch = 0.3950s	
292/2700 (epoch 5.407), train_loss = 3.32693064, grad/param norm = 7.1848e-01, time/batch = 0.4523s	
293/2700 (epoch 5.426), train_loss = 3.31844654, grad/param norm = 7.1582e-01, time/batch = 0.4664s	
294/2700 (epoch 5.444), train_loss = 3.24385521, grad/param norm = 7.8075e-01, time/batch = 0.4646s	
295/2700 (epoch 5.463), train_loss = 3.30213590, grad/param norm = 9.4511e-01, time/batch = 0.4016s	
296/2700 (epoch 5.481), train_loss = 3.38200858, grad/param norm = 9.9250e-01, time/batch = 0.4023s	
297/2700 (epoch 5.500), train_loss = 3.44086275, grad/param norm = 1.0514e+00, time/batch = 0.4079s	
298/2700 (epoch 5.519), train_loss = 3.38662293, grad/param norm = 1.0659e+00, time/batch = 0.4186s	
299/2700 (epoch 5.537), train_loss = 3.40332785, grad/param norm = 1.0423e+00, time/batch = 0.3932s	
300/2700 (epoch 5.556), train_loss = 3.34420567, grad/param norm = 9.0486e-01, time/batch = 0.4085s	
301/2700 (epoch 5.574), train_loss = 3.26845542, grad/param norm = 7.4077e-01, time/batch = 0.3304s	
302/2700 (epoch 5.593), train_loss = 3.27557046, grad/param norm = 7.7643e-01, time/batch = 0.3977s	
303/2700 (epoch 5.611), train_loss = 3.21205474, grad/param norm = 7.1227e-01, time/batch = 0.4521s	
304/2700 (epoch 5.630), train_loss = 3.25512280, grad/param norm = 7.3310e-01, time/batch = 0.4629s	
305/2700 (epoch 5.648), train_loss = 3.34632901, grad/param norm = 8.3515e-01, time/batch = 0.4643s	
306/2700 (epoch 5.667), train_loss = 3.28612213, grad/param norm = 8.9455e-01, time/batch = 0.4443s	
307/2700 (epoch 5.685), train_loss = 3.26940670, grad/param norm = 7.5913e-01, time/batch = 0.3481s	
308/2700 (epoch 5.704), train_loss = 3.22850903, grad/param norm = 7.5658e-01, time/batch = 0.4232s	
309/2700 (epoch 5.722), train_loss = 3.22180508, grad/param norm = 6.7928e-01, time/batch = 0.3763s	
310/2700 (epoch 5.741), train_loss = 3.35072389, grad/param norm = 6.2847e-01, time/batch = 0.4135s	
311/2700 (epoch 5.759), train_loss = 3.31135097, grad/param norm = 7.5735e-01, time/batch = 0.3261s	
312/2700 (epoch 5.778), train_loss = 3.31240188, grad/param norm = 9.0144e-01, time/batch = 0.3762s	
313/2700 (epoch 5.796), train_loss = 3.30880607, grad/param norm = 9.2199e-01, time/batch = 0.4226s	
314/2700 (epoch 5.815), train_loss = 3.26533412, grad/param norm = 8.6976e-01, time/batch = 0.4575s	
315/2700 (epoch 5.833), train_loss = 3.29038813, grad/param norm = 9.1564e-01, time/batch = 0.4638s	
316/2700 (epoch 5.852), train_loss = 3.28750504, grad/param norm = 9.9832e-01, time/batch = 0.4653s	
317/2700 (epoch 5.870), train_loss = 3.29253109, grad/param norm = 1.2059e+00, time/batch = 0.4215s	
318/2700 (epoch 5.889), train_loss = 3.34462396, grad/param norm = 1.2186e+00, time/batch = 0.3849s	
319/2700 (epoch 5.907), train_loss = 3.36419166, grad/param norm = 1.0292e+00, time/batch = 0.3310s	
320/2700 (epoch 5.926), train_loss = 3.31089571, grad/param norm = 9.8583e-01, time/batch = 0.4290s	
321/2700 (epoch 5.944), train_loss = 3.32012271, grad/param norm = 8.0824e-01, time/batch = 0.3874s	
322/2700 (epoch 5.963), train_loss = 3.39210614, grad/param norm = 7.4663e-01, time/batch = 0.3651s	
323/2700 (epoch 5.981), train_loss = 3.44350934, grad/param norm = 7.2789e-01, time/batch = 0.3868s	
324/2700 (epoch 6.000), train_loss = 3.34830467, grad/param norm = 6.9557e-01, time/batch = 0.4225s	
325/2700 (epoch 6.019), train_loss = 3.28249929, grad/param norm = 7.4318e-01, time/batch = 0.4682s	
326/2700 (epoch 6.037), train_loss = 3.30902419, grad/param norm = 7.8332e-01, time/batch = 0.4629s	
327/2700 (epoch 6.056), train_loss = 3.29683801, grad/param norm = 6.6415e-01, time/batch = 0.4190s	
328/2700 (epoch 6.074), train_loss = 3.33667573, grad/param norm = 7.0240e-01, time/batch = 0.3951s	
329/2700 (epoch 6.093), train_loss = 3.34818529, grad/param norm = 7.3232e-01, time/batch = 0.3819s	
330/2700 (epoch 6.111), train_loss = 3.31706706, grad/param norm = 7.3387e-01, time/batch = 0.4429s	
331/2700 (epoch 6.130), train_loss = 3.33235802, grad/param norm = 7.0867e-01, time/batch = 0.4514s	
332/2700 (epoch 6.148), train_loss = 3.28867365, grad/param norm = 8.6322e-01, time/batch = 0.3722s	
333/2700 (epoch 6.167), train_loss = 3.31764734, grad/param norm = 9.5274e-01, time/batch = 0.3214s	
334/2700 (epoch 6.185), train_loss = 3.30396339, grad/param norm = 9.0445e-01, time/batch = 0.3736s	
335/2700 (epoch 6.204), train_loss = 3.23252221, grad/param norm = 9.1050e-01, time/batch = 0.4289s	
336/2700 (epoch 6.222), train_loss = 3.20401121, grad/param norm = 9.8462e-01, time/batch = 0.4529s	
337/2700 (epoch 6.241), train_loss = 3.21052777, grad/param norm = 7.7971e-01, time/batch = 0.4617s	
338/2700 (epoch 6.259), train_loss = 3.25952992, grad/param norm = 8.8720e-01, time/batch = 0.4352s	
339/2700 (epoch 6.278), train_loss = 3.35221366, grad/param norm = 1.0454e+00, time/batch = 0.3746s	
340/2700 (epoch 6.296), train_loss = 3.34620467, grad/param norm = 9.4735e-01, time/batch = 0.3999s	
341/2700 (epoch 6.315), train_loss = 3.31738298, grad/param norm = 8.5396e-01, time/batch = 0.4219s	
342/2700 (epoch 6.333), train_loss = 3.39681302, grad/param norm = 8.1992e-01, time/batch = 0.4483s	
343/2700 (epoch 6.352), train_loss = 3.39848284, grad/param norm = 8.5362e-01, time/batch = 0.4357s	
344/2700 (epoch 6.370), train_loss = 3.36000255, grad/param norm = 8.9023e-01, time/batch = 0.3022s	
345/2700 (epoch 6.389), train_loss = 3.29699118, grad/param norm = 7.4547e-01, time/batch = 0.3559s	
346/2700 (epoch 6.407), train_loss = 3.32757127, grad/param norm = 7.3205e-01, time/batch = 0.4252s	
347/2700 (epoch 6.426), train_loss = 3.31860495, grad/param norm = 7.1921e-01, time/batch = 0.4572s	
348/2700 (epoch 6.444), train_loss = 3.24429051, grad/param norm = 7.7566e-01, time/batch = 0.4645s	
349/2700 (epoch 6.463), train_loss = 3.30227703, grad/param norm = 9.2587e-01, time/batch = 0.4187s	
350/2700 (epoch 6.481), train_loss = 3.38165351, grad/param norm = 9.6988e-01, time/batch = 0.4156s	
351/2700 (epoch 6.500), train_loss = 3.43993086, grad/param norm = 1.0289e+00, time/batch = 0.3827s	
352/2700 (epoch 6.519), train_loss = 3.38592117, grad/param norm = 1.0431e+00, time/batch = 0.4061s	
353/2700 (epoch 6.537), train_loss = 3.40352890, grad/param norm = 1.0335e+00, time/batch = 0.4355s	
354/2700 (epoch 6.556), train_loss = 3.34400634, grad/param norm = 9.0085e-01, time/batch = 0.4293s	
355/2700 (epoch 6.574), train_loss = 3.26738678, grad/param norm = 7.3705e-01, time/batch = 0.4128s	
356/2700 (epoch 6.593), train_loss = 3.27554474, grad/param norm = 7.7412e-01, time/batch = 0.3361s	
357/2700 (epoch 6.611), train_loss = 3.21267209, grad/param norm = 7.1424e-01, time/batch = 0.3499s	
358/2700 (epoch 6.630), train_loss = 3.25565427, grad/param norm = 7.3409e-01, time/batch = 0.4362s	
359/2700 (epoch 6.648), train_loss = 3.34628852, grad/param norm = 8.3557e-01, time/batch = 0.4425s	
360/2700 (epoch 6.667), train_loss = 3.28647305, grad/param norm = 8.9228e-01, time/batch = 0.4703s	
361/2700 (epoch 6.685), train_loss = 3.26919285, grad/param norm = 7.5774e-01, time/batch = 0.4614s	
362/2700 (epoch 6.704), train_loss = 3.22823886, grad/param norm = 7.5562e-01, time/batch = 0.4158s	
363/2700 (epoch 6.722), train_loss = 3.22169139, grad/param norm = 6.7878e-01, time/batch = 0.3899s	
364/2700 (epoch 6.741), train_loss = 3.35009660, grad/param norm = 6.2660e-01, time/batch = 0.3827s	
365/2700 (epoch 6.759), train_loss = 3.31077875, grad/param norm = 7.5588e-01, time/batch = 0.4247s	
366/2700 (epoch 6.778), train_loss = 3.31340116, grad/param norm = 9.0872e-01, time/batch = 0.4200s	
367/2700 (epoch 6.796), train_loss = 3.31018501, grad/param norm = 9.3855e-01, time/batch = 0.4068s	
368/2700 (epoch 6.815), train_loss = 3.26642510, grad/param norm = 8.8778e-01, time/batch = 0.3215s	
369/2700 (epoch 6.833), train_loss = 3.29208315, grad/param norm = 9.4242e-01, time/batch = 0.3720s	
370/2700 (epoch 6.852), train_loss = 3.28953453, grad/param norm = 1.0280e+00, time/batch = 0.4571s	
371/2700 (epoch 6.870), train_loss = 3.29181296, grad/param norm = 1.2117e+00, time/batch = 0.4592s	
372/2700 (epoch 6.889), train_loss = 3.34188494, grad/param norm = 1.1923e+00, time/batch = 0.4635s	
373/2700 (epoch 6.907), train_loss = 3.35970476, grad/param norm = 9.9120e-01, time/batch = 0.4302s	
374/2700 (epoch 6.926), train_loss = 3.30909137, grad/param norm = 9.6715e-01, time/batch = 0.3934s	
375/2700 (epoch 6.944), train_loss = 3.31989604, grad/param norm = 8.0166e-01, time/batch = 0.3928s	
376/2700 (epoch 6.963), train_loss = 3.39150329, grad/param norm = 7.3967e-01, time/batch = 0.4118s	
377/2700 (epoch 6.981), train_loss = 3.44270656, grad/param norm = 7.1785e-01, time/batch = 0.4251s	
378/2700 (epoch 7.000), train_loss = 3.34737300, grad/param norm = 6.8368e-01, time/batch = 0.4184s	
379/2700 (epoch 7.019), train_loss = 3.28206738, grad/param norm = 7.3723e-01, time/batch = 0.2901s	
380/2700 (epoch 7.037), train_loss = 3.30929897, grad/param norm = 7.8366e-01, time/batch = 0.4027s	
381/2700 (epoch 7.056), train_loss = 3.29708888, grad/param norm = 6.6647e-01, time/batch = 0.4411s	
382/2700 (epoch 7.074), train_loss = 3.33737463, grad/param norm = 7.0565e-01, time/batch = 0.4686s	
383/2700 (epoch 7.093), train_loss = 3.34862350, grad/param norm = 7.3529e-01, time/batch = 0.4676s	
384/2700 (epoch 7.111), train_loss = 3.31756752, grad/param norm = 7.3829e-01, time/batch = 0.4482s	
385/2700 (epoch 7.130), train_loss = 3.33325830, grad/param norm = 7.1356e-01, time/batch = 0.3976s	
386/2700 (epoch 7.148), train_loss = 3.28845461, grad/param norm = 8.6313e-01, time/batch = 0.3772s	
387/2700 (epoch 7.167), train_loss = 3.31730803, grad/param norm = 9.4671e-01, time/batch = 0.3982s	
388/2700 (epoch 7.185), train_loss = 3.30314618, grad/param norm = 8.9635e-01, time/batch = 0.4109s	
389/2700 (epoch 7.204), train_loss = 3.23221705, grad/param norm = 9.0311e-01, time/batch = 0.3956s	
390/2700 (epoch 7.222), train_loss = 3.20285142, grad/param norm = 9.7138e-01, time/batch = 0.4176s	
391/2700 (epoch 7.241), train_loss = 3.20858685, grad/param norm = 7.5387e-01, time/batch = 0.3617s	
392/2700 (epoch 7.259), train_loss = 3.25532424, grad/param norm = 8.3225e-01, time/batch = 0.3759s	
393/2700 (epoch 7.278), train_loss = 3.34957927, grad/param norm = 1.0369e+00, time/batch = 0.4579s	
394/2700 (epoch 7.296), train_loss = 3.35222723, grad/param norm = 1.0054e+00, time/batch = 0.4623s	
395/2700 (epoch 7.315), train_loss = 3.32318142, grad/param norm = 8.8562e-01, time/batch = 0.4527s	
396/2700 (epoch 7.333), train_loss = 3.39860919, grad/param norm = 8.2740e-01, time/batch = 0.4100s	
397/2700 (epoch 7.352), train_loss = 3.39824572, grad/param norm = 8.5655e-01, time/batch = 0.3564s	
398/2700 (epoch 7.370), train_loss = 3.36089791, grad/param norm = 8.9231e-01, time/batch = 0.3809s	
399/2700 (epoch 7.389), train_loss = 3.29674561, grad/param norm = 7.4335e-01, time/batch = 0.3952s	
400/2700 (epoch 7.407), train_loss = 3.32717100, grad/param norm = 7.2996e-01, time/batch = 0.4392s	
401/2700 (epoch 7.426), train_loss = 3.31839490, grad/param norm = 7.1509e-01, time/batch = 0.4280s	
402/2700 (epoch 7.444), train_loss = 3.24420441, grad/param norm = 7.6984e-01, time/batch = 0.4021s	
403/2700 (epoch 7.463), train_loss = 3.30192804, grad/param norm = 9.1766e-01, time/batch = 0.3831s	
404/2700 (epoch 7.481), train_loss = 3.38120173, grad/param norm = 9.6431e-01, time/batch = 0.3904s	
405/2700 (epoch 7.500), train_loss = 3.43962883, grad/param norm = 1.0264e+00, time/batch = 0.4642s	
406/2700 (epoch 7.519), train_loss = 3.38580908, grad/param norm = 1.0441e+00, time/batch = 0.4532s	
407/2700 (epoch 7.537), train_loss = 3.40295285, grad/param norm = 1.0350e+00, time/batch = 0.4185s	
408/2700 (epoch 7.556), train_loss = 3.34391521, grad/param norm = 9.0133e-01, time/batch = 0.3567s	
409/2700 (epoch 7.574), train_loss = 3.26714185, grad/param norm = 7.3530e-01, time/batch = 0.3161s	
410/2700 (epoch 7.593), train_loss = 3.27536220, grad/param norm = 7.7256e-01, time/batch = 0.4376s	
411/2700 (epoch 7.611), train_loss = 3.21288035, grad/param norm = 7.1270e-01, time/batch = 0.4351s	
412/2700 (epoch 7.630), train_loss = 3.25545249, grad/param norm = 7.3287e-01, time/batch = 0.4420s	
413/2700 (epoch 7.648), train_loss = 3.34661247, grad/param norm = 8.3576e-01, time/batch = 0.4044s	
414/2700 (epoch 7.667), train_loss = 3.28606661, grad/param norm = 8.9046e-01, time/batch = 0.3936s	
415/2700 (epoch 7.685), train_loss = 3.26883699, grad/param norm = 7.5572e-01, time/batch = 0.4331s	
416/2700 (epoch 7.704), train_loss = 3.22822916, grad/param norm = 7.5681e-01, time/batch = 0.4426s	
417/2700 (epoch 7.722), train_loss = 3.22208757, grad/param norm = 6.8118e-01, time/batch = 0.4379s	
418/2700 (epoch 7.741), train_loss = 3.34989535, grad/param norm = 6.2508e-01, time/batch = 0.3918s	
419/2700 (epoch 7.759), train_loss = 3.31089539, grad/param norm = 7.5801e-01, time/batch = 0.3353s	
420/2700 (epoch 7.778), train_loss = 3.31415883, grad/param norm = 9.1693e-01, time/batch = 0.4323s	
421/2700 (epoch 7.796), train_loss = 3.31083297, grad/param norm = 9.4541e-01, time/batch = 0.4280s	
422/2700 (epoch 7.815), train_loss = 3.26663293, grad/param norm = 8.9841e-01, time/batch = 0.4353s	
423/2700 (epoch 7.833), train_loss = 3.29377123, grad/param norm = 9.5364e-01, time/batch = 0.4026s	
424/2700 (epoch 7.852), train_loss = 3.28979729, grad/param norm = 1.0277e+00, time/batch = 0.3752s	
425/2700 (epoch 7.870), train_loss = 3.29149818, grad/param norm = 1.1994e+00, time/batch = 0.4095s	
426/2700 (epoch 7.889), train_loss = 3.34046492, grad/param norm = 1.1795e+00, time/batch = 0.4500s	
427/2700 (epoch 7.907), train_loss = 3.36143577, grad/param norm = 1.0044e+00, time/batch = 0.4648s	
428/2700 (epoch 7.926), train_loss = 3.30904250, grad/param norm = 9.7208e-01, time/batch = 0.4532s	
429/2700 (epoch 7.944), train_loss = 3.32015697, grad/param norm = 8.0049e-01, time/batch = 0.3871s	
430/2700 (epoch 7.963), train_loss = 3.39163672, grad/param norm = 7.3556e-01, time/batch = 0.4237s	
431/2700 (epoch 7.981), train_loss = 3.44248648, grad/param norm = 7.1707e-01, time/batch = 0.4065s	
432/2700 (epoch 8.000), train_loss = 3.34781147, grad/param norm = 6.8379e-01, time/batch = 0.4276s	
433/2700 (epoch 8.019), train_loss = 3.28201081, grad/param norm = 7.3653e-01, time/batch = 0.4278s	
434/2700 (epoch 8.037), train_loss = 3.30949476, grad/param norm = 7.8367e-01, time/batch = 0.4090s	
435/2700 (epoch 8.056), train_loss = 3.29762545, grad/param norm = 6.7003e-01, time/batch = 0.3692s	
436/2700 (epoch 8.074), train_loss = 3.33832664, grad/param norm = 7.1169e-01, time/batch = 0.3719s	
437/2700 (epoch 8.093), train_loss = 3.34930033, grad/param norm = 7.4035e-01, time/batch = 0.4074s	
438/2700 (epoch 8.111), train_loss = 3.31783695, grad/param norm = 7.3783e-01, time/batch = 0.4586s	
439/2700 (epoch 8.130), train_loss = 3.33295767, grad/param norm = 7.0944e-01, time/batch = 0.4413s	
440/2700 (epoch 8.148), train_loss = 3.28804093, grad/param norm = 8.5297e-01, time/batch = 0.4705s	
441/2700 (epoch 8.167), train_loss = 3.31625575, grad/param norm = 9.3549e-01, time/batch = 0.4149s	
442/2700 (epoch 8.185), train_loss = 3.30246580, grad/param norm = 8.8583e-01, time/batch = 0.3925s	
443/2700 (epoch 8.204), train_loss = 3.23196866, grad/param norm = 8.9716e-01, time/batch = 0.4224s	
444/2700 (epoch 8.222), train_loss = 3.20273310, grad/param norm = 9.6756e-01, time/batch = 0.4447s	
445/2700 (epoch 8.241), train_loss = 3.20816264, grad/param norm = 7.4856e-01, time/batch = 0.4226s	
446/2700 (epoch 8.259), train_loss = 3.25391613, grad/param norm = 8.1348e-01, time/batch = 0.3333s	
447/2700 (epoch 8.278), train_loss = 3.34754105, grad/param norm = 1.0308e+00, time/batch = 0.3234s	
448/2700 (epoch 8.296), train_loss = 3.34968806, grad/param norm = 9.9319e-01, time/batch = 0.4126s	
449/2700 (epoch 8.315), train_loss = 3.32237554, grad/param norm = 8.8721e-01, time/batch = 0.4363s	
450/2700 (epoch 8.333), train_loss = 3.39827155, grad/param norm = 8.3261e-01, time/batch = 0.4576s	
451/2700 (epoch 8.352), train_loss = 3.39939819, grad/param norm = 8.5856e-01, time/batch = 0.4525s	
452/2700 (epoch 8.370), train_loss = 3.36044664, grad/param norm = 8.8848e-01, time/batch = 0.4188s	
453/2700 (epoch 8.389), train_loss = 3.29899623, grad/param norm = 7.5850e-01, time/batch = 0.3397s	
454/2700 (epoch 8.407), train_loss = 3.32999072, grad/param norm = 7.4070e-01, time/batch = 0.4521s	
455/2700 (epoch 8.426), train_loss = 3.31923227, grad/param norm = 7.2842e-01, time/batch = 0.4186s	
456/2700 (epoch 8.444), train_loss = 3.24571314, grad/param norm = 7.9378e-01, time/batch = 0.3571s	
457/2700 (epoch 8.463), train_loss = 3.30384231, grad/param norm = 9.5527e-01, time/batch = 0.3353s	
458/2700 (epoch 8.481), train_loss = 3.38274890, grad/param norm = 9.7906e-01, time/batch = 0.3834s	
459/2700 (epoch 8.500), train_loss = 3.43799038, grad/param norm = 1.0211e+00, time/batch = 0.4369s	
460/2700 (epoch 8.519), train_loss = 3.38755317, grad/param norm = 1.0575e+00, time/batch = 0.4656s	
461/2700 (epoch 8.537), train_loss = 3.40837933, grad/param norm = 1.0472e+00, time/batch = 0.4528s	
462/2700 (epoch 8.556), train_loss = 3.34643996, grad/param norm = 8.9623e-01, time/batch = 0.4568s	
463/2700 (epoch 8.574), train_loss = 3.26643918, grad/param norm = 7.2507e-01, time/batch = 0.4178s	
464/2700 (epoch 8.593), train_loss = 3.27435714, grad/param norm = 7.6149e-01, time/batch = 0.3862s	
465/2700 (epoch 8.611), train_loss = 3.21307802, grad/param norm = 7.1809e-01, time/batch = 0.3987s	
466/2700 (epoch 8.630), train_loss = 3.25620098, grad/param norm = 7.3816e-01, time/batch = 0.3845s	
467/2700 (epoch 8.648), train_loss = 3.34723057, grad/param norm = 8.3468e-01, time/batch = 0.2985s	
468/2700 (epoch 8.667), train_loss = 3.28600601, grad/param norm = 8.9339e-01, time/batch = 0.3920s	
469/2700 (epoch 8.685), train_loss = 3.27194703, grad/param norm = 7.6773e-01, time/batch = 0.4208s	
470/2700 (epoch 8.704), train_loss = 3.23397721, grad/param norm = 7.8013e-01, time/batch = 0.4680s	
471/2700 (epoch 8.722), train_loss = 3.22480574, grad/param norm = 6.9011e-01, time/batch = 0.4596s	
472/2700 (epoch 8.741), train_loss = 3.34826188, grad/param norm = 6.1733e-01, time/batch = 0.4387s	
473/2700 (epoch 8.759), train_loss = 3.31138992, grad/param norm = 7.5968e-01, time/batch = 0.4180s	
474/2700 (epoch 8.778), train_loss = 3.31472863, grad/param norm = 9.3218e-01, time/batch = 0.3984s	
475/2700 (epoch 8.796), train_loss = 3.31600400, grad/param norm = 9.7675e-01, time/batch = 0.4210s	
476/2700 (epoch 8.815), train_loss = 3.26779787, grad/param norm = 9.2293e-01, time/batch = 0.4447s	
477/2700 (epoch 8.833), train_loss = 3.29482934, grad/param norm = 1.0178e+00, time/batch = 0.4183s	
478/2700 (epoch 8.852), train_loss = 3.29645402, grad/param norm = 1.1053e+00, time/batch = 0.3469s	
479/2700 (epoch 8.870), train_loss = 3.29419570, grad/param norm = 1.2235e+00, time/batch = 0.2922s	
480/2700 (epoch 8.889), train_loss = 3.34107851, grad/param norm = 1.1683e+00, time/batch = 0.4416s	
481/2700 (epoch 8.907), train_loss = 3.35470938, grad/param norm = 9.1495e-01, time/batch = 0.4382s	
482/2700 (epoch 8.926), train_loss = 3.30471384, grad/param norm = 9.0716e-01, time/batch = 0.4568s	
483/2700 (epoch 8.944), train_loss = 3.32002316, grad/param norm = 7.7289e-01, time/batch = 0.4430s	
484/2700 (epoch 8.963), train_loss = 3.39111649, grad/param norm = 7.1758e-01, time/batch = 0.4351s	
485/2700 (epoch 8.981), train_loss = 3.44187945, grad/param norm = 7.0025e-01, time/batch = 0.3984s	
486/2700 (epoch 9.000), train_loss = 3.34697106, grad/param norm = 6.6737e-01, time/batch = 0.4066s	
487/2700 (epoch 9.019), train_loss = 3.28197721, grad/param norm = 7.2573e-01, time/batch = 0.4382s	
488/2700 (epoch 9.037), train_loss = 3.30975043, grad/param norm = 7.8004e-01, time/batch = 0.4277s	
489/2700 (epoch 9.056), train_loss = 3.30089162, grad/param norm = 6.8249e-01, time/batch = 0.3235s	
490/2700 (epoch 9.074), train_loss = 3.33844623, grad/param norm = 7.1325e-01, time/batch = 0.3407s	
491/2700 (epoch 9.093), train_loss = 3.34961573, grad/param norm = 7.3682e-01, time/batch = 0.3915s	
492/2700 (epoch 9.111), train_loss = 3.31801740, grad/param norm = 7.3709e-01, time/batch = 0.4437s	
493/2700 (epoch 9.130), train_loss = 3.33502490, grad/param norm = 7.0974e-01, time/batch = 0.4590s	
494/2700 (epoch 9.148), train_loss = 3.28764316, grad/param norm = 8.3430e-01, time/batch = 0.4408s	
495/2700 (epoch 9.167), train_loss = 3.31397022, grad/param norm = 9.0850e-01, time/batch = 0.4213s	
496/2700 (epoch 9.185), train_loss = 3.29844341, grad/param norm = 8.4556e-01, time/batch = 0.3972s	
497/2700 (epoch 9.204), train_loss = 3.23008806, grad/param norm = 8.8054e-01, time/batch = 0.4162s	
498/2700 (epoch 9.222), train_loss = 3.20485816, grad/param norm = 9.7416e-01, time/batch = 0.4401s	
499/2700 (epoch 9.241), train_loss = 3.21303504, grad/param norm = 7.9703e-01, time/batch = 0.3986s	
500/2700 (epoch 9.259), train_loss = 3.25212972, grad/param norm = 8.0765e-01, time/batch = 0.4172s	
501/2700 (epoch 9.278), train_loss = 3.34234529, grad/param norm = 1.0672e+00, time/batch = 0.3330s	
502/2700 (epoch 9.296), train_loss = 3.35867410, grad/param norm = 1.1060e+00, time/batch = 0.3271s	
503/2700 (epoch 9.315), train_loss = 3.33040196, grad/param norm = 9.1892e-01, time/batch = 0.4368s	
504/2700 (epoch 9.333), train_loss = 3.39721932, grad/param norm = 8.0698e-01, time/batch = 0.4590s	
505/2700 (epoch 9.352), train_loss = 3.40117188, grad/param norm = 8.4870e-01, time/batch = 0.4531s	
506/2700 (epoch 9.370), train_loss = 3.36284201, grad/param norm = 8.8019e-01, time/batch = 0.4303s	
507/2700 (epoch 9.389), train_loss = 3.29576071, grad/param norm = 6.8746e-01, time/batch = 0.3953s	
508/2700 (epoch 9.407), train_loss = 3.32369332, grad/param norm = 6.5571e-01, time/batch = 0.3999s	
509/2700 (epoch 9.426), train_loss = 3.31587632, grad/param norm = 6.3099e-01, time/batch = 0.3908s	
510/2700 (epoch 9.444), train_loss = 3.23865323, grad/param norm = 6.5361e-01, time/batch = 0.4262s	
511/2700 (epoch 9.463), train_loss = 3.29641186, grad/param norm = 8.0298e-01, time/batch = 0.4376s	
512/2700 (epoch 9.481), train_loss = 3.37679966, grad/param norm = 8.9843e-01, time/batch = 0.4034s	
513/2700 (epoch 9.500), train_loss = 3.44021392, grad/param norm = 1.0358e+00, time/batch = 0.3596s	
514/2700 (epoch 9.519), train_loss = 3.38990156, grad/param norm = 1.0819e+00, time/batch = 0.3193s	
515/2700 (epoch 9.537), train_loss = 3.40708694, grad/param norm = 1.0642e+00, time/batch = 0.4301s	
516/2700 (epoch 9.556), train_loss = 3.34874411, grad/param norm = 9.2102e-01, time/batch = 0.4433s	
517/2700 (epoch 9.574), train_loss = 3.26596391, grad/param norm = 7.2589e-01, time/batch = 0.4577s	
518/2700 (epoch 9.593), train_loss = 3.27711904, grad/param norm = 7.9456e-01, time/batch = 0.4098s	
519/2700 (epoch 9.611), train_loss = 3.21449224, grad/param norm = 7.3218e-01, time/batch = 0.3236s	
520/2700 (epoch 9.630), train_loss = 3.25765417, grad/param norm = 7.5513e-01, time/batch = 0.4574s	
521/2700 (epoch 9.648), train_loss = 3.34771870, grad/param norm = 8.5283e-01, time/batch = 0.4629s	
522/2700 (epoch 9.667), train_loss = 3.28939798, grad/param norm = 9.2585e-01, time/batch = 0.4514s	
523/2700 (epoch 9.685), train_loss = 3.27155470, grad/param norm = 7.7280e-01, time/batch = 0.4070s	
524/2700 (epoch 9.704), train_loss = 3.22893623, grad/param norm = 7.6333e-01, time/batch = 0.3547s	
525/2700 (epoch 9.722), train_loss = 3.22247528, grad/param norm = 6.9178e-01, time/batch = 0.3291s	
526/2700 (epoch 9.741), train_loss = 3.35167419, grad/param norm = 6.3093e-01, time/batch = 0.3731s	
527/2700 (epoch 9.759), train_loss = 3.31492538, grad/param norm = 7.8594e-01, time/batch = 0.4035s	
528/2700 (epoch 9.778), train_loss = 3.31769650, grad/param norm = 9.4263e-01, time/batch = 0.4083s	
529/2700 (epoch 9.796), train_loss = 3.30927753, grad/param norm = 9.4595e-01, time/batch = 0.3844s	
530/2700 (epoch 9.815), train_loss = 3.26816563, grad/param norm = 9.2972e-01, time/batch = 0.4490s	
531/2700 (epoch 9.833), train_loss = 3.29631895, grad/param norm = 1.0163e+00, time/batch = 0.4541s	
532/2700 (epoch 9.852), train_loss = 3.29529885, grad/param norm = 1.0997e+00, time/batch = 0.4655s	
533/2700 (epoch 9.870), train_loss = 3.29141627, grad/param norm = 1.1508e+00, time/batch = 0.4376s	
534/2700 (epoch 9.889), train_loss = 3.33414271, grad/param norm = 1.0976e+00, time/batch = 0.3966s	
535/2700 (epoch 9.907), train_loss = 3.35549247, grad/param norm = 8.9618e-01, time/batch = 0.3060s	
536/2700 (epoch 9.926), train_loss = 3.30345841, grad/param norm = 8.9117e-01, time/batch = 0.3551s	
537/2700 (epoch 9.944), train_loss = 3.31781996, grad/param norm = 7.7046e-01, time/batch = 0.4474s	
538/2700 (epoch 9.963), train_loss = 3.39087487, grad/param norm = 7.1535e-01, time/batch = 0.4489s	
539/2700 (epoch 9.981), train_loss = 3.44206039, grad/param norm = 7.1038e-01, time/batch = 0.3677s	
decayed learning rate by a factor 0.97 to 0.00194	
540/2700 (epoch 10.000), train_loss = 3.34808069, grad/param norm = 6.7643e-01, time/batch = 0.4126s	
541/2700 (epoch 10.019), train_loss = 3.28636236, grad/param norm = 7.4661e-01, time/batch = 0.4222s	
542/2700 (epoch 10.037), train_loss = 3.30893426, grad/param norm = 7.6599e-01, time/batch = 0.4607s	
543/2700 (epoch 10.056), train_loss = 3.29509047, grad/param norm = 6.4995e-01, time/batch = 0.4556s	
544/2700 (epoch 10.074), train_loss = 3.34184963, grad/param norm = 7.3192e-01, time/batch = 0.4262s	
545/2700 (epoch 10.093), train_loss = 3.34750250, grad/param norm = 7.3127e-01, time/batch = 0.3204s	
546/2700 (epoch 10.111), train_loss = 3.31732373, grad/param norm = 7.1383e-01, time/batch = 0.3371s	
547/2700 (epoch 10.130), train_loss = 3.33182218, grad/param norm = 7.0470e-01, time/batch = 0.4010s	
548/2700 (epoch 10.148), train_loss = 3.29520765, grad/param norm = 9.1453e-01, time/batch = 0.4552s	
549/2700 (epoch 10.167), train_loss = 3.32735834, grad/param norm = 1.0126e+00, time/batch = 0.4313s	
550/2700 (epoch 10.185), train_loss = 3.30590757, grad/param norm = 9.0139e-01, time/batch = 0.4482s	
551/2700 (epoch 10.204), train_loss = 3.22787528, grad/param norm = 9.1122e-01, time/batch = 0.3755s	
552/2700 (epoch 10.222), train_loss = 3.20071797, grad/param norm = 9.6454e-01, time/batch = 0.4251s	
553/2700 (epoch 10.241), train_loss = 3.20460699, grad/param norm = 6.7395e-01, time/batch = 0.4630s	
554/2700 (epoch 10.259), train_loss = 3.24779689, grad/param norm = 7.1514e-01, time/batch = 0.4513s	
555/2700 (epoch 10.278), train_loss = 3.33716973, grad/param norm = 9.0020e-01, time/batch = 0.4228s	
556/2700 (epoch 10.296), train_loss = 3.33883144, grad/param norm = 8.7488e-01, time/batch = 0.3607s	
557/2700 (epoch 10.315), train_loss = 3.31322184, grad/param norm = 7.8638e-01, time/batch = 0.3382s	
558/2700 (epoch 10.333), train_loss = 3.39399242, grad/param norm = 7.6342e-01, time/batch = 0.3499s	
559/2700 (epoch 10.352), train_loss = 3.39759538, grad/param norm = 8.2250e-01, time/batch = 0.4187s	
560/2700 (epoch 10.370), train_loss = 3.36018331, grad/param norm = 8.6284e-01, time/batch = 0.4582s	
561/2700 (epoch 10.389), train_loss = 3.29442324, grad/param norm = 7.1782e-01, time/batch = 0.4642s	
562/2700 (epoch 10.407), train_loss = 3.32762990, grad/param norm = 7.3447e-01, time/batch = 0.4488s	
563/2700 (epoch 10.426), train_loss = 3.31955904, grad/param norm = 7.2896e-01, time/batch = 0.3534s	
564/2700 (epoch 10.444), train_loss = 3.24243099, grad/param norm = 7.8127e-01, time/batch = 0.4499s	
565/2700 (epoch 10.463), train_loss = 3.29959216, grad/param norm = 9.2588e-01, time/batch = 0.4584s	
566/2700 (epoch 10.481), train_loss = 3.37662371, grad/param norm = 9.6125e-01, time/batch = 0.4419s	
567/2700 (epoch 10.500), train_loss = 3.43791353, grad/param norm = 1.0058e+00, time/batch = 0.3733s	
568/2700 (epoch 10.519), train_loss = 3.38114492, grad/param norm = 1.0093e+00, time/batch = 0.3499s	
569/2700 (epoch 10.537), train_loss = 3.40129634, grad/param norm = 1.0021e+00, time/batch = 0.3247s	
570/2700 (epoch 10.556), train_loss = 3.34023426, grad/param norm = 8.6890e-01, time/batch = 0.4283s	
571/2700 (epoch 10.574), train_loss = 3.26545162, grad/param norm = 7.0326e-01, time/batch = 0.4143s	
572/2700 (epoch 10.593), train_loss = 3.27368901, grad/param norm = 7.2953e-01, time/batch = 0.4599s	
573/2700 (epoch 10.611), train_loss = 3.20874186, grad/param norm = 6.7245e-01, time/batch = 0.4266s	
574/2700 (epoch 10.630), train_loss = 3.25244302, grad/param norm = 6.9812e-01, time/batch = 0.3847s	
575/2700 (epoch 10.648), train_loss = 3.34348958, grad/param norm = 8.0748e-01, time/batch = 0.4051s	
576/2700 (epoch 10.667), train_loss = 3.28174370, grad/param norm = 8.5458e-01, time/batch = 0.4623s	
577/2700 (epoch 10.685), train_loss = 3.26483110, grad/param norm = 7.2423e-01, time/batch = 0.4463s	
578/2700 (epoch 10.704), train_loss = 3.22515551, grad/param norm = 7.2230e-01, time/batch = 0.4122s	
579/2700 (epoch 10.722), train_loss = 3.21833034, grad/param norm = 6.5032e-01, time/batch = 0.2873s	
580/2700 (epoch 10.741), train_loss = 3.34655984, grad/param norm = 6.0653e-01, time/batch = 0.4144s	
581/2700 (epoch 10.759), train_loss = 3.30712327, grad/param norm = 7.4145e-01, time/batch = 0.4263s	
582/2700 (epoch 10.778), train_loss = 3.31002949, grad/param norm = 8.6085e-01, time/batch = 0.4199s	
583/2700 (epoch 10.796), train_loss = 3.30383766, grad/param norm = 8.8918e-01, time/batch = 0.4615s	
584/2700 (epoch 10.815), train_loss = 3.26256462, grad/param norm = 8.1728e-01, time/batch = 0.4182s	
585/2700 (epoch 10.833), train_loss = 3.28313404, grad/param norm = 8.0792e-01, time/batch = 0.3978s	
586/2700 (epoch 10.852), train_loss = 3.27249830, grad/param norm = 7.9068e-01, time/batch = 0.4164s	
587/2700 (epoch 10.870), train_loss = 3.27314170, grad/param norm = 9.6211e-01, time/batch = 0.4459s	
588/2700 (epoch 10.889), train_loss = 3.33448432, grad/param norm = 1.1153e+00, time/batch = 0.4474s	
589/2700 (epoch 10.907), train_loss = 3.36881197, grad/param norm = 1.1527e+00, time/batch = 0.2854s	
590/2700 (epoch 10.926), train_loss = 3.31731099, grad/param norm = 1.0944e+00, time/batch = 0.3936s	
591/2700 (epoch 10.944), train_loss = 3.32053717, grad/param norm = 8.3713e-01, time/batch = 0.3947s	
592/2700 (epoch 10.963), train_loss = 3.39173981, grad/param norm = 7.6080e-01, time/batch = 0.4389s	
593/2700 (epoch 10.981), train_loss = 3.44224604, grad/param norm = 7.2121e-01, time/batch = 0.4307s	
decayed learning rate by a factor 0.97 to 0.0018818	
594/2700 (epoch 11.000), train_loss = 3.34562510, grad/param norm = 6.8986e-01, time/batch = 0.4228s	
595/2700 (epoch 11.019), train_loss = 3.28194196, grad/param norm = 7.4315e-01, time/batch = 0.4080s	
596/2700 (epoch 11.037), train_loss = 3.30304861, grad/param norm = 7.5216e-01, time/batch = 0.4190s	
597/2700 (epoch 11.056), train_loss = 3.29138289, grad/param norm = 6.1947e-01, time/batch = 0.4605s	
598/2700 (epoch 11.074), train_loss = 3.33141488, grad/param norm = 6.5229e-01, time/batch = 0.4607s	
599/2700 (epoch 11.093), train_loss = 3.34088222, grad/param norm = 6.8083e-01, time/batch = 0.3262s	
600/2700 (epoch 11.111), train_loss = 3.30929628, grad/param norm = 6.6758e-01, time/batch = 0.3316s	
601/2700 (epoch 11.130), train_loss = 3.32461329, grad/param norm = 6.2955e-01, time/batch = 0.3959s	
602/2700 (epoch 11.148), train_loss = 3.27928411, grad/param norm = 7.4478e-01, time/batch = 0.4199s	
603/2700 (epoch 11.167), train_loss = 3.30559918, grad/param norm = 8.3474e-01, time/batch = 0.4353s	
604/2700 (epoch 11.185), train_loss = 3.29177175, grad/param norm = 7.8795e-01, time/batch = 0.4298s	
605/2700 (epoch 11.204), train_loss = 3.22264998, grad/param norm = 7.9691e-01, time/batch = 0.4299s	
606/2700 (epoch 11.222), train_loss = 3.19325682, grad/param norm = 8.7286e-01, time/batch = 0.3927s	
607/2700 (epoch 11.241), train_loss = 3.20163010, grad/param norm = 6.4016e-01, time/batch = 0.4231s	
608/2700 (epoch 11.259), train_loss = 3.23961291, grad/param norm = 6.0512e-01, time/batch = 0.4602s	
609/2700 (epoch 11.278), train_loss = 3.32171743, grad/param norm = 8.1723e-01, time/batch = 0.4153s	
610/2700 (epoch 11.296), train_loss = 3.34008574, grad/param norm = 9.2143e-01, time/batch = 0.4424s	
611/2700 (epoch 11.315), train_loss = 3.32245042, grad/param norm = 8.6840e-01, time/batch = 0.4096s	
612/2700 (epoch 11.333), train_loss = 3.39241415, grad/param norm = 7.9849e-01, time/batch = 0.3066s	
613/2700 (epoch 11.352), train_loss = 3.39453886, grad/param norm = 8.4949e-01, time/batch = 0.3945s	
614/2700 (epoch 11.370), train_loss = 3.35779932, grad/param norm = 9.0299e-01, time/batch = 0.4180s	
615/2700 (epoch 11.389), train_loss = 3.29560287, grad/param norm = 7.6882e-01, time/batch = 0.4083s	
616/2700 (epoch 11.407), train_loss = 3.32488209, grad/param norm = 7.6778e-01, time/batch = 0.4329s	
617/2700 (epoch 11.426), train_loss = 3.31705019, grad/param norm = 7.4706e-01, time/batch = 0.3898s	
618/2700 (epoch 11.444), train_loss = 3.24378473, grad/param norm = 8.0364e-01, time/batch = 0.4142s	
619/2700 (epoch 11.463), train_loss = 3.29947503, grad/param norm = 9.2459e-01, time/batch = 0.4207s	
620/2700 (epoch 11.481), train_loss = 3.37604011, grad/param norm = 9.2994e-01, time/batch = 0.4619s	
621/2700 (epoch 11.500), train_loss = 3.43197000, grad/param norm = 9.4692e-01, time/batch = 0.4442s	
622/2700 (epoch 11.519), train_loss = 3.37710127, grad/param norm = 9.4959e-01, time/batch = 0.4146s	
623/2700 (epoch 11.537), train_loss = 3.39465322, grad/param norm = 9.5421e-01, time/batch = 0.3579s	
624/2700 (epoch 11.556), train_loss = 3.33546147, grad/param norm = 8.4592e-01, time/batch = 0.3020s	
625/2700 (epoch 11.574), train_loss = 3.26457525, grad/param norm = 7.0049e-01, time/batch = 0.4256s	
626/2700 (epoch 11.593), train_loss = 3.27092266, grad/param norm = 7.1718e-01, time/batch = 0.3780s	
627/2700 (epoch 11.611), train_loss = 3.20717793, grad/param norm = 6.6618e-01, time/batch = 0.4050s	
628/2700 (epoch 11.630), train_loss = 3.25065444, grad/param norm = 6.8236e-01, time/batch = 0.4017s	
629/2700 (epoch 11.648), train_loss = 3.33905475, grad/param norm = 7.7928e-01, time/batch = 0.3986s	
630/2700 (epoch 11.667), train_loss = 3.27695162, grad/param norm = 8.2208e-01, time/batch = 0.4627s	
631/2700 (epoch 11.685), train_loss = 3.26078597, grad/param norm = 7.0138e-01, time/batch = 0.4594s	
632/2700 (epoch 11.704), train_loss = 3.22192227, grad/param norm = 7.0168e-01, time/batch = 0.4214s	
633/2700 (epoch 11.722), train_loss = 3.21528583, grad/param norm = 6.3144e-01, time/batch = 0.3338s	
634/2700 (epoch 11.741), train_loss = 3.34417462, grad/param norm = 5.9124e-01, time/batch = 0.3162s	
635/2700 (epoch 11.759), train_loss = 3.30388459, grad/param norm = 7.1177e-01, time/batch = 0.4209s	
636/2700 (epoch 11.778), train_loss = 3.30557030, grad/param norm = 8.2910e-01, time/batch = 0.4306s	
637/2700 (epoch 11.796), train_loss = 3.30018897, grad/param norm = 8.7763e-01, time/batch = 0.3853s	
638/2700 (epoch 11.815), train_loss = 3.25987525, grad/param norm = 8.0863e-01, time/batch = 0.4005s	
639/2700 (epoch 11.833), train_loss = 3.28192588, grad/param norm = 8.1133e-01, time/batch = 0.3789s	
640/2700 (epoch 11.852), train_loss = 3.27307877, grad/param norm = 8.2773e-01, time/batch = 0.4334s	
641/2700 (epoch 11.870), train_loss = 3.27591731, grad/param norm = 1.0373e+00, time/batch = 0.4591s	
642/2700 (epoch 11.889), train_loss = 3.33578307, grad/param norm = 1.1400e+00, time/batch = 0.4490s	
643/2700 (epoch 11.907), train_loss = 3.36153666, grad/param norm = 1.0711e+00, time/batch = 0.3943s	
644/2700 (epoch 11.926), train_loss = 3.31153525, grad/param norm = 1.0275e+00, time/batch = 0.3203s	
645/2700 (epoch 11.944), train_loss = 3.31737940, grad/param norm = 8.0651e-01, time/batch = 0.3779s	
646/2700 (epoch 11.963), train_loss = 3.38819528, grad/param norm = 7.2709e-01, time/batch = 0.4387s	
647/2700 (epoch 11.981), train_loss = 3.43882463, grad/param norm = 6.9324e-01, time/batch = 0.4607s	
decayed learning rate by a factor 0.97 to 0.001825346	
648/2700 (epoch 12.000), train_loss = 3.34213864, grad/param norm = 6.6158e-01, time/batch = 0.4508s	
649/2700 (epoch 12.019), train_loss = 3.27937349, grad/param norm = 7.1790e-01, time/batch = 0.3737s	
650/2700 (epoch 12.037), train_loss = 3.30027827, grad/param norm = 7.2524e-01, time/batch = 0.4179s	
651/2700 (epoch 12.056), train_loss = 3.28934145, grad/param norm = 5.9570e-01, time/batch = 0.4218s	
652/2700 (epoch 12.074), train_loss = 3.32876193, grad/param norm = 6.3300e-01, time/batch = 0.4620s	
653/2700 (epoch 12.093), train_loss = 3.33782205, grad/param norm = 6.6447e-01, time/batch = 0.4494s	
654/2700 (epoch 12.111), train_loss = 3.30665468, grad/param norm = 6.4768e-01, time/batch = 0.3619s	
655/2700 (epoch 12.130), train_loss = 3.32209833, grad/param norm = 6.1098e-01, time/batch = 0.3227s	
656/2700 (epoch 12.148), train_loss = 3.27780093, grad/param norm = 7.2882e-01, time/batch = 0.3677s	
657/2700 (epoch 12.167), train_loss = 3.30363701, grad/param norm = 8.1675e-01, time/batch = 0.4404s	
658/2700 (epoch 12.185), train_loss = 3.28830583, grad/param norm = 7.5979e-01, time/batch = 0.4577s	
659/2700 (epoch 12.204), train_loss = 3.21960620, grad/param norm = 7.7242e-01, time/batch = 0.4275s	
660/2700 (epoch 12.222), train_loss = 3.19078770, grad/param norm = 8.5191e-01, time/batch = 0.4324s	
661/2700 (epoch 12.241), train_loss = 3.19971808, grad/param norm = 6.2749e-01, time/batch = 0.3612s	
662/2700 (epoch 12.259), train_loss = 3.23815808, grad/param norm = 6.0013e-01, time/batch = 0.4300s	
663/2700 (epoch 12.278), train_loss = 3.32011548, grad/param norm = 8.1626e-01, time/batch = 0.4605s	
664/2700 (epoch 12.296), train_loss = 3.33691550, grad/param norm = 9.0997e-01, time/batch = 0.4437s	
665/2700 (epoch 12.315), train_loss = 3.31833063, grad/param norm = 8.5570e-01, time/batch = 0.4034s	
666/2700 (epoch 12.333), train_loss = 3.38989014, grad/param norm = 7.8924e-01, time/batch = 0.3123s	
667/2700 (epoch 12.352), train_loss = 3.39179960, grad/param norm = 8.3329e-01, time/batch = 0.3370s	
668/2700 (epoch 12.370), train_loss = 3.35459488, grad/param norm = 8.8742e-01, time/batch = 0.4359s	
669/2700 (epoch 12.389), train_loss = 3.29344783, grad/param norm = 7.4920e-01, time/batch = 0.4376s	
670/2700 (epoch 12.407), train_loss = 3.32195180, grad/param norm = 7.4320e-01, time/batch = 0.4571s	
671/2700 (epoch 12.426), train_loss = 3.31522048, grad/param norm = 7.1702e-01, time/batch = 0.4641s	
672/2700 (epoch 12.444), train_loss = 3.24071424, grad/param norm = 7.7413e-01, time/batch = 0.4187s	
673/2700 (epoch 12.463), train_loss = 3.29586446, grad/param norm = 8.9099e-01, time/batch = 0.3424s	
674/2700 (epoch 12.481), train_loss = 3.37218892, grad/param norm = 9.0347e-01, time/batch = 0.4618s	
675/2700 (epoch 12.500), train_loss = 3.42970851, grad/param norm = 9.3591e-01, time/batch = 0.4268s	
676/2700 (epoch 12.519), train_loss = 3.37540775, grad/param norm = 9.4037e-01, time/batch = 0.3068s	
677/2700 (epoch 12.537), train_loss = 3.39285656, grad/param norm = 9.4387e-01, time/batch = 0.3455s	
678/2700 (epoch 12.556), train_loss = 3.33497024, grad/param norm = 8.4875e-01, time/batch = 0.4216s	
679/2700 (epoch 12.574), train_loss = 3.26402121, grad/param norm = 6.9367e-01, time/batch = 0.4433s	
680/2700 (epoch 12.593), train_loss = 3.26878689, grad/param norm = 6.9768e-01, time/batch = 0.4685s	
681/2700 (epoch 12.611), train_loss = 3.20388329, grad/param norm = 6.4336e-01, time/batch = 0.4539s	
682/2700 (epoch 12.630), train_loss = 3.25192036, grad/param norm = 6.8324e-01, time/batch = 0.4240s	
683/2700 (epoch 12.648), train_loss = 3.33651921, grad/param norm = 7.6044e-01, time/batch = 0.3912s	
684/2700 (epoch 12.667), train_loss = 3.28448882, grad/param norm = 8.4713e-01, time/batch = 0.4071s	
685/2700 (epoch 12.685), train_loss = 3.26625989, grad/param norm = 7.2104e-01, time/batch = 0.4158s	
686/2700 (epoch 12.704), train_loss = 3.28236118, grad/param norm = 1.0350e+00, time/batch = 0.3580s	
687/2700 (epoch 12.722), train_loss = 3.35020717, grad/param norm = 1.5479e+00, time/batch = 0.3313s	
688/2700 (epoch 12.741), train_loss = 3.54504149, grad/param norm = 1.1938e+00, time/batch = 0.3795s	
689/2700 (epoch 12.759), train_loss = 3.44539212, grad/param norm = 1.2176e+00, time/batch = 0.3997s	
690/2700 (epoch 12.778), train_loss = 3.44722455, grad/param norm = 1.7271e+00, time/batch = 0.4681s	
691/2700 (epoch 12.796), train_loss = 3.48662352, grad/param norm = 1.5161e+00, time/batch = 0.4682s	
692/2700 (epoch 12.815), train_loss = 3.35112500, grad/param norm = 1.3891e+00, time/batch = 0.4477s	
693/2700 (epoch 12.833), train_loss = 3.35940577, grad/param norm = 1.0878e+00, time/batch = 0.4364s	
694/2700 (epoch 12.852), train_loss = 3.31021927, grad/param norm = 9.8138e-01, time/batch = 0.3892s	
695/2700 (epoch 12.870), train_loss = 3.29576741, grad/param norm = 9.1388e-01, time/batch = 0.4189s	
696/2700 (epoch 12.889), train_loss = 3.31813061, grad/param norm = 8.8664e-01, time/batch = 0.4412s	
697/2700 (epoch 12.907), train_loss = 3.36123124, grad/param norm = 8.2719e-01, time/batch = 0.4265s	
698/2700 (epoch 12.926), train_loss = 3.31492185, grad/param norm = 7.4082e-01, time/batch = 0.3701s	
699/2700 (epoch 12.944), train_loss = 3.31286398, grad/param norm = 6.4045e-01, time/batch = 0.2758s	
700/2700 (epoch 12.963), train_loss = 3.39171711, grad/param norm = 6.2994e-01, time/batch = 0.4202s	
701/2700 (epoch 12.981), train_loss = 3.45696192, grad/param norm = 5.7625e-01, time/batch = 0.4382s	
decayed learning rate by a factor 0.97 to 0.00177058562	
702/2700 (epoch 13.000), train_loss = 3.34085802, grad/param norm = 5.6244e-01, time/batch = 0.4560s	
703/2700 (epoch 13.019), train_loss = 3.28503461, grad/param norm = 5.7313e-01, time/batch = 0.4524s	
704/2700 (epoch 13.037), train_loss = 3.28796862, grad/param norm = 5.6137e-01, time/batch = 0.4412s	
705/2700 (epoch 13.056), train_loss = 3.28732749, grad/param norm = 5.1718e-01, time/batch = 0.3955s	
706/2700 (epoch 13.074), train_loss = 3.32483840, grad/param norm = 6.2349e-01, time/batch = 0.4008s	
707/2700 (epoch 13.093), train_loss = 3.32786112, grad/param norm = 6.4650e-01, time/batch = 0.4420s	
708/2700 (epoch 13.111), train_loss = 3.31462234, grad/param norm = 6.2926e-01, time/batch = 0.4444s	
709/2700 (epoch 13.130), train_loss = 3.32761038, grad/param norm = 5.5287e-01, time/batch = 0.2948s	
710/2700 (epoch 13.148), train_loss = 3.27794914, grad/param norm = 6.6987e-01, time/batch = 0.3445s	
711/2700 (epoch 13.167), train_loss = 3.30372546, grad/param norm = 7.2898e-01, time/batch = 0.4200s	
712/2700 (epoch 13.185), train_loss = 3.27799967, grad/param norm = 6.3492e-01, time/batch = 0.4583s	
713/2700 (epoch 13.204), train_loss = 3.21171521, grad/param norm = 6.6261e-01, time/batch = 0.4668s	
714/2700 (epoch 13.222), train_loss = 3.19930835, grad/param norm = 7.7801e-01, time/batch = 0.4551s	
715/2700 (epoch 13.241), train_loss = 3.22347564, grad/param norm = 7.9267e-01, time/batch = 0.4308s	
716/2700 (epoch 13.259), train_loss = 3.24632520, grad/param norm = 7.9675e-01, time/batch = 0.3854s	
717/2700 (epoch 13.278), train_loss = 3.32849910, grad/param norm = 7.4705e-01, time/batch = 0.4026s	
718/2700 (epoch 13.296), train_loss = 3.33921817, grad/param norm = 7.7824e-01, time/batch = 0.4172s	
719/2700 (epoch 13.315), train_loss = 3.30937809, grad/param norm = 8.2021e-01, time/batch = 0.3812s	
720/2700 (epoch 13.333), train_loss = 3.38374283, grad/param norm = 8.1523e-01, time/batch = 0.4073s	
721/2700 (epoch 13.352), train_loss = 3.39137499, grad/param norm = 8.5049e-01, time/batch = 0.3261s	
722/2700 (epoch 13.370), train_loss = 3.33963142, grad/param norm = 7.4181e-01, time/batch = 0.3660s	
723/2700 (epoch 13.389), train_loss = 3.28733007, grad/param norm = 6.7982e-01, time/batch = 0.4564s	
724/2700 (epoch 13.407), train_loss = 3.31871225, grad/param norm = 6.1071e-01, time/batch = 0.4645s	
725/2700 (epoch 13.426), train_loss = 3.32012633, grad/param norm = 6.3521e-01, time/batch = 0.4418s	
726/2700 (epoch 13.444), train_loss = 3.24942472, grad/param norm = 6.3567e-01, time/batch = 0.3982s	
727/2700 (epoch 13.463), train_loss = 3.28560724, grad/param norm = 6.2754e-01, time/batch = 0.3629s	
728/2700 (epoch 13.481), train_loss = 3.35973842, grad/param norm = 5.4062e-01, time/batch = 0.3872s	
729/2700 (epoch 13.500), train_loss = 3.40240987, grad/param norm = 5.0973e-01, time/batch = 0.3916s	
730/2700 (epoch 13.519), train_loss = 3.36426132, grad/param norm = 5.4146e-01, time/batch = 0.4366s	
731/2700 (epoch 13.537), train_loss = 3.36856656, grad/param norm = 6.8069e-01, time/batch = 0.4133s	
732/2700 (epoch 13.556), train_loss = 3.33002569, grad/param norm = 7.1647e-01, time/batch = 0.3654s	
733/2700 (epoch 13.574), train_loss = 3.25839816, grad/param norm = 5.8496e-01, time/batch = 0.3878s	
734/2700 (epoch 13.593), train_loss = 3.26912929, grad/param norm = 6.8044e-01, time/batch = 0.4077s	
735/2700 (epoch 13.611), train_loss = 3.21287262, grad/param norm = 8.8274e-01, time/batch = 0.4649s	
736/2700 (epoch 13.630), train_loss = 3.28073647, grad/param norm = 9.1412e-01, time/batch = 0.4327s	
737/2700 (epoch 13.648), train_loss = 3.33897871, grad/param norm = 8.7019e-01, time/batch = 0.3917s	
738/2700 (epoch 13.667), train_loss = 3.27934536, grad/param norm = 9.6120e-01, time/batch = 0.3750s	
739/2700 (epoch 13.685), train_loss = 3.27494246, grad/param norm = 1.0087e+00, time/batch = 0.3930s	
740/2700 (epoch 13.704), train_loss = 3.23991002, grad/param norm = 9.4308e-01, time/batch = 0.4282s	
741/2700 (epoch 13.722), train_loss = 3.22379360, grad/param norm = 9.0752e-01, time/batch = 0.4291s	
742/2700 (epoch 13.741), train_loss = 3.36809012, grad/param norm = 9.7600e-01, time/batch = 0.3942s	
743/2700 (epoch 13.759), train_loss = 3.30756242, grad/param norm = 7.6480e-01, time/batch = 0.3639s	
744/2700 (epoch 13.778), train_loss = 3.29493170, grad/param norm = 5.9524e-01, time/batch = 0.3751s	
745/2700 (epoch 13.796), train_loss = 3.27585383, grad/param norm = 5.5307e-01, time/batch = 0.4478s	
746/2700 (epoch 13.815), train_loss = 3.23895402, grad/param norm = 6.6036e-01, time/batch = 0.4465s	
747/2700 (epoch 13.833), train_loss = 3.28706908, grad/param norm = 7.6284e-01, time/batch = 0.4170s	
748/2700 (epoch 13.852), train_loss = 3.28308585, grad/param norm = 8.4727e-01, time/batch = 0.3988s	
749/2700 (epoch 13.870), train_loss = 3.27472310, grad/param norm = 8.5602e-01, time/batch = 0.3186s	
750/2700 (epoch 13.889), train_loss = 3.29949176, grad/param norm = 7.4115e-01, time/batch = 0.4315s	
751/2700 (epoch 13.907), train_loss = 3.34200919, grad/param norm = 7.0038e-01, time/batch = 0.4328s	
752/2700 (epoch 13.926), train_loss = 3.31134065, grad/param norm = 8.3093e-01, time/batch = 0.4351s	
753/2700 (epoch 13.944), train_loss = 3.32460867, grad/param norm = 8.2007e-01, time/batch = 0.3702s	
754/2700 (epoch 13.963), train_loss = 3.40396330, grad/param norm = 8.4885e-01, time/batch = 0.4108s	
755/2700 (epoch 13.981), train_loss = 3.47445795, grad/param norm = 8.7531e-01, time/batch = 0.4460s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
756/2700 (epoch 14.000), train_loss = 3.36736561, grad/param norm = 8.0273e-01, time/batch = 0.4687s	
757/2700 (epoch 14.019), train_loss = 3.30745615, grad/param norm = 7.7308e-01, time/batch = 0.4677s	
758/2700 (epoch 14.037), train_loss = 3.29649638, grad/param norm = 6.4262e-01, time/batch = 0.4409s	
759/2700 (epoch 14.056), train_loss = 3.29009496, grad/param norm = 5.3197e-01, time/batch = 0.2790s	
760/2700 (epoch 14.074), train_loss = 3.32542761, grad/param norm = 5.6913e-01, time/batch = 0.4336s	
761/2700 (epoch 14.093), train_loss = 3.34003821, grad/param norm = 6.5644e-01, time/batch = 0.4492s	
762/2700 (epoch 14.111), train_loss = 3.31161917, grad/param norm = 6.8795e-01, time/batch = 0.4307s	
763/2700 (epoch 14.130), train_loss = 3.32579980, grad/param norm = 5.7367e-01, time/batch = 0.3995s	
764/2700 (epoch 14.148), train_loss = 3.27406715, grad/param norm = 6.9572e-01, time/batch = 0.3478s	
765/2700 (epoch 14.167), train_loss = 3.31261292, grad/param norm = 7.9534e-01, time/batch = 0.3828s	
766/2700 (epoch 14.185), train_loss = 3.27375426, grad/param norm = 7.0399e-01, time/batch = 0.4458s	
767/2700 (epoch 14.204), train_loss = 3.21948218, grad/param norm = 8.5695e-01, time/batch = 0.4631s	
768/2700 (epoch 14.222), train_loss = 3.21077572, grad/param norm = 1.0625e+00, time/batch = 0.4646s	
769/2700 (epoch 14.241), train_loss = 3.21780813, grad/param norm = 9.3052e-01, time/batch = 0.4116s	
770/2700 (epoch 14.259), train_loss = 3.24957610, grad/param norm = 7.9146e-01, time/batch = 0.4093s	
771/2700 (epoch 14.278), train_loss = 3.32751278, grad/param norm = 8.0108e-01, time/batch = 0.3619s	
772/2700 (epoch 14.296), train_loss = 3.34002142, grad/param norm = 8.1339e-01, time/batch = 0.4601s	
773/2700 (epoch 14.315), train_loss = 3.29903621, grad/param norm = 6.2892e-01, time/batch = 0.4350s	
774/2700 (epoch 14.333), train_loss = 3.36495978, grad/param norm = 5.4718e-01, time/batch = 0.3900s	
775/2700 (epoch 14.352), train_loss = 3.37267828, grad/param norm = 6.0507e-01, time/batch = 0.3264s	
776/2700 (epoch 14.370), train_loss = 3.34153342, grad/param norm = 7.1127e-01, time/batch = 0.3588s	
777/2700 (epoch 14.389), train_loss = 3.29395557, grad/param norm = 6.2153e-01, time/batch = 0.4364s	
778/2700 (epoch 14.407), train_loss = 3.31118395, grad/param norm = 5.5333e-01, time/batch = 0.4583s	
779/2700 (epoch 14.426), train_loss = 3.30044776, grad/param norm = 5.0113e-01, time/batch = 0.4453s	
780/2700 (epoch 14.444), train_loss = 3.23171420, grad/param norm = 5.2687e-01, time/batch = 0.4236s	
781/2700 (epoch 14.463), train_loss = 3.28491165, grad/param norm = 6.4535e-01, time/batch = 0.4096s	
782/2700 (epoch 14.481), train_loss = 3.37083117, grad/param norm = 7.4417e-01, time/batch = 0.3886s	
783/2700 (epoch 14.500), train_loss = 3.42730287, grad/param norm = 9.6534e-01, time/batch = 0.3960s	
784/2700 (epoch 14.519), train_loss = 3.38484612, grad/param norm = 9.5347e-01, time/batch = 0.4350s	
785/2700 (epoch 14.537), train_loss = 3.37663301, grad/param norm = 8.2077e-01, time/batch = 0.3768s	
786/2700 (epoch 14.556), train_loss = 3.31867661, grad/param norm = 7.4326e-01, time/batch = 0.3363s	
787/2700 (epoch 14.574), train_loss = 3.26436472, grad/param norm = 6.8001e-01, time/batch = 0.3766s	
788/2700 (epoch 14.593), train_loss = 3.27864440, grad/param norm = 8.2856e-01, time/batch = 0.4219s	
789/2700 (epoch 14.611), train_loss = 3.22037317, grad/param norm = 8.4889e-01, time/batch = 0.4421s	
790/2700 (epoch 14.630), train_loss = 3.25820285, grad/param norm = 8.2790e-01, time/batch = 0.4679s	
791/2700 (epoch 14.648), train_loss = 3.33599272, grad/param norm = 7.6254e-01, time/batch = 0.4149s	
792/2700 (epoch 14.667), train_loss = 3.26089497, grad/param norm = 7.0666e-01, time/batch = 0.4169s	
793/2700 (epoch 14.685), train_loss = 3.24865452, grad/param norm = 6.3978e-01, time/batch = 0.3982s	
794/2700 (epoch 14.704), train_loss = 3.22979942, grad/param norm = 7.2455e-01, time/batch = 0.4314s	
795/2700 (epoch 14.722), train_loss = 3.20924494, grad/param norm = 6.7407e-01, time/batch = 0.4410s	
796/2700 (epoch 14.741), train_loss = 3.35716007, grad/param norm = 6.9399e-01, time/batch = 0.4101s	
797/2700 (epoch 14.759), train_loss = 3.30293401, grad/param norm = 7.5267e-01, time/batch = 0.3363s	
798/2700 (epoch 14.778), train_loss = 3.31293809, grad/param norm = 8.8071e-01, time/batch = 0.3518s	
799/2700 (epoch 14.796), train_loss = 3.31614476, grad/param norm = 9.2886e-01, time/batch = 0.3598s	
800/2700 (epoch 14.815), train_loss = 3.25448190, grad/param norm = 8.7302e-01, time/batch = 0.4689s	
801/2700 (epoch 14.833), train_loss = 3.28267280, grad/param norm = 8.8058e-01, time/batch = 0.4562s	
802/2700 (epoch 14.852), train_loss = 3.27887643, grad/param norm = 9.1289e-01, time/batch = 0.4344s	
803/2700 (epoch 14.870), train_loss = 3.27397335, grad/param norm = 7.6657e-01, time/batch = 0.4208s	
804/2700 (epoch 14.889), train_loss = 3.29515394, grad/param norm = 7.6144e-01, time/batch = 0.4011s	
805/2700 (epoch 14.907), train_loss = 3.35772113, grad/param norm = 8.1420e-01, time/batch = 0.4256s	
806/2700 (epoch 14.926), train_loss = 3.30925383, grad/param norm = 7.8697e-01, time/batch = 0.4488s	
807/2700 (epoch 14.944), train_loss = 3.31295496, grad/param norm = 6.7668e-01, time/batch = 0.4196s	
808/2700 (epoch 14.963), train_loss = 3.37079330, grad/param norm = 5.7898e-01, time/batch = 0.3482s	
809/2700 (epoch 14.981), train_loss = 3.44426256, grad/param norm = 6.2191e-01, time/batch = 0.3038s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
810/2700 (epoch 15.000), train_loss = 3.34200426, grad/param norm = 6.1724e-01, time/batch = 0.4270s	
811/2700 (epoch 15.019), train_loss = 3.28077616, grad/param norm = 6.4835e-01, time/batch = 0.4329s	
812/2700 (epoch 15.037), train_loss = 3.29281857, grad/param norm = 6.4867e-01, time/batch = 0.4495s	
813/2700 (epoch 15.056), train_loss = 3.28616520, grad/param norm = 5.1107e-01, time/batch = 0.4347s	
814/2700 (epoch 15.074), train_loss = 3.32203087, grad/param norm = 5.6091e-01, time/batch = 0.4316s	
815/2700 (epoch 15.093), train_loss = 3.33124851, grad/param norm = 6.6874e-01, time/batch = 0.3915s	
816/2700 (epoch 15.111), train_loss = 3.30606734, grad/param norm = 6.6075e-01, time/batch = 0.4172s	
817/2700 (epoch 15.130), train_loss = 3.32412902, grad/param norm = 6.7794e-01, time/batch = 0.4388s	
818/2700 (epoch 15.148), train_loss = 3.28697045, grad/param norm = 8.1228e-01, time/batch = 0.4320s	
819/2700 (epoch 15.167), train_loss = 3.31756084, grad/param norm = 8.1532e-01, time/batch = 0.2937s	
820/2700 (epoch 15.185), train_loss = 3.27434443, grad/param norm = 6.3660e-01, time/batch = 0.3575s	
821/2700 (epoch 15.204), train_loss = 3.21868861, grad/param norm = 7.4444e-01, time/batch = 0.4034s	
822/2700 (epoch 15.222), train_loss = 3.20434666, grad/param norm = 8.7773e-01, time/batch = 0.4499s	
823/2700 (epoch 15.241), train_loss = 3.20669745, grad/param norm = 6.6745e-01, time/batch = 0.4553s	
824/2700 (epoch 15.259), train_loss = 3.24220611, grad/param norm = 6.3982e-01, time/batch = 0.3988s	
825/2700 (epoch 15.278), train_loss = 3.32447523, grad/param norm = 7.3048e-01, time/batch = 0.3987s	
826/2700 (epoch 15.296), train_loss = 3.33372870, grad/param norm = 8.6815e-01, time/batch = 0.4095s	
827/2700 (epoch 15.315), train_loss = 3.31049150, grad/param norm = 7.5899e-01, time/batch = 0.4386s	
828/2700 (epoch 15.333), train_loss = 3.37431584, grad/param norm = 6.7934e-01, time/batch = 0.4342s	
829/2700 (epoch 15.352), train_loss = 3.38262119, grad/param norm = 7.5452e-01, time/batch = 0.3425s	
830/2700 (epoch 15.370), train_loss = 3.33861491, grad/param norm = 9.0587e-01, time/batch = 0.3842s	
831/2700 (epoch 15.389), train_loss = 3.30616227, grad/param norm = 9.3098e-01, time/batch = 0.3720s	
832/2700 (epoch 15.407), train_loss = 3.32552557, grad/param norm = 8.8371e-01, time/batch = 0.3793s	
833/2700 (epoch 15.426), train_loss = 3.33097048, grad/param norm = 8.0749e-01, time/batch = 0.4651s	
834/2700 (epoch 15.444), train_loss = 3.26145733, grad/param norm = 8.2375e-01, time/batch = 0.4333s	
835/2700 (epoch 15.463), train_loss = 3.28887965, grad/param norm = 7.8973e-01, time/batch = 0.3810s	
836/2700 (epoch 15.481), train_loss = 3.37401114, grad/param norm = 7.6006e-01, time/batch = 0.4212s	
837/2700 (epoch 15.500), train_loss = 3.42408652, grad/param norm = 7.9726e-01, time/batch = 0.4398s	
838/2700 (epoch 15.519), train_loss = 3.37385547, grad/param norm = 8.2260e-01, time/batch = 0.4363s	
839/2700 (epoch 15.537), train_loss = 3.37437220, grad/param norm = 8.4510e-01, time/batch = 0.3608s	
840/2700 (epoch 15.556), train_loss = 3.31855379, grad/param norm = 7.6405e-01, time/batch = 0.3916s	
841/2700 (epoch 15.574), train_loss = 3.26317499, grad/param norm = 6.0977e-01, time/batch = 0.3750s	
842/2700 (epoch 15.593), train_loss = 3.26647499, grad/param norm = 6.6462e-01, time/batch = 0.4159s	
843/2700 (epoch 15.611), train_loss = 3.20323903, grad/param norm = 5.7811e-01, time/batch = 0.4515s	
844/2700 (epoch 15.630), train_loss = 3.24263273, grad/param norm = 6.0738e-01, time/batch = 0.4572s	
845/2700 (epoch 15.648), train_loss = 3.32719431, grad/param norm = 6.4871e-01, time/batch = 0.4244s	
846/2700 (epoch 15.667), train_loss = 3.25345817, grad/param norm = 6.0732e-01, time/batch = 0.3960s	
847/2700 (epoch 15.685), train_loss = 3.24560217, grad/param norm = 5.3038e-01, time/batch = 0.4023s	
848/2700 (epoch 15.704), train_loss = 3.21550509, grad/param norm = 5.6246e-01, time/batch = 0.4219s	
849/2700 (epoch 15.722), train_loss = 3.20010298, grad/param norm = 4.9807e-01, time/batch = 0.4009s	
850/2700 (epoch 15.741), train_loss = 3.34284304, grad/param norm = 5.9609e-01, time/batch = 0.4225s	
851/2700 (epoch 15.759), train_loss = 3.29781674, grad/param norm = 6.7959e-01, time/batch = 0.3779s	
852/2700 (epoch 15.778), train_loss = 3.30543744, grad/param norm = 8.0190e-01, time/batch = 0.3553s	
853/2700 (epoch 15.796), train_loss = 3.31114510, grad/param norm = 8.2597e-01, time/batch = 0.3988s	
854/2700 (epoch 15.815), train_loss = 3.22750422, grad/param norm = 6.6825e-01, time/batch = 0.4561s	
855/2700 (epoch 15.833), train_loss = 3.27337466, grad/param norm = 8.4568e-01, time/batch = 0.4660s	
856/2700 (epoch 15.852), train_loss = 3.27963917, grad/param norm = 9.1072e-01, time/batch = 0.4595s	
857/2700 (epoch 15.870), train_loss = 3.26601140, grad/param norm = 7.6150e-01, time/batch = 0.3929s	
858/2700 (epoch 15.889), train_loss = 3.29117668, grad/param norm = 8.1144e-01, time/batch = 0.3893s	
859/2700 (epoch 15.907), train_loss = 3.35154678, grad/param norm = 8.9962e-01, time/batch = 0.3751s	
860/2700 (epoch 15.926), train_loss = 3.31008886, grad/param norm = 8.7620e-01, time/batch = 0.4237s	
861/2700 (epoch 15.944), train_loss = 3.31797129, grad/param norm = 7.7130e-01, time/batch = 0.4326s	
862/2700 (epoch 15.963), train_loss = 3.38897026, grad/param norm = 6.6406e-01, time/batch = 0.4098s	
863/2700 (epoch 15.981), train_loss = 3.45154150, grad/param norm = 6.2365e-01, time/batch = 0.3586s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
864/2700 (epoch 16.000), train_loss = 3.33664786, grad/param norm = 5.9130e-01, time/batch = 0.3886s	
865/2700 (epoch 16.019), train_loss = 3.28128655, grad/param norm = 6.4792e-01, time/batch = 0.4504s	
866/2700 (epoch 16.037), train_loss = 3.28578631, grad/param norm = 6.3177e-01, time/batch = 0.4682s	
867/2700 (epoch 16.056), train_loss = 3.28085429, grad/param norm = 4.6190e-01, time/batch = 0.4640s	
868/2700 (epoch 16.074), train_loss = 3.31408418, grad/param norm = 4.9086e-01, time/batch = 0.4374s	
869/2700 (epoch 16.093), train_loss = 3.31824605, grad/param norm = 5.7915e-01, time/batch = 0.2998s	
870/2700 (epoch 16.111), train_loss = 3.30188672, grad/param norm = 6.6139e-01, time/batch = 0.4417s	
871/2700 (epoch 16.130), train_loss = 3.32408240, grad/param norm = 6.5841e-01, time/batch = 0.4511s	
872/2700 (epoch 16.148), train_loss = 3.28169640, grad/param norm = 7.7348e-01, time/batch = 0.4411s	
873/2700 (epoch 16.167), train_loss = 3.31223790, grad/param norm = 8.8607e-01, time/batch = 0.3939s	
874/2700 (epoch 16.185), train_loss = 3.28432627, grad/param norm = 8.0262e-01, time/batch = 0.3205s	
875/2700 (epoch 16.204), train_loss = 3.22354654, grad/param norm = 7.3465e-01, time/batch = 0.3795s	
876/2700 (epoch 16.222), train_loss = 3.18717486, grad/param norm = 7.1262e-01, time/batch = 0.4336s	
877/2700 (epoch 16.241), train_loss = 3.20553719, grad/param norm = 7.2882e-01, time/batch = 0.4625s	
878/2700 (epoch 16.259), train_loss = 3.24405866, grad/param norm = 8.3174e-01, time/batch = 0.4644s	
879/2700 (epoch 16.278), train_loss = 3.33619132, grad/param norm = 9.2296e-01, time/batch = 0.4131s	
880/2700 (epoch 16.296), train_loss = 3.35015163, grad/param norm = 9.7274e-01, time/batch = 0.4177s	
881/2700 (epoch 16.315), train_loss = 3.30670007, grad/param norm = 8.8383e-01, time/batch = 0.3565s	
882/2700 (epoch 16.333), train_loss = 3.38371877, grad/param norm = 6.7687e-01, time/batch = 0.4613s	
883/2700 (epoch 16.352), train_loss = 3.42730206, grad/param norm = 7.9332e-01, time/batch = 0.4479s	
884/2700 (epoch 16.370), train_loss = 3.37734647, grad/param norm = 7.9812e-01, time/batch = 0.3881s	
885/2700 (epoch 16.389), train_loss = 3.34330718, grad/param norm = 8.8719e-01, time/batch = 0.3372s	
886/2700 (epoch 16.407), train_loss = 3.34350072, grad/param norm = 8.2088e-01, time/batch = 0.3426s	
887/2700 (epoch 16.426), train_loss = 3.34791479, grad/param norm = 9.4158e-01, time/batch = 0.4331s	
888/2700 (epoch 16.444), train_loss = 3.27481241, grad/param norm = 8.6890e-01, time/batch = 0.4527s	
889/2700 (epoch 16.463), train_loss = 3.30304884, grad/param norm = 7.3919e-01, time/batch = 0.4379s	
890/2700 (epoch 16.481), train_loss = 3.35452852, grad/param norm = 5.3144e-01, time/batch = 0.4234s	
891/2700 (epoch 16.500), train_loss = 3.40662661, grad/param norm = 5.2937e-01, time/batch = 0.4193s	
892/2700 (epoch 16.519), train_loss = 3.35763081, grad/param norm = 5.5371e-01, time/batch = 0.3962s	
893/2700 (epoch 16.537), train_loss = 3.36660026, grad/param norm = 6.4158e-01, time/batch = 0.3993s	
894/2700 (epoch 16.556), train_loss = 3.30568540, grad/param norm = 5.9583e-01, time/batch = 0.4235s	
895/2700 (epoch 16.574), train_loss = 3.25473600, grad/param norm = 5.3869e-01, time/batch = 0.3368s	
896/2700 (epoch 16.593), train_loss = 3.26104126, grad/param norm = 6.1167e-01, time/batch = 0.3513s	
897/2700 (epoch 16.611), train_loss = 3.19990691, grad/param norm = 5.6416e-01, time/batch = 0.3846s	
898/2700 (epoch 16.630), train_loss = 3.23672439, grad/param norm = 5.4675e-01, time/batch = 0.4525s	
899/2700 (epoch 16.648), train_loss = 3.32392042, grad/param norm = 6.6114e-01, time/batch = 0.4478s	
900/2700 (epoch 16.667), train_loss = 3.25687294, grad/param norm = 6.8186e-01, time/batch = 0.4595s	
901/2700 (epoch 16.685), train_loss = 3.24859637, grad/param norm = 6.3677e-01, time/batch = 0.4036s	
902/2700 (epoch 16.704), train_loss = 3.21679182, grad/param norm = 6.9119e-01, time/batch = 0.3975s	
903/2700 (epoch 16.722), train_loss = 3.21026955, grad/param norm = 6.6957e-01, time/batch = 0.4090s	
904/2700 (epoch 16.741), train_loss = 3.34940369, grad/param norm = 8.0791e-01, time/batch = 0.4270s	
905/2700 (epoch 16.759), train_loss = 3.29947553, grad/param norm = 7.4723e-01, time/batch = 0.4216s	
906/2700 (epoch 16.778), train_loss = 3.27883806, grad/param norm = 6.1478e-01, time/batch = 0.3441s	
907/2700 (epoch 16.796), train_loss = 3.26704545, grad/param norm = 6.2849e-01, time/batch = 0.3439s	
908/2700 (epoch 16.815), train_loss = 3.24214405, grad/param norm = 6.3623e-01, time/batch = 0.3942s	
909/2700 (epoch 16.833), train_loss = 3.26186592, grad/param norm = 5.9573e-01, time/batch = 0.4364s	
910/2700 (epoch 16.852), train_loss = 3.25134099, grad/param norm = 5.3573e-01, time/batch = 0.4672s	
911/2700 (epoch 16.870), train_loss = 3.24005459, grad/param norm = 5.0694e-01, time/batch = 0.4665s	
912/2700 (epoch 16.889), train_loss = 3.29276512, grad/param norm = 6.0936e-01, time/batch = 0.4535s	
913/2700 (epoch 16.907), train_loss = 3.34042134, grad/param norm = 6.9030e-01, time/batch = 0.4233s	
914/2700 (epoch 16.926), train_loss = 3.29319811, grad/param norm = 7.8801e-01, time/batch = 0.3968s	
915/2700 (epoch 16.944), train_loss = 3.30742295, grad/param norm = 7.4687e-01, time/batch = 0.4095s	
916/2700 (epoch 16.963), train_loss = 3.38678193, grad/param norm = 7.6520e-01, time/batch = 0.4361s	
917/2700 (epoch 16.981), train_loss = 3.44714253, grad/param norm = 7.4915e-01, time/batch = 0.4186s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
918/2700 (epoch 17.000), train_loss = 3.33745481, grad/param norm = 7.0175e-01, time/batch = 0.3651s	
919/2700 (epoch 17.019), train_loss = 3.28035987, grad/param norm = 7.3858e-01, time/batch = 0.2726s	
920/2700 (epoch 17.037), train_loss = 3.29113903, grad/param norm = 7.0469e-01, time/batch = 0.4589s	
921/2700 (epoch 17.056), train_loss = 3.28423813, grad/param norm = 5.2555e-01, time/batch = 0.4488s	
922/2700 (epoch 17.074), train_loss = 3.31472218, grad/param norm = 5.1747e-01, time/batch = 0.4648s	
923/2700 (epoch 17.093), train_loss = 3.32859001, grad/param norm = 5.9074e-01, time/batch = 0.4486s	
924/2700 (epoch 17.111), train_loss = 3.30195136, grad/param norm = 5.8386e-01, time/batch = 0.4146s	
925/2700 (epoch 17.130), train_loss = 3.30758337, grad/param norm = 5.0695e-01, time/batch = 0.3970s	
926/2700 (epoch 17.148), train_loss = 3.26895770, grad/param norm = 5.9516e-01, time/batch = 0.4145s	
927/2700 (epoch 17.167), train_loss = 3.29466591, grad/param norm = 6.8330e-01, time/batch = 0.4416s	
928/2700 (epoch 17.185), train_loss = 3.28111509, grad/param norm = 6.6248e-01, time/batch = 0.4305s	
929/2700 (epoch 17.204), train_loss = 3.21348200, grad/param norm = 7.9161e-01, time/batch = 0.3048s	
930/2700 (epoch 17.222), train_loss = 3.19197166, grad/param norm = 8.1285e-01, time/batch = 0.3479s	
931/2700 (epoch 17.241), train_loss = 3.19217744, grad/param norm = 5.5302e-01, time/batch = 0.4164s	
932/2700 (epoch 17.259), train_loss = 3.23404937, grad/param norm = 5.4812e-01, time/batch = 0.4547s	
933/2700 (epoch 17.278), train_loss = 3.31320968, grad/param norm = 6.4906e-01, time/batch = 0.4667s	
934/2700 (epoch 17.296), train_loss = 3.31628208, grad/param norm = 6.3985e-01, time/batch = 0.4485s	
935/2700 (epoch 17.315), train_loss = 3.29629347, grad/param norm = 5.8751e-01, time/batch = 0.4186s	
936/2700 (epoch 17.333), train_loss = 3.36884626, grad/param norm = 5.4583e-01, time/batch = 0.3955s	
937/2700 (epoch 17.352), train_loss = 3.37533007, grad/param norm = 5.8768e-01, time/batch = 0.4159s	
938/2700 (epoch 17.370), train_loss = 3.33089253, grad/param norm = 7.1829e-01, time/batch = 0.4430s	
939/2700 (epoch 17.389), train_loss = 3.29291524, grad/param norm = 7.6041e-01, time/batch = 0.3957s	
940/2700 (epoch 17.407), train_loss = 3.31713006, grad/param norm = 7.5330e-01, time/batch = 0.4200s	
941/2700 (epoch 17.426), train_loss = 3.31011468, grad/param norm = 7.3769e-01, time/batch = 0.3847s	
942/2700 (epoch 17.444), train_loss = 3.23687364, grad/param norm = 7.7580e-01, time/batch = 0.2987s	
943/2700 (epoch 17.463), train_loss = 3.28399220, grad/param norm = 7.7010e-01, time/batch = 0.4018s	
944/2700 (epoch 17.481), train_loss = 3.35455103, grad/param norm = 7.2916e-01, time/batch = 0.4300s	
945/2700 (epoch 17.500), train_loss = 3.41598517, grad/param norm = 7.4754e-01, time/batch = 0.4470s	
946/2700 (epoch 17.519), train_loss = 3.36303504, grad/param norm = 7.3486e-01, time/batch = 0.4496s	
947/2700 (epoch 17.537), train_loss = 3.36997867, grad/param norm = 7.6132e-01, time/batch = 0.4080s	
948/2700 (epoch 17.556), train_loss = 3.31116316, grad/param norm = 6.5946e-01, time/batch = 0.3902s	
949/2700 (epoch 17.574), train_loss = 3.25425778, grad/param norm = 5.3058e-01, time/batch = 0.3880s	
950/2700 (epoch 17.593), train_loss = 3.26211739, grad/param norm = 6.2167e-01, time/batch = 0.4412s	
951/2700 (epoch 17.611), train_loss = 3.19874578, grad/param norm = 5.7478e-01, time/batch = 0.4551s	
952/2700 (epoch 17.630), train_loss = 3.23931871, grad/param norm = 5.8111e-01, time/batch = 0.4264s	
953/2700 (epoch 17.648), train_loss = 3.32629813, grad/param norm = 7.2235e-01, time/batch = 0.3567s	
954/2700 (epoch 17.667), train_loss = 3.26442320, grad/param norm = 7.4021e-01, time/batch = 0.2829s	
955/2700 (epoch 17.685), train_loss = 3.24846767, grad/param norm = 6.3827e-01, time/batch = 0.4309s	
956/2700 (epoch 17.704), train_loss = 3.21268265, grad/param norm = 6.3406e-01, time/batch = 0.4399s	
957/2700 (epoch 17.722), train_loss = 3.20162824, grad/param norm = 5.4526e-01, time/batch = 0.4482s	
958/2700 (epoch 17.741), train_loss = 3.33980356, grad/param norm = 6.2366e-01, time/batch = 0.3983s	
959/2700 (epoch 17.759), train_loss = 3.29317266, grad/param norm = 6.3814e-01, time/batch = 0.3342s	
960/2700 (epoch 17.778), train_loss = 3.28012033, grad/param norm = 6.1484e-01, time/batch = 0.4617s	
961/2700 (epoch 17.796), train_loss = 3.27087252, grad/param norm = 6.8302e-01, time/batch = 0.4619s	
962/2700 (epoch 17.815), train_loss = 3.24606737, grad/param norm = 6.8895e-01, time/batch = 0.4536s	
963/2700 (epoch 17.833), train_loss = 3.26435760, grad/param norm = 6.3085e-01, time/batch = 0.4129s	
964/2700 (epoch 17.852), train_loss = 3.25129466, grad/param norm = 5.5378e-01, time/batch = 0.3578s	
965/2700 (epoch 17.870), train_loss = 3.23790085, grad/param norm = 5.1387e-01, time/batch = 0.3149s	
966/2700 (epoch 17.889), train_loss = 3.29015456, grad/param norm = 5.9523e-01, time/batch = 0.3851s	
967/2700 (epoch 17.907), train_loss = 3.33715281, grad/param norm = 6.9737e-01, time/batch = 0.4040s	
968/2700 (epoch 17.926), train_loss = 3.29346264, grad/param norm = 8.1451e-01, time/batch = 0.4044s	
969/2700 (epoch 17.944), train_loss = 3.30836665, grad/param norm = 7.9795e-01, time/batch = 0.3958s	
970/2700 (epoch 17.963), train_loss = 3.38670335, grad/param norm = 8.0275e-01, time/batch = 0.4546s	
971/2700 (epoch 17.981), train_loss = 3.44422908, grad/param norm = 7.4360e-01, time/batch = 0.4630s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
972/2700 (epoch 18.000), train_loss = 3.33441027, grad/param norm = 6.8473e-01, time/batch = 0.4632s	
973/2700 (epoch 18.019), train_loss = 3.27741746, grad/param norm = 7.0736e-01, time/batch = 0.4443s	
974/2700 (epoch 18.037), train_loss = 3.28737919, grad/param norm = 6.7365e-01, time/batch = 0.3632s	
975/2700 (epoch 18.056), train_loss = 3.28246755, grad/param norm = 5.1062e-01, time/batch = 0.2874s	
976/2700 (epoch 18.074), train_loss = 3.31433426, grad/param norm = 5.1659e-01, time/batch = 0.4129s	
977/2700 (epoch 18.093), train_loss = 3.32731915, grad/param norm = 5.8708e-01, time/batch = 0.4517s	
978/2700 (epoch 18.111), train_loss = 3.29962129, grad/param norm = 5.7121e-01, time/batch = 0.4487s	
979/2700 (epoch 18.130), train_loss = 3.30502860, grad/param norm = 4.8689e-01, time/batch = 0.3613s	
980/2700 (epoch 18.148), train_loss = 3.26684075, grad/param norm = 5.7045e-01, time/batch = 0.4129s	
981/2700 (epoch 18.167), train_loss = 3.29116786, grad/param norm = 6.5341e-01, time/batch = 0.4230s	
982/2700 (epoch 18.185), train_loss = 3.27682711, grad/param norm = 6.1934e-01, time/batch = 0.4649s	
983/2700 (epoch 18.204), train_loss = 3.20969641, grad/param norm = 7.4201e-01, time/batch = 0.4542s	
984/2700 (epoch 18.222), train_loss = 3.18779349, grad/param norm = 7.7738e-01, time/batch = 0.4240s	
985/2700 (epoch 18.241), train_loss = 3.19107112, grad/param norm = 5.4195e-01, time/batch = 0.3633s	
986/2700 (epoch 18.259), train_loss = 3.23147589, grad/param norm = 5.2590e-01, time/batch = 0.3449s	
987/2700 (epoch 18.278), train_loss = 3.30842898, grad/param norm = 6.1000e-01, time/batch = 0.3688s	
988/2700 (epoch 18.296), train_loss = 3.31430569, grad/param norm = 6.1487e-01, time/batch = 0.4112s	
989/2700 (epoch 18.315), train_loss = 3.29415791, grad/param norm = 5.5874e-01, time/batch = 0.4298s	
990/2700 (epoch 18.333), train_loss = 3.36590186, grad/param norm = 5.0263e-01, time/batch = 0.4656s	
991/2700 (epoch 18.352), train_loss = 3.37114935, grad/param norm = 5.2693e-01, time/batch = 0.4025s	
992/2700 (epoch 18.370), train_loss = 3.32527807, grad/param norm = 6.1453e-01, time/batch = 0.4042s	
993/2700 (epoch 18.389), train_loss = 3.28497346, grad/param norm = 6.2203e-01, time/batch = 0.4416s	
994/2700 (epoch 18.407), train_loss = 3.31048704, grad/param norm = 6.5744e-01, time/batch = 0.4642s	
995/2700 (epoch 18.426), train_loss = 3.31042875, grad/param norm = 7.9080e-01, time/batch = 0.4461s	
996/2700 (epoch 18.444), train_loss = 3.24441948, grad/param norm = 8.9070e-01, time/batch = 0.4205s	
997/2700 (epoch 18.463), train_loss = 3.28722473, grad/param norm = 8.7500e-01, time/batch = 0.3043s	
998/2700 (epoch 18.481), train_loss = 3.35775280, grad/param norm = 7.9691e-01, time/batch = 0.3734s	
999/2700 (epoch 18.500), train_loss = 3.41559160, grad/param norm = 7.5517e-01, time/batch = 0.3951s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch18.52_3.2354.t7	
1000/2700 (epoch 18.519), train_loss = 3.36103034, grad/param norm = 7.2437e-01, time/batch = 0.4518s	
1001/2700 (epoch 18.537), train_loss = 3.36067372, grad/param norm = 7.1807e-01, time/batch = 0.3676s	
1002/2700 (epoch 18.556), train_loss = 3.31403764, grad/param norm = 6.9326e-01, time/batch = 0.3593s	
1003/2700 (epoch 18.574), train_loss = 3.25260736, grad/param norm = 5.5771e-01, time/batch = 0.4363s	
1004/2700 (epoch 18.593), train_loss = 3.26184773, grad/param norm = 6.0533e-01, time/batch = 0.4527s	
1005/2700 (epoch 18.611), train_loss = 3.18985490, grad/param norm = 5.1584e-01, time/batch = 0.4596s	
1006/2700 (epoch 18.630), train_loss = 3.23530632, grad/param norm = 4.9307e-01, time/batch = 0.4223s	
1007/2700 (epoch 18.648), train_loss = 3.30739174, grad/param norm = 5.4059e-01, time/batch = 0.3370s	
1008/2700 (epoch 18.667), train_loss = 3.25200699, grad/param norm = 6.1299e-01, time/batch = 0.3432s	
1009/2700 (epoch 18.685), train_loss = 3.24585577, grad/param norm = 6.2372e-01, time/batch = 0.3243s	
1010/2700 (epoch 18.704), train_loss = 3.21308004, grad/param norm = 6.0534e-01, time/batch = 0.4626s	
1011/2700 (epoch 18.722), train_loss = 3.19606147, grad/param norm = 4.9235e-01, time/batch = 0.4546s	
1012/2700 (epoch 18.741), train_loss = 3.33451418, grad/param norm = 5.6652e-01, time/batch = 0.4468s	
1013/2700 (epoch 18.759), train_loss = 3.29814461, grad/param norm = 6.6351e-01, time/batch = 0.3702s	
1014/2700 (epoch 18.778), train_loss = 3.28702579, grad/param norm = 6.7413e-01, time/batch = 0.4708s	
1015/2700 (epoch 18.796), train_loss = 3.27728033, grad/param norm = 6.8664e-01, time/batch = 0.4614s	
1016/2700 (epoch 18.815), train_loss = 3.23692247, grad/param norm = 6.0653e-01, time/batch = 0.4307s	
1017/2700 (epoch 18.833), train_loss = 3.25987383, grad/param norm = 5.9173e-01, time/batch = 0.3884s	
1018/2700 (epoch 18.852), train_loss = 3.25422636, grad/param norm = 5.8186e-01, time/batch = 0.3689s	
1019/2700 (epoch 18.870), train_loss = 3.24635985, grad/param norm = 5.7717e-01, time/batch = 0.3520s	
1020/2700 (epoch 18.889), train_loss = 3.29372846, grad/param norm = 6.6830e-01, time/batch = 0.3885s	
1021/2700 (epoch 18.907), train_loss = 3.34102246, grad/param norm = 7.7777e-01, time/batch = 0.4294s	
1022/2700 (epoch 18.926), train_loss = 3.29731509, grad/param norm = 8.6566e-01, time/batch = 0.4303s	
1023/2700 (epoch 18.944), train_loss = 3.29805068, grad/param norm = 7.5877e-01, time/batch = 0.4032s	
1024/2700 (epoch 18.963), train_loss = 3.37773100, grad/param norm = 7.3722e-01, time/batch = 0.3901s	
1025/2700 (epoch 18.981), train_loss = 3.43849959, grad/param norm = 6.8264e-01, time/batch = 0.4022s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1026/2700 (epoch 19.000), train_loss = 3.33165211, grad/param norm = 6.3677e-01, time/batch = 0.4439s	
1027/2700 (epoch 19.019), train_loss = 3.27196029, grad/param norm = 6.6887e-01, time/batch = 0.4078s	
1028/2700 (epoch 19.037), train_loss = 3.28504775, grad/param norm = 6.7176e-01, time/batch = 0.3394s	
1029/2700 (epoch 19.056), train_loss = 3.28337961, grad/param norm = 5.6732e-01, time/batch = 0.3258s	
1030/2700 (epoch 19.074), train_loss = 3.31464487, grad/param norm = 5.8244e-01, time/batch = 0.4219s	
1031/2700 (epoch 19.093), train_loss = 3.33376965, grad/param norm = 6.5335e-01, time/batch = 0.4096s	
1032/2700 (epoch 19.111), train_loss = 3.29853194, grad/param norm = 5.8164e-01, time/batch = 0.4600s	
1033/2700 (epoch 19.130), train_loss = 3.30691535, grad/param norm = 4.7756e-01, time/batch = 0.4188s	
1034/2700 (epoch 19.148), train_loss = 3.26355584, grad/param norm = 5.4222e-01, time/batch = 0.3892s	
1035/2700 (epoch 19.167), train_loss = 3.28638009, grad/param norm = 6.2596e-01, time/batch = 0.4257s	
1036/2700 (epoch 19.185), train_loss = 3.26974243, grad/param norm = 5.4045e-01, time/batch = 0.4613s	
1037/2700 (epoch 19.204), train_loss = 3.20331367, grad/param norm = 5.4709e-01, time/batch = 0.4515s	
1038/2700 (epoch 19.222), train_loss = 3.17350996, grad/param norm = 6.2731e-01, time/batch = 0.3963s	
1039/2700 (epoch 19.241), train_loss = 3.18864539, grad/param norm = 4.8770e-01, time/batch = 0.2804s	
1040/2700 (epoch 19.259), train_loss = 3.22900289, grad/param norm = 4.3821e-01, time/batch = 0.4184s	
1041/2700 (epoch 19.278), train_loss = 3.29996511, grad/param norm = 5.1771e-01, time/batch = 0.4246s	
1042/2700 (epoch 19.296), train_loss = 3.30982799, grad/param norm = 5.6581e-01, time/batch = 0.4073s	
1043/2700 (epoch 19.315), train_loss = 3.28688132, grad/param norm = 5.3283e-01, time/batch = 0.4560s	
1044/2700 (epoch 19.333), train_loss = 3.36236534, grad/param norm = 4.7275e-01, time/batch = 0.4321s	
1045/2700 (epoch 19.352), train_loss = 3.37206707, grad/param norm = 5.2413e-01, time/batch = 0.3931s	
1046/2700 (epoch 19.370), train_loss = 3.32309111, grad/param norm = 5.6446e-01, time/batch = 0.4034s	
1047/2700 (epoch 19.389), train_loss = 3.27875408, grad/param norm = 5.2936e-01, time/batch = 0.4366s	
1048/2700 (epoch 19.407), train_loss = 3.30727881, grad/param norm = 5.2367e-01, time/batch = 0.4623s	
1049/2700 (epoch 19.426), train_loss = 3.30147548, grad/param norm = 5.7964e-01, time/batch = 0.4019s	
1050/2700 (epoch 19.444), train_loss = 3.23966685, grad/param norm = 8.0941e-01, time/batch = 0.4091s	
1051/2700 (epoch 19.463), train_loss = 3.29588291, grad/param norm = 1.0969e+00, time/batch = 0.3376s	
1052/2700 (epoch 19.481), train_loss = 3.37831224, grad/param norm = 9.8455e-01, time/batch = 0.3962s	
1053/2700 (epoch 19.500), train_loss = 3.40688710, grad/param norm = 7.6181e-01, time/batch = 0.3934s	
1054/2700 (epoch 19.519), train_loss = 3.35914330, grad/param norm = 7.2805e-01, time/batch = 0.4497s	
1055/2700 (epoch 19.537), train_loss = 3.36009809, grad/param norm = 7.3809e-01, time/batch = 0.4461s	
1056/2700 (epoch 19.556), train_loss = 3.31735900, grad/param norm = 7.4768e-01, time/batch = 0.4073s	
1057/2700 (epoch 19.574), train_loss = 3.25241141, grad/param norm = 5.7309e-01, time/batch = 0.3977s	
1058/2700 (epoch 19.593), train_loss = 3.26330848, grad/param norm = 6.0066e-01, time/batch = 0.4248s	
1059/2700 (epoch 19.611), train_loss = 3.18867293, grad/param norm = 5.1133e-01, time/batch = 0.4259s	
1060/2700 (epoch 19.630), train_loss = 3.23450926, grad/param norm = 4.9244e-01, time/batch = 0.4621s	
1061/2700 (epoch 19.648), train_loss = 3.30680780, grad/param norm = 5.3692e-01, time/batch = 0.4365s	
1062/2700 (epoch 19.667), train_loss = 3.24786942, grad/param norm = 5.9118e-01, time/batch = 0.4019s	
1063/2700 (epoch 19.685), train_loss = 3.24344980, grad/param norm = 6.0210e-01, time/batch = 0.3625s	
1064/2700 (epoch 19.704), train_loss = 3.21063983, grad/param norm = 5.8504e-01, time/batch = 0.3757s	
1065/2700 (epoch 19.722), train_loss = 3.19446886, grad/param norm = 4.8712e-01, time/batch = 0.4051s	
1066/2700 (epoch 19.741), train_loss = 3.33303041, grad/param norm = 5.6835e-01, time/batch = 0.4376s	
1067/2700 (epoch 19.759), train_loss = 3.29540636, grad/param norm = 6.4543e-01, time/batch = 0.4215s	
1068/2700 (epoch 19.778), train_loss = 3.28330173, grad/param norm = 6.4611e-01, time/batch = 0.3926s	
1069/2700 (epoch 19.796), train_loss = 3.27310948, grad/param norm = 6.5895e-01, time/batch = 0.3602s	
1070/2700 (epoch 19.815), train_loss = 3.23435375, grad/param norm = 5.8873e-01, time/batch = 0.4465s	
1071/2700 (epoch 19.833), train_loss = 3.25701265, grad/param norm = 5.7513e-01, time/batch = 0.4523s	
1072/2700 (epoch 19.852), train_loss = 3.25128322, grad/param norm = 5.8609e-01, time/batch = 0.4576s	
1073/2700 (epoch 19.870), train_loss = 3.24421609, grad/param norm = 5.9924e-01, time/batch = 0.4457s	
1074/2700 (epoch 19.889), train_loss = 3.29299658, grad/param norm = 6.8765e-01, time/batch = 0.3930s	
1075/2700 (epoch 19.907), train_loss = 3.33803803, grad/param norm = 7.7362e-01, time/batch = 0.3196s	
1076/2700 (epoch 19.926), train_loss = 3.29360781, grad/param norm = 8.2845e-01, time/batch = 0.3944s	
1077/2700 (epoch 19.944), train_loss = 3.29357759, grad/param norm = 7.0217e-01, time/batch = 0.4393s	
1078/2700 (epoch 19.963), train_loss = 3.37397972, grad/param norm = 6.8270e-01, time/batch = 0.4430s	
1079/2700 (epoch 19.981), train_loss = 3.43595870, grad/param norm = 6.4819e-01, time/batch = 0.3777s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1080/2700 (epoch 20.000), train_loss = 3.32822986, grad/param norm = 6.0329e-01, time/batch = 0.3944s	
1081/2700 (epoch 20.019), train_loss = 3.27016844, grad/param norm = 6.3742e-01, time/batch = 0.4000s	
1082/2700 (epoch 20.037), train_loss = 3.28254888, grad/param norm = 6.4538e-01, time/batch = 0.4420s	
1083/2700 (epoch 20.056), train_loss = 3.28191629, grad/param norm = 5.5124e-01, time/batch = 0.4575s	
1084/2700 (epoch 20.074), train_loss = 3.31280562, grad/param norm = 5.7065e-01, time/batch = 0.4628s	
1085/2700 (epoch 20.093), train_loss = 3.33063825, grad/param norm = 6.3984e-01, time/batch = 0.4262s	
1086/2700 (epoch 20.111), train_loss = 3.29633989, grad/param norm = 5.6805e-01, time/batch = 0.3167s	
1087/2700 (epoch 20.130), train_loss = 3.30424018, grad/param norm = 4.7251e-01, time/batch = 0.4059s	
1088/2700 (epoch 20.148), train_loss = 3.26283626, grad/param norm = 5.3900e-01, time/batch = 0.4182s	
1089/2700 (epoch 20.167), train_loss = 3.28396585, grad/param norm = 6.1860e-01, time/batch = 0.3682s	
1090/2700 (epoch 20.185), train_loss = 3.26790314, grad/param norm = 5.2976e-01, time/batch = 0.4122s	
1091/2700 (epoch 20.204), train_loss = 3.20186737, grad/param norm = 5.3836e-01, time/batch = 0.3699s	
1092/2700 (epoch 20.222), train_loss = 3.17229250, grad/param norm = 6.1903e-01, time/batch = 0.4312s	
1093/2700 (epoch 20.241), train_loss = 3.18710317, grad/param norm = 4.7665e-01, time/batch = 0.4599s	
1094/2700 (epoch 20.259), train_loss = 3.22711702, grad/param norm = 4.2701e-01, time/batch = 0.4668s	
1095/2700 (epoch 20.278), train_loss = 3.29787428, grad/param norm = 5.0734e-01, time/batch = 0.4641s	
1096/2700 (epoch 20.296), train_loss = 3.30733499, grad/param norm = 5.5504e-01, time/batch = 0.4121s	
1097/2700 (epoch 20.315), train_loss = 3.28491823, grad/param norm = 5.2390e-01, time/batch = 0.3710s	
1098/2700 (epoch 20.333), train_loss = 3.36065087, grad/param norm = 4.6718e-01, time/batch = 0.3505s	
1099/2700 (epoch 20.352), train_loss = 3.37076305, grad/param norm = 5.1754e-01, time/batch = 0.3850s	
1100/2700 (epoch 20.370), train_loss = 3.32146230, grad/param norm = 5.8697e-01, time/batch = 0.3886s	
1101/2700 (epoch 20.389), train_loss = 3.28094860, grad/param norm = 6.1824e-01, time/batch = 0.3750s	
1102/2700 (epoch 20.407), train_loss = 3.31404224, grad/param norm = 7.0295e-01, time/batch = 0.3982s	
1103/2700 (epoch 20.426), train_loss = 3.31051257, grad/param norm = 8.4703e-01, time/batch = 0.4640s	
1104/2700 (epoch 20.444), train_loss = 3.24883645, grad/param norm = 9.1782e-01, time/batch = 0.4675s	
1105/2700 (epoch 20.463), train_loss = 3.28020378, grad/param norm = 7.8226e-01, time/batch = 0.4676s	
1106/2700 (epoch 20.481), train_loss = 3.35563890, grad/param norm = 7.2603e-01, time/batch = 0.4234s	
1107/2700 (epoch 20.500), train_loss = 3.40365058, grad/param norm = 7.1343e-01, time/batch = 0.3995s	
1108/2700 (epoch 20.519), train_loss = 3.35622209, grad/param norm = 6.9615e-01, time/batch = 0.3346s	
1109/2700 (epoch 20.537), train_loss = 3.35798323, grad/param norm = 7.2256e-01, time/batch = 0.3696s	
1110/2700 (epoch 20.556), train_loss = 3.31493803, grad/param norm = 7.3339e-01, time/batch = 0.3738s	
1111/2700 (epoch 20.574), train_loss = 3.25108266, grad/param norm = 5.6088e-01, time/batch = 0.4163s	
1112/2700 (epoch 20.593), train_loss = 3.26173901, grad/param norm = 5.8802e-01, time/batch = 0.3808s	
1113/2700 (epoch 20.611), train_loss = 3.18740026, grad/param norm = 4.9853e-01, time/batch = 0.4289s	
1114/2700 (epoch 20.630), train_loss = 3.23275043, grad/param norm = 4.7785e-01, time/batch = 0.4609s	
1115/2700 (epoch 20.648), train_loss = 3.30518945, grad/param norm = 5.2562e-01, time/batch = 0.4618s	
1116/2700 (epoch 20.667), train_loss = 3.24615613, grad/param norm = 5.8148e-01, time/batch = 0.4538s	
1117/2700 (epoch 20.685), train_loss = 3.24177981, grad/param norm = 5.9404e-01, time/batch = 0.4162s	
1118/2700 (epoch 20.704), train_loss = 3.20918132, grad/param norm = 5.7795e-01, time/batch = 0.3733s	
1119/2700 (epoch 20.722), train_loss = 3.19327177, grad/param norm = 4.8634e-01, time/batch = 0.3423s	
1120/2700 (epoch 20.741), train_loss = 3.33194991, grad/param norm = 5.8324e-01, time/batch = 0.4238s	
1121/2700 (epoch 20.759), train_loss = 3.29425209, grad/param norm = 6.5412e-01, time/batch = 0.4050s	
1122/2700 (epoch 20.778), train_loss = 3.28136158, grad/param norm = 6.4163e-01, time/batch = 0.4556s	
1123/2700 (epoch 20.796), train_loss = 3.27046674, grad/param norm = 6.4731e-01, time/batch = 0.3757s	
1124/2700 (epoch 20.815), train_loss = 3.23232700, grad/param norm = 5.7315e-01, time/batch = 0.4194s	
1125/2700 (epoch 20.833), train_loss = 3.25496796, grad/param norm = 5.5822e-01, time/batch = 0.4587s	
1126/2700 (epoch 20.852), train_loss = 3.24891460, grad/param norm = 5.6299e-01, time/batch = 0.4609s	
1127/2700 (epoch 20.870), train_loss = 3.24112195, grad/param norm = 5.6469e-01, time/batch = 0.4564s	
1128/2700 (epoch 20.889), train_loss = 3.28979194, grad/param norm = 6.4519e-01, time/batch = 0.4208s	
1129/2700 (epoch 20.907), train_loss = 3.33467991, grad/param norm = 7.2559e-01, time/batch = 0.2927s	
1130/2700 (epoch 20.926), train_loss = 3.28998689, grad/param norm = 7.9284e-01, time/batch = 0.4199s	
1131/2700 (epoch 20.944), train_loss = 3.29146495, grad/param norm = 6.9382e-01, time/batch = 0.4287s	
1132/2700 (epoch 20.963), train_loss = 3.37318212, grad/param norm = 6.8468e-01, time/batch = 0.4072s	
1133/2700 (epoch 20.981), train_loss = 3.43515993, grad/param norm = 6.5176e-01, time/batch = 0.4564s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1134/2700 (epoch 21.000), train_loss = 3.32701751, grad/param norm = 6.1172e-01, time/batch = 0.4226s	
1135/2700 (epoch 21.019), train_loss = 3.26992741, grad/param norm = 6.4706e-01, time/batch = 0.3612s	
1136/2700 (epoch 21.037), train_loss = 3.28160627, grad/param norm = 6.4689e-01, time/batch = 0.4430s	
1137/2700 (epoch 21.056), train_loss = 3.28070936, grad/param norm = 5.4415e-01, time/batch = 0.4551s	
1138/2700 (epoch 21.074), train_loss = 3.31143375, grad/param norm = 5.6125e-01, time/batch = 0.4590s	
1139/2700 (epoch 21.093), train_loss = 3.32828981, grad/param norm = 6.2828e-01, time/batch = 0.3709s	
1140/2700 (epoch 21.111), train_loss = 3.29456562, grad/param norm = 5.5713e-01, time/batch = 0.4125s	
1141/2700 (epoch 21.130), train_loss = 3.30238653, grad/param norm = 4.6508e-01, time/batch = 0.3951s	
1142/2700 (epoch 21.148), train_loss = 3.26190156, grad/param norm = 5.2992e-01, time/batch = 0.4142s	
1143/2700 (epoch 21.167), train_loss = 3.28208487, grad/param norm = 6.0809e-01, time/batch = 0.3867s	
1144/2700 (epoch 21.185), train_loss = 3.26655779, grad/param norm = 5.2350e-01, time/batch = 0.4331s	
1145/2700 (epoch 21.204), train_loss = 3.20049649, grad/param norm = 5.3042e-01, time/batch = 0.4284s	
1146/2700 (epoch 21.222), train_loss = 3.17120813, grad/param norm = 6.1151e-01, time/batch = 0.3850s	
1147/2700 (epoch 21.241), train_loss = 3.18572972, grad/param norm = 4.6715e-01, time/batch = 0.3836s	
1148/2700 (epoch 21.259), train_loss = 3.22576574, grad/param norm = 4.2082e-01, time/batch = 0.4455s	
1149/2700 (epoch 21.278), train_loss = 3.29674620, grad/param norm = 5.0854e-01, time/batch = 0.4384s	
1150/2700 (epoch 21.296), train_loss = 3.30604516, grad/param norm = 5.5925e-01, time/batch = 0.4537s	
1151/2700 (epoch 21.315), train_loss = 3.28393269, grad/param norm = 5.3099e-01, time/batch = 0.4218s	
1152/2700 (epoch 21.333), train_loss = 3.35978255, grad/param norm = 4.8421e-01, time/batch = 0.3668s	
1153/2700 (epoch 21.352), train_loss = 3.37067934, grad/param norm = 5.5656e-01, time/batch = 0.4080s	
1154/2700 (epoch 21.370), train_loss = 3.32392575, grad/param norm = 6.9003e-01, time/batch = 0.3786s	
1155/2700 (epoch 21.389), train_loss = 3.28748227, grad/param norm = 7.9236e-01, time/batch = 0.4248s	
1156/2700 (epoch 21.407), train_loss = 3.31942972, grad/param norm = 8.0252e-01, time/batch = 0.4100s	
1157/2700 (epoch 21.426), train_loss = 3.30458092, grad/param norm = 7.0143e-01, time/batch = 0.3766s	
1158/2700 (epoch 21.444), train_loss = 3.23395779, grad/param norm = 7.1045e-01, time/batch = 0.3948s	
1159/2700 (epoch 21.463), train_loss = 3.27398329, grad/param norm = 6.4215e-01, time/batch = 0.4052s	
1160/2700 (epoch 21.481), train_loss = 3.34936675, grad/param norm = 6.2181e-01, time/batch = 0.4496s	
1161/2700 (epoch 21.500), train_loss = 3.40064559, grad/param norm = 6.7242e-01, time/batch = 0.4273s	
1162/2700 (epoch 21.519), train_loss = 3.35535237, grad/param norm = 6.7754e-01, time/batch = 0.3950s	
1163/2700 (epoch 21.537), train_loss = 3.35626829, grad/param norm = 7.1026e-01, time/batch = 0.4073s	
1164/2700 (epoch 21.556), train_loss = 3.31063901, grad/param norm = 7.0170e-01, time/batch = 0.4515s	
1165/2700 (epoch 21.574), train_loss = 3.24907020, grad/param norm = 5.3516e-01, time/batch = 0.4257s	
1166/2700 (epoch 21.593), train_loss = 3.26114223, grad/param norm = 5.8498e-01, time/batch = 0.4006s	
1167/2700 (epoch 21.611), train_loss = 3.18754982, grad/param norm = 4.9204e-01, time/batch = 0.3576s	
1168/2700 (epoch 21.630), train_loss = 3.23154076, grad/param norm = 4.7181e-01, time/batch = 0.3297s	
1169/2700 (epoch 21.648), train_loss = 3.30435150, grad/param norm = 5.1803e-01, time/batch = 0.3975s	
1170/2700 (epoch 21.667), train_loss = 3.24363233, grad/param norm = 5.6854e-01, time/batch = 0.4572s	
1171/2700 (epoch 21.685), train_loss = 3.24043926, grad/param norm = 5.8203e-01, time/batch = 0.4446s	
1172/2700 (epoch 21.704), train_loss = 3.20787135, grad/param norm = 5.6851e-01, time/batch = 0.4271s	
1173/2700 (epoch 21.722), train_loss = 3.19240863, grad/param norm = 4.8768e-01, time/batch = 0.3941s	
1174/2700 (epoch 21.741), train_loss = 3.33183831, grad/param norm = 6.1016e-01, time/batch = 0.4152s	
1175/2700 (epoch 21.759), train_loss = 3.29409629, grad/param norm = 6.8073e-01, time/batch = 0.4522s	
1176/2700 (epoch 21.778), train_loss = 3.28045845, grad/param norm = 6.5245e-01, time/batch = 0.4499s	
1177/2700 (epoch 21.796), train_loss = 3.26861739, grad/param norm = 6.4584e-01, time/batch = 0.4171s	
1178/2700 (epoch 21.815), train_loss = 3.23056199, grad/param norm = 5.6048e-01, time/batch = 0.3556s	
1179/2700 (epoch 21.833), train_loss = 3.25298039, grad/param norm = 5.4185e-01, time/batch = 0.2526s	
1180/2700 (epoch 21.852), train_loss = 3.24653487, grad/param norm = 5.3895e-01, time/batch = 0.4362s	
1181/2700 (epoch 21.870), train_loss = 3.23814516, grad/param norm = 5.2814e-01, time/batch = 0.4362s	
1182/2700 (epoch 21.889), train_loss = 3.28656129, grad/param norm = 5.9732e-01, time/batch = 0.4552s	
1183/2700 (epoch 21.907), train_loss = 3.33111753, grad/param norm = 6.6303e-01, time/batch = 0.4498s	
1184/2700 (epoch 21.926), train_loss = 3.28576448, grad/param norm = 7.4083e-01, time/batch = 0.3644s	
1185/2700 (epoch 21.944), train_loss = 3.28905790, grad/param norm = 6.7633e-01, time/batch = 0.4179s	
1186/2700 (epoch 21.963), train_loss = 3.37242257, grad/param norm = 6.8595e-01, time/batch = 0.4432s	
1187/2700 (epoch 21.981), train_loss = 3.43440816, grad/param norm = 6.6005e-01, time/batch = 0.4553s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1188/2700 (epoch 22.000), train_loss = 3.32654603, grad/param norm = 6.2984e-01, time/batch = 0.4117s	
1189/2700 (epoch 22.019), train_loss = 3.27011915, grad/param norm = 6.6805e-01, time/batch = 0.3098s	
1190/2700 (epoch 22.037), train_loss = 3.28107224, grad/param norm = 6.5780e-01, time/batch = 0.3748s	
1191/2700 (epoch 22.056), train_loss = 3.27960320, grad/param norm = 5.4002e-01, time/batch = 0.3916s	
1192/2700 (epoch 22.074), train_loss = 3.31023712, grad/param norm = 5.5189e-01, time/batch = 0.4448s	
1193/2700 (epoch 22.093), train_loss = 3.32625696, grad/param norm = 6.1656e-01, time/batch = 0.4652s	
1194/2700 (epoch 22.111), train_loss = 3.29287736, grad/param norm = 5.4653e-01, time/batch = 0.4541s	
1195/2700 (epoch 22.130), train_loss = 3.30082688, grad/param norm = 4.5887e-01, time/batch = 0.4034s	
1196/2700 (epoch 22.148), train_loss = 3.26108619, grad/param norm = 5.2250e-01, time/batch = 0.3820s	
1197/2700 (epoch 22.167), train_loss = 3.28043403, grad/param norm = 5.9839e-01, time/batch = 0.4501s	
1198/2700 (epoch 22.185), train_loss = 3.26527902, grad/param norm = 5.1975e-01, time/batch = 0.4531s	
1199/2700 (epoch 22.204), train_loss = 3.19934762, grad/param norm = 5.2488e-01, time/batch = 0.3608s	
1200/2700 (epoch 22.222), train_loss = 3.17016619, grad/param norm = 6.0687e-01, time/batch = 0.3494s	
1201/2700 (epoch 22.241), train_loss = 3.18440842, grad/param norm = 4.6050e-01, time/batch = 0.3478s	
1202/2700 (epoch 22.259), train_loss = 3.22474554, grad/param norm = 4.1947e-01, time/batch = 0.4347s	
1203/2700 (epoch 22.278), train_loss = 3.29599260, grad/param norm = 5.1798e-01, time/batch = 0.4573s	
1204/2700 (epoch 22.296), train_loss = 3.30520555, grad/param norm = 5.6954e-01, time/batch = 0.4626s	
1205/2700 (epoch 22.315), train_loss = 3.28303410, grad/param norm = 5.4468e-01, time/batch = 0.4288s	
1206/2700 (epoch 22.333), train_loss = 3.35933925, grad/param norm = 5.0475e-01, time/batch = 0.4073s	
1207/2700 (epoch 22.352), train_loss = 3.37029828, grad/param norm = 5.8492e-01, time/batch = 0.4108s	
1208/2700 (epoch 22.370), train_loss = 3.32376670, grad/param norm = 7.1788e-01, time/batch = 0.4366s	
1209/2700 (epoch 22.389), train_loss = 3.28545079, grad/param norm = 7.6056e-01, time/batch = 0.3518s	
1210/2700 (epoch 22.407), train_loss = 3.31334983, grad/param norm = 7.2817e-01, time/batch = 0.3582s	
1211/2700 (epoch 22.426), train_loss = 3.30047979, grad/param norm = 6.1699e-01, time/batch = 0.3591s	
1212/2700 (epoch 22.444), train_loss = 3.22938148, grad/param norm = 6.4196e-01, time/batch = 0.4136s	
1213/2700 (epoch 22.463), train_loss = 3.27207136, grad/param norm = 6.1230e-01, time/batch = 0.4418s	
1214/2700 (epoch 22.481), train_loss = 3.34738163, grad/param norm = 5.9982e-01, time/batch = 0.4578s	
1215/2700 (epoch 22.500), train_loss = 3.39885906, grad/param norm = 6.6089e-01, time/batch = 0.4297s	
1216/2700 (epoch 22.519), train_loss = 3.35395133, grad/param norm = 6.6885e-01, time/batch = 0.3936s	
1217/2700 (epoch 22.537), train_loss = 3.35451092, grad/param norm = 6.9932e-01, time/batch = 0.3996s	
1218/2700 (epoch 22.556), train_loss = 3.30814751, grad/param norm = 6.8937e-01, time/batch = 0.4444s	
1219/2700 (epoch 22.574), train_loss = 3.24816988, grad/param norm = 5.2480e-01, time/batch = 0.4217s	
1220/2700 (epoch 22.593), train_loss = 3.25856924, grad/param norm = 5.6382e-01, time/batch = 0.4384s	
1221/2700 (epoch 22.611), train_loss = 3.18532360, grad/param norm = 4.7711e-01, time/batch = 0.3614s	
1222/2700 (epoch 22.630), train_loss = 3.23072049, grad/param norm = 4.6309e-01, time/batch = 0.3293s	
1223/2700 (epoch 22.648), train_loss = 3.30302706, grad/param norm = 5.0962e-01, time/batch = 0.3771s	
1224/2700 (epoch 22.667), train_loss = 3.24249114, grad/param norm = 5.5793e-01, time/batch = 0.4277s	
1225/2700 (epoch 22.685), train_loss = 3.23846011, grad/param norm = 5.7266e-01, time/batch = 0.4492s	
1226/2700 (epoch 22.704), train_loss = 3.20623042, grad/param norm = 5.6239e-01, time/batch = 0.4427s	
1227/2700 (epoch 22.722), train_loss = 3.19115716, grad/param norm = 4.8894e-01, time/batch = 0.3974s	
1228/2700 (epoch 22.741), train_loss = 3.33106184, grad/param norm = 6.2428e-01, time/batch = 0.3919s	
1229/2700 (epoch 22.759), train_loss = 3.29350044, grad/param norm = 6.8601e-01, time/batch = 0.4136s	
1230/2700 (epoch 22.778), train_loss = 3.27858141, grad/param norm = 6.4165e-01, time/batch = 0.4544s	
1231/2700 (epoch 22.796), train_loss = 3.26638363, grad/param norm = 6.2926e-01, time/batch = 0.4653s	
1232/2700 (epoch 22.815), train_loss = 3.22824489, grad/param norm = 5.4504e-01, time/batch = 0.4393s	
1233/2700 (epoch 22.833), train_loss = 3.25135961, grad/param norm = 5.2921e-01, time/batch = 0.3166s	
1234/2700 (epoch 22.852), train_loss = 3.24477893, grad/param norm = 5.2901e-01, time/batch = 0.3119s	
1235/2700 (epoch 22.870), train_loss = 3.23637079, grad/param norm = 5.2195e-01, time/batch = 0.2750s	
1236/2700 (epoch 22.889), train_loss = 3.28506110, grad/param norm = 5.9225e-01, time/batch = 0.4148s	
1237/2700 (epoch 22.907), train_loss = 3.32949983, grad/param norm = 6.5439e-01, time/batch = 0.3721s	
1238/2700 (epoch 22.926), train_loss = 3.28343777, grad/param norm = 7.2202e-01, time/batch = 0.4080s	
1239/2700 (epoch 22.944), train_loss = 3.28670576, grad/param norm = 6.4951e-01, time/batch = 0.4329s	
1240/2700 (epoch 22.963), train_loss = 3.37017735, grad/param norm = 6.5874e-01, time/batch = 0.4584s	
1241/2700 (epoch 22.981), train_loss = 3.43233563, grad/param norm = 6.3821e-01, time/batch = 0.4602s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1242/2700 (epoch 23.000), train_loss = 3.32427115, grad/param norm = 6.0781e-01, time/batch = 0.4688s	
1243/2700 (epoch 23.019), train_loss = 3.26842049, grad/param norm = 6.4641e-01, time/batch = 0.4258s	
1244/2700 (epoch 23.037), train_loss = 3.27939977, grad/param norm = 6.3794e-01, time/batch = 0.3806s	
1245/2700 (epoch 23.056), train_loss = 3.27832862, grad/param norm = 5.2638e-01, time/batch = 0.3851s	
1246/2700 (epoch 23.074), train_loss = 3.30888377, grad/param norm = 5.4168e-01, time/batch = 0.4143s	
1247/2700 (epoch 23.093), train_loss = 3.32424173, grad/param norm = 6.0470e-01, time/batch = 0.4251s	
1248/2700 (epoch 23.111), train_loss = 3.29124445, grad/param norm = 5.3466e-01, time/batch = 0.3312s	
1249/2700 (epoch 23.130), train_loss = 3.29954268, grad/param norm = 4.5320e-01, time/batch = 0.3709s	
1250/2700 (epoch 23.148), train_loss = 3.26053098, grad/param norm = 5.1763e-01, time/batch = 0.4649s	
1251/2700 (epoch 23.167), train_loss = 3.27911986, grad/param norm = 5.9056e-01, time/batch = 0.4588s	
1252/2700 (epoch 23.185), train_loss = 3.26386453, grad/param norm = 5.1031e-01, time/batch = 0.4588s	
1253/2700 (epoch 23.204), train_loss = 3.19799607, grad/param norm = 5.1655e-01, time/batch = 0.4583s	
1254/2700 (epoch 23.222), train_loss = 3.16926382, grad/param norm = 5.9937e-01, time/batch = 0.4171s	
1255/2700 (epoch 23.241), train_loss = 3.18332616, grad/param norm = 4.5245e-01, time/batch = 0.3739s	
1256/2700 (epoch 23.259), train_loss = 3.22353854, grad/param norm = 4.1511e-01, time/batch = 0.3966s	
1257/2700 (epoch 23.278), train_loss = 3.29499002, grad/param norm = 5.1961e-01, time/batch = 0.4194s	
1258/2700 (epoch 23.296), train_loss = 3.30401980, grad/param norm = 5.7043e-01, time/batch = 0.4229s	
1259/2700 (epoch 23.315), train_loss = 3.28178295, grad/param norm = 5.5110e-01, time/batch = 0.3279s	
1260/2700 (epoch 23.333), train_loss = 3.35880266, grad/param norm = 5.1695e-01, time/batch = 0.3802s	
1261/2700 (epoch 23.352), train_loss = 3.36949154, grad/param norm = 5.9588e-01, time/batch = 0.4324s	
1262/2700 (epoch 23.370), train_loss = 3.32275356, grad/param norm = 7.2104e-01, time/batch = 0.4625s	
1263/2700 (epoch 23.389), train_loss = 3.28318399, grad/param norm = 7.2866e-01, time/batch = 0.4591s	
1264/2700 (epoch 23.407), train_loss = 3.30941117, grad/param norm = 6.8039e-01, time/batch = 0.4470s	
1265/2700 (epoch 23.426), train_loss = 3.29797042, grad/param norm = 5.7133e-01, time/batch = 0.4035s	
1266/2700 (epoch 23.444), train_loss = 3.22687680, grad/param norm = 6.0303e-01, time/batch = 0.3882s	
1267/2700 (epoch 23.463), train_loss = 3.27039245, grad/param norm = 5.8802e-01, time/batch = 0.4236s	
1268/2700 (epoch 23.481), train_loss = 3.34571972, grad/param norm = 5.8018e-01, time/batch = 0.4180s	
1269/2700 (epoch 23.500), train_loss = 3.39719652, grad/param norm = 6.4864e-01, time/batch = 0.3757s	
1270/2700 (epoch 23.519), train_loss = 3.35262556, grad/param norm = 6.5804e-01, time/batch = 0.3926s	
1271/2700 (epoch 23.537), train_loss = 3.35278980, grad/param norm = 6.8698e-01, time/batch = 0.3573s	
1272/2700 (epoch 23.556), train_loss = 3.30577238, grad/param norm = 6.7638e-01, time/batch = 0.3770s	
1273/2700 (epoch 23.574), train_loss = 3.24727903, grad/param norm = 5.1491e-01, time/batch = 0.4687s	
1274/2700 (epoch 23.593), train_loss = 3.25711197, grad/param norm = 5.5396e-01, time/batch = 0.4377s	
1275/2700 (epoch 23.611), train_loss = 3.18423459, grad/param norm = 4.6602e-01, time/batch = 0.4167s	
1276/2700 (epoch 23.630), train_loss = 3.22963377, grad/param norm = 4.5512e-01, time/batch = 0.3874s	
1277/2700 (epoch 23.648), train_loss = 3.30209899, grad/param norm = 5.0335e-01, time/batch = 0.4005s	
1278/2700 (epoch 23.667), train_loss = 3.24092010, grad/param norm = 5.4865e-01, time/batch = 0.4223s	
1279/2700 (epoch 23.685), train_loss = 3.23695554, grad/param norm = 5.6212e-01, time/batch = 0.3793s	
1280/2700 (epoch 23.704), train_loss = 3.20485783, grad/param norm = 5.5308e-01, time/batch = 0.3965s	
1281/2700 (epoch 23.722), train_loss = 3.19002574, grad/param norm = 4.8228e-01, time/batch = 0.3589s	
1282/2700 (epoch 23.741), train_loss = 3.33004055, grad/param norm = 6.2266e-01, time/batch = 0.3756s	
1283/2700 (epoch 23.759), train_loss = 3.29218933, grad/param norm = 6.8181e-01, time/batch = 0.4203s	
1284/2700 (epoch 23.778), train_loss = 3.27703615, grad/param norm = 6.3032e-01, time/batch = 0.4497s	
1285/2700 (epoch 23.796), train_loss = 3.26450441, grad/param norm = 6.1431e-01, time/batch = 0.4098s	
1286/2700 (epoch 23.815), train_loss = 3.22623392, grad/param norm = 5.2926e-01, time/batch = 0.4031s	
1287/2700 (epoch 23.833), train_loss = 3.24978876, grad/param norm = 5.1509e-01, time/batch = 0.4191s	
1288/2700 (epoch 23.852), train_loss = 3.24297654, grad/param norm = 5.1672e-01, time/batch = 0.4317s	
1289/2700 (epoch 23.870), train_loss = 3.23454039, grad/param norm = 5.1088e-01, time/batch = 0.3996s	
1290/2700 (epoch 23.889), train_loss = 3.28333758, grad/param norm = 5.8089e-01, time/batch = 0.4338s	
1291/2700 (epoch 23.907), train_loss = 3.32778630, grad/param norm = 6.4141e-01, time/batch = 0.3632s	
1292/2700 (epoch 23.926), train_loss = 3.28129354, grad/param norm = 7.0423e-01, time/batch = 0.3550s	
1293/2700 (epoch 23.944), train_loss = 3.28462925, grad/param norm = 6.2936e-01, time/batch = 0.3942s	
1294/2700 (epoch 23.963), train_loss = 3.36826512, grad/param norm = 6.3842e-01, time/batch = 0.4592s	
1295/2700 (epoch 23.981), train_loss = 3.43038165, grad/param norm = 6.2156e-01, time/batch = 0.4679s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1296/2700 (epoch 24.000), train_loss = 3.32251418, grad/param norm = 5.9293e-01, time/batch = 0.4546s	
1297/2700 (epoch 24.019), train_loss = 3.26706174, grad/param norm = 6.3192e-01, time/batch = 0.3720s	
1298/2700 (epoch 24.037), train_loss = 3.27792975, grad/param norm = 6.2350e-01, time/batch = 0.4135s	
1299/2700 (epoch 24.056), train_loss = 3.27721074, grad/param norm = 5.1480e-01, time/batch = 0.4106s	
1300/2700 (epoch 24.074), train_loss = 3.30772881, grad/param norm = 5.3256e-01, time/batch = 0.4359s	
1301/2700 (epoch 24.093), train_loss = 3.32242037, grad/param norm = 5.9377e-01, time/batch = 0.4277s	
1302/2700 (epoch 24.111), train_loss = 3.28973843, grad/param norm = 5.2360e-01, time/batch = 0.3786s	
1303/2700 (epoch 24.130), train_loss = 3.29830513, grad/param norm = 4.4735e-01, time/batch = 0.3347s	
1304/2700 (epoch 24.148), train_loss = 3.25993980, grad/param norm = 5.1154e-01, time/batch = 0.3641s	
1305/2700 (epoch 24.167), train_loss = 3.27774849, grad/param norm = 5.8192e-01, time/batch = 0.4159s	
1306/2700 (epoch 24.185), train_loss = 3.26248875, grad/param norm = 5.0037e-01, time/batch = 0.4627s	
1307/2700 (epoch 24.204), train_loss = 3.19667016, grad/param norm = 5.0722e-01, time/batch = 0.4527s	
1308/2700 (epoch 24.222), train_loss = 3.16825781, grad/param norm = 5.9018e-01, time/batch = 0.4339s	
1309/2700 (epoch 24.241), train_loss = 3.18222759, grad/param norm = 4.4321e-01, time/batch = 0.3193s	
1310/2700 (epoch 24.259), train_loss = 3.22241147, grad/param norm = 4.0914e-01, time/batch = 0.4707s	
1311/2700 (epoch 24.278), train_loss = 3.29379722, grad/param norm = 5.1447e-01, time/batch = 0.4636s	
1312/2700 (epoch 24.296), train_loss = 3.30263841, grad/param norm = 5.6246e-01, time/batch = 0.4476s	
1313/2700 (epoch 24.315), train_loss = 3.28017825, grad/param norm = 5.4453e-01, time/batch = 0.3801s	
1314/2700 (epoch 24.333), train_loss = 3.35775412, grad/param norm = 5.1192e-01, time/batch = 0.3255s	
1315/2700 (epoch 24.352), train_loss = 3.36814393, grad/param norm = 5.8679e-01, time/batch = 0.3774s	
1316/2700 (epoch 24.370), train_loss = 3.32096202, grad/param norm = 7.0767e-01, time/batch = 0.4231s	
1317/2700 (epoch 24.389), train_loss = 3.28112927, grad/param norm = 7.0412e-01, time/batch = 0.4458s	
1318/2700 (epoch 24.407), train_loss = 3.30685211, grad/param norm = 6.5445e-01, time/batch = 0.4323s	
1319/2700 (epoch 24.426), train_loss = 3.29643065, grad/param norm = 5.5069e-01, time/batch = 0.3957s	
1320/2700 (epoch 24.444), train_loss = 3.22548566, grad/param norm = 5.8407e-01, time/batch = 0.4121s	
1321/2700 (epoch 24.463), train_loss = 3.26897952, grad/param norm = 5.7324e-01, time/batch = 0.3848s	
1322/2700 (epoch 24.481), train_loss = 3.34435797, grad/param norm = 5.6716e-01, time/batch = 0.4611s	
1323/2700 (epoch 24.500), train_loss = 3.39572396, grad/param norm = 6.3882e-01, time/batch = 0.4415s	
1324/2700 (epoch 24.519), train_loss = 3.35129831, grad/param norm = 6.4743e-01, time/batch = 0.3672s	
1325/2700 (epoch 24.537), train_loss = 3.35114365, grad/param norm = 6.7396e-01, time/batch = 0.3302s	
1326/2700 (epoch 24.556), train_loss = 3.30349510, grad/param norm = 6.6356e-01, time/batch = 0.3929s	
1327/2700 (epoch 24.574), train_loss = 3.24648770, grad/param norm = 5.0632e-01, time/batch = 0.4168s	
1328/2700 (epoch 24.593), train_loss = 3.25601879, grad/param norm = 5.4363e-01, time/batch = 0.4418s	
1329/2700 (epoch 24.611), train_loss = 3.18321545, grad/param norm = 4.5526e-01, time/batch = 0.3546s	
1330/2700 (epoch 24.630), train_loss = 3.22852933, grad/param norm = 4.4683e-01, time/batch = 0.4123s	
1331/2700 (epoch 24.648), train_loss = 3.30111449, grad/param norm = 4.9575e-01, time/batch = 0.4200s	
1332/2700 (epoch 24.667), train_loss = 3.23927491, grad/param norm = 5.3697e-01, time/batch = 0.4272s	
1333/2700 (epoch 24.685), train_loss = 3.23552456, grad/param norm = 5.5365e-01, time/batch = 0.4321s	
1334/2700 (epoch 24.704), train_loss = 3.20371344, grad/param norm = 5.4848e-01, time/batch = 0.4211s	
1335/2700 (epoch 24.722), train_loss = 3.18924535, grad/param norm = 4.8438e-01, time/batch = 0.3404s	
1336/2700 (epoch 24.741), train_loss = 3.32943402, grad/param norm = 6.3136e-01, time/batch = 0.3651s	
1337/2700 (epoch 24.759), train_loss = 3.29094389, grad/param norm = 6.7835e-01, time/batch = 0.4111s	
1338/2700 (epoch 24.778), train_loss = 3.27515747, grad/param norm = 6.1236e-01, time/batch = 0.4506s	
1339/2700 (epoch 24.796), train_loss = 3.26233835, grad/param norm = 5.9228e-01, time/batch = 0.4524s	
1340/2700 (epoch 24.815), train_loss = 3.22419647, grad/param norm = 5.1184e-01, time/batch = 0.4483s	
1341/2700 (epoch 24.833), train_loss = 3.24839694, grad/param norm = 5.0204e-01, time/batch = 0.4491s	
1342/2700 (epoch 24.852), train_loss = 3.24179562, grad/param norm = 5.1231e-01, time/batch = 0.4032s	
1343/2700 (epoch 24.870), train_loss = 3.23363390, grad/param norm = 5.1223e-01, time/batch = 0.4079s	
1344/2700 (epoch 24.889), train_loss = 3.28282761, grad/param norm = 5.8218e-01, time/batch = 0.4410s	
1345/2700 (epoch 24.907), train_loss = 3.32691880, grad/param norm = 6.4067e-01, time/batch = 0.4502s	
1346/2700 (epoch 24.926), train_loss = 3.28082404, grad/param norm = 7.1151e-01, time/batch = 0.3677s	
1347/2700 (epoch 24.944), train_loss = 3.28840272, grad/param norm = 6.5718e-01, time/batch = 0.2940s	
1348/2700 (epoch 24.963), train_loss = 3.36881679, grad/param norm = 6.5583e-01, time/batch = 0.3749s	
1349/2700 (epoch 24.981), train_loss = 3.43038774, grad/param norm = 6.0145e-01, time/batch = 0.4340s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1350/2700 (epoch 25.000), train_loss = 3.32042147, grad/param norm = 5.6553e-01, time/batch = 0.4691s	
1351/2700 (epoch 25.019), train_loss = 3.26491526, grad/param norm = 6.0279e-01, time/batch = 0.4459s	
1352/2700 (epoch 25.037), train_loss = 3.27467300, grad/param norm = 5.8060e-01, time/batch = 0.4418s	
1353/2700 (epoch 25.056), train_loss = 3.27606888, grad/param norm = 4.9382e-01, time/batch = 0.3964s	
1354/2700 (epoch 25.074), train_loss = 3.30817991, grad/param norm = 5.3050e-01, time/batch = 0.4010s	
1355/2700 (epoch 25.093), train_loss = 3.32120404, grad/param norm = 5.8678e-01, time/batch = 0.4508s	
1356/2700 (epoch 25.111), train_loss = 3.28906149, grad/param norm = 5.1646e-01, time/batch = 0.4406s	
1357/2700 (epoch 25.130), train_loss = 3.29885489, grad/param norm = 4.5700e-01, time/batch = 0.4059s	
1358/2700 (epoch 25.148), train_loss = 3.25996716, grad/param norm = 5.2384e-01, time/batch = 0.2881s	
1359/2700 (epoch 25.167), train_loss = 3.27682204, grad/param norm = 5.8072e-01, time/batch = 0.3493s	
1360/2700 (epoch 25.185), train_loss = 3.26118627, grad/param norm = 4.8389e-01, time/batch = 0.4616s	
1361/2700 (epoch 25.204), train_loss = 3.19556966, grad/param norm = 4.9412e-01, time/batch = 0.4534s	
1362/2700 (epoch 25.222), train_loss = 3.16692935, grad/param norm = 5.6385e-01, time/batch = 0.4469s	
1363/2700 (epoch 25.241), train_loss = 3.18117273, grad/param norm = 4.2046e-01, time/batch = 0.4265s	
1364/2700 (epoch 25.259), train_loss = 3.22111233, grad/param norm = 3.9262e-01, time/batch = 0.3820s	
1365/2700 (epoch 25.278), train_loss = 3.29132304, grad/param norm = 4.7456e-01, time/batch = 0.4148s	
1366/2700 (epoch 25.296), train_loss = 3.29973488, grad/param norm = 5.0939e-01, time/batch = 0.4423s	
1367/2700 (epoch 25.315), train_loss = 3.27691423, grad/param norm = 4.8168e-01, time/batch = 0.4200s	
1368/2700 (epoch 25.333), train_loss = 3.35483668, grad/param norm = 4.3717e-01, time/batch = 0.3596s	
1369/2700 (epoch 25.352), train_loss = 3.36452894, grad/param norm = 4.8958e-01, time/batch = 0.3047s	
1370/2700 (epoch 25.370), train_loss = 3.31477062, grad/param norm = 5.8238e-01, time/batch = 0.3915s	
1371/2700 (epoch 25.389), train_loss = 3.27551090, grad/param norm = 6.0399e-01, time/batch = 0.4409s	
1372/2700 (epoch 25.407), train_loss = 3.30488505, grad/param norm = 6.3870e-01, time/batch = 0.4563s	
1373/2700 (epoch 25.426), train_loss = 3.29861674, grad/param norm = 6.4059e-01, time/batch = 0.4107s	
1374/2700 (epoch 25.444), train_loss = 3.23072778, grad/param norm = 6.9602e-01, time/batch = 0.3926s	
1375/2700 (epoch 25.463), train_loss = 3.27084319, grad/param norm = 6.6282e-01, time/batch = 0.3946s	
1376/2700 (epoch 25.481), train_loss = 3.34653481, grad/param norm = 6.3042e-01, time/batch = 0.4332s	
1377/2700 (epoch 25.500), train_loss = 3.39554461, grad/param norm = 6.5579e-01, time/batch = 0.4261s	
1378/2700 (epoch 25.519), train_loss = 3.35029198, grad/param norm = 6.4155e-01, time/batch = 0.3970s	
1379/2700 (epoch 25.537), train_loss = 3.34945029, grad/param norm = 6.5782e-01, time/batch = 0.2916s	
1380/2700 (epoch 25.556), train_loss = 3.30218693, grad/param norm = 6.5741e-01, time/batch = 0.4114s	
1381/2700 (epoch 25.574), train_loss = 3.24623886, grad/param norm = 5.0473e-01, time/batch = 0.4313s	
1382/2700 (epoch 25.593), train_loss = 3.25489483, grad/param norm = 5.3690e-01, time/batch = 0.4499s	
1383/2700 (epoch 25.611), train_loss = 3.18234152, grad/param norm = 4.4521e-01, time/batch = 0.4246s	
1384/2700 (epoch 25.630), train_loss = 3.22759427, grad/param norm = 4.3835e-01, time/batch = 0.3838s	
1385/2700 (epoch 25.648), train_loss = 3.30033172, grad/param norm = 4.8828e-01, time/batch = 0.4253s	
1386/2700 (epoch 25.667), train_loss = 3.23790078, grad/param norm = 5.2706e-01, time/batch = 0.4320s	
1387/2700 (epoch 25.685), train_loss = 3.23388541, grad/param norm = 5.4082e-01, time/batch = 0.4284s	
1388/2700 (epoch 25.704), train_loss = 3.20230079, grad/param norm = 5.3201e-01, time/batch = 0.4106s	
1389/2700 (epoch 25.722), train_loss = 3.18769530, grad/param norm = 4.5597e-01, time/batch = 0.3095s	
1390/2700 (epoch 25.741), train_loss = 3.32696880, grad/param norm = 5.7642e-01, time/batch = 0.4082s	
1391/2700 (epoch 25.759), train_loss = 3.28747455, grad/param norm = 6.2935e-01, time/batch = 0.4282s	
1392/2700 (epoch 25.778), train_loss = 3.27315444, grad/param norm = 5.8258e-01, time/batch = 0.4622s	
1393/2700 (epoch 25.796), train_loss = 3.26062491, grad/param norm = 5.7025e-01, time/batch = 0.4672s	
1394/2700 (epoch 25.815), train_loss = 3.22226850, grad/param norm = 4.9411e-01, time/batch = 0.4561s	
1395/2700 (epoch 25.833), train_loss = 3.24701039, grad/param norm = 4.8856e-01, time/batch = 0.3519s	
1396/2700 (epoch 25.852), train_loss = 3.23995238, grad/param norm = 5.0287e-01, time/batch = 0.4277s	
1397/2700 (epoch 25.870), train_loss = 3.23196150, grad/param norm = 5.0537e-01, time/batch = 0.4259s	
1398/2700 (epoch 25.889), train_loss = 3.28087709, grad/param norm = 5.7546e-01, time/batch = 0.4166s	
1399/2700 (epoch 25.907), train_loss = 3.32515409, grad/param norm = 6.3475e-01, time/batch = 0.3030s	
1400/2700 (epoch 25.926), train_loss = 3.27792418, grad/param norm = 6.8078e-01, time/batch = 0.3983s	
1401/2700 (epoch 25.944), train_loss = 3.28095483, grad/param norm = 5.8779e-01, time/batch = 0.4147s	
1402/2700 (epoch 25.963), train_loss = 3.36401272, grad/param norm = 5.8773e-01, time/batch = 0.4615s	
1403/2700 (epoch 25.981), train_loss = 3.42611374, grad/param norm = 5.7615e-01, time/batch = 0.4653s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1404/2700 (epoch 26.000), train_loss = 3.31882166, grad/param norm = 5.4825e-01, time/batch = 0.4690s	
1405/2700 (epoch 26.019), train_loss = 3.26375609, grad/param norm = 5.8590e-01, time/batch = 0.4371s	
1406/2700 (epoch 26.037), train_loss = 3.27460176, grad/param norm = 5.8089e-01, time/batch = 0.3975s	
1407/2700 (epoch 26.056), train_loss = 3.27523394, grad/param norm = 4.8642e-01, time/batch = 0.3609s	
1408/2700 (epoch 26.074), train_loss = 3.30563683, grad/param norm = 5.1413e-01, time/batch = 0.4313s	
1409/2700 (epoch 26.093), train_loss = 3.31889478, grad/param norm = 5.7214e-01, time/batch = 0.3187s	
1410/2700 (epoch 26.111), train_loss = 3.28703039, grad/param norm = 5.0044e-01, time/batch = 0.3700s	
1411/2700 (epoch 26.130), train_loss = 3.29600708, grad/param norm = 4.3296e-01, time/batch = 0.4090s	
1412/2700 (epoch 26.148), train_loss = 3.25877596, grad/param norm = 4.9623e-01, time/batch = 0.4397s	
1413/2700 (epoch 26.167), train_loss = 3.27507563, grad/param norm = 5.6260e-01, time/batch = 0.4689s	
1414/2700 (epoch 26.185), train_loss = 3.25963341, grad/param norm = 4.7401e-01, time/batch = 0.4597s	
1415/2700 (epoch 26.204), train_loss = 3.19417527, grad/param norm = 4.8452e-01, time/batch = 0.4124s	
1416/2700 (epoch 26.222), train_loss = 3.16623592, grad/param norm = 5.6492e-01, time/batch = 0.4011s	
1417/2700 (epoch 26.241), train_loss = 3.18024374, grad/param norm = 4.2026e-01, time/batch = 0.4220s	
1418/2700 (epoch 26.259), train_loss = 3.22013502, grad/param norm = 3.8935e-01, time/batch = 0.4343s	
1419/2700 (epoch 26.278), train_loss = 3.29085166, grad/param norm = 4.7985e-01, time/batch = 0.3794s	
1420/2700 (epoch 26.296), train_loss = 3.29920064, grad/param norm = 5.2143e-01, time/batch = 0.3341s	
1421/2700 (epoch 26.315), train_loss = 3.27656306, grad/param norm = 5.0602e-01, time/batch = 0.3418s	
1422/2700 (epoch 26.333), train_loss = 3.35518367, grad/param norm = 4.8067e-01, time/batch = 0.4159s	
1423/2700 (epoch 26.352), train_loss = 3.36542052, grad/param norm = 5.6028e-01, time/batch = 0.4604s	
1424/2700 (epoch 26.370), train_loss = 3.31816990, grad/param norm = 6.9135e-01, time/batch = 0.4633s	
1425/2700 (epoch 26.389), train_loss = 3.27893986, grad/param norm = 7.0197e-01, time/batch = 0.4500s	
1426/2700 (epoch 26.407), train_loss = 3.30479405, grad/param norm = 6.5285e-01, time/batch = 0.4078s	
1427/2700 (epoch 26.426), train_loss = 3.29479568, grad/param norm = 5.3900e-01, time/batch = 0.3957s	
1428/2700 (epoch 26.444), train_loss = 3.22375605, grad/param norm = 5.6158e-01, time/batch = 0.4371s	
1429/2700 (epoch 26.463), train_loss = 3.26625565, grad/param norm = 5.4176e-01, time/batch = 0.3647s	
1430/2700 (epoch 26.481), train_loss = 3.34166103, grad/param norm = 5.3422e-01, time/batch = 0.4247s	
1431/2700 (epoch 26.500), train_loss = 3.39272639, grad/param norm = 6.0939e-01, time/batch = 0.3683s	
1432/2700 (epoch 26.519), train_loss = 3.34854037, grad/param norm = 6.1601e-01, time/batch = 0.3029s	
1433/2700 (epoch 26.537), train_loss = 3.34786117, grad/param norm = 6.4115e-01, time/batch = 0.4255s	
1434/2700 (epoch 26.556), train_loss = 3.29898985, grad/param norm = 6.3260e-01, time/batch = 0.4617s	
1435/2700 (epoch 26.574), train_loss = 3.24503304, grad/param norm = 4.8798e-01, time/batch = 0.4648s	
1436/2700 (epoch 26.593), train_loss = 3.25326935, grad/param norm = 5.2557e-01, time/batch = 0.4155s	
1437/2700 (epoch 26.611), train_loss = 3.18144672, grad/param norm = 4.3494e-01, time/batch = 0.3908s	
1438/2700 (epoch 26.630), train_loss = 3.22676275, grad/param norm = 4.3176e-01, time/batch = 0.4153s	
1439/2700 (epoch 26.648), train_loss = 3.29930913, grad/param norm = 4.8273e-01, time/batch = 0.4013s	
1440/2700 (epoch 26.667), train_loss = 3.23652602, grad/param norm = 5.1969e-01, time/batch = 0.3984s	
1441/2700 (epoch 26.685), train_loss = 3.23274022, grad/param norm = 5.3191e-01, time/batch = 0.4143s	
1442/2700 (epoch 26.704), train_loss = 3.20118227, grad/param norm = 5.2771e-01, time/batch = 0.3759s	
1443/2700 (epoch 26.722), train_loss = 3.18712197, grad/param norm = 4.6355e-01, time/batch = 0.3604s	
1444/2700 (epoch 26.741), train_loss = 3.32718264, grad/param norm = 6.0882e-01, time/batch = 0.3740s	
1445/2700 (epoch 26.759), train_loss = 3.28760054, grad/param norm = 6.5336e-01, time/batch = 0.4652s	
1446/2700 (epoch 26.778), train_loss = 3.27207207, grad/param norm = 5.8368e-01, time/batch = 0.4351s	
1447/2700 (epoch 26.796), train_loss = 3.25910794, grad/param norm = 5.6212e-01, time/batch = 0.3928s	
1448/2700 (epoch 26.815), train_loss = 3.22058535, grad/param norm = 4.8135e-01, time/batch = 0.4093s	
1449/2700 (epoch 26.833), train_loss = 3.24567466, grad/param norm = 4.7593e-01, time/batch = 0.4126s	
1450/2700 (epoch 26.852), train_loss = 3.23823185, grad/param norm = 4.8609e-01, time/batch = 0.4613s	
1451/2700 (epoch 26.870), train_loss = 3.22997587, grad/param norm = 4.8449e-01, time/batch = 0.4463s	
1452/2700 (epoch 26.889), train_loss = 3.27886879, grad/param norm = 5.5119e-01, time/batch = 0.3998s	
1453/2700 (epoch 26.907), train_loss = 3.32325643, grad/param norm = 6.0556e-01, time/batch = 0.3108s	
1454/2700 (epoch 26.926), train_loss = 3.27549389, grad/param norm = 6.5162e-01, time/batch = 0.3492s	
1455/2700 (epoch 26.944), train_loss = 3.27914949, grad/param norm = 5.6865e-01, time/batch = 0.4006s	
1456/2700 (epoch 26.963), train_loss = 3.36284372, grad/param norm = 5.7566e-01, time/batch = 0.4471s	
1457/2700 (epoch 26.981), train_loss = 3.42487293, grad/param norm = 5.6815e-01, time/batch = 0.4060s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1458/2700 (epoch 27.000), train_loss = 3.31757524, grad/param norm = 5.4368e-01, time/batch = 0.3984s	
1459/2700 (epoch 27.019), train_loss = 3.26293792, grad/param norm = 5.8308e-01, time/batch = 0.3952s	
1460/2700 (epoch 27.037), train_loss = 3.27368826, grad/param norm = 5.7594e-01, time/batch = 0.4632s	
1461/2700 (epoch 27.056), train_loss = 3.27427721, grad/param norm = 4.7966e-01, time/batch = 0.4537s	
1462/2700 (epoch 27.074), train_loss = 3.30465734, grad/param norm = 5.0660e-01, time/batch = 0.4451s	
1463/2700 (epoch 27.093), train_loss = 3.31741165, grad/param norm = 5.6204e-01, time/batch = 0.4042s	
1464/2700 (epoch 27.111), train_loss = 3.28572012, grad/param norm = 4.9171e-01, time/batch = 0.2857s	
1465/2700 (epoch 27.130), train_loss = 3.29498556, grad/param norm = 4.2969e-01, time/batch = 0.3653s	
1466/2700 (epoch 27.148), train_loss = 3.25830564, grad/param norm = 4.9155e-01, time/batch = 0.4375s	
1467/2700 (epoch 27.167), train_loss = 3.27387943, grad/param norm = 5.5524e-01, time/batch = 0.4640s	
1468/2700 (epoch 27.185), train_loss = 3.25864237, grad/param norm = 4.6885e-01, time/batch = 0.4565s	
1469/2700 (epoch 27.204), train_loss = 3.19321230, grad/param norm = 4.7971e-01, time/batch = 0.3223s	
1470/2700 (epoch 27.222), train_loss = 3.16547887, grad/param norm = 5.6124e-01, time/batch = 0.4499s	
1471/2700 (epoch 27.241), train_loss = 3.17931306, grad/param norm = 4.1600e-01, time/batch = 0.4591s	
1472/2700 (epoch 27.259), train_loss = 3.21939002, grad/param norm = 3.9206e-01, time/batch = 0.4510s	
1473/2700 (epoch 27.278), train_loss = 3.29052103, grad/param norm = 4.9641e-01, time/batch = 0.4187s	
1474/2700 (epoch 27.296), train_loss = 3.29877766, grad/param norm = 5.3578e-01, time/batch = 0.3307s	
1475/2700 (epoch 27.315), train_loss = 3.27584176, grad/param norm = 5.2397e-01, time/batch = 0.3119s	
1476/2700 (epoch 27.333), train_loss = 3.35494180, grad/param norm = 4.9720e-01, time/batch = 0.4332s	
1477/2700 (epoch 27.352), train_loss = 3.36446797, grad/param norm = 5.6221e-01, time/batch = 0.4584s	
1478/2700 (epoch 27.370), train_loss = 3.31627225, grad/param norm = 6.7307e-01, time/batch = 0.4634s	
1479/2700 (epoch 27.389), train_loss = 3.27583281, grad/param norm = 6.4125e-01, time/batch = 0.3958s	
1480/2700 (epoch 27.407), train_loss = 3.30046811, grad/param norm = 5.8690e-01, time/batch = 0.3971s	
1481/2700 (epoch 27.426), train_loss = 3.29250378, grad/param norm = 4.9585e-01, time/batch = 0.3743s	
1482/2700 (epoch 27.444), train_loss = 3.22188992, grad/param norm = 5.2991e-01, time/batch = 0.4599s	
1483/2700 (epoch 27.463), train_loss = 3.26503142, grad/param norm = 5.2656e-01, time/batch = 0.4347s	
1484/2700 (epoch 27.481), train_loss = 3.34066618, grad/param norm = 5.2586e-01, time/batch = 0.3460s	
1485/2700 (epoch 27.500), train_loss = 3.39157578, grad/param norm = 6.0680e-01, time/batch = 0.3241s	
1486/2700 (epoch 27.519), train_loss = 3.34759666, grad/param norm = 6.1298e-01, time/batch = 0.3975s	
1487/2700 (epoch 27.537), train_loss = 3.34656561, grad/param norm = 6.3379e-01, time/batch = 0.4345s	
1488/2700 (epoch 27.556), train_loss = 3.29723141, grad/param norm = 6.2363e-01, time/batch = 0.4640s	
1489/2700 (epoch 27.574), train_loss = 3.24440672, grad/param norm = 4.8058e-01, time/batch = 0.4115s	
1490/2700 (epoch 27.593), train_loss = 3.25210007, grad/param norm = 5.1803e-01, time/batch = 0.4138s	
1491/2700 (epoch 27.611), train_loss = 3.18068325, grad/param norm = 4.2571e-01, time/batch = 0.3862s	
1492/2700 (epoch 27.630), train_loss = 3.22597791, grad/param norm = 4.2579e-01, time/batch = 0.4272s	
1493/2700 (epoch 27.648), train_loss = 3.29844321, grad/param norm = 4.7779e-01, time/batch = 0.4451s	
1494/2700 (epoch 27.667), train_loss = 3.23518375, grad/param norm = 5.1138e-01, time/batch = 0.4164s	
1495/2700 (epoch 27.685), train_loss = 3.23153520, grad/param norm = 5.2241e-01, time/batch = 0.3437s	
1496/2700 (epoch 27.704), train_loss = 3.20003889, grad/param norm = 5.1991e-01, time/batch = 0.3494s	
1497/2700 (epoch 27.722), train_loss = 3.18625097, grad/param norm = 4.5723e-01, time/batch = 0.3961s	
1498/2700 (epoch 27.741), train_loss = 3.32634807, grad/param norm = 6.0559e-01, time/batch = 0.4462s	
1499/2700 (epoch 27.759), train_loss = 3.28638380, grad/param norm = 6.4787e-01, time/batch = 0.4299s	
1500/2700 (epoch 27.778), train_loss = 3.27072513, grad/param norm = 5.7330e-01, time/batch = 0.4266s	
1501/2700 (epoch 27.796), train_loss = 3.25766032, grad/param norm = 5.4951e-01, time/batch = 0.3984s	
1502/2700 (epoch 27.815), train_loss = 3.21894792, grad/param norm = 4.6784e-01, time/batch = 0.4135s	
1503/2700 (epoch 27.833), train_loss = 3.24447106, grad/param norm = 4.6498e-01, time/batch = 0.4572s	
1504/2700 (epoch 27.852), train_loss = 3.23674018, grad/param norm = 4.7518e-01, time/batch = 0.4604s	
1505/2700 (epoch 27.870), train_loss = 3.22840099, grad/param norm = 4.7289e-01, time/batch = 0.4500s	
1506/2700 (epoch 27.889), train_loss = 3.27738233, grad/param norm = 5.3865e-01, time/batch = 0.3554s	
1507/2700 (epoch 27.907), train_loss = 3.32182506, grad/param norm = 5.9146e-01, time/batch = 0.3611s	
1508/2700 (epoch 27.926), train_loss = 3.27367984, grad/param norm = 6.3440e-01, time/batch = 0.3965s	
1509/2700 (epoch 27.944), train_loss = 3.27758430, grad/param norm = 5.5290e-01, time/batch = 0.4254s	
1510/2700 (epoch 27.963), train_loss = 3.36146996, grad/param norm = 5.6092e-01, time/batch = 0.4600s	
1511/2700 (epoch 27.981), train_loss = 3.42336370, grad/param norm = 5.5540e-01, time/batch = 0.4105s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1512/2700 (epoch 28.000), train_loss = 3.31617600, grad/param norm = 5.3272e-01, time/batch = 0.3814s	
1513/2700 (epoch 28.019), train_loss = 3.26182737, grad/param norm = 5.7274e-01, time/batch = 0.4118s	
1514/2700 (epoch 28.037), train_loss = 3.27257979, grad/param norm = 5.6520e-01, time/batch = 0.4477s	
1515/2700 (epoch 28.056), train_loss = 3.27338666, grad/param norm = 4.7091e-01, time/batch = 0.4573s	
1516/2700 (epoch 28.074), train_loss = 3.30374120, grad/param norm = 4.9978e-01, time/batch = 0.4453s	
1517/2700 (epoch 28.093), train_loss = 3.31593892, grad/param norm = 5.5288e-01, time/batch = 0.3986s	
1518/2700 (epoch 28.111), train_loss = 3.28448592, grad/param norm = 4.8275e-01, time/batch = 0.3159s	
1519/2700 (epoch 28.130), train_loss = 3.29400333, grad/param norm = 4.2548e-01, time/batch = 0.3965s	
1520/2700 (epoch 28.148), train_loss = 3.25782531, grad/param norm = 4.8611e-01, time/batch = 0.4358s	
1521/2700 (epoch 28.167), train_loss = 3.27269328, grad/param norm = 5.4763e-01, time/batch = 0.4248s	
1522/2700 (epoch 28.185), train_loss = 3.25756444, grad/param norm = 4.6053e-01, time/batch = 0.3460s	
1523/2700 (epoch 28.204), train_loss = 3.19218162, grad/param norm = 4.7212e-01, time/batch = 0.4006s	
1524/2700 (epoch 28.222), train_loss = 3.16465568, grad/param norm = 5.5323e-01, time/batch = 0.4450s	
1525/2700 (epoch 28.241), train_loss = 3.17841095, grad/param norm = 4.0828e-01, time/batch = 0.4555s	
1526/2700 (epoch 28.259), train_loss = 3.21850537, grad/param norm = 3.8819e-01, time/batch = 0.4614s	
1527/2700 (epoch 28.278), train_loss = 3.28956439, grad/param norm = 4.9257e-01, time/batch = 0.4320s	
1528/2700 (epoch 28.296), train_loss = 3.29763647, grad/param norm = 5.2800e-01, time/batch = 0.3605s	
1529/2700 (epoch 28.315), train_loss = 3.27442146, grad/param norm = 5.1637e-01, time/batch = 0.3210s	
1530/2700 (epoch 28.333), train_loss = 3.35393719, grad/param norm = 4.8958e-01, time/batch = 0.4177s	
1531/2700 (epoch 28.352), train_loss = 3.36318167, grad/param norm = 5.5016e-01, time/batch = 0.4357s	
1532/2700 (epoch 28.370), train_loss = 3.31462156, grad/param norm = 6.5800e-01, time/batch = 0.3858s	
1533/2700 (epoch 28.389), train_loss = 3.27415681, grad/param norm = 6.2072e-01, time/batch = 0.3597s	
1534/2700 (epoch 28.407), train_loss = 3.29867893, grad/param norm = 5.6816e-01, time/batch = 0.4313s	
1535/2700 (epoch 28.426), train_loss = 3.29140900, grad/param norm = 4.8282e-01, time/batch = 0.4634s	
1536/2700 (epoch 28.444), train_loss = 3.22094544, grad/param norm = 5.1687e-01, time/batch = 0.4677s	
1537/2700 (epoch 28.463), train_loss = 3.26390215, grad/param norm = 5.1513e-01, time/batch = 0.4505s	
1538/2700 (epoch 28.481), train_loss = 3.33965951, grad/param norm = 5.1619e-01, time/batch = 0.3977s	
1539/2700 (epoch 28.500), train_loss = 3.39036894, grad/param norm = 5.9937e-01, time/batch = 0.3571s	
1540/2700 (epoch 28.519), train_loss = 3.34644806, grad/param norm = 6.0378e-01, time/batch = 0.4466s	
1541/2700 (epoch 28.537), train_loss = 3.34522905, grad/param norm = 6.2228e-01, time/batch = 0.4443s	
1542/2700 (epoch 28.556), train_loss = 3.29536953, grad/param norm = 6.1255e-01, time/batch = 0.4325s	
1543/2700 (epoch 28.574), train_loss = 3.24380871, grad/param norm = 4.7391e-01, time/batch = 0.3703s	
1544/2700 (epoch 28.593), train_loss = 3.25098335, grad/param norm = 5.1069e-01, time/batch = 0.3285s	
1545/2700 (epoch 28.611), train_loss = 3.17994374, grad/param norm = 4.1702e-01, time/batch = 0.3862s	
1546/2700 (epoch 28.630), train_loss = 3.22519128, grad/param norm = 4.1984e-01, time/batch = 0.4406s	
1547/2700 (epoch 28.648), train_loss = 3.29755401, grad/param norm = 4.7246e-01, time/batch = 0.4633s	
1548/2700 (epoch 28.667), train_loss = 3.23391346, grad/param norm = 5.0355e-01, time/batch = 0.4519s	
1549/2700 (epoch 28.685), train_loss = 3.23041490, grad/param norm = 5.1437e-01, time/batch = 0.3583s	
1550/2700 (epoch 28.704), train_loss = 3.19899530, grad/param norm = 5.1366e-01, time/batch = 0.4158s	
1551/2700 (epoch 28.722), train_loss = 3.18546162, grad/param norm = 4.5248e-01, time/batch = 0.4124s	
1552/2700 (epoch 28.741), train_loss = 3.32551150, grad/param norm = 6.0164e-01, time/batch = 0.4300s	
1553/2700 (epoch 28.759), train_loss = 3.28500482, grad/param norm = 6.3915e-01, time/batch = 0.4395s	
1554/2700 (epoch 28.778), train_loss = 3.26928730, grad/param norm = 5.6010e-01, time/batch = 0.3833s	
1555/2700 (epoch 28.796), train_loss = 3.25618876, grad/param norm = 5.3511e-01, time/batch = 0.2902s	
1556/2700 (epoch 28.815), train_loss = 3.21735240, grad/param norm = 4.5444e-01, time/batch = 0.4391s	
1557/2700 (epoch 28.833), train_loss = 3.24337024, grad/param norm = 4.5537e-01, time/batch = 0.4599s	
1558/2700 (epoch 28.852), train_loss = 3.23542106, grad/param norm = 4.6692e-01, time/batch = 0.4638s	
1559/2700 (epoch 28.870), train_loss = 3.22706033, grad/param norm = 4.6446e-01, time/batch = 0.3856s	
1560/2700 (epoch 28.889), train_loss = 3.27607590, grad/param norm = 5.2871e-01, time/batch = 0.3933s	
1561/2700 (epoch 28.907), train_loss = 3.32051789, grad/param norm = 5.7897e-01, time/batch = 0.3735s	
1562/2700 (epoch 28.926), train_loss = 3.27194679, grad/param norm = 6.1732e-01, time/batch = 0.4020s	
1563/2700 (epoch 28.944), train_loss = 3.27606473, grad/param norm = 5.3613e-01, time/batch = 0.4169s	
1564/2700 (epoch 28.963), train_loss = 3.36006344, grad/param norm = 5.4474e-01, time/batch = 0.3955s	
1565/2700 (epoch 28.981), train_loss = 3.42185709, grad/param norm = 5.4136e-01, time/batch = 0.3589s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
1566/2700 (epoch 29.000), train_loss = 3.31478298, grad/param norm = 5.2015e-01, time/batch = 0.3872s	
1567/2700 (epoch 29.019), train_loss = 3.26063463, grad/param norm = 5.6012e-01, time/batch = 0.4143s	
1568/2700 (epoch 29.037), train_loss = 3.27142012, grad/param norm = 5.5253e-01, time/batch = 0.4552s	
1569/2700 (epoch 29.056), train_loss = 3.27253018, grad/param norm = 4.6168e-01, time/batch = 0.3781s	
1570/2700 (epoch 29.074), train_loss = 3.30285701, grad/param norm = 4.9324e-01, time/batch = 0.4147s	
1571/2700 (epoch 29.093), train_loss = 3.31450187, grad/param norm = 5.4413e-01, time/batch = 0.4062s	
1572/2700 (epoch 29.111), train_loss = 3.28332108, grad/param norm = 4.7407e-01, time/batch = 0.4421s	
1573/2700 (epoch 29.130), train_loss = 3.29307230, grad/param norm = 4.2139e-01, time/batch = 0.4304s	
1574/2700 (epoch 29.148), train_loss = 3.25736887, grad/param norm = 4.8079e-01, time/batch = 0.3879s	
1575/2700 (epoch 29.167), train_loss = 3.27155171, grad/param norm = 5.4030e-01, time/batch = 0.3297s	
1576/2700 (epoch 29.185), train_loss = 3.25650944, grad/param norm = 4.5175e-01, time/batch = 0.3622s	
1577/2700 (epoch 29.204), train_loss = 3.19118907, grad/param norm = 4.6428e-01, time/batch = 0.4279s	
1578/2700 (epoch 29.222), train_loss = 3.16385712, grad/param norm = 5.4468e-01, time/batch = 0.4588s	
1579/2700 (epoch 29.241), train_loss = 3.17756425, grad/param norm = 4.0025e-01, time/batch = 0.4367s	
1580/2700 (epoch 29.259), train_loss = 3.21763861, grad/param norm = 3.8346e-01, time/batch = 0.3917s	
1581/2700 (epoch 29.278), train_loss = 3.28857364, grad/param norm = 4.8589e-01, time/batch = 0.3999s	
1582/2700 (epoch 29.296), train_loss = 3.29646784, grad/param norm = 5.1804e-01, time/batch = 0.4353s	
1583/2700 (epoch 29.315), train_loss = 3.27305152, grad/param norm = 5.0779e-01, time/batch = 0.4411s	
1584/2700 (epoch 29.333), train_loss = 3.35299826, grad/param norm = 4.8266e-01, time/batch = 0.4205s	
1585/2700 (epoch 29.352), train_loss = 3.36202670, grad/param norm = 5.4120e-01, time/batch = 0.3086s	
1586/2700 (epoch 29.370), train_loss = 3.31322948, grad/param norm = 6.4761e-01, time/batch = 0.3544s	
1587/2700 (epoch 29.389), train_loss = 3.27274215, grad/param norm = 6.0605e-01, time/batch = 0.4226s	
1588/2700 (epoch 29.407), train_loss = 3.29718899, grad/param norm = 5.5425e-01, time/batch = 0.4501s	
1589/2700 (epoch 29.426), train_loss = 3.29045347, grad/param norm = 4.7202e-01, time/batch = 0.4338s	
1590/2700 (epoch 29.444), train_loss = 3.22007343, grad/param norm = 5.0453e-01, time/batch = 0.4500s	
1591/2700 (epoch 29.463), train_loss = 3.26279472, grad/param norm = 5.0277e-01, time/batch = 0.4260s	
1592/2700 (epoch 29.481), train_loss = 3.33865739, grad/param norm = 5.0520e-01, time/batch = 0.3515s	
1593/2700 (epoch 29.500), train_loss = 3.38915884, grad/param norm = 5.9053e-01, time/batch = 0.4535s	
1594/2700 (epoch 29.519), train_loss = 3.34529173, grad/param norm = 5.9326e-01, time/batch = 0.4281s	
1595/2700 (epoch 29.537), train_loss = 3.34393311, grad/param norm = 6.1036e-01, time/batch = 0.3625s	
1596/2700 (epoch 29.556), train_loss = 3.29357963, grad/param norm = 6.0154e-01, time/batch = 0.2846s	
1597/2700 (epoch 29.574), train_loss = 3.24323716, grad/param norm = 4.6757e-01, time/batch = 0.4006s	
1598/2700 (epoch 29.593), train_loss = 3.24990870, grad/param norm = 5.0358e-01, time/batch = 0.4553s	
1599/2700 (epoch 29.611), train_loss = 3.17925203, grad/param norm = 4.0876e-01, time/batch = 0.4332s	
1600/2700 (epoch 29.630), train_loss = 3.22444928, grad/param norm = 4.1425e-01, time/batch = 0.4440s	
1601/2700 (epoch 29.648), train_loss = 3.29668119, grad/param norm = 4.6726e-01, time/batch = 0.4192s	
1602/2700 (epoch 29.667), train_loss = 3.23270485, grad/param norm = 4.9602e-01, time/batch = 0.3872s	
1603/2700 (epoch 29.685), train_loss = 3.22935702, grad/param norm = 5.0689e-01, time/batch = 0.4291s	
1604/2700 (epoch 29.704), train_loss = 3.19802320, grad/param norm = 5.0818e-01, time/batch = 0.4432s	
1605/2700 (epoch 29.722), train_loss = 3.18473527, grad/param norm = 4.4853e-01, time/batch = 0.4021s	
1606/2700 (epoch 29.741), train_loss = 3.32473114, grad/param norm = 5.9835e-01, time/batch = 0.2868s	
1607/2700 (epoch 29.759), train_loss = 3.28366420, grad/param norm = 6.3049e-01, time/batch = 0.3548s	
1608/2700 (epoch 29.778), train_loss = 3.26789258, grad/param norm = 5.4699e-01, time/batch = 0.4427s	
1609/2700 (epoch 29.796), train_loss = 3.25479301, grad/param norm = 5.2110e-01, time/batch = 0.4364s	
1610/2700 (epoch 29.815), train_loss = 3.21584419, grad/param norm = 4.4171e-01, time/batch = 0.4645s	
1611/2700 (epoch 29.833), train_loss = 3.24234903, grad/param norm = 4.4666e-01, time/batch = 0.4331s	
1612/2700 (epoch 29.852), train_loss = 3.23418055, grad/param norm = 4.5921e-01, time/batch = 0.3976s	
1613/2700 (epoch 29.870), train_loss = 3.22580142, grad/param norm = 4.5627e-01, time/batch = 0.4058s	
1614/2700 (epoch 29.889), train_loss = 3.27482982, grad/param norm = 5.1876e-01, time/batch = 0.4556s	
1615/2700 (epoch 29.907), train_loss = 3.31926142, grad/param norm = 5.6620e-01, time/batch = 0.4418s	
1616/2700 (epoch 29.926), train_loss = 3.27027277, grad/param norm = 6.0003e-01, time/batch = 0.3382s	
1617/2700 (epoch 29.944), train_loss = 3.27463040, grad/param norm = 5.1973e-01, time/batch = 0.2858s	
1618/2700 (epoch 29.963), train_loss = 3.35873065, grad/param norm = 5.2923e-01, time/batch = 0.4294s	
1619/2700 (epoch 29.981), train_loss = 3.42044254, grad/param norm = 5.2785e-01, time/batch = 0.4332s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
1620/2700 (epoch 30.000), train_loss = 3.31346004, grad/param norm = 5.0804e-01, time/batch = 0.4602s	
1621/2700 (epoch 30.019), train_loss = 3.25946768, grad/param norm = 5.4773e-01, time/batch = 0.4287s	
1622/2700 (epoch 30.037), train_loss = 3.27029767, grad/param norm = 5.3989e-01, time/batch = 0.3938s	
1623/2700 (epoch 30.056), train_loss = 3.27171675, grad/param norm = 4.5273e-01, time/batch = 0.4185s	
1624/2700 (epoch 30.074), train_loss = 3.30201225, grad/param norm = 4.8709e-01, time/batch = 0.4576s	
1625/2700 (epoch 30.093), train_loss = 3.31311460, grad/param norm = 5.3572e-01, time/batch = 0.4619s	
1626/2700 (epoch 30.111), train_loss = 3.28221558, grad/param norm = 4.6572e-01, time/batch = 0.4370s	
1627/2700 (epoch 30.130), train_loss = 3.29218603, grad/param norm = 4.1747e-01, time/batch = 0.3070s	
1628/2700 (epoch 30.148), train_loss = 3.25692963, grad/param norm = 4.7548e-01, time/batch = 0.3572s	
1629/2700 (epoch 30.167), train_loss = 3.27045103, grad/param norm = 5.3316e-01, time/batch = 0.3823s	
1630/2700 (epoch 30.185), train_loss = 3.25549876, grad/param norm = 4.4294e-01, time/batch = 0.4479s	
1631/2700 (epoch 30.204), train_loss = 3.19024311, grad/param norm = 4.5646e-01, time/batch = 0.4070s	
1632/2700 (epoch 30.222), train_loss = 3.16308058, grad/param norm = 5.3578e-01, time/batch = 0.3843s	
1633/2700 (epoch 30.241), train_loss = 3.17676146, grad/param norm = 3.9197e-01, time/batch = 0.4350s	
1634/2700 (epoch 30.259), train_loss = 3.21679076, grad/param norm = 3.7802e-01, time/batch = 0.4602s	
1635/2700 (epoch 30.278), train_loss = 3.28754953, grad/param norm = 4.7634e-01, time/batch = 0.4525s	
1636/2700 (epoch 30.296), train_loss = 3.29526134, grad/param norm = 5.0550e-01, time/batch = 0.4072s	
1637/2700 (epoch 30.315), train_loss = 3.27170133, grad/param norm = 4.9723e-01, time/batch = 0.3250s	
1638/2700 (epoch 30.333), train_loss = 3.35208069, grad/param norm = 4.7503e-01, time/batch = 0.3098s	
1639/2700 (epoch 30.352), train_loss = 3.36096220, grad/param norm = 5.3378e-01, time/batch = 0.4135s	
1640/2700 (epoch 30.370), train_loss = 3.31202419, grad/param norm = 6.4041e-01, time/batch = 0.4638s	
1641/2700 (epoch 30.389), train_loss = 3.27154627, grad/param norm = 5.9650e-01, time/batch = 0.4471s	
1642/2700 (epoch 30.407), train_loss = 3.29597481, grad/param norm = 5.4514e-01, time/batch = 0.4099s	
1643/2700 (epoch 30.426), train_loss = 3.28963741, grad/param norm = 4.6406e-01, time/batch = 0.3980s	
1644/2700 (epoch 30.444), train_loss = 3.21929327, grad/param norm = 4.9364e-01, time/batch = 0.4374s	
1645/2700 (epoch 30.463), train_loss = 3.26173011, grad/param norm = 4.9048e-01, time/batch = 0.4623s	
1646/2700 (epoch 30.481), train_loss = 3.33769235, grad/param norm = 4.9388e-01, time/batch = 0.4496s	
1647/2700 (epoch 30.500), train_loss = 3.38796409, grad/param norm = 5.8091e-01, time/batch = 0.4058s	
1648/2700 (epoch 30.519), train_loss = 3.34413610, grad/param norm = 5.8176e-01, time/batch = 0.3213s	
1649/2700 (epoch 30.537), train_loss = 3.34268870, grad/param norm = 5.9814e-01, time/batch = 0.2995s	
1650/2700 (epoch 30.556), train_loss = 3.29186085, grad/param norm = 5.9057e-01, time/batch = 0.4669s	
1651/2700 (epoch 30.574), train_loss = 3.24269379, grad/param norm = 4.6154e-01, time/batch = 0.4497s	
1652/2700 (epoch 30.593), train_loss = 3.24886560, grad/param norm = 4.9663e-01, time/batch = 0.4625s	
1653/2700 (epoch 30.611), train_loss = 3.17859714, grad/param norm = 4.0082e-01, time/batch = 0.4310s	
1654/2700 (epoch 30.630), train_loss = 3.22374885, grad/param norm = 4.0896e-01, time/batch = 0.3543s	
1655/2700 (epoch 30.648), train_loss = 3.29582328, grad/param norm = 4.6218e-01, time/batch = 0.4553s	
1656/2700 (epoch 30.667), train_loss = 3.23155777, grad/param norm = 4.8884e-01, time/batch = 0.4595s	
1657/2700 (epoch 30.685), train_loss = 3.22836047, grad/param norm = 4.9982e-01, time/batch = 0.4445s	
1658/2700 (epoch 30.704), train_loss = 3.19711003, grad/param norm = 5.0312e-01, time/batch = 0.3987s	
1659/2700 (epoch 30.722), train_loss = 3.18404583, grad/param norm = 4.4462e-01, time/batch = 0.3003s	
1660/2700 (epoch 30.741), train_loss = 3.32396226, grad/param norm = 5.9440e-01, time/batch = 0.3951s	
1661/2700 (epoch 30.759), train_loss = 3.28233269, grad/param norm = 6.2128e-01, time/batch = 0.4227s	
1662/2700 (epoch 30.778), train_loss = 3.26655270, grad/param norm = 5.3413e-01, time/batch = 0.4452s	
1663/2700 (epoch 30.796), train_loss = 3.25348130, grad/param norm = 5.0771e-01, time/batch = 0.4534s	
1664/2700 (epoch 30.815), train_loss = 3.21442200, grad/param norm = 4.2967e-01, time/batch = 0.4091s	
1665/2700 (epoch 30.833), train_loss = 3.24139871, grad/param norm = 4.3872e-01, time/batch = 0.3828s	
1666/2700 (epoch 30.852), train_loss = 3.23300682, grad/param norm = 4.5180e-01, time/batch = 0.4138s	
1667/2700 (epoch 30.870), train_loss = 3.22461041, grad/param norm = 4.4812e-01, time/batch = 0.4643s	
1668/2700 (epoch 30.889), train_loss = 3.27363845, grad/param norm = 5.0874e-01, time/batch = 0.4399s	
1669/2700 (epoch 30.907), train_loss = 3.31805731, grad/param norm = 5.5342e-01, time/batch = 0.3472s	
1670/2700 (epoch 30.926), train_loss = 3.26867544, grad/param norm = 5.8302e-01, time/batch = 0.4109s	
1671/2700 (epoch 30.944), train_loss = 3.27329300, grad/param norm = 5.0419e-01, time/batch = 0.3902s	
1672/2700 (epoch 30.963), train_loss = 3.35748078, grad/param norm = 5.1472e-01, time/batch = 0.4233s	
1673/2700 (epoch 30.981), train_loss = 3.41911851, grad/param norm = 5.1505e-01, time/batch = 0.4270s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
1674/2700 (epoch 31.000), train_loss = 3.31220771, grad/param norm = 4.9662e-01, time/batch = 0.4171s	
1675/2700 (epoch 31.019), train_loss = 3.25833343, grad/param norm = 5.3579e-01, time/batch = 0.3578s	
1676/2700 (epoch 31.037), train_loss = 3.26921559, grad/param norm = 5.2740e-01, time/batch = 0.4070s	
1677/2700 (epoch 31.056), train_loss = 3.27094212, grad/param norm = 4.4408e-01, time/batch = 0.4519s	
1678/2700 (epoch 31.074), train_loss = 3.30120538, grad/param norm = 4.8136e-01, time/batch = 0.4487s	
1679/2700 (epoch 31.093), train_loss = 3.31177884, grad/param norm = 5.2771e-01, time/batch = 0.3889s	
1680/2700 (epoch 31.111), train_loss = 3.28116194, grad/param norm = 4.5769e-01, time/batch = 0.4130s	
1681/2700 (epoch 31.130), train_loss = 3.29133742, grad/param norm = 4.1367e-01, time/batch = 0.3894s	
1682/2700 (epoch 31.148), train_loss = 3.25650535, grad/param norm = 4.7015e-01, time/batch = 0.3922s	
1683/2700 (epoch 31.167), train_loss = 3.26939158, grad/param norm = 5.2622e-01, time/batch = 0.4244s	
1684/2700 (epoch 31.185), train_loss = 3.25452825, grad/param norm = 4.3407e-01, time/batch = 0.4110s	
1685/2700 (epoch 31.204), train_loss = 3.18933887, grad/param norm = 4.4859e-01, time/batch = 0.3755s	
1686/2700 (epoch 31.222), train_loss = 3.16231583, grad/param norm = 5.2630e-01, time/batch = 0.3937s	
1687/2700 (epoch 31.241), train_loss = 3.17599330, grad/param norm = 3.8320e-01, time/batch = 0.4303s	
1688/2700 (epoch 31.259), train_loss = 3.21594324, grad/param norm = 3.7128e-01, time/batch = 0.4532s	
1689/2700 (epoch 31.278), train_loss = 3.28642193, grad/param norm = 4.6155e-01, time/batch = 0.4312s	
1690/2700 (epoch 31.296), train_loss = 3.29393274, grad/param norm = 4.8759e-01, time/batch = 0.4441s	
1691/2700 (epoch 31.315), train_loss = 3.27027794, grad/param norm = 4.8129e-01, time/batch = 0.3696s	
1692/2700 (epoch 31.333), train_loss = 3.35109033, grad/param norm = 4.6381e-01, time/batch = 0.4212s	
1693/2700 (epoch 31.352), train_loss = 3.35997510, grad/param norm = 5.2714e-01, time/batch = 0.4249s	
1694/2700 (epoch 31.370), train_loss = 3.31107636, grad/param norm = 6.3797e-01, time/batch = 0.4166s	
1695/2700 (epoch 31.389), train_loss = 3.27070773, grad/param norm = 5.9671e-01, time/batch = 0.3768s	
1696/2700 (epoch 31.407), train_loss = 3.29521968, grad/param norm = 5.4534e-01, time/batch = 0.3357s	
1697/2700 (epoch 31.426), train_loss = 3.28903249, grad/param norm = 4.6132e-01, time/batch = 0.3766s	
1698/2700 (epoch 31.444), train_loss = 3.21864958, grad/param norm = 4.8554e-01, time/batch = 0.4373s	
1699/2700 (epoch 31.463), train_loss = 3.26070824, grad/param norm = 4.7865e-01, time/batch = 0.4386s	
1700/2700 (epoch 31.481), train_loss = 3.33675790, grad/param norm = 4.8220e-01, time/batch = 0.4634s	
1701/2700 (epoch 31.500), train_loss = 3.38676843, grad/param norm = 5.7007e-01, time/batch = 0.4627s	
1702/2700 (epoch 31.519), train_loss = 3.34295094, grad/param norm = 5.6866e-01, time/batch = 0.4168s	
1703/2700 (epoch 31.537), train_loss = 3.34148307, grad/param norm = 5.8518e-01, time/batch = 0.3410s	
1704/2700 (epoch 31.556), train_loss = 3.29019466, grad/param norm = 5.7950e-01, time/batch = 0.4511s	
1705/2700 (epoch 31.574), train_loss = 3.24217873, grad/param norm = 4.5601e-01, time/batch = 0.4101s	
1706/2700 (epoch 31.593), train_loss = 3.24786867, grad/param norm = 4.9003e-01, time/batch = 0.3091s	
1707/2700 (epoch 31.611), train_loss = 3.17798435, grad/param norm = 3.9339e-01, time/batch = 0.3501s	
1708/2700 (epoch 31.630), train_loss = 3.22309852, grad/param norm = 4.0428e-01, time/batch = 0.4184s	
1709/2700 (epoch 31.648), train_loss = 3.29497485, grad/param norm = 4.5713e-01, time/batch = 0.4306s	
1710/2700 (epoch 31.667), train_loss = 3.23044888, grad/param norm = 4.8170e-01, time/batch = 0.4665s	
1711/2700 (epoch 31.685), train_loss = 3.22741520, grad/param norm = 4.9311e-01, time/batch = 0.4551s	
1712/2700 (epoch 31.704), train_loss = 3.19624942, grad/param norm = 4.9846e-01, time/batch = 0.4159s	
1713/2700 (epoch 31.722), train_loss = 3.18338233, grad/param norm = 4.4043e-01, time/batch = 0.3900s	
1714/2700 (epoch 31.741), train_loss = 3.32317786, grad/param norm = 5.8903e-01, time/batch = 0.4285s	
1715/2700 (epoch 31.759), train_loss = 3.28098197, grad/param norm = 6.1099e-01, time/batch = 0.4316s	
1716/2700 (epoch 31.778), train_loss = 3.26525677, grad/param norm = 5.2134e-01, time/batch = 0.4040s	
1717/2700 (epoch 31.796), train_loss = 3.25224566, grad/param norm = 4.9482e-01, time/batch = 0.3431s	
1718/2700 (epoch 31.815), train_loss = 3.21307989, grad/param norm = 4.1830e-01, time/batch = 0.3387s	
1719/2700 (epoch 31.833), train_loss = 3.24051340, grad/param norm = 4.3150e-01, time/batch = 0.3635s	
1720/2700 (epoch 31.852), train_loss = 3.23190113, grad/param norm = 4.4477e-01, time/batch = 0.4571s	
1721/2700 (epoch 31.870), train_loss = 3.22349522, grad/param norm = 4.4021e-01, time/batch = 0.4501s	
1722/2700 (epoch 31.889), train_loss = 3.27250859, grad/param norm = 4.9895e-01, time/batch = 0.4595s	
1723/2700 (epoch 31.907), train_loss = 3.31691536, grad/param norm = 5.4102e-01, time/batch = 0.4076s	
1724/2700 (epoch 31.926), train_loss = 3.26716429, grad/param norm = 5.6657e-01, time/batch = 0.3901s	
1725/2700 (epoch 31.944), train_loss = 3.27204986, grad/param norm = 4.8953e-01, time/batch = 0.4203s	
1726/2700 (epoch 31.963), train_loss = 3.35630780, grad/param norm = 5.0111e-01, time/batch = 0.4603s	
1727/2700 (epoch 31.981), train_loss = 3.41787864, grad/param norm = 5.0292e-01, time/batch = 0.4393s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
1728/2700 (epoch 32.000), train_loss = 3.31102209, grad/param norm = 4.8581e-01, time/batch = 0.3551s	
1729/2700 (epoch 32.019), train_loss = 3.25722897, grad/param norm = 5.2422e-01, time/batch = 0.2955s	
1730/2700 (epoch 32.037), train_loss = 3.26816640, grad/param norm = 5.1486e-01, time/batch = 0.4345s	
1731/2700 (epoch 32.056), train_loss = 3.27020060, grad/param norm = 4.3560e-01, time/batch = 0.4341s	
1732/2700 (epoch 32.074), train_loss = 3.30043500, grad/param norm = 4.7606e-01, time/batch = 0.4501s	
1733/2700 (epoch 32.093), train_loss = 3.31049383, grad/param norm = 5.2010e-01, time/batch = 0.4493s	
1734/2700 (epoch 32.111), train_loss = 3.28015500, grad/param norm = 4.4991e-01, time/batch = 0.4022s	
1735/2700 (epoch 32.130), train_loss = 3.29051601, grad/param norm = 4.0978e-01, time/batch = 0.3894s	
1736/2700 (epoch 32.148), train_loss = 3.25609077, grad/param norm = 4.6462e-01, time/batch = 0.4216s	
1737/2700 (epoch 32.167), train_loss = 3.26837456, grad/param norm = 5.1946e-01, time/batch = 0.4591s	
1738/2700 (epoch 32.185), train_loss = 3.25359217, grad/param norm = 4.2491e-01, time/batch = 0.4322s	
1739/2700 (epoch 32.204), train_loss = 3.18846864, grad/param norm = 4.4054e-01, time/batch = 0.3103s	
1740/2700 (epoch 32.222), train_loss = 3.16155538, grad/param norm = 5.1586e-01, time/batch = 0.3492s	
1741/2700 (epoch 32.241), train_loss = 3.17525881, grad/param norm = 3.7388e-01, time/batch = 0.4106s	
1742/2700 (epoch 32.259), train_loss = 3.21508849, grad/param norm = 3.6313e-01, time/batch = 0.4372s	
1743/2700 (epoch 32.278), train_loss = 3.28510586, grad/param norm = 4.3831e-01, time/batch = 0.4443s	
1744/2700 (epoch 32.296), train_loss = 3.29235482, grad/param norm = 4.5902e-01, time/batch = 0.4121s	
1745/2700 (epoch 32.315), train_loss = 3.26851646, grad/param norm = 4.5007e-01, time/batch = 0.3859s	
1746/2700 (epoch 32.333), train_loss = 3.34960688, grad/param norm = 4.3483e-01, time/batch = 0.4241s	
1747/2700 (epoch 32.352), train_loss = 3.35866543, grad/param norm = 5.0626e-01, time/batch = 0.4461s	
1748/2700 (epoch 32.370), train_loss = 3.31008082, grad/param norm = 6.3315e-01, time/batch = 0.4587s	
1749/2700 (epoch 32.389), train_loss = 3.27063898, grad/param norm = 6.2095e-01, time/batch = 0.3532s	
1750/2700 (epoch 32.407), train_loss = 3.29579429, grad/param norm = 5.7371e-01, time/batch = 0.3715s	
1751/2700 (epoch 32.426), train_loss = 3.28897996, grad/param norm = 4.7491e-01, time/batch = 0.3555s	
1752/2700 (epoch 32.444), train_loss = 3.21840575, grad/param norm = 4.8727e-01, time/batch = 0.3892s	
1753/2700 (epoch 32.463), train_loss = 3.25977546, grad/param norm = 4.7000e-01, time/batch = 0.4453s	
1754/2700 (epoch 32.481), train_loss = 3.33587940, grad/param norm = 4.7130e-01, time/batch = 0.4046s	
1755/2700 (epoch 32.500), train_loss = 3.38558315, grad/param norm = 5.5787e-01, time/batch = 0.3937s	
1756/2700 (epoch 32.519), train_loss = 3.34170379, grad/param norm = 5.5295e-01, time/batch = 0.4546s	
1757/2700 (epoch 32.537), train_loss = 3.34029423, grad/param norm = 5.7041e-01, time/batch = 0.4654s	
1758/2700 (epoch 32.556), train_loss = 3.28853358, grad/param norm = 5.6776e-01, time/batch = 0.4548s	
1759/2700 (epoch 32.574), train_loss = 3.24170402, grad/param norm = 4.5140e-01, time/batch = 0.3760s	
1760/2700 (epoch 32.593), train_loss = 3.24694000, grad/param norm = 4.8393e-01, time/batch = 0.3746s	
1761/2700 (epoch 32.611), train_loss = 3.17740413, grad/param norm = 3.8661e-01, time/batch = 0.3761s	
1762/2700 (epoch 32.630), train_loss = 3.22245949, grad/param norm = 3.9938e-01, time/batch = 0.4156s	
1763/2700 (epoch 32.648), train_loss = 3.29411842, grad/param norm = 4.5222e-01, time/batch = 0.4361s	
1764/2700 (epoch 32.667), train_loss = 3.22944054, grad/param norm = 4.7566e-01, time/batch = 0.4411s	
1765/2700 (epoch 32.685), train_loss = 3.22655759, grad/param norm = 4.8746e-01, time/batch = 0.3803s	
1766/2700 (epoch 32.704), train_loss = 3.19543808, grad/param norm = 4.9397e-01, time/batch = 0.4158s	
1767/2700 (epoch 32.722), train_loss = 3.18270006, grad/param norm = 4.3463e-01, time/batch = 0.4534s	
1768/2700 (epoch 32.741), train_loss = 3.32227317, grad/param norm = 5.7889e-01, time/batch = 0.4682s	
1769/2700 (epoch 32.759), train_loss = 3.27950497, grad/param norm = 5.9728e-01, time/batch = 0.4443s	
1770/2700 (epoch 32.778), train_loss = 3.26399695, grad/param norm = 5.0814e-01, time/batch = 0.4381s	
1771/2700 (epoch 32.796), train_loss = 3.25108224, grad/param norm = 4.8236e-01, time/batch = 0.3975s	
1772/2700 (epoch 32.815), train_loss = 3.21181099, grad/param norm = 4.0764e-01, time/batch = 0.3746s	
1773/2700 (epoch 32.833), train_loss = 3.23969041, grad/param norm = 4.2511e-01, time/batch = 0.3829s	
1774/2700 (epoch 32.852), train_loss = 3.23088346, grad/param norm = 4.3862e-01, time/batch = 0.4156s	
1775/2700 (epoch 32.870), train_loss = 3.22248117, grad/param norm = 4.3321e-01, time/batch = 0.4261s	
1776/2700 (epoch 32.889), train_loss = 3.27146129, grad/param norm = 4.9009e-01, time/batch = 0.4000s	
1777/2700 (epoch 32.907), train_loss = 3.31585731, grad/param norm = 5.2976e-01, time/batch = 0.3492s	
1778/2700 (epoch 32.926), train_loss = 3.26576468, grad/param norm = 5.5135e-01, time/batch = 0.4478s	
1779/2700 (epoch 32.944), train_loss = 3.27090201, grad/param norm = 4.7597e-01, time/batch = 0.4473s	
1780/2700 (epoch 32.963), train_loss = 3.35519571, grad/param norm = 4.8825e-01, time/batch = 0.4566s	
1781/2700 (epoch 32.981), train_loss = 3.41670527, grad/param norm = 4.9130e-01, time/batch = 0.4347s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
1782/2700 (epoch 33.000), train_loss = 3.30989434, grad/param norm = 4.7548e-01, time/batch = 0.3976s	
1783/2700 (epoch 33.019), train_loss = 3.25614710, grad/param norm = 5.1287e-01, time/batch = 0.3782s	
1784/2700 (epoch 33.037), train_loss = 3.26713933, grad/param norm = 5.0205e-01, time/batch = 0.3867s	
1785/2700 (epoch 33.056), train_loss = 3.26948786, grad/param norm = 4.2720e-01, time/batch = 0.4011s	
1786/2700 (epoch 33.074), train_loss = 3.29970257, grad/param norm = 4.7132e-01, time/batch = 0.4237s	
1787/2700 (epoch 33.093), train_loss = 3.30926025, grad/param norm = 5.1310e-01, time/batch = 0.3830s	
1788/2700 (epoch 33.111), train_loss = 3.27918803, grad/param norm = 4.4237e-01, time/batch = 0.3442s	
1789/2700 (epoch 33.130), train_loss = 3.28970761, grad/param norm = 4.0566e-01, time/batch = 0.3807s	
1790/2700 (epoch 33.148), train_loss = 3.25567883, grad/param norm = 4.5876e-01, time/batch = 0.4536s	
1791/2700 (epoch 33.167), train_loss = 3.26739823, grad/param norm = 5.1298e-01, time/batch = 0.4463s	
1792/2700 (epoch 33.185), train_loss = 3.25268456, grad/param norm = 4.1542e-01, time/batch = 0.4144s	
1793/2700 (epoch 33.204), train_loss = 3.18763298, grad/param norm = 4.3251e-01, time/batch = 0.3858s	
1794/2700 (epoch 33.222), train_loss = 3.16080096, grad/param norm = 5.0448e-01, time/batch = 0.4109s	
1795/2700 (epoch 33.241), train_loss = 3.17459325, grad/param norm = 3.6568e-01, time/batch = 0.4162s	
1796/2700 (epoch 33.259), train_loss = 3.21431256, grad/param norm = 3.5791e-01, time/batch = 0.4281s	
1797/2700 (epoch 33.278), train_loss = 3.28369427, grad/param norm = 4.1067e-01, time/batch = 0.3731s	
1798/2700 (epoch 33.296), train_loss = 3.29079474, grad/param norm = 4.2424e-01, time/batch = 0.3591s	
1799/2700 (epoch 33.315), train_loss = 3.26653357, grad/param norm = 4.0989e-01, time/batch = 0.3775s	
1800/2700 (epoch 33.333), train_loss = 3.34778200, grad/param norm = 3.8079e-01, time/batch = 0.4647s	
1801/2700 (epoch 33.352), train_loss = 3.35596346, grad/param norm = 4.2652e-01, time/batch = 0.4440s	
1802/2700 (epoch 33.370), train_loss = 3.30360690, grad/param norm = 4.7092e-01, time/batch = 0.3933s	
1803/2700 (epoch 33.389), train_loss = 3.26284201, grad/param norm = 4.2243e-01, time/batch = 0.4152s	
1804/2700 (epoch 33.407), train_loss = 3.29101614, grad/param norm = 5.0981e-01, time/batch = 0.4313s	
1805/2700 (epoch 33.426), train_loss = 3.29333597, grad/param norm = 6.0542e-01, time/batch = 0.4305s	
1806/2700 (epoch 33.444), train_loss = 3.22221095, grad/param norm = 6.4266e-01, time/batch = 0.4284s	
1807/2700 (epoch 33.463), train_loss = 3.26475859, grad/param norm = 5.8807e-01, time/batch = 0.3976s	
1808/2700 (epoch 33.481), train_loss = 3.33516012, grad/param norm = 4.7079e-01, time/batch = 0.3525s	
1809/2700 (epoch 33.500), train_loss = 3.38404509, grad/param norm = 5.1521e-01, time/batch = 0.3538s	
1810/2700 (epoch 33.519), train_loss = 3.33941027, grad/param norm = 4.9168e-01, time/batch = 0.4513s	
1811/2700 (epoch 33.537), train_loss = 3.33913769, grad/param norm = 5.3573e-01, time/batch = 0.4483s	
1812/2700 (epoch 33.556), train_loss = 3.28574067, grad/param norm = 5.5372e-01, time/batch = 0.4663s	
1813/2700 (epoch 33.574), train_loss = 3.24210225, grad/param norm = 4.7204e-01, time/batch = 0.4538s	
1814/2700 (epoch 33.593), train_loss = 3.24676595, grad/param norm = 4.9948e-01, time/batch = 0.4043s	
1815/2700 (epoch 33.611), train_loss = 3.17760209, grad/param norm = 4.1480e-01, time/batch = 0.4086s	
1816/2700 (epoch 33.630), train_loss = 3.22244295, grad/param norm = 4.1656e-01, time/batch = 0.4510s	
1817/2700 (epoch 33.648), train_loss = 3.29401111, grad/param norm = 4.7047e-01, time/batch = 0.4552s	
1818/2700 (epoch 33.667), train_loss = 3.22907455, grad/param norm = 4.9454e-01, time/batch = 0.4199s	
1819/2700 (epoch 33.685), train_loss = 3.22693465, grad/param norm = 5.2295e-01, time/batch = 0.2930s	
1820/2700 (epoch 33.704), train_loss = 3.19576813, grad/param norm = 5.2792e-01, time/batch = 0.3649s	
1821/2700 (epoch 33.722), train_loss = 3.18315380, grad/param norm = 4.7184e-01, time/batch = 0.4163s	
1822/2700 (epoch 33.741), train_loss = 3.32217103, grad/param norm = 5.9585e-01, time/batch = 0.4590s	
1823/2700 (epoch 33.759), train_loss = 3.27731141, grad/param norm = 5.7186e-01, time/batch = 0.4680s	
1824/2700 (epoch 33.778), train_loss = 3.26178570, grad/param norm = 4.7437e-01, time/batch = 0.4377s	
1825/2700 (epoch 33.796), train_loss = 3.24970462, grad/param norm = 4.6407e-01, time/batch = 0.4103s	
1826/2700 (epoch 33.815), train_loss = 3.21101019, grad/param norm = 4.0898e-01, time/batch = 0.3667s	
1827/2700 (epoch 33.833), train_loss = 3.23917968, grad/param norm = 4.2921e-01, time/batch = 0.4620s	
1828/2700 (epoch 33.852), train_loss = 3.23011963, grad/param norm = 4.4036e-01, time/batch = 0.4267s	
1829/2700 (epoch 33.870), train_loss = 3.22172966, grad/param norm = 4.3065e-01, time/batch = 0.2865s	
1830/2700 (epoch 33.889), train_loss = 3.27031983, grad/param norm = 4.7844e-01, time/batch = 0.3907s	
1831/2700 (epoch 33.907), train_loss = 3.31457283, grad/param norm = 5.0573e-01, time/batch = 0.4034s	
1832/2700 (epoch 33.926), train_loss = 3.26361029, grad/param norm = 5.1670e-01, time/batch = 0.4336s	
1833/2700 (epoch 33.944), train_loss = 3.26905693, grad/param norm = 4.4327e-01, time/batch = 0.4699s	
1834/2700 (epoch 33.963), train_loss = 3.35382864, grad/param norm = 4.6546e-01, time/batch = 0.4453s	
1835/2700 (epoch 33.981), train_loss = 3.41545149, grad/param norm = 4.7569e-01, time/batch = 0.3792s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
1836/2700 (epoch 34.000), train_loss = 3.30868318, grad/param norm = 4.5867e-01, time/batch = 0.4075s	
1837/2700 (epoch 34.019), train_loss = 3.25471440, grad/param norm = 4.9122e-01, time/batch = 0.4220s	
1838/2700 (epoch 34.037), train_loss = 3.26576412, grad/param norm = 4.7756e-01, time/batch = 0.4134s	
1839/2700 (epoch 34.056), train_loss = 3.26880309, grad/param norm = 4.1674e-01, time/batch = 0.3085s	
1840/2700 (epoch 34.074), train_loss = 3.29913074, grad/param norm = 4.7353e-01, time/batch = 0.3882s	
1841/2700 (epoch 34.093), train_loss = 3.30840112, grad/param norm = 5.1665e-01, time/batch = 0.4008s	
1842/2700 (epoch 34.111), train_loss = 3.27840419, grad/param norm = 4.4082e-01, time/batch = 0.4535s	
1843/2700 (epoch 34.130), train_loss = 3.28879704, grad/param norm = 4.0126e-01, time/batch = 0.4676s	
1844/2700 (epoch 34.148), train_loss = 3.25519000, grad/param norm = 4.4927e-01, time/batch = 0.4695s	
1845/2700 (epoch 34.167), train_loss = 3.26663968, grad/param norm = 5.1292e-01, time/batch = 0.4308s	
1846/2700 (epoch 34.185), train_loss = 3.25178203, grad/param norm = 4.0650e-01, time/batch = 0.3822s	
1847/2700 (epoch 34.204), train_loss = 3.18727848, grad/param norm = 4.3970e-01, time/batch = 0.3771s	
1848/2700 (epoch 34.222), train_loss = 3.16076964, grad/param norm = 5.0834e-01, time/batch = 0.4122s	
1849/2700 (epoch 34.241), train_loss = 3.17622973, grad/param norm = 4.4300e-01, time/batch = 0.4037s	
1850/2700 (epoch 34.259), train_loss = 3.21770248, grad/param norm = 5.2969e-01, time/batch = 0.4232s	
1851/2700 (epoch 34.278), train_loss = 3.28768188, grad/param norm = 5.5167e-01, time/batch = 0.3185s	
1852/2700 (epoch 34.296), train_loss = 3.29593712, grad/param norm = 6.0745e-01, time/batch = 0.4054s	
1853/2700 (epoch 34.315), train_loss = 3.27117997, grad/param norm = 5.7409e-01, time/batch = 0.4524s	
1854/2700 (epoch 34.333), train_loss = 3.35081804, grad/param norm = 4.9593e-01, time/batch = 0.4630s	
1855/2700 (epoch 34.352), train_loss = 3.35650329, grad/param norm = 4.6206e-01, time/batch = 0.4589s	
1856/2700 (epoch 34.370), train_loss = 3.30131776, grad/param norm = 4.4395e-01, time/batch = 0.4202s	
1857/2700 (epoch 34.389), train_loss = 3.26060032, grad/param norm = 3.7501e-01, time/batch = 0.3911s	
1858/2700 (epoch 34.407), train_loss = 3.28790761, grad/param norm = 4.0506e-01, time/batch = 0.3523s	
1859/2700 (epoch 34.426), train_loss = 3.28475049, grad/param norm = 3.8249e-01, time/batch = 0.3900s	
1860/2700 (epoch 34.444), train_loss = 3.21442595, grad/param norm = 3.8239e-01, time/batch = 0.4300s	
1861/2700 (epoch 34.463), train_loss = 3.25661449, grad/param norm = 3.8083e-01, time/batch = 0.4094s	
1862/2700 (epoch 34.481), train_loss = 3.33246833, grad/param norm = 3.8809e-01, time/batch = 0.3773s	
1863/2700 (epoch 34.500), train_loss = 3.38305289, grad/param norm = 5.1330e-01, time/batch = 0.3586s	
1864/2700 (epoch 34.519), train_loss = 3.34030940, grad/param norm = 5.2748e-01, time/batch = 0.4475s	
1865/2700 (epoch 34.537), train_loss = 3.33856880, grad/param norm = 5.6021e-01, time/batch = 0.4642s	
1866/2700 (epoch 34.556), train_loss = 3.28553756, grad/param norm = 5.4974e-01, time/batch = 0.4647s	
1867/2700 (epoch 34.574), train_loss = 3.24043783, grad/param norm = 4.3323e-01, time/batch = 0.4206s	
1868/2700 (epoch 34.593), train_loss = 3.24486984, grad/param norm = 4.7038e-01, time/batch = 0.3882s	
1869/2700 (epoch 34.611), train_loss = 3.17626285, grad/param norm = 3.6594e-01, time/batch = 0.3522s	
1870/2700 (epoch 34.630), train_loss = 3.22147033, grad/param norm = 3.9322e-01, time/batch = 0.4323s	
1871/2700 (epoch 34.648), train_loss = 3.29265919, grad/param norm = 4.4402e-01, time/batch = 0.4311s	
1872/2700 (epoch 34.667), train_loss = 3.22729348, grad/param norm = 4.6019e-01, time/batch = 0.4159s	
1873/2700 (epoch 34.685), train_loss = 3.22429819, grad/param norm = 4.5507e-01, time/batch = 0.3472s	
1874/2700 (epoch 34.704), train_loss = 3.19311131, grad/param norm = 4.5888e-01, time/batch = 0.3511s	
1875/2700 (epoch 34.722), train_loss = 3.18064065, grad/param norm = 3.8875e-01, time/batch = 0.4022s	
1876/2700 (epoch 34.741), train_loss = 3.32076831, grad/param norm = 5.6007e-01, time/batch = 0.4378s	
1877/2700 (epoch 34.759), train_loss = 3.27936088, grad/param norm = 6.2201e-01, time/batch = 0.3944s	
1878/2700 (epoch 34.778), train_loss = 3.26321332, grad/param norm = 5.2832e-01, time/batch = 0.4164s	
1879/2700 (epoch 34.796), train_loss = 3.25024684, grad/param norm = 4.9341e-01, time/batch = 0.4213s	
1880/2700 (epoch 34.815), train_loss = 3.21008502, grad/param norm = 3.9749e-01, time/batch = 0.4440s	
1881/2700 (epoch 34.833), train_loss = 3.23785835, grad/param norm = 4.0574e-01, time/batch = 0.4496s	
1882/2700 (epoch 34.852), train_loss = 3.22822229, grad/param norm = 4.0077e-01, time/batch = 0.4021s	
1883/2700 (epoch 34.870), train_loss = 3.21964186, grad/param norm = 3.8769e-01, time/batch = 0.3229s	
1884/2700 (epoch 34.889), train_loss = 3.26859965, grad/param norm = 4.4438e-01, time/batch = 0.3411s	
1885/2700 (epoch 34.907), train_loss = 3.31315518, grad/param norm = 4.8839e-01, time/batch = 0.4138s	
1886/2700 (epoch 34.926), train_loss = 3.26287589, grad/param norm = 5.1952e-01, time/batch = 0.4589s	
1887/2700 (epoch 34.944), train_loss = 3.26912531, grad/param norm = 4.6549e-01, time/batch = 0.4608s	
1888/2700 (epoch 34.963), train_loss = 3.35382511, grad/param norm = 4.8520e-01, time/batch = 0.3887s	
1889/2700 (epoch 34.981), train_loss = 3.41487205, grad/param norm = 4.8272e-01, time/batch = 0.3756s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
1890/2700 (epoch 35.000), train_loss = 3.30828796, grad/param norm = 4.7670e-01, time/batch = 0.4526s	
1891/2700 (epoch 35.019), train_loss = 3.25526870, grad/param norm = 5.2416e-01, time/batch = 0.4622s	
1892/2700 (epoch 35.037), train_loss = 3.26620832, grad/param norm = 5.0755e-01, time/batch = 0.4432s	
1893/2700 (epoch 35.056), train_loss = 3.26835152, grad/param norm = 4.2192e-01, time/batch = 0.4048s	
1894/2700 (epoch 35.074), train_loss = 3.29832543, grad/param norm = 4.5917e-01, time/batch = 0.3518s	
1895/2700 (epoch 35.093), train_loss = 3.30688041, grad/param norm = 4.9419e-01, time/batch = 0.3136s	
1896/2700 (epoch 35.111), train_loss = 3.27742590, grad/param norm = 4.2903e-01, time/batch = 0.4160s	
1897/2700 (epoch 35.130), train_loss = 3.28838965, grad/param norm = 4.0386e-01, time/batch = 0.4564s	
1898/2700 (epoch 35.148), train_loss = 3.25504704, grad/param norm = 4.5475e-01, time/batch = 0.4627s	
1899/2700 (epoch 35.167), train_loss = 3.26556601, grad/param norm = 5.0348e-01, time/batch = 0.3926s	
1900/2700 (epoch 35.185), train_loss = 3.25177708, grad/param norm = 4.2237e-01, time/batch = 0.3653s	
1901/2700 (epoch 35.204), train_loss = 3.18673830, grad/param norm = 4.3892e-01, time/batch = 0.4227s	
1902/2700 (epoch 35.222), train_loss = 3.16040522, grad/param norm = 5.2080e-01, time/batch = 0.4631s	
1903/2700 (epoch 35.241), train_loss = 3.17395369, grad/param norm = 3.8268e-01, time/batch = 0.4365s	
1904/2700 (epoch 35.259), train_loss = 3.21429613, grad/param norm = 3.9872e-01, time/batch = 0.3333s	
1905/2700 (epoch 35.278), train_loss = 3.28557453, grad/param norm = 5.1731e-01, time/batch = 0.3207s	
1906/2700 (epoch 35.296), train_loss = 3.29160245, grad/param norm = 4.9439e-01, time/batch = 0.3819s	
1907/2700 (epoch 35.315), train_loss = 3.26587429, grad/param norm = 4.4976e-01, time/batch = 0.4554s	
1908/2700 (epoch 35.333), train_loss = 3.34687922, grad/param norm = 4.0318e-01, time/batch = 0.4626s	
1909/2700 (epoch 35.352), train_loss = 3.35448415, grad/param norm = 4.3547e-01, time/batch = 0.4000s	
1910/2700 (epoch 35.370), train_loss = 3.30349378, grad/param norm = 5.2073e-01, time/batch = 0.4121s	
1911/2700 (epoch 35.389), train_loss = 3.26332148, grad/param norm = 4.5675e-01, time/batch = 0.3960s	
1912/2700 (epoch 35.407), train_loss = 3.28813784, grad/param norm = 4.3739e-01, time/batch = 0.4084s	
1913/2700 (epoch 35.426), train_loss = 3.28506452, grad/param norm = 4.0255e-01, time/batch = 0.4261s	
1914/2700 (epoch 35.444), train_loss = 3.21554800, grad/param norm = 4.3396e-01, time/batch = 0.3150s	
1915/2700 (epoch 35.463), train_loss = 3.25762969, grad/param norm = 4.4885e-01, time/batch = 0.3357s	
1916/2700 (epoch 35.481), train_loss = 3.33466636, grad/param norm = 4.7248e-01, time/batch = 0.4193s	
1917/2700 (epoch 35.500), train_loss = 3.38366185, grad/param norm = 5.7208e-01, time/batch = 0.4597s	
1918/2700 (epoch 35.519), train_loss = 3.34038700, grad/param norm = 5.6200e-01, time/batch = 0.4623s	
1919/2700 (epoch 35.537), train_loss = 3.33782109, grad/param norm = 5.5999e-01, time/batch = 0.3956s	
1920/2700 (epoch 35.556), train_loss = 3.28479104, grad/param norm = 5.4602e-01, time/batch = 0.4069s	
1921/2700 (epoch 35.574), train_loss = 3.24029624, grad/param norm = 4.3314e-01, time/batch = 0.3933s	
1922/2700 (epoch 35.593), train_loss = 3.24417474, grad/param norm = 4.6470e-01, time/batch = 0.4460s	
1923/2700 (epoch 35.611), train_loss = 3.17604883, grad/param norm = 3.6555e-01, time/batch = 0.4587s	
1924/2700 (epoch 35.630), train_loss = 3.22095706, grad/param norm = 3.8801e-01, time/batch = 0.4124s	
1925/2700 (epoch 35.648), train_loss = 3.29173655, grad/param norm = 4.3834e-01, time/batch = 0.3397s	
1926/2700 (epoch 35.667), train_loss = 3.22647376, grad/param norm = 4.5414e-01, time/batch = 0.3297s	
1927/2700 (epoch 35.685), train_loss = 3.22402955, grad/param norm = 4.6328e-01, time/batch = 0.3792s	
1928/2700 (epoch 35.704), train_loss = 3.19303753, grad/param norm = 4.7382e-01, time/batch = 0.4356s	
1929/2700 (epoch 35.722), train_loss = 3.18070653, grad/param norm = 4.1012e-01, time/batch = 0.4403s	
1930/2700 (epoch 35.741), train_loss = 3.32000127, grad/param norm = 5.5515e-01, time/batch = 0.4713s	
1931/2700 (epoch 35.759), train_loss = 3.27617696, grad/param norm = 5.7301e-01, time/batch = 0.4461s	
1932/2700 (epoch 35.778), train_loss = 3.26102160, grad/param norm = 4.8290e-01, time/batch = 0.4017s	
1933/2700 (epoch 35.796), train_loss = 3.24829386, grad/param norm = 4.5570e-01, time/batch = 0.3960s	
1934/2700 (epoch 35.815), train_loss = 3.20856945, grad/param norm = 3.8011e-01, time/batch = 0.4308s	
1935/2700 (epoch 35.833), train_loss = 3.23746789, grad/param norm = 4.0681e-01, time/batch = 0.4570s	
1936/2700 (epoch 35.852), train_loss = 3.22782422, grad/param norm = 4.1438e-01, time/batch = 0.4165s	
1937/2700 (epoch 35.870), train_loss = 3.21951621, grad/param norm = 4.0743e-01, time/batch = 0.2675s	
1938/2700 (epoch 35.889), train_loss = 3.26849606, grad/param norm = 4.6210e-01, time/batch = 0.3715s	
1939/2700 (epoch 35.907), train_loss = 3.31296322, grad/param norm = 4.9896e-01, time/batch = 0.4337s	
1940/2700 (epoch 35.926), train_loss = 3.26207939, grad/param norm = 5.1233e-01, time/batch = 0.4705s	
1941/2700 (epoch 35.944), train_loss = 3.26809635, grad/param norm = 4.4573e-01, time/batch = 0.4629s	
1942/2700 (epoch 35.963), train_loss = 3.35244844, grad/param norm = 4.5987e-01, time/batch = 0.4437s	
1943/2700 (epoch 35.981), train_loss = 3.41385335, grad/param norm = 4.6486e-01, time/batch = 0.4014s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
1944/2700 (epoch 36.000), train_loss = 3.30703822, grad/param norm = 4.5338e-01, time/batch = 0.3907s	
1945/2700 (epoch 36.019), train_loss = 3.25334395, grad/param norm = 4.8841e-01, time/batch = 0.4432s	
1946/2700 (epoch 36.037), train_loss = 3.26449073, grad/param norm = 4.7111e-01, time/batch = 0.4564s	
1947/2700 (epoch 36.056), train_loss = 3.26764032, grad/param norm = 4.0685e-01, time/batch = 0.4176s	
1948/2700 (epoch 36.074), train_loss = 3.29771570, grad/param norm = 4.5915e-01, time/batch = 0.3613s	
1949/2700 (epoch 36.093), train_loss = 3.30582459, grad/param norm = 4.9311e-01, time/batch = 0.2486s	
1950/2700 (epoch 36.111), train_loss = 3.27651726, grad/param norm = 4.2132e-01, time/batch = 0.4349s	
1951/2700 (epoch 36.130), train_loss = 3.28745502, grad/param norm = 3.9418e-01, time/batch = 0.4283s	
1952/2700 (epoch 36.148), train_loss = 3.25448646, grad/param norm = 4.4160e-01, time/batch = 0.4426s	
1953/2700 (epoch 36.167), train_loss = 3.26468395, grad/param norm = 4.9533e-01, time/batch = 0.4147s	
1954/2700 (epoch 36.185), train_loss = 3.25035840, grad/param norm = 3.9364e-01, time/batch = 0.3874s	
1955/2700 (epoch 36.204), train_loss = 3.18553177, grad/param norm = 4.1639e-01, time/batch = 0.4161s	
1956/2700 (epoch 36.222), train_loss = 3.15901163, grad/param norm = 4.8205e-01, time/batch = 0.4393s	
1957/2700 (epoch 36.241), train_loss = 3.17334065, grad/param norm = 3.6646e-01, time/batch = 0.4610s	
1958/2700 (epoch 36.259), train_loss = 3.21342668, grad/param norm = 4.0135e-01, time/batch = 0.4451s	
1959/2700 (epoch 36.278), train_loss = 3.28297344, grad/param norm = 4.4914e-01, time/batch = 0.3553s	
1960/2700 (epoch 36.296), train_loss = 3.29274095, grad/param norm = 5.4740e-01, time/batch = 0.3742s	
1961/2700 (epoch 36.315), train_loss = 3.27082011, grad/param norm = 5.9241e-01, time/batch = 0.3409s	
1962/2700 (epoch 36.333), train_loss = 3.35145391, grad/param norm = 5.6003e-01, time/batch = 0.4379s	
1963/2700 (epoch 36.352), train_loss = 3.35734928, grad/param norm = 5.1383e-01, time/batch = 0.4463s	
1964/2700 (epoch 36.370), train_loss = 3.30048976, grad/param norm = 4.5447e-01, time/batch = 0.4231s	
1965/2700 (epoch 36.389), train_loss = 3.25940598, grad/param norm = 3.7101e-01, time/batch = 0.3902s	
1966/2700 (epoch 36.407), train_loss = 3.28634269, grad/param norm = 4.0031e-01, time/batch = 0.4094s	
1967/2700 (epoch 36.426), train_loss = 3.28372557, grad/param norm = 3.8328e-01, time/batch = 0.4305s	
1968/2700 (epoch 36.444), train_loss = 3.21368161, grad/param norm = 3.7756e-01, time/batch = 0.4548s	
1969/2700 (epoch 36.463), train_loss = 3.25543614, grad/param norm = 3.7104e-01, time/batch = 0.4028s	
1970/2700 (epoch 36.481), train_loss = 3.33158180, grad/param norm = 3.7918e-01, time/batch = 0.4049s	
1971/2700 (epoch 36.500), train_loss = 3.38099779, grad/param norm = 4.9591e-01, time/batch = 0.3483s	
1972/2700 (epoch 36.519), train_loss = 3.33810955, grad/param norm = 5.0180e-01, time/batch = 0.3477s	
1973/2700 (epoch 36.537), train_loss = 3.33674643, grad/param norm = 5.3733e-01, time/batch = 0.3778s	
1974/2700 (epoch 36.556), train_loss = 3.28283998, grad/param norm = 5.3010e-01, time/batch = 0.4524s	
1975/2700 (epoch 36.574), train_loss = 3.23959324, grad/param norm = 4.2383e-01, time/batch = 0.4112s	
1976/2700 (epoch 36.593), train_loss = 3.24316503, grad/param norm = 4.5769e-01, time/batch = 0.4036s	
1977/2700 (epoch 36.611), train_loss = 3.17545751, grad/param norm = 3.5521e-01, time/batch = 0.4323s	
1978/2700 (epoch 36.630), train_loss = 3.22053214, grad/param norm = 3.8553e-01, time/batch = 0.4423s	
1979/2700 (epoch 36.648), train_loss = 3.29101068, grad/param norm = 4.3377e-01, time/batch = 0.4382s	
1980/2700 (epoch 36.667), train_loss = 3.22553135, grad/param norm = 4.4739e-01, time/batch = 0.4479s	
1981/2700 (epoch 36.685), train_loss = 3.22315137, grad/param norm = 4.5230e-01, time/batch = 0.4169s	
1982/2700 (epoch 36.704), train_loss = 3.19238613, grad/param norm = 4.7198e-01, time/batch = 0.3536s	
1983/2700 (epoch 36.722), train_loss = 3.18080021, grad/param norm = 4.3089e-01, time/batch = 0.3595s	
1984/2700 (epoch 36.741), train_loss = 3.32203291, grad/param norm = 6.3214e-01, time/batch = 0.4072s	
1985/2700 (epoch 36.759), train_loss = 3.27759624, grad/param norm = 6.1776e-01, time/batch = 0.4232s	
1986/2700 (epoch 36.778), train_loss = 3.26008651, grad/param norm = 4.7890e-01, time/batch = 0.4198s	
1987/2700 (epoch 36.796), train_loss = 3.24747173, grad/param norm = 4.4922e-01, time/batch = 0.4063s	
1988/2700 (epoch 36.815), train_loss = 3.20768109, grad/param norm = 3.7288e-01, time/batch = 0.4343s	
1989/2700 (epoch 36.833), train_loss = 3.23672244, grad/param norm = 4.0032e-01, time/batch = 0.4251s	
1990/2700 (epoch 36.852), train_loss = 3.22680476, grad/param norm = 4.0320e-01, time/batch = 0.4530s	
1991/2700 (epoch 36.870), train_loss = 3.21848139, grad/param norm = 3.9252e-01, time/batch = 0.4678s	
1992/2700 (epoch 36.889), train_loss = 3.26728616, grad/param norm = 4.4285e-01, time/batch = 0.4702s	
1993/2700 (epoch 36.907), train_loss = 3.31162427, grad/param norm = 4.7396e-01, time/batch = 0.4243s	
1994/2700 (epoch 36.926), train_loss = 3.26043353, grad/param norm = 4.8520e-01, time/batch = 0.3630s	
1995/2700 (epoch 36.944), train_loss = 3.26689492, grad/param norm = 4.2560e-01, time/batch = 0.3814s	
1996/2700 (epoch 36.963), train_loss = 3.35144670, grad/param norm = 4.4550e-01, time/batch = 0.4201s	
1997/2700 (epoch 36.981), train_loss = 3.41283775, grad/param norm = 4.5329e-01, time/batch = 0.4367s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
1998/2700 (epoch 37.000), train_loss = 3.30606357, grad/param norm = 4.4283e-01, time/batch = 0.3977s	
1999/2700 (epoch 37.019), train_loss = 3.25226539, grad/param norm = 4.7551e-01, time/batch = 0.3895s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch37.04_3.2009.t7	
2000/2700 (epoch 37.037), train_loss = 3.26353821, grad/param norm = 4.5697e-01, time/batch = 0.4401s	
2001/2700 (epoch 37.056), train_loss = 3.27412203, grad/param norm = 4.7831e-01, time/batch = 0.4424s	
2002/2700 (epoch 37.074), train_loss = 3.30416133, grad/param norm = 4.5373e-01, time/batch = 0.4576s	
2003/2700 (epoch 37.093), train_loss = 3.30586851, grad/param norm = 4.8062e-01, time/batch = 0.4579s	
2004/2700 (epoch 37.111), train_loss = 3.27524461, grad/param norm = 4.5635e-01, time/batch = 0.4188s	
2005/2700 (epoch 37.130), train_loss = 3.29312529, grad/param norm = 3.9517e-01, time/batch = 0.3816s	
2006/2700 (epoch 37.148), train_loss = 3.25460948, grad/param norm = 4.3313e-01, time/batch = 0.4117s	
2007/2700 (epoch 37.167), train_loss = 3.26806596, grad/param norm = 5.1287e-01, time/batch = 0.3968s	
2008/2700 (epoch 37.185), train_loss = 3.25411997, grad/param norm = 4.1212e-01, time/batch = 0.3533s	
2009/2700 (epoch 37.204), train_loss = 3.18557710, grad/param norm = 4.5742e-01, time/batch = 0.2102s	
2010/2700 (epoch 37.222), train_loss = 3.15749587, grad/param norm = 4.9667e-01, time/batch = 0.4233s	
2011/2700 (epoch 37.241), train_loss = 3.17669269, grad/param norm = 4.2242e-01, time/batch = 0.4390s	
2012/2700 (epoch 37.259), train_loss = 3.21316411, grad/param norm = 4.8783e-01, time/batch = 0.4621s	
2013/2700 (epoch 37.278), train_loss = 3.28763174, grad/param norm = 5.0602e-01, time/batch = 0.4472s	
2014/2700 (epoch 37.296), train_loss = 3.29550441, grad/param norm = 5.5313e-01, time/batch = 0.4134s	
2015/2700 (epoch 37.315), train_loss = 3.27107666, grad/param norm = 5.3774e-01, time/batch = 0.3600s	
2016/2700 (epoch 37.333), train_loss = 3.34544962, grad/param norm = 4.5662e-01, time/batch = 0.3398s	
2017/2700 (epoch 37.352), train_loss = 3.35588286, grad/param norm = 4.5477e-01, time/batch = 0.3905s	
2018/2700 (epoch 37.370), train_loss = 3.29776105, grad/param norm = 4.2115e-01, time/batch = 0.4320s	
2019/2700 (epoch 37.389), train_loss = 3.25933512, grad/param norm = 3.7561e-01, time/batch = 0.4166s	
2020/2700 (epoch 37.407), train_loss = 3.28792269, grad/param norm = 3.7992e-01, time/batch = 0.3874s	
2021/2700 (epoch 37.426), train_loss = 3.28337007, grad/param norm = 3.4373e-01, time/batch = 0.4007s	
2022/2700 (epoch 37.444), train_loss = 3.21074990, grad/param norm = 3.3586e-01, time/batch = 0.4390s	
2023/2700 (epoch 37.463), train_loss = 3.25426560, grad/param norm = 3.6639e-01, time/batch = 0.4630s	
2024/2700 (epoch 37.481), train_loss = 3.33221381, grad/param norm = 3.7839e-01, time/batch = 0.4597s	
2025/2700 (epoch 37.500), train_loss = 3.38441967, grad/param norm = 5.0795e-01, time/batch = 0.4220s	
2026/2700 (epoch 37.519), train_loss = 3.33657063, grad/param norm = 4.7801e-01, time/batch = 0.3643s	
2027/2700 (epoch 37.537), train_loss = 3.34071208, grad/param norm = 5.3712e-01, time/batch = 0.3421s	
2028/2700 (epoch 37.556), train_loss = 3.28123809, grad/param norm = 5.0817e-01, time/batch = 0.3726s	
2029/2700 (epoch 37.574), train_loss = 3.24348895, grad/param norm = 4.4797e-01, time/batch = 0.4195s	
2030/2700 (epoch 37.593), train_loss = 3.24279868, grad/param norm = 4.6227e-01, time/batch = 0.4663s	
2031/2700 (epoch 37.611), train_loss = 3.17590386, grad/param norm = 3.5603e-01, time/batch = 0.4388s	
2032/2700 (epoch 37.630), train_loss = 3.21971291, grad/param norm = 3.9392e-01, time/batch = 0.4090s	
2033/2700 (epoch 37.648), train_loss = 3.29154006, grad/param norm = 4.5455e-01, time/batch = 0.4016s	
2034/2700 (epoch 37.667), train_loss = 3.22527613, grad/param norm = 4.1626e-01, time/batch = 0.4320s	
2035/2700 (epoch 37.685), train_loss = 3.22086719, grad/param norm = 4.0472e-01, time/batch = 0.4634s	
2036/2700 (epoch 37.704), train_loss = 3.19181724, grad/param norm = 4.7765e-01, time/batch = 0.4621s	
2037/2700 (epoch 37.722), train_loss = 3.18348431, grad/param norm = 4.3195e-01, time/batch = 0.4195s	
2038/2700 (epoch 37.741), train_loss = 3.32492035, grad/param norm = 5.8831e-01, time/batch = 0.3735s	
2039/2700 (epoch 37.759), train_loss = 3.27678359, grad/param norm = 5.8731e-01, time/batch = 0.3293s	
2040/2700 (epoch 37.778), train_loss = 3.26199908, grad/param norm = 4.8145e-01, time/batch = 0.4076s	
2041/2700 (epoch 37.796), train_loss = 3.24784799, grad/param norm = 4.5152e-01, time/batch = 0.4268s	
2042/2700 (epoch 37.815), train_loss = 3.20707976, grad/param norm = 3.6370e-01, time/batch = 0.4185s	
2043/2700 (epoch 37.833), train_loss = 3.23727325, grad/param norm = 3.7465e-01, time/batch = 0.4612s	
2044/2700 (epoch 37.852), train_loss = 3.22491048, grad/param norm = 3.7651e-01, time/batch = 0.3901s	
2045/2700 (epoch 37.870), train_loss = 3.22226810, grad/param norm = 3.9625e-01, time/batch = 0.4078s	
2046/2700 (epoch 37.889), train_loss = 3.26870710, grad/param norm = 4.4980e-01, time/batch = 0.4486s	
2047/2700 (epoch 37.907), train_loss = 3.31640292, grad/param norm = 4.8494e-01, time/batch = 0.4639s	
2048/2700 (epoch 37.926), train_loss = 3.26068018, grad/param norm = 4.6635e-01, time/batch = 0.4554s	
2049/2700 (epoch 37.944), train_loss = 3.26782343, grad/param norm = 4.2158e-01, time/batch = 0.3923s	
2050/2700 (epoch 37.963), train_loss = 3.35168606, grad/param norm = 4.4362e-01, time/batch = 0.4100s	
2051/2700 (epoch 37.981), train_loss = 3.41335246, grad/param norm = 4.6419e-01, time/batch = 0.3889s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2052/2700 (epoch 38.000), train_loss = 3.30892181, grad/param norm = 4.4868e-01, time/batch = 0.3937s	
2053/2700 (epoch 38.019), train_loss = 3.25097847, grad/param norm = 4.6341e-01, time/batch = 0.3815s	
2054/2700 (epoch 38.037), train_loss = 3.26613532, grad/param norm = 4.3375e-01, time/batch = 0.4406s	
2055/2700 (epoch 38.056), train_loss = 3.26585098, grad/param norm = 3.7648e-01, time/batch = 0.4525s	
2056/2700 (epoch 38.074), train_loss = 3.29570430, grad/param norm = 4.3209e-01, time/batch = 0.3831s	
2057/2700 (epoch 38.093), train_loss = 3.30451004, grad/param norm = 4.7872e-01, time/batch = 0.4041s	
2058/2700 (epoch 38.111), train_loss = 3.27689974, grad/param norm = 4.7347e-01, time/batch = 0.4437s	
2059/2700 (epoch 38.130), train_loss = 3.29057258, grad/param norm = 4.0760e-01, time/batch = 0.4366s	
2060/2700 (epoch 38.148), train_loss = 3.25385409, grad/param norm = 4.3024e-01, time/batch = 0.4627s	
2061/2700 (epoch 38.167), train_loss = 3.26660017, grad/param norm = 5.1165e-01, time/batch = 0.4516s	
2062/2700 (epoch 38.185), train_loss = 3.25117314, grad/param norm = 4.1492e-01, time/batch = 0.4100s	
2063/2700 (epoch 38.204), train_loss = 3.18589185, grad/param norm = 4.7526e-01, time/batch = 0.3885s	
2064/2700 (epoch 38.222), train_loss = 3.15849806, grad/param norm = 5.1019e-01, time/batch = 0.3586s	
2065/2700 (epoch 38.241), train_loss = 3.17504041, grad/param norm = 4.4061e-01, time/batch = 0.4164s	
2066/2700 (epoch 38.259), train_loss = 3.21210562, grad/param norm = 4.8994e-01, time/batch = 0.4303s	
2067/2700 (epoch 38.278), train_loss = 3.28607014, grad/param norm = 4.8794e-01, time/batch = 0.4240s	
2068/2700 (epoch 38.296), train_loss = 3.29174708, grad/param norm = 5.1819e-01, time/batch = 0.3611s	
2069/2700 (epoch 38.315), train_loss = 3.26760548, grad/param norm = 5.0242e-01, time/batch = 0.3790s	
2070/2700 (epoch 38.333), train_loss = 3.34439615, grad/param norm = 4.3458e-01, time/batch = 0.4514s	
2071/2700 (epoch 38.352), train_loss = 3.35518962, grad/param norm = 4.4426e-01, time/batch = 0.4538s	
2072/2700 (epoch 38.370), train_loss = 3.29676016, grad/param norm = 4.1470e-01, time/batch = 0.4587s	
2073/2700 (epoch 38.389), train_loss = 3.25861788, grad/param norm = 3.7343e-01, time/batch = 0.4645s	
2074/2700 (epoch 38.407), train_loss = 3.28650432, grad/param norm = 3.7501e-01, time/batch = 0.4273s	
2075/2700 (epoch 38.426), train_loss = 3.28213461, grad/param norm = 3.4282e-01, time/batch = 0.3892s	
2076/2700 (epoch 38.444), train_loss = 3.21039478, grad/param norm = 3.3280e-01, time/batch = 0.3831s	
2077/2700 (epoch 38.463), train_loss = 3.25311319, grad/param norm = 3.6448e-01, time/batch = 0.4016s	
2078/2700 (epoch 38.481), train_loss = 3.33124350, grad/param norm = 3.7863e-01, time/batch = 0.4122s	
2079/2700 (epoch 38.500), train_loss = 3.38180623, grad/param norm = 5.0584e-01, time/batch = 0.3843s	
2080/2700 (epoch 38.519), train_loss = 3.33578506, grad/param norm = 4.7466e-01, time/batch = 0.3720s	
2081/2700 (epoch 38.537), train_loss = 3.33910201, grad/param norm = 5.3178e-01, time/batch = 0.4008s	
2082/2700 (epoch 38.556), train_loss = 3.28039845, grad/param norm = 5.0220e-01, time/batch = 0.4537s	
2083/2700 (epoch 38.574), train_loss = 3.24218503, grad/param norm = 4.4339e-01, time/batch = 0.4678s	
2084/2700 (epoch 38.593), train_loss = 3.24177257, grad/param norm = 4.5504e-01, time/batch = 0.4663s	
2085/2700 (epoch 38.611), train_loss = 3.17551434, grad/param norm = 3.4976e-01, time/batch = 0.4354s	
2086/2700 (epoch 38.630), train_loss = 3.21960468, grad/param norm = 3.9044e-01, time/batch = 0.3925s	
2087/2700 (epoch 38.648), train_loss = 3.29003425, grad/param norm = 4.5017e-01, time/batch = 0.3830s	
2088/2700 (epoch 38.667), train_loss = 3.22349443, grad/param norm = 4.1092e-01, time/batch = 0.3930s	
2089/2700 (epoch 38.685), train_loss = 3.22010091, grad/param norm = 4.0118e-01, time/batch = 0.4054s	
2090/2700 (epoch 38.704), train_loss = 3.19066480, grad/param norm = 4.7656e-01, time/batch = 0.4384s	
2091/2700 (epoch 38.722), train_loss = 3.18215029, grad/param norm = 4.2740e-01, time/batch = 0.3946s	
2092/2700 (epoch 38.741), train_loss = 3.32159037, grad/param norm = 5.7759e-01, time/batch = 0.3642s	
2093/2700 (epoch 38.759), train_loss = 3.27496286, grad/param norm = 5.7364e-01, time/batch = 0.4266s	
2094/2700 (epoch 38.778), train_loss = 3.25985109, grad/param norm = 4.7093e-01, time/batch = 0.4612s	
2095/2700 (epoch 38.796), train_loss = 3.24691290, grad/param norm = 4.4244e-01, time/batch = 0.4705s	
2096/2700 (epoch 38.815), train_loss = 3.20585663, grad/param norm = 3.5669e-01, time/batch = 0.4579s	
2097/2700 (epoch 38.833), train_loss = 3.23562787, grad/param norm = 3.7073e-01, time/batch = 0.4260s	
2098/2700 (epoch 38.852), train_loss = 3.22373984, grad/param norm = 3.7256e-01, time/batch = 0.3957s	
2099/2700 (epoch 38.870), train_loss = 3.22105017, grad/param norm = 3.9207e-01, time/batch = 0.3741s	
2100/2700 (epoch 38.889), train_loss = 3.26709879, grad/param norm = 4.4406e-01, time/batch = 0.4371s	
2101/2700 (epoch 38.907), train_loss = 3.31462853, grad/param norm = 4.7802e-01, time/batch = 0.4386s	
2102/2700 (epoch 38.926), train_loss = 3.25897737, grad/param norm = 4.5729e-01, time/batch = 0.4285s	
2103/2700 (epoch 38.944), train_loss = 3.26642315, grad/param norm = 4.1426e-01, time/batch = 0.4247s	
2104/2700 (epoch 38.963), train_loss = 3.35105917, grad/param norm = 4.3618e-01, time/batch = 0.3326s	
2105/2700 (epoch 38.981), train_loss = 3.41198472, grad/param norm = 4.5813e-01, time/batch = 0.3894s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2106/2700 (epoch 39.000), train_loss = 3.30718158, grad/param norm = 4.4239e-01, time/batch = 0.4509s	
2107/2700 (epoch 39.019), train_loss = 3.25019189, grad/param norm = 4.5691e-01, time/batch = 0.4521s	
2108/2700 (epoch 39.037), train_loss = 3.26391054, grad/param norm = 4.2569e-01, time/batch = 0.4645s	
2109/2700 (epoch 39.056), train_loss = 3.26564661, grad/param norm = 3.7524e-01, time/batch = 0.4120s	
2110/2700 (epoch 39.074), train_loss = 3.29506259, grad/param norm = 4.3634e-01, time/batch = 0.4194s	
2111/2700 (epoch 39.093), train_loss = 3.30342567, grad/param norm = 4.8074e-01, time/batch = 0.3983s	
2112/2700 (epoch 39.111), train_loss = 3.27639302, grad/param norm = 4.7183e-01, time/batch = 0.4081s	
2113/2700 (epoch 39.130), train_loss = 3.28918331, grad/param norm = 4.0299e-01, time/batch = 0.4234s	
2114/2700 (epoch 39.148), train_loss = 3.25288798, grad/param norm = 4.2261e-01, time/batch = 0.4205s	
2115/2700 (epoch 39.167), train_loss = 3.26533958, grad/param norm = 5.0424e-01, time/batch = 0.4201s	
2116/2700 (epoch 39.185), train_loss = 3.25012784, grad/param norm = 4.0744e-01, time/batch = 0.3388s	
2117/2700 (epoch 39.204), train_loss = 3.18496354, grad/param norm = 4.6542e-01, time/batch = 0.3902s	
2118/2700 (epoch 39.222), train_loss = 3.15772202, grad/param norm = 4.9767e-01, time/batch = 0.4242s	
2119/2700 (epoch 39.241), train_loss = 3.17387081, grad/param norm = 4.1823e-01, time/batch = 0.4563s	
2120/2700 (epoch 39.259), train_loss = 3.21108411, grad/param norm = 4.6205e-01, time/batch = 0.4703s	
2121/2700 (epoch 39.278), train_loss = 3.28451993, grad/param norm = 4.6870e-01, time/batch = 0.4530s	
2122/2700 (epoch 39.296), train_loss = 3.29033442, grad/param norm = 5.0450e-01, time/batch = 0.4021s	
2123/2700 (epoch 39.315), train_loss = 3.26686515, grad/param norm = 4.9637e-01, time/batch = 0.3511s	
2124/2700 (epoch 39.333), train_loss = 3.34393071, grad/param norm = 4.3406e-01, time/batch = 0.3834s	
2125/2700 (epoch 39.352), train_loss = 3.35464597, grad/param norm = 4.4355e-01, time/batch = 0.4222s	
2126/2700 (epoch 39.370), train_loss = 3.29634472, grad/param norm = 4.1149e-01, time/batch = 0.4402s	
2127/2700 (epoch 39.389), train_loss = 3.25806545, grad/param norm = 3.7062e-01, time/batch = 0.4507s	
2128/2700 (epoch 39.407), train_loss = 3.28566184, grad/param norm = 3.7144e-01, time/batch = 0.3876s	
2129/2700 (epoch 39.426), train_loss = 3.28143032, grad/param norm = 3.4198e-01, time/batch = 0.3599s	
2130/2700 (epoch 39.444), train_loss = 3.21008641, grad/param norm = 3.2993e-01, time/batch = 0.4693s	
2131/2700 (epoch 39.463), train_loss = 3.25257782, grad/param norm = 3.6066e-01, time/batch = 0.4662s	
2132/2700 (epoch 39.481), train_loss = 3.33043943, grad/param norm = 3.7668e-01, time/batch = 0.4632s	
2133/2700 (epoch 39.500), train_loss = 3.38076087, grad/param norm = 5.0202e-01, time/batch = 0.4479s	
2134/2700 (epoch 39.519), train_loss = 3.33485949, grad/param norm = 4.6882e-01, time/batch = 0.3898s	
2135/2700 (epoch 39.537), train_loss = 3.33818760, grad/param norm = 5.2607e-01, time/batch = 0.3415s	
2136/2700 (epoch 39.556), train_loss = 3.27939581, grad/param norm = 4.9522e-01, time/batch = 0.3800s	
2137/2700 (epoch 39.574), train_loss = 3.24131651, grad/param norm = 4.3761e-01, time/batch = 0.4067s	
2138/2700 (epoch 39.593), train_loss = 3.24115388, grad/param norm = 4.4858e-01, time/batch = 0.4549s	
2139/2700 (epoch 39.611), train_loss = 3.17524221, grad/param norm = 3.4439e-01, time/batch = 0.4457s	
2140/2700 (epoch 39.630), train_loss = 3.21927351, grad/param norm = 3.8742e-01, time/batch = 0.3653s	
2141/2700 (epoch 39.648), train_loss = 3.28889194, grad/param norm = 4.4511e-01, time/batch = 0.4234s	
2142/2700 (epoch 39.667), train_loss = 3.22233004, grad/param norm = 4.0464e-01, time/batch = 0.4478s	
2143/2700 (epoch 39.685), train_loss = 3.21954226, grad/param norm = 3.9683e-01, time/batch = 0.4641s	
2144/2700 (epoch 39.704), train_loss = 3.19006747, grad/param norm = 4.7331e-01, time/batch = 0.4376s	
2145/2700 (epoch 39.722), train_loss = 3.18124377, grad/param norm = 4.2102e-01, time/batch = 0.3956s	
2146/2700 (epoch 39.741), train_loss = 3.31999453, grad/param norm = 5.7050e-01, time/batch = 0.3284s	
2147/2700 (epoch 39.759), train_loss = 3.27369192, grad/param norm = 5.6371e-01, time/batch = 0.3595s	
2148/2700 (epoch 39.778), train_loss = 3.25861285, grad/param norm = 4.6140e-01, time/batch = 0.4184s	
2149/2700 (epoch 39.796), train_loss = 3.24608158, grad/param norm = 4.3351e-01, time/batch = 0.4441s	
2150/2700 (epoch 39.815), train_loss = 3.20499220, grad/param norm = 3.5003e-01, time/batch = 0.4692s	
2151/2700 (epoch 39.833), train_loss = 3.23468002, grad/param norm = 3.6693e-01, time/batch = 0.4507s	
2152/2700 (epoch 39.852), train_loss = 3.22292673, grad/param norm = 3.6833e-01, time/batch = 0.4063s	
2153/2700 (epoch 39.870), train_loss = 3.22026659, grad/param norm = 3.8779e-01, time/batch = 0.4079s	
2154/2700 (epoch 39.889), train_loss = 3.26603920, grad/param norm = 4.3814e-01, time/batch = 0.4361s	
2155/2700 (epoch 39.907), train_loss = 3.31353097, grad/param norm = 4.7090e-01, time/batch = 0.4600s	
2156/2700 (epoch 39.926), train_loss = 3.25787370, grad/param norm = 4.4882e-01, time/batch = 0.4292s	
2157/2700 (epoch 39.944), train_loss = 3.26546711, grad/param norm = 4.0738e-01, time/batch = 0.3753s	
2158/2700 (epoch 39.963), train_loss = 3.35044503, grad/param norm = 4.2901e-01, time/batch = 0.3355s	
2159/2700 (epoch 39.981), train_loss = 3.41124498, grad/param norm = 4.5277e-01, time/batch = 0.3350s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2160/2700 (epoch 40.000), train_loss = 3.30611617, grad/param norm = 4.3650e-01, time/batch = 0.4380s	
2161/2700 (epoch 40.019), train_loss = 3.24942365, grad/param norm = 4.5106e-01, time/batch = 0.4476s	
2162/2700 (epoch 40.037), train_loss = 3.26241636, grad/param norm = 4.1859e-01, time/batch = 0.4588s	
2163/2700 (epoch 40.056), train_loss = 3.26544804, grad/param norm = 3.7475e-01, time/batch = 0.4628s	
2164/2700 (epoch 40.074), train_loss = 3.29462204, grad/param norm = 4.4088e-01, time/batch = 0.4054s	
2165/2700 (epoch 40.093), train_loss = 3.30258074, grad/param norm = 4.8227e-01, time/batch = 0.4104s	
2166/2700 (epoch 40.111), train_loss = 3.27585844, grad/param norm = 4.6858e-01, time/batch = 0.4396s	
2167/2700 (epoch 40.130), train_loss = 3.28812072, grad/param norm = 3.9734e-01, time/batch = 0.4612s	
2168/2700 (epoch 40.148), train_loss = 3.25225160, grad/param norm = 4.1468e-01, time/batch = 0.4353s	
2169/2700 (epoch 40.167), train_loss = 3.26424996, grad/param norm = 4.9564e-01, time/batch = 0.3509s	
2170/2700 (epoch 40.185), train_loss = 3.24929260, grad/param norm = 3.9963e-01, time/batch = 0.3580s	
2171/2700 (epoch 40.204), train_loss = 3.18418364, grad/param norm = 4.5538e-01, time/batch = 0.3579s	
2172/2700 (epoch 40.222), train_loss = 3.15690038, grad/param norm = 4.8586e-01, time/batch = 0.4024s	
2173/2700 (epoch 40.241), train_loss = 3.17293581, grad/param norm = 3.9852e-01, time/batch = 0.4393s	
2174/2700 (epoch 40.259), train_loss = 3.21021489, grad/param norm = 4.3789e-01, time/batch = 0.4676s	
2175/2700 (epoch 40.278), train_loss = 3.28326740, grad/param norm = 4.5109e-01, time/batch = 0.4634s	
2176/2700 (epoch 40.296), train_loss = 3.28918656, grad/param norm = 4.9001e-01, time/batch = 0.3847s	
2177/2700 (epoch 40.315), train_loss = 3.26612350, grad/param norm = 4.8940e-01, time/batch = 0.4215s	
2178/2700 (epoch 40.333), train_loss = 3.34345998, grad/param norm = 4.3329e-01, time/batch = 0.4587s	
2179/2700 (epoch 40.352), train_loss = 3.35413659, grad/param norm = 4.4286e-01, time/batch = 0.4233s	
2180/2700 (epoch 40.370), train_loss = 3.29581289, grad/param norm = 4.0846e-01, time/batch = 0.4400s	
2181/2700 (epoch 40.389), train_loss = 3.25758203, grad/param norm = 3.6792e-01, time/batch = 0.4125s	
2182/2700 (epoch 40.407), train_loss = 3.28498214, grad/param norm = 3.6806e-01, time/batch = 0.3384s	
2183/2700 (epoch 40.426), train_loss = 3.28092265, grad/param norm = 3.4125e-01, time/batch = 0.3425s	
2184/2700 (epoch 40.444), train_loss = 3.20978704, grad/param norm = 3.2728e-01, time/batch = 0.3847s	
2185/2700 (epoch 40.463), train_loss = 3.25213632, grad/param norm = 3.5702e-01, time/batch = 0.4580s	
2186/2700 (epoch 40.481), train_loss = 3.32984024, grad/param norm = 3.7474e-01, time/batch = 0.4645s	
2187/2700 (epoch 40.500), train_loss = 3.37988248, grad/param norm = 4.9792e-01, time/batch = 0.4600s	
2188/2700 (epoch 40.519), train_loss = 3.33406134, grad/param norm = 4.6301e-01, time/batch = 0.3756s	
2189/2700 (epoch 40.537), train_loss = 3.33744637, grad/param norm = 5.2048e-01, time/batch = 0.3883s	
2190/2700 (epoch 40.556), train_loss = 3.27843871, grad/param norm = 4.8843e-01, time/batch = 0.4644s	
2191/2700 (epoch 40.574), train_loss = 3.24062139, grad/param norm = 4.3206e-01, time/batch = 0.4631s	
2192/2700 (epoch 40.593), train_loss = 3.24049369, grad/param norm = 4.4233e-01, time/batch = 0.4472s	
2193/2700 (epoch 40.611), train_loss = 3.17498421, grad/param norm = 3.3944e-01, time/batch = 0.3915s	
2194/2700 (epoch 40.630), train_loss = 3.21894219, grad/param norm = 3.8449e-01, time/batch = 0.3488s	
2195/2700 (epoch 40.648), train_loss = 3.28790096, grad/param norm = 4.4010e-01, time/batch = 0.3140s	
2196/2700 (epoch 40.667), train_loss = 3.22143264, grad/param norm = 3.9859e-01, time/batch = 0.4242s	
2197/2700 (epoch 40.685), train_loss = 3.21903688, grad/param norm = 3.9285e-01, time/batch = 0.4590s	
2198/2700 (epoch 40.704), train_loss = 3.18957371, grad/param norm = 4.7024e-01, time/batch = 0.4648s	
2199/2700 (epoch 40.722), train_loss = 3.18044535, grad/param norm = 4.1472e-01, time/batch = 0.3977s	
2200/2700 (epoch 40.741), train_loss = 3.31893714, grad/param norm = 5.6344e-01, time/batch = 0.3669s	
2201/2700 (epoch 40.759), train_loss = 3.27257801, grad/param norm = 5.5388e-01, time/batch = 0.4395s	
2202/2700 (epoch 40.778), train_loss = 3.25763975, grad/param norm = 4.5225e-01, time/batch = 0.4621s	
2203/2700 (epoch 40.796), train_loss = 3.24527945, grad/param norm = 4.2502e-01, time/batch = 0.4493s	
2204/2700 (epoch 40.815), train_loss = 3.20421699, grad/param norm = 3.4393e-01, time/batch = 0.4168s	
2205/2700 (epoch 40.833), train_loss = 3.23398084, grad/param norm = 3.6353e-01, time/batch = 0.3712s	
2206/2700 (epoch 40.852), train_loss = 3.22222468, grad/param norm = 3.6430e-01, time/batch = 0.3115s	
2207/2700 (epoch 40.870), train_loss = 3.21961102, grad/param norm = 3.8377e-01, time/batch = 0.3688s	
2208/2700 (epoch 40.889), train_loss = 3.26515606, grad/param norm = 4.3254e-01, time/batch = 0.3717s	
2209/2700 (epoch 40.907), train_loss = 3.31264195, grad/param norm = 4.6423e-01, time/batch = 0.4425s	
2210/2700 (epoch 40.926), train_loss = 3.25694439, grad/param norm = 4.4099e-01, time/batch = 0.4481s	
2211/2700 (epoch 40.944), train_loss = 3.26469088, grad/param norm = 4.0107e-01, time/batch = 0.4213s	
2212/2700 (epoch 40.963), train_loss = 3.34979175, grad/param norm = 4.2230e-01, time/batch = 0.3574s	
2213/2700 (epoch 40.981), train_loss = 3.41065918, grad/param norm = 4.4800e-01, time/batch = 0.4637s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2214/2700 (epoch 41.000), train_loss = 3.30526239, grad/param norm = 4.3099e-01, time/batch = 0.4430s	
2215/2700 (epoch 41.019), train_loss = 3.24867840, grad/param norm = 4.4575e-01, time/batch = 0.3930s	
2216/2700 (epoch 41.037), train_loss = 3.26142245, grad/param norm = 4.1218e-01, time/batch = 0.3322s	
2217/2700 (epoch 41.056), train_loss = 3.26523301, grad/param norm = 3.7480e-01, time/batch = 0.3578s	
2218/2700 (epoch 41.074), train_loss = 3.29424432, grad/param norm = 4.4521e-01, time/batch = 0.4020s	
2219/2700 (epoch 41.093), train_loss = 3.30183823, grad/param norm = 4.8275e-01, time/batch = 0.4135s	
2220/2700 (epoch 41.111), train_loss = 3.27530992, grad/param norm = 4.6376e-01, time/batch = 0.4670s	
2221/2700 (epoch 41.130), train_loss = 3.28722006, grad/param norm = 3.9107e-01, time/batch = 0.4606s	
2222/2700 (epoch 41.148), train_loss = 3.25172476, grad/param norm = 4.0714e-01, time/batch = 0.4204s	
2223/2700 (epoch 41.167), train_loss = 3.26325330, grad/param norm = 4.8655e-01, time/batch = 0.3980s	
2224/2700 (epoch 41.185), train_loss = 3.24854467, grad/param norm = 3.9196e-01, time/batch = 0.4151s	
2225/2700 (epoch 41.204), train_loss = 3.18348344, grad/param norm = 4.4572e-01, time/batch = 0.4546s	
2226/2700 (epoch 41.222), train_loss = 3.15612108, grad/param norm = 4.7491e-01, time/batch = 0.4320s	
2227/2700 (epoch 41.241), train_loss = 3.17215665, grad/param norm = 3.8154e-01, time/batch = 0.3538s	
2228/2700 (epoch 41.259), train_loss = 3.20944865, grad/param norm = 4.1745e-01, time/batch = 0.3345s	
2229/2700 (epoch 41.278), train_loss = 3.28231607, grad/param norm = 4.3516e-01, time/batch = 0.3637s	
2230/2700 (epoch 41.296), train_loss = 3.28816453, grad/param norm = 4.7469e-01, time/batch = 0.4430s	
2231/2700 (epoch 41.315), train_loss = 3.26533373, grad/param norm = 4.8113e-01, time/batch = 0.4545s	
2232/2700 (epoch 41.333), train_loss = 3.34300079, grad/param norm = 4.3192e-01, time/batch = 0.4642s	
2233/2700 (epoch 41.352), train_loss = 3.35362864, grad/param norm = 4.4206e-01, time/batch = 0.4265s	
2234/2700 (epoch 41.370), train_loss = 3.29524378, grad/param norm = 4.0555e-01, time/batch = 0.3975s	
2235/2700 (epoch 41.389), train_loss = 3.25713542, grad/param norm = 3.6534e-01, time/batch = 0.4185s	
2236/2700 (epoch 41.407), train_loss = 3.28436767, grad/param norm = 3.6484e-01, time/batch = 0.4437s	
2237/2700 (epoch 41.426), train_loss = 3.28049408, grad/param norm = 3.4065e-01, time/batch = 0.4452s	
2238/2700 (epoch 41.444), train_loss = 3.20951867, grad/param norm = 3.2484e-01, time/batch = 0.4099s	
2239/2700 (epoch 41.463), train_loss = 3.25171900, grad/param norm = 3.5358e-01, time/batch = 0.2732s	
2240/2700 (epoch 41.481), train_loss = 3.32935038, grad/param norm = 3.7289e-01, time/batch = 0.4186s	
2241/2700 (epoch 41.500), train_loss = 3.37905001, grad/param norm = 4.9365e-01, time/batch = 0.3992s	
2242/2700 (epoch 41.519), train_loss = 3.33335648, grad/param norm = 4.5736e-01, time/batch = 0.4556s	
2243/2700 (epoch 41.537), train_loss = 3.33677910, grad/param norm = 5.1501e-01, time/batch = 0.4640s	
2244/2700 (epoch 41.556), train_loss = 3.27751894, grad/param norm = 4.8179e-01, time/batch = 0.4276s	
2245/2700 (epoch 41.574), train_loss = 3.24001820, grad/param norm = 4.2675e-01, time/batch = 0.3934s	
2246/2700 (epoch 41.593), train_loss = 3.23980021, grad/param norm = 4.3624e-01, time/batch = 0.4144s	
2247/2700 (epoch 41.611), train_loss = 3.17473716, grad/param norm = 3.3490e-01, time/batch = 0.4547s	
2248/2700 (epoch 41.630), train_loss = 3.21862238, grad/param norm = 3.8163e-01, time/batch = 0.4529s	
2249/2700 (epoch 41.648), train_loss = 3.28699148, grad/param norm = 4.3515e-01, time/batch = 0.3294s	
2250/2700 (epoch 41.667), train_loss = 3.22067765, grad/param norm = 3.9278e-01, time/batch = 0.3908s	
2251/2700 (epoch 41.685), train_loss = 3.21856271, grad/param norm = 3.8927e-01, time/batch = 0.3927s	
2252/2700 (epoch 41.704), train_loss = 3.18912188, grad/param norm = 4.6743e-01, time/batch = 0.3951s	
2253/2700 (epoch 41.722), train_loss = 3.17971639, grad/param norm = 4.0856e-01, time/batch = 0.4498s	
2254/2700 (epoch 41.741), train_loss = 3.31808863, grad/param norm = 5.5631e-01, time/batch = 0.4390s	
2255/2700 (epoch 41.759), train_loss = 3.27152995, grad/param norm = 5.4409e-01, time/batch = 0.4078s	
2256/2700 (epoch 41.778), train_loss = 3.25678341, grad/param norm = 4.4347e-01, time/batch = 0.3958s	
2257/2700 (epoch 41.796), train_loss = 3.24451532, grad/param norm = 4.1695e-01, time/batch = 0.4301s	
2258/2700 (epoch 41.815), train_loss = 3.20349331, grad/param norm = 3.3839e-01, time/batch = 0.4595s	
2259/2700 (epoch 41.833), train_loss = 3.23340133, grad/param norm = 3.6049e-01, time/batch = 0.4143s	
2260/2700 (epoch 41.852), train_loss = 3.22159020, grad/param norm = 3.6044e-01, time/batch = 0.4496s	
2261/2700 (epoch 41.870), train_loss = 3.21902252, grad/param norm = 3.7999e-01, time/batch = 0.3901s	
2262/2700 (epoch 41.889), train_loss = 3.26435685, grad/param norm = 4.2720e-01, time/batch = 0.3677s	
2263/2700 (epoch 41.907), train_loss = 3.31186165, grad/param norm = 4.5797e-01, time/batch = 0.3716s	
2264/2700 (epoch 41.926), train_loss = 3.25611736, grad/param norm = 4.3372e-01, time/batch = 0.4186s	
2265/2700 (epoch 41.944), train_loss = 3.26400536, grad/param norm = 3.9526e-01, time/batch = 0.4375s	
2266/2700 (epoch 41.963), train_loss = 3.34913369, grad/param norm = 4.1599e-01, time/batch = 0.4263s	
2267/2700 (epoch 41.981), train_loss = 3.41014597, grad/param norm = 4.4374e-01, time/batch = 0.3947s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2268/2700 (epoch 42.000), train_loss = 3.30450606, grad/param norm = 4.2578e-01, time/batch = 0.3915s	
2269/2700 (epoch 42.019), train_loss = 3.24795384, grad/param norm = 4.4092e-01, time/batch = 0.4075s	
2270/2700 (epoch 42.037), train_loss = 3.26069634, grad/param norm = 4.0635e-01, time/batch = 0.4618s	
2271/2700 (epoch 42.056), train_loss = 3.26501115, grad/param norm = 3.7515e-01, time/batch = 0.4549s	
2272/2700 (epoch 42.074), train_loss = 3.29388259, grad/param norm = 4.4897e-01, time/batch = 0.4557s	
2273/2700 (epoch 42.093), train_loss = 3.30113357, grad/param norm = 4.8193e-01, time/batch = 0.3675s	
2274/2700 (epoch 42.111), train_loss = 3.27474120, grad/param norm = 4.5757e-01, time/batch = 0.3766s	
2275/2700 (epoch 42.130), train_loss = 3.28641322, grad/param norm = 3.8456e-01, time/batch = 0.4010s	
2276/2700 (epoch 42.148), train_loss = 3.25125767, grad/param norm = 4.0035e-01, time/batch = 0.4266s	
2277/2700 (epoch 42.167), train_loss = 3.26232724, grad/param norm = 4.7755e-01, time/batch = 0.4169s	
2278/2700 (epoch 42.185), train_loss = 3.24786428, grad/param norm = 3.8486e-01, time/batch = 0.3709s	
2279/2700 (epoch 42.204), train_loss = 3.18284275, grad/param norm = 4.3685e-01, time/batch = 0.3578s	
2280/2700 (epoch 42.222), train_loss = 3.15539744, grad/param norm = 4.6491e-01, time/batch = 0.4464s	
2281/2700 (epoch 42.241), train_loss = 3.17150040, grad/param norm = 3.6743e-01, time/batch = 0.4420s	
2282/2700 (epoch 42.259), train_loss = 3.20877606, grad/param norm = 4.0077e-01, time/batch = 0.4572s	
2283/2700 (epoch 42.278), train_loss = 3.28151595, grad/param norm = 4.2098e-01, time/batch = 0.4622s	
2284/2700 (epoch 42.296), train_loss = 3.28721337, grad/param norm = 4.5879e-01, time/batch = 0.4281s	
2285/2700 (epoch 42.315), train_loss = 3.26450050, grad/param norm = 4.7132e-01, time/batch = 0.3389s	
2286/2700 (epoch 42.333), train_loss = 3.34254029, grad/param norm = 4.2943e-01, time/batch = 0.4279s	
2287/2700 (epoch 42.352), train_loss = 3.35310470, grad/param norm = 4.4079e-01, time/batch = 0.4213s	
2288/2700 (epoch 42.370), train_loss = 3.29467455, grad/param norm = 4.0268e-01, time/batch = 0.4161s	
2289/2700 (epoch 42.389), train_loss = 3.25671718, grad/param norm = 3.6285e-01, time/batch = 0.3042s	
2290/2700 (epoch 42.407), train_loss = 3.28378922, grad/param norm = 3.6179e-01, time/batch = 0.4147s	
2291/2700 (epoch 42.426), train_loss = 3.28010588, grad/param norm = 3.4010e-01, time/batch = 0.4200s	
2292/2700 (epoch 42.444), train_loss = 3.20927911, grad/param norm = 3.2259e-01, time/batch = 0.4637s	
2293/2700 (epoch 42.463), train_loss = 3.25131637, grad/param norm = 3.5033e-01, time/batch = 0.4675s	
2294/2700 (epoch 42.481), train_loss = 3.32892231, grad/param norm = 3.7117e-01, time/batch = 0.4700s	
2295/2700 (epoch 42.500), train_loss = 3.37824194, grad/param norm = 4.8940e-01, time/batch = 0.4293s	
2296/2700 (epoch 42.519), train_loss = 3.33271803, grad/param norm = 4.5202e-01, time/batch = 0.3981s	
2297/2700 (epoch 42.537), train_loss = 3.33615452, grad/param norm = 5.0970e-01, time/batch = 0.3664s	
2298/2700 (epoch 42.556), train_loss = 3.27663672, grad/param norm = 4.7532e-01, time/batch = 0.4380s	
2299/2700 (epoch 42.574), train_loss = 3.23947068, grad/param norm = 4.2168e-01, time/batch = 0.3627s	
2300/2700 (epoch 42.593), train_loss = 3.23909679, grad/param norm = 4.3029e-01, time/batch = 0.3778s	
2301/2700 (epoch 42.611), train_loss = 3.17450520, grad/param norm = 3.3074e-01, time/batch = 0.3623s	
2302/2700 (epoch 42.630), train_loss = 3.21831571, grad/param norm = 3.7881e-01, time/batch = 0.4119s	
2303/2700 (epoch 42.648), train_loss = 3.28613656, grad/param norm = 4.3029e-01, time/batch = 0.4494s	
2304/2700 (epoch 42.667), train_loss = 3.22001124, grad/param norm = 3.8721e-01, time/batch = 0.4715s	
2305/2700 (epoch 42.685), train_loss = 3.21811255, grad/param norm = 3.8602e-01, time/batch = 0.4621s	
2306/2700 (epoch 42.704), train_loss = 3.18869309, grad/param norm = 4.6475e-01, time/batch = 0.4063s	
2307/2700 (epoch 42.722), train_loss = 3.17903908, grad/param norm = 4.0236e-01, time/batch = 0.4004s	
2308/2700 (epoch 42.741), train_loss = 3.31733787, grad/param norm = 5.4894e-01, time/batch = 0.4049s	
2309/2700 (epoch 42.759), train_loss = 3.27052266, grad/param norm = 5.3436e-01, time/batch = 0.3793s	
2310/2700 (epoch 42.778), train_loss = 3.25599953, grad/param norm = 4.3508e-01, time/batch = 0.4199s	
2311/2700 (epoch 42.796), train_loss = 3.24379503, grad/param norm = 4.0931e-01, time/batch = 0.3671s	
2312/2700 (epoch 42.815), train_loss = 3.20281044, grad/param norm = 3.3335e-01, time/batch = 0.3605s	
2313/2700 (epoch 42.833), train_loss = 3.23288963, grad/param norm = 3.5773e-01, time/batch = 0.4064s	
2314/2700 (epoch 42.852), train_loss = 3.22100590, grad/param norm = 3.5673e-01, time/batch = 0.4569s	
2315/2700 (epoch 42.870), train_loss = 3.21848120, grad/param norm = 3.7644e-01, time/batch = 0.4684s	
2316/2700 (epoch 42.889), train_loss = 3.26361070, grad/param norm = 4.2212e-01, time/batch = 0.4648s	
2317/2700 (epoch 42.907), train_loss = 3.31115301, grad/param norm = 4.5210e-01, time/batch = 0.4048s	
2318/2700 (epoch 42.926), train_loss = 3.25537076, grad/param norm = 4.2697e-01, time/batch = 0.3924s	
2319/2700 (epoch 42.944), train_loss = 3.26338008, grad/param norm = 3.8988e-01, time/batch = 0.3441s	
2320/2700 (epoch 42.963), train_loss = 3.34849514, grad/param norm = 4.1006e-01, time/batch = 0.4271s	
2321/2700 (epoch 42.981), train_loss = 3.40967968, grad/param norm = 4.3991e-01, time/batch = 0.4248s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
2322/2700 (epoch 43.000), train_loss = 3.30380330, grad/param norm = 4.2081e-01, time/batch = 0.3960s	
2323/2700 (epoch 43.019), train_loss = 3.24724886, grad/param norm = 4.3653e-01, time/batch = 0.3746s	
2324/2700 (epoch 43.037), train_loss = 3.26007363, grad/param norm = 4.0098e-01, time/batch = 0.4103s	
2325/2700 (epoch 43.056), train_loss = 3.26478934, grad/param norm = 3.7559e-01, time/batch = 0.4600s	
2326/2700 (epoch 43.074), train_loss = 3.29351980, grad/param norm = 4.5186e-01, time/batch = 0.4696s	
2327/2700 (epoch 43.093), train_loss = 3.30043851, grad/param norm = 4.7977e-01, time/batch = 0.4712s	
2328/2700 (epoch 43.111), train_loss = 3.27416334, grad/param norm = 4.5041e-01, time/batch = 0.4339s	
2329/2700 (epoch 43.130), train_loss = 3.28567765, grad/param norm = 3.7819e-01, time/batch = 0.3608s	
2330/2700 (epoch 43.148), train_loss = 3.25083754, grad/param norm = 3.9439e-01, time/batch = 0.4305s	
2331/2700 (epoch 43.167), train_loss = 3.26146404, grad/param norm = 4.6895e-01, time/batch = 0.4329s	
2332/2700 (epoch 43.185), train_loss = 3.24724239, grad/param norm = 3.7850e-01, time/batch = 0.4338s	
2333/2700 (epoch 43.204), train_loss = 3.18225342, grad/param norm = 4.2891e-01, time/batch = 0.4215s	
2334/2700 (epoch 43.222), train_loss = 3.15473015, grad/param norm = 4.5586e-01, time/batch = 0.3746s	
2335/2700 (epoch 43.241), train_loss = 3.17094401, grad/param norm = 3.5594e-01, time/batch = 0.3495s	
2336/2700 (epoch 43.259), train_loss = 3.20818900, grad/param norm = 3.8762e-01, time/batch = 0.3912s	
2337/2700 (epoch 43.278), train_loss = 3.28080609, grad/param norm = 4.0869e-01, time/batch = 0.4545s	
2338/2700 (epoch 43.296), train_loss = 3.28632455, grad/param norm = 4.4299e-01, time/batch = 0.4673s	
2339/2700 (epoch 43.315), train_loss = 3.26364280, grad/param norm = 4.6025e-01, time/batch = 0.4362s	
2340/2700 (epoch 43.333), train_loss = 3.34207171, grad/param norm = 4.2552e-01, time/batch = 0.4382s	
2341/2700 (epoch 43.352), train_loss = 3.35255970, grad/param norm = 4.3878e-01, time/batch = 0.4067s	
2342/2700 (epoch 43.370), train_loss = 3.29411486, grad/param norm = 3.9976e-01, time/batch = 0.3935s	
2343/2700 (epoch 43.389), train_loss = 3.25632118, grad/param norm = 3.6038e-01, time/batch = 0.4109s	
2344/2700 (epoch 43.407), train_loss = 3.28323802, grad/param norm = 3.5887e-01, time/batch = 0.4203s	
2345/2700 (epoch 43.426), train_loss = 3.27974267, grad/param norm = 3.3955e-01, time/batch = 0.4182s	
2346/2700 (epoch 43.444), train_loss = 3.20906401, grad/param norm = 3.2051e-01, time/batch = 0.3540s	
2347/2700 (epoch 43.463), train_loss = 3.25092829, grad/param norm = 3.4728e-01, time/batch = 0.3491s	
2348/2700 (epoch 43.481), train_loss = 3.32853668, grad/param norm = 3.6965e-01, time/batch = 0.4084s	
2349/2700 (epoch 43.500), train_loss = 3.37745596, grad/param norm = 4.8529e-01, time/batch = 0.4421s	
2350/2700 (epoch 43.519), train_loss = 3.33213258, grad/param norm = 4.4706e-01, time/batch = 0.4588s	
2351/2700 (epoch 43.537), train_loss = 3.33556103, grad/param norm = 5.0458e-01, time/batch = 0.4632s	
2352/2700 (epoch 43.556), train_loss = 3.27579194, grad/param norm = 4.6903e-01, time/batch = 0.4366s	
2353/2700 (epoch 43.574), train_loss = 3.23896205, grad/param norm = 4.1684e-01, time/batch = 0.3974s	
2354/2700 (epoch 43.593), train_loss = 3.23839754, grad/param norm = 4.2447e-01, time/batch = 0.3798s	
2355/2700 (epoch 43.611), train_loss = 3.17429125, grad/param norm = 3.2694e-01, time/batch = 0.3934s	
2356/2700 (epoch 43.630), train_loss = 3.21802136, grad/param norm = 3.7600e-01, time/batch = 0.4150s	
2357/2700 (epoch 43.648), train_loss = 3.28532301, grad/param norm = 4.2553e-01, time/batch = 0.4173s	
2358/2700 (epoch 43.667), train_loss = 3.21940806, grad/param norm = 3.8186e-01, time/batch = 0.3536s	
2359/2700 (epoch 43.685), train_loss = 3.21768583, grad/param norm = 3.8314e-01, time/batch = 0.3652s	
2360/2700 (epoch 43.704), train_loss = 3.18828340, grad/param norm = 4.6223e-01, time/batch = 0.4496s	
2361/2700 (epoch 43.722), train_loss = 3.17840622, grad/param norm = 3.9614e-01, time/batch = 0.4356s	
2362/2700 (epoch 43.741), train_loss = 3.31664312, grad/param norm = 5.4128e-01, time/batch = 0.4699s	
2363/2700 (epoch 43.759), train_loss = 3.26955019, grad/param norm = 5.2468e-01, time/batch = 0.4655s	
2364/2700 (epoch 43.778), train_loss = 3.25526951, grad/param norm = 4.2707e-01, time/batch = 0.4360s	
2365/2700 (epoch 43.796), train_loss = 3.24311731, grad/param norm = 4.0205e-01, time/batch = 0.3951s	
2366/2700 (epoch 43.815), train_loss = 3.20216480, grad/param norm = 3.2879e-01, time/batch = 0.3860s	
2367/2700 (epoch 43.833), train_loss = 3.23242313, grad/param norm = 3.5521e-01, time/batch = 0.3984s	
2368/2700 (epoch 43.852), train_loss = 3.22046180, grad/param norm = 3.5313e-01, time/batch = 0.4215s	
2369/2700 (epoch 43.870), train_loss = 3.21797776, grad/param norm = 3.7309e-01, time/batch = 0.4027s	
2370/2700 (epoch 43.889), train_loss = 3.26290432, grad/param norm = 4.1727e-01, time/batch = 0.4062s	
2371/2700 (epoch 43.907), train_loss = 3.31049700, grad/param norm = 4.4657e-01, time/batch = 0.3739s	
2372/2700 (epoch 43.926), train_loss = 3.25468952, grad/param norm = 4.2070e-01, time/batch = 0.4074s	
2373/2700 (epoch 43.944), train_loss = 3.26280087, grad/param norm = 3.8488e-01, time/batch = 0.4704s	
2374/2700 (epoch 43.963), train_loss = 3.34788709, grad/param norm = 4.0448e-01, time/batch = 0.4634s	
2375/2700 (epoch 43.981), train_loss = 3.40924802, grad/param norm = 4.3644e-01, time/batch = 0.4576s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
2376/2700 (epoch 44.000), train_loss = 3.30313441, grad/param norm = 4.1601e-01, time/batch = 0.4061s	
2377/2700 (epoch 44.019), train_loss = 3.24656154, grad/param norm = 4.3249e-01, time/batch = 0.3661s	
2378/2700 (epoch 44.037), train_loss = 3.25949776, grad/param norm = 3.9597e-01, time/batch = 0.3637s	
2379/2700 (epoch 44.056), train_loss = 3.26456973, grad/param norm = 3.7600e-01, time/batch = 0.4010s	
2380/2700 (epoch 44.074), train_loss = 3.29314966, grad/param norm = 4.5384e-01, time/batch = 0.4435s	
2381/2700 (epoch 44.093), train_loss = 3.29974449, grad/param norm = 4.7641e-01, time/batch = 0.4272s	
2382/2700 (epoch 44.111), train_loss = 3.27358823, grad/param norm = 4.4269e-01, time/batch = 0.3951s	
2383/2700 (epoch 44.130), train_loss = 3.28500151, grad/param norm = 3.7222e-01, time/batch = 0.3879s	
2384/2700 (epoch 44.148), train_loss = 3.25045266, grad/param norm = 3.8917e-01, time/batch = 0.4487s	
2385/2700 (epoch 44.167), train_loss = 3.26065718, grad/param norm = 4.6085e-01, time/batch = 0.4641s	
2386/2700 (epoch 44.185), train_loss = 3.24667032, grad/param norm = 3.7287e-01, time/batch = 0.4644s	
2387/2700 (epoch 44.204), train_loss = 3.18170882, grad/param norm = 4.2182e-01, time/batch = 0.4364s	
2388/2700 (epoch 44.222), train_loss = 3.15411699, grad/param norm = 4.4770e-01, time/batch = 0.3808s	
2389/2700 (epoch 44.241), train_loss = 3.17046688, grad/param norm = 3.4662e-01, time/batch = 0.3071s	
2390/2700 (epoch 44.259), train_loss = 3.20767098, grad/param norm = 3.7738e-01, time/batch = 0.4021s	
2391/2700 (epoch 44.278), train_loss = 3.28016870, grad/param norm = 3.9817e-01, time/batch = 0.4151s	
2392/2700 (epoch 44.296), train_loss = 3.28549896, grad/param norm = 4.2787e-01, time/batch = 0.4535s	
2393/2700 (epoch 44.315), train_loss = 3.26278466, grad/param norm = 4.4841e-01, time/batch = 0.4633s	
2394/2700 (epoch 44.333), train_loss = 3.34159618, grad/param norm = 4.2025e-01, time/batch = 0.3728s	
2395/2700 (epoch 44.352), train_loss = 3.35199371, grad/param norm = 4.3592e-01, time/batch = 0.4160s	
2396/2700 (epoch 44.370), train_loss = 3.29356567, grad/param norm = 3.9674e-01, time/batch = 0.4385s	
2397/2700 (epoch 44.389), train_loss = 3.25594246, grad/param norm = 3.5790e-01, time/batch = 0.4394s	
2398/2700 (epoch 44.407), train_loss = 3.28271120, grad/param norm = 3.5607e-01, time/batch = 0.4191s	
2399/2700 (epoch 44.426), train_loss = 3.27939632, grad/param norm = 3.3893e-01, time/batch = 0.3514s	
2400/2700 (epoch 44.444), train_loss = 3.20886957, grad/param norm = 3.1858e-01, time/batch = 0.3807s	
2401/2700 (epoch 44.463), train_loss = 3.25055436, grad/param norm = 3.4443e-01, time/batch = 0.3695s	
2402/2700 (epoch 44.481), train_loss = 3.32818343, grad/param norm = 3.6837e-01, time/batch = 0.4278s	
2403/2700 (epoch 44.500), train_loss = 3.37669670, grad/param norm = 4.8145e-01, time/batch = 0.4625s	
2404/2700 (epoch 44.519), train_loss = 3.33159398, grad/param norm = 4.4257e-01, time/batch = 0.4700s	
2405/2700 (epoch 44.537), train_loss = 3.33499305, grad/param norm = 4.9962e-01, time/batch = 0.4508s	
2406/2700 (epoch 44.556), train_loss = 3.27498440, grad/param norm = 4.6289e-01, time/batch = 0.3780s	
2407/2700 (epoch 44.574), train_loss = 3.23848393, grad/param norm = 4.1222e-01, time/batch = 0.4173s	
2408/2700 (epoch 44.593), train_loss = 3.23770996, grad/param norm = 4.1877e-01, time/batch = 0.4316s	
2409/2700 (epoch 44.611), train_loss = 3.17409647, grad/param norm = 3.2350e-01, time/batch = 0.4011s	
2410/2700 (epoch 44.630), train_loss = 3.21773803, grad/param norm = 3.7319e-01, time/batch = 0.4264s	
2411/2700 (epoch 44.648), train_loss = 3.28454479, grad/param norm = 4.2087e-01, time/batch = 0.3835s	
2412/2700 (epoch 44.667), train_loss = 3.21885405, grad/param norm = 3.7676e-01, time/batch = 0.3318s	
2413/2700 (epoch 44.685), train_loss = 3.21728104, grad/param norm = 3.8059e-01, time/batch = 0.3866s	
2414/2700 (epoch 44.704), train_loss = 3.18788915, grad/param norm = 4.5979e-01, time/batch = 0.4445s	
2415/2700 (epoch 44.722), train_loss = 3.17780845, grad/param norm = 3.8975e-01, time/batch = 0.4646s	
2416/2700 (epoch 44.741), train_loss = 3.31598155, grad/param norm = 5.3323e-01, time/batch = 0.4535s	
2417/2700 (epoch 44.759), train_loss = 3.26861152, grad/param norm = 5.1510e-01, time/batch = 0.4322s	
2418/2700 (epoch 44.778), train_loss = 3.25458500, grad/param norm = 4.1944e-01, time/batch = 0.3587s	
2419/2700 (epoch 44.796), train_loss = 3.24247990, grad/param norm = 3.9517e-01, time/batch = 0.4222s	
2420/2700 (epoch 44.815), train_loss = 3.20155357, grad/param norm = 3.2466e-01, time/batch = 0.4479s	
2421/2700 (epoch 44.833), train_loss = 3.23198980, grad/param norm = 3.5290e-01, time/batch = 0.4369s	
2422/2700 (epoch 44.852), train_loss = 3.21995155, grad/param norm = 3.4964e-01, time/batch = 0.3824s	
2423/2700 (epoch 44.870), train_loss = 3.21750639, grad/param norm = 3.6995e-01, time/batch = 0.3387s	
2424/2700 (epoch 44.889), train_loss = 3.26222991, grad/param norm = 4.1262e-01, time/batch = 0.3561s	
2425/2700 (epoch 44.907), train_loss = 3.30988204, grad/param norm = 4.4137e-01, time/batch = 0.4043s	
2426/2700 (epoch 44.926), train_loss = 3.25406362, grad/param norm = 4.1486e-01, time/batch = 0.4610s	
2427/2700 (epoch 44.944), train_loss = 3.26225919, grad/param norm = 3.8021e-01, time/batch = 0.4554s	
2428/2700 (epoch 44.963), train_loss = 3.34731281, grad/param norm = 3.9920e-01, time/batch = 0.4493s	
2429/2700 (epoch 44.981), train_loss = 3.40884422, grad/param norm = 4.3327e-01, time/batch = 0.3615s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
2430/2700 (epoch 45.000), train_loss = 3.30248963, grad/param norm = 4.1134e-01, time/batch = 0.4058s	
2431/2700 (epoch 45.019), train_loss = 3.24589121, grad/param norm = 4.2874e-01, time/batch = 0.4642s	
2432/2700 (epoch 45.037), train_loss = 3.25895047, grad/param norm = 3.9123e-01, time/batch = 0.4636s	
2433/2700 (epoch 45.056), train_loss = 3.26435298, grad/param norm = 3.7627e-01, time/batch = 0.4261s	
2434/2700 (epoch 45.074), train_loss = 3.29276947, grad/param norm = 4.5488e-01, time/batch = 0.3622s	
2435/2700 (epoch 45.093), train_loss = 3.29904932, grad/param norm = 4.7205e-01, time/batch = 0.3382s	
2436/2700 (epoch 45.111), train_loss = 3.27302677, grad/param norm = 4.3476e-01, time/batch = 0.3695s	
2437/2700 (epoch 45.130), train_loss = 3.28437776, grad/param norm = 3.6677e-01, time/batch = 0.4422s	
2438/2700 (epoch 45.148), train_loss = 3.25009573, grad/param norm = 3.8455e-01, time/batch = 0.4510s	
2439/2700 (epoch 45.167), train_loss = 3.25989997, grad/param norm = 4.5324e-01, time/batch = 0.4402s	
2440/2700 (epoch 45.185), train_loss = 3.24613999, grad/param norm = 3.6791e-01, time/batch = 0.4365s	
2441/2700 (epoch 45.204), train_loss = 3.18120435, grad/param norm = 4.1550e-01, time/batch = 0.4067s	
2442/2700 (epoch 45.222), train_loss = 3.15355419, grad/param norm = 4.4035e-01, time/batch = 0.3783s	
2443/2700 (epoch 45.241), train_loss = 3.17005438, grad/param norm = 3.3909e-01, time/batch = 0.4632s	
2444/2700 (epoch 45.259), train_loss = 3.20720913, grad/param norm = 3.6953e-01, time/batch = 0.4409s	
2445/2700 (epoch 45.278), train_loss = 3.27959571, grad/param norm = 3.8927e-01, time/batch = 0.3632s	
2446/2700 (epoch 45.296), train_loss = 3.28473942, grad/param norm = 4.1390e-01, time/batch = 0.3388s	
2447/2700 (epoch 45.315), train_loss = 3.26194541, grad/param norm = 4.3635e-01, time/batch = 0.3755s	
2448/2700 (epoch 45.333), train_loss = 3.34111801, grad/param norm = 4.1380e-01, time/batch = 0.4230s	
2449/2700 (epoch 45.352), train_loss = 3.35140808, grad/param norm = 4.3218e-01, time/batch = 0.4199s	
2450/2700 (epoch 45.370), train_loss = 3.29302572, grad/param norm = 3.9358e-01, time/batch = 0.4671s	
2451/2700 (epoch 45.389), train_loss = 3.25557768, grad/param norm = 3.5537e-01, time/batch = 0.4476s	
2452/2700 (epoch 45.407), train_loss = 3.28220506, grad/param norm = 3.5336e-01, time/batch = 0.4071s	
2453/2700 (epoch 45.426), train_loss = 3.27906134, grad/param norm = 3.3819e-01, time/batch = 0.3957s	
2454/2700 (epoch 45.444), train_loss = 3.20869281, grad/param norm = 3.1677e-01, time/batch = 0.4410s	
2455/2700 (epoch 45.463), train_loss = 3.25019534, grad/param norm = 3.4177e-01, time/batch = 0.3732s	
2456/2700 (epoch 45.481), train_loss = 3.32785867, grad/param norm = 3.6741e-01, time/batch = 0.3424s	
2457/2700 (epoch 45.500), train_loss = 3.37596597, grad/param norm = 4.7798e-01, time/batch = 0.3898s	
2458/2700 (epoch 45.519), train_loss = 3.33109837, grad/param norm = 4.3857e-01, time/batch = 0.3567s	
2459/2700 (epoch 45.537), train_loss = 3.33444766, grad/param norm = 4.9479e-01, time/batch = 0.3509s	
2460/2700 (epoch 45.556), train_loss = 3.27421108, grad/param norm = 4.5688e-01, time/batch = 0.4132s	
2461/2700 (epoch 45.574), train_loss = 3.23803123, grad/param norm = 4.0782e-01, time/batch = 0.4543s	
2462/2700 (epoch 45.593), train_loss = 3.23703796, grad/param norm = 4.1319e-01, time/batch = 0.4453s	
2463/2700 (epoch 45.611), train_loss = 3.17392051, grad/param norm = 3.2042e-01, time/batch = 0.4066s	
2464/2700 (epoch 45.630), train_loss = 3.21746494, grad/param norm = 3.7037e-01, time/batch = 0.3913s	
2465/2700 (epoch 45.648), train_loss = 3.28379847, grad/param norm = 4.1632e-01, time/batch = 0.4341s	
2466/2700 (epoch 45.667), train_loss = 3.21834071, grad/param norm = 3.7188e-01, time/batch = 0.4602s	
2467/2700 (epoch 45.685), train_loss = 3.21689759, grad/param norm = 3.7837e-01, time/batch = 0.4593s	
2468/2700 (epoch 45.704), train_loss = 3.18750937, grad/param norm = 4.5742e-01, time/batch = 0.4334s	
2469/2700 (epoch 45.722), train_loss = 3.17724080, grad/param norm = 3.8316e-01, time/batch = 0.2755s	
2470/2700 (epoch 45.741), train_loss = 3.31534084, grad/param norm = 5.2474e-01, time/batch = 0.4307s	
2471/2700 (epoch 45.759), train_loss = 3.26770567, grad/param norm = 5.0561e-01, time/batch = 0.3929s	
2472/2700 (epoch 45.778), train_loss = 3.25393895, grad/param norm = 4.1217e-01, time/batch = 0.4467s	
2473/2700 (epoch 45.796), train_loss = 3.24187930, grad/param norm = 3.8863e-01, time/batch = 0.4307s	
2474/2700 (epoch 45.815), train_loss = 3.20097478, grad/param norm = 3.2093e-01, time/batch = 0.3915s	
2475/2700 (epoch 45.833), train_loss = 3.23158274, grad/param norm = 3.5076e-01, time/batch = 0.3996s	
2476/2700 (epoch 45.852), train_loss = 3.21947001, grad/param norm = 3.4625e-01, time/batch = 0.4360s	
2477/2700 (epoch 45.870), train_loss = 3.21706413, grad/param norm = 3.6700e-01, time/batch = 0.4596s	
2478/2700 (epoch 45.889), train_loss = 3.26158409, grad/param norm = 4.0818e-01, time/batch = 0.4609s	
2479/2700 (epoch 45.907), train_loss = 3.30930165, grad/param norm = 4.3648e-01, time/batch = 0.3858s	
2480/2700 (epoch 45.926), train_loss = 3.25348556, grad/param norm = 4.0943e-01, time/batch = 0.4093s	
2481/2700 (epoch 45.944), train_loss = 3.26175110, grad/param norm = 3.7581e-01, time/batch = 0.3583s	
2482/2700 (epoch 45.963), train_loss = 3.34677212, grad/param norm = 3.9419e-01, time/batch = 0.3932s	
2483/2700 (epoch 45.981), train_loss = 3.40846405, grad/param norm = 4.3034e-01, time/batch = 0.4323s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
2484/2700 (epoch 46.000), train_loss = 3.30186400, grad/param norm = 4.0676e-01, time/batch = 0.4262s	
2485/2700 (epoch 46.019), train_loss = 3.24523640, grad/param norm = 4.2523e-01, time/batch = 0.4045s	
2486/2700 (epoch 46.037), train_loss = 3.25842521, grad/param norm = 3.8670e-01, time/batch = 0.3889s	
2487/2700 (epoch 46.056), train_loss = 3.26413831, grad/param norm = 3.7636e-01, time/batch = 0.4191s	
2488/2700 (epoch 46.074), train_loss = 3.29238006, grad/param norm = 4.5505e-01, time/batch = 0.4528s	
2489/2700 (epoch 46.093), train_loss = 3.29835687, grad/param norm = 4.6692e-01, time/batch = 0.4336s	
2490/2700 (epoch 46.111), train_loss = 3.27248571, grad/param norm = 4.2689e-01, time/batch = 0.4572s	
2491/2700 (epoch 46.130), train_loss = 3.28380038, grad/param norm = 3.6189e-01, time/batch = 0.4346s	
2492/2700 (epoch 46.148), train_loss = 3.24975877, grad/param norm = 3.8038e-01, time/batch = 0.3882s	
2493/2700 (epoch 46.167), train_loss = 3.25918601, grad/param norm = 4.4607e-01, time/batch = 0.3303s	
2494/2700 (epoch 46.185), train_loss = 3.24564620, grad/param norm = 3.6352e-01, time/batch = 0.4236s	
2495/2700 (epoch 46.204), train_loss = 3.18073340, grad/param norm = 4.0983e-01, time/batch = 0.3750s	
2496/2700 (epoch 46.222), train_loss = 3.15303703, grad/param norm = 4.3372e-01, time/batch = 0.3536s	
2497/2700 (epoch 46.241), train_loss = 3.16969287, grad/param norm = 3.3297e-01, time/batch = 0.3921s	
2498/2700 (epoch 46.259), train_loss = 3.20679018, grad/param norm = 3.6350e-01, time/batch = 0.4446s	
2499/2700 (epoch 46.278), train_loss = 3.27907540, grad/param norm = 3.8170e-01, time/batch = 0.4501s	
2500/2700 (epoch 46.296), train_loss = 3.28404262, grad/param norm = 4.0126e-01, time/batch = 0.4711s	
2501/2700 (epoch 46.315), train_loss = 3.26114098, grad/param norm = 4.2454e-01, time/batch = 0.4621s	
2502/2700 (epoch 46.333), train_loss = 3.34064559, grad/param norm = 4.0655e-01, time/batch = 0.4316s	
2503/2700 (epoch 46.352), train_loss = 3.35080951, grad/param norm = 4.2772e-01, time/batch = 0.3867s	
2504/2700 (epoch 46.370), train_loss = 3.29249514, grad/param norm = 3.9027e-01, time/batch = 0.3961s	
2505/2700 (epoch 46.389), train_loss = 3.25522488, grad/param norm = 3.5279e-01, time/batch = 0.4083s	
2506/2700 (epoch 46.407), train_loss = 3.28172003, grad/param norm = 3.5075e-01, time/batch = 0.3755s	
2507/2700 (epoch 46.426), train_loss = 3.27873547, grad/param norm = 3.3732e-01, time/batch = 0.3285s	
2508/2700 (epoch 46.444), train_loss = 3.20853090, grad/param norm = 3.1507e-01, time/batch = 0.3738s	
2509/2700 (epoch 46.463), train_loss = 3.24985134, grad/param norm = 3.3933e-01, time/batch = 0.4051s	
2510/2700 (epoch 46.481), train_loss = 3.32756085, grad/param norm = 3.6680e-01, time/batch = 0.4685s	
2511/2700 (epoch 46.500), train_loss = 3.37526671, grad/param norm = 4.7492e-01, time/batch = 0.4591s	
2512/2700 (epoch 46.519), train_loss = 3.33064187, grad/param norm = 4.3507e-01, time/batch = 0.4659s	
2513/2700 (epoch 46.537), train_loss = 3.33392158, grad/param norm = 4.9001e-01, time/batch = 0.4293s	
2514/2700 (epoch 46.556), train_loss = 3.27347009, grad/param norm = 4.5094e-01, time/batch = 0.3674s	
2515/2700 (epoch 46.574), train_loss = 3.23760086, grad/param norm = 4.0364e-01, time/batch = 0.4183s	
2516/2700 (epoch 46.593), train_loss = 3.23638309, grad/param norm = 4.0773e-01, time/batch = 0.4316s	
2517/2700 (epoch 46.611), train_loss = 3.17376331, grad/param norm = 3.1771e-01, time/batch = 0.4107s	
2518/2700 (epoch 46.630), train_loss = 3.21720069, grad/param norm = 3.6753e-01, time/batch = 0.3615s	
2519/2700 (epoch 46.648), train_loss = 3.28308075, grad/param norm = 4.1190e-01, time/batch = 0.3289s	
2520/2700 (epoch 46.667), train_loss = 3.21786235, grad/param norm = 3.6725e-01, time/batch = 0.4241s	
2521/2700 (epoch 46.685), train_loss = 3.21653509, grad/param norm = 3.7645e-01, time/batch = 0.4371s	
2522/2700 (epoch 46.704), train_loss = 3.18714149, grad/param norm = 4.5504e-01, time/batch = 0.4682s	
2523/2700 (epoch 46.722), train_loss = 3.17669712, grad/param norm = 3.7625e-01, time/batch = 0.4710s	
2524/2700 (epoch 46.741), train_loss = 3.31471443, grad/param norm = 5.1585e-01, time/batch = 0.4571s	
2525/2700 (epoch 46.759), train_loss = 3.26683382, grad/param norm = 4.9629e-01, time/batch = 0.4046s	
2526/2700 (epoch 46.778), train_loss = 3.25332725, grad/param norm = 4.0524e-01, time/batch = 0.3858s	
2527/2700 (epoch 46.796), train_loss = 3.24131240, grad/param norm = 3.8242e-01, time/batch = 0.4023s	
2528/2700 (epoch 46.815), train_loss = 3.20042629, grad/param norm = 3.1756e-01, time/batch = 0.4209s	
2529/2700 (epoch 46.833), train_loss = 3.23119752, grad/param norm = 3.4877e-01, time/batch = 0.3890s	
2530/2700 (epoch 46.852), train_loss = 3.21901442, grad/param norm = 3.4294e-01, time/batch = 0.3789s	
2531/2700 (epoch 46.870), train_loss = 3.21664831, grad/param norm = 3.6425e-01, time/batch = 0.3612s	
2532/2700 (epoch 46.889), train_loss = 3.26096434, grad/param norm = 4.0392e-01, time/batch = 0.3947s	
2533/2700 (epoch 46.907), train_loss = 3.30875137, grad/param norm = 4.3188e-01, time/batch = 0.4552s	
2534/2700 (epoch 46.926), train_loss = 3.25294975, grad/param norm = 4.0437e-01, time/batch = 0.4699s	
2535/2700 (epoch 46.944), train_loss = 3.26127079, grad/param norm = 3.7166e-01, time/batch = 0.4644s	
2536/2700 (epoch 46.963), train_loss = 3.34626274, grad/param norm = 3.8944e-01, time/batch = 0.4243s	
2537/2700 (epoch 46.981), train_loss = 3.40810427, grad/param norm = 4.2760e-01, time/batch = 0.3919s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
2538/2700 (epoch 47.000), train_loss = 3.30125596, grad/param norm = 4.0225e-01, time/batch = 0.3905s	
2539/2700 (epoch 47.019), train_loss = 3.24459643, grad/param norm = 4.2191e-01, time/batch = 0.3879s	
2540/2700 (epoch 47.037), train_loss = 3.25791823, grad/param norm = 3.8233e-01, time/batch = 0.4358s	
2541/2700 (epoch 47.056), train_loss = 3.26392540, grad/param norm = 3.7625e-01, time/batch = 0.4233s	
2542/2700 (epoch 47.074), train_loss = 3.29198287, grad/param norm = 4.5446e-01, time/batch = 0.3545s	
2543/2700 (epoch 47.093), train_loss = 3.29767226, grad/param norm = 4.6125e-01, time/batch = 0.3632s	
2544/2700 (epoch 47.111), train_loss = 3.27196922, grad/param norm = 4.1926e-01, time/batch = 0.4239s	
2545/2700 (epoch 47.130), train_loss = 3.28326323, grad/param norm = 3.5754e-01, time/batch = 0.4623s	
2546/2700 (epoch 47.148), train_loss = 3.24943674, grad/param norm = 3.7655e-01, time/batch = 0.4668s	
2547/2700 (epoch 47.167), train_loss = 3.25851098, grad/param norm = 4.3931e-01, time/batch = 0.4471s	
2548/2700 (epoch 47.185), train_loss = 3.24518253, grad/param norm = 3.5961e-01, time/batch = 0.4152s	
2549/2700 (epoch 47.204), train_loss = 3.18029217, grad/param norm = 4.0470e-01, time/batch = 0.3175s	
2550/2700 (epoch 47.222), train_loss = 3.15256035, grad/param norm = 4.2776e-01, time/batch = 0.4325s	
2551/2700 (epoch 47.241), train_loss = 3.16937433, grad/param norm = 3.2799e-01, time/batch = 0.4335s	
2552/2700 (epoch 47.259), train_loss = 3.20640560, grad/param norm = 3.5887e-01, time/batch = 0.4295s	
2553/2700 (epoch 47.278), train_loss = 3.27860050, grad/param norm = 3.7525e-01, time/batch = 0.4034s	
2554/2700 (epoch 47.296), train_loss = 3.28340568, grad/param norm = 3.9000e-01, time/batch = 0.3315s	
2555/2700 (epoch 47.315), train_loss = 3.26037876, grad/param norm = 4.1329e-01, time/batch = 0.4048s	
2556/2700 (epoch 47.333), train_loss = 3.34018569, grad/param norm = 3.9885e-01, time/batch = 0.4631s	
2557/2700 (epoch 47.352), train_loss = 3.35020394, grad/param norm = 4.2266e-01, time/batch = 0.4652s	
2558/2700 (epoch 47.370), train_loss = 3.29197487, grad/param norm = 3.8682e-01, time/batch = 0.4555s	
2559/2700 (epoch 47.389), train_loss = 3.25488322, grad/param norm = 3.5016e-01, time/batch = 0.3861s	
2560/2700 (epoch 47.407), train_loss = 3.28125405, grad/param norm = 3.4822e-01, time/batch = 0.4203s	
2561/2700 (epoch 47.426), train_loss = 3.27841538, grad/param norm = 3.3627e-01, time/batch = 0.4013s	
2562/2700 (epoch 47.444), train_loss = 3.20838363, grad/param norm = 3.1347e-01, time/batch = 0.4088s	
2563/2700 (epoch 47.463), train_loss = 3.24952293, grad/param norm = 3.3713e-01, time/batch = 0.4205s	
2564/2700 (epoch 47.481), train_loss = 3.32728814, grad/param norm = 3.6659e-01, time/batch = 0.4264s	
2565/2700 (epoch 47.500), train_loss = 3.37460052, grad/param norm = 4.7235e-01, time/batch = 0.3826s	
2566/2700 (epoch 47.519), train_loss = 3.33022191, grad/param norm = 4.3203e-01, time/batch = 0.3224s	
2567/2700 (epoch 47.537), train_loss = 3.33341147, grad/param norm = 4.8518e-01, time/batch = 0.4262s	
2568/2700 (epoch 47.556), train_loss = 3.27275782, grad/param norm = 4.4503e-01, time/batch = 0.4588s	
2569/2700 (epoch 47.574), train_loss = 3.23719188, grad/param norm = 3.9970e-01, time/batch = 0.4395s	
2570/2700 (epoch 47.593), train_loss = 3.23574848, grad/param norm = 4.0241e-01, time/batch = 0.4492s	
2571/2700 (epoch 47.611), train_loss = 3.17362423, grad/param norm = 3.1537e-01, time/batch = 0.4273s	
2572/2700 (epoch 47.630), train_loss = 3.21694440, grad/param norm = 3.6468e-01, time/batch = 0.3796s	
2573/2700 (epoch 47.648), train_loss = 3.28239113, grad/param norm = 4.0763e-01, time/batch = 0.4004s	
2574/2700 (epoch 47.667), train_loss = 3.21741578, grad/param norm = 3.6286e-01, time/batch = 0.4225s	
2575/2700 (epoch 47.685), train_loss = 3.21619085, grad/param norm = 3.7479e-01, time/batch = 0.4233s	
2576/2700 (epoch 47.704), train_loss = 3.18678292, grad/param norm = 4.5256e-01, time/batch = 0.4100s	
2577/2700 (epoch 47.722), train_loss = 3.17617211, grad/param norm = 3.6892e-01, time/batch = 0.3595s	
2578/2700 (epoch 47.741), train_loss = 3.31409693, grad/param norm = 5.0653e-01, time/batch = 0.3461s	
2579/2700 (epoch 47.759), train_loss = 3.26599622, grad/param norm = 4.8719e-01, time/batch = 0.4251s	
2580/2700 (epoch 47.778), train_loss = 3.25274699, grad/param norm = 3.9865e-01, time/batch = 0.4576s	
2581/2700 (epoch 47.796), train_loss = 3.24077740, grad/param norm = 3.7651e-01, time/batch = 0.4623s	
2582/2700 (epoch 47.815), train_loss = 3.19990605, grad/param norm = 3.1453e-01, time/batch = 0.4633s	
2583/2700 (epoch 47.833), train_loss = 3.23083093, grad/param norm = 3.4690e-01, time/batch = 0.4370s	
2584/2700 (epoch 47.852), train_loss = 3.21858300, grad/param norm = 3.3973e-01, time/batch = 0.3950s	
2585/2700 (epoch 47.870), train_loss = 3.21625722, grad/param norm = 3.6169e-01, time/batch = 0.4126s	
2586/2700 (epoch 47.889), train_loss = 3.26036910, grad/param norm = 3.9984e-01, time/batch = 0.4443s	
2587/2700 (epoch 47.907), train_loss = 3.30822888, grad/param norm = 4.2755e-01, time/batch = 0.4425s	
2588/2700 (epoch 47.926), train_loss = 3.25245180, grad/param norm = 3.9967e-01, time/batch = 0.4084s	
2589/2700 (epoch 47.944), train_loss = 3.26081619, grad/param norm = 3.6772e-01, time/batch = 0.3173s	
2590/2700 (epoch 47.963), train_loss = 3.34578259, grad/param norm = 3.8492e-01, time/batch = 0.3470s	
2591/2700 (epoch 47.981), train_loss = 3.40776230, grad/param norm = 4.2503e-01, time/batch = 0.3988s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
2592/2700 (epoch 48.000), train_loss = 3.30066501, grad/param norm = 3.9780e-01, time/batch = 0.4642s	
2593/2700 (epoch 48.019), train_loss = 3.24397059, grad/param norm = 4.1874e-01, time/batch = 0.4635s	
2594/2700 (epoch 48.037), train_loss = 3.25742930, grad/param norm = 3.7812e-01, time/batch = 0.4563s	
2595/2700 (epoch 48.056), train_loss = 3.26371554, grad/param norm = 3.7596e-01, time/batch = 0.4173s	
2596/2700 (epoch 48.074), train_loss = 3.29158185, grad/param norm = 4.5325e-01, time/batch = 0.4012s	
2597/2700 (epoch 48.093), train_loss = 3.29699922, grad/param norm = 4.5523e-01, time/batch = 0.4285s	
2598/2700 (epoch 48.111), train_loss = 3.27147930, grad/param norm = 4.1196e-01, time/batch = 0.4606s	
2599/2700 (epoch 48.130), train_loss = 3.28276094, grad/param norm = 3.5366e-01, time/batch = 0.3568s	
2600/2700 (epoch 48.148), train_loss = 3.24912764, grad/param norm = 3.7299e-01, time/batch = 0.3925s	
2601/2700 (epoch 48.167), train_loss = 3.25787142, grad/param norm = 4.3290e-01, time/batch = 0.3449s	
2602/2700 (epoch 48.185), train_loss = 3.24474585, grad/param norm = 3.5609e-01, time/batch = 0.3118s	
2603/2700 (epoch 48.204), train_loss = 3.17987627, grad/param norm = 4.0002e-01, time/batch = 0.4646s	
2604/2700 (epoch 48.222), train_loss = 3.15211917, grad/param norm = 4.2235e-01, time/batch = 0.4602s	
2605/2700 (epoch 48.241), train_loss = 3.16908961, grad/param norm = 3.2387e-01, time/batch = 0.4232s	
2606/2700 (epoch 48.259), train_loss = 3.20604612, grad/param norm = 3.5524e-01, time/batch = 0.3928s	
2607/2700 (epoch 48.278), train_loss = 3.27816202, grad/param norm = 3.6967e-01, time/batch = 0.4296s	
2608/2700 (epoch 48.296), train_loss = 3.28282069, grad/param norm = 3.7999e-01, time/batch = 0.4644s	
2609/2700 (epoch 48.315), train_loss = 3.25966190, grad/param norm = 4.0276e-01, time/batch = 0.4018s	
2610/2700 (epoch 48.333), train_loss = 3.33974456, grad/param norm = 3.9102e-01, time/batch = 0.4251s	
2611/2700 (epoch 48.352), train_loss = 3.34959842, grad/param norm = 4.1722e-01, time/batch = 0.3446s	
2612/2700 (epoch 48.370), train_loss = 3.29146507, grad/param norm = 3.8329e-01, time/batch = 0.3286s	
2613/2700 (epoch 48.389), train_loss = 3.25455262, grad/param norm = 3.4749e-01, time/batch = 0.3661s	
2614/2700 (epoch 48.407), train_loss = 3.28080680, grad/param norm = 3.4578e-01, time/batch = 0.4351s	
2615/2700 (epoch 48.426), train_loss = 3.27810064, grad/param norm = 3.3506e-01, time/batch = 0.4255s	
2616/2700 (epoch 48.444), train_loss = 3.20824900, grad/param norm = 3.1197e-01, time/batch = 0.4011s	
2617/2700 (epoch 48.463), train_loss = 3.24921024, grad/param norm = 3.3520e-01, time/batch = 0.4198s	
2618/2700 (epoch 48.481), train_loss = 3.32703961, grad/param norm = 3.6682e-01, time/batch = 0.4605s	
2619/2700 (epoch 48.500), train_loss = 3.37396857, grad/param norm = 4.7031e-01, time/batch = 0.4253s	
2620/2700 (epoch 48.519), train_loss = 3.32983449, grad/param norm = 4.2939e-01, time/batch = 0.4529s	
2621/2700 (epoch 48.537), train_loss = 3.33291373, grad/param norm = 4.8019e-01, time/batch = 0.4420s	
2622/2700 (epoch 48.556), train_loss = 3.27207166, grad/param norm = 4.3910e-01, time/batch = 0.3680s	
2623/2700 (epoch 48.574), train_loss = 3.23680231, grad/param norm = 3.9602e-01, time/batch = 0.3324s	
2624/2700 (epoch 48.593), train_loss = 3.23513306, grad/param norm = 3.9727e-01, time/batch = 0.3636s	
2625/2700 (epoch 48.611), train_loss = 3.17350208, grad/param norm = 3.1340e-01, time/batch = 0.4449s	
2626/2700 (epoch 48.630), train_loss = 3.21669621, grad/param norm = 3.6183e-01, time/batch = 0.4531s	
2627/2700 (epoch 48.648), train_loss = 3.28172811, grad/param norm = 4.0350e-01, time/batch = 0.4116s	
2628/2700 (epoch 48.667), train_loss = 3.21699745, grad/param norm = 3.5870e-01, time/batch = 0.3937s	
2629/2700 (epoch 48.685), train_loss = 3.21586191, grad/param norm = 3.7324e-01, time/batch = 0.3991s	
2630/2700 (epoch 48.704), train_loss = 3.18642774, grad/param norm = 4.4980e-01, time/batch = 0.4653s	
2631/2700 (epoch 48.722), train_loss = 3.17566184, grad/param norm = 3.6103e-01, time/batch = 0.4542s	
2632/2700 (epoch 48.741), train_loss = 3.31348814, grad/param norm = 4.9688e-01, time/batch = 0.4549s	
2633/2700 (epoch 48.759), train_loss = 3.26519550, grad/param norm = 4.7842e-01, time/batch = 0.4239s	
2634/2700 (epoch 48.778), train_loss = 3.25219538, grad/param norm = 3.9239e-01, time/batch = 0.3833s	
2635/2700 (epoch 48.796), train_loss = 3.24027208, grad/param norm = 3.7088e-01, time/batch = 0.3351s	
2636/2700 (epoch 48.815), train_loss = 3.19941273, grad/param norm = 3.1180e-01, time/batch = 0.4047s	
2637/2700 (epoch 48.833), train_loss = 3.23048144, grad/param norm = 3.4512e-01, time/batch = 0.4256s	
2638/2700 (epoch 48.852), train_loss = 3.21817255, grad/param norm = 3.3660e-01, time/batch = 0.4440s	
2639/2700 (epoch 48.870), train_loss = 3.21588908, grad/param norm = 3.5933e-01, time/batch = 0.3534s	
2640/2700 (epoch 48.889), train_loss = 3.25979744, grad/param norm = 3.9594e-01, time/batch = 0.4221s	
2641/2700 (epoch 48.907), train_loss = 3.30773174, grad/param norm = 4.2349e-01, time/batch = 0.4280s	
2642/2700 (epoch 48.926), train_loss = 3.25198817, grad/param norm = 3.9529e-01, time/batch = 0.4595s	
2643/2700 (epoch 48.944), train_loss = 3.26038408, grad/param norm = 3.6396e-01, time/batch = 0.4655s	
2644/2700 (epoch 48.963), train_loss = 3.34532907, grad/param norm = 3.8061e-01, time/batch = 0.4618s	
2645/2700 (epoch 48.981), train_loss = 3.40743663, grad/param norm = 4.2258e-01, time/batch = 0.4104s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
2646/2700 (epoch 49.000), train_loss = 3.30009042, grad/param norm = 3.9339e-01, time/batch = 0.3669s	
2647/2700 (epoch 49.019), train_loss = 3.24335845, grad/param norm = 4.1571e-01, time/batch = 0.3746s	
2648/2700 (epoch 49.037), train_loss = 3.25695567, grad/param norm = 3.7404e-01, time/batch = 0.4165s	
2649/2700 (epoch 49.056), train_loss = 3.26350698, grad/param norm = 3.7548e-01, time/batch = 0.4102s	
2650/2700 (epoch 49.074), train_loss = 3.29117848, grad/param norm = 4.5153e-01, time/batch = 0.4489s	
2651/2700 (epoch 49.093), train_loss = 3.29634223, grad/param norm = 4.4901e-01, time/batch = 0.3633s	
2652/2700 (epoch 49.111), train_loss = 3.27101606, grad/param norm = 4.0507e-01, time/batch = 0.3857s	
2653/2700 (epoch 49.130), train_loss = 3.28228966, grad/param norm = 3.5020e-01, time/batch = 0.4405s	
2654/2700 (epoch 49.148), train_loss = 3.24882894, grad/param norm = 3.6963e-01, time/batch = 0.4628s	
2655/2700 (epoch 49.167), train_loss = 3.25726397, grad/param norm = 4.2680e-01, time/batch = 0.4665s	
2656/2700 (epoch 49.185), train_loss = 3.24433297, grad/param norm = 3.5292e-01, time/batch = 0.4479s	
2657/2700 (epoch 49.204), train_loss = 3.17948346, grad/param norm = 3.9573e-01, time/batch = 0.4010s	
2658/2700 (epoch 49.222), train_loss = 3.15170948, grad/param norm = 4.1744e-01, time/batch = 0.3593s	
2659/2700 (epoch 49.241), train_loss = 3.16883367, grad/param norm = 3.2046e-01, time/batch = 0.3587s	
2660/2700 (epoch 49.259), train_loss = 3.20570776, grad/param norm = 3.5237e-01, time/batch = 0.4295s	
2661/2700 (epoch 49.278), train_loss = 3.27775524, grad/param norm = 3.6479e-01, time/batch = 0.4326s	
2662/2700 (epoch 49.296), train_loss = 3.28228203, grad/param norm = 3.7113e-01, time/batch = 0.4024s	
2663/2700 (epoch 49.315), train_loss = 3.25899023, grad/param norm = 3.9304e-01, time/batch = 0.3465s	
2664/2700 (epoch 49.333), train_loss = 3.33932638, grad/param norm = 3.8333e-01, time/batch = 0.4355s	
2665/2700 (epoch 49.352), train_loss = 3.34899899, grad/param norm = 4.1155e-01, time/batch = 0.4654s	
2666/2700 (epoch 49.370), train_loss = 3.29096738, grad/param norm = 3.7969e-01, time/batch = 0.4662s	
2667/2700 (epoch 49.389), train_loss = 3.25423322, grad/param norm = 3.4483e-01, time/batch = 0.4557s	
2668/2700 (epoch 49.407), train_loss = 3.28037734, grad/param norm = 3.4343e-01, time/batch = 0.4164s	
2669/2700 (epoch 49.426), train_loss = 3.27779008, grad/param norm = 3.3369e-01, time/batch = 0.3570s	
2670/2700 (epoch 49.444), train_loss = 3.20812676, grad/param norm = 3.1060e-01, time/batch = 0.4135s	
2671/2700 (epoch 49.463), train_loss = 3.24891421, grad/param norm = 3.3356e-01, time/batch = 0.4191s	
2672/2700 (epoch 49.481), train_loss = 3.32681472, grad/param norm = 3.6749e-01, time/batch = 0.4259s	
2673/2700 (epoch 49.500), train_loss = 3.37336938, grad/param norm = 4.6878e-01, time/batch = 0.4290s	
2674/2700 (epoch 49.519), train_loss = 3.32947276, grad/param norm = 4.2697e-01, time/batch = 0.4174s	
2675/2700 (epoch 49.537), train_loss = 3.33242441, grad/param norm = 4.7487e-01, time/batch = 0.3466s	
2676/2700 (epoch 49.556), train_loss = 3.27140995, grad/param norm = 4.3314e-01, time/batch = 0.4018s	
2677/2700 (epoch 49.574), train_loss = 3.23643212, grad/param norm = 3.9262e-01, time/batch = 0.4526s	
2678/2700 (epoch 49.593), train_loss = 3.23453794, grad/param norm = 3.9232e-01, time/batch = 0.4519s	
2679/2700 (epoch 49.611), train_loss = 3.17339618, grad/param norm = 3.1179e-01, time/batch = 0.4521s	
2680/2700 (epoch 49.630), train_loss = 3.21645481, grad/param norm = 3.5899e-01, time/batch = 0.4461s	
2681/2700 (epoch 49.648), train_loss = 3.28109076, grad/param norm = 3.9953e-01, time/batch = 0.4110s	
2682/2700 (epoch 49.667), train_loss = 3.21660529, grad/param norm = 3.5474e-01, time/batch = 0.3872s	
2683/2700 (epoch 49.685), train_loss = 3.21554431, grad/param norm = 3.7169e-01, time/batch = 0.3949s	
2684/2700 (epoch 49.704), train_loss = 3.18607364, grad/param norm = 4.4668e-01, time/batch = 0.4128s	
2685/2700 (epoch 49.722), train_loss = 3.17516511, grad/param norm = 3.5259e-01, time/batch = 0.4244s	
2686/2700 (epoch 49.741), train_loss = 3.31289098, grad/param norm = 4.8708e-01, time/batch = 0.4174s	
2687/2700 (epoch 49.759), train_loss = 3.26443291, grad/param norm = 4.7005e-01, time/batch = 0.3497s	
2688/2700 (epoch 49.778), train_loss = 3.25166874, grad/param norm = 3.8642e-01, time/batch = 0.3979s	
2689/2700 (epoch 49.796), train_loss = 3.23979539, grad/param norm = 3.6554e-01, time/batch = 0.4113s	
2690/2700 (epoch 49.815), train_loss = 3.19894482, grad/param norm = 3.0934e-01, time/batch = 0.4661s	
2691/2700 (epoch 49.833), train_loss = 3.23014828, grad/param norm = 3.4343e-01, time/batch = 0.4649s	
2692/2700 (epoch 49.852), train_loss = 3.21778266, grad/param norm = 3.3357e-01, time/batch = 0.4491s	
2693/2700 (epoch 49.870), train_loss = 3.21554236, grad/param norm = 3.5717e-01, time/batch = 0.3945s	
2694/2700 (epoch 49.889), train_loss = 3.25924774, grad/param norm = 3.9219e-01, time/batch = 0.3644s	
2695/2700 (epoch 49.907), train_loss = 3.30725747, grad/param norm = 4.1966e-01, time/batch = 0.3868s	
2696/2700 (epoch 49.926), train_loss = 3.25155624, grad/param norm = 3.9121e-01, time/batch = 0.4220s	
2697/2700 (epoch 49.944), train_loss = 3.25997195, grad/param norm = 3.6035e-01, time/batch = 0.4353s	
2698/2700 (epoch 49.963), train_loss = 3.34490005, grad/param norm = 3.7649e-01, time/batch = 0.4405s	
2699/2700 (epoch 49.981), train_loss = 3.40712477, grad/param norm = 4.2024e-01, time/batch = 0.3244s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch50.00_3.1947.t7	
2700/2700 (epoch 50.000), train_loss = 3.29953341, grad/param norm = 3.8904e-01, time/batch = 0.4274s	
