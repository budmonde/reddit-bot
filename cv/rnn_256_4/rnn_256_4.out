using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 54, val: 3, test: 0	
vocab size: 91	
creating an rnn with 4 layers	
number of parameters in the model: 507483	
cloning rnn	
cloning criterion	
1/2700 (epoch 0.019), train_loss = 4.52979122, grad/param norm = 2.3780e+00, time/batch = 0.3806s	
2/2700 (epoch 0.037), train_loss = 3.78103051, grad/param norm = 3.7181e+00, time/batch = 0.1123s	
3/2700 (epoch 0.056), train_loss = 3.64110998, grad/param norm = 4.0742e+00, time/batch = 0.1049s	
4/2700 (epoch 0.074), train_loss = 7.97071635, grad/param norm = 1.2952e+01, time/batch = 0.1071s	
5/2700 (epoch 0.093), train_loss = 4.18872137, grad/param norm = 2.9455e+00, time/batch = 0.1069s	
6/2700 (epoch 0.111), train_loss = 3.53684064, grad/param norm = 3.1559e+00, time/batch = 0.0875s	
7/2700 (epoch 0.130), train_loss = 3.51391580, grad/param norm = 3.1461e+00, time/batch = 0.1051s	
8/2700 (epoch 0.148), train_loss = 3.46126827, grad/param norm = 3.2542e+00, time/batch = 0.1039s	
9/2700 (epoch 0.167), train_loss = 3.36505586, grad/param norm = 2.7599e+00, time/batch = 0.1077s	
10/2700 (epoch 0.185), train_loss = 3.28554565, grad/param norm = 1.7069e+00, time/batch = 0.1094s	
11/2700 (epoch 0.204), train_loss = 3.21953603, grad/param norm = 1.8797e+00, time/batch = 0.1122s	
12/2700 (epoch 0.222), train_loss = 3.19403521, grad/param norm = 1.6231e+00, time/batch = 0.1048s	
13/2700 (epoch 0.241), train_loss = 3.20617335, grad/param norm = 1.4553e+00, time/batch = 0.1043s	
14/2700 (epoch 0.259), train_loss = 3.23846880, grad/param norm = 1.4290e+00, time/batch = 0.1079s	
15/2700 (epoch 0.278), train_loss = 3.29929079, grad/param norm = 1.3287e+00, time/batch = 0.0820s	
16/2700 (epoch 0.296), train_loss = 3.31249532, grad/param norm = 1.5232e+00, time/batch = 0.1150s	
17/2700 (epoch 0.315), train_loss = 3.28872071, grad/param norm = 1.5410e+00, time/batch = 0.1148s	
18/2700 (epoch 0.333), train_loss = 3.36348387, grad/param norm = 1.2961e+00, time/batch = 0.1079s	
19/2700 (epoch 0.352), train_loss = 3.36098070, grad/param norm = 1.1625e+00, time/batch = 0.1025s	
20/2700 (epoch 0.370), train_loss = 3.30804515, grad/param norm = 1.0117e+00, time/batch = 0.1032s	
21/2700 (epoch 0.389), train_loss = 3.26860746, grad/param norm = 9.4899e-01, time/batch = 0.1126s	
22/2700 (epoch 0.407), train_loss = 3.29386938, grad/param norm = 9.0484e-01, time/batch = 0.1026s	
23/2700 (epoch 0.426), train_loss = 3.30098693, grad/param norm = 1.0203e+00, time/batch = 0.1053s	
24/2700 (epoch 0.444), train_loss = 3.22362629, grad/param norm = 1.0188e+00, time/batch = 0.0748s	
25/2700 (epoch 0.463), train_loss = 3.27003403, grad/param norm = 1.0534e+00, time/batch = 0.1140s	
26/2700 (epoch 0.481), train_loss = 3.34174725, grad/param norm = 9.7557e-01, time/batch = 0.1158s	
27/2700 (epoch 0.500), train_loss = 3.38126161, grad/param norm = 1.2178e+00, time/batch = 0.1155s	
28/2700 (epoch 0.519), train_loss = 3.34354068, grad/param norm = 1.4587e+00, time/batch = 0.1158s	
29/2700 (epoch 0.537), train_loss = 3.35383626, grad/param norm = 1.7836e+00, time/batch = 0.1151s	
30/2700 (epoch 0.556), train_loss = 3.31266557, grad/param norm = 1.8224e+00, time/batch = 0.1141s	
31/2700 (epoch 0.574), train_loss = 3.25025481, grad/param norm = 1.5446e+00, time/batch = 0.1143s	
32/2700 (epoch 0.593), train_loss = 3.26007004, grad/param norm = 1.7879e+00, time/batch = 0.1156s	
33/2700 (epoch 0.611), train_loss = 3.20266683, grad/param norm = 1.6403e+00, time/batch = 0.1045s	
34/2700 (epoch 0.630), train_loss = 3.24273220, grad/param norm = 1.7248e+00, time/batch = 0.1126s	
35/2700 (epoch 0.648), train_loss = 3.31824108, grad/param norm = 1.7635e+00, time/batch = 0.1139s	
36/2700 (epoch 0.667), train_loss = 3.25591282, grad/param norm = 1.7699e+00, time/batch = 0.1153s	
37/2700 (epoch 0.685), train_loss = 3.24268650, grad/param norm = 1.5096e+00, time/batch = 0.1141s	
38/2700 (epoch 0.704), train_loss = 3.21818982, grad/param norm = 1.6151e+00, time/batch = 0.1141s	
39/2700 (epoch 0.722), train_loss = 3.20780637, grad/param norm = 1.3726e+00, time/batch = 0.1150s	
40/2700 (epoch 0.741), train_loss = 3.32975475, grad/param norm = 1.1788e+00, time/batch = 0.1145s	
41/2700 (epoch 0.759), train_loss = 3.28421707, grad/param norm = 1.4166e+00, time/batch = 0.1021s	
42/2700 (epoch 0.778), train_loss = 3.29198952, grad/param norm = 1.8163e+00, time/batch = 0.1026s	
43/2700 (epoch 0.796), train_loss = 3.29186796, grad/param norm = 1.7968e+00, time/batch = 0.0772s	
44/2700 (epoch 0.815), train_loss = 3.22746208, grad/param norm = 1.5918e+00, time/batch = 0.1136s	
45/2700 (epoch 0.833), train_loss = 3.26694389, grad/param norm = 1.6153e+00, time/batch = 0.1154s	
46/2700 (epoch 0.852), train_loss = 3.25881842, grad/param norm = 1.6838e+00, time/batch = 0.1144s	
47/2700 (epoch 0.870), train_loss = 3.25568852, grad/param norm = 1.5503e+00, time/batch = 0.1134s	
48/2700 (epoch 0.889), train_loss = 3.27279615, grad/param norm = 1.4073e+00, time/batch = 0.1151s	
49/2700 (epoch 0.907), train_loss = 3.32118024, grad/param norm = 1.5467e+00, time/batch = 0.1084s	
50/2700 (epoch 0.926), train_loss = 3.28764617, grad/param norm = 1.7717e+00, time/batch = 0.1038s	
51/2700 (epoch 0.944), train_loss = 3.29939905, grad/param norm = 1.5190e+00, time/batch = 0.1139s	
52/2700 (epoch 0.963), train_loss = 3.36552386, grad/param norm = 1.3523e+00, time/batch = 0.0834s	
53/2700 (epoch 0.981), train_loss = 3.42318368, grad/param norm = 1.3271e+00, time/batch = 0.1130s	
54/2700 (epoch 1.000), train_loss = 3.32859920, grad/param norm = 1.3382e+00, time/batch = 0.1137s	
55/2700 (epoch 1.019), train_loss = 3.25768747, grad/param norm = 1.4356e+00, time/batch = 0.1136s	
56/2700 (epoch 1.037), train_loss = 3.28563578, grad/param norm = 1.4986e+00, time/batch = 0.1130s	
57/2700 (epoch 1.056), train_loss = 3.28146321, grad/param norm = 1.1329e+00, time/batch = 0.1139s	
58/2700 (epoch 1.074), train_loss = 3.30487676, grad/param norm = 9.8666e-01, time/batch = 0.1135s	
59/2700 (epoch 1.093), train_loss = 3.31818372, grad/param norm = 1.1601e+00, time/batch = 0.1125s	
60/2700 (epoch 1.111), train_loss = 3.29351025, grad/param norm = 1.2941e+00, time/batch = 0.1132s	
61/2700 (epoch 1.130), train_loss = 3.31507221, grad/param norm = 1.2901e+00, time/batch = 0.0995s	
62/2700 (epoch 1.148), train_loss = 3.26928236, grad/param norm = 1.6286e+00, time/batch = 0.0734s	
63/2700 (epoch 1.167), train_loss = 3.30541309, grad/param norm = 1.7931e+00, time/batch = 0.1123s	
64/2700 (epoch 1.185), train_loss = 3.27817665, grad/param norm = 1.6739e+00, time/batch = 0.1139s	
65/2700 (epoch 1.204), train_loss = 3.20986145, grad/param norm = 1.7180e+00, time/batch = 0.1132s	
66/2700 (epoch 1.222), train_loss = 3.18453622, grad/param norm = 2.0207e+00, time/batch = 0.1126s	
67/2700 (epoch 1.241), train_loss = 3.20169221, grad/param norm = 1.7833e+00, time/batch = 0.1147s	
68/2700 (epoch 1.259), train_loss = 3.23728533, grad/param norm = 1.7228e+00, time/batch = 0.1136s	
69/2700 (epoch 1.278), train_loss = 3.32715000, grad/param norm = 2.0868e+00, time/batch = 0.1137s	
70/2700 (epoch 1.296), train_loss = 3.32320992, grad/param norm = 1.8774e+00, time/batch = 0.1150s	
71/2700 (epoch 1.315), train_loss = 3.29077677, grad/param norm = 1.4373e+00, time/batch = 0.1011s	
72/2700 (epoch 1.333), train_loss = 3.35601543, grad/param norm = 1.1050e+00, time/batch = 0.0698s	
73/2700 (epoch 1.352), train_loss = 3.36434526, grad/param norm = 1.1916e+00, time/batch = 0.1148s	
74/2700 (epoch 1.370), train_loss = 3.31698863, grad/param norm = 1.3290e+00, time/batch = 0.1146s	
75/2700 (epoch 1.389), train_loss = 3.27643876, grad/param norm = 1.2972e+00, time/batch = 0.1146s	
76/2700 (epoch 1.407), train_loss = 3.30216290, grad/param norm = 1.2268e+00, time/batch = 0.1153s	
77/2700 (epoch 1.426), train_loss = 3.30091128, grad/param norm = 1.1730e+00, time/batch = 0.1141s	
78/2700 (epoch 1.444), train_loss = 3.22400051, grad/param norm = 1.2207e+00, time/batch = 0.1143s	
79/2700 (epoch 1.463), train_loss = 3.27354231, grad/param norm = 1.5134e+00, time/batch = 0.1148s	
80/2700 (epoch 1.481), train_loss = 3.35999518, grad/param norm = 1.6955e+00, time/batch = 0.1146s	
81/2700 (epoch 1.500), train_loss = 3.40289432, grad/param norm = 1.9383e+00, time/batch = 0.1111s	
82/2700 (epoch 1.519), train_loss = 3.36326735, grad/param norm = 1.9984e+00, time/batch = 0.1069s	
83/2700 (epoch 1.537), train_loss = 3.36661623, grad/param norm = 1.8084e+00, time/batch = 0.1136s	
84/2700 (epoch 1.556), train_loss = 3.30212816, grad/param norm = 1.4606e+00, time/batch = 0.1142s	
85/2700 (epoch 1.574), train_loss = 3.24092014, grad/param norm = 1.1194e+00, time/batch = 0.1155s	
86/2700 (epoch 1.593), train_loss = 3.25084366, grad/param norm = 1.3519e+00, time/batch = 0.1152s	
87/2700 (epoch 1.611), train_loss = 3.19337645, grad/param norm = 1.2348e+00, time/batch = 0.1143s	
88/2700 (epoch 1.630), train_loss = 3.23477121, grad/param norm = 1.3869e+00, time/batch = 0.1158s	
89/2700 (epoch 1.648), train_loss = 3.31529353, grad/param norm = 1.5283e+00, time/batch = 0.1147s	
90/2700 (epoch 1.667), train_loss = 3.25457511, grad/param norm = 1.5897e+00, time/batch = 0.1138s	
91/2700 (epoch 1.685), train_loss = 3.24356728, grad/param norm = 1.4811e+00, time/batch = 0.0769s	
92/2700 (epoch 1.704), train_loss = 3.22300619, grad/param norm = 1.6630e+00, time/batch = 0.1152s	
93/2700 (epoch 1.722), train_loss = 3.21446123, grad/param norm = 1.5216e+00, time/batch = 0.1141s	
94/2700 (epoch 1.741), train_loss = 3.33881279, grad/param norm = 1.3816e+00, time/batch = 0.1141s	
95/2700 (epoch 1.759), train_loss = 3.29552589, grad/param norm = 1.6706e+00, time/batch = 0.1151s	
96/2700 (epoch 1.778), train_loss = 3.29765313, grad/param norm = 2.0660e+00, time/batch = 0.1158s	
97/2700 (epoch 1.796), train_loss = 3.30127936, grad/param norm = 2.0243e+00, time/batch = 0.1075s	
98/2700 (epoch 1.815), train_loss = 3.23269855, grad/param norm = 1.7965e+00, time/batch = 0.1074s	
99/2700 (epoch 1.833), train_loss = 3.27336307, grad/param norm = 1.7870e+00, time/batch = 0.1116s	
100/2700 (epoch 1.852), train_loss = 3.26208414, grad/param norm = 1.8154e+00, time/batch = 0.1167s	
101/2700 (epoch 1.870), train_loss = 3.25469622, grad/param norm = 1.5180e+00, time/batch = 0.1066s	
102/2700 (epoch 1.889), train_loss = 3.27203840, grad/param norm = 1.3079e+00, time/batch = 0.1091s	
103/2700 (epoch 1.907), train_loss = 3.31813812, grad/param norm = 1.3658e+00, time/batch = 0.1103s	
104/2700 (epoch 1.926), train_loss = 3.28364866, grad/param norm = 1.6312e+00, time/batch = 0.1058s	
105/2700 (epoch 1.944), train_loss = 3.29972000, grad/param norm = 1.4226e+00, time/batch = 0.1126s	
106/2700 (epoch 1.963), train_loss = 3.36355325, grad/param norm = 1.2445e+00, time/batch = 0.1124s	
107/2700 (epoch 1.981), train_loss = 3.42049842, grad/param norm = 1.2552e+00, time/batch = 0.1129s	
108/2700 (epoch 2.000), train_loss = 3.32988568, grad/param norm = 1.2695e+00, time/batch = 0.1101s	
109/2700 (epoch 2.019), train_loss = 3.26107430, grad/param norm = 1.3606e+00, time/batch = 0.1098s	
110/2700 (epoch 2.037), train_loss = 3.28603099, grad/param norm = 1.4118e+00, time/batch = 0.1093s	
111/2700 (epoch 2.056), train_loss = 3.27899946, grad/param norm = 1.0611e+00, time/batch = 0.1016s	
112/2700 (epoch 2.074), train_loss = 3.30514791, grad/param norm = 9.5742e-01, time/batch = 0.1046s	
113/2700 (epoch 2.093), train_loss = 3.31889950, grad/param norm = 1.1460e+00, time/batch = 0.1094s	
114/2700 (epoch 2.111), train_loss = 3.29409914, grad/param norm = 1.2390e+00, time/batch = 0.1037s	
115/2700 (epoch 2.130), train_loss = 3.31416395, grad/param norm = 1.1870e+00, time/batch = 0.1032s	
116/2700 (epoch 2.148), train_loss = 3.26924632, grad/param norm = 1.4634e+00, time/batch = 0.1053s	
117/2700 (epoch 2.167), train_loss = 3.29896046, grad/param norm = 1.6159e+00, time/batch = 0.1052s	
118/2700 (epoch 2.185), train_loss = 3.27401109, grad/param norm = 1.4024e+00, time/batch = 0.1048s	
119/2700 (epoch 2.204), train_loss = 3.20381595, grad/param norm = 1.3819e+00, time/batch = 0.1067s	
120/2700 (epoch 2.222), train_loss = 3.17672047, grad/param norm = 1.7286e+00, time/batch = 0.1071s	
121/2700 (epoch 2.241), train_loss = 3.20190299, grad/param norm = 1.7227e+00, time/batch = 0.1012s	
122/2700 (epoch 2.259), train_loss = 3.23982543, grad/param norm = 1.7907e+00, time/batch = 0.1064s	
123/2700 (epoch 2.278), train_loss = 3.32414839, grad/param norm = 2.4830e+00, time/batch = 0.1115s	
124/2700 (epoch 2.296), train_loss = 3.33783011, grad/param norm = 2.2557e+00, time/batch = 0.1116s	
125/2700 (epoch 2.315), train_loss = 3.29791124, grad/param norm = 1.5510e+00, time/batch = 0.1236s	
126/2700 (epoch 2.333), train_loss = 3.35782791, grad/param norm = 1.1774e+00, time/batch = 0.1559s	
127/2700 (epoch 2.352), train_loss = 3.36722365, grad/param norm = 1.2683e+00, time/batch = 0.1630s	
128/2700 (epoch 2.370), train_loss = 3.32157420, grad/param norm = 1.4311e+00, time/batch = 0.1670s	
129/2700 (epoch 2.389), train_loss = 3.27906433, grad/param norm = 1.3724e+00, time/batch = 0.1696s	
130/2700 (epoch 2.407), train_loss = 3.30296643, grad/param norm = 1.2745e+00, time/batch = 0.1666s	
131/2700 (epoch 2.426), train_loss = 3.30108109, grad/param norm = 1.2033e+00, time/batch = 0.1745s	
132/2700 (epoch 2.444), train_loss = 3.22473304, grad/param norm = 1.2486e+00, time/batch = 0.1852s	
133/2700 (epoch 2.463), train_loss = 3.27454545, grad/param norm = 1.5161e+00, time/batch = 0.1717s	
134/2700 (epoch 2.481), train_loss = 3.36197555, grad/param norm = 1.6754e+00, time/batch = 0.1526s	
135/2700 (epoch 2.500), train_loss = 3.40549252, grad/param norm = 1.9050e+00, time/batch = 0.1299s	
136/2700 (epoch 2.519), train_loss = 3.36304175, grad/param norm = 1.9641e+00, time/batch = 0.1666s	
137/2700 (epoch 2.537), train_loss = 3.36665247, grad/param norm = 1.7811e+00, time/batch = 0.1668s	
138/2700 (epoch 2.556), train_loss = 3.30174053, grad/param norm = 1.4326e+00, time/batch = 0.1664s	
139/2700 (epoch 2.574), train_loss = 3.24137743, grad/param norm = 1.1094e+00, time/batch = 0.1658s	
140/2700 (epoch 2.593), train_loss = 3.25122471, grad/param norm = 1.3495e+00, time/batch = 0.1668s	
141/2700 (epoch 2.611), train_loss = 3.19368474, grad/param norm = 1.2327e+00, time/batch = 0.1476s	
142/2700 (epoch 2.630), train_loss = 3.23454279, grad/param norm = 1.3745e+00, time/batch = 0.1533s	
143/2700 (epoch 2.648), train_loss = 3.31503674, grad/param norm = 1.5115e+00, time/batch = 0.1507s	
144/2700 (epoch 2.667), train_loss = 3.25405169, grad/param norm = 1.5783e+00, time/batch = 0.1508s	
145/2700 (epoch 2.685), train_loss = 3.24363458, grad/param norm = 1.4739e+00, time/batch = 0.1258s	
146/2700 (epoch 2.704), train_loss = 3.22236664, grad/param norm = 1.6587e+00, time/batch = 0.1607s	
147/2700 (epoch 2.722), train_loss = 3.21523024, grad/param norm = 1.5370e+00, time/batch = 0.1622s	
148/2700 (epoch 2.741), train_loss = 3.34028831, grad/param norm = 1.4127e+00, time/batch = 0.1622s	
149/2700 (epoch 2.759), train_loss = 3.29707967, grad/param norm = 1.6825e+00, time/batch = 0.1625s	
150/2700 (epoch 2.778), train_loss = 3.29679494, grad/param norm = 2.0468e+00, time/batch = 0.1617s	
151/2700 (epoch 2.796), train_loss = 3.30046193, grad/param norm = 2.0098e+00, time/batch = 0.1530s	
152/2700 (epoch 2.815), train_loss = 3.23286058, grad/param norm = 1.7898e+00, time/batch = 0.1528s	
153/2700 (epoch 2.833), train_loss = 3.27358557, grad/param norm = 1.7866e+00, time/batch = 0.1512s	
154/2700 (epoch 2.852), train_loss = 3.26232844, grad/param norm = 1.8313e+00, time/batch = 0.1514s	
155/2700 (epoch 2.870), train_loss = 3.25563122, grad/param norm = 1.5350e+00, time/batch = 0.1286s	
156/2700 (epoch 2.889), train_loss = 3.27215987, grad/param norm = 1.3115e+00, time/batch = 0.1620s	
157/2700 (epoch 2.907), train_loss = 3.31901337, grad/param norm = 1.3588e+00, time/batch = 0.1644s	
158/2700 (epoch 2.926), train_loss = 3.28406724, grad/param norm = 1.6314e+00, time/batch = 0.1612s	
159/2700 (epoch 2.944), train_loss = 3.30008504, grad/param norm = 1.4188e+00, time/batch = 0.1625s	
160/2700 (epoch 2.963), train_loss = 3.36338026, grad/param norm = 1.2391e+00, time/batch = 0.1624s	
161/2700 (epoch 2.981), train_loss = 3.42084793, grad/param norm = 1.2531e+00, time/batch = 0.1558s	
162/2700 (epoch 3.000), train_loss = 3.33016051, grad/param norm = 1.2637e+00, time/batch = 0.1530s	
163/2700 (epoch 3.019), train_loss = 3.26182058, grad/param norm = 1.3537e+00, time/batch = 0.1513s	
164/2700 (epoch 3.037), train_loss = 3.28694274, grad/param norm = 1.4095e+00, time/batch = 0.1509s	
165/2700 (epoch 3.056), train_loss = 3.27890201, grad/param norm = 1.0597e+00, time/batch = 0.1381s	
166/2700 (epoch 3.074), train_loss = 3.30484276, grad/param norm = 9.5300e-01, time/batch = 0.1854s	
167/2700 (epoch 3.093), train_loss = 3.31907129, grad/param norm = 1.1424e+00, time/batch = 0.1968s	
168/2700 (epoch 3.111), train_loss = 3.29410339, grad/param norm = 1.2405e+00, time/batch = 0.1979s	
169/2700 (epoch 3.130), train_loss = 3.31420993, grad/param norm = 1.1930e+00, time/batch = 0.2023s	
170/2700 (epoch 3.148), train_loss = 3.26971153, grad/param norm = 1.4734e+00, time/batch = 0.2000s	
171/2700 (epoch 3.167), train_loss = 3.29904862, grad/param norm = 1.6284e+00, time/batch = 0.1915s	
172/2700 (epoch 3.185), train_loss = 3.27433630, grad/param norm = 1.4376e+00, time/batch = 0.2005s	
173/2700 (epoch 3.204), train_loss = 3.20491801, grad/param norm = 1.4571e+00, time/batch = 0.2020s	
174/2700 (epoch 3.222), train_loss = 3.17950015, grad/param norm = 1.8474e+00, time/batch = 0.1935s	
175/2700 (epoch 3.241), train_loss = 3.20468906, grad/param norm = 1.8872e+00, time/batch = 0.1917s	
176/2700 (epoch 3.259), train_loss = 3.24315259, grad/param norm = 1.8925e+00, time/batch = 0.1741s	
177/2700 (epoch 3.278), train_loss = 3.32209529, grad/param norm = 2.3691e+00, time/batch = 0.1769s	
178/2700 (epoch 3.296), train_loss = 3.33467788, grad/param norm = 2.1883e+00, time/batch = 0.1804s	
179/2700 (epoch 3.315), train_loss = 3.29872267, grad/param norm = 1.5299e+00, time/batch = 0.1839s	
180/2700 (epoch 3.333), train_loss = 3.35691280, grad/param norm = 1.1180e+00, time/batch = 0.1887s	
181/2700 (epoch 3.352), train_loss = 3.36595829, grad/param norm = 1.2217e+00, time/batch = 0.1717s	
182/2700 (epoch 3.370), train_loss = 3.32089354, grad/param norm = 1.3776e+00, time/batch = 0.1739s	
183/2700 (epoch 3.389), train_loss = 3.27719668, grad/param norm = 1.3110e+00, time/batch = 0.1819s	
184/2700 (epoch 3.407), train_loss = 3.30189203, grad/param norm = 1.2216e+00, time/batch = 0.1593s	
185/2700 (epoch 3.426), train_loss = 3.30037318, grad/param norm = 1.1635e+00, time/batch = 0.1754s	
186/2700 (epoch 3.444), train_loss = 3.22384477, grad/param norm = 1.2064e+00, time/batch = 0.1720s	
187/2700 (epoch 3.463), train_loss = 3.27390859, grad/param norm = 1.4781e+00, time/batch = 0.1922s	
188/2700 (epoch 3.481), train_loss = 3.36135512, grad/param norm = 1.6494e+00, time/batch = 0.2070s	
189/2700 (epoch 3.500), train_loss = 3.40567226, grad/param norm = 1.9099e+00, time/batch = 0.2171s	
190/2700 (epoch 3.519), train_loss = 3.36382399, grad/param norm = 1.9860e+00, time/batch = 0.2197s	
191/2700 (epoch 3.537), train_loss = 3.36752753, grad/param norm = 1.8044e+00, time/batch = 0.2363s	
192/2700 (epoch 3.556), train_loss = 3.30220838, grad/param norm = 1.4555e+00, time/batch = 0.2408s	
193/2700 (epoch 3.574), train_loss = 3.24188152, grad/param norm = 1.1301e+00, time/batch = 0.2399s	
194/2700 (epoch 3.593), train_loss = 3.25162296, grad/param norm = 1.3672e+00, time/batch = 0.2418s	
195/2700 (epoch 3.611), train_loss = 3.19407254, grad/param norm = 1.2513e+00, time/batch = 0.2519s	
196/2700 (epoch 3.630), train_loss = 3.23490563, grad/param norm = 1.3938e+00, time/batch = 0.2572s	
197/2700 (epoch 3.648), train_loss = 3.31557160, grad/param norm = 1.5274e+00, time/batch = 0.2470s	
198/2700 (epoch 3.667), train_loss = 3.25432632, grad/param norm = 1.5903e+00, time/batch = 0.2562s	
199/2700 (epoch 3.685), train_loss = 3.24378391, grad/param norm = 1.4792e+00, time/batch = 0.2608s	
200/2700 (epoch 3.704), train_loss = 3.22241520, grad/param norm = 1.6621e+00, time/batch = 0.2516s	
201/2700 (epoch 3.722), train_loss = 3.21540766, grad/param norm = 1.5384e+00, time/batch = 0.2561s	
202/2700 (epoch 3.741), train_loss = 3.34041180, grad/param norm = 1.4091e+00, time/batch = 0.2441s	
203/2700 (epoch 3.759), train_loss = 3.29698583, grad/param norm = 1.6750e+00, time/batch = 0.2318s	
204/2700 (epoch 3.778), train_loss = 3.29652544, grad/param norm = 2.0353e+00, time/batch = 0.2386s	
205/2700 (epoch 3.796), train_loss = 3.30015014, grad/param norm = 1.9958e+00, time/batch = 0.2426s	
206/2700 (epoch 3.815), train_loss = 3.23266116, grad/param norm = 1.7802e+00, time/batch = 0.2483s	
207/2700 (epoch 3.833), train_loss = 3.27371470, grad/param norm = 1.7805e+00, time/batch = 0.2522s	
208/2700 (epoch 3.852), train_loss = 3.26224693, grad/param norm = 1.8274e+00, time/batch = 0.2426s	
209/2700 (epoch 3.870), train_loss = 3.25579207, grad/param norm = 1.5373e+00, time/batch = 0.2385s	
210/2700 (epoch 3.889), train_loss = 3.27261428, grad/param norm = 1.3260e+00, time/batch = 0.2344s	
211/2700 (epoch 3.907), train_loss = 3.32152502, grad/param norm = 1.4166e+00, time/batch = 0.2302s	
212/2700 (epoch 3.926), train_loss = 3.28533066, grad/param norm = 1.6452e+00, time/batch = 0.2290s	
213/2700 (epoch 3.944), train_loss = 3.29985019, grad/param norm = 1.4242e+00, time/batch = 0.2001s	
214/2700 (epoch 3.963), train_loss = 3.36362577, grad/param norm = 1.2545e+00, time/batch = 0.2311s	
215/2700 (epoch 3.981), train_loss = 3.42149222, grad/param norm = 1.2606e+00, time/batch = 0.2264s	
216/2700 (epoch 4.000), train_loss = 3.33027210, grad/param norm = 1.2678e+00, time/batch = 0.2307s	
217/2700 (epoch 4.019), train_loss = 3.26218495, grad/param norm = 1.3674e+00, time/batch = 0.2347s	
218/2700 (epoch 4.037), train_loss = 3.28764321, grad/param norm = 1.4164e+00, time/batch = 0.2354s	
219/2700 (epoch 4.056), train_loss = 3.27866249, grad/param norm = 1.0554e+00, time/batch = 0.2497s	
220/2700 (epoch 4.074), train_loss = 3.30470302, grad/param norm = 9.4991e-01, time/batch = 0.2558s	
221/2700 (epoch 4.093), train_loss = 3.31901597, grad/param norm = 1.1415e+00, time/batch = 0.2286s	
222/2700 (epoch 4.111), train_loss = 3.29396963, grad/param norm = 1.2346e+00, time/batch = 0.2367s	
223/2700 (epoch 4.130), train_loss = 3.31374839, grad/param norm = 1.1800e+00, time/batch = 0.2265s	
224/2700 (epoch 4.148), train_loss = 3.26919987, grad/param norm = 1.4570e+00, time/batch = 0.2244s	
225/2700 (epoch 4.167), train_loss = 3.29861353, grad/param norm = 1.6169e+00, time/batch = 0.2213s	
226/2700 (epoch 4.185), train_loss = 3.27373969, grad/param norm = 1.4134e+00, time/batch = 0.2290s	
227/2700 (epoch 4.204), train_loss = 3.20384729, grad/param norm = 1.4135e+00, time/batch = 0.2394s	
228/2700 (epoch 4.222), train_loss = 3.17797301, grad/param norm = 1.7865e+00, time/batch = 0.2323s	
229/2700 (epoch 4.241), train_loss = 3.20314030, grad/param norm = 1.7988e+00, time/batch = 0.2302s	
230/2700 (epoch 4.259), train_loss = 3.24135708, grad/param norm = 1.8316e+00, time/batch = 0.2402s	
231/2700 (epoch 4.278), train_loss = 3.32336037, grad/param norm = 2.4135e+00, time/batch = 0.2621s	
232/2700 (epoch 4.296), train_loss = 3.33666924, grad/param norm = 2.2317e+00, time/batch = 0.2552s	
233/2700 (epoch 4.315), train_loss = 3.29883723, grad/param norm = 1.5457e+00, time/batch = 0.2573s	
234/2700 (epoch 4.333), train_loss = 3.35713508, grad/param norm = 1.1391e+00, time/batch = 0.2578s	
235/2700 (epoch 4.352), train_loss = 3.36626351, grad/param norm = 1.2377e+00, time/batch = 0.2567s	
236/2700 (epoch 4.370), train_loss = 3.32120731, grad/param norm = 1.3981e+00, time/batch = 0.2570s	
237/2700 (epoch 4.389), train_loss = 3.27761215, grad/param norm = 1.3319e+00, time/batch = 0.2547s	
238/2700 (epoch 4.407), train_loss = 3.30219164, grad/param norm = 1.2413e+00, time/batch = 0.2372s	
239/2700 (epoch 4.426), train_loss = 3.30056942, grad/param norm = 1.1788e+00, time/batch = 0.2247s	
240/2700 (epoch 4.444), train_loss = 3.22416272, grad/param norm = 1.2255e+00, time/batch = 0.2414s	
241/2700 (epoch 4.463), train_loss = 3.27431482, grad/param norm = 1.4967e+00, time/batch = 0.2141s	
242/2700 (epoch 4.481), train_loss = 3.36182599, grad/param norm = 1.6620e+00, time/batch = 0.1938s	
243/2700 (epoch 4.500), train_loss = 3.40565753, grad/param norm = 1.9051e+00, time/batch = 0.2221s	
244/2700 (epoch 4.519), train_loss = 3.36326661, grad/param norm = 1.9692e+00, time/batch = 0.2268s	
245/2700 (epoch 4.537), train_loss = 3.36702612, grad/param norm = 1.7892e+00, time/batch = 0.2405s	
246/2700 (epoch 4.556), train_loss = 3.30200289, grad/param norm = 1.4436e+00, time/batch = 0.2347s	
247/2700 (epoch 4.574), train_loss = 3.24168479, grad/param norm = 1.1189e+00, time/batch = 0.2381s	
248/2700 (epoch 4.593), train_loss = 3.25141109, grad/param norm = 1.3557e+00, time/batch = 0.2308s	
249/2700 (epoch 4.611), train_loss = 3.19383634, grad/param norm = 1.2391e+00, time/batch = 0.2185s	
250/2700 (epoch 4.630), train_loss = 3.23463621, grad/param norm = 1.3808e+00, time/batch = 0.2343s	
251/2700 (epoch 4.648), train_loss = 3.31522190, grad/param norm = 1.5157e+00, time/batch = 0.2532s	
252/2700 (epoch 4.667), train_loss = 3.25419037, grad/param norm = 1.5823e+00, time/batch = 0.2596s	
253/2700 (epoch 4.685), train_loss = 3.24375357, grad/param norm = 1.4753e+00, time/batch = 0.2570s	
254/2700 (epoch 4.704), train_loss = 3.22246097, grad/param norm = 1.6590e+00, time/batch = 0.2598s	
255/2700 (epoch 4.722), train_loss = 3.21537899, grad/param norm = 1.5363e+00, time/batch = 0.2599s	
256/2700 (epoch 4.741), train_loss = 3.34049601, grad/param norm = 1.4098e+00, time/batch = 0.2538s	
257/2700 (epoch 4.759), train_loss = 3.29704506, grad/param norm = 1.6766e+00, time/batch = 0.2349s	
258/2700 (epoch 4.778), train_loss = 3.29667552, grad/param norm = 2.0384e+00, time/batch = 0.2579s	
259/2700 (epoch 4.796), train_loss = 3.30041213, grad/param norm = 2.0013e+00, time/batch = 0.2529s	
260/2700 (epoch 4.815), train_loss = 3.23284980, grad/param norm = 1.7842e+00, time/batch = 0.2261s	
261/2700 (epoch 4.833), train_loss = 3.27389959, grad/param norm = 1.7827e+00, time/batch = 0.2198s	
262/2700 (epoch 4.852), train_loss = 3.26232244, grad/param norm = 1.8283e+00, time/batch = 0.2221s	
263/2700 (epoch 4.870), train_loss = 3.25578731, grad/param norm = 1.5350e+00, time/batch = 0.2148s	
264/2700 (epoch 4.889), train_loss = 3.27258584, grad/param norm = 1.3225e+00, time/batch = 0.2167s	
265/2700 (epoch 4.907), train_loss = 3.32148813, grad/param norm = 1.4120e+00, time/batch = 0.2292s	
266/2700 (epoch 4.926), train_loss = 3.28530406, grad/param norm = 1.6412e+00, time/batch = 0.2394s	
267/2700 (epoch 4.944), train_loss = 3.29985993, grad/param norm = 1.4213e+00, time/batch = 0.2381s	
268/2700 (epoch 4.963), train_loss = 3.36361674, grad/param norm = 1.2520e+00, time/batch = 0.2416s	
269/2700 (epoch 4.981), train_loss = 3.42150161, grad/param norm = 1.2585e+00, time/batch = 0.2502s	
270/2700 (epoch 5.000), train_loss = 3.33023768, grad/param norm = 1.2649e+00, time/batch = 0.2490s	
271/2700 (epoch 5.019), train_loss = 3.26213959, grad/param norm = 1.3638e+00, time/batch = 0.2367s	
272/2700 (epoch 5.037), train_loss = 3.28761614, grad/param norm = 1.4129e+00, time/batch = 0.2582s	
273/2700 (epoch 5.056), train_loss = 3.27864979, grad/param norm = 1.0532e+00, time/batch = 0.2575s	
274/2700 (epoch 5.074), train_loss = 3.30471256, grad/param norm = 9.4882e-01, time/batch = 0.2563s	
275/2700 (epoch 5.093), train_loss = 3.31901694, grad/param norm = 1.1402e+00, time/batch = 0.2554s	
276/2700 (epoch 5.111), train_loss = 3.29396729, grad/param norm = 1.2324e+00, time/batch = 0.2491s	
277/2700 (epoch 5.130), train_loss = 3.31372263, grad/param norm = 1.1774e+00, time/batch = 0.2527s	
278/2700 (epoch 5.148), train_loss = 3.26918479, grad/param norm = 1.4523e+00, time/batch = 0.2439s	
279/2700 (epoch 5.167), train_loss = 3.29845269, grad/param norm = 1.6119e+00, time/batch = 0.2308s	
280/2700 (epoch 5.185), train_loss = 3.27364144, grad/param norm = 1.4052e+00, time/batch = 0.2181s	
281/2700 (epoch 5.204), train_loss = 3.20362659, grad/param norm = 1.3996e+00, time/batch = 0.2111s	
282/2700 (epoch 5.222), train_loss = 3.17757545, grad/param norm = 1.7667e+00, time/batch = 0.2101s	
283/2700 (epoch 5.241), train_loss = 3.20276314, grad/param norm = 1.7731e+00, time/batch = 0.1992s	
284/2700 (epoch 5.259), train_loss = 3.24096244, grad/param norm = 1.8154e+00, time/batch = 0.2026s	
285/2700 (epoch 5.278), train_loss = 3.32374908, grad/param norm = 2.4277e+00, time/batch = 0.2202s	
286/2700 (epoch 5.296), train_loss = 3.33718683, grad/param norm = 2.2388e+00, time/batch = 0.2197s	
287/2700 (epoch 5.315), train_loss = 3.29867326, grad/param norm = 1.5461e+00, time/batch = 0.2317s	
288/2700 (epoch 5.333), train_loss = 3.35727833, grad/param norm = 1.1433e+00, time/batch = 0.2426s	
289/2700 (epoch 5.352), train_loss = 3.36635322, grad/param norm = 1.2414e+00, time/batch = 0.2608s	
290/2700 (epoch 5.370), train_loss = 3.32136120, grad/param norm = 1.4040e+00, time/batch = 0.2556s	
291/2700 (epoch 5.389), train_loss = 3.27781267, grad/param norm = 1.3375e+00, time/batch = 0.2255s	
292/2700 (epoch 5.407), train_loss = 3.30230566, grad/param norm = 1.2459e+00, time/batch = 0.2583s	
293/2700 (epoch 5.426), train_loss = 3.30063669, grad/param norm = 1.1819e+00, time/batch = 0.2584s	
294/2700 (epoch 5.444), train_loss = 3.22426505, grad/param norm = 1.2292e+00, time/batch = 0.2598s	
295/2700 (epoch 5.463), train_loss = 3.27444283, grad/param norm = 1.4993e+00, time/batch = 0.2551s	
296/2700 (epoch 5.481), train_loss = 3.36199066, grad/param norm = 1.6597e+00, time/batch = 0.2588s	
297/2700 (epoch 5.500), train_loss = 3.40521242, grad/param norm = 1.8894e+00, time/batch = 0.2565s	
298/2700 (epoch 5.519), train_loss = 3.36270997, grad/param norm = 1.9536e+00, time/batch = 0.2553s	
299/2700 (epoch 5.537), train_loss = 3.36686271, grad/param norm = 1.7820e+00, time/batch = 0.2562s	
300/2700 (epoch 5.556), train_loss = 3.30200721, grad/param norm = 1.4405e+00, time/batch = 0.2507s	
301/2700 (epoch 5.574), train_loss = 3.24159709, grad/param norm = 1.1149e+00, time/batch = 0.2390s	
302/2700 (epoch 5.593), train_loss = 3.25125212, grad/param norm = 1.3486e+00, time/batch = 0.2397s	
303/2700 (epoch 5.611), train_loss = 3.19362931, grad/param norm = 1.2316e+00, time/batch = 0.2403s	
304/2700 (epoch 5.630), train_loss = 3.23450264, grad/param norm = 1.3756e+00, time/batch = 0.2335s	
305/2700 (epoch 5.648), train_loss = 3.31524236, grad/param norm = 1.5128e+00, time/batch = 0.2263s	
306/2700 (epoch 5.667), train_loss = 3.25427160, grad/param norm = 1.5805e+00, time/batch = 0.2254s	
307/2700 (epoch 5.685), train_loss = 3.24387762, grad/param norm = 1.4751e+00, time/batch = 0.2349s	
308/2700 (epoch 5.704), train_loss = 3.22272393, grad/param norm = 1.6596e+00, time/batch = 0.2408s	
309/2700 (epoch 5.722), train_loss = 3.21551813, grad/param norm = 1.5367e+00, time/batch = 0.2482s	
310/2700 (epoch 5.741), train_loss = 3.34064559, grad/param norm = 1.4109e+00, time/batch = 0.2450s	
311/2700 (epoch 5.759), train_loss = 3.29725998, grad/param norm = 1.6773e+00, time/batch = 0.2402s	
312/2700 (epoch 5.778), train_loss = 3.29675951, grad/param norm = 2.0370e+00, time/batch = 0.2261s	
313/2700 (epoch 5.796), train_loss = 3.30046903, grad/param norm = 1.9992e+00, time/batch = 0.2536s	
314/2700 (epoch 5.815), train_loss = 3.23287354, grad/param norm = 1.7816e+00, time/batch = 0.2430s	
315/2700 (epoch 5.833), train_loss = 3.27386724, grad/param norm = 1.7789e+00, time/batch = 0.2429s	
316/2700 (epoch 5.852), train_loss = 3.26226690, grad/param norm = 1.8238e+00, time/batch = 0.2381s	
317/2700 (epoch 5.870), train_loss = 3.25576089, grad/param norm = 1.5311e+00, time/batch = 0.2316s	
318/2700 (epoch 5.889), train_loss = 3.27257200, grad/param norm = 1.3189e+00, time/batch = 0.2299s	
319/2700 (epoch 5.907), train_loss = 3.32146151, grad/param norm = 1.4080e+00, time/batch = 0.2320s	
320/2700 (epoch 5.926), train_loss = 3.28546650, grad/param norm = 1.6372e+00, time/batch = 0.2237s	
321/2700 (epoch 5.944), train_loss = 3.30025185, grad/param norm = 1.4243e+00, time/batch = 0.2283s	
322/2700 (epoch 5.963), train_loss = 3.36345888, grad/param norm = 1.2461e+00, time/batch = 0.2215s	
323/2700 (epoch 5.981), train_loss = 3.42124369, grad/param norm = 1.2451e+00, time/batch = 0.2176s	
324/2700 (epoch 6.000), train_loss = 3.32998816, grad/param norm = 1.2534e+00, time/batch = 0.1922s	
325/2700 (epoch 6.019), train_loss = 3.26196689, grad/param norm = 1.3519e+00, time/batch = 0.2164s	
326/2700 (epoch 6.037), train_loss = 3.28760305, grad/param norm = 1.4072e+00, time/batch = 0.2148s	
327/2700 (epoch 6.056), train_loss = 3.27881810, grad/param norm = 1.0566e+00, time/batch = 0.2279s	
328/2700 (epoch 6.074), train_loss = 3.30498590, grad/param norm = 9.5422e-01, time/batch = 0.2395s	
329/2700 (epoch 6.093), train_loss = 3.31919855, grad/param norm = 1.1442e+00, time/batch = 0.2508s	
330/2700 (epoch 6.111), train_loss = 3.29420982, grad/param norm = 1.2358e+00, time/batch = 0.2387s	
331/2700 (epoch 6.130), train_loss = 3.31395861, grad/param norm = 1.1800e+00, time/batch = 0.2333s	
332/2700 (epoch 6.148), train_loss = 3.26912635, grad/param norm = 1.4495e+00, time/batch = 0.2494s	
333/2700 (epoch 6.167), train_loss = 3.29830924, grad/param norm = 1.6025e+00, time/batch = 0.2445s	
334/2700 (epoch 6.185), train_loss = 3.27330141, grad/param norm = 1.3891e+00, time/batch = 0.2452s	
335/2700 (epoch 6.204), train_loss = 3.20331703, grad/param norm = 1.3804e+00, time/batch = 0.2501s	
336/2700 (epoch 6.222), train_loss = 3.17723280, grad/param norm = 1.7392e+00, time/batch = 0.2563s	
337/2700 (epoch 6.241), train_loss = 3.20222963, grad/param norm = 1.7286e+00, time/batch = 0.2579s	
338/2700 (epoch 6.259), train_loss = 3.23982948, grad/param norm = 1.7749e+00, time/batch = 0.2594s	
339/2700 (epoch 6.278), train_loss = 3.32339942, grad/param norm = 2.4206e+00, time/batch = 0.2514s	
340/2700 (epoch 6.296), train_loss = 3.33620335, grad/param norm = 2.2081e+00, time/batch = 0.2498s	
341/2700 (epoch 6.315), train_loss = 3.29775653, grad/param norm = 1.5464e+00, time/batch = 0.2590s	
342/2700 (epoch 6.333), train_loss = 3.35828114, grad/param norm = 1.1793e+00, time/batch = 0.2543s	
343/2700 (epoch 6.352), train_loss = 3.36753914, grad/param norm = 1.2719e+00, time/batch = 0.2270s	
344/2700 (epoch 6.370), train_loss = 3.32223366, grad/param norm = 1.4293e+00, time/batch = 0.2270s	
345/2700 (epoch 6.389), train_loss = 3.27867963, grad/param norm = 1.3611e+00, time/batch = 0.2194s	
346/2700 (epoch 6.407), train_loss = 3.30291331, grad/param norm = 1.2666e+00, time/batch = 0.2098s	
347/2700 (epoch 6.426), train_loss = 3.30104189, grad/param norm = 1.1969e+00, time/batch = 0.2081s	
348/2700 (epoch 6.444), train_loss = 3.22465109, grad/param norm = 1.2447e+00, time/batch = 0.2082s	
349/2700 (epoch 6.463), train_loss = 3.27480341, grad/param norm = 1.5099e+00, time/batch = 0.2034s	
350/2700 (epoch 6.481), train_loss = 3.36216829, grad/param norm = 1.6650e+00, time/batch = 0.2358s	
351/2700 (epoch 6.500), train_loss = 3.40566452, grad/param norm = 1.8912e+00, time/batch = 0.2212s	
352/2700 (epoch 6.519), train_loss = 3.36294875, grad/param norm = 1.9488e+00, time/batch = 0.2364s	
353/2700 (epoch 6.537), train_loss = 3.36674078, grad/param norm = 1.7684e+00, time/batch = 0.2361s	
354/2700 (epoch 6.556), train_loss = 3.30168363, grad/param norm = 1.4231e+00, time/batch = 0.2275s	
355/2700 (epoch 6.574), train_loss = 3.24148399, grad/param norm = 1.1020e+00, time/batch = 0.2418s	
356/2700 (epoch 6.593), train_loss = 3.25121989, grad/param norm = 1.3392e+00, time/batch = 0.2448s	
357/2700 (epoch 6.611), train_loss = 3.19361834, grad/param norm = 1.2235e+00, time/batch = 0.2523s	
358/2700 (epoch 6.630), train_loss = 3.23443364, grad/param norm = 1.3638e+00, time/batch = 0.2535s	
359/2700 (epoch 6.648), train_loss = 3.31492999, grad/param norm = 1.4989e+00, time/batch = 0.2488s	
360/2700 (epoch 6.667), train_loss = 3.25398144, grad/param norm = 1.5668e+00, time/batch = 0.2409s	
361/2700 (epoch 6.685), train_loss = 3.24357953, grad/param norm = 1.4630e+00, time/batch = 0.2603s	
362/2700 (epoch 6.704), train_loss = 3.22232551, grad/param norm = 1.6474e+00, time/batch = 0.2503s	
363/2700 (epoch 6.722), train_loss = 3.21530303, grad/param norm = 1.5279e+00, time/batch = 0.2586s	
364/2700 (epoch 6.741), train_loss = 3.34052079, grad/param norm = 1.4046e+00, time/batch = 0.2565s	
365/2700 (epoch 6.759), train_loss = 3.29714315, grad/param norm = 1.6724e+00, time/batch = 0.2275s	
366/2700 (epoch 6.778), train_loss = 3.29686679, grad/param norm = 2.0351e+00, time/batch = 0.2183s	
367/2700 (epoch 6.796), train_loss = 3.30066489, grad/param norm = 1.9986e+00, time/batch = 0.2056s	
368/2700 (epoch 6.815), train_loss = 3.23299995, grad/param norm = 1.7806e+00, time/batch = 0.1952s	
369/2700 (epoch 6.833), train_loss = 3.27402598, grad/param norm = 1.7775e+00, time/batch = 0.2304s	
370/2700 (epoch 6.852), train_loss = 3.26242145, grad/param norm = 1.8219e+00, time/batch = 0.2312s	
371/2700 (epoch 6.870), train_loss = 3.25579317, grad/param norm = 1.5262e+00, time/batch = 0.2202s	
372/2700 (epoch 6.889), train_loss = 3.27254213, grad/param norm = 1.3134e+00, time/batch = 0.2168s	
373/2700 (epoch 6.907), train_loss = 3.32143971, grad/param norm = 1.4021e+00, time/batch = 0.2261s	
374/2700 (epoch 6.926), train_loss = 3.28524559, grad/param norm = 1.6305e+00, time/batch = 0.2361s	
375/2700 (epoch 6.944), train_loss = 3.29983230, grad/param norm = 1.4128e+00, time/batch = 0.2242s	
376/2700 (epoch 6.963), train_loss = 3.36361024, grad/param norm = 1.2447e+00, time/batch = 0.2390s	
377/2700 (epoch 6.981), train_loss = 3.42148101, grad/param norm = 1.2517e+00, time/batch = 0.2360s	
378/2700 (epoch 7.000), train_loss = 3.33022962, grad/param norm = 1.2576e+00, time/batch = 0.2228s	
379/2700 (epoch 7.019), train_loss = 3.26210403, grad/param norm = 1.3557e+00, time/batch = 0.2505s	
380/2700 (epoch 7.037), train_loss = 3.28757571, grad/param norm = 1.4041e+00, time/batch = 0.2405s	
381/2700 (epoch 7.056), train_loss = 3.27861584, grad/param norm = 1.0466e+00, time/batch = 0.2290s	
382/2700 (epoch 7.074), train_loss = 3.30470234, grad/param norm = 9.4375e-01, time/batch = 0.2289s	
383/2700 (epoch 7.093), train_loss = 3.31901144, grad/param norm = 1.1344e+00, time/batch = 0.2278s	
384/2700 (epoch 7.111), train_loss = 3.29396181, grad/param norm = 1.2258e+00, time/batch = 0.2272s	
385/2700 (epoch 7.130), train_loss = 3.31371114, grad/param norm = 1.1709e+00, time/batch = 0.2297s	
386/2700 (epoch 7.148), train_loss = 3.26917278, grad/param norm = 1.4437e+00, time/batch = 0.1891s	
387/2700 (epoch 7.167), train_loss = 3.29838929, grad/param norm = 1.6024e+00, time/batch = 0.2425s	
388/2700 (epoch 7.185), train_loss = 3.27358104, grad/param norm = 1.3944e+00, time/batch = 0.2292s	
389/2700 (epoch 7.204), train_loss = 3.20350043, grad/param norm = 1.3858e+00, time/batch = 0.2366s	
390/2700 (epoch 7.222), train_loss = 3.17735025, grad/param norm = 1.7478e+00, time/batch = 0.2319s	
391/2700 (epoch 7.241), train_loss = 3.20253923, grad/param norm = 1.7508e+00, time/batch = 0.2334s	
392/2700 (epoch 7.259), train_loss = 3.24072934, grad/param norm = 1.7981e+00, time/batch = 0.2558s	
393/2700 (epoch 7.278), train_loss = 3.32397632, grad/param norm = 2.4255e+00, time/batch = 0.2484s	
394/2700 (epoch 7.296), train_loss = 3.33752302, grad/param norm = 2.2340e+00, time/batch = 0.2449s	
395/2700 (epoch 7.315), train_loss = 3.29860940, grad/param norm = 1.5400e+00, time/batch = 0.2400s	
396/2700 (epoch 7.333), train_loss = 3.35735929, grad/param norm = 1.1411e+00, time/batch = 0.2318s	
397/2700 (epoch 7.352), train_loss = 3.36641323, grad/param norm = 1.2382e+00, time/batch = 0.2346s	
398/2700 (epoch 7.370), train_loss = 3.32143617, grad/param norm = 1.4011e+00, time/batch = 0.2410s	
399/2700 (epoch 7.389), train_loss = 3.27791881, grad/param norm = 1.3348e+00, time/batch = 0.2342s	
400/2700 (epoch 7.407), train_loss = 3.30237038, grad/param norm = 1.2432e+00, time/batch = 0.2258s	
401/2700 (epoch 7.426), train_loss = 3.30067812, grad/param norm = 1.1788e+00, time/batch = 0.2585s	
402/2700 (epoch 7.444), train_loss = 3.22432958, grad/param norm = 1.2265e+00, time/batch = 0.2578s	
403/2700 (epoch 7.463), train_loss = 3.27451618, grad/param norm = 1.4950e+00, time/batch = 0.2606s	
404/2700 (epoch 7.481), train_loss = 3.36201530, grad/param norm = 1.6565e+00, time/batch = 0.2598s	
405/2700 (epoch 7.500), train_loss = 3.40574186, grad/param norm = 1.8929e+00, time/batch = 0.2540s	
406/2700 (epoch 7.519), train_loss = 3.36320776, grad/param norm = 1.9536e+00, time/batch = 0.2444s	
407/2700 (epoch 7.537), train_loss = 3.36693721, grad/param norm = 1.7732e+00, time/batch = 0.2023s	
408/2700 (epoch 7.556), train_loss = 3.30187171, grad/param norm = 1.4290e+00, time/batch = 0.2182s	
409/2700 (epoch 7.574), train_loss = 3.24161326, grad/param norm = 1.1070e+00, time/batch = 0.2273s	
410/2700 (epoch 7.593), train_loss = 3.25132393, grad/param norm = 1.3425e+00, time/batch = 0.2142s	
411/2700 (epoch 7.611), train_loss = 3.19374024, grad/param norm = 1.2267e+00, time/batch = 0.2236s	
412/2700 (epoch 7.630), train_loss = 3.23454261, grad/param norm = 1.3672e+00, time/batch = 0.2296s	
413/2700 (epoch 7.648), train_loss = 3.31507835, grad/param norm = 1.5012e+00, time/batch = 0.2426s	
414/2700 (epoch 7.667), train_loss = 3.25409092, grad/param norm = 1.5680e+00, time/batch = 0.2466s	
415/2700 (epoch 7.685), train_loss = 3.24366845, grad/param norm = 1.4629e+00, time/batch = 0.2476s	
416/2700 (epoch 7.704), train_loss = 3.22237967, grad/param norm = 1.6460e+00, time/batch = 0.2515s	
417/2700 (epoch 7.722), train_loss = 3.21530541, grad/param norm = 1.5251e+00, time/batch = 0.2283s	
418/2700 (epoch 7.741), train_loss = 3.34050219, grad/param norm = 1.4007e+00, time/batch = 0.2570s	
419/2700 (epoch 7.759), train_loss = 3.29707565, grad/param norm = 1.6669e+00, time/batch = 0.2560s	
420/2700 (epoch 7.778), train_loss = 3.29677024, grad/param norm = 2.0279e+00, time/batch = 0.2562s	
421/2700 (epoch 7.796), train_loss = 3.30053795, grad/param norm = 1.9913e+00, time/batch = 0.2333s	
422/2700 (epoch 7.815), train_loss = 3.23291989, grad/param norm = 1.7747e+00, time/batch = 0.2353s	
423/2700 (epoch 7.833), train_loss = 3.27395225, grad/param norm = 1.7725e+00, time/batch = 0.2396s	
424/2700 (epoch 7.852), train_loss = 3.26236239, grad/param norm = 1.8173e+00, time/batch = 0.2470s	
425/2700 (epoch 7.870), train_loss = 3.25579232, grad/param norm = 1.5244e+00, time/batch = 0.2514s	
426/2700 (epoch 7.889), train_loss = 3.27257509, grad/param norm = 1.3127e+00, time/batch = 0.2455s	
427/2700 (epoch 7.907), train_loss = 3.32146591, grad/param norm = 1.4013e+00, time/batch = 0.2369s	
428/2700 (epoch 7.926), train_loss = 3.28527534, grad/param norm = 1.6289e+00, time/batch = 0.2094s	
429/2700 (epoch 7.944), train_loss = 3.29984442, grad/param norm = 1.4110e+00, time/batch = 0.2479s	
430/2700 (epoch 7.963), train_loss = 3.36361532, grad/param norm = 1.2431e+00, time/batch = 0.2582s	
431/2700 (epoch 7.981), train_loss = 3.42149639, grad/param norm = 1.2498e+00, time/batch = 0.2398s	
432/2700 (epoch 8.000), train_loss = 3.33023120, grad/param norm = 1.2559e+00, time/batch = 0.2438s	
433/2700 (epoch 8.019), train_loss = 3.26211821, grad/param norm = 1.3539e+00, time/batch = 0.2511s	
434/2700 (epoch 8.037), train_loss = 3.28758896, grad/param norm = 1.4024e+00, time/batch = 0.2584s	
435/2700 (epoch 8.056), train_loss = 3.27862902, grad/param norm = 1.0455e+00, time/batch = 0.2532s	
436/2700 (epoch 8.074), train_loss = 3.30470379, grad/param norm = 9.4218e-01, time/batch = 0.2355s	
437/2700 (epoch 8.093), train_loss = 3.31901151, grad/param norm = 1.1323e+00, time/batch = 0.2417s	
438/2700 (epoch 8.111), train_loss = 3.29395978, grad/param norm = 1.2239e+00, time/batch = 0.2346s	
439/2700 (epoch 8.130), train_loss = 3.31372541, grad/param norm = 1.1695e+00, time/batch = 0.2277s	
440/2700 (epoch 8.148), train_loss = 3.26918471, grad/param norm = 1.4424e+00, time/batch = 0.2571s	
441/2700 (epoch 8.167), train_loss = 3.29844940, grad/param norm = 1.6009e+00, time/batch = 0.2440s	
442/2700 (epoch 8.185), train_loss = 3.27363429, grad/param norm = 1.3953e+00, time/batch = 0.2460s	
443/2700 (epoch 8.204), train_loss = 3.20361821, grad/param norm = 1.3897e+00, time/batch = 0.2495s	
444/2700 (epoch 8.222), train_loss = 3.17756809, grad/param norm = 1.7543e+00, time/batch = 0.2539s	
445/2700 (epoch 8.241), train_loss = 3.20275920, grad/param norm = 1.7607e+00, time/batch = 0.2609s	
446/2700 (epoch 8.259), train_loss = 3.24096524, grad/param norm = 1.8029e+00, time/batch = 0.2475s	
447/2700 (epoch 8.278), train_loss = 3.32377038, grad/param norm = 2.4115e+00, time/batch = 0.2547s	
448/2700 (epoch 8.296), train_loss = 3.33721539, grad/param norm = 2.2239e+00, time/batch = 0.2425s	
449/2700 (epoch 8.315), train_loss = 3.29867380, grad/param norm = 1.5353e+00, time/batch = 0.2161s	
450/2700 (epoch 8.333), train_loss = 3.35728196, grad/param norm = 1.1346e+00, time/batch = 0.2421s	
451/2700 (epoch 8.352), train_loss = 3.36632716, grad/param norm = 1.2323e+00, time/batch = 0.2246s	
452/2700 (epoch 8.370), train_loss = 3.32135371, grad/param norm = 1.3942e+00, time/batch = 0.2303s	
453/2700 (epoch 8.389), train_loss = 3.27780520, grad/param norm = 1.3279e+00, time/batch = 0.2385s	
454/2700 (epoch 8.407), train_loss = 3.30229309, grad/param norm = 1.2370e+00, time/batch = 0.2456s	
455/2700 (epoch 8.426), train_loss = 3.30063134, grad/param norm = 1.1737e+00, time/batch = 0.2530s	
456/2700 (epoch 8.444), train_loss = 3.22426616, grad/param norm = 1.2210e+00, time/batch = 0.2489s	
457/2700 (epoch 8.463), train_loss = 3.27444335, grad/param norm = 1.4893e+00, time/batch = 0.2592s	
458/2700 (epoch 8.481), train_loss = 3.36195320, grad/param norm = 1.6517e+00, time/batch = 0.2465s	
459/2700 (epoch 8.500), train_loss = 3.40574987, grad/param norm = 1.8900e+00, time/batch = 0.2331s	
460/2700 (epoch 8.519), train_loss = 3.36327677, grad/param norm = 1.9519e+00, time/batch = 0.2374s	
461/2700 (epoch 8.537), train_loss = 3.36699861, grad/param norm = 1.7717e+00, time/batch = 0.2537s	
462/2700 (epoch 8.556), train_loss = 3.30191303, grad/param norm = 1.4279e+00, time/batch = 0.2497s	
463/2700 (epoch 8.574), train_loss = 3.24164256, grad/param norm = 1.1063e+00, time/batch = 0.2439s	
464/2700 (epoch 8.593), train_loss = 3.25135392, grad/param norm = 1.3413e+00, time/batch = 0.2418s	
465/2700 (epoch 8.611), train_loss = 3.19377325, grad/param norm = 1.2258e+00, time/batch = 0.2401s	
466/2700 (epoch 8.630), train_loss = 3.23457585, grad/param norm = 1.3660e+00, time/batch = 0.2489s	
467/2700 (epoch 8.648), train_loss = 3.31511908, grad/param norm = 1.4996e+00, time/batch = 0.2534s	
468/2700 (epoch 8.667), train_loss = 3.25410816, grad/param norm = 1.5658e+00, time/batch = 0.2403s	
469/2700 (epoch 8.685), train_loss = 3.24367521, grad/param norm = 1.4604e+00, time/batch = 0.2327s	
470/2700 (epoch 8.704), train_loss = 3.22237799, grad/param norm = 1.6429e+00, time/batch = 0.2089s	
471/2700 (epoch 8.722), train_loss = 3.21531171, grad/param norm = 1.5221e+00, time/batch = 0.2399s	
472/2700 (epoch 8.741), train_loss = 3.34049217, grad/param norm = 1.3976e+00, time/batch = 0.2436s	
473/2700 (epoch 8.759), train_loss = 3.29706072, grad/param norm = 1.6630e+00, time/batch = 0.2502s	
474/2700 (epoch 8.778), train_loss = 3.29674161, grad/param norm = 2.0230e+00, time/batch = 0.2580s	
475/2700 (epoch 8.796), train_loss = 3.30049708, grad/param norm = 1.9863e+00, time/batch = 0.2543s	
476/2700 (epoch 8.815), train_loss = 3.23289688, grad/param norm = 1.7705e+00, time/batch = 0.2592s	
477/2700 (epoch 8.833), train_loss = 3.27393551, grad/param norm = 1.7685e+00, time/batch = 0.2548s	
478/2700 (epoch 8.852), train_loss = 3.26234901, grad/param norm = 1.8133e+00, time/batch = 0.2607s	
479/2700 (epoch 8.870), train_loss = 3.25579226, grad/param norm = 1.5215e+00, time/batch = 0.2593s	
480/2700 (epoch 8.889), train_loss = 3.27258000, grad/param norm = 1.3104e+00, time/batch = 0.2463s	
481/2700 (epoch 8.907), train_loss = 3.32147454, grad/param norm = 1.3986e+00, time/batch = 0.2306s	
482/2700 (epoch 8.926), train_loss = 3.28528518, grad/param norm = 1.6256e+00, time/batch = 0.2290s	
483/2700 (epoch 8.944), train_loss = 3.29984899, grad/param norm = 1.4082e+00, time/batch = 0.2291s	
484/2700 (epoch 8.963), train_loss = 3.36361850, grad/param norm = 1.2406e+00, time/batch = 0.2296s	
485/2700 (epoch 8.981), train_loss = 3.42149990, grad/param norm = 1.2472e+00, time/batch = 0.1961s	
486/2700 (epoch 9.000), train_loss = 3.33023307, grad/param norm = 1.2533e+00, time/batch = 0.2221s	
487/2700 (epoch 9.019), train_loss = 3.26212342, grad/param norm = 1.3510e+00, time/batch = 0.2231s	
488/2700 (epoch 9.037), train_loss = 3.28759306, grad/param norm = 1.3994e+00, time/batch = 0.2315s	
489/2700 (epoch 9.056), train_loss = 3.27863183, grad/param norm = 1.0432e+00, time/batch = 0.2378s	
490/2700 (epoch 9.074), train_loss = 3.30470317, grad/param norm = 9.3999e-01, time/batch = 0.2464s	
491/2700 (epoch 9.093), train_loss = 3.31901113, grad/param norm = 1.1297e+00, time/batch = 0.2090s	
492/2700 (epoch 9.111), train_loss = 3.29395936, grad/param norm = 1.2211e+00, time/batch = 0.2374s	
493/2700 (epoch 9.130), train_loss = 3.31372594, grad/param norm = 1.1669e+00, time/batch = 0.2356s	
494/2700 (epoch 9.148), train_loss = 3.26918582, grad/param norm = 1.4393e+00, time/batch = 0.2334s	
495/2700 (epoch 9.167), train_loss = 3.29846330, grad/param norm = 1.5975e+00, time/batch = 0.2218s	
496/2700 (epoch 9.185), train_loss = 3.27364757, grad/param norm = 1.3930e+00, time/batch = 0.2509s	
497/2700 (epoch 9.204), train_loss = 3.20364807, grad/param norm = 1.3883e+00, time/batch = 0.2560s	
498/2700 (epoch 9.222), train_loss = 3.17762672, grad/param norm = 1.7529e+00, time/batch = 0.2480s	
499/2700 (epoch 9.241), train_loss = 3.20281770, grad/param norm = 1.7602e+00, time/batch = 0.2375s	
500/2700 (epoch 9.259), train_loss = 3.24103166, grad/param norm = 1.8009e+00, time/batch = 0.2242s	
501/2700 (epoch 9.278), train_loss = 3.32372072, grad/param norm = 2.4036e+00, time/batch = 0.2579s	
502/2700 (epoch 9.296), train_loss = 3.33714368, grad/param norm = 2.2174e+00, time/batch = 0.2375s	
503/2700 (epoch 9.315), train_loss = 3.29869282, grad/param norm = 1.5312e+00, time/batch = 0.2325s	
504/2700 (epoch 9.333), train_loss = 3.35725710, grad/param norm = 1.1307e+00, time/batch = 0.2191s	
505/2700 (epoch 9.352), train_loss = 3.36629997, grad/param norm = 1.2284e+00, time/batch = 0.2156s	
506/2700 (epoch 9.370), train_loss = 3.32132847, grad/param norm = 1.3898e+00, time/batch = 0.2166s	
507/2700 (epoch 9.389), train_loss = 3.27777153, grad/param norm = 1.3236e+00, time/batch = 0.2242s	
508/2700 (epoch 9.407), train_loss = 3.30226985, grad/param norm = 1.2331e+00, time/batch = 0.2386s	
509/2700 (epoch 9.426), train_loss = 3.30061661, grad/param norm = 1.1702e+00, time/batch = 0.2537s	
510/2700 (epoch 9.444), train_loss = 3.22424754, grad/param norm = 1.2172e+00, time/batch = 0.2561s	
511/2700 (epoch 9.463), train_loss = 3.27442251, grad/param norm = 1.4850e+00, time/batch = 0.2360s	
512/2700 (epoch 9.481), train_loss = 3.36193677, grad/param norm = 1.6474e+00, time/batch = 0.2364s	
513/2700 (epoch 9.500), train_loss = 3.40575241, grad/param norm = 1.8858e+00, time/batch = 0.2587s	
514/2700 (epoch 9.519), train_loss = 3.36329576, grad/param norm = 1.9479e+00, time/batch = 0.2547s	
515/2700 (epoch 9.537), train_loss = 3.36701600, grad/param norm = 1.7680e+00, time/batch = 0.2562s	
516/2700 (epoch 9.556), train_loss = 3.30192576, grad/param norm = 1.4251e+00, time/batch = 0.2605s	
517/2700 (epoch 9.574), train_loss = 3.24165122, grad/param norm = 1.1042e+00, time/batch = 0.2587s	
518/2700 (epoch 9.593), train_loss = 3.25136254, grad/param norm = 1.3386e+00, time/batch = 0.2578s	
519/2700 (epoch 9.611), train_loss = 3.19378228, grad/param norm = 1.2234e+00, time/batch = 0.2595s	
520/2700 (epoch 9.630), train_loss = 3.23458526, grad/param norm = 1.3633e+00, time/batch = 0.2575s	
521/2700 (epoch 9.648), train_loss = 3.31513128, grad/param norm = 1.4965e+00, time/batch = 0.2403s	
522/2700 (epoch 9.667), train_loss = 3.25411411, grad/param norm = 1.5625e+00, time/batch = 0.2318s	
523/2700 (epoch 9.685), train_loss = 3.24367674, grad/param norm = 1.4571e+00, time/batch = 0.2359s	
524/2700 (epoch 9.704), train_loss = 3.22237711, grad/param norm = 1.6392e+00, time/batch = 0.2224s	
525/2700 (epoch 9.722), train_loss = 3.21531241, grad/param norm = 1.5186e+00, time/batch = 0.2359s	
526/2700 (epoch 9.741), train_loss = 3.34048814, grad/param norm = 1.3942e+00, time/batch = 0.2298s	
527/2700 (epoch 9.759), train_loss = 3.29705511, grad/param norm = 1.6589e+00, time/batch = 0.2196s	
528/2700 (epoch 9.778), train_loss = 3.29673275, grad/param norm = 2.0179e+00, time/batch = 0.2282s	
529/2700 (epoch 9.796), train_loss = 3.30048615, grad/param norm = 1.9813e+00, time/batch = 0.2348s	
530/2700 (epoch 9.815), train_loss = 3.23289098, grad/param norm = 1.7661e+00, time/batch = 0.2433s	
531/2700 (epoch 9.833), train_loss = 3.27393118, grad/param norm = 1.7642e+00, time/batch = 0.2254s	
532/2700 (epoch 9.852), train_loss = 3.26234641, grad/param norm = 1.8090e+00, time/batch = 0.2254s	
533/2700 (epoch 9.870), train_loss = 3.25579207, grad/param norm = 1.5180e+00, time/batch = 0.2173s	
534/2700 (epoch 9.889), train_loss = 3.27258235, grad/param norm = 1.3074e+00, time/batch = 0.2137s	
535/2700 (epoch 9.907), train_loss = 3.32147596, grad/param norm = 1.3957e+00, time/batch = 0.2557s	
536/2700 (epoch 9.926), train_loss = 3.28528470, grad/param norm = 1.6221e+00, time/batch = 0.2561s	
537/2700 (epoch 9.944), train_loss = 3.29984911, grad/param norm = 1.4051e+00, time/batch = 0.2565s	
538/2700 (epoch 9.963), train_loss = 3.36362028, grad/param norm = 1.2379e+00, time/batch = 0.2571s	
539/2700 (epoch 9.981), train_loss = 3.42150208, grad/param norm = 1.2445e+00, time/batch = 0.2554s	
decayed learning rate by a factor 0.97 to 0.00194	
540/2700 (epoch 10.000), train_loss = 3.33023545, grad/param norm = 1.2506e+00, time/batch = 0.2495s	
541/2700 (epoch 10.019), train_loss = 3.26212504, grad/param norm = 1.3482e+00, time/batch = 0.2416s	
542/2700 (epoch 10.037), train_loss = 3.28430381, grad/param norm = 1.3342e+00, time/batch = 0.2459s	
543/2700 (epoch 10.056), train_loss = 3.27538464, grad/param norm = 9.6439e-01, time/batch = 0.2499s	
544/2700 (epoch 10.074), train_loss = 3.30280404, grad/param norm = 8.8899e-01, time/batch = 0.2122s	
545/2700 (epoch 10.093), train_loss = 3.31613938, grad/param norm = 1.0783e+00, time/batch = 0.2114s	
546/2700 (epoch 10.111), train_loss = 3.28989998, grad/param norm = 1.1348e+00, time/batch = 0.2132s	
547/2700 (epoch 10.130), train_loss = 3.30909460, grad/param norm = 1.0633e+00, time/batch = 0.2152s	
548/2700 (epoch 10.148), train_loss = 3.26534352, grad/param norm = 1.3181e+00, time/batch = 0.2207s	
549/2700 (epoch 10.167), train_loss = 3.29238206, grad/param norm = 1.4990e+00, time/batch = 0.2333s	
550/2700 (epoch 10.185), train_loss = 3.26824580, grad/param norm = 1.2284e+00, time/batch = 0.2406s	
551/2700 (epoch 10.204), train_loss = 3.19613729, grad/param norm = 1.1679e+00, time/batch = 0.2343s	
552/2700 (epoch 10.222), train_loss = 3.17056179, grad/param norm = 1.4075e+00, time/batch = 0.2400s	
553/2700 (epoch 10.241), train_loss = 3.19132379, grad/param norm = 1.1276e+00, time/batch = 0.2425s	
554/2700 (epoch 10.259), train_loss = 3.22244409, grad/param norm = 8.4873e-01, time/batch = 0.2148s	
555/2700 (epoch 10.278), train_loss = 3.29695696, grad/param norm = 1.0604e+00, time/batch = 0.2543s	
556/2700 (epoch 10.296), train_loss = 3.30451075, grad/param norm = 1.2134e+00, time/batch = 0.2564s	
557/2700 (epoch 10.315), train_loss = 3.28413262, grad/param norm = 1.2384e+00, time/batch = 0.2523s	
558/2700 (epoch 10.333), train_loss = 3.36157402, grad/param norm = 1.3494e+00, time/batch = 0.2402s	
559/2700 (epoch 10.352), train_loss = 3.38357208, grad/param norm = 1.9018e+00, time/batch = 0.2395s	
560/2700 (epoch 10.370), train_loss = 3.35188811, grad/param norm = 2.3443e+00, time/batch = 0.2406s	
561/2700 (epoch 10.389), train_loss = 3.30469316, grad/param norm = 2.4146e+00, time/batch = 0.2595s	
562/2700 (epoch 10.407), train_loss = 3.32970700, grad/param norm = 2.1452e+00, time/batch = 0.2564s	
563/2700 (epoch 10.426), train_loss = 3.30729369, grad/param norm = 1.5391e+00, time/batch = 0.2457s	
564/2700 (epoch 10.444), train_loss = 3.23011652, grad/param norm = 1.4900e+00, time/batch = 0.2526s	
565/2700 (epoch 10.463), train_loss = 3.27383446, grad/param norm = 1.5084e+00, time/batch = 0.2379s	
566/2700 (epoch 10.481), train_loss = 3.35580884, grad/param norm = 1.5059e+00, time/batch = 0.2285s	
567/2700 (epoch 10.500), train_loss = 3.39860539, grad/param norm = 1.6013e+00, time/batch = 0.2220s	
568/2700 (epoch 10.519), train_loss = 3.35165507, grad/param norm = 1.5944e+00, time/batch = 0.2285s	
569/2700 (epoch 10.537), train_loss = 3.35665221, grad/param norm = 1.5060e+00, time/batch = 0.2359s	
570/2700 (epoch 10.556), train_loss = 3.29575204, grad/param norm = 1.2234e+00, time/batch = 0.2445s	
571/2700 (epoch 10.574), train_loss = 3.23963613, grad/param norm = 9.6864e-01, time/batch = 0.2145s	
572/2700 (epoch 10.593), train_loss = 3.24895114, grad/param norm = 1.2168e+00, time/batch = 0.2170s	
573/2700 (epoch 10.611), train_loss = 3.19012710, grad/param norm = 1.0828e+00, time/batch = 0.2132s	
574/2700 (epoch 10.630), train_loss = 3.23005160, grad/param norm = 1.1701e+00, time/batch = 0.2416s	
575/2700 (epoch 10.648), train_loss = 3.30846010, grad/param norm = 1.3108e+00, time/batch = 0.2249s	
576/2700 (epoch 10.667), train_loss = 3.24907495, grad/param norm = 1.3903e+00, time/batch = 0.2413s	
577/2700 (epoch 10.685), train_loss = 3.23843369, grad/param norm = 1.3094e+00, time/batch = 0.2421s	
578/2700 (epoch 10.704), train_loss = 3.21681373, grad/param norm = 1.4965e+00, time/batch = 0.2372s	
579/2700 (epoch 10.722), train_loss = 3.20867109, grad/param norm = 1.3662e+00, time/batch = 0.2253s	
580/2700 (epoch 10.741), train_loss = 3.33587219, grad/param norm = 1.2722e+00, time/batch = 0.2174s	
581/2700 (epoch 10.759), train_loss = 3.29186521, grad/param norm = 1.5732e+00, time/batch = 0.2611s	
582/2700 (epoch 10.778), train_loss = 3.29732324, grad/param norm = 2.0495e+00, time/batch = 0.2490s	
583/2700 (epoch 10.796), train_loss = 3.30350034, grad/param norm = 2.0656e+00, time/batch = 0.2588s	
584/2700 (epoch 10.815), train_loss = 3.23428028, grad/param norm = 1.8350e+00, time/batch = 0.2611s	
585/2700 (epoch 10.833), train_loss = 3.27415467, grad/param norm = 1.8250e+00, time/batch = 0.2503s	
586/2700 (epoch 10.852), train_loss = 3.26278077, grad/param norm = 1.8515e+00, time/batch = 0.2187s	
587/2700 (epoch 10.870), train_loss = 3.25414260, grad/param norm = 1.5122e+00, time/batch = 0.2293s	
588/2700 (epoch 10.889), train_loss = 3.27129019, grad/param norm = 1.2807e+00, time/batch = 0.2367s	
589/2700 (epoch 10.907), train_loss = 3.32004963, grad/param norm = 1.3515e+00, time/batch = 0.2456s	
590/2700 (epoch 10.926), train_loss = 3.28314142, grad/param norm = 1.5692e+00, time/batch = 0.2543s	
591/2700 (epoch 10.944), train_loss = 3.29727270, grad/param norm = 1.3544e+00, time/batch = 0.2358s	
592/2700 (epoch 10.963), train_loss = 3.36176501, grad/param norm = 1.1900e+00, time/batch = 0.2261s	
593/2700 (epoch 10.981), train_loss = 3.41982678, grad/param norm = 1.2063e+00, time/batch = 0.2446s	
decayed learning rate by a factor 0.97 to 0.0018818	
594/2700 (epoch 11.000), train_loss = 3.32830470, grad/param norm = 1.2078e+00, time/batch = 0.2517s	
595/2700 (epoch 11.019), train_loss = 3.26054775, grad/param norm = 1.3019e+00, time/batch = 0.2542s	
596/2700 (epoch 11.037), train_loss = 3.28228411, grad/param norm = 1.2790e+00, time/batch = 0.2478s	
597/2700 (epoch 11.056), train_loss = 3.27391498, grad/param norm = 9.2271e-01, time/batch = 0.2576s	
598/2700 (epoch 11.074), train_loss = 3.30226217, grad/param norm = 8.8534e-01, time/batch = 0.2575s	
599/2700 (epoch 11.093), train_loss = 3.31514382, grad/param norm = 1.0793e+00, time/batch = 0.2572s	
600/2700 (epoch 11.111), train_loss = 3.28867438, grad/param norm = 1.1170e+00, time/batch = 0.2571s	
601/2700 (epoch 11.130), train_loss = 3.30743187, grad/param norm = 1.0411e+00, time/batch = 0.2459s	
602/2700 (epoch 11.148), train_loss = 3.26407604, grad/param norm = 1.2782e+00, time/batch = 0.2389s	
603/2700 (epoch 11.167), train_loss = 3.28966984, grad/param norm = 1.4803e+00, time/batch = 0.2584s	
604/2700 (epoch 11.185), train_loss = 3.26671906, grad/param norm = 1.1960e+00, time/batch = 0.2573s	
605/2700 (epoch 11.204), train_loss = 3.19477507, grad/param norm = 1.2123e+00, time/batch = 0.2564s	
606/2700 (epoch 11.222), train_loss = 3.17362598, grad/param norm = 1.4876e+00, time/batch = 0.2578s	
607/2700 (epoch 11.241), train_loss = 3.19942194, grad/param norm = 1.6360e+00, time/batch = 0.2201s	
608/2700 (epoch 11.259), train_loss = 3.24873599, grad/param norm = 2.3192e+00, time/batch = 0.2074s	
609/2700 (epoch 11.278), train_loss = 3.32975142, grad/param norm = 2.2317e+00, time/batch = 0.2047s	
610/2700 (epoch 11.296), train_loss = 3.31519182, grad/param norm = 1.9156e+00, time/batch = 0.2084s	
611/2700 (epoch 11.315), train_loss = 3.28758348, grad/param norm = 1.6848e+00, time/batch = 0.2186s	
612/2700 (epoch 11.333), train_loss = 3.36261228, grad/param norm = 1.4133e+00, time/batch = 0.2104s	
613/2700 (epoch 11.352), train_loss = 3.37421260, grad/param norm = 1.4347e+00, time/batch = 0.2184s	
614/2700 (epoch 11.370), train_loss = 3.32187168, grad/param norm = 1.2636e+00, time/batch = 0.2288s	
615/2700 (epoch 11.389), train_loss = 3.27121554, grad/param norm = 1.0356e+00, time/batch = 0.2423s	
616/2700 (epoch 11.407), train_loss = 3.29322448, grad/param norm = 9.1250e-01, time/batch = 0.2438s	
617/2700 (epoch 11.426), train_loss = 3.29623824, grad/param norm = 9.3648e-01, time/batch = 0.2370s	
618/2700 (epoch 11.444), train_loss = 3.21734592, grad/param norm = 9.0328e-01, time/batch = 0.2519s	
619/2700 (epoch 11.463), train_loss = 3.26472645, grad/param norm = 9.7135e-01, time/batch = 0.2566s	
620/2700 (epoch 11.481), train_loss = 3.33890747, grad/param norm = 7.9587e-01, time/batch = 0.2553s	
621/2700 (epoch 11.500), train_loss = 3.38157262, grad/param norm = 9.0102e-01, time/batch = 0.2526s	
622/2700 (epoch 11.519), train_loss = 3.33831072, grad/param norm = 1.0958e+00, time/batch = 0.2597s	
623/2700 (epoch 11.537), train_loss = 3.35076674, grad/param norm = 1.3344e+00, time/batch = 0.2523s	
624/2700 (epoch 11.556), train_loss = 3.29540514, grad/param norm = 1.3141e+00, time/batch = 0.2428s	
625/2700 (epoch 11.574), train_loss = 3.24324501, grad/param norm = 1.2533e+00, time/batch = 0.2398s	
626/2700 (epoch 11.593), train_loss = 3.25612747, grad/param norm = 1.5882e+00, time/batch = 0.2416s	
627/2700 (epoch 11.611), train_loss = 3.20211745, grad/param norm = 1.6286e+00, time/batch = 0.2401s	
628/2700 (epoch 11.630), train_loss = 3.24537465, grad/param norm = 1.8460e+00, time/batch = 0.2398s	
629/2700 (epoch 11.648), train_loss = 3.32823421, grad/param norm = 1.9885e+00, time/batch = 0.2359s	
630/2700 (epoch 11.667), train_loss = 3.26571408, grad/param norm = 2.0565e+00, time/batch = 0.2288s	
631/2700 (epoch 11.685), train_loss = 3.25089548, grad/param norm = 1.6972e+00, time/batch = 0.2407s	
632/2700 (epoch 11.704), train_loss = 3.22188344, grad/param norm = 1.6740e+00, time/batch = 0.2588s	
633/2700 (epoch 11.722), train_loss = 3.20875292, grad/param norm = 1.3988e+00, time/batch = 0.2507s	
634/2700 (epoch 11.741), train_loss = 3.33240995, grad/param norm = 1.1699e+00, time/batch = 0.2452s	
635/2700 (epoch 11.759), train_loss = 3.28475288, grad/param norm = 1.3756e+00, time/batch = 0.2374s	
636/2700 (epoch 11.778), train_loss = 3.28491904, grad/param norm = 1.6953e+00, time/batch = 0.2302s	
637/2700 (epoch 11.796), train_loss = 3.28645003, grad/param norm = 1.6585e+00, time/batch = 0.2220s	
638/2700 (epoch 11.815), train_loss = 3.22466038, grad/param norm = 1.4727e+00, time/batch = 0.2244s	
639/2700 (epoch 11.833), train_loss = 3.26323075, grad/param norm = 1.4633e+00, time/batch = 0.2429s	
640/2700 (epoch 11.852), train_loss = 3.25066780, grad/param norm = 1.5080e+00, time/batch = 0.2580s	
641/2700 (epoch 11.870), train_loss = 3.24823921, grad/param norm = 1.3823e+00, time/batch = 0.2213s	
642/2700 (epoch 11.889), train_loss = 3.27068865, grad/param norm = 1.2587e+00, time/batch = 0.2342s	
643/2700 (epoch 11.907), train_loss = 3.32064040, grad/param norm = 1.4049e+00, time/batch = 0.2291s	
644/2700 (epoch 11.926), train_loss = 3.28394394, grad/param norm = 1.6253e+00, time/batch = 0.2271s	
645/2700 (epoch 11.944), train_loss = 3.29677177, grad/param norm = 1.4012e+00, time/batch = 0.2295s	
646/2700 (epoch 11.963), train_loss = 3.36206085, grad/param norm = 1.2483e+00, time/batch = 0.2352s	
647/2700 (epoch 11.981), train_loss = 3.42036118, grad/param norm = 1.2404e+00, time/batch = 0.2338s	
decayed learning rate by a factor 0.97 to 0.001825346	
648/2700 (epoch 12.000), train_loss = 3.32739439, grad/param norm = 1.2468e+00, time/batch = 0.2279s	
649/2700 (epoch 12.019), train_loss = 3.26144945, grad/param norm = 1.3551e+00, time/batch = 0.2410s	
650/2700 (epoch 12.037), train_loss = 3.28226342, grad/param norm = 1.3426e+00, time/batch = 0.2425s	
651/2700 (epoch 12.056), train_loss = 3.27379881, grad/param norm = 9.5969e-01, time/batch = 0.2611s	
652/2700 (epoch 12.074), train_loss = 3.30115012, grad/param norm = 8.5290e-01, time/batch = 0.2600s	
653/2700 (epoch 12.093), train_loss = 3.31378197, grad/param norm = 1.0365e+00, time/batch = 0.2588s	
654/2700 (epoch 12.111), train_loss = 3.28708784, grad/param norm = 1.1057e+00, time/batch = 0.2556s	
655/2700 (epoch 12.130), train_loss = 3.30676747, grad/param norm = 1.0501e+00, time/batch = 0.2558s	
656/2700 (epoch 12.148), train_loss = 3.26330259, grad/param norm = 1.3281e+00, time/batch = 0.2516s	
657/2700 (epoch 12.167), train_loss = 3.28996856, grad/param norm = 1.4903e+00, time/batch = 0.2508s	
658/2700 (epoch 12.185), train_loss = 3.26590857, grad/param norm = 1.2886e+00, time/batch = 0.2253s	
659/2700 (epoch 12.204), train_loss = 3.19587080, grad/param norm = 1.3080e+00, time/batch = 0.2290s	
660/2700 (epoch 12.222), train_loss = 3.17313335, grad/param norm = 1.6890e+00, time/batch = 0.2142s	
661/2700 (epoch 12.241), train_loss = 3.19567357, grad/param norm = 1.6068e+00, time/batch = 0.2269s	
662/2700 (epoch 12.259), train_loss = 3.23279207, grad/param norm = 1.5857e+00, time/batch = 0.2291s	
663/2700 (epoch 12.278), train_loss = 3.31656981, grad/param norm = 2.0910e+00, time/batch = 0.2197s	
664/2700 (epoch 12.296), train_loss = 3.32452907, grad/param norm = 1.9999e+00, time/batch = 0.2165s	
665/2700 (epoch 12.315), train_loss = 3.28989727, grad/param norm = 1.4038e+00, time/batch = 0.2334s	
666/2700 (epoch 12.333), train_loss = 3.35224908, grad/param norm = 1.0207e+00, time/batch = 0.2461s	
667/2700 (epoch 12.352), train_loss = 3.36206262, grad/param norm = 1.1379e+00, time/batch = 0.2531s	
668/2700 (epoch 12.370), train_loss = 3.31560668, grad/param norm = 1.3020e+00, time/batch = 0.2496s	
669/2700 (epoch 12.389), train_loss = 3.27405282, grad/param norm = 1.2302e+00, time/batch = 0.2348s	
670/2700 (epoch 12.407), train_loss = 3.29662981, grad/param norm = 1.1121e+00, time/batch = 0.2411s	
671/2700 (epoch 12.426), train_loss = 3.29564196, grad/param norm = 1.0486e+00, time/batch = 0.2485s	
672/2700 (epoch 12.444), train_loss = 3.21927542, grad/param norm = 1.0881e+00, time/batch = 0.2416s	
673/2700 (epoch 12.463), train_loss = 3.26820965, grad/param norm = 1.3427e+00, time/batch = 0.2367s	
674/2700 (epoch 12.481), train_loss = 3.35351614, grad/param norm = 1.5052e+00, time/batch = 0.2339s	
675/2700 (epoch 12.500), train_loss = 3.39947083, grad/param norm = 1.7656e+00, time/batch = 0.2322s	
676/2700 (epoch 12.519), train_loss = 3.35618701, grad/param norm = 1.8130e+00, time/batch = 0.2307s	
677/2700 (epoch 12.537), train_loss = 3.35941426, grad/param norm = 1.6539e+00, time/batch = 0.2304s	
678/2700 (epoch 12.556), train_loss = 3.29470983, grad/param norm = 1.3298e+00, time/batch = 0.2411s	
679/2700 (epoch 12.574), train_loss = 3.23948786, grad/param norm = 1.0368e+00, time/batch = 0.2398s	
680/2700 (epoch 12.593), train_loss = 3.24830620, grad/param norm = 1.2593e+00, time/batch = 0.1933s	
681/2700 (epoch 12.611), train_loss = 3.18966887, grad/param norm = 1.1270e+00, time/batch = 0.2323s	
682/2700 (epoch 12.630), train_loss = 3.23030962, grad/param norm = 1.2378e+00, time/batch = 0.2403s	
683/2700 (epoch 12.648), train_loss = 3.30871028, grad/param norm = 1.3604e+00, time/batch = 0.2481s	
684/2700 (epoch 12.667), train_loss = 3.24660095, grad/param norm = 1.4086e+00, time/batch = 0.2518s	
685/2700 (epoch 12.685), train_loss = 3.23655327, grad/param norm = 1.3039e+00, time/batch = 0.2465s	
686/2700 (epoch 12.704), train_loss = 3.21399098, grad/param norm = 1.4761e+00, time/batch = 0.2394s	
687/2700 (epoch 12.722), train_loss = 3.20464425, grad/param norm = 1.3249e+00, time/batch = 0.2294s	
688/2700 (epoch 12.741), train_loss = 3.33179683, grad/param norm = 1.1949e+00, time/batch = 0.2554s	
689/2700 (epoch 12.759), train_loss = 3.28665659, grad/param norm = 1.4696e+00, time/batch = 0.2406s	
690/2700 (epoch 12.778), train_loss = 3.28954505, grad/param norm = 1.8775e+00, time/batch = 0.2350s	
691/2700 (epoch 12.796), train_loss = 3.29262160, grad/param norm = 1.8751e+00, time/batch = 0.2599s	
692/2700 (epoch 12.815), train_loss = 3.22735734, grad/param norm = 1.6606e+00, time/batch = 0.2605s	
693/2700 (epoch 12.833), train_loss = 3.26601863, grad/param norm = 1.6509e+00, time/batch = 0.2579s	
694/2700 (epoch 12.852), train_loss = 3.25474069, grad/param norm = 1.6838e+00, time/batch = 0.2573s	
695/2700 (epoch 12.870), train_loss = 3.24870359, grad/param norm = 1.4281e+00, time/batch = 0.2571s	
696/2700 (epoch 12.889), train_loss = 3.26931542, grad/param norm = 1.2309e+00, time/batch = 0.2512s	
697/2700 (epoch 12.907), train_loss = 3.31858638, grad/param norm = 1.3218e+00, time/batch = 0.2553s	
698/2700 (epoch 12.926), train_loss = 3.28060676, grad/param norm = 1.5239e+00, time/batch = 0.2561s	
699/2700 (epoch 12.944), train_loss = 3.29327592, grad/param norm = 1.3033e+00, time/batch = 0.2492s	
700/2700 (epoch 12.963), train_loss = 3.35920677, grad/param norm = 1.1481e+00, time/batch = 0.2568s	
701/2700 (epoch 12.981), train_loss = 3.41751359, grad/param norm = 1.1628e+00, time/batch = 0.2303s	
decayed learning rate by a factor 0.97 to 0.00177058562	
702/2700 (epoch 13.000), train_loss = 3.32510599, grad/param norm = 1.1627e+00, time/batch = 0.2216s	
703/2700 (epoch 13.019), train_loss = 3.25894336, grad/param norm = 1.2618e+00, time/batch = 0.2233s	
704/2700 (epoch 13.037), train_loss = 3.27958100, grad/param norm = 1.2338e+00, time/batch = 0.2175s	
705/2700 (epoch 13.056), train_loss = 3.27186345, grad/param norm = 8.7877e-01, time/batch = 0.2231s	
706/2700 (epoch 13.074), train_loss = 3.30079371, grad/param norm = 8.5245e-01, time/batch = 0.2200s	
707/2700 (epoch 13.093), train_loss = 3.31286019, grad/param norm = 1.0434e+00, time/batch = 0.2188s	
708/2700 (epoch 13.111), train_loss = 3.28583120, grad/param norm = 1.0695e+00, time/batch = 0.2323s	
709/2700 (epoch 13.130), train_loss = 3.30448424, grad/param norm = 9.8911e-01, time/batch = 0.2272s	
710/2700 (epoch 13.148), train_loss = 3.26143201, grad/param norm = 1.2210e+00, time/batch = 0.2358s	
711/2700 (epoch 13.167), train_loss = 3.28565923, grad/param norm = 1.4112e+00, time/batch = 0.2229s	
712/2700 (epoch 13.185), train_loss = 3.26287380, grad/param norm = 1.1187e+00, time/batch = 0.2565s	
713/2700 (epoch 13.204), train_loss = 3.19126030, grad/param norm = 1.1255e+00, time/batch = 0.2569s	
714/2700 (epoch 13.222), train_loss = 3.16987089, grad/param norm = 1.3926e+00, time/batch = 0.2602s	
715/2700 (epoch 13.241), train_loss = 3.19471004, grad/param norm = 1.5027e+00, time/batch = 0.2553s	
716/2700 (epoch 13.259), train_loss = 3.24168246, grad/param norm = 2.1151e+00, time/batch = 0.2596s	
717/2700 (epoch 13.278), train_loss = 3.32272077, grad/param norm = 2.0915e+00, time/batch = 0.2581s	
718/2700 (epoch 13.296), train_loss = 3.31284267, grad/param norm = 1.8865e+00, time/batch = 0.2526s	
719/2700 (epoch 13.315), train_loss = 3.28599492, grad/param norm = 1.6624e+00, time/batch = 0.2585s	
720/2700 (epoch 13.333), train_loss = 3.36074119, grad/param norm = 1.3781e+00, time/batch = 0.2557s	
721/2700 (epoch 13.352), train_loss = 3.37146965, grad/param norm = 1.3748e+00, time/batch = 0.2323s	
722/2700 (epoch 13.370), train_loss = 3.31672087, grad/param norm = 1.1921e+00, time/batch = 0.2384s	
723/2700 (epoch 13.389), train_loss = 3.26831211, grad/param norm = 9.6744e-01, time/batch = 0.2375s	
724/2700 (epoch 13.407), train_loss = 3.29043909, grad/param norm = 8.4875e-01, time/batch = 0.2304s	
725/2700 (epoch 13.426), train_loss = 3.29353873, grad/param norm = 8.7450e-01, time/batch = 0.2225s	
726/2700 (epoch 13.444), train_loss = 3.21523684, grad/param norm = 8.3345e-01, time/batch = 0.2244s	
727/2700 (epoch 13.463), train_loss = 3.26220030, grad/param norm = 9.0639e-01, time/batch = 0.2296s	
728/2700 (epoch 13.481), train_loss = 3.33660578, grad/param norm = 7.5015e-01, time/batch = 0.2186s	
729/2700 (epoch 13.500), train_loss = 3.38041478, grad/param norm = 9.0628e-01, time/batch = 0.2500s	
730/2700 (epoch 13.519), train_loss = 3.33741828, grad/param norm = 1.1010e+00, time/batch = 0.2540s	
731/2700 (epoch 13.537), train_loss = 3.34868556, grad/param norm = 1.3188e+00, time/batch = 0.2345s	
732/2700 (epoch 13.556), train_loss = 3.29137104, grad/param norm = 1.2609e+00, time/batch = 0.2282s	
733/2700 (epoch 13.574), train_loss = 3.24099566, grad/param norm = 1.1876e+00, time/batch = 0.2475s	
734/2700 (epoch 13.593), train_loss = 3.25361461, grad/param norm = 1.5206e+00, time/batch = 0.2366s	
735/2700 (epoch 13.611), train_loss = 3.19913146, grad/param norm = 1.5540e+00, time/batch = 0.2382s	
736/2700 (epoch 13.630), train_loss = 3.24355923, grad/param norm = 1.7844e+00, time/batch = 0.2320s	
737/2700 (epoch 13.648), train_loss = 3.32451073, grad/param norm = 1.8824e+00, time/batch = 0.2294s	
738/2700 (epoch 13.667), train_loss = 3.25649671, grad/param norm = 1.8266e+00, time/batch = 0.2236s	
739/2700 (epoch 13.685), train_loss = 3.24165565, grad/param norm = 1.5028e+00, time/batch = 0.2572s	
740/2700 (epoch 13.704), train_loss = 3.21511779, grad/param norm = 1.5458e+00, time/batch = 0.2525s	
741/2700 (epoch 13.722), train_loss = 3.20317027, grad/param norm = 1.2899e+00, time/batch = 0.2326s	
742/2700 (epoch 13.741), train_loss = 3.32805350, grad/param norm = 1.0707e+00, time/batch = 0.2194s	
743/2700 (epoch 13.759), train_loss = 3.28040759, grad/param norm = 1.2858e+00, time/batch = 0.2345s	
744/2700 (epoch 13.778), train_loss = 3.28060523, grad/param norm = 1.5988e+00, time/batch = 0.2030s	
745/2700 (epoch 13.796), train_loss = 3.28079637, grad/param norm = 1.5701e+00, time/batch = 0.2260s	
746/2700 (epoch 13.815), train_loss = 3.22096336, grad/param norm = 1.3927e+00, time/batch = 0.2155s	
747/2700 (epoch 13.833), train_loss = 3.25900627, grad/param norm = 1.3824e+00, time/batch = 0.2139s	
748/2700 (epoch 13.852), train_loss = 3.24670531, grad/param norm = 1.4286e+00, time/batch = 0.2123s	
749/2700 (epoch 13.870), train_loss = 3.24398684, grad/param norm = 1.3091e+00, time/batch = 0.2247s	
750/2700 (epoch 13.889), train_loss = 3.26839907, grad/param norm = 1.1946e+00, time/batch = 0.2345s	
751/2700 (epoch 13.907), train_loss = 3.31878633, grad/param norm = 1.3454e+00, time/batch = 0.2348s	
752/2700 (epoch 13.926), train_loss = 3.28085078, grad/param norm = 1.5498e+00, time/batch = 0.2426s	
753/2700 (epoch 13.944), train_loss = 3.29262734, grad/param norm = 1.3284e+00, time/batch = 0.2348s	
754/2700 (epoch 13.963), train_loss = 3.35934319, grad/param norm = 1.1834e+00, time/batch = 0.2569s	
755/2700 (epoch 13.981), train_loss = 3.41771492, grad/param norm = 1.1804e+00, time/batch = 0.2560s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
756/2700 (epoch 14.000), train_loss = 3.32420936, grad/param norm = 1.1825e+00, time/batch = 0.2598s	
757/2700 (epoch 14.019), train_loss = 3.25943302, grad/param norm = 1.2917e+00, time/batch = 0.2550s	
758/2700 (epoch 14.037), train_loss = 3.27924129, grad/param norm = 1.2692e+00, time/batch = 0.2579s	
759/2700 (epoch 14.056), train_loss = 3.27150697, grad/param norm = 8.9437e-01, time/batch = 0.2585s	
760/2700 (epoch 14.074), train_loss = 3.29981019, grad/param norm = 8.1593e-01, time/batch = 0.2572s	
761/2700 (epoch 14.093), train_loss = 3.31159309, grad/param norm = 9.9947e-01, time/batch = 0.2564s	
762/2700 (epoch 14.111), train_loss = 3.28441841, grad/param norm = 1.0471e+00, time/batch = 0.2403s	
763/2700 (epoch 14.130), train_loss = 3.30364988, grad/param norm = 9.8047e-01, time/batch = 0.2061s	
764/2700 (epoch 14.148), train_loss = 3.26059603, grad/param norm = 1.2382e+00, time/batch = 0.2313s	
765/2700 (epoch 14.167), train_loss = 3.28483711, grad/param norm = 1.3919e+00, time/batch = 0.2254s	
766/2700 (epoch 14.185), train_loss = 3.26131835, grad/param norm = 1.1463e+00, time/batch = 0.2122s	
767/2700 (epoch 14.204), train_loss = 3.19087355, grad/param norm = 1.1286e+00, time/batch = 0.1878s	
768/2700 (epoch 14.222), train_loss = 3.16772129, grad/param norm = 1.4816e+00, time/batch = 0.2053s	
769/2700 (epoch 14.241), train_loss = 3.19028084, grad/param norm = 1.3696e+00, time/batch = 0.2058s	
770/2700 (epoch 14.259), train_loss = 3.22669752, grad/param norm = 1.3839e+00, time/batch = 0.2122s	
771/2700 (epoch 14.278), train_loss = 3.31176793, grad/param norm = 2.0336e+00, time/batch = 0.2264s	
772/2700 (epoch 14.296), train_loss = 3.32219297, grad/param norm = 1.9792e+00, time/batch = 0.2325s	
773/2700 (epoch 14.315), train_loss = 3.28639231, grad/param norm = 1.3855e+00, time/batch = 0.2359s	
774/2700 (epoch 14.333), train_loss = 3.35031767, grad/param norm = 1.0190e+00, time/batch = 0.2328s	
775/2700 (epoch 14.352), train_loss = 3.36031107, grad/param norm = 1.1198e+00, time/batch = 0.2600s	
776/2700 (epoch 14.370), train_loss = 3.31325191, grad/param norm = 1.3011e+00, time/batch = 0.2549s	
777/2700 (epoch 14.389), train_loss = 3.27345388, grad/param norm = 1.2297e+00, time/batch = 0.2513s	
778/2700 (epoch 14.407), train_loss = 3.29437995, grad/param norm = 1.0869e+00, time/batch = 0.2558s	
779/2700 (epoch 14.426), train_loss = 3.29342626, grad/param norm = 1.0065e+00, time/batch = 0.2580s	
780/2700 (epoch 14.444), train_loss = 3.21764395, grad/param norm = 1.0495e+00, time/batch = 0.2546s	
781/2700 (epoch 14.463), train_loss = 3.26602180, grad/param norm = 1.2855e+00, time/batch = 0.2549s	
782/2700 (epoch 14.481), train_loss = 3.34969435, grad/param norm = 1.4226e+00, time/batch = 0.2352s	
783/2700 (epoch 14.500), train_loss = 3.39566634, grad/param norm = 1.6573e+00, time/batch = 0.2577s	
784/2700 (epoch 14.519), train_loss = 3.35100042, grad/param norm = 1.6782e+00, time/batch = 0.2524s	
785/2700 (epoch 14.537), train_loss = 3.35413877, grad/param norm = 1.5403e+00, time/batch = 0.2303s	
786/2700 (epoch 14.556), train_loss = 3.29000852, grad/param norm = 1.2356e+00, time/batch = 0.2149s	
787/2700 (epoch 14.574), train_loss = 3.23792373, grad/param norm = 9.6828e-01, time/batch = 0.2119s	
788/2700 (epoch 14.593), train_loss = 3.24610178, grad/param norm = 1.1870e+00, time/batch = 0.2138s	
789/2700 (epoch 14.611), train_loss = 3.18698787, grad/param norm = 1.0474e+00, time/batch = 0.2277s	
790/2700 (epoch 14.630), train_loss = 3.22769629, grad/param norm = 1.1445e+00, time/batch = 0.2410s	
791/2700 (epoch 14.648), train_loss = 3.30504133, grad/param norm = 1.2623e+00, time/batch = 0.2266s	
792/2700 (epoch 14.667), train_loss = 3.24210173, grad/param norm = 1.2970e+00, time/batch = 0.2314s	
793/2700 (epoch 14.685), train_loss = 3.23250953, grad/param norm = 1.1981e+00, time/batch = 0.2417s	
794/2700 (epoch 14.704), train_loss = 3.20924778, grad/param norm = 1.3666e+00, time/batch = 0.2446s	
795/2700 (epoch 14.722), train_loss = 3.19904737, grad/param norm = 1.2018e+00, time/batch = 0.2299s	
796/2700 (epoch 14.741), train_loss = 3.32723786, grad/param norm = 1.0815e+00, time/batch = 0.2296s	
797/2700 (epoch 14.759), train_loss = 3.28171055, grad/param norm = 1.3620e+00, time/batch = 0.2565s	
798/2700 (epoch 14.778), train_loss = 3.28502147, grad/param norm = 1.7724e+00, time/batch = 0.2563s	
799/2700 (epoch 14.796), train_loss = 3.28760503, grad/param norm = 1.8029e+00, time/batch = 0.2572s	
800/2700 (epoch 14.815), train_loss = 3.22442879, grad/param norm = 1.6021e+00, time/batch = 0.2533s	
801/2700 (epoch 14.833), train_loss = 3.26209729, grad/param norm = 1.5933e+00, time/batch = 0.2315s	
802/2700 (epoch 14.852), train_loss = 3.25074899, grad/param norm = 1.6148e+00, time/batch = 0.2338s	
803/2700 (epoch 14.870), train_loss = 3.24445145, grad/param norm = 1.3693e+00, time/batch = 0.2353s	
804/2700 (epoch 14.889), train_loss = 3.26738303, grad/param norm = 1.1820e+00, time/batch = 0.2423s	
805/2700 (epoch 14.907), train_loss = 3.31699172, grad/param norm = 1.2727e+00, time/batch = 0.2405s	
806/2700 (epoch 14.926), train_loss = 3.27775979, grad/param norm = 1.4532e+00, time/batch = 0.1813s	
807/2700 (epoch 14.944), train_loss = 3.28927679, grad/param norm = 1.2334e+00, time/batch = 0.2374s	
808/2700 (epoch 14.963), train_loss = 3.35664419, grad/param norm = 1.0890e+00, time/batch = 0.2401s	
809/2700 (epoch 14.981), train_loss = 3.41529779, grad/param norm = 1.1111e+00, time/batch = 0.2372s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
810/2700 (epoch 15.000), train_loss = 3.32214019, grad/param norm = 1.1087e+00, time/batch = 0.2287s	
811/2700 (epoch 15.019), train_loss = 3.25710007, grad/param norm = 1.2064e+00, time/batch = 0.2260s	
812/2700 (epoch 15.037), train_loss = 3.27672194, grad/param norm = 1.1675e+00, time/batch = 0.2401s	
813/2700 (epoch 15.056), train_loss = 3.26985966, grad/param norm = 8.2841e-01, time/batch = 0.2405s	
814/2700 (epoch 15.074), train_loss = 3.29972314, grad/param norm = 8.4114e-01, time/batch = 0.2459s	
815/2700 (epoch 15.093), train_loss = 3.31101337, grad/param norm = 1.0287e+00, time/batch = 0.2442s	
816/2700 (epoch 15.111), train_loss = 3.28346038, grad/param norm = 1.0351e+00, time/batch = 0.2450s	
817/2700 (epoch 15.130), train_loss = 3.30182188, grad/param norm = 9.5245e-01, time/batch = 0.2597s	
818/2700 (epoch 15.148), train_loss = 3.25935619, grad/param norm = 1.1714e+00, time/batch = 0.2580s	
819/2700 (epoch 15.167), train_loss = 3.28190519, grad/param norm = 1.3768e+00, time/batch = 0.2532s	
820/2700 (epoch 15.185), train_loss = 3.26009304, grad/param norm = 1.0934e+00, time/batch = 0.2423s	
821/2700 (epoch 15.204), train_loss = 3.18972634, grad/param norm = 1.1627e+00, time/batch = 0.2620s	
822/2700 (epoch 15.222), train_loss = 3.17064474, grad/param norm = 1.4836e+00, time/batch = 0.2587s	
823/2700 (epoch 15.241), train_loss = 3.19729944, grad/param norm = 1.6675e+00, time/batch = 0.2573s	
824/2700 (epoch 15.259), train_loss = 3.24010721, grad/param norm = 2.1411e+00, time/batch = 0.2560s	
825/2700 (epoch 15.278), train_loss = 3.31445097, grad/param norm = 1.9243e+00, time/batch = 0.2356s	
826/2700 (epoch 15.296), train_loss = 3.30569632, grad/param norm = 1.6363e+00, time/batch = 0.2442s	
827/2700 (epoch 15.315), train_loss = 3.27911282, grad/param norm = 1.4466e+00, time/batch = 0.2359s	
828/2700 (epoch 15.333), train_loss = 3.35672706, grad/param norm = 1.2506e+00, time/batch = 0.2277s	
829/2700 (epoch 15.352), train_loss = 3.36643919, grad/param norm = 1.2513e+00, time/batch = 0.2265s	
830/2700 (epoch 15.370), train_loss = 3.31086102, grad/param norm = 1.0961e+00, time/batch = 0.2192s	
831/2700 (epoch 15.389), train_loss = 3.26540949, grad/param norm = 8.9891e-01, time/batch = 0.2241s	
832/2700 (epoch 15.407), train_loss = 3.28807863, grad/param norm = 7.9948e-01, time/batch = 0.2138s	
833/2700 (epoch 15.426), train_loss = 3.29135327, grad/param norm = 8.3164e-01, time/batch = 0.2098s	
834/2700 (epoch 15.444), train_loss = 3.21418057, grad/param norm = 8.1180e-01, time/batch = 0.2007s	
835/2700 (epoch 15.463), train_loss = 3.26093972, grad/param norm = 8.9518e-01, time/batch = 0.2069s	
836/2700 (epoch 15.481), train_loss = 3.33504633, grad/param norm = 7.4644e-01, time/batch = 0.2447s	
837/2700 (epoch 15.500), train_loss = 3.37958771, grad/param norm = 9.4232e-01, time/batch = 0.2427s	
838/2700 (epoch 15.519), train_loss = 3.33652827, grad/param norm = 1.1288e+00, time/batch = 0.2461s	
839/2700 (epoch 15.537), train_loss = 3.34671283, grad/param norm = 1.3239e+00, time/batch = 0.2454s	
840/2700 (epoch 15.556), train_loss = 3.28821334, grad/param norm = 1.2384e+00, time/batch = 0.2140s	
841/2700 (epoch 15.574), train_loss = 3.24003627, grad/param norm = 1.1484e+00, time/batch = 0.2252s	
842/2700 (epoch 15.593), train_loss = 3.25165592, grad/param norm = 1.4677e+00, time/batch = 0.2543s	
843/2700 (epoch 15.611), train_loss = 3.19598334, grad/param norm = 1.4529e+00, time/batch = 0.2559s	
844/2700 (epoch 15.630), train_loss = 3.23840540, grad/param norm = 1.6313e+00, time/batch = 0.2526s	
845/2700 (epoch 15.648), train_loss = 3.31725543, grad/param norm = 1.7182e+00, time/batch = 0.2577s	
846/2700 (epoch 15.667), train_loss = 3.24884682, grad/param norm = 1.6513e+00, time/batch = 0.2555s	
847/2700 (epoch 15.685), train_loss = 3.23554700, grad/param norm = 1.3636e+00, time/batch = 0.2528s	
848/2700 (epoch 15.704), train_loss = 3.20938920, grad/param norm = 1.4357e+00, time/batch = 0.2609s	
849/2700 (epoch 15.722), train_loss = 3.19828666, grad/param norm = 1.1972e+00, time/batch = 0.2607s	
850/2700 (epoch 15.741), train_loss = 3.32438320, grad/param norm = 9.9402e-01, time/batch = 0.2547s	
851/2700 (epoch 15.759), train_loss = 3.27682742, grad/param norm = 1.2219e+00, time/batch = 0.2526s	
852/2700 (epoch 15.778), train_loss = 3.27694521, grad/param norm = 1.5279e+00, time/batch = 0.2558s	
853/2700 (epoch 15.796), train_loss = 3.27609216, grad/param norm = 1.5125e+00, time/batch = 0.2529s	
854/2700 (epoch 15.815), train_loss = 3.21805838, grad/param norm = 1.3468e+00, time/batch = 0.2425s	
855/2700 (epoch 15.833), train_loss = 3.25581658, grad/param norm = 1.3387e+00, time/batch = 0.2563s	
856/2700 (epoch 15.852), train_loss = 3.24373809, grad/param norm = 1.3853e+00, time/batch = 0.2583s	
857/2700 (epoch 15.870), train_loss = 3.24034469, grad/param norm = 1.2617e+00, time/batch = 0.2514s	
858/2700 (epoch 15.889), train_loss = 3.26635871, grad/param norm = 1.1499e+00, time/batch = 0.2172s	
859/2700 (epoch 15.907), train_loss = 3.31714536, grad/param norm = 1.3010e+00, time/batch = 0.2201s	
860/2700 (epoch 15.926), train_loss = 3.27793577, grad/param norm = 1.4865e+00, time/batch = 0.2232s	
861/2700 (epoch 15.944), train_loss = 3.28875092, grad/param norm = 1.2651e+00, time/batch = 0.1963s	
862/2700 (epoch 15.963), train_loss = 3.35686290, grad/param norm = 1.1276e+00, time/batch = 0.2101s	
863/2700 (epoch 15.981), train_loss = 3.41542772, grad/param norm = 1.1324e+00, time/batch = 0.2268s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
864/2700 (epoch 16.000), train_loss = 3.32133162, grad/param norm = 1.1298e+00, time/batch = 0.2183s	
865/2700 (epoch 16.019), train_loss = 3.25754426, grad/param norm = 1.2382e+00, time/batch = 0.2355s	
866/2700 (epoch 16.037), train_loss = 3.27638585, grad/param norm = 1.2029e+00, time/batch = 0.2323s	
867/2700 (epoch 16.056), train_loss = 3.26943528, grad/param norm = 8.3756e-01, time/batch = 0.2338s	
868/2700 (epoch 16.074), train_loss = 3.29867909, grad/param norm = 7.9596e-01, time/batch = 0.2266s	
869/2700 (epoch 16.093), train_loss = 3.30964952, grad/param norm = 9.7868e-01, time/batch = 0.2406s	
870/2700 (epoch 16.111), train_loss = 3.28199188, grad/param norm = 1.0025e+00, time/batch = 0.2424s	
871/2700 (epoch 16.130), train_loss = 3.30076470, grad/param norm = 9.2518e-01, time/batch = 0.2592s	
872/2700 (epoch 16.148), train_loss = 3.25822004, grad/param norm = 1.1616e+00, time/batch = 0.2591s	
873/2700 (epoch 16.167), train_loss = 3.28021984, grad/param norm = 1.3162e+00, time/batch = 0.2536s	
874/2700 (epoch 16.185), train_loss = 3.25742980, grad/param norm = 1.0195e+00, time/batch = 0.2586s	
875/2700 (epoch 16.204), train_loss = 3.18655593, grad/param norm = 9.6785e-01, time/batch = 0.2532s	
876/2700 (epoch 16.222), train_loss = 3.16298631, grad/param norm = 1.2411e+00, time/batch = 0.2500s	
877/2700 (epoch 16.241), train_loss = 3.18319818, grad/param norm = 9.7187e-01, time/batch = 0.2476s	
878/2700 (epoch 16.259), train_loss = 3.21535863, grad/param norm = 7.5487e-01, time/batch = 0.2371s	
879/2700 (epoch 16.278), train_loss = 3.29328049, grad/param norm = 1.1570e+00, time/batch = 0.2327s	
880/2700 (epoch 16.296), train_loss = 3.30463902, grad/param norm = 1.4865e+00, time/batch = 0.1995s	
881/2700 (epoch 16.315), train_loss = 3.28716344, grad/param norm = 1.6225e+00, time/batch = 0.2349s	
882/2700 (epoch 16.333), train_loss = 3.36135255, grad/param norm = 1.5491e+00, time/batch = 0.2288s	
883/2700 (epoch 16.352), train_loss = 3.36827088, grad/param norm = 1.6313e+00, time/batch = 0.2184s	
884/2700 (epoch 16.370), train_loss = 3.32234590, grad/param norm = 1.8015e+00, time/batch = 0.2281s	
885/2700 (epoch 16.389), train_loss = 3.28002262, grad/param norm = 1.5895e+00, time/batch = 0.2265s	
886/2700 (epoch 16.407), train_loss = 3.29748281, grad/param norm = 1.3526e+00, time/batch = 0.2208s	
887/2700 (epoch 16.426), train_loss = 3.29379006, grad/param norm = 1.1175e+00, time/batch = 0.2297s	
888/2700 (epoch 16.444), train_loss = 3.21856755, grad/param norm = 1.1300e+00, time/batch = 0.2345s	
889/2700 (epoch 16.463), train_loss = 3.26478959, grad/param norm = 1.2337e+00, time/batch = 0.2350s	
890/2700 (epoch 16.481), train_loss = 3.34459992, grad/param norm = 1.2526e+00, time/batch = 0.2524s	
891/2700 (epoch 16.500), train_loss = 3.38894848, grad/param norm = 1.3981e+00, time/batch = 0.2351s	
892/2700 (epoch 16.519), train_loss = 3.34192472, grad/param norm = 1.3849e+00, time/batch = 0.2311s	
893/2700 (epoch 16.537), train_loss = 3.34654412, grad/param norm = 1.3276e+00, time/batch = 0.2248s	
894/2700 (epoch 16.556), train_loss = 3.28458305, grad/param norm = 1.0698e+00, time/batch = 0.2471s	
895/2700 (epoch 16.574), train_loss = 3.23596047, grad/param norm = 8.6267e-01, time/batch = 0.2421s	
896/2700 (epoch 16.593), train_loss = 3.24362840, grad/param norm = 1.0958e+00, time/batch = 0.2375s	
897/2700 (epoch 16.611), train_loss = 3.18407505, grad/param norm = 9.5316e-01, time/batch = 0.2312s	
898/2700 (epoch 16.630), train_loss = 3.22463349, grad/param norm = 1.0222e+00, time/batch = 0.2300s	
899/2700 (epoch 16.648), train_loss = 3.30049718, grad/param norm = 1.1281e+00, time/batch = 0.2208s	
900/2700 (epoch 16.667), train_loss = 3.23694856, grad/param norm = 1.1495e+00, time/batch = 0.2399s	
901/2700 (epoch 16.685), train_loss = 3.22797853, grad/param norm = 1.0688e+00, time/batch = 0.2545s	
902/2700 (epoch 16.704), train_loss = 3.20418561, grad/param norm = 1.2436e+00, time/batch = 0.2450s	
903/2700 (epoch 16.722), train_loss = 3.19379156, grad/param norm = 1.0686e+00, time/batch = 0.2442s	
904/2700 (epoch 16.741), train_loss = 3.32299156, grad/param norm = 9.7128e-01, time/batch = 0.2417s	
905/2700 (epoch 16.759), train_loss = 3.27702837, grad/param norm = 1.2599e+00, time/batch = 0.2444s	
906/2700 (epoch 16.778), train_loss = 3.28109073, grad/param norm = 1.6869e+00, time/batch = 0.2433s	
907/2700 (epoch 16.796), train_loss = 3.28437916, grad/param norm = 1.7815e+00, time/batch = 0.2415s	
908/2700 (epoch 16.815), train_loss = 3.22323379, grad/param norm = 1.6088e+00, time/batch = 0.2412s	
909/2700 (epoch 16.833), train_loss = 3.26016409, grad/param norm = 1.6113e+00, time/batch = 0.2309s	
910/2700 (epoch 16.852), train_loss = 3.24884720, grad/param norm = 1.6129e+00, time/batch = 0.2060s	
911/2700 (epoch 16.870), train_loss = 3.24092587, grad/param norm = 1.3350e+00, time/batch = 0.2422s	
912/2700 (epoch 16.889), train_loss = 3.26548450, grad/param norm = 1.1411e+00, time/batch = 0.2426s	
913/2700 (epoch 16.907), train_loss = 3.31540184, grad/param norm = 1.2235e+00, time/batch = 0.2561s	
914/2700 (epoch 16.926), train_loss = 3.27493072, grad/param norm = 1.3833e+00, time/batch = 0.2585s	
915/2700 (epoch 16.944), train_loss = 3.28552999, grad/param norm = 1.1665e+00, time/batch = 0.2603s	
916/2700 (epoch 16.963), train_loss = 3.35435440, grad/param norm = 1.0357e+00, time/batch = 0.2574s	
917/2700 (epoch 16.981), train_loss = 3.41350485, grad/param norm = 1.0714e+00, time/batch = 0.2585s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
918/2700 (epoch 17.000), train_loss = 3.31955292, grad/param norm = 1.0649e+00, time/batch = 0.2546s	
919/2700 (epoch 17.019), train_loss = 3.25530052, grad/param norm = 1.1558e+00, time/batch = 0.2570s	
920/2700 (epoch 17.037), train_loss = 3.27396749, grad/param norm = 1.1028e+00, time/batch = 0.2463s	
921/2700 (epoch 17.056), train_loss = 3.26808877, grad/param norm = 7.8804e-01, time/batch = 0.2411s	
922/2700 (epoch 17.074), train_loss = 3.29893824, grad/param norm = 8.5220e-01, time/batch = 0.2301s	
923/2700 (epoch 17.093), train_loss = 3.30950683, grad/param norm = 1.0322e+00, time/batch = 0.2294s	
924/2700 (epoch 17.111), train_loss = 3.28136213, grad/param norm = 1.0157e+00, time/batch = 0.2362s	
925/2700 (epoch 17.130), train_loss = 3.29940431, grad/param norm = 9.2942e-01, time/batch = 0.2449s	
926/2700 (epoch 17.148), train_loss = 3.25754492, grad/param norm = 1.1355e+00, time/batch = 0.2330s	
927/2700 (epoch 17.167), train_loss = 3.27876565, grad/param norm = 1.3560e+00, time/batch = 0.2255s	
928/2700 (epoch 17.185), train_loss = 3.25782654, grad/param norm = 1.0861e+00, time/batch = 0.2182s	
929/2700 (epoch 17.204), train_loss = 3.18849297, grad/param norm = 1.1879e+00, time/batch = 0.2208s	
930/2700 (epoch 17.222), train_loss = 3.17004303, grad/param norm = 1.5046e+00, time/batch = 0.2360s	
931/2700 (epoch 17.241), train_loss = 3.19514491, grad/param norm = 1.6366e+00, time/batch = 0.2026s	
932/2700 (epoch 17.259), train_loss = 3.23311679, grad/param norm = 1.9094e+00, time/batch = 0.2560s	
933/2700 (epoch 17.278), train_loss = 3.30528701, grad/param norm = 1.6990e+00, time/batch = 0.2565s	
934/2700 (epoch 17.296), train_loss = 3.30209645, grad/param norm = 1.5345e+00, time/batch = 0.2572s	
935/2700 (epoch 17.315), train_loss = 3.27637729, grad/param norm = 1.3758e+00, time/batch = 0.2596s	
936/2700 (epoch 17.333), train_loss = 3.35425868, grad/param norm = 1.2007e+00, time/batch = 0.2586s	
937/2700 (epoch 17.352), train_loss = 3.36308698, grad/param norm = 1.1911e+00, time/batch = 0.2571s	
938/2700 (epoch 17.370), train_loss = 3.30679624, grad/param norm = 1.0388e+00, time/batch = 0.2609s	
939/2700 (epoch 17.389), train_loss = 3.26319618, grad/param norm = 8.4699e-01, time/batch = 0.2583s	
940/2700 (epoch 17.407), train_loss = 3.28601758, grad/param norm = 7.5767e-01, time/batch = 0.2588s	
941/2700 (epoch 17.426), train_loss = 3.28946429, grad/param norm = 7.9817e-01, time/batch = 0.2353s	
942/2700 (epoch 17.444), train_loss = 3.21309479, grad/param norm = 7.8118e-01, time/batch = 0.2360s	
943/2700 (epoch 17.463), train_loss = 3.25939674, grad/param norm = 8.6872e-01, time/batch = 0.2383s	
944/2700 (epoch 17.481), train_loss = 3.33345491, grad/param norm = 7.2493e-01, time/batch = 0.2286s	
945/2700 (epoch 17.500), train_loss = 3.37863206, grad/param norm = 9.4817e-01, time/batch = 0.2139s	
946/2700 (epoch 17.519), train_loss = 3.33554098, grad/param norm = 1.1278e+00, time/batch = 0.2335s	
947/2700 (epoch 17.537), train_loss = 3.34470659, grad/param norm = 1.3031e+00, time/batch = 0.2259s	
948/2700 (epoch 17.556), train_loss = 3.28485608, grad/param norm = 1.1921e+00, time/batch = 0.2403s	
949/2700 (epoch 17.574), train_loss = 3.23876961, grad/param norm = 1.0976e+00, time/batch = 0.2522s	
950/2700 (epoch 17.593), train_loss = 3.24941913, grad/param norm = 1.4072e+00, time/batch = 0.2563s	
951/2700 (epoch 17.611), train_loss = 3.19269816, grad/param norm = 1.3652e+00, time/batch = 0.2233s	
952/2700 (epoch 17.630), train_loss = 3.23448866, grad/param norm = 1.5143e+00, time/batch = 0.2397s	
953/2700 (epoch 17.648), train_loss = 3.31172638, grad/param norm = 1.5923e+00, time/batch = 0.2464s	
954/2700 (epoch 17.667), train_loss = 3.24327577, grad/param norm = 1.5261e+00, time/batch = 0.2403s	
955/2700 (epoch 17.685), train_loss = 3.23116055, grad/param norm = 1.2598e+00, time/batch = 0.2362s	
956/2700 (epoch 17.704), train_loss = 3.20503880, grad/param norm = 1.3464e+00, time/batch = 0.2309s	
957/2700 (epoch 17.722), train_loss = 3.19430642, grad/param norm = 1.1143e+00, time/batch = 0.2407s	
958/2700 (epoch 17.741), train_loss = 3.32130354, grad/param norm = 9.2527e-01, time/batch = 0.2508s	
959/2700 (epoch 17.759), train_loss = 3.27365981, grad/param norm = 1.1597e+00, time/batch = 0.2562s	
960/2700 (epoch 17.778), train_loss = 3.27325742, grad/param norm = 1.4466e+00, time/batch = 0.2495s	
961/2700 (epoch 17.796), train_loss = 3.27146696, grad/param norm = 1.4475e+00, time/batch = 0.2527s	
962/2700 (epoch 17.815), train_loss = 3.21536470, grad/param norm = 1.2955e+00, time/batch = 0.2385s	
963/2700 (epoch 17.833), train_loss = 3.25284508, grad/param norm = 1.2883e+00, time/batch = 0.2374s	
964/2700 (epoch 17.852), train_loss = 3.24079601, grad/param norm = 1.3333e+00, time/batch = 0.2351s	
965/2700 (epoch 17.870), train_loss = 3.23683722, grad/param norm = 1.2084e+00, time/batch = 0.2261s	
966/2700 (epoch 17.889), train_loss = 3.26442410, grad/param norm = 1.1041e+00, time/batch = 0.2267s	
967/2700 (epoch 17.907), train_loss = 3.31571085, grad/param norm = 1.2602e+00, time/batch = 0.2148s	
968/2700 (epoch 17.926), train_loss = 3.27522340, grad/param norm = 1.4252e+00, time/batch = 0.2321s	
969/2700 (epoch 17.944), train_loss = 3.28519710, grad/param norm = 1.2062e+00, time/batch = 0.2386s	
970/2700 (epoch 17.963), train_loss = 3.35475638, grad/param norm = 1.0793e+00, time/batch = 0.2358s	
971/2700 (epoch 17.981), train_loss = 3.41358060, grad/param norm = 1.0916e+00, time/batch = 0.2313s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
972/2700 (epoch 18.000), train_loss = 3.31877240, grad/param norm = 1.0852e+00, time/batch = 0.2400s	
973/2700 (epoch 18.019), train_loss = 3.25587825, grad/param norm = 1.1916e+00, time/batch = 0.2401s	
974/2700 (epoch 18.037), train_loss = 3.27381993, grad/param norm = 1.1438e+00, time/batch = 0.2597s	
975/2700 (epoch 18.056), train_loss = 3.26766830, grad/param norm = 7.9011e-01, time/batch = 0.2506s	
976/2700 (epoch 18.074), train_loss = 3.29770526, grad/param norm = 7.8459e-01, time/batch = 0.2584s	
977/2700 (epoch 18.093), train_loss = 3.30793265, grad/param norm = 9.6359e-01, time/batch = 0.2558s	
978/2700 (epoch 18.111), train_loss = 3.27983237, grad/param norm = 9.6688e-01, time/batch = 0.2571s	
979/2700 (epoch 18.130), train_loss = 3.29824080, grad/param norm = 8.8387e-01, time/batch = 0.2571s	
980/2700 (epoch 18.148), train_loss = 3.25628731, grad/param norm = 1.1030e+00, time/batch = 0.2491s	
981/2700 (epoch 18.167), train_loss = 3.27652134, grad/param norm = 1.2656e+00, time/batch = 0.2482s	
982/2700 (epoch 18.185), train_loss = 3.25466820, grad/param norm = 9.4748e-01, time/batch = 0.2413s	
983/2700 (epoch 18.204), train_loss = 3.18418056, grad/param norm = 9.1943e-01, time/batch = 0.2184s	
984/2700 (epoch 18.222), train_loss = 3.16175581, grad/param norm = 1.1673e+00, time/batch = 0.2177s	
985/2700 (epoch 18.241), train_loss = 3.18200860, grad/param norm = 1.0225e+00, time/batch = 0.1937s	
986/2700 (epoch 18.259), train_loss = 3.21937751, grad/param norm = 1.2000e+00, time/batch = 0.2170s	
987/2700 (epoch 18.278), train_loss = 3.29917252, grad/param norm = 1.5118e+00, time/batch = 0.2121s	
988/2700 (epoch 18.296), train_loss = 3.31201158, grad/param norm = 2.0200e+00, time/batch = 0.2159s	
989/2700 (epoch 18.315), train_loss = 3.29229440, grad/param norm = 1.9019e+00, time/batch = 0.2220s	
990/2700 (epoch 18.333), train_loss = 3.35907667, grad/param norm = 1.4639e+00, time/batch = 0.2210s	
991/2700 (epoch 18.352), train_loss = 3.36671891, grad/param norm = 1.3612e+00, time/batch = 0.2140s	
992/2700 (epoch 18.370), train_loss = 3.30729617, grad/param norm = 1.0933e+00, time/batch = 0.2279s	
993/2700 (epoch 18.389), train_loss = 3.26209724, grad/param norm = 8.3568e-01, time/batch = 0.2405s	
994/2700 (epoch 18.407), train_loss = 3.28476747, grad/param norm = 7.3181e-01, time/batch = 0.2297s	
995/2700 (epoch 18.426), train_loss = 3.28827610, grad/param norm = 7.7934e-01, time/batch = 0.2305s	
996/2700 (epoch 18.444), train_loss = 3.21130907, grad/param norm = 6.9715e-01, time/batch = 0.2513s	
997/2700 (epoch 18.463), train_loss = 3.25689009, grad/param norm = 7.7683e-01, time/batch = 0.2486s	
998/2700 (epoch 18.481), train_loss = 3.33228286, grad/param norm = 6.7270e-01, time/batch = 0.2425s	
999/2700 (epoch 18.500), train_loss = 3.37882267, grad/param norm = 9.2647e-01, time/batch = 0.2393s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch18.52_3.2179.t7	
1000/2700 (epoch 18.519), train_loss = 3.33596574, grad/param norm = 1.0958e+00, time/batch = 0.2412s	
1001/2700 (epoch 18.537), train_loss = 3.34356916, grad/param norm = 1.2415e+00, time/batch = 0.2349s	
1002/2700 (epoch 18.556), train_loss = 3.28196682, grad/param norm = 1.0969e+00, time/batch = 0.2113s	
1003/2700 (epoch 18.574), train_loss = 3.23641998, grad/param norm = 1.0053e+00, time/batch = 0.2328s	
1004/2700 (epoch 18.593), train_loss = 3.24621501, grad/param norm = 1.3106e+00, time/batch = 0.2356s	
1005/2700 (epoch 18.611), train_loss = 3.18881128, grad/param norm = 1.2758e+00, time/batch = 0.2403s	
1006/2700 (epoch 18.630), train_loss = 3.23292633, grad/param norm = 1.4730e+00, time/batch = 0.2432s	
1007/2700 (epoch 18.648), train_loss = 3.31033100, grad/param norm = 1.5825e+00, time/batch = 0.2077s	
1008/2700 (epoch 18.667), train_loss = 3.24248547, grad/param norm = 1.5404e+00, time/batch = 0.2166s	
1009/2700 (epoch 18.685), train_loss = 3.23075594, grad/param norm = 1.2820e+00, time/batch = 0.2102s	
1010/2700 (epoch 18.704), train_loss = 3.20496963, grad/param norm = 1.3725e+00, time/batch = 0.2082s	
1011/2700 (epoch 18.722), train_loss = 3.19398195, grad/param norm = 1.1323e+00, time/batch = 0.2380s	
1012/2700 (epoch 18.741), train_loss = 3.32066032, grad/param norm = 9.2767e-01, time/batch = 0.2368s	
1013/2700 (epoch 18.759), train_loss = 3.27283681, grad/param norm = 1.1538e+00, time/batch = 0.2091s	
1014/2700 (epoch 18.778), train_loss = 3.27141064, grad/param norm = 1.4115e+00, time/batch = 0.2576s	
1015/2700 (epoch 18.796), train_loss = 3.26900757, grad/param norm = 1.4165e+00, time/batch = 0.2588s	
1016/2700 (epoch 18.815), train_loss = 3.21404110, grad/param norm = 1.2671e+00, time/batch = 0.2512s	
1017/2700 (epoch 18.833), train_loss = 3.25122265, grad/param norm = 1.2453e+00, time/batch = 0.2578s	
1018/2700 (epoch 18.852), train_loss = 3.23877658, grad/param norm = 1.2777e+00, time/batch = 0.2571s	
1019/2700 (epoch 18.870), train_loss = 3.23463709, grad/param norm = 1.1470e+00, time/batch = 0.2557s	
1020/2700 (epoch 18.889), train_loss = 3.26286308, grad/param norm = 1.0451e+00, time/batch = 0.2568s	
1021/2700 (epoch 18.907), train_loss = 3.31464167, grad/param norm = 1.2134e+00, time/batch = 0.2291s	
1022/2700 (epoch 18.926), train_loss = 3.27364698, grad/param norm = 1.3807e+00, time/batch = 0.2573s	
1023/2700 (epoch 18.944), train_loss = 3.28360256, grad/param norm = 1.1776e+00, time/batch = 0.2441s	
1024/2700 (epoch 18.963), train_loss = 3.35410291, grad/param norm = 1.0621e+00, time/batch = 0.2347s	
1025/2700 (epoch 18.981), train_loss = 3.41284159, grad/param norm = 1.0745e+00, time/batch = 0.2303s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1026/2700 (epoch 19.000), train_loss = 3.31747961, grad/param norm = 1.0634e+00, time/batch = 0.2078s	
1027/2700 (epoch 19.019), train_loss = 3.25510571, grad/param norm = 1.1712e+00, time/batch = 0.2147s	
1028/2700 (epoch 19.037), train_loss = 3.27264516, grad/param norm = 1.1186e+00, time/batch = 0.2190s	
1029/2700 (epoch 19.056), train_loss = 3.26687412, grad/param norm = 7.6978e-01, time/batch = 0.2302s	
1030/2700 (epoch 19.074), train_loss = 3.29717648, grad/param norm = 7.7604e-01, time/batch = 0.2449s	
1031/2700 (epoch 19.093), train_loss = 3.30710639, grad/param norm = 9.5406e-01, time/batch = 0.2238s	
1032/2700 (epoch 19.111), train_loss = 3.27883232, grad/param norm = 9.5039e-01, time/batch = 0.2303s	
1033/2700 (epoch 19.130), train_loss = 3.29709587, grad/param norm = 8.6625e-01, time/batch = 0.2367s	
1034/2700 (epoch 19.148), train_loss = 3.25544382, grad/param norm = 1.0807e+00, time/batch = 0.2361s	
1035/2700 (epoch 19.167), train_loss = 3.27500892, grad/param norm = 1.2453e+00, time/batch = 0.2557s	
1036/2700 (epoch 19.185), train_loss = 3.25350138, grad/param norm = 9.2322e-01, time/batch = 0.2521s	
1037/2700 (epoch 19.204), train_loss = 3.18334385, grad/param norm = 9.0715e-01, time/batch = 0.2585s	
1038/2700 (epoch 19.222), train_loss = 3.16131517, grad/param norm = 1.1608e+00, time/batch = 0.2568s	
1039/2700 (epoch 19.241), train_loss = 3.18188125, grad/param norm = 1.0685e+00, time/batch = 0.2578s	
1040/2700 (epoch 19.259), train_loss = 3.22095585, grad/param norm = 1.3709e+00, time/batch = 0.2521s	
1041/2700 (epoch 19.278), train_loss = 3.30195939, grad/param norm = 1.6267e+00, time/batch = 0.2403s	
1042/2700 (epoch 19.296), train_loss = 3.30957986, grad/param norm = 1.9463e+00, time/batch = 0.2330s	
1043/2700 (epoch 19.315), train_loss = 3.28672590, grad/param norm = 1.7697e+00, time/batch = 0.2322s	
1044/2700 (epoch 19.333), train_loss = 3.35631742, grad/param norm = 1.3661e+00, time/batch = 0.2297s	
1045/2700 (epoch 19.352), train_loss = 3.36359498, grad/param norm = 1.2713e+00, time/batch = 0.2409s	
1046/2700 (epoch 19.370), train_loss = 3.30488483, grad/param norm = 1.0430e+00, time/batch = 0.2074s	
1047/2700 (epoch 19.389), train_loss = 3.26124014, grad/param norm = 8.0410e-01, time/batch = 0.1986s	
1048/2700 (epoch 19.407), train_loss = 3.28395470, grad/param norm = 7.1225e-01, time/batch = 0.2038s	
1049/2700 (epoch 19.426), train_loss = 3.28746067, grad/param norm = 7.5776e-01, time/batch = 0.2031s	
1050/2700 (epoch 19.444), train_loss = 3.21089496, grad/param norm = 6.8487e-01, time/batch = 0.1907s	
1051/2700 (epoch 19.463), train_loss = 3.25640881, grad/param norm = 7.7398e-01, time/batch = 0.2174s	
1052/2700 (epoch 19.481), train_loss = 3.33179718, grad/param norm = 6.8127e-01, time/batch = 0.2322s	
1053/2700 (epoch 19.500), train_loss = 3.37862205, grad/param norm = 9.5356e-01, time/batch = 0.2470s	
1054/2700 (epoch 19.519), train_loss = 3.33564819, grad/param norm = 1.1190e+00, time/batch = 0.2555s	
1055/2700 (epoch 19.537), train_loss = 3.34287192, grad/param norm = 1.2475e+00, time/batch = 0.2440s	
1056/2700 (epoch 19.556), train_loss = 3.28062169, grad/param norm = 1.0831e+00, time/batch = 0.2470s	
1057/2700 (epoch 19.574), train_loss = 3.23595777, grad/param norm = 9.7772e-01, time/batch = 0.2518s	
1058/2700 (epoch 19.593), train_loss = 3.24522587, grad/param norm = 1.2728e+00, time/batch = 0.2600s	
1059/2700 (epoch 19.611), train_loss = 3.18733319, grad/param norm = 1.2099e+00, time/batch = 0.2550s	
1060/2700 (epoch 19.630), train_loss = 3.23033561, grad/param norm = 1.3778e+00, time/batch = 0.2549s	
1061/2700 (epoch 19.648), train_loss = 3.30693393, grad/param norm = 1.4795e+00, time/batch = 0.2595s	
1062/2700 (epoch 19.667), train_loss = 3.23931560, grad/param norm = 1.4491e+00, time/batch = 0.2533s	
1063/2700 (epoch 19.685), train_loss = 3.22866942, grad/param norm = 1.2218e+00, time/batch = 0.2467s	
1064/2700 (epoch 19.704), train_loss = 3.20282066, grad/param norm = 1.3232e+00, time/batch = 0.2380s	
1065/2700 (epoch 19.722), train_loss = 3.19219069, grad/param norm = 1.0953e+00, time/batch = 0.2295s	
1066/2700 (epoch 19.741), train_loss = 3.31946495, grad/param norm = 9.0492e-01, time/batch = 0.2396s	
1067/2700 (epoch 19.759), train_loss = 3.27172971, grad/param norm = 1.1377e+00, time/batch = 0.2336s	
1068/2700 (epoch 19.778), train_loss = 3.27019832, grad/param norm = 1.3931e+00, time/batch = 0.2276s	
1069/2700 (epoch 19.796), train_loss = 3.26753552, grad/param norm = 1.4068e+00, time/batch = 0.2189s	
1070/2700 (epoch 19.815), train_loss = 3.21308683, grad/param norm = 1.2603e+00, time/batch = 0.2285s	
1071/2700 (epoch 19.833), train_loss = 3.25024130, grad/param norm = 1.2401e+00, time/batch = 0.2231s	
1072/2700 (epoch 19.852), train_loss = 3.23788476, grad/param norm = 1.2707e+00, time/batch = 0.2118s	
1073/2700 (epoch 19.870), train_loss = 3.23325398, grad/param norm = 1.1296e+00, time/batch = 0.2127s	
1074/2700 (epoch 19.889), train_loss = 3.26203071, grad/param norm = 1.0255e+00, time/batch = 0.2176s	
1075/2700 (epoch 19.907), train_loss = 3.31396520, grad/param norm = 1.1913e+00, time/batch = 0.2148s	
1076/2700 (epoch 19.926), train_loss = 3.27228257, grad/param norm = 1.3458e+00, time/batch = 0.2438s	
1077/2700 (epoch 19.944), train_loss = 3.28193259, grad/param norm = 1.1442e+00, time/batch = 0.2514s	
1078/2700 (epoch 19.963), train_loss = 3.35309593, grad/param norm = 1.0346e+00, time/batch = 0.2399s	
1079/2700 (epoch 19.981), train_loss = 3.41203799, grad/param norm = 1.0538e+00, time/batch = 0.2409s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1080/2700 (epoch 20.000), train_loss = 3.31635396, grad/param norm = 1.0401e+00, time/batch = 0.2346s	
1081/2700 (epoch 20.019), train_loss = 3.25424441, grad/param norm = 1.1448e+00, time/batch = 0.2533s	
1082/2700 (epoch 20.037), train_loss = 3.27141866, grad/param norm = 1.0845e+00, time/batch = 0.2481s	
1083/2700 (epoch 20.056), train_loss = 3.26610590, grad/param norm = 7.4733e-01, time/batch = 0.2420s	
1084/2700 (epoch 20.074), train_loss = 3.29685347, grad/param norm = 7.8133e-01, time/batch = 0.2355s	
1085/2700 (epoch 20.093), train_loss = 3.30643668, grad/param norm = 9.5611e-01, time/batch = 0.2434s	
1086/2700 (epoch 20.111), train_loss = 3.27792009, grad/param norm = 9.3950e-01, time/batch = 0.2444s	
1087/2700 (epoch 20.130), train_loss = 3.29595814, grad/param norm = 8.5250e-01, time/batch = 0.2590s	
1088/2700 (epoch 20.148), train_loss = 3.25465893, grad/param norm = 1.0560e+00, time/batch = 0.2407s	
1089/2700 (epoch 20.167), train_loss = 3.27354197, grad/param norm = 1.2358e+00, time/batch = 0.2407s	
1090/2700 (epoch 20.185), train_loss = 3.25273715, grad/param norm = 9.2171e-01, time/batch = 0.2386s	
1091/2700 (epoch 20.204), train_loss = 3.18326042, grad/param norm = 9.5719e-01, time/batch = 0.2579s	
1092/2700 (epoch 20.222), train_loss = 3.16272437, grad/param norm = 1.2449e+00, time/batch = 0.2551s	
1093/2700 (epoch 20.241), train_loss = 3.18559813, grad/param norm = 1.3217e+00, time/batch = 0.2549s	
1094/2700 (epoch 20.259), train_loss = 3.22702996, grad/param norm = 1.7740e+00, time/batch = 0.2580s	
1095/2700 (epoch 20.278), train_loss = 3.30455366, grad/param norm = 1.7202e+00, time/batch = 0.2304s	
1096/2700 (epoch 20.296), train_loss = 3.30176332, grad/param norm = 1.6106e+00, time/batch = 0.2238s	
1097/2700 (epoch 20.315), train_loss = 3.27612550, grad/param norm = 1.4300e+00, time/batch = 0.2085s	
1098/2700 (epoch 20.333), train_loss = 3.35219610, grad/param norm = 1.1925e+00, time/batch = 0.2180s	
1099/2700 (epoch 20.352), train_loss = 3.35978272, grad/param norm = 1.1433e+00, time/batch = 0.2260s	
1100/2700 (epoch 20.370), train_loss = 3.30222568, grad/param norm = 9.8208e-01, time/batch = 0.2355s	
1101/2700 (epoch 20.389), train_loss = 3.26058238, grad/param norm = 7.7975e-01, time/batch = 0.2206s	
1102/2700 (epoch 20.407), train_loss = 3.28334015, grad/param norm = 7.0070e-01, time/batch = 0.2192s	
1103/2700 (epoch 20.426), train_loss = 3.28678173, grad/param norm = 7.4296e-01, time/batch = 0.2248s	
1104/2700 (epoch 20.444), train_loss = 3.21084032, grad/param norm = 6.9305e-01, time/batch = 0.2265s	
1105/2700 (epoch 20.463), train_loss = 3.25636581, grad/param norm = 7.9176e-01, time/batch = 0.2297s	
1106/2700 (epoch 20.481), train_loss = 3.33142033, grad/param norm = 6.9616e-01, time/batch = 0.2349s	
1107/2700 (epoch 20.500), train_loss = 3.37814515, grad/param norm = 9.7591e-01, time/batch = 0.2228s	
1108/2700 (epoch 20.519), train_loss = 3.33500561, grad/param norm = 1.1376e+00, time/batch = 0.2428s	
1109/2700 (epoch 20.537), train_loss = 3.34211032, grad/param norm = 1.2559e+00, time/batch = 0.2406s	
1110/2700 (epoch 20.556), train_loss = 3.27955268, grad/param norm = 1.0798e+00, time/batch = 0.2435s	
1111/2700 (epoch 20.574), train_loss = 3.23596414, grad/param norm = 9.6898e-01, time/batch = 0.2587s	
1112/2700 (epoch 20.593), train_loss = 3.24486796, grad/param norm = 1.2584e+00, time/batch = 0.2568s	
1113/2700 (epoch 20.611), train_loss = 3.18657492, grad/param norm = 1.1723e+00, time/batch = 0.2573s	
1114/2700 (epoch 20.630), train_loss = 3.22834610, grad/param norm = 1.3050e+00, time/batch = 0.2545s	
1115/2700 (epoch 20.648), train_loss = 3.30414604, grad/param norm = 1.3928e+00, time/batch = 0.2500s	
1116/2700 (epoch 20.667), train_loss = 3.23646350, grad/param norm = 1.3607e+00, time/batch = 0.2358s	
1117/2700 (epoch 20.685), train_loss = 3.22650648, grad/param norm = 1.1505e+00, time/batch = 0.2550s	
1118/2700 (epoch 20.704), train_loss = 3.20046765, grad/param norm = 1.2590e+00, time/batch = 0.2353s	
1119/2700 (epoch 20.722), train_loss = 3.19016616, grad/param norm = 1.0397e+00, time/batch = 0.2268s	
1120/2700 (epoch 20.741), train_loss = 3.31810438, grad/param norm = 8.6818e-01, time/batch = 0.2192s	
1121/2700 (epoch 20.759), train_loss = 3.27038640, grad/param norm = 1.1080e+00, time/batch = 0.2194s	
1122/2700 (epoch 20.778), train_loss = 3.26880583, grad/param norm = 1.3620e+00, time/batch = 0.2122s	
1123/2700 (epoch 20.796), train_loss = 3.26592820, grad/param norm = 1.3860e+00, time/batch = 0.2054s	
1124/2700 (epoch 20.815), train_loss = 3.21210715, grad/param norm = 1.2470e+00, time/batch = 0.2028s	
1125/2700 (epoch 20.833), train_loss = 3.24928428, grad/param norm = 1.2341e+00, time/batch = 0.2161s	
1126/2700 (epoch 20.852), train_loss = 3.23707973, grad/param norm = 1.2668e+00, time/batch = 0.1993s	
1127/2700 (epoch 20.870), train_loss = 3.23201538, grad/param norm = 1.1202e+00, time/batch = 0.2270s	
1128/2700 (epoch 20.889), train_loss = 3.26144319, grad/param norm = 1.0178e+00, time/batch = 0.2220s	
1129/2700 (epoch 20.907), train_loss = 3.31348725, grad/param norm = 1.1802e+00, time/batch = 0.2366s	
1130/2700 (epoch 20.926), train_loss = 3.27106406, grad/param norm = 1.3174e+00, time/batch = 0.2410s	
1131/2700 (epoch 20.944), train_loss = 3.28031707, grad/param norm = 1.1131e+00, time/batch = 0.2615s	
1132/2700 (epoch 20.963), train_loss = 3.35207866, grad/param norm = 1.0085e+00, time/batch = 0.2588s	
1133/2700 (epoch 20.981), train_loss = 3.41131382, grad/param norm = 1.0353e+00, time/batch = 0.2586s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1134/2700 (epoch 21.000), train_loss = 3.31533469, grad/param norm = 1.0209e+00, time/batch = 0.2582s	
1135/2700 (epoch 21.019), train_loss = 3.25345829, grad/param norm = 1.1217e+00, time/batch = 0.2477s	
1136/2700 (epoch 21.037), train_loss = 3.27029393, grad/param norm = 1.0547e+00, time/batch = 0.2585s	
1137/2700 (epoch 21.056), train_loss = 3.26543077, grad/param norm = 7.2955e-01, time/batch = 0.2580s	
1138/2700 (epoch 21.074), train_loss = 3.29657569, grad/param norm = 7.8924e-01, time/batch = 0.2561s	
1139/2700 (epoch 21.093), train_loss = 3.30581116, grad/param norm = 9.5893e-01, time/batch = 0.2251s	
1140/2700 (epoch 21.111), train_loss = 3.27705385, grad/param norm = 9.3061e-01, time/batch = 0.2230s	
1141/2700 (epoch 21.130), train_loss = 3.29490474, grad/param norm = 8.4139e-01, time/batch = 0.2234s	
1142/2700 (epoch 21.148), train_loss = 3.25392379, grad/param norm = 1.0354e+00, time/batch = 0.2142s	
1143/2700 (epoch 21.167), train_loss = 3.27220824, grad/param norm = 1.2270e+00, time/batch = 0.2189s	
1144/2700 (epoch 21.185), train_loss = 3.25200674, grad/param norm = 9.2450e-01, time/batch = 0.2293s	
1145/2700 (epoch 21.204), train_loss = 3.18316930, grad/param norm = 9.9299e-01, time/batch = 0.2181s	
1146/2700 (epoch 21.222), train_loss = 3.16334484, grad/param norm = 1.2950e+00, time/batch = 0.2378s	
1147/2700 (epoch 21.241), train_loss = 3.18660063, grad/param norm = 1.3948e+00, time/batch = 0.2450s	
1148/2700 (epoch 21.259), train_loss = 3.22586661, grad/param norm = 1.7501e+00, time/batch = 0.2519s	
1149/2700 (epoch 21.278), train_loss = 3.30073228, grad/param norm = 1.6146e+00, time/batch = 0.2397s	
1150/2700 (epoch 21.296), train_loss = 3.29884787, grad/param norm = 1.4962e+00, time/batch = 0.2572s	
1151/2700 (epoch 21.315), train_loss = 3.27343419, grad/param norm = 1.3365e+00, time/batch = 0.2462s	
1152/2700 (epoch 21.333), train_loss = 3.35046863, grad/param norm = 1.1348e+00, time/batch = 0.2400s	
1153/2700 (epoch 21.352), train_loss = 3.35786426, grad/param norm = 1.0941e+00, time/batch = 0.2341s	
1154/2700 (epoch 21.370), train_loss = 3.30050623, grad/param norm = 9.5126e-01, time/batch = 0.2271s	
1155/2700 (epoch 21.389), train_loss = 3.25985363, grad/param norm = 7.5922e-01, time/batch = 0.2202s	
1156/2700 (epoch 21.407), train_loss = 3.28264526, grad/param norm = 6.8749e-01, time/batch = 0.2518s	
1157/2700 (epoch 21.426), train_loss = 3.28610543, grad/param norm = 7.3150e-01, time/batch = 0.2438s	
1158/2700 (epoch 21.444), train_loss = 3.21060561, grad/param norm = 6.8894e-01, time/batch = 0.2340s	
1159/2700 (epoch 21.463), train_loss = 3.25596736, grad/param norm = 7.9097e-01, time/batch = 0.2257s	
1160/2700 (epoch 21.481), train_loss = 3.33092135, grad/param norm = 6.9588e-01, time/batch = 0.2134s	
1161/2700 (epoch 21.500), train_loss = 3.37776005, grad/param norm = 9.8271e-01, time/batch = 0.2229s	
1162/2700 (epoch 21.519), train_loss = 3.33446534, grad/param norm = 1.1365e+00, time/batch = 0.2224s	
1163/2700 (epoch 21.537), train_loss = 3.34116067, grad/param norm = 1.2426e+00, time/batch = 0.2237s	
1164/2700 (epoch 21.556), train_loss = 3.27822120, grad/param norm = 1.0564e+00, time/batch = 0.2170s	
1165/2700 (epoch 21.574), train_loss = 3.23567067, grad/param norm = 9.4665e-01, time/batch = 0.2270s	
1166/2700 (epoch 21.593), train_loss = 3.24400486, grad/param norm = 1.2290e+00, time/batch = 0.2317s	
1167/2700 (epoch 21.611), train_loss = 3.18523226, grad/param norm = 1.1249e+00, time/batch = 0.2220s	
1168/2700 (epoch 21.630), train_loss = 3.22657691, grad/param norm = 1.2422e+00, time/batch = 0.2229s	
1169/2700 (epoch 21.648), train_loss = 3.30197186, grad/param norm = 1.3286e+00, time/batch = 0.2319s	
1170/2700 (epoch 21.667), train_loss = 3.23431779, grad/param norm = 1.2993e+00, time/batch = 0.2274s	
1171/2700 (epoch 21.685), train_loss = 3.22492814, grad/param norm = 1.1032e+00, time/batch = 0.2605s	
1172/2700 (epoch 21.704), train_loss = 3.19879011, grad/param norm = 1.2170e+00, time/batch = 0.2587s	
1173/2700 (epoch 21.722), train_loss = 3.18868157, grad/param norm = 1.0025e+00, time/batch = 0.2520s	
1174/2700 (epoch 21.741), train_loss = 3.31705769, grad/param norm = 8.4338e-01, time/batch = 0.2548s	
1175/2700 (epoch 21.759), train_loss = 3.26932624, grad/param norm = 1.0868e+00, time/batch = 0.2576s	
1176/2700 (epoch 21.778), train_loss = 3.26746097, grad/param norm = 1.3334e+00, time/batch = 0.2568s	
1177/2700 (epoch 21.796), train_loss = 3.26427749, grad/param norm = 1.3642e+00, time/batch = 0.2582s	
1178/2700 (epoch 21.815), train_loss = 3.21109577, grad/param norm = 1.2305e+00, time/batch = 0.2566s	
1179/2700 (epoch 21.833), train_loss = 3.24824491, grad/param norm = 1.2203e+00, time/batch = 0.2536s	
1180/2700 (epoch 21.852), train_loss = 3.23607718, grad/param norm = 1.2521e+00, time/batch = 0.2445s	
1181/2700 (epoch 21.870), train_loss = 3.23065219, grad/param norm = 1.0992e+00, time/batch = 0.2118s	
1182/2700 (epoch 21.889), train_loss = 3.26070261, grad/param norm = 9.9903e-01, time/batch = 0.2029s	
1183/2700 (epoch 21.907), train_loss = 3.31292765, grad/param norm = 1.1618e+00, time/batch = 0.1726s	
1184/2700 (epoch 21.926), train_loss = 3.26980043, grad/param norm = 1.2853e+00, time/batch = 0.2099s	
1185/2700 (epoch 21.944), train_loss = 3.27879174, grad/param norm = 1.0828e+00, time/batch = 0.2451s	
1186/2700 (epoch 21.963), train_loss = 3.35119835, grad/param norm = 9.8495e-01, time/batch = 0.2490s	
1187/2700 (epoch 21.981), train_loss = 3.41065031, grad/param norm = 1.0179e+00, time/batch = 0.2416s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1188/2700 (epoch 22.000), train_loss = 3.31432730, grad/param norm = 1.0024e+00, time/batch = 0.2367s	
1189/2700 (epoch 22.019), train_loss = 3.25269807, grad/param norm = 1.1004e+00, time/batch = 0.2328s	
1190/2700 (epoch 22.037), train_loss = 3.26923816, grad/param norm = 1.0275e+00, time/batch = 0.2235s	
1191/2700 (epoch 22.056), train_loss = 3.26481748, grad/param norm = 7.1452e-01, time/batch = 0.2467s	
1192/2700 (epoch 22.074), train_loss = 3.29629611, grad/param norm = 7.9683e-01, time/batch = 0.2585s	
1193/2700 (epoch 22.093), train_loss = 3.30521121, grad/param norm = 9.6122e-01, time/batch = 0.2445s	
1194/2700 (epoch 22.111), train_loss = 3.27622776, grad/param norm = 9.2233e-01, time/batch = 0.2538s	
1195/2700 (epoch 22.130), train_loss = 3.29390175, grad/param norm = 8.3075e-01, time/batch = 0.2562s	
1196/2700 (epoch 22.148), train_loss = 3.25321303, grad/param norm = 1.0160e+00, time/batch = 0.2579s	
1197/2700 (epoch 22.167), train_loss = 3.27095469, grad/param norm = 1.2163e+00, time/batch = 0.2547s	
1198/2700 (epoch 22.185), train_loss = 3.25123496, grad/param norm = 9.2202e-01, time/batch = 0.2487s	
1199/2700 (epoch 22.204), train_loss = 3.18288293, grad/param norm = 1.0071e+00, time/batch = 0.2396s	
1200/2700 (epoch 22.222), train_loss = 3.16322886, grad/param norm = 1.3064e+00, time/batch = 0.2310s	
1201/2700 (epoch 22.241), train_loss = 3.18599733, grad/param norm = 1.3895e+00, time/batch = 0.2530s	
1202/2700 (epoch 22.259), train_loss = 3.22356260, grad/param norm = 1.6629e+00, time/batch = 0.2309s	
1203/2700 (epoch 22.278), train_loss = 3.29746626, grad/param norm = 1.5172e+00, time/batch = 0.2159s	
1204/2700 (epoch 22.296), train_loss = 3.29712233, grad/param norm = 1.4374e+00, time/batch = 0.2198s	
1205/2700 (epoch 22.315), train_loss = 3.27200449, grad/param norm = 1.2939e+00, time/batch = 0.2270s	
1206/2700 (epoch 22.333), train_loss = 3.34931450, grad/param norm = 1.1060e+00, time/batch = 0.2341s	
1207/2700 (epoch 22.352), train_loss = 3.35647144, grad/param norm = 1.0657e+00, time/batch = 0.2373s	
1208/2700 (epoch 22.370), train_loss = 3.29911947, grad/param norm = 9.2974e-01, time/batch = 0.2467s	
1209/2700 (epoch 22.389), train_loss = 3.25915495, grad/param norm = 7.4036e-01, time/batch = 0.2549s	
1210/2700 (epoch 22.407), train_loss = 3.28196508, grad/param norm = 6.7386e-01, time/batch = 0.2588s	
1211/2700 (epoch 22.426), train_loss = 3.28544077, grad/param norm = 7.2023e-01, time/batch = 0.2335s	
1212/2700 (epoch 22.444), train_loss = 3.21028472, grad/param norm = 6.7826e-01, time/batch = 0.2101s	
1213/2700 (epoch 22.463), train_loss = 3.25543174, grad/param norm = 7.8221e-01, time/batch = 0.2212s	
1214/2700 (epoch 22.481), train_loss = 3.33040209, grad/param norm = 6.9058e-01, time/batch = 0.2574s	
1215/2700 (epoch 22.500), train_loss = 3.37743190, grad/param norm = 9.8586e-01, time/batch = 0.2569s	
1216/2700 (epoch 22.519), train_loss = 3.33400795, grad/param norm = 1.1323e+00, time/batch = 0.2568s	
1217/2700 (epoch 22.537), train_loss = 3.34024159, grad/param norm = 1.2268e+00, time/batch = 0.2580s	
1218/2700 (epoch 22.556), train_loss = 3.27692029, grad/param norm = 1.0319e+00, time/batch = 0.2531s	
1219/2700 (epoch 22.574), train_loss = 3.23532145, grad/param norm = 9.2465e-01, time/batch = 0.2383s	
1220/2700 (epoch 22.593), train_loss = 3.24308417, grad/param norm = 1.1998e+00, time/batch = 0.2310s	
1221/2700 (epoch 22.611), train_loss = 3.18388587, grad/param norm = 1.0796e+00, time/batch = 0.2333s	
1222/2700 (epoch 22.630), train_loss = 3.22503790, grad/param norm = 1.1877e+00, time/batch = 0.2232s	
1223/2700 (epoch 22.648), train_loss = 3.30008898, grad/param norm = 1.2731e+00, time/batch = 0.1691s	
1224/2700 (epoch 22.667), train_loss = 3.23240422, grad/param norm = 1.2447e+00, time/batch = 0.2579s	
1225/2700 (epoch 22.685), train_loss = 3.22353827, grad/param norm = 1.0617e+00, time/batch = 0.2606s	
1226/2700 (epoch 22.704), train_loss = 3.19733600, grad/param norm = 1.1805e+00, time/batch = 0.2593s	
1227/2700 (epoch 22.722), train_loss = 3.18738122, grad/param norm = 9.6928e-01, time/batch = 0.2590s	
1228/2700 (epoch 22.741), train_loss = 3.31613644, grad/param norm = 8.2155e-01, time/batch = 0.2586s	
1229/2700 (epoch 22.759), train_loss = 3.26837419, grad/param norm = 1.0677e+00, time/batch = 0.2578s	
1230/2700 (epoch 22.778), train_loss = 3.26616217, grad/param norm = 1.3051e+00, time/batch = 0.2535s	
1231/2700 (epoch 22.796), train_loss = 3.26266836, grad/param norm = 1.3413e+00, time/batch = 0.2486s	
1232/2700 (epoch 22.815), train_loss = 3.21008731, grad/param norm = 1.2117e+00, time/batch = 0.2477s	
1233/2700 (epoch 22.833), train_loss = 3.24720597, grad/param norm = 1.2039e+00, time/batch = 0.2360s	
1234/2700 (epoch 22.852), train_loss = 3.23504928, grad/param norm = 1.2346e+00, time/batch = 0.2137s	
1235/2700 (epoch 22.870), train_loss = 3.22930861, grad/param norm = 1.0762e+00, time/batch = 0.2168s	
1236/2700 (epoch 22.889), train_loss = 3.25998526, grad/param norm = 9.7944e-01, time/batch = 0.1868s	
1237/2700 (epoch 22.907), train_loss = 3.31239754, grad/param norm = 1.1437e+00, time/batch = 0.2606s	
1238/2700 (epoch 22.926), train_loss = 3.26856199, grad/param norm = 1.2534e+00, time/batch = 0.2590s	
1239/2700 (epoch 22.944), train_loss = 3.27733905, grad/param norm = 1.0536e+00, time/batch = 0.2600s	
1240/2700 (epoch 22.963), train_loss = 3.35037941, grad/param norm = 9.6276e-01, time/batch = 0.2474s	
1241/2700 (epoch 22.981), train_loss = 3.41003462, grad/param norm = 1.0013e+00, time/batch = 0.2564s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1242/2700 (epoch 23.000), train_loss = 3.31335576, grad/param norm = 9.8508e-01, time/batch = 0.2502s	
1243/2700 (epoch 23.019), train_loss = 3.25195982, grad/param norm = 1.0804e+00, time/batch = 0.2568s	
1244/2700 (epoch 23.037), train_loss = 3.26824450, grad/param norm = 1.0023e+00, time/batch = 0.2577s	
1245/2700 (epoch 23.056), train_loss = 3.26425918, grad/param norm = 7.0174e-01, time/batch = 0.2588s	
1246/2700 (epoch 23.074), train_loss = 3.29602958, grad/param norm = 8.0486e-01, time/batch = 0.2571s	
1247/2700 (epoch 23.093), train_loss = 3.30463608, grad/param norm = 9.6328e-01, time/batch = 0.2305s	
1248/2700 (epoch 23.111), train_loss = 3.27543472, grad/param norm = 9.1416e-01, time/batch = 0.2205s	
1249/2700 (epoch 23.130), train_loss = 3.29293321, grad/param norm = 8.1965e-01, time/batch = 0.2266s	
1250/2700 (epoch 23.148), train_loss = 3.25250968, grad/param norm = 9.9615e-01, time/batch = 0.2326s	
1251/2700 (epoch 23.167), train_loss = 3.26972775, grad/param norm = 1.2025e+00, time/batch = 0.2006s	
1252/2700 (epoch 23.185), train_loss = 3.25041018, grad/param norm = 9.1242e-01, time/batch = 0.2033s	
1253/2700 (epoch 23.204), train_loss = 3.18241675, grad/param norm = 1.0038e+00, time/batch = 0.2440s	
1254/2700 (epoch 23.222), train_loss = 3.16267795, grad/param norm = 1.2937e+00, time/batch = 0.2495s	
1255/2700 (epoch 23.241), train_loss = 3.18470073, grad/param norm = 1.3502e+00, time/batch = 0.2565s	
1256/2700 (epoch 23.259), train_loss = 3.22124623, grad/param norm = 1.5703e+00, time/batch = 0.2580s	
1257/2700 (epoch 23.278), train_loss = 3.29488995, grad/param norm = 1.4365e+00, time/batch = 0.2497s	
1258/2700 (epoch 23.296), train_loss = 3.29581419, grad/param norm = 1.3976e+00, time/batch = 0.2544s	
1259/2700 (epoch 23.315), train_loss = 3.27094440, grad/param norm = 1.2673e+00, time/batch = 0.2489s	
1260/2700 (epoch 23.333), train_loss = 3.34837024, grad/param norm = 1.0867e+00, time/batch = 0.2443s	
1261/2700 (epoch 23.352), train_loss = 3.35531509, grad/param norm = 1.0451e+00, time/batch = 0.2447s	
1262/2700 (epoch 23.370), train_loss = 3.29791422, grad/param norm = 9.1256e-01, time/batch = 0.2443s	
1263/2700 (epoch 23.389), train_loss = 3.25850612, grad/param norm = 7.2290e-01, time/batch = 0.2522s	
1264/2700 (epoch 23.407), train_loss = 3.28131852, grad/param norm = 6.6065e-01, time/batch = 0.2537s	
1265/2700 (epoch 23.426), train_loss = 3.28479409, grad/param norm = 7.0905e-01, time/batch = 0.2561s	
1266/2700 (epoch 23.444), train_loss = 3.20992959, grad/param norm = 6.6452e-01, time/batch = 0.2557s	
1267/2700 (epoch 23.463), train_loss = 3.25484951, grad/param norm = 7.7009e-01, time/batch = 0.2538s	
1268/2700 (epoch 23.481), train_loss = 3.32990511, grad/param norm = 6.8415e-01, time/batch = 0.2228s	
1269/2700 (epoch 23.500), train_loss = 3.37715355, grad/param norm = 9.8855e-01, time/batch = 0.2238s	
1270/2700 (epoch 23.519), train_loss = 3.33360154, grad/param norm = 1.1273e+00, time/batch = 0.2233s	
1271/2700 (epoch 23.537), train_loss = 3.33935205, grad/param norm = 1.2101e+00, time/batch = 0.2538s	
1272/2700 (epoch 23.556), train_loss = 3.27567767, grad/param norm = 1.0076e+00, time/batch = 0.2586s	
1273/2700 (epoch 23.574), train_loss = 3.23497447, grad/param norm = 9.0342e-01, time/batch = 0.2593s	
1274/2700 (epoch 23.593), train_loss = 3.24216387, grad/param norm = 1.1710e+00, time/batch = 0.2516s	
1275/2700 (epoch 23.611), train_loss = 3.18258921, grad/param norm = 1.0353e+00, time/batch = 0.2438s	
1276/2700 (epoch 23.630), train_loss = 3.22363353, grad/param norm = 1.1370e+00, time/batch = 0.2373s	
1277/2700 (epoch 23.648), train_loss = 3.29836354, grad/param norm = 1.2211e+00, time/batch = 0.2287s	
1278/2700 (epoch 23.667), train_loss = 3.23061876, grad/param norm = 1.1920e+00, time/batch = 0.2152s	
1279/2700 (epoch 23.685), train_loss = 3.22225706, grad/param norm = 1.0222e+00, time/batch = 0.2527s	
1280/2700 (epoch 23.704), train_loss = 3.19601373, grad/param norm = 1.1465e+00, time/batch = 0.2522s	
1281/2700 (epoch 23.722), train_loss = 3.18620141, grad/param norm = 9.3800e-01, time/batch = 0.2242s	
1282/2700 (epoch 23.741), train_loss = 3.31530572, grad/param norm = 8.0173e-01, time/batch = 0.2435s	
1283/2700 (epoch 23.759), train_loss = 3.26750762, grad/param norm = 1.0502e+00, time/batch = 0.2422s	
1284/2700 (epoch 23.778), train_loss = 3.26494407, grad/param norm = 1.2785e+00, time/batch = 0.2442s	
1285/2700 (epoch 23.796), train_loss = 3.26116004, grad/param norm = 1.3191e+00, time/batch = 0.2473s	
1286/2700 (epoch 23.815), train_loss = 3.20911325, grad/param norm = 1.1928e+00, time/batch = 0.2521s	
1287/2700 (epoch 23.833), train_loss = 3.24620674, grad/param norm = 1.1875e+00, time/batch = 0.2509s	
1288/2700 (epoch 23.852), train_loss = 3.23405732, grad/param norm = 1.2170e+00, time/batch = 0.2387s	
1289/2700 (epoch 23.870), train_loss = 3.22801775, grad/param norm = 1.0529e+00, time/batch = 0.2487s	
1290/2700 (epoch 23.889), train_loss = 3.25930676, grad/param norm = 9.6013e-01, time/batch = 0.2319s	
1291/2700 (epoch 23.907), train_loss = 3.31189280, grad/param norm = 1.1260e+00, time/batch = 0.2270s	
1292/2700 (epoch 23.926), train_loss = 3.26734813, grad/param norm = 1.2216e+00, time/batch = 0.2504s	
1293/2700 (epoch 23.944), train_loss = 3.27595032, grad/param norm = 1.0248e+00, time/batch = 0.2454s	
1294/2700 (epoch 23.963), train_loss = 3.34959827, grad/param norm = 9.4112e-01, time/batch = 0.2417s	
1295/2700 (epoch 23.981), train_loss = 3.40945258, grad/param norm = 9.8510e-01, time/batch = 0.2278s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1296/2700 (epoch 24.000), train_loss = 3.31242179, grad/param norm = 9.6856e-01, time/batch = 0.2253s	
1297/2700 (epoch 24.019), train_loss = 3.25123639, grad/param norm = 1.0614e+00, time/batch = 0.2168s	
1298/2700 (epoch 24.037), train_loss = 3.26730400, grad/param norm = 9.7836e-01, time/batch = 0.2275s	
1299/2700 (epoch 24.056), train_loss = 3.26375016, grad/param norm = 6.9097e-01, time/batch = 0.1807s	
1300/2700 (epoch 24.074), train_loss = 3.29578336, grad/param norm = 8.1377e-01, time/batch = 0.2406s	
1301/2700 (epoch 24.093), train_loss = 3.30408670, grad/param norm = 9.6550e-01, time/batch = 0.2244s	
1302/2700 (epoch 24.111), train_loss = 3.27467336, grad/param norm = 9.0601e-01, time/batch = 0.2405s	
1303/2700 (epoch 24.130), train_loss = 3.29199273, grad/param norm = 8.0787e-01, time/batch = 0.2526s	
1304/2700 (epoch 24.148), train_loss = 3.25181286, grad/param norm = 9.7517e-01, time/batch = 0.2576s	
1305/2700 (epoch 24.167), train_loss = 3.26851532, grad/param norm = 1.1856e+00, time/batch = 0.2580s	
1306/2700 (epoch 24.185), train_loss = 3.24955307, grad/param norm = 8.9677e-01, time/batch = 0.2575s	
1307/2700 (epoch 24.204), train_loss = 3.18183586, grad/param norm = 9.8883e-01, time/batch = 0.2520s	
1308/2700 (epoch 24.222), train_loss = 3.16191307, grad/param norm = 1.2683e+00, time/batch = 0.2489s	
1309/2700 (epoch 24.241), train_loss = 3.18316698, grad/param norm = 1.2962e+00, time/batch = 0.2274s	
1310/2700 (epoch 24.259), train_loss = 3.21909348, grad/param norm = 1.4810e+00, time/batch = 0.2528s	
1311/2700 (epoch 24.278), train_loss = 3.29276661, grad/param norm = 1.3676e+00, time/batch = 0.2460s	
1312/2700 (epoch 24.296), train_loss = 3.29470865, grad/param norm = 1.3666e+00, time/batch = 0.2391s	
1313/2700 (epoch 24.315), train_loss = 3.27004870, grad/param norm = 1.2476e+00, time/batch = 0.2415s	
1314/2700 (epoch 24.333), train_loss = 3.34754072, grad/param norm = 1.0721e+00, time/batch = 0.2433s	
1315/2700 (epoch 24.352), train_loss = 3.35430391, grad/param norm = 1.0288e+00, time/batch = 0.2469s	
1316/2700 (epoch 24.370), train_loss = 3.29683449, grad/param norm = 8.9804e-01, time/batch = 0.2502s	
1317/2700 (epoch 24.389), train_loss = 3.25790595, grad/param norm = 7.0665e-01, time/batch = 0.2468s	
1318/2700 (epoch 24.407), train_loss = 3.28071015, grad/param norm = 6.4815e-01, time/batch = 0.2384s	
1319/2700 (epoch 24.426), train_loss = 3.28417266, grad/param norm = 6.9819e-01, time/batch = 0.2314s	
1320/2700 (epoch 24.444), train_loss = 3.20957259, grad/param norm = 6.4953e-01, time/batch = 0.2014s	
1321/2700 (epoch 24.463), train_loss = 3.25426320, grad/param norm = 7.5648e-01, time/batch = 0.2349s	
1322/2700 (epoch 24.481), train_loss = 3.32943949, grad/param norm = 6.7755e-01, time/batch = 0.2436s	
1323/2700 (epoch 24.500), train_loss = 3.37691005, grad/param norm = 9.9098e-01, time/batch = 0.2525s	
1324/2700 (epoch 24.519), train_loss = 3.33321252, grad/param norm = 1.1212e+00, time/batch = 0.2589s	
1325/2700 (epoch 24.537), train_loss = 3.33847860, grad/param norm = 1.1924e+00, time/batch = 0.2591s	
1326/2700 (epoch 24.556), train_loss = 3.27450191, grad/param norm = 9.8364e-01, time/batch = 0.2563s	
1327/2700 (epoch 24.574), train_loss = 3.23465463, grad/param norm = 8.8333e-01, time/batch = 0.2569s	
1328/2700 (epoch 24.593), train_loss = 3.24126113, grad/param norm = 1.1430e+00, time/batch = 0.2542s	
1329/2700 (epoch 24.611), train_loss = 3.18135308, grad/param norm = 9.9183e-01, time/batch = 0.2568s	
1330/2700 (epoch 24.630), train_loss = 3.22233844, grad/param norm = 1.0888e+00, time/batch = 0.2405s	
1331/2700 (epoch 24.648), train_loss = 3.29676416, grad/param norm = 1.1715e+00, time/batch = 0.2361s	
1332/2700 (epoch 24.667), train_loss = 3.22893989, grad/param norm = 1.1403e+00, time/batch = 0.2233s	
1333/2700 (epoch 24.685), train_loss = 3.22106085, grad/param norm = 9.8392e-01, time/batch = 0.2290s	
1334/2700 (epoch 24.704), train_loss = 3.19478885, grad/param norm = 1.1139e+00, time/batch = 0.2293s	
1335/2700 (epoch 24.722), train_loss = 3.18511077, grad/param norm = 9.0791e-01, time/batch = 0.2200s	
1336/2700 (epoch 24.741), train_loss = 3.31454547, grad/param norm = 7.8329e-01, time/batch = 0.2131s	
1337/2700 (epoch 24.759), train_loss = 3.26670556, grad/param norm = 1.0341e+00, time/batch = 0.2093s	
1338/2700 (epoch 24.778), train_loss = 3.26380358, grad/param norm = 1.2538e+00, time/batch = 0.2070s	
1339/2700 (epoch 24.796), train_loss = 3.25975831, grad/param norm = 1.2982e+00, time/batch = 0.2212s	
1340/2700 (epoch 24.815), train_loss = 3.20818141, grad/param norm = 1.1745e+00, time/batch = 0.2200s	
1341/2700 (epoch 24.833), train_loss = 3.24525686, grad/param norm = 1.1719e+00, time/batch = 0.2118s	
1342/2700 (epoch 24.852), train_loss = 3.23311646, grad/param norm = 1.2002e+00, time/batch = 0.2515s	
1343/2700 (epoch 24.870), train_loss = 3.22678409, grad/param norm = 1.0298e+00, time/batch = 0.2540s	
1344/2700 (epoch 24.889), train_loss = 3.25867132, grad/param norm = 9.4135e-01, time/batch = 0.2610s	
1345/2700 (epoch 24.907), train_loss = 3.31141126, grad/param norm = 1.1088e+00, time/batch = 0.2617s	
1346/2700 (epoch 24.926), train_loss = 3.26615883, grad/param norm = 1.1899e+00, time/batch = 0.2592s	
1347/2700 (epoch 24.944), train_loss = 3.27462636, grad/param norm = 9.9661e-01, time/batch = 0.2553s	
1348/2700 (epoch 24.963), train_loss = 3.34885122, grad/param norm = 9.1990e-01, time/batch = 0.2591s	
1349/2700 (epoch 24.981), train_loss = 3.40889699, grad/param norm = 9.6918e-01, time/batch = 0.2525s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1350/2700 (epoch 25.000), train_loss = 3.31152066, grad/param norm = 9.5271e-01, time/batch = 0.2493s	
1351/2700 (epoch 25.019), train_loss = 3.25052519, grad/param norm = 1.0432e+00, time/batch = 0.2413s	
1352/2700 (epoch 25.037), train_loss = 3.26641483, grad/param norm = 9.5570e-01, time/batch = 0.2302s	
1353/2700 (epoch 25.056), train_loss = 3.26328883, grad/param norm = 6.8211e-01, time/batch = 0.2226s	
1354/2700 (epoch 25.074), train_loss = 3.29555413, grad/param norm = 8.2342e-01, time/batch = 0.2196s	
1355/2700 (epoch 25.093), train_loss = 3.30356054, grad/param norm = 9.6770e-01, time/batch = 0.2174s	
1356/2700 (epoch 25.111), train_loss = 3.27394097, grad/param norm = 8.9752e-01, time/batch = 0.2275s	
1357/2700 (epoch 25.130), train_loss = 3.29107878, grad/param norm = 7.9510e-01, time/batch = 0.2265s	
1358/2700 (epoch 25.148), train_loss = 3.25112360, grad/param norm = 9.5289e-01, time/batch = 0.2414s	
1359/2700 (epoch 25.167), train_loss = 3.26731298, grad/param norm = 1.1657e+00, time/batch = 0.2391s	
1360/2700 (epoch 25.185), train_loss = 3.24867644, grad/param norm = 8.7595e-01, time/batch = 0.2549s	
1361/2700 (epoch 25.204), train_loss = 3.18118660, grad/param norm = 9.6560e-01, time/batch = 0.2389s	
1362/2700 (epoch 25.222), train_loss = 3.16104634, grad/param norm = 1.2361e+00, time/batch = 0.2325s	
1363/2700 (epoch 25.241), train_loss = 3.18159107, grad/param norm = 1.2355e+00, time/batch = 0.2574s	
1364/2700 (epoch 25.259), train_loss = 3.21711585, grad/param norm = 1.3958e+00, time/batch = 0.2560s	
1365/2700 (epoch 25.278), train_loss = 3.29095081, grad/param norm = 1.3067e+00, time/batch = 0.2521s	
1366/2700 (epoch 25.296), train_loss = 3.29373125, grad/param norm = 1.3408e+00, time/batch = 0.2470s	
1367/2700 (epoch 25.315), train_loss = 3.26925691, grad/param norm = 1.2321e+00, time/batch = 0.2465s	
1368/2700 (epoch 25.333), train_loss = 3.34679711, grad/param norm = 1.0607e+00, time/batch = 0.2431s	
1369/2700 (epoch 25.352), train_loss = 3.35340459, grad/param norm = 1.0157e+00, time/batch = 0.2259s	
1370/2700 (epoch 25.370), train_loss = 3.29585465, grad/param norm = 8.8556e-01, time/batch = 0.2406s	
1371/2700 (epoch 25.389), train_loss = 3.25734902, grad/param norm = 6.9150e-01, time/batch = 0.2409s	
1372/2700 (epoch 25.407), train_loss = 3.28013840, grad/param norm = 6.3644e-01, time/batch = 0.2316s	
1373/2700 (epoch 25.426), train_loss = 3.28357825, grad/param norm = 6.8780e-01, time/batch = 0.2176s	
1374/2700 (epoch 25.444), train_loss = 3.20922727, grad/param norm = 6.3418e-01, time/batch = 0.2095s	
1375/2700 (epoch 25.463), train_loss = 3.25369074, grad/param norm = 7.4225e-01, time/batch = 0.2018s	
1376/2700 (epoch 25.481), train_loss = 3.32900863, grad/param norm = 6.7123e-01, time/batch = 0.1867s	
1377/2700 (epoch 25.500), train_loss = 3.37669420, grad/param norm = 9.9324e-01, time/batch = 0.2315s	
1378/2700 (epoch 25.519), train_loss = 3.33282561, grad/param norm = 1.1138e+00, time/batch = 0.2387s	
1379/2700 (epoch 25.537), train_loss = 3.33761267, grad/param norm = 1.1737e+00, time/batch = 0.2226s	
1380/2700 (epoch 25.556), train_loss = 3.27339866, grad/param norm = 9.6037e-01, time/batch = 0.2259s	
1381/2700 (epoch 25.574), train_loss = 3.23437337, grad/param norm = 8.6464e-01, time/batch = 0.2471s	
1382/2700 (epoch 25.593), train_loss = 3.24038168, grad/param norm = 1.1157e+00, time/batch = 0.2512s	
1383/2700 (epoch 25.611), train_loss = 3.18017743, grad/param norm = 9.4911e-01, time/batch = 0.2455s	
1384/2700 (epoch 25.630), train_loss = 3.22113934, grad/param norm = 1.0428e+00, time/batch = 0.2588s	
1385/2700 (epoch 25.648), train_loss = 3.29527379, grad/param norm = 1.1240e+00, time/batch = 0.2556s	
1386/2700 (epoch 25.667), train_loss = 3.22736129, grad/param norm = 1.0895e+00, time/batch = 0.2575s	
1387/2700 (epoch 25.685), train_loss = 3.21994055, grad/param norm = 9.4642e-01, time/batch = 0.2572s	
1388/2700 (epoch 25.704), train_loss = 3.19364232, grad/param norm = 1.0824e+00, time/batch = 0.2536s	
1389/2700 (epoch 25.722), train_loss = 3.18409204, grad/param norm = 8.7842e-01, time/batch = 0.2598s	
1390/2700 (epoch 25.741), train_loss = 3.31384035, grad/param norm = 7.6573e-01, time/batch = 0.2509s	
1391/2700 (epoch 25.759), train_loss = 3.26594997, grad/param norm = 1.0187e+00, time/batch = 0.2548s	
1392/2700 (epoch 25.778), train_loss = 3.26272379, grad/param norm = 1.2303e+00, time/batch = 0.2500s	
1393/2700 (epoch 25.796), train_loss = 3.25845256, grad/param norm = 1.2783e+00, time/batch = 0.2349s	
1394/2700 (epoch 25.815), train_loss = 3.20729841, grad/param norm = 1.1571e+00, time/batch = 0.2204s	
1395/2700 (epoch 25.833), train_loss = 3.24436446, grad/param norm = 1.1576e+00, time/batch = 0.1824s	
1396/2700 (epoch 25.852), train_loss = 3.23223203, grad/param norm = 1.1845e+00, time/batch = 0.2067s	
1397/2700 (epoch 25.870), train_loss = 3.22561592, grad/param norm = 1.0075e+00, time/batch = 0.2097s	
1398/2700 (epoch 25.889), train_loss = 3.25808142, grad/param norm = 9.2345e-01, time/batch = 0.2049s	
1399/2700 (epoch 25.907), train_loss = 3.31095059, grad/param norm = 1.0921e+00, time/batch = 0.2269s	
1400/2700 (epoch 25.926), train_loss = 3.26500112, grad/param norm = 1.1586e+00, time/batch = 0.2292s	
1401/2700 (epoch 25.944), train_loss = 3.27337078, grad/param norm = 9.6905e-01, time/batch = 0.2177s	
1402/2700 (epoch 25.963), train_loss = 3.34813620, grad/param norm = 8.9910e-01, time/batch = 0.2267s	
1403/2700 (epoch 25.981), train_loss = 3.40836260, grad/param norm = 9.5338e-01, time/batch = 0.2438s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1404/2700 (epoch 26.000), train_loss = 3.31064987, grad/param norm = 9.3745e-01, time/batch = 0.2352s	
1405/2700 (epoch 26.019), train_loss = 3.24982684, grad/param norm = 1.0258e+00, time/batch = 0.2372s	
1406/2700 (epoch 26.037), train_loss = 3.26557645, grad/param norm = 9.3429e-01, time/batch = 0.2402s	
1407/2700 (epoch 26.056), train_loss = 3.26287177, grad/param norm = 6.7495e-01, time/batch = 0.2444s	
1408/2700 (epoch 26.074), train_loss = 3.29533677, grad/param norm = 8.3334e-01, time/batch = 0.2411s	
1409/2700 (epoch 26.093), train_loss = 3.30304862, grad/param norm = 9.6941e-01, time/batch = 0.2449s	
1410/2700 (epoch 26.111), train_loss = 3.27323212, grad/param norm = 8.8822e-01, time/batch = 0.2376s	
1411/2700 (epoch 26.130), train_loss = 3.29018796, grad/param norm = 7.8109e-01, time/batch = 0.2611s	
1412/2700 (epoch 26.148), train_loss = 3.25044853, grad/param norm = 9.2942e-01, time/batch = 0.2582s	
1413/2700 (epoch 26.167), train_loss = 3.26612493, grad/param norm = 1.1432e+00, time/batch = 0.2574s	
1414/2700 (epoch 26.185), train_loss = 3.24779493, grad/param norm = 8.5103e-01, time/batch = 0.2465s	
1415/2700 (epoch 26.204), train_loss = 3.18050600, grad/param norm = 9.3685e-01, time/batch = 0.2281s	
1416/2700 (epoch 26.222), train_loss = 3.16014323, grad/param norm = 1.2010e+00, time/batch = 0.2142s	
1417/2700 (epoch 26.241), train_loss = 3.18006273, grad/param norm = 1.1724e+00, time/batch = 0.2093s	
1418/2700 (epoch 26.259), train_loss = 3.21529905, grad/param norm = 1.3140e+00, time/batch = 0.2336s	
1419/2700 (epoch 26.278), train_loss = 3.28934703, grad/param norm = 1.2512e+00, time/batch = 0.2419s	
1420/2700 (epoch 26.296), train_loss = 3.29283827, grad/param norm = 1.3180e+00, time/batch = 0.2465s	
1421/2700 (epoch 26.315), train_loss = 3.26854031, grad/param norm = 1.2195e+00, time/batch = 0.2197s	
1422/2700 (epoch 26.333), train_loss = 3.34612540, grad/param norm = 1.0518e+00, time/batch = 0.2219s	
1423/2700 (epoch 26.352), train_loss = 3.35259889, grad/param norm = 1.0053e+00, time/batch = 0.2272s	
1424/2700 (epoch 26.370), train_loss = 3.29495885, grad/param norm = 8.7474e-01, time/batch = 0.2209s	
1425/2700 (epoch 26.389), train_loss = 3.25683354, grad/param norm = 6.7739e-01, time/batch = 0.2202s	
1426/2700 (epoch 26.407), train_loss = 3.27960162, grad/param norm = 6.2553e-01, time/batch = 0.2388s	
1427/2700 (epoch 26.426), train_loss = 3.28301191, grad/param norm = 6.7798e-01, time/batch = 0.2222s	
1428/2700 (epoch 26.444), train_loss = 3.20890341, grad/param norm = 6.1909e-01, time/batch = 0.2289s	
1429/2700 (epoch 26.463), train_loss = 3.25314388, grad/param norm = 7.2794e-01, time/batch = 0.2265s	
1430/2700 (epoch 26.481), train_loss = 3.32861382, grad/param norm = 6.6532e-01, time/batch = 0.2236s	
1431/2700 (epoch 26.500), train_loss = 3.37649563, grad/param norm = 9.9521e-01, time/batch = 0.2582s	
1432/2700 (epoch 26.519), train_loss = 3.33242171, grad/param norm = 1.1046e+00, time/batch = 0.2579s	
1433/2700 (epoch 26.537), train_loss = 3.33675564, grad/param norm = 1.1540e+00, time/batch = 0.2519s	
1434/2700 (epoch 26.556), train_loss = 3.27237254, grad/param norm = 9.3823e-01, time/batch = 0.2573s	
1435/2700 (epoch 26.574), train_loss = 3.23413569, grad/param norm = 8.4761e-01, time/batch = 0.2595s	
1436/2700 (epoch 26.593), train_loss = 3.23952840, grad/param norm = 1.0892e+00, time/batch = 0.2196s	
1437/2700 (epoch 26.611), train_loss = 3.17906741, grad/param norm = 9.0727e-01, time/batch = 0.2204s	
1438/2700 (epoch 26.630), train_loss = 3.22003133, grad/param norm = 9.9891e-01, time/batch = 0.2165s	
1439/2700 (epoch 26.648), train_loss = 3.29388655, grad/param norm = 1.0786e+00, time/batch = 0.2214s	
1440/2700 (epoch 26.667), train_loss = 3.22588589, grad/param norm = 1.0398e+00, time/batch = 0.2249s	
1441/2700 (epoch 26.685), train_loss = 3.21889089, grad/param norm = 9.0956e-01, time/batch = 0.2322s	
1442/2700 (epoch 26.704), train_loss = 3.19255961, grad/param norm = 1.0513e+00, time/batch = 0.2375s	
1443/2700 (epoch 26.722), train_loss = 3.18312868, grad/param norm = 8.4889e-01, time/batch = 0.2351s	
1444/2700 (epoch 26.741), train_loss = 3.31317585, grad/param norm = 7.4849e-01, time/batch = 0.2486s	
1445/2700 (epoch 26.759), train_loss = 3.26522078, grad/param norm = 1.0032e+00, time/batch = 0.2563s	
1446/2700 (epoch 26.778), train_loss = 3.26168650, grad/param norm = 1.2070e+00, time/batch = 0.2371s	
1447/2700 (epoch 26.796), train_loss = 3.25722162, grad/param norm = 1.2587e+00, time/batch = 0.2578s	
1448/2700 (epoch 26.815), train_loss = 3.20646171, grad/param norm = 1.1403e+00, time/batch = 0.2579s	
1449/2700 (epoch 26.833), train_loss = 3.24352967, grad/param norm = 1.1448e+00, time/batch = 0.2561s	
1450/2700 (epoch 26.852), train_loss = 3.23140875, grad/param norm = 1.1704e+00, time/batch = 0.2470s	
1451/2700 (epoch 26.870), train_loss = 3.22451601, grad/param norm = 9.8645e-01, time/batch = 0.2359s	
1452/2700 (epoch 26.889), train_loss = 3.25754567, grad/param norm = 9.0699e-01, time/batch = 0.2254s	
1453/2700 (epoch 26.907), train_loss = 3.31051367, grad/param norm = 1.0763e+00, time/batch = 0.2344s	
1454/2700 (epoch 26.926), train_loss = 3.26388285, grad/param norm = 1.1280e+00, time/batch = 0.2415s	
1455/2700 (epoch 26.944), train_loss = 3.27218723, grad/param norm = 9.4245e-01, time/batch = 0.2433s	
1456/2700 (epoch 26.963), train_loss = 3.34745523, grad/param norm = 8.7882e-01, time/batch = 0.2304s	
1457/2700 (epoch 26.981), train_loss = 3.40784496, grad/param norm = 9.3762e-01, time/batch = 0.1954s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1458/2700 (epoch 27.000), train_loss = 3.30980570, grad/param norm = 9.2271e-01, time/batch = 0.2461s	
1459/2700 (epoch 27.019), train_loss = 3.24914305, grad/param norm = 1.0092e+00, time/batch = 0.2481s	
1460/2700 (epoch 27.037), train_loss = 3.26478653, grad/param norm = 9.1416e-01, time/batch = 0.2513s	
1461/2700 (epoch 27.056), train_loss = 3.26249405, grad/param norm = 6.6925e-01, time/batch = 0.2419s	
1462/2700 (epoch 27.074), train_loss = 3.29512440, grad/param norm = 8.4296e-01, time/batch = 0.2316s	
1463/2700 (epoch 27.093), train_loss = 3.30254138, grad/param norm = 9.7007e-01, time/batch = 0.2475s	
1464/2700 (epoch 27.111), train_loss = 3.27254274, grad/param norm = 8.7759e-01, time/batch = 0.2448s	
1465/2700 (epoch 27.130), train_loss = 3.28932035, grad/param norm = 7.6563e-01, time/batch = 0.2316s	
1466/2700 (epoch 27.148), train_loss = 3.24979545, grad/param norm = 9.0505e-01, time/batch = 0.2427s	
1467/2700 (epoch 27.167), train_loss = 3.26495958, grad/param norm = 1.1186e+00, time/batch = 0.2390s	
1468/2700 (epoch 27.185), train_loss = 3.24692166, grad/param norm = 8.2313e-01, time/batch = 0.2538s	
1469/2700 (epoch 27.204), train_loss = 3.17982522, grad/param norm = 9.0468e-01, time/batch = 0.2603s	
1470/2700 (epoch 27.222), train_loss = 3.15923867, grad/param norm = 1.1650e+00, time/batch = 0.2505s	
1471/2700 (epoch 27.241), train_loss = 3.17862648, grad/param norm = 1.1092e+00, time/batch = 0.2557s	
1472/2700 (epoch 27.259), train_loss = 3.21362890, grad/param norm = 1.2352e+00, time/batch = 0.2584s	
1473/2700 (epoch 27.278), train_loss = 3.28789687, grad/param norm = 1.1992e+00, time/batch = 0.2567s	
1474/2700 (epoch 27.296), train_loss = 3.29200088, grad/param norm = 1.2967e+00, time/batch = 0.2562s	
1475/2700 (epoch 27.315), train_loss = 3.26787678, grad/param norm = 1.2086e+00, time/batch = 0.2458s	
1476/2700 (epoch 27.333), train_loss = 3.34551569, grad/param norm = 1.0450e+00, time/batch = 0.2562s	
1477/2700 (epoch 27.352), train_loss = 3.35187442, grad/param norm = 9.9725e-01, time/batch = 0.2518s	
1478/2700 (epoch 27.370), train_loss = 3.29413489, grad/param norm = 8.6528e-01, time/batch = 0.2252s	
1479/2700 (epoch 27.389), train_loss = 3.25635614, grad/param norm = 6.6428e-01, time/batch = 0.2111s	
1480/2700 (epoch 27.407), train_loss = 3.27909696, grad/param norm = 6.1543e-01, time/batch = 0.2109s	
1481/2700 (epoch 27.426), train_loss = 3.28247293, grad/param norm = 6.6880e-01, time/batch = 0.2086s	
1482/2700 (epoch 27.444), train_loss = 3.20860679, grad/param norm = 6.0468e-01, time/batch = 0.2043s	
1483/2700 (epoch 27.463), train_loss = 3.25263021, grad/param norm = 7.1390e-01, time/batch = 0.2139s	
1484/2700 (epoch 27.481), train_loss = 3.32825401, grad/param norm = 6.5989e-01, time/batch = 0.2259s	
1485/2700 (epoch 27.500), train_loss = 3.37630249, grad/param norm = 9.9667e-01, time/batch = 0.2241s	
1486/2700 (epoch 27.519), train_loss = 3.33198618, grad/param norm = 1.0935e+00, time/batch = 0.2460s	
1487/2700 (epoch 27.537), train_loss = 3.33591074, grad/param norm = 1.1336e+00, time/batch = 0.2420s	
1488/2700 (epoch 27.556), train_loss = 3.27142472, grad/param norm = 9.1739e-01, time/batch = 0.2271s	
1489/2700 (epoch 27.574), train_loss = 3.23393756, grad/param norm = 8.3219e-01, time/batch = 0.2327s	
1490/2700 (epoch 27.593), train_loss = 3.23870319, grad/param norm = 1.0635e+00, time/batch = 0.2286s	
1491/2700 (epoch 27.611), train_loss = 3.17802720, grad/param norm = 8.6657e-01, time/batch = 0.2595s	
1492/2700 (epoch 27.630), train_loss = 3.21901534, grad/param norm = 9.5732e-01, time/batch = 0.2581s	
1493/2700 (epoch 27.648), train_loss = 3.29259838, grad/param norm = 1.0355e+00, time/batch = 0.2592s	
1494/2700 (epoch 27.667), train_loss = 3.22451797, grad/param norm = 9.9182e-01, time/batch = 0.2530s	
1495/2700 (epoch 27.685), train_loss = 3.21791487, grad/param norm = 8.7366e-01, time/batch = 0.2608s	
1496/2700 (epoch 27.704), train_loss = 3.19153723, grad/param norm = 1.0207e+00, time/batch = 0.2585s	
1497/2700 (epoch 27.722), train_loss = 3.18221304, grad/param norm = 8.1902e-01, time/batch = 0.2514s	
1498/2700 (epoch 27.741), train_loss = 3.31254321, grad/param norm = 7.3125e-01, time/batch = 0.2441s	
1499/2700 (epoch 27.759), train_loss = 3.26449987, grad/param norm = 9.8713e-01, time/batch = 0.2256s	
1500/2700 (epoch 27.778), train_loss = 3.26066611, grad/param norm = 1.1830e+00, time/batch = 0.1928s	
1501/2700 (epoch 27.796), train_loss = 3.25603944, grad/param norm = 1.2384e+00, time/batch = 0.2450s	
1502/2700 (epoch 27.815), train_loss = 3.20566195, grad/param norm = 1.1239e+00, time/batch = 0.2337s	
1503/2700 (epoch 27.833), train_loss = 3.24275360, grad/param norm = 1.1337e+00, time/batch = 0.2383s	
1504/2700 (epoch 27.852), train_loss = 3.23065173, grad/param norm = 1.1582e+00, time/batch = 0.2152s	
1505/2700 (epoch 27.870), train_loss = 3.22349040, grad/param norm = 9.6716e-01, time/batch = 0.2227s	
1506/2700 (epoch 27.889), train_loss = 3.25706458, grad/param norm = 8.9237e-01, time/batch = 0.2243s	
1507/2700 (epoch 27.907), train_loss = 3.31009969, grad/param norm = 1.0616e+00, time/batch = 0.2304s	
1508/2700 (epoch 27.926), train_loss = 3.26281063, grad/param norm = 1.0985e+00, time/batch = 0.2353s	
1509/2700 (epoch 27.944), train_loss = 3.27108152, grad/param norm = 9.1709e-01, time/batch = 0.2408s	
1510/2700 (epoch 27.963), train_loss = 3.34681125, grad/param norm = 8.5924e-01, time/batch = 0.2500s	
1511/2700 (epoch 27.981), train_loss = 3.40734180, grad/param norm = 9.2186e-01, time/batch = 0.2376s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1512/2700 (epoch 28.000), train_loss = 3.30898483, grad/param norm = 9.0841e-01, time/batch = 0.2339s	
1513/2700 (epoch 28.019), train_loss = 3.24847479, grad/param norm = 9.9363e-01, time/batch = 0.2317s	
1514/2700 (epoch 28.037), train_loss = 3.26404243, grad/param norm = 8.9527e-01, time/batch = 0.2236s	
1515/2700 (epoch 28.056), train_loss = 3.26215016, grad/param norm = 6.6466e-01, time/batch = 0.2536s	
1516/2700 (epoch 28.074), train_loss = 3.29491070, grad/param norm = 8.5170e-01, time/batch = 0.2526s	
1517/2700 (epoch 28.093), train_loss = 3.30203053, grad/param norm = 9.6923e-01, time/batch = 0.2462s	
1518/2700 (epoch 28.111), train_loss = 3.27186957, grad/param norm = 8.6537e-01, time/batch = 0.2448s	
1519/2700 (epoch 28.130), train_loss = 3.28847831, grad/param norm = 7.4889e-01, time/batch = 0.2333s	
1520/2700 (epoch 28.148), train_loss = 3.24917666, grad/param norm = 8.8047e-01, time/batch = 0.2249s	
1521/2700 (epoch 28.167), train_loss = 3.26383316, grad/param norm = 1.0927e+00, time/batch = 0.2537s	
1522/2700 (epoch 28.185), train_loss = 3.24607189, grad/param norm = 7.9360e-01, time/batch = 0.2473s	
1523/2700 (epoch 28.204), train_loss = 3.17916635, grad/param norm = 8.7107e-01, time/batch = 0.2361s	
1524/2700 (epoch 28.222), train_loss = 3.15835638, grad/param norm = 1.1297e+00, time/batch = 0.2431s	
1525/2700 (epoch 28.241), train_loss = 3.17729883, grad/param norm = 1.0476e+00, time/batch = 0.2413s	
1526/2700 (epoch 28.259), train_loss = 3.21209019, grad/param norm = 1.1587e+00, time/batch = 0.2405s	
1527/2700 (epoch 28.278), train_loss = 3.28655530, grad/param norm = 1.1490e+00, time/batch = 0.2363s	
1528/2700 (epoch 28.296), train_loss = 3.29119004, grad/param norm = 1.2752e+00, time/batch = 0.2286s	
1529/2700 (epoch 28.315), train_loss = 3.26724387, grad/param norm = 1.1984e+00, time/batch = 0.2162s	
1530/2700 (epoch 28.333), train_loss = 3.34496045, grad/param norm = 1.0401e+00, time/batch = 0.2187s	
1531/2700 (epoch 28.352), train_loss = 3.35122036, grad/param norm = 9.9126e-01, time/batch = 0.2499s	
1532/2700 (epoch 28.370), train_loss = 3.29337244, grad/param norm = 8.5697e-01, time/batch = 0.2561s	
1533/2700 (epoch 28.389), train_loss = 3.25591260, grad/param norm = 6.5211e-01, time/batch = 0.2567s	
1534/2700 (epoch 28.407), train_loss = 3.27862319, grad/param norm = 6.0608e-01, time/batch = 0.2576s	
1535/2700 (epoch 28.426), train_loss = 3.28195921, grad/param norm = 6.6023e-01, time/batch = 0.2562s	
1536/2700 (epoch 28.444), train_loss = 3.20833908, grad/param norm = 5.9120e-01, time/batch = 0.2573s	
1537/2700 (epoch 28.463), train_loss = 3.25215037, grad/param norm = 7.0045e-01, time/batch = 0.2598s	
1538/2700 (epoch 28.481), train_loss = 3.32792896, grad/param norm = 6.5502e-01, time/batch = 0.2482s	
1539/2700 (epoch 28.500), train_loss = 3.37610398, grad/param norm = 9.9753e-01, time/batch = 0.2541s	
1540/2700 (epoch 28.519), train_loss = 3.33151177, grad/param norm = 1.0805e+00, time/batch = 0.2446s	
1541/2700 (epoch 28.537), train_loss = 3.33508908, grad/param norm = 1.1128e+00, time/batch = 0.2383s	
1542/2700 (epoch 28.556), train_loss = 3.27055331, grad/param norm = 8.9807e-01, time/batch = 0.2324s	
1543/2700 (epoch 28.574), train_loss = 3.23376779, grad/param norm = 8.1816e-01, time/batch = 0.2322s	
1544/2700 (epoch 28.593), train_loss = 3.23790735, grad/param norm = 1.0387e+00, time/batch = 0.2408s	
1545/2700 (epoch 28.611), train_loss = 3.17706795, grad/param norm = 8.2736e-01, time/batch = 0.2388s	
1546/2700 (epoch 28.630), train_loss = 3.21809200, grad/param norm = 9.1828e-01, time/batch = 0.2292s	
1547/2700 (epoch 28.648), train_loss = 3.29140593, grad/param norm = 9.9499e-01, time/batch = 0.2282s	
1548/2700 (epoch 28.667), train_loss = 3.22325936, grad/param norm = 9.4591e-01, time/batch = 0.2206s	
1549/2700 (epoch 28.685), train_loss = 3.21701272, grad/param norm = 8.3886e-01, time/batch = 0.2309s	
1550/2700 (epoch 28.704), train_loss = 3.19057019, grad/param norm = 9.9044e-01, time/batch = 0.2375s	
1551/2700 (epoch 28.722), train_loss = 3.18133668, grad/param norm = 7.8847e-01, time/batch = 0.2074s	
1552/2700 (epoch 28.741), train_loss = 3.31193336, grad/param norm = 7.1373e-01, time/batch = 0.2508s	
1553/2700 (epoch 28.759), train_loss = 3.26377153, grad/param norm = 9.6982e-01, time/batch = 0.2567s	
1554/2700 (epoch 28.778), train_loss = 3.25964297, grad/param norm = 1.1570e+00, time/batch = 0.2578s	
1555/2700 (epoch 28.796), train_loss = 3.25487776, grad/param norm = 1.2160e+00, time/batch = 0.2592s	
1556/2700 (epoch 28.815), train_loss = 3.20488643, grad/param norm = 1.1069e+00, time/batch = 0.2592s	
1557/2700 (epoch 28.833), train_loss = 3.24203175, grad/param norm = 1.1240e+00, time/batch = 0.2535s	
1558/2700 (epoch 28.852), train_loss = 3.22996309, grad/param norm = 1.1482e+00, time/batch = 0.2586s	
1559/2700 (epoch 28.870), train_loss = 3.22254780, grad/param norm = 9.5053e-01, time/batch = 0.2588s	
1560/2700 (epoch 28.889), train_loss = 3.25664861, grad/param norm = 8.8043e-01, time/batch = 0.2563s	
1561/2700 (epoch 28.907), train_loss = 3.30971108, grad/param norm = 1.0483e+00, time/batch = 0.2354s	
1562/2700 (epoch 28.926), train_loss = 3.26179066, grad/param norm = 1.0705e+00, time/batch = 0.2288s	
1563/2700 (epoch 28.944), train_loss = 3.27005536, grad/param norm = 8.9323e-01, time/batch = 0.2386s	
1564/2700 (epoch 28.963), train_loss = 3.34620552, grad/param norm = 8.4047e-01, time/batch = 0.2307s	
1565/2700 (epoch 28.981), train_loss = 3.40685086, grad/param norm = 9.0608e-01, time/batch = 0.2227s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
1566/2700 (epoch 29.000), train_loss = 3.30818513, grad/param norm = 8.9449e-01, time/batch = 0.2284s	
1567/2700 (epoch 29.019), train_loss = 3.24782289, grad/param norm = 9.7892e-01, time/batch = 0.2230s	
1568/2700 (epoch 29.037), train_loss = 3.26334154, grad/param norm = 8.7757e-01, time/batch = 0.2333s	
1569/2700 (epoch 29.056), train_loss = 3.26183644, grad/param norm = 6.6075e-01, time/batch = 0.2412s	
1570/2700 (epoch 29.074), train_loss = 3.29468552, grad/param norm = 8.5883e-01, time/batch = 0.2492s	
1571/2700 (epoch 29.093), train_loss = 3.30150814, grad/param norm = 9.6635e-01, time/batch = 0.2271s	
1572/2700 (epoch 29.111), train_loss = 3.27121169, grad/param norm = 8.5133e-01, time/batch = 0.2139s	
1573/2700 (epoch 29.130), train_loss = 3.28766476, grad/param norm = 7.3109e-01, time/batch = 0.2561s	
1574/2700 (epoch 29.148), train_loss = 3.24860126, grad/param norm = 8.5632e-01, time/batch = 0.2563s	
1575/2700 (epoch 29.167), train_loss = 3.26275710, grad/param norm = 1.0664e+00, time/batch = 0.2500s	
1576/2700 (epoch 29.185), train_loss = 3.24525607, grad/param norm = 7.6355e-01, time/batch = 0.2410s	
1577/2700 (epoch 29.204), train_loss = 3.17854535, grad/param norm = 8.3744e-01, time/batch = 0.2417s	
1578/2700 (epoch 29.222), train_loss = 3.15750687, grad/param norm = 1.0957e+00, time/batch = 0.2317s	
1579/2700 (epoch 29.241), train_loss = 3.17608693, grad/param norm = 9.8863e-01, time/batch = 0.2275s	
1580/2700 (epoch 29.259), train_loss = 3.21068114, grad/param norm = 1.0848e+00, time/batch = 0.2249s	
1581/2700 (epoch 29.278), train_loss = 3.28530599, grad/param norm = 1.0999e+00, time/batch = 0.2503s	
1582/2700 (epoch 29.296), train_loss = 3.29038169, grad/param norm = 1.2523e+00, time/batch = 0.2393s	
1583/2700 (epoch 29.315), train_loss = 3.26662006, grad/param norm = 1.1879e+00, time/batch = 0.2392s	
1584/2700 (epoch 29.333), train_loss = 3.34444951, grad/param norm = 1.0364e+00, time/batch = 0.2411s	
1585/2700 (epoch 29.352), train_loss = 3.35062675, grad/param norm = 9.8701e-01, time/batch = 0.2316s	
1586/2700 (epoch 29.370), train_loss = 3.29266186, grad/param norm = 8.4954e-01, time/batch = 0.2257s	
1587/2700 (epoch 29.389), train_loss = 3.25550211, grad/param norm = 6.4081e-01, time/batch = 0.2139s	
1588/2700 (epoch 29.407), train_loss = 3.27817617, grad/param norm = 5.9745e-01, time/batch = 0.2317s	
1589/2700 (epoch 29.426), train_loss = 3.28147044, grad/param norm = 6.5228e-01, time/batch = 0.2443s	
1590/2700 (epoch 29.444), train_loss = 3.20810066, grad/param norm = 5.7880e-01, time/batch = 0.2489s	
1591/2700 (epoch 29.463), train_loss = 3.25170661, grad/param norm = 6.8771e-01, time/batch = 0.2293s	
1592/2700 (epoch 29.481), train_loss = 3.32763369, grad/param norm = 6.5063e-01, time/batch = 0.2406s	
1593/2700 (epoch 29.500), train_loss = 3.37588725, grad/param norm = 9.9754e-01, time/batch = 0.2406s	
1594/2700 (epoch 29.519), train_loss = 3.33099224, grad/param norm = 1.0657e+00, time/batch = 0.2604s	
1595/2700 (epoch 29.537), train_loss = 3.33429788, grad/param norm = 1.0920e+00, time/batch = 0.2571s	
1596/2700 (epoch 29.556), train_loss = 3.26974807, grad/param norm = 8.8002e-01, time/batch = 0.2585s	
1597/2700 (epoch 29.574), train_loss = 3.23361055, grad/param norm = 8.0502e-01, time/batch = 0.2577s	
1598/2700 (epoch 29.593), train_loss = 3.23714507, grad/param norm = 1.0149e+00, time/batch = 0.2613s	
1599/2700 (epoch 29.611), train_loss = 3.17619622, grad/param norm = 7.9009e-01, time/batch = 0.2577s	
1600/2700 (epoch 29.630), train_loss = 3.21726532, grad/param norm = 8.8214e-01, time/batch = 0.2575s	
1601/2700 (epoch 29.648), train_loss = 3.29030607, grad/param norm = 9.5717e-01, time/batch = 0.2166s	
1602/2700 (epoch 29.667), train_loss = 3.22211165, grad/param norm = 9.0254e-01, time/batch = 0.2435s	
1603/2700 (epoch 29.685), train_loss = 3.21618792, grad/param norm = 8.0572e-01, time/batch = 0.2494s	
1604/2700 (epoch 29.704), train_loss = 3.18966542, grad/param norm = 9.6113e-01, time/batch = 0.2486s	
1605/2700 (epoch 29.722), train_loss = 3.18050167, grad/param norm = 7.5753e-01, time/batch = 0.2381s	
1606/2700 (epoch 29.741), train_loss = 3.31134638, grad/param norm = 6.9618e-01, time/batch = 0.2369s	
1607/2700 (epoch 29.759), train_loss = 3.26303245, grad/param norm = 9.5118e-01, time/batch = 0.2252s	
1608/2700 (epoch 29.778), train_loss = 3.25860593, grad/param norm = 1.1282e+00, time/batch = 0.2214s	
1609/2700 (epoch 29.796), train_loss = 3.25371152, grad/param norm = 1.1904e+00, time/batch = 0.2299s	
1610/2700 (epoch 29.815), train_loss = 3.20410993, grad/param norm = 1.0880e+00, time/batch = 0.2386s	
1611/2700 (epoch 29.833), train_loss = 3.24135558, grad/param norm = 1.1154e+00, time/batch = 0.2008s	
1612/2700 (epoch 29.852), train_loss = 3.22934455, grad/param norm = 1.1406e+00, time/batch = 0.2394s	
1613/2700 (epoch 29.870), train_loss = 3.22169073, grad/param norm = 9.3715e-01, time/batch = 0.2486s	
1614/2700 (epoch 29.889), train_loss = 3.25629903, grad/param norm = 8.7162e-01, time/batch = 0.2395s	
1615/2700 (epoch 29.907), train_loss = 3.30934620, grad/param norm = 1.0368e+00, time/batch = 0.2564s	
1616/2700 (epoch 29.926), train_loss = 3.26082838, grad/param norm = 1.0442e+00, time/batch = 0.2561s	
1617/2700 (epoch 29.944), train_loss = 3.26911067, grad/param norm = 8.7108e-01, time/batch = 0.2554s	
1618/2700 (epoch 29.963), train_loss = 3.34563949, grad/param norm = 8.2260e-01, time/batch = 0.2566s	
1619/2700 (epoch 29.981), train_loss = 3.40637302, grad/param norm = 8.9030e-01, time/batch = 0.2578s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
1620/2700 (epoch 30.000), train_loss = 3.30740415, grad/param norm = 8.8087e-01, time/batch = 0.2532s	
1621/2700 (epoch 30.019), train_loss = 3.24718999, grad/param norm = 9.6512e-01, time/batch = 0.2296s	
1622/2700 (epoch 30.037), train_loss = 3.26268137, grad/param norm = 8.6093e-01, time/batch = 0.2376s	
1623/2700 (epoch 30.056), train_loss = 3.26154637, grad/param norm = 6.5714e-01, time/batch = 0.2261s	
1624/2700 (epoch 30.074), train_loss = 3.29444291, grad/param norm = 8.6391e-01, time/batch = 0.2024s	
1625/2700 (epoch 30.093), train_loss = 3.30096810, grad/param norm = 9.6115e-01, time/batch = 0.2402s	
1626/2700 (epoch 30.111), train_loss = 3.27056928, grad/param norm = 8.3552e-01, time/batch = 0.2373s	
1627/2700 (epoch 30.130), train_loss = 3.28688548, grad/param norm = 7.1270e-01, time/batch = 0.2368s	
1628/2700 (epoch 30.148), train_loss = 3.24807555, grad/param norm = 8.3331e-01, time/batch = 0.2254s	
1629/2700 (epoch 30.167), train_loss = 3.26174407, grad/param norm = 1.0405e+00, time/batch = 0.2176s	
1630/2700 (epoch 30.185), train_loss = 3.24448466, grad/param norm = 7.3398e-01, time/batch = 0.2233s	
1631/2700 (epoch 30.204), train_loss = 3.17797143, grad/param norm = 8.0488e-01, time/batch = 0.2107s	
1632/2700 (epoch 30.222), train_loss = 3.15669744, grad/param norm = 1.0635e+00, time/batch = 0.2091s	
1633/2700 (epoch 30.241), train_loss = 3.17498975, grad/param norm = 9.3300e-01, time/batch = 0.2267s	
1634/2700 (epoch 30.259), train_loss = 3.20940019, grad/param norm = 1.0139e+00, time/batch = 0.2301s	
1635/2700 (epoch 30.278), train_loss = 3.28413555, grad/param norm = 1.0514e+00, time/batch = 0.2257s	
1636/2700 (epoch 30.296), train_loss = 3.28955471, grad/param norm = 1.2265e+00, time/batch = 0.2444s	
1637/2700 (epoch 30.315), train_loss = 3.26598150, grad/param norm = 1.1759e+00, time/batch = 0.2471s	
1638/2700 (epoch 30.333), train_loss = 3.34397515, grad/param norm = 1.0336e+00, time/batch = 0.2534s	
1639/2700 (epoch 30.352), train_loss = 3.35008670, grad/param norm = 9.8425e-01, time/batch = 0.2580s	
1640/2700 (epoch 30.370), train_loss = 3.29199684, grad/param norm = 8.4286e-01, time/batch = 0.2532s	
1641/2700 (epoch 30.389), train_loss = 3.25512051, grad/param norm = 6.3037e-01, time/batch = 0.2594s	
1642/2700 (epoch 30.407), train_loss = 3.27775437, grad/param norm = 5.8948e-01, time/batch = 0.2610s	
1643/2700 (epoch 30.426), train_loss = 3.28100530, grad/param norm = 6.4488e-01, time/batch = 0.2521s	
1644/2700 (epoch 30.444), train_loss = 3.20789061, grad/param norm = 5.6746e-01, time/batch = 0.2548s	
1645/2700 (epoch 30.463), train_loss = 3.25129615, grad/param norm = 6.7574e-01, time/batch = 0.2483s	
1646/2700 (epoch 30.481), train_loss = 3.32736559, grad/param norm = 6.4662e-01, time/batch = 0.2264s	
1647/2700 (epoch 30.500), train_loss = 3.37564076, grad/param norm = 9.9652e-01, time/batch = 0.2210s	
1648/2700 (epoch 30.519), train_loss = 3.33043173, grad/param norm = 1.0494e+00, time/batch = 0.2050s	
1649/2700 (epoch 30.537), train_loss = 3.33354473, grad/param norm = 1.0715e+00, time/batch = 0.2041s	
1650/2700 (epoch 30.556), train_loss = 3.26899925, grad/param norm = 8.6306e-01, time/batch = 0.1948s	
1651/2700 (epoch 30.574), train_loss = 3.23345752, grad/param norm = 7.9255e-01, time/batch = 0.2272s	
1652/2700 (epoch 30.593), train_loss = 3.23641960, grad/param norm = 9.9229e-01, time/batch = 0.2233s	
1653/2700 (epoch 30.611), train_loss = 3.17541643, grad/param norm = 7.5517e-01, time/batch = 0.2250s	
1654/2700 (epoch 30.630), train_loss = 3.21653475, grad/param norm = 8.4919e-01, time/batch = 0.2369s	
1655/2700 (epoch 30.648), train_loss = 3.28929234, grad/param norm = 9.2226e-01, time/batch = 0.2435s	
1656/2700 (epoch 30.667), train_loss = 3.22107002, grad/param norm = 8.6202e-01, time/batch = 0.2397s	
1657/2700 (epoch 30.685), train_loss = 3.21544000, grad/param norm = 7.7464e-01, time/batch = 0.2601s	
1658/2700 (epoch 30.704), train_loss = 3.18882546, grad/param norm = 9.3315e-01, time/batch = 0.2578s	
1659/2700 (epoch 30.722), train_loss = 3.17971187, grad/param norm = 7.2656e-01, time/batch = 0.2539s	
1660/2700 (epoch 30.741), train_loss = 3.31078466, grad/param norm = 6.7899e-01, time/batch = 0.2579s	
1661/2700 (epoch 30.759), train_loss = 3.26228328, grad/param norm = 9.3136e-01, time/batch = 0.2611s	
1662/2700 (epoch 30.778), train_loss = 3.25754636, grad/param norm = 1.0960e+00, time/batch = 0.2448s	
1663/2700 (epoch 30.796), train_loss = 3.25251196, grad/param norm = 1.1599e+00, time/batch = 0.2581s	
1664/2700 (epoch 30.815), train_loss = 3.20329963, grad/param norm = 1.0651e+00, time/batch = 0.2573s	
1665/2700 (epoch 30.833), train_loss = 3.24070723, grad/param norm = 1.1069e+00, time/batch = 0.2524s	
1666/2700 (epoch 30.852), train_loss = 3.22879318, grad/param norm = 1.1354e+00, time/batch = 0.2444s	
1667/2700 (epoch 30.870), train_loss = 3.22092867, grad/param norm = 9.2799e-01, time/batch = 0.2289s	
1668/2700 (epoch 30.889), train_loss = 3.25602633, grad/param norm = 8.6690e-01, time/batch = 0.2220s	
1669/2700 (epoch 30.907), train_loss = 3.30900812, grad/param norm = 1.0275e+00, time/batch = 0.2038s	
1670/2700 (epoch 30.926), train_loss = 3.25992838, grad/param norm = 1.0202e+00, time/batch = 0.2247s	
1671/2700 (epoch 30.944), train_loss = 3.26824517, grad/param norm = 8.5077e-01, time/batch = 0.2315s	
1672/2700 (epoch 30.963), train_loss = 3.34511198, grad/param norm = 8.0570e-01, time/batch = 0.2271s	
1673/2700 (epoch 30.981), train_loss = 3.40590924, grad/param norm = 8.7456e-01, time/batch = 0.2144s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
1674/2700 (epoch 31.000), train_loss = 3.30664270, grad/param norm = 8.6751e-01, time/batch = 0.2087s	
1675/2700 (epoch 31.019), train_loss = 3.24657595, grad/param norm = 9.5220e-01, time/batch = 0.2082s	
1676/2700 (epoch 31.037), train_loss = 3.26205562, grad/param norm = 8.4523e-01, time/batch = 0.2105s	
1677/2700 (epoch 31.056), train_loss = 3.26127617, grad/param norm = 6.5344e-01, time/batch = 0.2058s	
1678/2700 (epoch 31.074), train_loss = 3.29417716, grad/param norm = 8.6649e-01, time/batch = 0.2349s	
1679/2700 (epoch 31.093), train_loss = 3.30040800, grad/param norm = 9.5353e-01, time/batch = 0.2243s	
1680/2700 (epoch 31.111), train_loss = 3.26994427, grad/param norm = 8.1824e-01, time/batch = 0.2559s	
1681/2700 (epoch 31.130), train_loss = 3.28614626, grad/param norm = 6.9433e-01, time/batch = 0.2302s	
1682/2700 (epoch 31.148), train_loss = 3.24760576, grad/param norm = 8.1204e-01, time/batch = 0.2390s	
1683/2700 (epoch 31.167), train_loss = 3.26079978, grad/param norm = 1.0157e+00, time/batch = 0.2429s	
1684/2700 (epoch 31.185), train_loss = 3.24376147, grad/param norm = 7.0559e-01, time/batch = 0.2518s	
1685/2700 (epoch 31.204), train_loss = 3.17744915, grad/param norm = 7.7413e-01, time/batch = 0.2596s	
1686/2700 (epoch 31.222), train_loss = 3.15593259, grad/param norm = 1.0334e+00, time/batch = 0.2585s	
1687/2700 (epoch 31.241), train_loss = 3.17400336, grad/param norm = 8.8122e-01, time/batch = 0.2484s	
1688/2700 (epoch 31.259), train_loss = 3.20824556, grad/param norm = 9.4669e-01, time/batch = 0.2196s	
1689/2700 (epoch 31.278), train_loss = 3.28304440, grad/param norm = 1.0036e+00, time/batch = 0.2162s	
1690/2700 (epoch 31.296), train_loss = 3.28869684, grad/param norm = 1.1972e+00, time/batch = 0.2100s	
1691/2700 (epoch 31.315), train_loss = 3.26530900, grad/param norm = 1.1614e+00, time/batch = 0.2572s	
1692/2700 (epoch 31.333), train_loss = 3.34352697, grad/param norm = 1.0312e+00, time/batch = 0.2495s	
1693/2700 (epoch 31.352), train_loss = 3.34959163, grad/param norm = 9.8265e-01, time/batch = 0.2382s	
1694/2700 (epoch 31.370), train_loss = 3.29136917, grad/param norm = 8.3676e-01, time/batch = 0.2314s	
1695/2700 (epoch 31.389), train_loss = 3.25476743, grad/param norm = 6.2073e-01, time/batch = 0.2234s	
1696/2700 (epoch 31.407), train_loss = 3.27735589, grad/param norm = 5.8213e-01, time/batch = 0.2215s	
1697/2700 (epoch 31.426), train_loss = 3.28056003, grad/param norm = 6.3802e-01, time/batch = 0.2290s	
1698/2700 (epoch 31.444), train_loss = 3.20770685, grad/param norm = 5.5718e-01, time/batch = 0.2263s	
1699/2700 (epoch 31.463), train_loss = 3.25091704, grad/param norm = 6.6456e-01, time/batch = 0.2590s	
1700/2700 (epoch 31.481), train_loss = 3.32712034, grad/param norm = 6.4289e-01, time/batch = 0.2474s	
1701/2700 (epoch 31.500), train_loss = 3.37536075, grad/param norm = 9.9437e-01, time/batch = 0.2456s	
1702/2700 (epoch 31.519), train_loss = 3.32983881, grad/param norm = 1.0319e+00, time/batch = 0.2477s	
1703/2700 (epoch 31.537), train_loss = 3.33283411, grad/param norm = 1.0515e+00, time/batch = 0.2422s	
1704/2700 (epoch 31.556), train_loss = 3.26829703, grad/param norm = 8.4687e-01, time/batch = 0.2366s	
1705/2700 (epoch 31.574), train_loss = 3.23330115, grad/param norm = 7.8045e-01, time/batch = 0.2303s	
1706/2700 (epoch 31.593), train_loss = 3.23573236, grad/param norm = 9.7084e-01, time/batch = 0.2305s	
1707/2700 (epoch 31.611), train_loss = 3.17472445, grad/param norm = 7.2278e-01, time/batch = 0.2320s	
1708/2700 (epoch 31.630), train_loss = 3.21589433, grad/param norm = 8.1948e-01, time/batch = 0.2183s	
1709/2700 (epoch 31.648), train_loss = 3.28835476, grad/param norm = 8.9023e-01, time/batch = 0.2186s	
1710/2700 (epoch 31.667), train_loss = 3.22012547, grad/param norm = 8.2443e-01, time/batch = 0.1916s	
1711/2700 (epoch 31.685), train_loss = 3.21476684, grad/param norm = 7.4597e-01, time/batch = 0.2516s	
1712/2700 (epoch 31.704), train_loss = 3.18805480, grad/param norm = 9.0702e-01, time/batch = 0.2406s	
1713/2700 (epoch 31.722), train_loss = 3.17897142, grad/param norm = 6.9619e-01, time/batch = 0.2302s	
1714/2700 (epoch 31.741), train_loss = 3.31025316, grad/param norm = 6.6298e-01, time/batch = 0.2168s	
1715/2700 (epoch 31.759), train_loss = 3.26153729, grad/param norm = 9.1109e-01, time/batch = 0.2090s	
1716/2700 (epoch 31.778), train_loss = 3.25647566, grad/param norm = 1.0607e+00, time/batch = 0.2140s	
1717/2700 (epoch 31.796), train_loss = 3.25127198, grad/param norm = 1.1237e+00, time/batch = 0.2070s	
1718/2700 (epoch 31.815), train_loss = 3.20242460, grad/param norm = 1.0362e+00, time/batch = 0.2251s	
1719/2700 (epoch 31.833), train_loss = 3.24006141, grad/param norm = 1.0965e+00, time/batch = 0.2282s	
1720/2700 (epoch 31.852), train_loss = 3.22829915, grad/param norm = 1.1322e+00, time/batch = 0.2391s	
1721/2700 (epoch 31.870), train_loss = 3.22026586, grad/param norm = 9.2381e-01, time/batch = 0.2593s	
1722/2700 (epoch 31.889), train_loss = 3.25583601, grad/param norm = 8.6694e-01, time/batch = 0.2576s	
1723/2700 (epoch 31.907), train_loss = 3.30869709, grad/param norm = 1.0206e+00, time/batch = 0.2589s	
1724/2700 (epoch 31.926), train_loss = 3.25909209, grad/param norm = 9.9857e-01, time/batch = 0.2581s	
1725/2700 (epoch 31.944), train_loss = 3.26745656, grad/param norm = 8.3235e-01, time/batch = 0.2583s	
1726/2700 (epoch 31.963), train_loss = 3.34462099, grad/param norm = 7.8972e-01, time/batch = 0.2563s	
1727/2700 (epoch 31.981), train_loss = 3.40546083, grad/param norm = 8.5894e-01, time/batch = 0.2493s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
1728/2700 (epoch 32.000), train_loss = 3.30590228, grad/param norm = 8.5439e-01, time/batch = 0.2564s	
1729/2700 (epoch 32.019), train_loss = 3.24598075, grad/param norm = 9.4008e-01, time/batch = 0.2446s	
1730/2700 (epoch 32.037), train_loss = 3.26146226, grad/param norm = 8.3028e-01, time/batch = 0.2426s	
1731/2700 (epoch 32.056), train_loss = 3.26102213, grad/param norm = 6.4944e-01, time/batch = 0.2338s	
1732/2700 (epoch 32.074), train_loss = 3.29388644, grad/param norm = 8.6647e-01, time/batch = 0.2292s	
1733/2700 (epoch 32.093), train_loss = 3.29983265, grad/param norm = 9.4361e-01, time/batch = 0.2252s	
1734/2700 (epoch 32.111), train_loss = 3.26934115, grad/param norm = 7.9984e-01, time/batch = 0.2172s	
1735/2700 (epoch 32.130), train_loss = 3.28544993, grad/param norm = 6.7650e-01, time/batch = 0.2223s	
1736/2700 (epoch 32.148), train_loss = 3.24719072, grad/param norm = 7.9283e-01, time/batch = 0.2067s	
1737/2700 (epoch 32.167), train_loss = 3.25992843, grad/param norm = 9.9238e-01, time/batch = 0.2138s	
1738/2700 (epoch 32.185), train_loss = 3.24309096, grad/param norm = 6.7890e-01, time/batch = 0.2202s	
1739/2700 (epoch 32.204), train_loss = 3.17697985, grad/param norm = 7.4571e-01, time/batch = 0.2199s	
1740/2700 (epoch 32.222), train_loss = 3.15521552, grad/param norm = 1.0054e+00, time/batch = 0.2216s	
1741/2700 (epoch 32.241), train_loss = 3.17312402, grad/param norm = 8.3371e-01, time/batch = 0.2569s	
1742/2700 (epoch 32.259), train_loss = 3.20721863, grad/param norm = 8.8415e-01, time/batch = 0.2601s	
1743/2700 (epoch 32.278), train_loss = 3.28203627, grad/param norm = 9.5703e-01, time/batch = 0.2580s	
1744/2700 (epoch 32.296), train_loss = 3.28779810, grad/param norm = 1.1638e+00, time/batch = 0.2588s	
1745/2700 (epoch 32.315), train_loss = 3.26458383, grad/param norm = 1.1434e+00, time/batch = 0.2594s	
1746/2700 (epoch 32.333), train_loss = 3.34309660, grad/param norm = 1.0284e+00, time/batch = 0.2536s	
1747/2700 (epoch 32.352), train_loss = 3.34913421, grad/param norm = 9.8183e-01, time/batch = 0.2587s	
1748/2700 (epoch 32.370), train_loss = 3.29077640, grad/param norm = 8.3114e-01, time/batch = 0.2532s	
1749/2700 (epoch 32.389), train_loss = 3.25443949, grad/param norm = 6.1189e-01, time/batch = 0.2589s	
1750/2700 (epoch 32.407), train_loss = 3.27697824, grad/param norm = 5.7538e-01, time/batch = 0.2542s	
1751/2700 (epoch 32.426), train_loss = 3.28013528, grad/param norm = 6.3163e-01, time/batch = 0.2240s	
1752/2700 (epoch 32.444), train_loss = 3.20754591, grad/param norm = 5.4788e-01, time/batch = 0.2288s	
1753/2700 (epoch 32.463), train_loss = 3.25056458, grad/param norm = 6.5408e-01, time/batch = 0.2256s	
1754/2700 (epoch 32.481), train_loss = 3.32689431, grad/param norm = 6.3932e-01, time/batch = 0.2193s	
1755/2700 (epoch 32.500), train_loss = 3.37504253, grad/param norm = 9.9103e-01, time/batch = 0.2249s	
1756/2700 (epoch 32.519), train_loss = 3.32922588, grad/param norm = 1.0136e+00, time/batch = 0.1936s	
1757/2700 (epoch 32.537), train_loss = 3.33216756, grad/param norm = 1.0322e+00, time/batch = 0.2158s	
1758/2700 (epoch 32.556), train_loss = 3.26763378, grad/param norm = 8.3130e-01, time/batch = 0.2092s	
1759/2700 (epoch 32.574), train_loss = 3.23314067, grad/param norm = 7.6873e-01, time/batch = 0.2178s	
1760/2700 (epoch 32.593), train_loss = 3.23508400, grad/param norm = 9.5061e-01, time/batch = 0.2321s	
1761/2700 (epoch 32.611), train_loss = 3.17411441, grad/param norm = 6.9294e-01, time/batch = 0.2229s	
1762/2700 (epoch 32.630), train_loss = 3.21533522, grad/param norm = 7.9289e-01, time/batch = 0.2579s	
1763/2700 (epoch 32.648), train_loss = 3.28748325, grad/param norm = 8.6092e-01, time/batch = 0.2590s	
1764/2700 (epoch 32.667), train_loss = 3.21926973, grad/param norm = 7.8969e-01, time/batch = 0.2605s	
1765/2700 (epoch 32.685), train_loss = 3.21416369, grad/param norm = 7.1984e-01, time/batch = 0.2539s	
1766/2700 (epoch 32.704), train_loss = 3.18735231, grad/param norm = 8.8300e-01, time/batch = 0.2550s	
1767/2700 (epoch 32.722), train_loss = 3.17828171, grad/param norm = 6.6694e-01, time/batch = 0.2504s	
1768/2700 (epoch 32.741), train_loss = 3.30976280, grad/param norm = 6.4895e-01, time/batch = 0.2554s	
1769/2700 (epoch 32.759), train_loss = 3.26081029, grad/param norm = 8.9131e-01, time/batch = 0.2621s	
1770/2700 (epoch 32.778), train_loss = 3.25540791, grad/param norm = 1.0227e+00, time/batch = 0.2588s	
1771/2700 (epoch 32.796), train_loss = 3.24998883, grad/param norm = 1.0811e+00, time/batch = 0.2397s	
1772/2700 (epoch 32.815), train_loss = 3.20145282, grad/param norm = 9.9852e-01, time/batch = 0.2312s	
1773/2700 (epoch 32.833), train_loss = 3.23937609, grad/param norm = 1.0814e+00, time/batch = 0.2339s	
1774/2700 (epoch 32.852), train_loss = 3.22783833, grad/param norm = 1.1297e+00, time/batch = 0.2283s	
1775/2700 (epoch 32.870), train_loss = 3.21971342, grad/param norm = 9.2581e-01, time/batch = 0.2082s	
1776/2700 (epoch 32.889), train_loss = 3.25574317, grad/param norm = 8.7311e-01, time/batch = 0.2297s	
1777/2700 (epoch 32.907), train_loss = 3.30841764, grad/param norm = 1.0169e+00, time/batch = 0.2234s	
1778/2700 (epoch 32.926), train_loss = 3.25832661, grad/param norm = 9.7998e-01, time/batch = 0.2380s	
1779/2700 (epoch 32.944), train_loss = 3.26673805, grad/param norm = 8.1586e-01, time/batch = 0.2540s	
1780/2700 (epoch 32.963), train_loss = 3.34416179, grad/param norm = 7.7460e-01, time/batch = 0.2554s	
1781/2700 (epoch 32.981), train_loss = 3.40503028, grad/param norm = 8.4350e-01, time/batch = 0.2380s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
1782/2700 (epoch 33.000), train_loss = 3.30518585, grad/param norm = 8.4153e-01, time/batch = 0.2369s	
1783/2700 (epoch 33.019), train_loss = 3.24540428, grad/param norm = 9.2874e-01, time/batch = 0.2576s	
1784/2700 (epoch 33.037), train_loss = 3.26089495, grad/param norm = 8.1596e-01, time/batch = 0.2564s	
1785/2700 (epoch 33.056), train_loss = 3.26078154, grad/param norm = 6.4492e-01, time/batch = 0.2526s	
1786/2700 (epoch 33.074), train_loss = 3.29356936, grad/param norm = 8.6378e-01, time/batch = 0.2529s	
1787/2700 (epoch 33.093), train_loss = 3.29924232, grad/param norm = 9.3156e-01, time/batch = 0.2560s	
1788/2700 (epoch 33.111), train_loss = 3.26876240, grad/param norm = 7.8069e-01, time/batch = 0.2564s	
1789/2700 (epoch 33.130), train_loss = 3.28479994, grad/param norm = 6.5969e-01, time/batch = 0.2556s	
1790/2700 (epoch 33.148), train_loss = 3.24682804, grad/param norm = 7.7590e-01, time/batch = 0.2544s	
1791/2700 (epoch 33.167), train_loss = 3.25912614, grad/param norm = 9.7082e-01, time/batch = 0.2327s	
1792/2700 (epoch 33.185), train_loss = 3.24247067, grad/param norm = 6.5414e-01, time/batch = 0.2220s	
1793/2700 (epoch 33.204), train_loss = 3.17656189, grad/param norm = 7.1976e-01, time/batch = 0.2200s	
1794/2700 (epoch 33.222), train_loss = 3.15454512, grad/param norm = 9.7957e-01, time/batch = 0.2244s	
1795/2700 (epoch 33.241), train_loss = 3.17234307, grad/param norm = 7.9043e-01, time/batch = 0.2119s	
1796/2700 (epoch 33.259), train_loss = 3.20631361, grad/param norm = 8.2675e-01, time/batch = 0.1905s	
1797/2700 (epoch 33.278), train_loss = 3.28111282, grad/param norm = 9.1219e-01, time/batch = 0.1962s	
1798/2700 (epoch 33.296), train_loss = 3.28686206, grad/param norm = 1.1263e+00, time/batch = 0.1958s	
1799/2700 (epoch 33.315), train_loss = 3.26380124, grad/param norm = 1.1216e+00, time/batch = 0.2441s	
1800/2700 (epoch 33.333), train_loss = 3.34267586, grad/param norm = 1.0247e+00, time/batch = 0.2536s	
1801/2700 (epoch 33.352), train_loss = 3.34870640, grad/param norm = 9.8152e-01, time/batch = 0.2388s	
1802/2700 (epoch 33.370), train_loss = 3.29021211, grad/param norm = 8.2592e-01, time/batch = 0.2445s	
1803/2700 (epoch 33.389), train_loss = 3.25413720, grad/param norm = 6.0384e-01, time/batch = 0.2464s	
1804/2700 (epoch 33.407), train_loss = 3.27662063, grad/param norm = 5.6921e-01, time/batch = 0.2500s	
1805/2700 (epoch 33.426), train_loss = 3.27972984, grad/param norm = 6.2572e-01, time/batch = 0.2574s	
1806/2700 (epoch 33.444), train_loss = 3.20740588, grad/param norm = 5.3951e-01, time/batch = 0.2573s	
1807/2700 (epoch 33.463), train_loss = 3.25023542, grad/param norm = 6.4423e-01, time/batch = 0.2568s	
1808/2700 (epoch 33.481), train_loss = 3.32668245, grad/param norm = 6.3573e-01, time/batch = 0.2504s	
1809/2700 (epoch 33.500), train_loss = 3.37468640, grad/param norm = 9.8643e-01, time/batch = 0.2592s	
1810/2700 (epoch 33.519), train_loss = 3.32860387, grad/param norm = 9.9476e-01, time/batch = 0.2573s	
1811/2700 (epoch 33.537), train_loss = 3.33154549, grad/param norm = 1.0136e+00, time/batch = 0.2501s	
1812/2700 (epoch 33.556), train_loss = 3.26700616, grad/param norm = 8.1623e-01, time/batch = 0.2390s	
1813/2700 (epoch 33.574), train_loss = 3.23297751, grad/param norm = 7.5739e-01, time/batch = 0.2307s	
1814/2700 (epoch 33.593), train_loss = 3.23447223, grad/param norm = 9.3159e-01, time/batch = 0.2292s	
1815/2700 (epoch 33.611), train_loss = 3.17357678, grad/param norm = 6.6561e-01, time/batch = 0.2393s	
1816/2700 (epoch 33.630), train_loss = 3.21484956, grad/param norm = 7.6923e-01, time/batch = 0.2328s	
1817/2700 (epoch 33.648), train_loss = 3.28666901, grad/param norm = 8.3424e-01, time/batch = 0.2283s	
1818/2700 (epoch 33.667), train_loss = 3.21849272, grad/param norm = 7.5782e-01, time/batch = 0.2146s	
1819/2700 (epoch 33.685), train_loss = 3.21362688, grad/param norm = 6.9642e-01, time/batch = 0.2313s	
1820/2700 (epoch 33.704), train_loss = 3.18671650, grad/param norm = 8.6132e-01, time/batch = 0.2395s	
1821/2700 (epoch 33.722), train_loss = 3.17764602, grad/param norm = 6.3947e-01, time/batch = 0.2197s	
1822/2700 (epoch 33.741), train_loss = 3.30931772, grad/param norm = 6.3779e-01, time/batch = 0.2299s	
1823/2700 (epoch 33.759), train_loss = 3.26011981, grad/param norm = 8.7323e-01, time/batch = 0.2380s	
1824/2700 (epoch 33.778), train_loss = 3.25437115, grad/param norm = 9.8358e-01, time/batch = 0.2311s	
1825/2700 (epoch 33.796), train_loss = 3.24868278, grad/param norm = 1.0330e+00, time/batch = 0.2583s	
1826/2700 (epoch 33.815), train_loss = 3.20036647, grad/param norm = 9.4985e-01, time/batch = 0.2603s	
1827/2700 (epoch 33.833), train_loss = 3.23858588, grad/param norm = 1.0561e+00, time/batch = 0.2522s	
1828/2700 (epoch 33.852), train_loss = 3.22735072, grad/param norm = 1.1247e+00, time/batch = 0.2576s	
1829/2700 (epoch 33.870), train_loss = 3.21927588, grad/param norm = 9.3480e-01, time/batch = 0.2573s	
1830/2700 (epoch 33.889), train_loss = 3.25577065, grad/param norm = 8.8698e-01, time/batch = 0.2596s	
1831/2700 (epoch 33.907), train_loss = 3.30818127, grad/param norm = 1.0176e+00, time/batch = 0.2369s	
1832/2700 (epoch 33.926), train_loss = 3.25764045, grad/param norm = 9.6516e-01, time/batch = 0.2215s	
1833/2700 (epoch 33.944), train_loss = 3.26608524, grad/param norm = 8.0132e-01, time/batch = 0.2355s	
1834/2700 (epoch 33.963), train_loss = 3.34373112, grad/param norm = 7.6023e-01, time/batch = 0.1998s	
1835/2700 (epoch 33.981), train_loss = 3.40461978, grad/param norm = 8.2836e-01, time/batch = 0.2288s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
1836/2700 (epoch 34.000), train_loss = 3.30449516, grad/param norm = 8.2898e-01, time/batch = 0.2230s	
1837/2700 (epoch 34.019), train_loss = 3.24484577, grad/param norm = 9.1811e-01, time/batch = 0.2153s	
1838/2700 (epoch 34.037), train_loss = 3.26035329, grad/param norm = 8.0216e-01, time/batch = 0.2055s	
1839/2700 (epoch 34.056), train_loss = 3.26055344, grad/param norm = 6.3983e-01, time/batch = 0.2045s	
1840/2700 (epoch 34.074), train_loss = 3.29322846, grad/param norm = 8.5856e-01, time/batch = 0.2169s	
1841/2700 (epoch 34.093), train_loss = 3.29864295, grad/param norm = 9.1771e-01, time/batch = 0.2249s	
1842/2700 (epoch 34.111), train_loss = 3.26820912, grad/param norm = 7.6121e-01, time/batch = 0.2282s	
1843/2700 (epoch 34.130), train_loss = 3.28419825, grad/param norm = 6.4429e-01, time/batch = 0.2323s	
1844/2700 (epoch 34.148), train_loss = 3.24651448, grad/param norm = 7.6127e-01, time/batch = 0.2301s	
1845/2700 (epoch 34.167), train_loss = 3.25839038, grad/param norm = 9.5105e-01, time/batch = 0.2330s	
1846/2700 (epoch 34.185), train_loss = 3.24190001, grad/param norm = 6.3145e-01, time/batch = 0.2447s	
1847/2700 (epoch 34.204), train_loss = 3.17619257, grad/param norm = 6.9641e-01, time/batch = 0.2556s	
1848/2700 (epoch 34.222), train_loss = 3.15392182, grad/param norm = 9.5580e-01, time/batch = 0.2575s	
1849/2700 (epoch 34.241), train_loss = 3.17165490, grad/param norm = 7.5153e-01, time/batch = 0.2595s	
1850/2700 (epoch 34.259), train_loss = 3.20552389, grad/param norm = 7.7525e-01, time/batch = 0.2603s	
1851/2700 (epoch 34.278), train_loss = 3.28027828, grad/param norm = 8.6986e-01, time/batch = 0.2553s	
1852/2700 (epoch 34.296), train_loss = 3.28589901, grad/param norm = 1.0852e+00, time/batch = 0.2480s	
1853/2700 (epoch 34.315), train_loss = 3.26295888, grad/param norm = 1.0955e+00, time/batch = 0.2377s	
1854/2700 (epoch 34.333), train_loss = 3.34225628, grad/param norm = 1.0194e+00, time/batch = 0.2425s	
1855/2700 (epoch 34.352), train_loss = 3.34829880, grad/param norm = 9.8114e-01, time/batch = 0.2329s	
1856/2700 (epoch 34.370), train_loss = 3.28967490, grad/param norm = 8.2098e-01, time/batch = 0.2213s	
1857/2700 (epoch 34.389), train_loss = 3.25385715, grad/param norm = 5.9652e-01, time/batch = 0.2398s	
1858/2700 (epoch 34.407), train_loss = 3.27628150, grad/param norm = 5.6359e-01, time/batch = 0.2216s	
1859/2700 (epoch 34.426), train_loss = 3.27934260, grad/param norm = 6.2023e-01, time/batch = 0.2186s	
1860/2700 (epoch 34.444), train_loss = 3.20728594, grad/param norm = 5.3202e-01, time/batch = 0.2094s	
1861/2700 (epoch 34.463), train_loss = 3.24992657, grad/param norm = 6.3497e-01, time/batch = 0.2209s	
1862/2700 (epoch 34.481), train_loss = 3.32648330, grad/param norm = 6.3214e-01, time/batch = 0.2117s	
1863/2700 (epoch 34.500), train_loss = 3.37429584, grad/param norm = 9.8071e-01, time/batch = 0.1964s	
1864/2700 (epoch 34.519), train_loss = 3.32798339, grad/param norm = 9.7568e-01, time/batch = 0.2316s	
1865/2700 (epoch 34.537), train_loss = 3.33096579, grad/param norm = 9.9599e-01, time/batch = 0.2396s	
1866/2700 (epoch 34.556), train_loss = 3.26640975, grad/param norm = 8.0163e-01, time/batch = 0.2386s	
1867/2700 (epoch 34.574), train_loss = 3.23281416, grad/param norm = 7.4649e-01, time/batch = 0.2573s	
1868/2700 (epoch 34.593), train_loss = 3.23389434, grad/param norm = 9.1363e-01, time/batch = 0.2576s	
1869/2700 (epoch 34.611), train_loss = 3.17310138, grad/param norm = 6.4056e-01, time/batch = 0.2571s	
1870/2700 (epoch 34.630), train_loss = 3.21442528, grad/param norm = 7.4813e-01, time/batch = 0.2570s	
1871/2700 (epoch 34.648), train_loss = 3.28590046, grad/param norm = 8.0982e-01, time/batch = 0.2374s	
1872/2700 (epoch 34.667), train_loss = 3.21778553, grad/param norm = 7.2855e-01, time/batch = 0.2328s	
1873/2700 (epoch 34.685), train_loss = 3.21314915, grad/param norm = 6.7561e-01, time/batch = 0.2251s	
1874/2700 (epoch 34.704), train_loss = 3.18614027, grad/param norm = 8.4192e-01, time/batch = 0.2555s	
1875/2700 (epoch 34.722), train_loss = 3.17706143, grad/param norm = 6.1407e-01, time/batch = 0.2506s	
1876/2700 (epoch 34.741), train_loss = 3.30892443, grad/param norm = 6.3018e-01, time/batch = 0.2478s	
1877/2700 (epoch 34.759), train_loss = 3.25948378, grad/param norm = 8.5796e-01, time/batch = 0.2246s	
1878/2700 (epoch 34.778), train_loss = 3.25339102, grad/param norm = 9.4503e-01, time/batch = 0.2194s	
1879/2700 (epoch 34.796), train_loss = 3.24738757, grad/param norm = 9.8161e-01, time/batch = 0.2094s	
1880/2700 (epoch 34.815), train_loss = 3.19917603, grad/param norm = 8.8887e-01, time/batch = 0.2103s	
1881/2700 (epoch 34.833), train_loss = 3.23760521, grad/param norm = 1.0133e+00, time/batch = 0.2272s	
1882/2700 (epoch 34.852), train_loss = 3.22672514, grad/param norm = 1.1111e+00, time/batch = 0.2099s	
1883/2700 (epoch 34.870), train_loss = 3.21895956, grad/param norm = 9.5151e-01, time/batch = 0.2130s	
1884/2700 (epoch 34.889), train_loss = 3.25595936, grad/param norm = 9.1116e-01, time/batch = 0.2130s	
1885/2700 (epoch 34.907), train_loss = 3.30800970, grad/param norm = 1.0245e+00, time/batch = 0.2089s	
1886/2700 (epoch 34.926), train_loss = 3.25704936, grad/param norm = 9.5543e-01, time/batch = 0.2488s	
1887/2700 (epoch 34.944), train_loss = 3.26549410, grad/param norm = 7.8890e-01, time/batch = 0.2349s	
1888/2700 (epoch 34.963), train_loss = 3.34332465, grad/param norm = 7.4658e-01, time/batch = 0.2449s	
1889/2700 (epoch 34.981), train_loss = 3.40423287, grad/param norm = 8.1366e-01, time/batch = 0.2432s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
1890/2700 (epoch 35.000), train_loss = 3.30383438, grad/param norm = 8.1685e-01, time/batch = 0.2395s	
1891/2700 (epoch 35.019), train_loss = 3.24430746, grad/param norm = 9.0825e-01, time/batch = 0.2589s	
1892/2700 (epoch 35.037), train_loss = 3.25983335, grad/param norm = 7.8887e-01, time/batch = 0.2534s	
1893/2700 (epoch 35.056), train_loss = 3.26033581, grad/param norm = 6.3416e-01, time/batch = 0.2601s	
1894/2700 (epoch 35.074), train_loss = 3.29286498, grad/param norm = 8.5100e-01, time/batch = 0.2526s	
1895/2700 (epoch 35.093), train_loss = 3.29803760, grad/param norm = 9.0228e-01, time/batch = 0.2579s	
1896/2700 (epoch 35.111), train_loss = 3.26768345, grad/param norm = 7.4162e-01, time/batch = 0.2568s	
1897/2700 (epoch 35.130), train_loss = 3.28364487, grad/param norm = 6.3051e-01, time/batch = 0.2500s	
1898/2700 (epoch 35.148), train_loss = 3.24624556, grad/param norm = 7.4888e-01, time/batch = 0.2318s	
1899/2700 (epoch 35.167), train_loss = 3.25771402, grad/param norm = 9.3299e-01, time/batch = 0.2215s	
1900/2700 (epoch 35.185), train_loss = 3.24137542, grad/param norm = 6.1079e-01, time/batch = 0.2096s	
1901/2700 (epoch 35.204), train_loss = 3.17586691, grad/param norm = 6.7550e-01, time/batch = 0.2309s	
1902/2700 (epoch 35.222), train_loss = 3.15334270, grad/param norm = 9.3393e-01, time/batch = 0.2106s	
1903/2700 (epoch 35.241), train_loss = 3.17104767, grad/param norm = 7.1665e-01, time/batch = 0.2080s	
1904/2700 (epoch 35.259), train_loss = 3.20483845, grad/param norm = 7.2958e-01, time/batch = 0.1824s	
1905/2700 (epoch 35.278), train_loss = 3.27952780, grad/param norm = 8.3043e-01, time/batch = 0.2189s	
1906/2700 (epoch 35.296), train_loss = 3.28492163, grad/param norm = 1.0413e+00, time/batch = 0.2284s	
1907/2700 (epoch 35.315), train_loss = 3.26206655, grad/param norm = 1.0651e+00, time/batch = 0.2401s	
1908/2700 (epoch 35.333), train_loss = 3.34183074, grad/param norm = 1.0119e+00, time/batch = 0.2345s	
1909/2700 (epoch 35.352), train_loss = 3.34790614, grad/param norm = 9.8042e-01, time/batch = 0.2557s	
1910/2700 (epoch 35.370), train_loss = 3.28916214, grad/param norm = 8.1630e-01, time/batch = 0.2503s	
1911/2700 (epoch 35.389), train_loss = 3.25359942, grad/param norm = 5.8995e-01, time/batch = 0.2548s	
1912/2700 (epoch 35.407), train_loss = 3.27596035, grad/param norm = 5.5855e-01, time/batch = 0.2597s	
1913/2700 (epoch 35.426), train_loss = 3.27897304, grad/param norm = 6.1522e-01, time/batch = 0.2584s	
1914/2700 (epoch 35.444), train_loss = 3.20718237, grad/param norm = 5.2536e-01, time/batch = 0.2506s	
1915/2700 (epoch 35.463), train_loss = 3.24963555, grad/param norm = 6.2620e-01, time/batch = 0.2556s	
1916/2700 (epoch 35.481), train_loss = 3.32629444, grad/param norm = 6.2843e-01, time/batch = 0.2571s	
1917/2700 (epoch 35.500), train_loss = 3.37387434, grad/param norm = 9.7394e-01, time/batch = 0.2599s	
1918/2700 (epoch 35.519), train_loss = 3.32737271, grad/param norm = 9.5656e-01, time/batch = 0.2600s	
1919/2700 (epoch 35.537), train_loss = 3.33042726, grad/param norm = 9.7925e-01, time/batch = 0.2285s	
1920/2700 (epoch 35.556), train_loss = 3.26584367, grad/param norm = 7.8754e-01, time/batch = 0.2203s	
1921/2700 (epoch 35.574), train_loss = 3.23265382, grad/param norm = 7.3610e-01, time/batch = 0.2365s	
1922/2700 (epoch 35.593), train_loss = 3.23334659, grad/param norm = 8.9668e-01, time/batch = 0.2385s	
1923/2700 (epoch 35.611), train_loss = 3.17268422, grad/param norm = 6.1769e-01, time/batch = 0.2203s	
1924/2700 (epoch 35.630), train_loss = 3.21405366, grad/param norm = 7.2935e-01, time/batch = 0.2210s	
1925/2700 (epoch 35.648), train_loss = 3.28517265, grad/param norm = 7.8747e-01, time/batch = 0.2248s	
1926/2700 (epoch 35.667), train_loss = 3.21714049, grad/param norm = 7.0175e-01, time/batch = 0.2299s	
1927/2700 (epoch 35.685), train_loss = 3.21272471, grad/param norm = 6.5732e-01, time/batch = 0.2378s	
1928/2700 (epoch 35.704), train_loss = 3.18561910, grad/param norm = 8.2475e-01, time/batch = 0.2389s	
1929/2700 (epoch 35.722), train_loss = 3.17652746, grad/param norm = 5.9107e-01, time/batch = 0.2367s	
1930/2700 (epoch 35.741), train_loss = 3.30858368, grad/param norm = 6.2659e-01, time/batch = 0.2477s	
1931/2700 (epoch 35.759), train_loss = 3.25891131, grad/param norm = 8.4642e-01, time/batch = 0.2218s	
1932/2700 (epoch 35.778), train_loss = 3.25249521, grad/param norm = 9.0926e-01, time/batch = 0.2255s	
1933/2700 (epoch 35.796), train_loss = 3.24615788, grad/param norm = 9.3064e-01, time/batch = 0.2044s	
1934/2700 (epoch 35.815), train_loss = 3.19794101, grad/param norm = 8.1724e-01, time/batch = 0.2376s	
1935/2700 (epoch 35.833), train_loss = 3.23636152, grad/param norm = 9.4456e-01, time/batch = 0.2353s	
1936/2700 (epoch 35.852), train_loss = 3.22576947, grad/param norm = 1.0780e+00, time/batch = 0.2352s	
1937/2700 (epoch 35.870), train_loss = 3.21873268, grad/param norm = 9.7321e-01, time/batch = 0.2343s	
1938/2700 (epoch 35.889), train_loss = 3.25635277, grad/param norm = 9.4768e-01, time/batch = 0.2349s	
1939/2700 (epoch 35.907), train_loss = 3.30793489, grad/param norm = 1.0405e+00, time/batch = 0.2398s	
1940/2700 (epoch 35.926), train_loss = 3.25658243, grad/param norm = 9.5282e-01, time/batch = 0.2469s	
1941/2700 (epoch 35.944), train_loss = 3.26496433, grad/param norm = 7.7904e-01, time/batch = 0.2587s	
1942/2700 (epoch 35.963), train_loss = 3.34294048, grad/param norm = 7.3370e-01, time/batch = 0.2537s	
1943/2700 (epoch 35.981), train_loss = 3.40387184, grad/param norm = 7.9955e-01, time/batch = 0.2588s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
1944/2700 (epoch 36.000), train_loss = 3.30320764, grad/param norm = 8.0526e-01, time/batch = 0.2574s	
1945/2700 (epoch 36.019), train_loss = 3.24378955, grad/param norm = 8.9927e-01, time/batch = 0.2557s	
1946/2700 (epoch 36.037), train_loss = 3.25933497, grad/param norm = 7.7614e-01, time/batch = 0.2555s	
1947/2700 (epoch 36.056), train_loss = 3.26012734, grad/param norm = 6.2791e-01, time/batch = 0.2567s	
1948/2700 (epoch 36.074), train_loss = 3.29248258, grad/param norm = 8.4131e-01, time/batch = 0.2543s	
1949/2700 (epoch 36.093), train_loss = 3.29743081, grad/param norm = 8.8558e-01, time/batch = 0.2460s	
1950/2700 (epoch 36.111), train_loss = 3.26718589, grad/param norm = 7.2220e-01, time/batch = 0.2083s	
1951/2700 (epoch 36.130), train_loss = 3.28313772, grad/param norm = 6.1851e-01, time/batch = 0.2410s	
1952/2700 (epoch 36.148), train_loss = 3.24601755, grad/param norm = 7.3864e-01, time/batch = 0.2329s	
1953/2700 (epoch 36.167), train_loss = 3.25709148, grad/param norm = 9.1649e-01, time/batch = 0.2252s	
1954/2700 (epoch 36.185), train_loss = 3.24089355, grad/param norm = 5.9207e-01, time/batch = 0.2147s	
1955/2700 (epoch 36.204), train_loss = 3.17558018, grad/param norm = 6.5686e-01, time/batch = 0.2311s	
1956/2700 (epoch 36.222), train_loss = 3.15280493, grad/param norm = 9.1383e-01, time/batch = 0.2392s	
1957/2700 (epoch 36.241), train_loss = 3.17051398, grad/param norm = 6.8557e-01, time/batch = 0.2457s	
1958/2700 (epoch 36.259), train_loss = 3.20424606, grad/param norm = 6.8980e-01, time/batch = 0.2532s	
1959/2700 (epoch 36.278), train_loss = 3.27885536, grad/param norm = 7.9430e-01, time/batch = 0.2506s	
1960/2700 (epoch 36.296), train_loss = 3.28395118, grad/param norm = 9.9560e-01, time/batch = 0.2327s	
1961/2700 (epoch 36.315), train_loss = 3.26113883, grad/param norm = 1.0309e+00, time/batch = 0.2281s	
1962/2700 (epoch 36.333), train_loss = 3.34139083, grad/param norm = 1.0015e+00, time/batch = 0.2335s	
1963/2700 (epoch 36.352), train_loss = 3.34751540, grad/param norm = 9.7878e-01, time/batch = 0.2335s	
1964/2700 (epoch 36.370), train_loss = 3.28867208, grad/param norm = 8.1179e-01, time/batch = 0.2374s	
1965/2700 (epoch 36.389), train_loss = 3.25336323, grad/param norm = 5.8413e-01, time/batch = 0.2440s	
1966/2700 (epoch 36.407), train_loss = 3.27565654, grad/param norm = 5.5407e-01, time/batch = 0.2479s	
1967/2700 (epoch 36.426), train_loss = 3.27862051, grad/param norm = 6.1067e-01, time/batch = 0.2535s	
1968/2700 (epoch 36.444), train_loss = 3.20709561, grad/param norm = 5.1950e-01, time/batch = 0.2531s	
1969/2700 (epoch 36.463), train_loss = 3.24935763, grad/param norm = 6.1779e-01, time/batch = 0.2476s	
1970/2700 (epoch 36.481), train_loss = 3.32611255, grad/param norm = 6.2443e-01, time/batch = 0.2434s	
1971/2700 (epoch 36.500), train_loss = 3.37342490, grad/param norm = 9.6606e-01, time/batch = 0.2174s	
1972/2700 (epoch 36.519), train_loss = 3.32677666, grad/param norm = 9.3744e-01, time/batch = 0.2304s	
1973/2700 (epoch 36.537), train_loss = 3.32992704, grad/param norm = 9.6345e-01, time/batch = 0.2215s	
1974/2700 (epoch 36.556), train_loss = 3.26530682, grad/param norm = 7.7407e-01, time/batch = 0.2281s	
1975/2700 (epoch 36.574), train_loss = 3.23249850, grad/param norm = 7.2634e-01, time/batch = 0.2304s	
1976/2700 (epoch 36.593), train_loss = 3.23282645, grad/param norm = 8.8067e-01, time/batch = 0.2389s	
1977/2700 (epoch 36.611), train_loss = 3.17231502, grad/param norm = 5.9687e-01, time/batch = 0.2401s	
1978/2700 (epoch 36.630), train_loss = 3.21372825, grad/param norm = 7.1268e-01, time/batch = 0.2424s	
1979/2700 (epoch 36.648), train_loss = 3.28448000, grad/param norm = 7.6710e-01, time/batch = 0.2419s	
1980/2700 (epoch 36.667), train_loss = 3.21655154, grad/param norm = 6.7741e-01, time/batch = 0.2509s	
1981/2700 (epoch 36.685), train_loss = 3.21234817, grad/param norm = 6.4152e-01, time/batch = 0.2227s	
1982/2700 (epoch 36.704), train_loss = 3.18514788, grad/param norm = 8.0979e-01, time/batch = 0.2358s	
1983/2700 (epoch 36.722), train_loss = 3.17604120, grad/param norm = 5.7080e-01, time/batch = 0.2331s	
1984/2700 (epoch 36.741), train_loss = 3.30829633, grad/param norm = 6.2705e-01, time/batch = 0.2357s	
1985/2700 (epoch 36.759), train_loss = 3.25841033, grad/param norm = 8.3908e-01, time/batch = 0.2441s	
1986/2700 (epoch 36.778), train_loss = 3.25169931, grad/param norm = 8.7850e-01, time/batch = 0.2503s	
1987/2700 (epoch 36.796), train_loss = 3.24505082, grad/param norm = 8.8521e-01, time/batch = 0.2565s	
1988/2700 (epoch 36.815), train_loss = 3.19678085, grad/param norm = 7.4280e-01, time/batch = 0.2499s	
1989/2700 (epoch 36.833), train_loss = 3.23490800, grad/param norm = 8.4978e-01, time/batch = 0.2400s	
1990/2700 (epoch 36.852), train_loss = 3.22430386, grad/param norm = 1.0116e+00, time/batch = 0.2244s	
1991/2700 (epoch 36.870), train_loss = 3.21841767, grad/param norm = 9.8453e-01, time/batch = 0.2529s	
1992/2700 (epoch 36.889), train_loss = 3.25688377, grad/param norm = 9.9082e-01, time/batch = 0.2410s	
1993/2700 (epoch 36.907), train_loss = 3.30798559, grad/param norm = 1.0675e+00, time/batch = 0.2273s	
1994/2700 (epoch 36.926), train_loss = 3.25627560, grad/param norm = 9.5987e-01, time/batch = 0.2135s	
1995/2700 (epoch 36.944), train_loss = 3.26450035, grad/param norm = 7.7262e-01, time/batch = 0.2152s	
1996/2700 (epoch 36.963), train_loss = 3.34257993, grad/param norm = 7.2200e-01, time/batch = 0.2072s	
1997/2700 (epoch 36.981), train_loss = 3.40354084, grad/param norm = 7.8626e-01, time/batch = 0.2241s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
1998/2700 (epoch 37.000), train_loss = 3.30261756, grad/param norm = 7.9447e-01, time/batch = 0.2261s	
1999/2700 (epoch 37.019), train_loss = 3.24329675, grad/param norm = 8.9148e-01, time/batch = 0.2467s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch37.04_3.1851.t7	
2000/2700 (epoch 37.037), train_loss = 3.25886079, grad/param norm = 7.6425e-01, time/batch = 0.2398s	
2001/2700 (epoch 37.056), train_loss = 3.25992407, grad/param norm = 6.2098e-01, time/batch = 0.2270s	
2002/2700 (epoch 37.074), train_loss = 3.29208560, grad/param norm = 8.2989e-01, time/batch = 0.2222s	
2003/2700 (epoch 37.093), train_loss = 3.29683277, grad/param norm = 8.6835e-01, time/batch = 0.2225s	
2004/2700 (epoch 37.111), train_loss = 3.26672162, grad/param norm = 7.0366e-01, time/batch = 0.2132s	
2005/2700 (epoch 37.130), train_loss = 3.28267786, grad/param norm = 6.0871e-01, time/batch = 0.2210s	
2006/2700 (epoch 37.148), train_loss = 3.24582693, grad/param norm = 7.3038e-01, time/batch = 0.2430s	
2007/2700 (epoch 37.167), train_loss = 3.25651660, grad/param norm = 9.0149e-01, time/batch = 0.2364s	
2008/2700 (epoch 37.185), train_loss = 3.24045290, grad/param norm = 5.7533e-01, time/batch = 0.2465s	
2009/2700 (epoch 37.204), train_loss = 3.17533081, grad/param norm = 6.4073e-01, time/batch = 0.2565s	
2010/2700 (epoch 37.222), train_loss = 3.15231262, grad/param norm = 8.9562e-01, time/batch = 0.2483s	
2011/2700 (epoch 37.241), train_loss = 3.17005768, grad/param norm = 6.5915e-01, time/batch = 0.2575s	
2012/2700 (epoch 37.259), train_loss = 3.20374978, grad/param norm = 6.5785e-01, time/batch = 0.2579s	
2013/2700 (epoch 37.278), train_loss = 3.27827262, grad/param norm = 7.6328e-01, time/batch = 0.2564s	
2014/2700 (epoch 37.296), train_loss = 3.28302868, grad/param norm = 9.5128e-01, time/batch = 0.2502s	
2015/2700 (epoch 37.315), train_loss = 3.26021173, grad/param norm = 9.9440e-01, time/batch = 0.2423s	
2016/2700 (epoch 37.333), train_loss = 3.34092465, grad/param norm = 9.8693e-01, time/batch = 0.2504s	
2017/2700 (epoch 37.352), train_loss = 3.34709502, grad/param norm = 9.7436e-01, time/batch = 0.2558s	
2018/2700 (epoch 37.370), train_loss = 3.28819057, grad/param norm = 8.0650e-01, time/batch = 0.2542s	
2019/2700 (epoch 37.389), train_loss = 3.25314149, grad/param norm = 5.7833e-01, time/batch = 0.2561s	
2020/2700 (epoch 37.407), train_loss = 3.27536791, grad/param norm = 5.4996e-01, time/batch = 0.2526s	
2021/2700 (epoch 37.426), train_loss = 3.27828280, grad/param norm = 6.0625e-01, time/batch = 0.2612s	
2022/2700 (epoch 37.444), train_loss = 3.20702280, grad/param norm = 5.1439e-01, time/batch = 0.2579s	
2023/2700 (epoch 37.463), train_loss = 3.24909569, grad/param norm = 6.1009e-01, time/batch = 0.2584s	
2024/2700 (epoch 37.481), train_loss = 3.32594354, grad/param norm = 6.2099e-01, time/batch = 0.2565s	
2025/2700 (epoch 37.500), train_loss = 3.37296314, grad/param norm = 9.5811e-01, time/batch = 0.2500s	
2026/2700 (epoch 37.519), train_loss = 3.32621024, grad/param norm = 9.1922e-01, time/batch = 0.2448s	
2027/2700 (epoch 37.537), train_loss = 3.32946198, grad/param norm = 9.4865e-01, time/batch = 0.2393s	
2028/2700 (epoch 37.556), train_loss = 3.26479431, grad/param norm = 7.6090e-01, time/batch = 0.2305s	
2029/2700 (epoch 37.574), train_loss = 3.23234670, grad/param norm = 7.1684e-01, time/batch = 0.2236s	
2030/2700 (epoch 37.593), train_loss = 3.23232582, grad/param norm = 8.6510e-01, time/batch = 0.2276s	
2031/2700 (epoch 37.611), train_loss = 3.17198740, grad/param norm = 5.7741e-01, time/batch = 0.2160s	
2032/2700 (epoch 37.630), train_loss = 3.21343349, grad/param norm = 6.9705e-01, time/batch = 0.2213s	
2033/2700 (epoch 37.648), train_loss = 3.28380874, grad/param norm = 7.4760e-01, time/batch = 0.2180s	
2034/2700 (epoch 37.667), train_loss = 3.21600576, grad/param norm = 6.5420e-01, time/batch = 0.2127s	
2035/2700 (epoch 37.685), train_loss = 3.21200953, grad/param norm = 6.2735e-01, time/batch = 0.2362s	
2036/2700 (epoch 37.704), train_loss = 3.18471725, grad/param norm = 7.9635e-01, time/batch = 0.2384s	
2037/2700 (epoch 37.722), train_loss = 3.17559382, grad/param norm = 5.5276e-01, time/batch = 0.2407s	
2038/2700 (epoch 37.741), train_loss = 3.30806540, grad/param norm = 6.3249e-01, time/batch = 0.2399s	
2039/2700 (epoch 37.759), train_loss = 3.25798612, grad/param norm = 8.3668e-01, time/batch = 0.2421s	
2040/2700 (epoch 37.778), train_loss = 3.25100823, grad/param norm = 8.5333e-01, time/batch = 0.2438s	
2041/2700 (epoch 37.796), train_loss = 3.24408570, grad/param norm = 8.4747e-01, time/batch = 0.2429s	
2042/2700 (epoch 37.815), train_loss = 3.19576950, grad/param norm = 6.7223e-01, time/batch = 0.2536s	
2043/2700 (epoch 37.833), train_loss = 3.23336994, grad/param norm = 7.3470e-01, time/batch = 0.2578s	
2044/2700 (epoch 37.852), train_loss = 3.22222130, grad/param norm = 8.9493e-01, time/batch = 0.2389s	
2045/2700 (epoch 37.870), train_loss = 3.21754394, grad/param norm = 9.4411e-01, time/batch = 0.2442s	
2046/2700 (epoch 37.889), train_loss = 3.25725022, grad/param norm = 1.0223e+00, time/batch = 0.2531s	
2047/2700 (epoch 37.907), train_loss = 3.30830198, grad/param norm = 1.1162e+00, time/batch = 0.2569s	
2048/2700 (epoch 37.926), train_loss = 3.25631740, grad/param norm = 9.8917e-01, time/batch = 0.2494s	
2049/2700 (epoch 37.944), train_loss = 3.26415349, grad/param norm = 7.7519e-01, time/batch = 0.2463s	
2050/2700 (epoch 37.963), train_loss = 3.34225852, grad/param norm = 7.1366e-01, time/batch = 0.2357s	
2051/2700 (epoch 37.981), train_loss = 3.40323216, grad/param norm = 7.7394e-01, time/batch = 0.2425s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2052/2700 (epoch 38.000), train_loss = 3.30206499, grad/param norm = 7.8514e-01, time/batch = 0.2279s	
2053/2700 (epoch 38.019), train_loss = 3.24285346, grad/param norm = 8.8641e-01, time/batch = 0.2142s	
2054/2700 (epoch 38.037), train_loss = 3.25842349, grad/param norm = 7.5440e-01, time/batch = 0.1868s	
2055/2700 (epoch 38.056), train_loss = 3.25970505, grad/param norm = 6.1122e-01, time/batch = 0.2254s	
2056/2700 (epoch 38.074), train_loss = 3.29164902, grad/param norm = 8.1423e-01, time/batch = 0.2306s	
2057/2700 (epoch 38.093), train_loss = 3.29623147, grad/param norm = 8.5000e-01, time/batch = 0.2431s	
2058/2700 (epoch 38.111), train_loss = 3.26629913, grad/param norm = 6.8671e-01, time/batch = 0.2570s	
2059/2700 (epoch 38.130), train_loss = 3.28227278, grad/param norm = 6.0195e-01, time/batch = 0.2489s	
2060/2700 (epoch 38.148), train_loss = 3.24568496, grad/param norm = 7.2464e-01, time/batch = 0.2399s	
2061/2700 (epoch 38.167), train_loss = 3.25599276, grad/param norm = 8.8817e-01, time/batch = 0.2401s	
2062/2700 (epoch 38.185), train_loss = 3.24005166, grad/param norm = 5.6045e-01, time/batch = 0.2338s	
2063/2700 (epoch 38.204), train_loss = 3.17511454, grad/param norm = 6.2719e-01, time/batch = 0.2524s	
2064/2700 (epoch 38.222), train_loss = 3.15186304, grad/param norm = 8.7913e-01, time/batch = 0.2279s	
2065/2700 (epoch 38.241), train_loss = 3.16968223, grad/param norm = 6.3883e-01, time/batch = 0.2237s	
2066/2700 (epoch 38.259), train_loss = 3.20337191, grad/param norm = 6.3806e-01, time/batch = 0.2340s	
2067/2700 (epoch 38.278), train_loss = 3.27781156, grad/param norm = 7.4160e-01, time/batch = 0.2386s	
2068/2700 (epoch 38.296), train_loss = 3.28226400, grad/param norm = 9.1688e-01, time/batch = 0.2445s	
2069/2700 (epoch 38.315), train_loss = 3.25940375, grad/param norm = 9.6322e-01, time/batch = 0.2514s	
2070/2700 (epoch 38.333), train_loss = 3.34045318, grad/param norm = 9.6974e-01, time/batch = 0.2545s	
2071/2700 (epoch 38.352), train_loss = 3.34660925, grad/param norm = 9.6476e-01, time/batch = 0.2573s	
2072/2700 (epoch 38.370), train_loss = 3.28768434, grad/param norm = 7.9792e-01, time/batch = 0.2413s	
2073/2700 (epoch 38.389), train_loss = 3.25291488, grad/param norm = 5.7025e-01, time/batch = 0.2240s	
2074/2700 (epoch 38.407), train_loss = 3.27508948, grad/param norm = 5.4547e-01, time/batch = 0.2374s	
2075/2700 (epoch 38.426), train_loss = 3.27795002, grad/param norm = 6.0057e-01, time/batch = 0.2192s	
2076/2700 (epoch 38.444), train_loss = 3.20696020, grad/param norm = 5.0974e-01, time/batch = 0.2190s	
2077/2700 (epoch 38.463), train_loss = 3.24885627, grad/param norm = 6.0431e-01, time/batch = 0.2161s	
2078/2700 (epoch 38.481), train_loss = 3.32580596, grad/param norm = 6.2078e-01, time/batch = 0.2194s	
2079/2700 (epoch 38.500), train_loss = 3.37252426, grad/param norm = 9.5291e-01, time/batch = 0.2229s	
2080/2700 (epoch 38.519), train_loss = 3.32569962, grad/param norm = 9.0391e-01, time/batch = 0.2381s	
2081/2700 (epoch 38.537), train_loss = 3.32901927, grad/param norm = 9.3410e-01, time/batch = 0.2329s	
2082/2700 (epoch 38.556), train_loss = 3.26427826, grad/param norm = 7.4576e-01, time/batch = 0.2402s	
2083/2700 (epoch 38.574), train_loss = 3.23218503, grad/param norm = 7.0595e-01, time/batch = 0.2271s	
2084/2700 (epoch 38.593), train_loss = 3.23183102, grad/param norm = 8.4825e-01, time/batch = 0.2534s	
2085/2700 (epoch 38.611), train_loss = 3.17167756, grad/param norm = 5.5720e-01, time/batch = 0.2491s	
2086/2700 (epoch 38.630), train_loss = 3.21313515, grad/param norm = 6.7936e-01, time/batch = 0.2568s	
2087/2700 (epoch 38.648), train_loss = 3.28312795, grad/param norm = 7.2597e-01, time/batch = 0.2558s	
2088/2700 (epoch 38.667), train_loss = 3.21547006, grad/param norm = 6.2846e-01, time/batch = 0.2581s	
2089/2700 (epoch 38.685), train_loss = 3.21168896, grad/param norm = 6.1323e-01, time/batch = 0.2582s	
2090/2700 (epoch 38.704), train_loss = 3.18431636, grad/param norm = 7.8349e-01, time/batch = 0.2563s	
2091/2700 (epoch 38.722), train_loss = 3.17517348, grad/param norm = 5.3703e-01, time/batch = 0.2402s	
2092/2700 (epoch 38.741), train_loss = 3.30793903, grad/param norm = 6.4992e-01, time/batch = 0.2290s	
2093/2700 (epoch 38.759), train_loss = 3.25770103, grad/param norm = 8.4498e-01, time/batch = 0.2325s	
2094/2700 (epoch 38.778), train_loss = 3.25044770, grad/param norm = 8.3616e-01, time/batch = 0.2390s	
2095/2700 (epoch 38.796), train_loss = 3.24328059, grad/param norm = 8.2080e-01, time/batch = 0.2042s	
2096/2700 (epoch 38.815), train_loss = 3.19497459, grad/param norm = 6.1456e-01, time/batch = 0.2179s	
2097/2700 (epoch 38.833), train_loss = 3.23192094, grad/param norm = 6.1422e-01, time/batch = 0.2103s	
2098/2700 (epoch 38.852), train_loss = 3.21961624, grad/param norm = 7.0341e-01, time/batch = 0.2101s	
2099/2700 (epoch 38.870), train_loss = 3.21482800, grad/param norm = 7.0803e-01, time/batch = 0.2184s	
2100/2700 (epoch 38.889), train_loss = 3.25543925, grad/param norm = 9.2066e-01, time/batch = 0.2184s	
2101/2700 (epoch 38.907), train_loss = 3.30913322, grad/param norm = 1.2013e+00, time/batch = 0.2147s	
2102/2700 (epoch 38.926), train_loss = 3.25766725, grad/param norm = 1.0957e+00, time/batch = 0.2160s	
2103/2700 (epoch 38.944), train_loss = 3.26428405, grad/param norm = 8.2288e-01, time/batch = 0.2492s	
2104/2700 (epoch 38.963), train_loss = 3.34215927, grad/param norm = 7.2889e-01, time/batch = 0.2317s	
2105/2700 (epoch 38.981), train_loss = 3.40295919, grad/param norm = 7.6785e-01, time/batch = 0.2280s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2106/2700 (epoch 39.000), train_loss = 3.30159419, grad/param norm = 7.8464e-01, time/batch = 0.2368s	
2107/2700 (epoch 39.019), train_loss = 3.24264265, grad/param norm = 8.9493e-01, time/batch = 0.2437s	
2108/2700 (epoch 39.037), train_loss = 3.25812066, grad/param norm = 7.5544e-01, time/batch = 0.2417s	
2109/2700 (epoch 39.056), train_loss = 3.25936441, grad/param norm = 5.8809e-01, time/batch = 0.2466s	
2110/2700 (epoch 39.074), train_loss = 3.29100597, grad/param norm = 7.7739e-01, time/batch = 0.2398s	
2111/2700 (epoch 39.093), train_loss = 3.29551958, grad/param norm = 8.2130e-01, time/batch = 0.2522s	
2112/2700 (epoch 39.111), train_loss = 3.26593038, grad/param norm = 6.7073e-01, time/batch = 0.2577s	
2113/2700 (epoch 39.130), train_loss = 3.28197161, grad/param norm = 6.0105e-01, time/batch = 0.2562s	
2114/2700 (epoch 39.148), train_loss = 3.24566147, grad/param norm = 7.2501e-01, time/batch = 0.2479s	
2115/2700 (epoch 39.167), train_loss = 3.25552424, grad/param norm = 8.7637e-01, time/batch = 0.2302s	
2116/2700 (epoch 39.185), train_loss = 3.23969442, grad/param norm = 5.4677e-01, time/batch = 0.2232s	
2117/2700 (epoch 39.204), train_loss = 3.17491843, grad/param norm = 6.1516e-01, time/batch = 0.2230s	
2118/2700 (epoch 39.222), train_loss = 3.15142889, grad/param norm = 8.6234e-01, time/batch = 0.2258s	
2119/2700 (epoch 39.241), train_loss = 3.16938851, grad/param norm = 6.2640e-01, time/batch = 0.2308s	
2120/2700 (epoch 39.259), train_loss = 3.20318188, grad/param norm = 6.4111e-01, time/batch = 0.2372s	
2121/2700 (epoch 39.278), train_loss = 3.27758184, grad/param norm = 7.4088e-01, time/batch = 0.2116s	
2122/2700 (epoch 39.296), train_loss = 3.28193863, grad/param norm = 9.1530e-01, time/batch = 0.2188s	
2123/2700 (epoch 39.315), train_loss = 3.25904210, grad/param norm = 9.5989e-01, time/batch = 0.2289s	
2124/2700 (epoch 39.333), train_loss = 3.34009458, grad/param norm = 9.5956e-01, time/batch = 0.2342s	
2125/2700 (epoch 39.352), train_loss = 3.34603485, grad/param norm = 9.4796e-01, time/batch = 0.2343s	
2126/2700 (epoch 39.370), train_loss = 3.28708867, grad/param norm = 7.8082e-01, time/batch = 0.2539s	
2127/2700 (epoch 39.389), train_loss = 3.25263801, grad/param norm = 5.5448e-01, time/batch = 0.2566s	
2128/2700 (epoch 39.407), train_loss = 3.27481368, grad/param norm = 5.3927e-01, time/batch = 0.2541s	
2129/2700 (epoch 39.426), train_loss = 3.27759494, grad/param norm = 5.9043e-01, time/batch = 0.2471s	
2130/2700 (epoch 39.444), train_loss = 3.20690377, grad/param norm = 5.0545e-01, time/batch = 0.2329s	
2131/2700 (epoch 39.463), train_loss = 3.24867364, grad/param norm = 6.0465e-01, time/batch = 0.2354s	
2132/2700 (epoch 39.481), train_loss = 3.32576665, grad/param norm = 6.3120e-01, time/batch = 0.2411s	
2133/2700 (epoch 39.500), train_loss = 3.37217712, grad/param norm = 9.5632e-01, time/batch = 0.2415s	
2134/2700 (epoch 39.519), train_loss = 3.32526258, grad/param norm = 8.9322e-01, time/batch = 0.2202s	
2135/2700 (epoch 39.537), train_loss = 3.32852622, grad/param norm = 9.1448e-01, time/batch = 0.2285s	
2136/2700 (epoch 39.556), train_loss = 3.26366714, grad/param norm = 7.2026e-01, time/batch = 0.1876s	
2137/2700 (epoch 39.574), train_loss = 3.23198526, grad/param norm = 6.8960e-01, time/batch = 0.2304s	
2138/2700 (epoch 39.593), train_loss = 3.23131053, grad/param norm = 8.2658e-01, time/batch = 0.2329s	
2139/2700 (epoch 39.611), train_loss = 3.17135639, grad/param norm = 5.3266e-01, time/batch = 0.2332s	
2140/2700 (epoch 39.630), train_loss = 3.21277866, grad/param norm = 6.5353e-01, time/batch = 0.2335s	
2141/2700 (epoch 39.648), train_loss = 3.28238183, grad/param norm = 6.9645e-01, time/batch = 0.2443s	
2142/2700 (epoch 39.667), train_loss = 3.21489744, grad/param norm = 5.9325e-01, time/batch = 0.2385s	
2143/2700 (epoch 39.685), train_loss = 3.21137027, grad/param norm = 5.9878e-01, time/batch = 0.2356s	
2144/2700 (epoch 39.704), train_loss = 3.18397486, grad/param norm = 7.7337e-01, time/batch = 0.2461s	
2145/2700 (epoch 39.722), train_loss = 3.17482964, grad/param norm = 5.3451e-01, time/batch = 0.2522s	
2146/2700 (epoch 39.741), train_loss = 3.30822010, grad/param norm = 7.1551e-01, time/batch = 0.2475s	
2147/2700 (epoch 39.759), train_loss = 3.25790935, grad/param norm = 8.9195e-01, time/batch = 0.2586s	
2148/2700 (epoch 39.778), train_loss = 3.25016963, grad/param norm = 8.4189e-01, time/batch = 0.2588s	
2149/2700 (epoch 39.796), train_loss = 3.24276090, grad/param norm = 8.1950e-01, time/batch = 0.2563s	
2150/2700 (epoch 39.815), train_loss = 3.19461131, grad/param norm = 6.0412e-01, time/batch = 0.2539s	
2151/2700 (epoch 39.833), train_loss = 3.23119546, grad/param norm = 5.7269e-01, time/batch = 0.2595s	
2152/2700 (epoch 39.852), train_loss = 3.21822070, grad/param norm = 5.8236e-01, time/batch = 0.2570s	
2153/2700 (epoch 39.870), train_loss = 3.21228858, grad/param norm = 3.9732e-01, time/batch = 0.2489s	
2154/2700 (epoch 39.889), train_loss = 3.25081693, grad/param norm = 5.1026e-01, time/batch = 0.2568s	
2155/2700 (epoch 39.907), train_loss = 3.30432121, grad/param norm = 8.2155e-01, time/batch = 0.2545s	
2156/2700 (epoch 39.926), train_loss = 3.25392187, grad/param norm = 8.7841e-01, time/batch = 0.2517s	
2157/2700 (epoch 39.944), train_loss = 3.26427573, grad/param norm = 8.6856e-01, time/batch = 0.2239s	
2158/2700 (epoch 39.963), train_loss = 3.34398458, grad/param norm = 8.9053e-01, time/batch = 0.2221s	
2159/2700 (epoch 39.981), train_loss = 3.40419069, grad/param norm = 9.1938e-01, time/batch = 0.1918s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2160/2700 (epoch 40.000), train_loss = 3.30355744, grad/param norm = 9.8807e-01, time/batch = 0.2218s	
2161/2700 (epoch 40.019), train_loss = 3.24521892, grad/param norm = 1.0952e+00, time/batch = 0.2039s	
2162/2700 (epoch 40.037), train_loss = 3.25930646, grad/param norm = 8.9951e-01, time/batch = 0.2030s	
2163/2700 (epoch 40.056), train_loss = 3.25888234, grad/param norm = 5.5616e-01, time/batch = 0.2076s	
2164/2700 (epoch 40.074), train_loss = 3.28958085, grad/param norm = 6.4935e-01, time/batch = 0.2450s	
2165/2700 (epoch 40.093), train_loss = 3.29443305, grad/param norm = 7.3125e-01, time/batch = 0.2513s	
2166/2700 (epoch 40.111), train_loss = 3.26564054, grad/param norm = 6.4091e-01, time/batch = 0.2498s	
2167/2700 (epoch 40.130), train_loss = 3.28196360, grad/param norm = 6.1350e-01, time/batch = 0.2317s	
2168/2700 (epoch 40.148), train_loss = 3.24575733, grad/param norm = 7.4307e-01, time/batch = 0.2384s	
2169/2700 (epoch 40.167), train_loss = 3.25488918, grad/param norm = 8.5429e-01, time/batch = 0.2337s	
2170/2700 (epoch 40.185), train_loss = 3.23962362, grad/param norm = 5.5887e-01, time/batch = 0.2398s	
2171/2700 (epoch 40.204), train_loss = 3.17481435, grad/param norm = 5.9408e-01, time/batch = 0.2612s	
2172/2700 (epoch 40.222), train_loss = 3.15071786, grad/param norm = 8.4634e-01, time/batch = 0.2605s	
2173/2700 (epoch 40.241), train_loss = 3.16843824, grad/param norm = 5.4392e-01, time/batch = 0.2642s	
2174/2700 (epoch 40.259), train_loss = 3.20207778, grad/param norm = 4.9460e-01, time/batch = 0.2556s	
2175/2700 (epoch 40.278), train_loss = 3.27681014, grad/param norm = 6.6732e-01, time/batch = 0.2412s	
2176/2700 (epoch 40.296), train_loss = 3.27921343, grad/param norm = 6.9925e-01, time/batch = 0.2446s	
2177/2700 (epoch 40.315), train_loss = 3.25508870, grad/param norm = 6.4030e-01, time/batch = 0.2378s	
2178/2700 (epoch 40.333), train_loss = 3.33625530, grad/param norm = 6.0984e-01, time/batch = 0.2312s	
2179/2700 (epoch 40.352), train_loss = 3.34285897, grad/param norm = 7.4533e-01, time/batch = 0.2297s	
2180/2700 (epoch 40.370), train_loss = 3.28678169, grad/param norm = 7.6394e-01, time/batch = 0.2284s	
2181/2700 (epoch 40.389), train_loss = 3.25304073, grad/param norm = 5.8453e-01, time/batch = 0.2475s	
2182/2700 (epoch 40.407), train_loss = 3.27469162, grad/param norm = 5.7130e-01, time/batch = 0.2360s	
2183/2700 (epoch 40.426), train_loss = 3.27853809, grad/param norm = 7.2514e-01, time/batch = 0.2582s	
2184/2700 (epoch 40.444), train_loss = 3.20881242, grad/param norm = 7.5407e-01, time/batch = 0.2516s	
2185/2700 (epoch 40.463), train_loss = 3.25092978, grad/param norm = 8.5304e-01, time/batch = 0.2441s	
2186/2700 (epoch 40.481), train_loss = 3.32789660, grad/param norm = 8.6573e-01, time/batch = 0.2335s	
2187/2700 (epoch 40.500), train_loss = 3.37243183, grad/param norm = 9.7624e-01, time/batch = 0.2137s	
2188/2700 (epoch 40.519), train_loss = 3.32327407, grad/param norm = 7.3648e-01, time/batch = 0.2141s	
2189/2700 (epoch 40.537), train_loss = 3.32726850, grad/param norm = 8.0499e-01, time/batch = 0.2586s	
2190/2700 (epoch 40.556), train_loss = 3.26276734, grad/param norm = 6.4017e-01, time/batch = 0.2569s	
2191/2700 (epoch 40.574), train_loss = 3.23317680, grad/param norm = 8.1682e-01, time/batch = 0.2314s	
2192/2700 (epoch 40.593), train_loss = 3.23304467, grad/param norm = 9.5223e-01, time/batch = 0.2290s	
2193/2700 (epoch 40.611), train_loss = 3.17295539, grad/param norm = 7.4543e-01, time/batch = 0.2544s	
2194/2700 (epoch 40.630), train_loss = 3.21306669, grad/param norm = 7.1258e-01, time/batch = 0.2466s	
2195/2700 (epoch 40.648), train_loss = 3.28246027, grad/param norm = 7.5937e-01, time/batch = 0.2449s	
2196/2700 (epoch 40.667), train_loss = 3.21537048, grad/param norm = 6.8165e-01, time/batch = 0.2365s	
2197/2700 (epoch 40.685), train_loss = 3.21313257, grad/param norm = 8.1470e-01, time/batch = 0.2293s	
2198/2700 (epoch 40.704), train_loss = 3.18585653, grad/param norm = 9.5071e-01, time/batch = 0.2259s	
2199/2700 (epoch 40.722), train_loss = 3.17653281, grad/param norm = 7.8512e-01, time/batch = 0.2434s	
2200/2700 (epoch 40.741), train_loss = 3.31017825, grad/param norm = 9.6291e-01, time/batch = 0.2403s	
2201/2700 (epoch 40.759), train_loss = 3.25687314, grad/param norm = 8.6752e-01, time/batch = 0.2385s	
2202/2700 (epoch 40.778), train_loss = 3.24841756, grad/param norm = 7.5019e-01, time/batch = 0.2455s	
2203/2700 (epoch 40.796), train_loss = 3.24152300, grad/param norm = 7.6226e-01, time/batch = 0.2468s	
2204/2700 (epoch 40.815), train_loss = 3.19403054, grad/param norm = 6.0767e-01, time/batch = 0.2480s	
2205/2700 (epoch 40.833), train_loss = 3.23114581, grad/param norm = 6.0218e-01, time/batch = 0.2457s	
2206/2700 (epoch 40.852), train_loss = 3.21837780, grad/param norm = 6.3597e-01, time/batch = 0.2366s	
2207/2700 (epoch 40.870), train_loss = 3.21237879, grad/param norm = 4.6199e-01, time/batch = 0.2282s	
2208/2700 (epoch 40.889), train_loss = 3.25105302, grad/param norm = 5.5850e-01, time/batch = 0.2259s	
2209/2700 (epoch 40.907), train_loss = 3.30430462, grad/param norm = 8.2504e-01, time/batch = 0.2057s	
2210/2700 (epoch 40.926), train_loss = 3.25272610, grad/param norm = 7.9453e-01, time/batch = 0.2631s	
2211/2700 (epoch 40.944), train_loss = 3.26221796, grad/param norm = 6.9866e-01, time/batch = 0.2431s	
2212/2700 (epoch 40.963), train_loss = 3.34161285, grad/param norm = 6.8638e-01, time/batch = 0.2518s	
2213/2700 (epoch 40.981), train_loss = 3.40259176, grad/param norm = 7.4205e-01, time/batch = 0.2587s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2214/2700 (epoch 41.000), train_loss = 3.30061377, grad/param norm = 7.5268e-01, time/batch = 0.2594s	
2215/2700 (epoch 41.019), train_loss = 3.24111455, grad/param norm = 8.4918e-01, time/batch = 0.2579s	
2216/2700 (epoch 41.037), train_loss = 3.25702373, grad/param norm = 7.1577e-01, time/batch = 0.2467s	
2217/2700 (epoch 41.056), train_loss = 3.25940656, grad/param norm = 6.1206e-01, time/batch = 0.2520s	
2218/2700 (epoch 41.074), train_loss = 3.29098837, grad/param norm = 8.3615e-01, time/batch = 0.2472s	
2219/2700 (epoch 41.093), train_loss = 3.29588145, grad/param norm = 8.9972e-01, time/batch = 0.2273s	
2220/2700 (epoch 41.111), train_loss = 3.26583059, grad/param norm = 7.1855e-01, time/batch = 0.2226s	
2221/2700 (epoch 41.130), train_loss = 3.28140820, grad/param norm = 6.2538e-01, time/batch = 0.2325s	
2222/2700 (epoch 41.148), train_loss = 3.24517766, grad/param norm = 7.0450e-01, time/batch = 0.2338s	
2223/2700 (epoch 41.167), train_loss = 3.25493626, grad/param norm = 8.8063e-01, time/batch = 0.2393s	
2224/2700 (epoch 41.185), train_loss = 3.23919450, grad/param norm = 5.4748e-01, time/batch = 0.2430s	
2225/2700 (epoch 41.204), train_loss = 3.17511719, grad/param norm = 6.4865e-01, time/batch = 0.2406s	
2226/2700 (epoch 41.222), train_loss = 3.15148908, grad/param norm = 8.7888e-01, time/batch = 0.2522s	
2227/2700 (epoch 41.241), train_loss = 3.16959780, grad/param norm = 6.7333e-01, time/batch = 0.2598s	
2228/2700 (epoch 41.259), train_loss = 3.20316680, grad/param norm = 6.9997e-01, time/batch = 0.2552s	
2229/2700 (epoch 41.278), train_loss = 3.27715826, grad/param norm = 7.4651e-01, time/batch = 0.2460s	
2230/2700 (epoch 41.296), train_loss = 3.28091653, grad/param norm = 8.8867e-01, time/batch = 0.2125s	
2231/2700 (epoch 41.315), train_loss = 3.25744648, grad/param norm = 8.9159e-01, time/batch = 0.2201s	
2232/2700 (epoch 41.333), train_loss = 3.33846736, grad/param norm = 8.5161e-01, time/batch = 0.2158s	
2233/2700 (epoch 41.352), train_loss = 3.34394453, grad/param norm = 8.5069e-01, time/batch = 0.2155s	
2234/2700 (epoch 41.370), train_loss = 3.28570157, grad/param norm = 7.3022e-01, time/batch = 0.2197s	
2235/2700 (epoch 41.389), train_loss = 3.25208464, grad/param norm = 5.2057e-01, time/batch = 0.2177s	
2236/2700 (epoch 41.407), train_loss = 3.27432569, grad/param norm = 5.2990e-01, time/batch = 0.2446s	
2237/2700 (epoch 41.426), train_loss = 3.27695594, grad/param norm = 5.7067e-01, time/batch = 0.2454s	
2238/2700 (epoch 41.444), train_loss = 3.20685048, grad/param norm = 5.0305e-01, time/batch = 0.2444s	
2239/2700 (epoch 41.463), train_loss = 3.24833325, grad/param norm = 6.1121e-01, time/batch = 0.2476s	
2240/2700 (epoch 41.481), train_loss = 3.32573770, grad/param norm = 6.5700e-01, time/batch = 0.2199s	
2241/2700 (epoch 41.500), train_loss = 3.37169135, grad/param norm = 9.7441e-01, time/batch = 0.2598s	
2242/2700 (epoch 41.519), train_loss = 3.32463674, grad/param norm = 8.8327e-01, time/batch = 0.2566s	
2243/2700 (epoch 41.537), train_loss = 3.32765207, grad/param norm = 8.8126e-01, time/batch = 0.2562s	
2244/2700 (epoch 41.556), train_loss = 3.26261379, grad/param norm = 6.7644e-01, time/batch = 0.2527s	
2245/2700 (epoch 41.574), train_loss = 3.23167324, grad/param norm = 6.6503e-01, time/batch = 0.2562s	
2246/2700 (epoch 41.593), train_loss = 3.23038161, grad/param norm = 7.9033e-01, time/batch = 0.2565s	
2247/2700 (epoch 41.611), train_loss = 3.17084660, grad/param norm = 4.9456e-01, time/batch = 0.2548s	
2248/2700 (epoch 41.630), train_loss = 3.21220138, grad/param norm = 6.1403e-01, time/batch = 0.2591s	
2249/2700 (epoch 41.648), train_loss = 3.28113283, grad/param norm = 6.5473e-01, time/batch = 0.2471s	
2250/2700 (epoch 41.667), train_loss = 3.21404567, grad/param norm = 5.4660e-01, time/batch = 0.2314s	
2251/2700 (epoch 41.685), train_loss = 3.21097847, grad/param norm = 5.9378e-01, time/batch = 0.2048s	
2252/2700 (epoch 41.704), train_loss = 3.18356613, grad/param norm = 7.7814e-01, time/batch = 0.2043s	
2253/2700 (epoch 41.722), train_loss = 3.17457882, grad/param norm = 5.7928e-01, time/batch = 0.2023s	
2254/2700 (epoch 41.741), train_loss = 3.30919354, grad/param norm = 8.6935e-01, time/batch = 0.2019s	
2255/2700 (epoch 41.759), train_loss = 3.25819534, grad/param norm = 9.5868e-01, time/batch = 0.2182s	
2256/2700 (epoch 41.778), train_loss = 3.24911930, grad/param norm = 8.1546e-01, time/batch = 0.2366s	
2257/2700 (epoch 41.796), train_loss = 3.24138123, grad/param norm = 7.7078e-01, time/batch = 0.2415s	
2258/2700 (epoch 41.815), train_loss = 3.19358773, grad/param norm = 5.6361e-01, time/batch = 0.2479s	
2259/2700 (epoch 41.833), train_loss = 3.23054297, grad/param norm = 5.5444e-01, time/batch = 0.2531s	
2260/2700 (epoch 41.852), train_loss = 3.21764357, grad/param norm = 5.8405e-01, time/batch = 0.2364s	
2261/2700 (epoch 41.870), train_loss = 3.21183942, grad/param norm = 4.2210e-01, time/batch = 0.2421s	
2262/2700 (epoch 41.889), train_loss = 3.25095234, grad/param norm = 5.5891e-01, time/batch = 0.2600s	
2263/2700 (epoch 41.907), train_loss = 3.30423602, grad/param norm = 8.5169e-01, time/batch = 0.2593s	
2264/2700 (epoch 41.926), train_loss = 3.25300159, grad/param norm = 8.5496e-01, time/batch = 0.2615s	
2265/2700 (epoch 41.944), train_loss = 3.26264023, grad/param norm = 7.6929e-01, time/batch = 0.2594s	
2266/2700 (epoch 41.963), train_loss = 3.34184235, grad/param norm = 7.3712e-01, time/batch = 0.2580s	
2267/2700 (epoch 41.981), train_loss = 3.40251913, grad/param norm = 7.6374e-01, time/batch = 0.2557s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2268/2700 (epoch 42.000), train_loss = 3.30072560, grad/param norm = 8.0794e-01, time/batch = 0.2560s	
2269/2700 (epoch 42.019), train_loss = 3.24203963, grad/param norm = 9.3804e-01, time/batch = 0.2414s	
2270/2700 (epoch 42.037), train_loss = 3.25745272, grad/param norm = 7.8915e-01, time/batch = 0.2448s	
2271/2700 (epoch 42.056), train_loss = 3.25878603, grad/param norm = 5.4795e-01, time/batch = 0.2498s	
2272/2700 (epoch 42.074), train_loss = 3.28898657, grad/param norm = 6.4469e-01, time/batch = 0.2516s	
2273/2700 (epoch 42.093), train_loss = 3.29363310, grad/param norm = 7.2724e-01, time/batch = 0.2442s	
2274/2700 (epoch 42.111), train_loss = 3.26499519, grad/param norm = 6.2604e-01, time/batch = 0.2377s	
2275/2700 (epoch 42.130), train_loss = 3.28119693, grad/param norm = 6.0117e-01, time/batch = 0.2304s	
2276/2700 (epoch 42.148), train_loss = 3.24530524, grad/param norm = 7.1385e-01, time/batch = 0.2249s	
2277/2700 (epoch 42.167), train_loss = 3.25411294, grad/param norm = 8.3936e-01, time/batch = 0.2253s	
2278/2700 (epoch 42.185), train_loss = 3.23876502, grad/param norm = 5.1483e-01, time/batch = 0.2314s	
2279/2700 (epoch 42.204), train_loss = 3.17450954, grad/param norm = 5.8806e-01, time/batch = 0.2014s	
2280/2700 (epoch 42.222), train_loss = 3.15031795, grad/param norm = 8.2304e-01, time/batch = 0.2049s	
2281/2700 (epoch 42.241), train_loss = 3.16873390, grad/param norm = 6.0815e-01, time/batch = 0.2268s	
2282/2700 (epoch 42.259), train_loss = 3.20315645, grad/param norm = 7.1400e-01, time/batch = 0.2082s	
2283/2700 (epoch 42.278), train_loss = 3.27786446, grad/param norm = 8.2461e-01, time/batch = 0.2184s	
2284/2700 (epoch 42.296), train_loss = 3.28262703, grad/param norm = 1.0459e+00, time/batch = 0.2008s	
2285/2700 (epoch 42.315), train_loss = 3.25926393, grad/param norm = 1.0294e+00, time/batch = 0.2466s	
2286/2700 (epoch 42.333), train_loss = 3.33876477, grad/param norm = 8.9745e-01, time/batch = 0.2435s	
2287/2700 (epoch 42.352), train_loss = 3.34369021, grad/param norm = 8.4767e-01, time/batch = 0.2356s	
2288/2700 (epoch 42.370), train_loss = 3.28517766, grad/param norm = 7.1249e-01, time/batch = 0.2174s	
2289/2700 (epoch 42.389), train_loss = 3.25182657, grad/param norm = 5.0373e-01, time/batch = 0.2227s	
2290/2700 (epoch 42.407), train_loss = 3.27412117, grad/param norm = 5.3193e-01, time/batch = 0.2282s	
2291/2700 (epoch 42.426), train_loss = 3.27662313, grad/param norm = 5.6226e-01, time/batch = 0.2128s	
2292/2700 (epoch 42.444), train_loss = 3.20685929, grad/param norm = 5.0575e-01, time/batch = 0.1949s	
2293/2700 (epoch 42.463), train_loss = 3.24825547, grad/param norm = 6.2042e-01, time/batch = 0.2360s	
2294/2700 (epoch 42.481), train_loss = 3.32576617, grad/param norm = 6.6751e-01, time/batch = 0.2441s	
2295/2700 (epoch 42.500), train_loss = 3.37094867, grad/param norm = 9.4952e-01, time/batch = 0.2440s	
2296/2700 (epoch 42.519), train_loss = 3.32363822, grad/param norm = 8.2453e-01, time/batch = 0.2568s	
2297/2700 (epoch 42.537), train_loss = 3.32686739, grad/param norm = 8.2501e-01, time/batch = 0.2586s	
2298/2700 (epoch 42.556), train_loss = 3.26182667, grad/param norm = 6.2305e-01, time/batch = 0.2471s	
2299/2700 (epoch 42.574), train_loss = 3.23146065, grad/param norm = 6.4913e-01, time/batch = 0.2472s	
2300/2700 (epoch 42.593), train_loss = 3.22995301, grad/param norm = 7.7190e-01, time/batch = 0.2426s	
2301/2700 (epoch 42.611), train_loss = 3.17068434, grad/param norm = 4.8409e-01, time/batch = 0.2514s	
2302/2700 (epoch 42.630), train_loss = 3.21196816, grad/param norm = 5.9497e-01, time/batch = 0.2571s	
2303/2700 (epoch 42.648), train_loss = 3.28051637, grad/param norm = 6.3479e-01, time/batch = 0.2541s	
2304/2700 (epoch 42.667), train_loss = 3.21366089, grad/param norm = 5.2739e-01, time/batch = 0.2489s	
2305/2700 (epoch 42.685), train_loss = 3.21096487, grad/param norm = 6.1281e-01, time/batch = 0.2351s	
2306/2700 (epoch 42.704), train_loss = 3.18371700, grad/param norm = 8.1100e-01, time/batch = 0.2417s	
2307/2700 (epoch 42.722), train_loss = 3.17492670, grad/param norm = 6.5521e-01, time/batch = 0.2396s	
2308/2700 (epoch 42.741), train_loss = 3.31019150, grad/param norm = 9.8365e-01, time/batch = 0.2188s	
2309/2700 (epoch 42.759), train_loss = 3.25805511, grad/param norm = 9.7119e-01, time/batch = 0.2432s	
2310/2700 (epoch 42.778), train_loss = 3.24832002, grad/param norm = 7.7698e-01, time/batch = 0.2369s	
2311/2700 (epoch 42.796), train_loss = 3.24061235, grad/param norm = 7.3449e-01, time/batch = 0.2320s	
2312/2700 (epoch 42.815), train_loss = 3.19311625, grad/param norm = 5.4750e-01, time/batch = 0.2307s	
2313/2700 (epoch 42.833), train_loss = 3.23035476, grad/param norm = 5.6005e-01, time/batch = 0.2274s	
2314/2700 (epoch 42.852), train_loss = 3.21749234, grad/param norm = 5.9766e-01, time/batch = 0.2248s	
2315/2700 (epoch 42.870), train_loss = 3.21164106, grad/param norm = 4.3524e-01, time/batch = 0.2272s	
2316/2700 (epoch 42.889), train_loss = 3.25086153, grad/param norm = 5.6182e-01, time/batch = 0.1865s	
2317/2700 (epoch 42.907), train_loss = 3.30383276, grad/param norm = 8.2992e-01, time/batch = 0.2403s	
2318/2700 (epoch 42.926), train_loss = 3.25213266, grad/param norm = 8.0499e-01, time/batch = 0.2260s	
2319/2700 (epoch 42.944), train_loss = 3.26184747, grad/param norm = 7.1395e-01, time/batch = 0.2428s	
2320/2700 (epoch 42.963), train_loss = 3.34116261, grad/param norm = 6.8067e-01, time/batch = 0.2390s	
2321/2700 (epoch 42.981), train_loss = 3.40217081, grad/param norm = 7.2633e-01, time/batch = 0.2315s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
2322/2700 (epoch 43.000), train_loss = 3.29987653, grad/param norm = 7.5068e-01, time/batch = 0.2563s	
2323/2700 (epoch 43.019), train_loss = 3.24056305, grad/param norm = 8.6158e-01, time/batch = 0.2524s	
2324/2700 (epoch 43.037), train_loss = 3.25639458, grad/param norm = 7.1120e-01, time/batch = 0.2490s	
2325/2700 (epoch 43.056), train_loss = 3.25879934, grad/param norm = 5.5408e-01, time/batch = 0.2480s	
2326/2700 (epoch 43.074), train_loss = 3.28938225, grad/param norm = 7.1979e-01, time/batch = 0.2368s	
2327/2700 (epoch 43.093), train_loss = 3.29412464, grad/param norm = 8.0752e-01, time/batch = 0.2337s	
2328/2700 (epoch 43.111), train_loss = 3.26515561, grad/param norm = 6.7889e-01, time/batch = 0.2394s	
2329/2700 (epoch 43.130), train_loss = 3.28099738, grad/param norm = 6.2854e-01, time/batch = 0.2313s	
2330/2700 (epoch 43.148), train_loss = 3.24503484, grad/param norm = 7.0231e-01, time/batch = 0.2299s	
2331/2700 (epoch 43.167), train_loss = 3.25400795, grad/param norm = 8.6257e-01, time/batch = 0.2600s	
2332/2700 (epoch 43.185), train_loss = 3.23872712, grad/param norm = 5.4734e-01, time/batch = 0.2567s	
2333/2700 (epoch 43.204), train_loss = 3.17513786, grad/param norm = 6.7703e-01, time/batch = 0.2567s	
2334/2700 (epoch 43.222), train_loss = 3.15107235, grad/param norm = 8.8416e-01, time/batch = 0.2573s	
2335/2700 (epoch 43.241), train_loss = 3.17022872, grad/param norm = 7.6625e-01, time/batch = 0.2477s	
2336/2700 (epoch 43.259), train_loss = 3.20389047, grad/param norm = 8.2798e-01, time/batch = 0.2405s	
2337/2700 (epoch 43.278), train_loss = 3.27722598, grad/param norm = 7.8563e-01, time/batch = 0.2069s	
2338/2700 (epoch 43.296), train_loss = 3.28035203, grad/param norm = 8.8093e-01, time/batch = 0.2403s	
2339/2700 (epoch 43.315), train_loss = 3.25609426, grad/param norm = 8.2598e-01, time/batch = 0.2446s	
2340/2700 (epoch 43.333), train_loss = 3.33714042, grad/param norm = 7.5386e-01, time/batch = 0.2352s	
2341/2700 (epoch 43.352), train_loss = 3.34230063, grad/param norm = 7.6829e-01, time/batch = 0.2310s	
2342/2700 (epoch 43.370), train_loss = 3.28455826, grad/param norm = 6.9210e-01, time/batch = 0.2376s	
2343/2700 (epoch 43.389), train_loss = 3.25170662, grad/param norm = 5.0043e-01, time/batch = 0.2424s	
2344/2700 (epoch 43.407), train_loss = 3.27392559, grad/param norm = 5.3073e-01, time/batch = 0.2469s	
2345/2700 (epoch 43.426), train_loss = 3.27637840, grad/param norm = 5.5670e-01, time/batch = 0.2520s	
2346/2700 (epoch 43.444), train_loss = 3.20686924, grad/param norm = 5.0874e-01, time/batch = 0.2546s	
2347/2700 (epoch 43.463), train_loss = 3.24808028, grad/param norm = 6.2454e-01, time/batch = 0.2404s	
2348/2700 (epoch 43.481), train_loss = 3.32572690, grad/param norm = 6.7898e-01, time/batch = 0.2584s	
2349/2700 (epoch 43.500), train_loss = 3.37084527, grad/param norm = 9.6713e-01, time/batch = 0.2563s	
2350/2700 (epoch 43.519), train_loss = 3.32355253, grad/param norm = 8.3535e-01, time/batch = 0.2458s	
2351/2700 (epoch 43.537), train_loss = 3.32665206, grad/param norm = 8.2524e-01, time/batch = 0.2393s	
2352/2700 (epoch 43.556), train_loss = 3.26152612, grad/param norm = 6.1907e-01, time/batch = 0.2348s	
2353/2700 (epoch 43.574), train_loss = 3.23138764, grad/param norm = 6.4505e-01, time/batch = 0.2324s	
2354/2700 (epoch 43.593), train_loss = 3.22955657, grad/param norm = 7.6010e-01, time/batch = 0.2359s	
2355/2700 (epoch 43.611), train_loss = 3.17052907, grad/param norm = 4.7268e-01, time/batch = 0.2410s	
2356/2700 (epoch 43.630), train_loss = 3.21178343, grad/param norm = 5.8603e-01, time/batch = 0.2277s	
2357/2700 (epoch 43.648), train_loss = 3.28003340, grad/param norm = 6.2588e-01, time/batch = 0.2101s	
2358/2700 (epoch 43.667), train_loss = 3.21340449, grad/param norm = 5.2039e-01, time/batch = 0.2023s	
2359/2700 (epoch 43.685), train_loss = 3.21080695, grad/param norm = 6.0971e-01, time/batch = 0.2324s	
2360/2700 (epoch 43.704), train_loss = 3.18340887, grad/param norm = 8.0298e-01, time/batch = 0.2467s	
2361/2700 (epoch 43.722), train_loss = 3.17458842, grad/param norm = 6.3884e-01, time/batch = 0.2458s	
2362/2700 (epoch 43.741), train_loss = 3.30972797, grad/param norm = 9.5971e-01, time/batch = 0.2518s	
2363/2700 (epoch 43.759), train_loss = 3.25740909, grad/param norm = 9.4506e-01, time/batch = 0.2603s	
2364/2700 (epoch 43.778), train_loss = 3.24784589, grad/param norm = 7.5974e-01, time/batch = 0.2587s	
2365/2700 (epoch 43.796), train_loss = 3.24015800, grad/param norm = 7.1862e-01, time/batch = 0.2575s	
2366/2700 (epoch 43.815), train_loss = 3.19275762, grad/param norm = 5.3589e-01, time/batch = 0.2391s	
2367/2700 (epoch 43.833), train_loss = 3.23010964, grad/param norm = 5.5680e-01, time/batch = 0.2446s	
2368/2700 (epoch 43.852), train_loss = 3.21723017, grad/param norm = 5.9475e-01, time/batch = 0.2349s	
2369/2700 (epoch 43.870), train_loss = 3.21138704, grad/param norm = 4.3198e-01, time/batch = 0.2232s	
2370/2700 (epoch 43.889), train_loss = 3.25075453, grad/param norm = 5.6126e-01, time/batch = 0.2598s	
2371/2700 (epoch 43.907), train_loss = 3.30359010, grad/param norm = 8.2370e-01, time/batch = 0.2457s	
2372/2700 (epoch 43.926), train_loss = 3.25170750, grad/param norm = 7.9273e-01, time/batch = 0.2378s	
2373/2700 (epoch 43.944), train_loss = 3.26147290, grad/param norm = 7.0227e-01, time/batch = 0.2419s	
2374/2700 (epoch 43.963), train_loss = 3.34087934, grad/param norm = 6.6676e-01, time/batch = 0.2443s	
2375/2700 (epoch 43.981), train_loss = 3.40205647, grad/param norm = 7.1923e-01, time/batch = 0.2487s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
2376/2700 (epoch 44.000), train_loss = 3.29945754, grad/param norm = 7.3954e-01, time/batch = 0.2482s	
2377/2700 (epoch 44.019), train_loss = 3.23997212, grad/param norm = 8.4747e-01, time/batch = 0.2491s	
2378/2700 (epoch 44.037), train_loss = 3.25595503, grad/param norm = 6.9211e-01, time/batch = 0.2417s	
2379/2700 (epoch 44.056), train_loss = 3.25879234, grad/param norm = 5.5906e-01, time/batch = 0.2124s	
2380/2700 (epoch 44.074), train_loss = 3.28931239, grad/param norm = 7.3781e-01, time/batch = 0.2534s	
2381/2700 (epoch 44.093), train_loss = 3.29392546, grad/param norm = 8.1722e-01, time/batch = 0.2323s	
2382/2700 (epoch 44.111), train_loss = 3.26490684, grad/param norm = 6.7386e-01, time/batch = 0.2429s	
2383/2700 (epoch 44.130), train_loss = 3.28063511, grad/param norm = 6.2090e-01, time/batch = 0.2516s	
2384/2700 (epoch 44.148), train_loss = 3.24475530, grad/param norm = 6.8649e-01, time/batch = 0.2567s	
2385/2700 (epoch 44.167), train_loss = 3.25346845, grad/param norm = 8.4258e-01, time/batch = 0.2588s	
2386/2700 (epoch 44.185), train_loss = 3.23835658, grad/param norm = 5.2584e-01, time/batch = 0.2578s	
2387/2700 (epoch 44.204), train_loss = 3.17482953, grad/param norm = 6.5023e-01, time/batch = 0.2566s	
2388/2700 (epoch 44.222), train_loss = 3.15054070, grad/param norm = 8.5651e-01, time/batch = 0.2522s	
2389/2700 (epoch 44.241), train_loss = 3.16962937, grad/param norm = 7.1779e-01, time/batch = 0.2462s	
2390/2700 (epoch 44.259), train_loss = 3.20326880, grad/param norm = 7.7839e-01, time/batch = 0.2418s	
2391/2700 (epoch 44.278), train_loss = 3.27669267, grad/param norm = 7.5601e-01, time/batch = 0.2344s	
2392/2700 (epoch 44.296), train_loss = 3.27982156, grad/param norm = 8.5832e-01, time/batch = 0.2337s	
2393/2700 (epoch 44.315), train_loss = 3.25572633, grad/param norm = 8.1633e-01, time/batch = 0.2274s	
2394/2700 (epoch 44.333), train_loss = 3.33698824, grad/param norm = 7.5597e-01, time/batch = 0.2332s	
2395/2700 (epoch 44.352), train_loss = 3.34206269, grad/param norm = 7.7019e-01, time/batch = 0.2275s	
2396/2700 (epoch 44.370), train_loss = 3.28420550, grad/param norm = 6.8548e-01, time/batch = 0.2270s	
2397/2700 (epoch 44.389), train_loss = 3.25153084, grad/param norm = 4.9242e-01, time/batch = 0.2157s	
2398/2700 (epoch 44.407), train_loss = 3.27372216, grad/param norm = 5.2698e-01, time/batch = 0.2142s	
2399/2700 (epoch 44.426), train_loss = 3.27611341, grad/param norm = 5.5142e-01, time/batch = 0.2271s	
2400/2700 (epoch 44.444), train_loss = 3.20684279, grad/param norm = 5.0454e-01, time/batch = 0.2281s	
2401/2700 (epoch 44.463), train_loss = 3.24787098, grad/param norm = 6.1861e-01, time/batch = 0.2605s	
2402/2700 (epoch 44.481), train_loss = 3.32563914, grad/param norm = 6.7845e-01, time/batch = 0.2579s	
2403/2700 (epoch 44.500), train_loss = 3.37041680, grad/param norm = 9.6062e-01, time/batch = 0.2584s	
2404/2700 (epoch 44.519), train_loss = 3.32320115, grad/param norm = 8.2265e-01, time/batch = 0.2564s	
2405/2700 (epoch 44.537), train_loss = 3.32638732, grad/param norm = 8.1526e-01, time/batch = 0.2552s	
2406/2700 (epoch 44.556), train_loss = 3.26117027, grad/param norm = 6.0842e-01, time/batch = 0.2572s	
2407/2700 (epoch 44.574), train_loss = 3.23128057, grad/param norm = 6.3999e-01, time/batch = 0.2537s	
2408/2700 (epoch 44.593), train_loss = 3.22917987, grad/param norm = 7.4892e-01, time/batch = 0.2558s	
2409/2700 (epoch 44.611), train_loss = 3.17043002, grad/param norm = 4.6548e-01, time/batch = 0.2590s	
2410/2700 (epoch 44.630), train_loss = 3.21165192, grad/param norm = 5.7898e-01, time/batch = 0.2532s	
2411/2700 (epoch 44.648), train_loss = 3.27954823, grad/param norm = 6.1694e-01, time/batch = 0.2229s	
2412/2700 (epoch 44.667), train_loss = 3.21312796, grad/param norm = 5.1192e-01, time/batch = 0.2287s	
2413/2700 (epoch 44.685), train_loss = 3.21069720, grad/param norm = 6.1069e-01, time/batch = 0.2259s	
2414/2700 (epoch 44.704), train_loss = 3.18322067, grad/param norm = 8.0285e-01, time/batch = 0.2191s	
2415/2700 (epoch 44.722), train_loss = 3.17438107, grad/param norm = 6.3689e-01, time/batch = 0.1898s	
2416/2700 (epoch 44.741), train_loss = 3.30950727, grad/param norm = 9.5586e-01, time/batch = 0.2202s	
2417/2700 (epoch 44.759), train_loss = 3.25687178, grad/param norm = 9.2603e-01, time/batch = 0.2249s	
2418/2700 (epoch 44.778), train_loss = 3.24738076, grad/param norm = 7.4256e-01, time/batch = 0.2357s	
2419/2700 (epoch 44.796), train_loss = 3.23970219, grad/param norm = 7.0232e-01, time/batch = 0.2431s	
2420/2700 (epoch 44.815), train_loss = 3.19242705, grad/param norm = 5.2501e-01, time/batch = 0.2496s	
2421/2700 (epoch 44.833), train_loss = 3.22986966, grad/param norm = 5.5361e-01, time/batch = 0.2133s	
2422/2700 (epoch 44.852), train_loss = 3.21695866, grad/param norm = 5.9003e-01, time/batch = 0.2342s	
2423/2700 (epoch 44.870), train_loss = 3.21111516, grad/param norm = 4.2374e-01, time/batch = 0.2323s	
2424/2700 (epoch 44.889), train_loss = 3.25059323, grad/param norm = 5.5423e-01, time/batch = 0.2373s	
2425/2700 (epoch 44.907), train_loss = 3.30328928, grad/param norm = 8.1097e-01, time/batch = 0.2244s	
2426/2700 (epoch 44.926), train_loss = 3.25123573, grad/param norm = 7.7463e-01, time/batch = 0.2461s	
2427/2700 (epoch 44.944), train_loss = 3.26107977, grad/param norm = 6.8767e-01, time/batch = 0.2489s	
2428/2700 (epoch 44.963), train_loss = 3.34059459, grad/param norm = 6.5144e-01, time/batch = 0.2356s	
2429/2700 (epoch 44.981), train_loss = 3.40197338, grad/param norm = 7.1311e-01, time/batch = 0.2275s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
2430/2700 (epoch 45.000), train_loss = 3.29903981, grad/param norm = 7.2744e-01, time/batch = 0.2184s	
2431/2700 (epoch 45.019), train_loss = 3.23935659, grad/param norm = 8.3155e-01, time/batch = 0.2562s	
2432/2700 (epoch 45.037), train_loss = 3.25551565, grad/param norm = 6.7190e-01, time/batch = 0.2241s	
2433/2700 (epoch 45.056), train_loss = 3.25884012, grad/param norm = 5.6992e-01, time/batch = 0.2138s	
2434/2700 (epoch 45.074), train_loss = 3.28935343, grad/param norm = 7.6661e-01, time/batch = 0.2059s	
2435/2700 (epoch 45.093), train_loss = 3.29382256, grad/param norm = 8.3365e-01, time/batch = 0.2151s	
2436/2700 (epoch 45.111), train_loss = 3.26467324, grad/param norm = 6.6887e-01, time/batch = 0.2249s	
2437/2700 (epoch 45.130), train_loss = 3.28027287, grad/param norm = 6.1167e-01, time/batch = 0.2368s	
2438/2700 (epoch 45.148), train_loss = 3.24447490, grad/param norm = 6.6989e-01, time/batch = 0.2495s	
2439/2700 (epoch 45.167), train_loss = 3.25293104, grad/param norm = 8.2133e-01, time/batch = 0.2590s	
2440/2700 (epoch 45.185), train_loss = 3.23800622, grad/param norm = 5.0487e-01, time/batch = 0.2557s	
2441/2700 (epoch 45.204), train_loss = 3.17453809, grad/param norm = 6.2368e-01, time/batch = 0.2420s	
2442/2700 (epoch 45.222), train_loss = 3.15003590, grad/param norm = 8.3034e-01, time/batch = 0.2453s	
2443/2700 (epoch 45.241), train_loss = 3.16905445, grad/param norm = 6.6769e-01, time/batch = 0.2601s	
2444/2700 (epoch 45.259), train_loss = 3.20262118, grad/param norm = 7.2108e-01, time/batch = 0.2524s	
2445/2700 (epoch 45.278), train_loss = 3.27610768, grad/param norm = 7.1925e-01, time/batch = 0.2575s	
2446/2700 (epoch 45.296), train_loss = 3.27920175, grad/param norm = 8.2627e-01, time/batch = 0.2599s	
2447/2700 (epoch 45.315), train_loss = 3.25532371, grad/param norm = 8.0288e-01, time/batch = 0.2579s	
2448/2700 (epoch 45.333), train_loss = 3.33687003, grad/param norm = 7.6088e-01, time/batch = 0.2566s	
2449/2700 (epoch 45.352), train_loss = 3.34187479, grad/param norm = 7.7574e-01, time/batch = 0.2592s	
2450/2700 (epoch 45.370), train_loss = 3.28387659, grad/param norm = 6.7993e-01, time/batch = 0.2479s	
2451/2700 (epoch 45.389), train_loss = 3.25136558, grad/param norm = 4.8491e-01, time/batch = 0.2433s	
2452/2700 (epoch 45.407), train_loss = 3.27352618, grad/param norm = 5.2294e-01, time/batch = 0.2293s	
2453/2700 (epoch 45.426), train_loss = 3.27585634, grad/param norm = 5.4631e-01, time/batch = 0.2356s	
2454/2700 (epoch 45.444), train_loss = 3.20681780, grad/param norm = 4.9990e-01, time/batch = 0.2169s	
2455/2700 (epoch 45.463), train_loss = 3.24765609, grad/param norm = 6.1139e-01, time/batch = 0.2389s	
2456/2700 (epoch 45.481), train_loss = 3.32554534, grad/param norm = 6.7688e-01, time/batch = 0.2350s	
2457/2700 (epoch 45.500), train_loss = 3.36999835, grad/param norm = 9.5455e-01, time/batch = 0.2223s	
2458/2700 (epoch 45.519), train_loss = 3.32290190, grad/param norm = 8.1276e-01, time/batch = 0.2239s	
2459/2700 (epoch 45.537), train_loss = 3.32616397, grad/param norm = 8.0783e-01, time/batch = 0.2279s	
2460/2700 (epoch 45.556), train_loss = 3.26083932, grad/param norm = 5.9950e-01, time/batch = 0.2341s	
2461/2700 (epoch 45.574), train_loss = 3.23117952, grad/param norm = 6.3539e-01, time/batch = 0.2150s	
2462/2700 (epoch 45.593), train_loss = 3.22881552, grad/param norm = 7.3812e-01, time/batch = 0.2158s	
2463/2700 (epoch 45.611), train_loss = 3.17035127, grad/param norm = 4.5918e-01, time/batch = 0.2107s	
2464/2700 (epoch 45.630), train_loss = 3.21153230, grad/param norm = 5.7250e-01, time/batch = 0.2216s	
2465/2700 (epoch 45.648), train_loss = 3.27907730, grad/param norm = 6.0860e-01, time/batch = 0.2308s	
2466/2700 (epoch 45.667), train_loss = 3.21286994, grad/param norm = 5.0399e-01, time/batch = 0.2326s	
2467/2700 (epoch 45.685), train_loss = 3.21059149, grad/param norm = 6.1085e-01, time/batch = 0.1881s	
2468/2700 (epoch 45.704), train_loss = 3.18302563, grad/param norm = 8.0090e-01, time/batch = 0.1887s	
2469/2700 (epoch 45.722), train_loss = 3.17415194, grad/param norm = 6.3100e-01, time/batch = 0.1879s	
2470/2700 (epoch 45.741), train_loss = 3.30924593, grad/param norm = 9.4743e-01, time/batch = 0.1801s	
2471/2700 (epoch 45.759), train_loss = 3.25634843, grad/param norm = 9.0697e-01, time/batch = 0.1806s	
2472/2700 (epoch 45.778), train_loss = 3.24695848, grad/param norm = 7.2724e-01, time/batch = 0.1843s	
2473/2700 (epoch 45.796), train_loss = 3.23928159, grad/param norm = 6.8748e-01, time/batch = 0.1907s	
2474/2700 (epoch 45.815), train_loss = 3.19212488, grad/param norm = 5.1523e-01, time/batch = 0.1550s	
2475/2700 (epoch 45.833), train_loss = 3.22963686, grad/param norm = 5.5019e-01, time/batch = 0.1633s	
2476/2700 (epoch 45.852), train_loss = 3.21669334, grad/param norm = 5.8455e-01, time/batch = 0.1585s	
2477/2700 (epoch 45.870), train_loss = 3.21085952, grad/param norm = 4.1527e-01, time/batch = 0.1628s	
2478/2700 (epoch 45.889), train_loss = 3.25043887, grad/param norm = 5.4761e-01, time/batch = 0.1593s	
2479/2700 (epoch 45.907), train_loss = 3.30300958, grad/param norm = 7.9954e-01, time/batch = 0.1693s	
2480/2700 (epoch 45.926), train_loss = 3.25081059, grad/param norm = 7.5895e-01, time/batch = 0.1835s	
2481/2700 (epoch 45.944), train_loss = 3.26071320, grad/param norm = 6.7509e-01, time/batch = 0.1857s	
2482/2700 (epoch 45.963), train_loss = 3.34033625, grad/param norm = 6.3822e-01, time/batch = 0.1916s	
2483/2700 (epoch 45.981), train_loss = 3.40191451, grad/param norm = 7.0890e-01, time/batch = 0.1932s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
2484/2700 (epoch 46.000), train_loss = 3.29864088, grad/param norm = 7.1721e-01, time/batch = 0.1678s	
2485/2700 (epoch 46.019), train_loss = 3.23879074, grad/param norm = 8.1877e-01, time/batch = 0.1907s	
2486/2700 (epoch 46.037), train_loss = 3.25512479, grad/param norm = 6.5546e-01, time/batch = 0.1904s	
2487/2700 (epoch 46.056), train_loss = 3.25890028, grad/param norm = 5.8101e-01, time/batch = 0.1911s	
2488/2700 (epoch 46.074), train_loss = 3.28934843, grad/param norm = 7.8941e-01, time/batch = 0.1865s	
2489/2700 (epoch 46.093), train_loss = 3.29362331, grad/param norm = 8.4093e-01, time/batch = 0.1877s	
2490/2700 (epoch 46.111), train_loss = 3.26439710, grad/param norm = 6.5651e-01, time/batch = 0.1839s	
2491/2700 (epoch 46.130), train_loss = 3.27992178, grad/param norm = 6.0022e-01, time/batch = 0.1891s	
2492/2700 (epoch 46.148), train_loss = 3.24423486, grad/param norm = 6.5557e-01, time/batch = 0.1892s	
2493/2700 (epoch 46.167), train_loss = 3.25243277, grad/param norm = 8.0105e-01, time/batch = 0.1806s	
2494/2700 (epoch 46.185), train_loss = 3.23769814, grad/param norm = 4.8740e-01, time/batch = 0.1883s	
2495/2700 (epoch 46.204), train_loss = 3.17429890, grad/param norm = 6.0222e-01, time/batch = 0.1662s	
2496/2700 (epoch 46.222), train_loss = 3.14960037, grad/param norm = 8.0968e-01, time/batch = 0.1633s	
2497/2700 (epoch 46.241), train_loss = 3.16862628, grad/param norm = 6.3012e-01, time/batch = 0.1676s	
2498/2700 (epoch 46.259), train_loss = 3.20212248, grad/param norm = 6.7707e-01, time/batch = 0.1763s	
2499/2700 (epoch 46.278), train_loss = 3.27559841, grad/param norm = 6.8662e-01, time/batch = 0.1834s	
2500/2700 (epoch 46.296), train_loss = 3.27857493, grad/param norm = 7.9064e-01, time/batch = 0.1895s	
2501/2700 (epoch 46.315), train_loss = 3.25485568, grad/param norm = 7.8249e-01, time/batch = 0.1761s	
2502/2700 (epoch 46.333), train_loss = 3.33671382, grad/param norm = 7.6047e-01, time/batch = 0.1823s	
2503/2700 (epoch 46.352), train_loss = 3.34165836, grad/param norm = 7.7867e-01, time/batch = 0.1768s	
2504/2700 (epoch 46.370), train_loss = 3.28355111, grad/param norm = 6.7414e-01, time/batch = 0.1884s	
2505/2700 (epoch 46.389), train_loss = 3.25121462, grad/param norm = 4.7806e-01, time/batch = 0.1786s	
2506/2700 (epoch 46.407), train_loss = 3.27334275, grad/param norm = 5.1961e-01, time/batch = 0.1907s	
2507/2700 (epoch 46.426), train_loss = 3.27560780, grad/param norm = 5.4137e-01, time/batch = 0.1909s	
2508/2700 (epoch 46.444), train_loss = 3.20680108, grad/param norm = 4.9593e-01, time/batch = 0.1915s	
2509/2700 (epoch 46.463), train_loss = 3.24744579, grad/param norm = 6.0447e-01, time/batch = 0.1864s	
2510/2700 (epoch 46.481), train_loss = 3.32545602, grad/param norm = 6.7534e-01, time/batch = 0.1862s	
2511/2700 (epoch 46.500), train_loss = 3.36957963, grad/param norm = 9.4815e-01, time/batch = 0.1899s	
2512/2700 (epoch 46.519), train_loss = 3.32261508, grad/param norm = 8.0277e-01, time/batch = 0.1883s	
2513/2700 (epoch 46.537), train_loss = 3.32594892, grad/param norm = 8.0005e-01, time/batch = 0.1801s	
2514/2700 (epoch 46.556), train_loss = 3.26051629, grad/param norm = 5.8995e-01, time/batch = 0.1893s	
2515/2700 (epoch 46.574), train_loss = 3.23108106, grad/param norm = 6.3100e-01, time/batch = 0.1840s	
2516/2700 (epoch 46.593), train_loss = 3.22846126, grad/param norm = 7.2744e-01, time/batch = 0.1457s	
2517/2700 (epoch 46.611), train_loss = 3.17028900, grad/param norm = 4.5385e-01, time/batch = 0.1792s	
2518/2700 (epoch 46.630), train_loss = 3.21141806, grad/param norm = 5.6601e-01, time/batch = 0.1860s	
2519/2700 (epoch 46.648), train_loss = 3.27861879, grad/param norm = 6.0060e-01, time/batch = 0.1896s	
2520/2700 (epoch 46.667), train_loss = 3.21262908, grad/param norm = 4.9656e-01, time/batch = 0.1886s	
2521/2700 (epoch 46.685), train_loss = 3.21049428, grad/param norm = 6.1136e-01, time/batch = 0.1804s	
2522/2700 (epoch 46.704), train_loss = 3.18283856, grad/param norm = 7.9879e-01, time/batch = 0.1874s	
2523/2700 (epoch 46.722), train_loss = 3.17392476, grad/param norm = 6.2417e-01, time/batch = 0.1831s	
2524/2700 (epoch 46.741), train_loss = 3.30897336, grad/param norm = 9.3743e-01, time/batch = 0.1916s	
2525/2700 (epoch 46.759), train_loss = 3.25584036, grad/param norm = 8.8786e-01, time/batch = 0.1899s	
2526/2700 (epoch 46.778), train_loss = 3.24656339, grad/param norm = 7.1291e-01, time/batch = 0.1754s	
2527/2700 (epoch 46.796), train_loss = 3.23888874, grad/param norm = 6.7354e-01, time/batch = 0.1850s	
2528/2700 (epoch 46.815), train_loss = 3.19184733, grad/param norm = 5.0655e-01, time/batch = 0.1754s	
2529/2700 (epoch 46.833), train_loss = 3.22941446, grad/param norm = 5.4689e-01, time/batch = 0.1682s	
2530/2700 (epoch 46.852), train_loss = 3.21643696, grad/param norm = 5.7880e-01, time/batch = 0.1652s	
2531/2700 (epoch 46.870), train_loss = 3.21061944, grad/param norm = 4.0683e-01, time/batch = 0.1577s	
2532/2700 (epoch 46.889), train_loss = 3.25029015, grad/param norm = 5.4112e-01, time/batch = 0.1585s	
2533/2700 (epoch 46.907), train_loss = 3.30274224, grad/param norm = 7.8865e-01, time/batch = 0.1393s	
2534/2700 (epoch 46.926), train_loss = 3.25041695, grad/param norm = 7.4449e-01, time/batch = 0.1808s	
2535/2700 (epoch 46.944), train_loss = 3.26036787, grad/param norm = 6.6353e-01, time/batch = 0.1898s	
2536/2700 (epoch 46.963), train_loss = 3.34009739, grad/param norm = 6.2631e-01, time/batch = 0.1913s	
2537/2700 (epoch 46.981), train_loss = 3.40187473, grad/param norm = 7.0597e-01, time/batch = 0.1705s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
2538/2700 (epoch 47.000), train_loss = 3.29825522, grad/param norm = 7.0788e-01, time/batch = 0.1865s	
2539/2700 (epoch 47.019), train_loss = 3.23825423, grad/param norm = 8.0764e-01, time/batch = 0.1837s	
2540/2700 (epoch 47.037), train_loss = 3.25476467, grad/param norm = 6.4122e-01, time/batch = 0.1763s	
2541/2700 (epoch 47.056), train_loss = 3.25896797, grad/param norm = 5.9227e-01, time/batch = 0.1745s	
2542/2700 (epoch 47.074), train_loss = 3.28931015, grad/param norm = 8.0803e-01, time/batch = 0.1652s	
2543/2700 (epoch 47.093), train_loss = 3.29335612, grad/param norm = 8.4177e-01, time/batch = 0.1278s	
2544/2700 (epoch 47.111), train_loss = 3.26410849, grad/param norm = 6.4040e-01, time/batch = 0.1641s	
2545/2700 (epoch 47.130), train_loss = 3.27959646, grad/param norm = 5.8906e-01, time/batch = 0.1689s	
2546/2700 (epoch 47.148), train_loss = 3.24402804, grad/param norm = 6.4361e-01, time/batch = 0.1764s	
2547/2700 (epoch 47.167), train_loss = 3.25197474, grad/param norm = 7.8261e-01, time/batch = 0.1850s	
2548/2700 (epoch 47.185), train_loss = 3.23742948, grad/param norm = 4.7364e-01, time/batch = 0.1784s	
2549/2700 (epoch 47.204), train_loss = 3.17410090, grad/param norm = 5.8522e-01, time/batch = 0.1909s	
2550/2700 (epoch 47.222), train_loss = 3.14922361, grad/param norm = 7.9307e-01, time/batch = 0.1883s	
2551/2700 (epoch 47.241), train_loss = 3.16829536, grad/param norm = 6.0136e-01, time/batch = 0.1808s	
2552/2700 (epoch 47.259), train_loss = 3.20172308, grad/param norm = 6.4274e-01, time/batch = 0.1778s	
2553/2700 (epoch 47.278), train_loss = 3.27515165, grad/param norm = 6.5772e-01, time/batch = 0.1624s	
2554/2700 (epoch 47.296), train_loss = 3.27795658, grad/param norm = 7.5293e-01, time/batch = 0.1881s	
2555/2700 (epoch 47.315), train_loss = 3.25433704, grad/param norm = 7.5597e-01, time/batch = 0.1890s	
2556/2700 (epoch 47.333), train_loss = 3.33651574, grad/param norm = 7.5419e-01, time/batch = 0.1897s	
2557/2700 (epoch 47.352), train_loss = 3.34140942, grad/param norm = 7.7857e-01, time/batch = 0.1862s	
2558/2700 (epoch 47.370), train_loss = 3.28322930, grad/param norm = 6.6809e-01, time/batch = 0.1851s	
2559/2700 (epoch 47.389), train_loss = 3.25107586, grad/param norm = 4.7173e-01, time/batch = 0.1430s	
2560/2700 (epoch 47.407), train_loss = 3.27317123, grad/param norm = 5.1686e-01, time/batch = 0.1888s	
2561/2700 (epoch 47.426), train_loss = 3.27536901, grad/param norm = 5.3655e-01, time/batch = 0.1757s	
2562/2700 (epoch 47.444), train_loss = 3.20678988, grad/param norm = 4.9250e-01, time/batch = 0.1801s	
2563/2700 (epoch 47.463), train_loss = 3.24723829, grad/param norm = 5.9779e-01, time/batch = 0.1717s	
2564/2700 (epoch 47.481), train_loss = 3.32537233, grad/param norm = 6.7409e-01, time/batch = 0.1903s	
2565/2700 (epoch 47.500), train_loss = 3.36917249, grad/param norm = 9.4215e-01, time/batch = 0.1899s	
2566/2700 (epoch 47.519), train_loss = 3.32235142, grad/param norm = 7.9357e-01, time/batch = 0.1892s	
2567/2700 (epoch 47.537), train_loss = 3.32574643, grad/param norm = 7.9242e-01, time/batch = 0.1862s	
2568/2700 (epoch 47.556), train_loss = 3.26020178, grad/param norm = 5.8024e-01, time/batch = 0.1811s	
2569/2700 (epoch 47.574), train_loss = 3.23098826, grad/param norm = 6.2689e-01, time/batch = 0.1679s	
2570/2700 (epoch 47.593), train_loss = 3.22811640, grad/param norm = 7.1692e-01, time/batch = 0.1735s	
2571/2700 (epoch 47.611), train_loss = 3.17024190, grad/param norm = 4.4937e-01, time/batch = 0.1903s	
2572/2700 (epoch 47.630), train_loss = 3.21130906, grad/param norm = 5.5955e-01, time/batch = 0.1870s	
2573/2700 (epoch 47.648), train_loss = 3.27817451, grad/param norm = 5.9298e-01, time/batch = 0.1866s	
2574/2700 (epoch 47.667), train_loss = 3.21240650, grad/param norm = 4.8960e-01, time/batch = 0.1872s	
2575/2700 (epoch 47.685), train_loss = 3.21040201, grad/param norm = 6.1188e-01, time/batch = 0.1852s	
2576/2700 (epoch 47.704), train_loss = 3.18265486, grad/param norm = 7.9609e-01, time/batch = 0.1771s	
2577/2700 (epoch 47.722), train_loss = 3.17369419, grad/param norm = 6.1579e-01, time/batch = 0.1661s	
2578/2700 (epoch 47.741), train_loss = 3.30868700, grad/param norm = 9.2560e-01, time/batch = 0.1720s	
2579/2700 (epoch 47.759), train_loss = 3.25535111, grad/param norm = 8.6895e-01, time/batch = 0.1654s	
2580/2700 (epoch 47.778), train_loss = 3.24619344, grad/param norm = 6.9953e-01, time/batch = 0.1530s	
2581/2700 (epoch 47.796), train_loss = 3.23852051, grad/param norm = 6.6036e-01, time/batch = 0.1915s	
2582/2700 (epoch 47.815), train_loss = 3.19159249, grad/param norm = 4.9883e-01, time/batch = 0.1782s	
2583/2700 (epoch 47.833), train_loss = 3.22920027, grad/param norm = 5.4364e-01, time/batch = 0.1901s	
2584/2700 (epoch 47.852), train_loss = 3.21619153, grad/param norm = 5.7287e-01, time/batch = 0.1892s	
2585/2700 (epoch 47.870), train_loss = 3.21039602, grad/param norm = 3.9861e-01, time/batch = 0.1897s	
2586/2700 (epoch 47.889), train_loss = 3.25014697, grad/param norm = 5.3496e-01, time/batch = 0.1884s	
2587/2700 (epoch 47.907), train_loss = 3.30248882, grad/param norm = 7.7844e-01, time/batch = 0.1908s	
2588/2700 (epoch 47.926), train_loss = 3.25005436, grad/param norm = 7.3130e-01, time/batch = 0.1892s	
2589/2700 (epoch 47.944), train_loss = 3.26003910, grad/param norm = 6.5286e-01, time/batch = 0.1915s	
2590/2700 (epoch 47.963), train_loss = 3.33987765, grad/param norm = 6.1552e-01, time/batch = 0.1875s	
2591/2700 (epoch 47.981), train_loss = 3.40184952, grad/param norm = 7.0395e-01, time/batch = 0.1891s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
2592/2700 (epoch 48.000), train_loss = 3.29787655, grad/param norm = 6.9914e-01, time/batch = 0.1795s	
2593/2700 (epoch 48.019), train_loss = 3.23774456, grad/param norm = 7.9785e-01, time/batch = 0.1901s	
2594/2700 (epoch 48.037), train_loss = 3.25442882, grad/param norm = 6.2865e-01, time/batch = 0.1852s	
2595/2700 (epoch 48.056), train_loss = 3.25903594, grad/param norm = 6.0270e-01, time/batch = 0.1872s	
2596/2700 (epoch 48.074), train_loss = 3.28923093, grad/param norm = 8.2175e-01, time/batch = 0.1781s	
2597/2700 (epoch 48.093), train_loss = 3.29302934, grad/param norm = 8.3711e-01, time/batch = 0.1709s	
2598/2700 (epoch 48.111), train_loss = 3.26382695, grad/param norm = 6.2287e-01, time/batch = 0.1650s	
2599/2700 (epoch 48.130), train_loss = 3.27930498, grad/param norm = 5.7956e-01, time/batch = 0.1656s	
2600/2700 (epoch 48.148), train_loss = 3.24384679, grad/param norm = 6.3375e-01, time/batch = 0.1715s	
2601/2700 (epoch 48.167), train_loss = 3.25155830, grad/param norm = 7.6617e-01, time/batch = 0.1511s	
2602/2700 (epoch 48.185), train_loss = 3.23719652, grad/param norm = 4.6313e-01, time/batch = 0.1780s	
2603/2700 (epoch 48.204), train_loss = 3.17393641, grad/param norm = 5.7211e-01, time/batch = 0.1896s	
2604/2700 (epoch 48.222), train_loss = 3.14889731, grad/param norm = 7.7972e-01, time/batch = 0.1887s	
2605/2700 (epoch 48.241), train_loss = 3.16804328, grad/param norm = 5.8025e-01, time/batch = 0.1894s	
2606/2700 (epoch 48.259), train_loss = 3.20141161, grad/param norm = 6.1784e-01, time/batch = 0.1912s	
2607/2700 (epoch 48.278), train_loss = 3.27477059, grad/param norm = 6.3386e-01, time/batch = 0.1898s	
2608/2700 (epoch 48.296), train_loss = 3.27738561, grad/param norm = 7.1701e-01, time/batch = 0.1909s	
2609/2700 (epoch 48.315), train_loss = 3.25380380, grad/param norm = 7.2601e-01, time/batch = 0.1897s	
2610/2700 (epoch 48.333), train_loss = 3.33627197, grad/param norm = 7.4167e-01, time/batch = 0.1903s	
2611/2700 (epoch 48.352), train_loss = 3.34111303, grad/param norm = 7.7423e-01, time/batch = 0.1761s	
2612/2700 (epoch 48.370), train_loss = 3.28290660, grad/param norm = 6.6125e-01, time/batch = 0.1721s	
2613/2700 (epoch 48.389), train_loss = 3.25094550, grad/param norm = 4.6560e-01, time/batch = 0.1755s	
2614/2700 (epoch 48.407), train_loss = 3.27301148, grad/param norm = 5.1472e-01, time/batch = 0.1687s	
2615/2700 (epoch 48.426), train_loss = 3.27513666, grad/param norm = 5.3170e-01, time/batch = 0.1683s	
2616/2700 (epoch 48.444), train_loss = 3.20678606, grad/param norm = 4.8978e-01, time/batch = 0.1658s	
2617/2700 (epoch 48.463), train_loss = 3.24703872, grad/param norm = 5.9195e-01, time/batch = 0.1715s	
2618/2700 (epoch 48.481), train_loss = 3.32530135, grad/param norm = 6.7391e-01, time/batch = 0.1778s	
2619/2700 (epoch 48.500), train_loss = 3.36878408, grad/param norm = 9.3696e-01, time/batch = 0.1870s	
2620/2700 (epoch 48.519), train_loss = 3.32210791, grad/param norm = 7.8487e-01, time/batch = 0.1873s	
2621/2700 (epoch 48.537), train_loss = 3.32554758, grad/param norm = 7.8433e-01, time/batch = 0.1792s	
2622/2700 (epoch 48.556), train_loss = 3.25989437, grad/param norm = 5.6995e-01, time/batch = 0.1436s	
2623/2700 (epoch 48.574), train_loss = 3.23089923, grad/param norm = 6.2309e-01, time/batch = 0.1863s	
2624/2700 (epoch 48.593), train_loss = 3.22778178, grad/param norm = 7.0656e-01, time/batch = 0.1822s	
2625/2700 (epoch 48.611), train_loss = 3.17020878, grad/param norm = 4.4579e-01, time/batch = 0.1746s	
2626/2700 (epoch 48.630), train_loss = 3.21120266, grad/param norm = 5.5301e-01, time/batch = 0.1653s	
2627/2700 (epoch 48.648), train_loss = 3.27774382, grad/param norm = 5.8571e-01, time/batch = 0.1645s	
2628/2700 (epoch 48.667), train_loss = 3.21219992, grad/param norm = 4.8304e-01, time/batch = 0.1677s	
2629/2700 (epoch 48.685), train_loss = 3.21031663, grad/param norm = 6.1255e-01, time/batch = 0.1768s	
2630/2700 (epoch 48.704), train_loss = 3.18247699, grad/param norm = 7.9298e-01, time/batch = 0.1834s	
2631/2700 (epoch 48.722), train_loss = 3.17346442, grad/param norm = 6.0612e-01, time/batch = 0.1726s	
2632/2700 (epoch 48.741), train_loss = 3.30838965, grad/param norm = 9.1215e-01, time/batch = 0.1734s	
2633/2700 (epoch 48.759), train_loss = 3.25487773, grad/param norm = 8.5017e-01, time/batch = 0.1676s	
2634/2700 (epoch 48.778), train_loss = 3.24584535, grad/param norm = 6.8695e-01, time/batch = 0.1868s	
2635/2700 (epoch 48.796), train_loss = 3.23817344, grad/param norm = 6.4783e-01, time/batch = 0.1867s	
2636/2700 (epoch 48.815), train_loss = 3.19135819, grad/param norm = 4.9198e-01, time/batch = 0.1879s	
2637/2700 (epoch 48.833), train_loss = 3.22899666, grad/param norm = 5.4046e-01, time/batch = 0.1799s	
2638/2700 (epoch 48.852), train_loss = 3.21595592, grad/param norm = 5.6685e-01, time/batch = 0.1717s	
2639/2700 (epoch 48.870), train_loss = 3.21018892, grad/param norm = 3.9071e-01, time/batch = 0.1641s	
2640/2700 (epoch 48.889), train_loss = 3.25000877, grad/param norm = 5.2913e-01, time/batch = 0.1658s	
2641/2700 (epoch 48.907), train_loss = 3.30224894, grad/param norm = 7.6880e-01, time/batch = 0.1618s	
2642/2700 (epoch 48.926), train_loss = 3.24971873, grad/param norm = 7.1920e-01, time/batch = 0.1585s	
2643/2700 (epoch 48.944), train_loss = 3.25972576, grad/param norm = 6.4287e-01, time/batch = 0.1675s	
2644/2700 (epoch 48.963), train_loss = 3.33967365, grad/param norm = 6.0567e-01, time/batch = 0.1553s	
2645/2700 (epoch 48.981), train_loss = 3.40183331, grad/param norm = 7.0257e-01, time/batch = 0.1863s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
2646/2700 (epoch 49.000), train_loss = 3.29750450, grad/param norm = 6.9074e-01, time/batch = 0.1903s	
2647/2700 (epoch 49.019), train_loss = 3.23725527, grad/param norm = 7.8904e-01, time/batch = 0.1877s	
2648/2700 (epoch 49.037), train_loss = 3.25411237, grad/param norm = 6.1724e-01, time/batch = 0.1913s	
2649/2700 (epoch 49.056), train_loss = 3.25909895, grad/param norm = 6.1193e-01, time/batch = 0.1732s	
2650/2700 (epoch 49.074), train_loss = 3.28911184, grad/param norm = 8.3090e-01, time/batch = 0.1663s	
2651/2700 (epoch 49.093), train_loss = 3.29266202, grad/param norm = 8.2834e-01, time/batch = 0.1864s	
2652/2700 (epoch 49.111), train_loss = 3.26356134, grad/param norm = 6.0545e-01, time/batch = 0.1786s	
2653/2700 (epoch 49.130), train_loss = 3.27904492, grad/param norm = 5.7205e-01, time/batch = 0.1834s	
2654/2700 (epoch 49.148), train_loss = 3.24368444, grad/param norm = 6.2538e-01, time/batch = 0.1763s	
2655/2700 (epoch 49.167), train_loss = 3.25117441, grad/param norm = 7.5136e-01, time/batch = 0.1531s	
2656/2700 (epoch 49.185), train_loss = 3.23699117, grad/param norm = 4.5500e-01, time/batch = 0.2089s	
2657/2700 (epoch 49.204), train_loss = 3.17379470, grad/param norm = 5.6182e-01, time/batch = 0.2080s	
2658/2700 (epoch 49.222), train_loss = 3.14860901, grad/param norm = 7.6874e-01, time/batch = 0.2083s	
2659/2700 (epoch 49.241), train_loss = 3.16784568, grad/param norm = 5.6476e-01, time/batch = 0.2072s	
2660/2700 (epoch 49.259), train_loss = 3.20116177, grad/param norm = 6.0032e-01, time/batch = 0.2068s	
2661/2700 (epoch 49.278), train_loss = 3.27444752, grad/param norm = 6.1474e-01, time/batch = 0.1996s	
2662/2700 (epoch 49.296), train_loss = 3.27687949, grad/param norm = 6.8513e-01, time/batch = 0.1824s	
2663/2700 (epoch 49.315), train_loss = 3.25329335, grad/param norm = 6.9585e-01, time/batch = 0.2067s	
2664/2700 (epoch 49.333), train_loss = 3.33600148, grad/param norm = 7.2479e-01, time/batch = 0.2070s	
2665/2700 (epoch 49.352), train_loss = 3.34077427, grad/param norm = 7.6599e-01, time/batch = 0.1977s	
2666/2700 (epoch 49.370), train_loss = 3.28258220, grad/param norm = 6.5338e-01, time/batch = 0.1992s	
2667/2700 (epoch 49.389), train_loss = 3.25082079, grad/param norm = 4.5936e-01, time/batch = 0.1922s	
2668/2700 (epoch 49.407), train_loss = 3.27286267, grad/param norm = 5.1314e-01, time/batch = 0.1745s	
2669/2700 (epoch 49.426), train_loss = 3.27490917, grad/param norm = 5.2663e-01, time/batch = 0.1731s	
2670/2700 (epoch 49.444), train_loss = 3.20678746, grad/param norm = 4.8781e-01, time/batch = 0.1606s	
2671/2700 (epoch 49.463), train_loss = 3.24685092, grad/param norm = 5.8737e-01, time/batch = 0.2015s	
2672/2700 (epoch 49.481), train_loss = 3.32524808, grad/param norm = 6.7522e-01, time/batch = 0.2072s	
2673/2700 (epoch 49.500), train_loss = 3.36841715, grad/param norm = 9.3269e-01, time/batch = 0.2073s	
2674/2700 (epoch 49.519), train_loss = 3.32187642, grad/param norm = 7.7613e-01, time/batch = 0.2077s	
2675/2700 (epoch 49.537), train_loss = 3.32534921, grad/param norm = 7.7523e-01, time/batch = 0.2062s	
2676/2700 (epoch 49.556), train_loss = 3.25959050, grad/param norm = 5.5875e-01, time/batch = 0.1899s	
2677/2700 (epoch 49.574), train_loss = 3.23081658, grad/param norm = 6.1966e-01, time/batch = 0.1830s	
2678/2700 (epoch 49.593), train_loss = 3.22745584, grad/param norm = 6.9637e-01, time/batch = 0.1748s	
2679/2700 (epoch 49.611), train_loss = 3.17018861, grad/param norm = 4.4310e-01, time/batch = 0.1713s	
2680/2700 (epoch 49.630), train_loss = 3.21109809, grad/param norm = 5.4640e-01, time/batch = 0.1787s	
2681/2700 (epoch 49.648), train_loss = 3.27732885, grad/param norm = 5.7881e-01, time/batch = 0.1910s	
2682/2700 (epoch 49.667), train_loss = 3.21200796, grad/param norm = 4.7691e-01, time/batch = 0.2036s	
2683/2700 (epoch 49.685), train_loss = 3.21023499, grad/param norm = 6.1333e-01, time/batch = 0.1977s	
2684/2700 (epoch 49.704), train_loss = 3.18230155, grad/param norm = 7.8938e-01, time/batch = 0.1900s	
2685/2700 (epoch 49.722), train_loss = 3.17323327, grad/param norm = 5.9507e-01, time/batch = 0.1824s	
2686/2700 (epoch 49.741), train_loss = 3.30808228, grad/param norm = 8.9721e-01, time/batch = 0.1582s	
2687/2700 (epoch 49.759), train_loss = 3.25442335, grad/param norm = 8.3167e-01, time/batch = 0.2074s	
2688/2700 (epoch 49.778), train_loss = 3.24551731, grad/param norm = 6.7503e-01, time/batch = 0.2070s	
2689/2700 (epoch 49.796), train_loss = 3.23784662, grad/param norm = 6.3584e-01, time/batch = 0.2080s	
2690/2700 (epoch 49.815), train_loss = 3.19114116, grad/param norm = 4.8593e-01, time/batch = 0.2068s	
2691/2700 (epoch 49.833), train_loss = 3.22879926, grad/param norm = 5.3733e-01, time/batch = 0.1827s	
2692/2700 (epoch 49.852), train_loss = 3.21573116, grad/param norm = 5.6081e-01, time/batch = 0.2053s	
2693/2700 (epoch 49.870), train_loss = 3.20999730, grad/param norm = 3.8320e-01, time/batch = 0.2054s	
2694/2700 (epoch 49.889), train_loss = 3.24987689, grad/param norm = 5.2364e-01, time/batch = 0.1990s	
2695/2700 (epoch 49.907), train_loss = 3.30201996, grad/param norm = 7.5970e-01, time/batch = 0.1963s	
2696/2700 (epoch 49.926), train_loss = 3.24940972, grad/param norm = 7.0808e-01, time/batch = 0.1842s	
2697/2700 (epoch 49.944), train_loss = 3.25942693, grad/param norm = 6.3344e-01, time/batch = 0.1925s	
2698/2700 (epoch 49.963), train_loss = 3.33948322, grad/param norm = 5.9659e-01, time/batch = 0.1882s	
2699/2700 (epoch 49.981), train_loss = 3.40182527, grad/param norm = 7.0163e-01, time/batch = 0.1830s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch50.00_3.1894.t7	
2700/2700 (epoch 50.000), train_loss = 3.29713931, grad/param norm = 6.8255e-01, time/batch = 0.1836s	
