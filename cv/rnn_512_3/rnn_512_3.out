using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 54, val: 3, test: 0	
vocab size: 91	
creating an rnn with 3 layers	
number of parameters in the model: 1407067	
cloning rnn	
cloning criterion	
1/2700 (epoch 0.019), train_loss = 4.66013421, grad/param norm = 6.9097e+00, time/batch = 0.6709s	
2/2700 (epoch 0.037), train_loss = 4.09031096, grad/param norm = 1.3872e+01, time/batch = 0.2300s	
3/2700 (epoch 0.056), train_loss = 7.67606844, grad/param norm = 4.6251e+00, time/batch = 0.2316s	
4/2700 (epoch 0.074), train_loss = 4.96881142, grad/param norm = 1.8262e+00, time/batch = 0.2273s	
5/2700 (epoch 0.093), train_loss = 4.63818464, grad/param norm = 5.2085e+00, time/batch = 0.2309s	
6/2700 (epoch 0.111), train_loss = 4.36225091, grad/param norm = 5.7776e+00, time/batch = 0.2309s	
7/2700 (epoch 0.130), train_loss = 4.95204514, grad/param norm = 5.0226e+00, time/batch = 0.2236s	
8/2700 (epoch 0.148), train_loss = 4.53047745, grad/param norm = 4.2076e+00, time/batch = 0.2354s	
9/2700 (epoch 0.167), train_loss = 4.59306459, grad/param norm = 4.8418e+00, time/batch = 0.2351s	
10/2700 (epoch 0.185), train_loss = 3.71929707, grad/param norm = 3.7361e+00, time/batch = 0.2240s	
11/2700 (epoch 0.204), train_loss = 3.80119940, grad/param norm = 3.5839e+00, time/batch = 0.2317s	
12/2700 (epoch 0.222), train_loss = 3.64436767, grad/param norm = 3.8670e+00, time/batch = 0.2210s	
13/2700 (epoch 0.241), train_loss = 3.43468948, grad/param norm = 2.8688e+00, time/batch = 0.2100s	
14/2700 (epoch 0.259), train_loss = 3.36514195, grad/param norm = 2.7008e+00, time/batch = 0.2179s	
15/2700 (epoch 0.278), train_loss = 3.42503184, grad/param norm = 2.3208e+00, time/batch = 0.2314s	
16/2700 (epoch 0.296), train_loss = 3.35219149, grad/param norm = 2.0398e+00, time/batch = 0.2367s	
17/2700 (epoch 0.315), train_loss = 3.33356449, grad/param norm = 2.1334e+00, time/batch = 0.2327s	
18/2700 (epoch 0.333), train_loss = 3.46036098, grad/param norm = 2.2455e+00, time/batch = 0.2357s	
19/2700 (epoch 0.352), train_loss = 3.42977828, grad/param norm = 2.3403e+00, time/batch = 0.2352s	
20/2700 (epoch 0.370), train_loss = 3.41454572, grad/param norm = 2.6295e+00, time/batch = 0.2354s	
21/2700 (epoch 0.389), train_loss = 3.35813067, grad/param norm = 2.4285e+00, time/batch = 0.2226s	
22/2700 (epoch 0.407), train_loss = 3.37851674, grad/param norm = 2.2614e+00, time/batch = 0.2161s	
23/2700 (epoch 0.426), train_loss = 3.37616460, grad/param norm = 2.1486e+00, time/batch = 0.2193s	
24/2700 (epoch 0.444), train_loss = 3.30040259, grad/param norm = 2.3521e+00, time/batch = 0.1994s	
25/2700 (epoch 0.463), train_loss = 3.36490381, grad/param norm = 2.4543e+00, time/batch = 0.2293s	
26/2700 (epoch 0.481), train_loss = 3.43847472, grad/param norm = 2.3907e+00, time/batch = 0.2004s	
27/2700 (epoch 0.500), train_loss = 3.46261733, grad/param norm = 2.3651e+00, time/batch = 0.2153s	
28/2700 (epoch 0.519), train_loss = 3.42616263, grad/param norm = 2.4468e+00, time/batch = 0.2164s	
29/2700 (epoch 0.537), train_loss = 3.43724575, grad/param norm = 2.1968e+00, time/batch = 0.2254s	
30/2700 (epoch 0.556), train_loss = 3.41104872, grad/param norm = 2.2687e+00, time/batch = 0.2321s	
31/2700 (epoch 0.574), train_loss = 3.29415730, grad/param norm = 1.6510e+00, time/batch = 0.2217s	
32/2700 (epoch 0.593), train_loss = 3.31460335, grad/param norm = 2.0882e+00, time/batch = 0.2011s	
33/2700 (epoch 0.611), train_loss = 3.29044793, grad/param norm = 2.1014e+00, time/batch = 0.2237s	
34/2700 (epoch 0.630), train_loss = 3.33481867, grad/param norm = 2.3760e+00, time/batch = 0.2224s	
35/2700 (epoch 0.648), train_loss = 3.43662956, grad/param norm = 2.2802e+00, time/batch = 0.2273s	
36/2700 (epoch 0.667), train_loss = 3.31364207, grad/param norm = 2.2093e+00, time/batch = 0.2372s	
37/2700 (epoch 0.685), train_loss = 3.31844125, grad/param norm = 2.0359e+00, time/batch = 0.2372s	
38/2700 (epoch 0.704), train_loss = 3.32177910, grad/param norm = 2.4999e+00, time/batch = 0.2353s	
39/2700 (epoch 0.722), train_loss = 3.36920421, grad/param norm = 2.3642e+00, time/batch = 0.2373s	
40/2700 (epoch 0.741), train_loss = 3.44038872, grad/param norm = 2.2367e+00, time/batch = 0.2369s	
41/2700 (epoch 0.759), train_loss = 3.39476797, grad/param norm = 2.3316e+00, time/batch = 0.2154s	
42/2700 (epoch 0.778), train_loss = 3.37594104, grad/param norm = 2.5077e+00, time/batch = 0.2292s	
43/2700 (epoch 0.796), train_loss = 3.40336589, grad/param norm = 2.3748e+00, time/batch = 0.2019s	
44/2700 (epoch 0.815), train_loss = 3.31381281, grad/param norm = 2.4315e+00, time/batch = 0.2309s	
45/2700 (epoch 0.833), train_loss = 3.38817321, grad/param norm = 2.5639e+00, time/batch = 0.2316s	
46/2700 (epoch 0.852), train_loss = 3.35785343, grad/param norm = 2.4815e+00, time/batch = 0.2351s	
47/2700 (epoch 0.870), train_loss = 3.35285915, grad/param norm = 2.3495e+00, time/batch = 0.2364s	
48/2700 (epoch 0.889), train_loss = 3.38036935, grad/param norm = 2.4118e+00, time/batch = 0.2355s	
49/2700 (epoch 0.907), train_loss = 3.45050656, grad/param norm = 2.7275e+00, time/batch = 0.2365s	
50/2700 (epoch 0.926), train_loss = 3.39855783, grad/param norm = 2.5052e+00, time/batch = 0.2262s	
51/2700 (epoch 0.944), train_loss = 3.39115073, grad/param norm = 2.2455e+00, time/batch = 0.2239s	
52/2700 (epoch 0.963), train_loss = 3.45870117, grad/param norm = 2.1543e+00, time/batch = 0.2222s	
53/2700 (epoch 0.981), train_loss = 3.50952778, grad/param norm = 2.1600e+00, time/batch = 0.2067s	
54/2700 (epoch 1.000), train_loss = 3.43449447, grad/param norm = 2.2364e+00, time/batch = 0.1995s	
55/2700 (epoch 1.019), train_loss = 3.34402150, grad/param norm = 2.3433e+00, time/batch = 0.2243s	
56/2700 (epoch 1.037), train_loss = 3.38262825, grad/param norm = 2.4765e+00, time/batch = 0.2273s	
57/2700 (epoch 1.056), train_loss = 3.36165979, grad/param norm = 2.1404e+00, time/batch = 0.2321s	
58/2700 (epoch 1.074), train_loss = 3.38072824, grad/param norm = 2.0674e+00, time/batch = 0.2375s	
59/2700 (epoch 1.093), train_loss = 3.43191271, grad/param norm = 2.0649e+00, time/batch = 0.2337s	
60/2700 (epoch 1.111), train_loss = 3.40912522, grad/param norm = 2.2723e+00, time/batch = 0.2377s	
61/2700 (epoch 1.130), train_loss = 3.41891700, grad/param norm = 2.2925e+00, time/batch = 0.2297s	
62/2700 (epoch 1.148), train_loss = 3.36066804, grad/param norm = 2.3367e+00, time/batch = 0.2094s	
63/2700 (epoch 1.167), train_loss = 3.38766973, grad/param norm = 2.3646e+00, time/batch = 0.2050s	
64/2700 (epoch 1.185), train_loss = 3.35582261, grad/param norm = 2.2745e+00, time/batch = 0.2346s	
65/2700 (epoch 1.204), train_loss = 3.30014057, grad/param norm = 2.2511e+00, time/batch = 0.2352s	
66/2700 (epoch 1.222), train_loss = 3.27164421, grad/param norm = 2.5983e+00, time/batch = 0.2251s	
67/2700 (epoch 1.241), train_loss = 3.31594213, grad/param norm = 2.5262e+00, time/batch = 0.2192s	
68/2700 (epoch 1.259), train_loss = 3.35843718, grad/param norm = 2.3395e+00, time/batch = 0.2154s	
69/2700 (epoch 1.278), train_loss = 3.42605498, grad/param norm = 2.6387e+00, time/batch = 0.2344s	
70/2700 (epoch 1.296), train_loss = 3.42337644, grad/param norm = 2.5469e+00, time/batch = 0.2376s	
71/2700 (epoch 1.315), train_loss = 3.39156826, grad/param norm = 2.0236e+00, time/batch = 0.2258s	
72/2700 (epoch 1.333), train_loss = 3.42612745, grad/param norm = 1.7284e+00, time/batch = 0.1946s	
73/2700 (epoch 1.352), train_loss = 3.43994206, grad/param norm = 1.7671e+00, time/batch = 0.2160s	
74/2700 (epoch 1.370), train_loss = 3.41999375, grad/param norm = 2.0816e+00, time/batch = 0.2201s	
75/2700 (epoch 1.389), train_loss = 3.35118644, grad/param norm = 2.2133e+00, time/batch = 0.2304s	
76/2700 (epoch 1.407), train_loss = 3.39395766, grad/param norm = 2.2487e+00, time/batch = 0.2309s	
77/2700 (epoch 1.426), train_loss = 3.39270006, grad/param norm = 2.3121e+00, time/batch = 0.2299s	
78/2700 (epoch 1.444), train_loss = 3.32476790, grad/param norm = 2.4409e+00, time/batch = 0.2363s	
79/2700 (epoch 1.463), train_loss = 3.37509559, grad/param norm = 2.5310e+00, time/batch = 0.2299s	
80/2700 (epoch 1.481), train_loss = 3.45544028, grad/param norm = 2.5358e+00, time/batch = 0.2229s	
81/2700 (epoch 1.500), train_loss = 3.49601149, grad/param norm = 2.5639e+00, time/batch = 0.2180s	
82/2700 (epoch 1.519), train_loss = 3.46634432, grad/param norm = 2.8091e+00, time/batch = 0.2220s	
83/2700 (epoch 1.537), train_loss = 3.48798222, grad/param norm = 2.2858e+00, time/batch = 0.2337s	
84/2700 (epoch 1.556), train_loss = 3.39491041, grad/param norm = 2.0204e+00, time/batch = 0.2354s	
85/2700 (epoch 1.574), train_loss = 3.32268426, grad/param norm = 1.8389e+00, time/batch = 0.2337s	
86/2700 (epoch 1.593), train_loss = 3.33095023, grad/param norm = 2.2206e+00, time/batch = 0.2309s	
87/2700 (epoch 1.611), train_loss = 3.29994771, grad/param norm = 2.1997e+00, time/batch = 0.2358s	
88/2700 (epoch 1.630), train_loss = 3.31822196, grad/param norm = 2.3341e+00, time/batch = 0.2356s	
89/2700 (epoch 1.648), train_loss = 3.41771863, grad/param norm = 2.2930e+00, time/batch = 0.2288s	
90/2700 (epoch 1.667), train_loss = 3.32417485, grad/param norm = 2.2497e+00, time/batch = 0.2233s	
91/2700 (epoch 1.685), train_loss = 3.33654810, grad/param norm = 2.1716e+00, time/batch = 0.1640s	
92/2700 (epoch 1.704), train_loss = 3.34763711, grad/param norm = 2.4741e+00, time/batch = 0.2080s	
93/2700 (epoch 1.722), train_loss = 3.35928186, grad/param norm = 2.4070e+00, time/batch = 0.2082s	
94/2700 (epoch 1.741), train_loss = 3.44305573, grad/param norm = 2.2393e+00, time/batch = 0.2277s	
95/2700 (epoch 1.759), train_loss = 3.40340388, grad/param norm = 2.5050e+00, time/batch = 0.2322s	
96/2700 (epoch 1.778), train_loss = 3.40155701, grad/param norm = 2.6514e+00, time/batch = 0.2330s	
97/2700 (epoch 1.796), train_loss = 3.42632618, grad/param norm = 2.4101e+00, time/batch = 0.2328s	
98/2700 (epoch 1.815), train_loss = 3.31380356, grad/param norm = 2.4613e+00, time/batch = 0.2388s	
99/2700 (epoch 1.833), train_loss = 3.39281647, grad/param norm = 2.5030e+00, time/batch = 0.2379s	
100/2700 (epoch 1.852), train_loss = 3.34277027, grad/param norm = 2.4862e+00, time/batch = 0.2308s	
101/2700 (epoch 1.870), train_loss = 3.36810779, grad/param norm = 2.2507e+00, time/batch = 0.2267s	
102/2700 (epoch 1.889), train_loss = 3.36828959, grad/param norm = 2.3410e+00, time/batch = 0.2299s	
103/2700 (epoch 1.907), train_loss = 3.43392407, grad/param norm = 2.3916e+00, time/batch = 0.2266s	
104/2700 (epoch 1.926), train_loss = 3.38705724, grad/param norm = 2.3069e+00, time/batch = 0.2186s	
105/2700 (epoch 1.944), train_loss = 3.41346749, grad/param norm = 2.0839e+00, time/batch = 0.2214s	
106/2700 (epoch 1.963), train_loss = 3.43516716, grad/param norm = 1.8937e+00, time/batch = 0.2306s	
107/2700 (epoch 1.981), train_loss = 3.49933853, grad/param norm = 1.8986e+00, time/batch = 0.2298s	
108/2700 (epoch 2.000), train_loss = 3.41680184, grad/param norm = 2.0540e+00, time/batch = 0.2343s	
109/2700 (epoch 2.019), train_loss = 3.33753236, grad/param norm = 2.1815e+00, time/batch = 0.2342s	
110/2700 (epoch 2.037), train_loss = 3.38141880, grad/param norm = 2.3548e+00, time/batch = 0.2297s	
111/2700 (epoch 2.056), train_loss = 3.36483531, grad/param norm = 2.1266e+00, time/batch = 0.2232s	
112/2700 (epoch 2.074), train_loss = 3.36591868, grad/param norm = 2.0135e+00, time/batch = 0.2161s	
113/2700 (epoch 2.093), train_loss = 3.40438064, grad/param norm = 2.0633e+00, time/batch = 0.2158s	
114/2700 (epoch 2.111), train_loss = 3.40246092, grad/param norm = 2.3580e+00, time/batch = 0.2192s	
115/2700 (epoch 2.130), train_loss = 3.45660401, grad/param norm = 2.6679e+00, time/batch = 0.2248s	
116/2700 (epoch 2.148), train_loss = 3.44135226, grad/param norm = 2.8261e+00, time/batch = 0.2318s	
117/2700 (epoch 2.167), train_loss = 3.43947419, grad/param norm = 2.8121e+00, time/batch = 0.2227s	
118/2700 (epoch 2.185), train_loss = 3.39574191, grad/param norm = 2.6008e+00, time/batch = 0.2242s	
119/2700 (epoch 2.204), train_loss = 3.30262797, grad/param norm = 2.3993e+00, time/batch = 0.2041s	
120/2700 (epoch 2.222), train_loss = 3.25835885, grad/param norm = 2.6337e+00, time/batch = 0.2197s	
121/2700 (epoch 2.241), train_loss = 3.28660438, grad/param norm = 2.3743e+00, time/batch = 0.2276s	
122/2700 (epoch 2.259), train_loss = 3.32083779, grad/param norm = 2.5512e+00, time/batch = 0.2323s	
123/2700 (epoch 2.278), train_loss = 3.41478868, grad/param norm = 2.4050e+00, time/batch = 0.2205s	
124/2700 (epoch 2.296), train_loss = 3.39284698, grad/param norm = 2.1516e+00, time/batch = 0.2325s	
125/2700 (epoch 2.315), train_loss = 3.36403891, grad/param norm = 1.7044e+00, time/batch = 0.2345s	
126/2700 (epoch 2.333), train_loss = 3.41151000, grad/param norm = 1.5121e+00, time/batch = 0.2358s	
127/2700 (epoch 2.352), train_loss = 3.44412420, grad/param norm = 1.7456e+00, time/batch = 0.2364s	
128/2700 (epoch 2.370), train_loss = 3.45235297, grad/param norm = 2.3343e+00, time/batch = 0.2280s	
129/2700 (epoch 2.389), train_loss = 3.41318642, grad/param norm = 2.4586e+00, time/batch = 0.2320s	
130/2700 (epoch 2.407), train_loss = 3.41224137, grad/param norm = 2.2240e+00, time/batch = 0.2364s	
131/2700 (epoch 2.426), train_loss = 3.39688594, grad/param norm = 2.2712e+00, time/batch = 0.2177s	
132/2700 (epoch 2.444), train_loss = 3.32452312, grad/param norm = 2.3774e+00, time/batch = 0.1931s	
133/2700 (epoch 2.463), train_loss = 3.37169196, grad/param norm = 2.4986e+00, time/batch = 0.2271s	
134/2700 (epoch 2.481), train_loss = 3.44165421, grad/param norm = 2.5035e+00, time/batch = 0.2314s	
135/2700 (epoch 2.500), train_loss = 3.49068840, grad/param norm = 2.3712e+00, time/batch = 0.2246s	
136/2700 (epoch 2.519), train_loss = 3.42379591, grad/param norm = 2.1975e+00, time/batch = 0.2214s	
137/2700 (epoch 2.537), train_loss = 3.43041896, grad/param norm = 2.1047e+00, time/batch = 0.2271s	
138/2700 (epoch 2.556), train_loss = 3.42327866, grad/param norm = 2.3134e+00, time/batch = 0.2341s	
139/2700 (epoch 2.574), train_loss = 3.33095239, grad/param norm = 2.2478e+00, time/batch = 0.2333s	
140/2700 (epoch 2.593), train_loss = 3.41439305, grad/param norm = 2.5485e+00, time/batch = 0.2351s	
141/2700 (epoch 2.611), train_loss = 3.31658227, grad/param norm = 2.2057e+00, time/batch = 0.2248s	
142/2700 (epoch 2.630), train_loss = 3.32578063, grad/param norm = 2.3045e+00, time/batch = 0.2222s	
143/2700 (epoch 2.648), train_loss = 3.42256834, grad/param norm = 2.5230e+00, time/batch = 0.2259s	
144/2700 (epoch 2.667), train_loss = 3.36374322, grad/param norm = 2.5591e+00, time/batch = 0.2253s	
145/2700 (epoch 2.685), train_loss = 3.35560730, grad/param norm = 2.3404e+00, time/batch = 0.2221s	
146/2700 (epoch 2.704), train_loss = 3.32463378, grad/param norm = 2.4363e+00, time/batch = 0.2289s	
147/2700 (epoch 2.722), train_loss = 3.34817275, grad/param norm = 2.5819e+00, time/batch = 0.2308s	
148/2700 (epoch 2.741), train_loss = 3.46766874, grad/param norm = 2.4679e+00, time/batch = 0.2111s	
149/2700 (epoch 2.759), train_loss = 3.41234314, grad/param norm = 2.5826e+00, time/batch = 0.2362s	
150/2700 (epoch 2.778), train_loss = 3.40951704, grad/param norm = 2.7838e+00, time/batch = 0.2280s	
151/2700 (epoch 2.796), train_loss = 3.42469265, grad/param norm = 2.4460e+00, time/batch = 0.2254s	
152/2700 (epoch 2.815), train_loss = 3.31988082, grad/param norm = 2.3964e+00, time/batch = 0.2130s	
153/2700 (epoch 2.833), train_loss = 3.39442448, grad/param norm = 2.5249e+00, time/batch = 0.2157s	
154/2700 (epoch 2.852), train_loss = 3.35406383, grad/param norm = 2.4832e+00, time/batch = 0.2224s	
155/2700 (epoch 2.870), train_loss = 3.36327441, grad/param norm = 2.3433e+00, time/batch = 0.2260s	
156/2700 (epoch 2.889), train_loss = 3.36541304, grad/param norm = 2.2909e+00, time/batch = 0.2263s	
157/2700 (epoch 2.907), train_loss = 3.42270250, grad/param norm = 2.3183e+00, time/batch = 0.2278s	
158/2700 (epoch 2.926), train_loss = 3.39166853, grad/param norm = 2.3599e+00, time/batch = 0.2352s	
159/2700 (epoch 2.944), train_loss = 3.39128515, grad/param norm = 2.2261e+00, time/batch = 0.2310s	
160/2700 (epoch 2.963), train_loss = 3.46088261, grad/param norm = 2.2155e+00, time/batch = 0.2356s	
161/2700 (epoch 2.981), train_loss = 3.52425600, grad/param norm = 2.0845e+00, time/batch = 0.2316s	
162/2700 (epoch 3.000), train_loss = 3.41128378, grad/param norm = 2.0507e+00, time/batch = 0.2202s	
163/2700 (epoch 3.019), train_loss = 3.32486288, grad/param norm = 2.1806e+00, time/batch = 0.2194s	
164/2700 (epoch 3.037), train_loss = 3.38124327, grad/param norm = 2.3698e+00, time/batch = 0.2271s	
165/2700 (epoch 3.056), train_loss = 3.35814861, grad/param norm = 2.0815e+00, time/batch = 0.2277s	
166/2700 (epoch 3.074), train_loss = 3.37446603, grad/param norm = 2.0580e+00, time/batch = 0.2189s	
167/2700 (epoch 3.093), train_loss = 3.42573756, grad/param norm = 2.0538e+00, time/batch = 0.1997s	
168/2700 (epoch 3.111), train_loss = 3.41382658, grad/param norm = 2.4102e+00, time/batch = 0.2302s	
169/2700 (epoch 3.130), train_loss = 3.43999633, grad/param norm = 2.3821e+00, time/batch = 0.2325s	
170/2700 (epoch 3.148), train_loss = 3.36415427, grad/param norm = 2.3914e+00, time/batch = 0.2336s	
171/2700 (epoch 3.167), train_loss = 3.38271101, grad/param norm = 2.3723e+00, time/batch = 0.2218s	
172/2700 (epoch 3.185), train_loss = 3.36730567, grad/param norm = 2.3909e+00, time/batch = 0.2169s	
173/2700 (epoch 3.204), train_loss = 3.31922018, grad/param norm = 2.3111e+00, time/batch = 0.2104s	
174/2700 (epoch 3.222), train_loss = 3.28458186, grad/param norm = 2.6246e+00, time/batch = 0.1856s	
175/2700 (epoch 3.241), train_loss = 3.31609385, grad/param norm = 2.4152e+00, time/batch = 0.2301s	
176/2700 (epoch 3.259), train_loss = 3.33648029, grad/param norm = 2.2438e+00, time/batch = 0.2196s	
177/2700 (epoch 3.278), train_loss = 3.43196117, grad/param norm = 2.6565e+00, time/batch = 0.2176s	
178/2700 (epoch 3.296), train_loss = 3.42889384, grad/param norm = 2.5634e+00, time/batch = 0.2306s	
179/2700 (epoch 3.315), train_loss = 3.39052309, grad/param norm = 2.0385e+00, time/batch = 0.2321s	
180/2700 (epoch 3.333), train_loss = 3.42485018, grad/param norm = 1.7462e+00, time/batch = 0.2378s	
181/2700 (epoch 3.352), train_loss = 3.43345580, grad/param norm = 1.7687e+00, time/batch = 0.2369s	
182/2700 (epoch 3.370), train_loss = 3.41148185, grad/param norm = 2.1503e+00, time/batch = 0.2289s	
183/2700 (epoch 3.389), train_loss = 3.35659324, grad/param norm = 2.2976e+00, time/batch = 0.2228s	
184/2700 (epoch 3.407), train_loss = 3.40004755, grad/param norm = 2.2504e+00, time/batch = 0.2346s	
185/2700 (epoch 3.426), train_loss = 3.39052374, grad/param norm = 2.2630e+00, time/batch = 0.2255s	
186/2700 (epoch 3.444), train_loss = 3.32009942, grad/param norm = 2.3901e+00, time/batch = 0.2053s	
187/2700 (epoch 3.463), train_loss = 3.37519901, grad/param norm = 2.5150e+00, time/batch = 0.2366s	
188/2700 (epoch 3.481), train_loss = 3.45221000, grad/param norm = 2.4964e+00, time/batch = 0.2240s	
189/2700 (epoch 3.500), train_loss = 3.48671172, grad/param norm = 2.4168e+00, time/batch = 0.2083s	
190/2700 (epoch 3.519), train_loss = 3.44802936, grad/param norm = 2.4258e+00, time/batch = 0.2083s	
191/2700 (epoch 3.537), train_loss = 3.46690538, grad/param norm = 2.3429e+00, time/batch = 0.2326s	
192/2700 (epoch 3.556), train_loss = 3.40523585, grad/param norm = 2.1131e+00, time/batch = 0.2231s	
193/2700 (epoch 3.574), train_loss = 3.30771835, grad/param norm = 1.8981e+00, time/batch = 0.2314s	
194/2700 (epoch 3.593), train_loss = 3.33252665, grad/param norm = 2.2362e+00, time/batch = 0.2353s	
195/2700 (epoch 3.611), train_loss = 3.28206418, grad/param norm = 2.2519e+00, time/batch = 0.2249s	
196/2700 (epoch 3.630), train_loss = 3.31958405, grad/param norm = 2.4601e+00, time/batch = 0.2345s	
197/2700 (epoch 3.648), train_loss = 3.42705355, grad/param norm = 2.6261e+00, time/batch = 0.2350s	
198/2700 (epoch 3.667), train_loss = 3.37162542, grad/param norm = 2.6657e+00, time/batch = 0.2352s	
199/2700 (epoch 3.685), train_loss = 3.36399274, grad/param norm = 2.3586e+00, time/batch = 0.2334s	
200/2700 (epoch 3.704), train_loss = 3.31868634, grad/param norm = 2.3948e+00, time/batch = 0.2244s	
201/2700 (epoch 3.722), train_loss = 3.34137086, grad/param norm = 2.3089e+00, time/batch = 0.2278s	
202/2700 (epoch 3.741), train_loss = 3.45097398, grad/param norm = 2.3471e+00, time/batch = 0.2109s	
203/2700 (epoch 3.759), train_loss = 3.44263736, grad/param norm = 2.5688e+00, time/batch = 0.2183s	
204/2700 (epoch 3.778), train_loss = 3.42407734, grad/param norm = 2.6695e+00, time/batch = 0.2159s	
205/2700 (epoch 3.796), train_loss = 3.43029002, grad/param norm = 2.5361e+00, time/batch = 0.1917s	
206/2700 (epoch 3.815), train_loss = 3.32308678, grad/param norm = 2.4053e+00, time/batch = 0.2347s	
207/2700 (epoch 3.833), train_loss = 3.38733271, grad/param norm = 2.5102e+00, time/batch = 0.2337s	
208/2700 (epoch 3.852), train_loss = 3.35047069, grad/param norm = 2.4201e+00, time/batch = 0.2351s	
209/2700 (epoch 3.870), train_loss = 3.33273108, grad/param norm = 2.2879e+00, time/batch = 0.2356s	
210/2700 (epoch 3.889), train_loss = 3.34946554, grad/param norm = 2.2586e+00, time/batch = 0.2281s	
211/2700 (epoch 3.907), train_loss = 3.40828787, grad/param norm = 2.2398e+00, time/batch = 0.1993s	
212/2700 (epoch 3.926), train_loss = 3.38805676, grad/param norm = 2.3478e+00, time/batch = 0.2229s	
213/2700 (epoch 3.944), train_loss = 3.39983720, grad/param norm = 2.3448e+00, time/batch = 0.2317s	
214/2700 (epoch 3.963), train_loss = 3.49258178, grad/param norm = 2.3888e+00, time/batch = 0.2236s	
215/2700 (epoch 3.981), train_loss = 3.53557832, grad/param norm = 2.1930e+00, time/batch = 0.2243s	
216/2700 (epoch 4.000), train_loss = 3.40973346, grad/param norm = 2.0130e+00, time/batch = 0.2240s	
217/2700 (epoch 4.019), train_loss = 3.31117580, grad/param norm = 2.0517e+00, time/batch = 0.2331s	
218/2700 (epoch 4.037), train_loss = 3.36000454, grad/param norm = 2.2184e+00, time/batch = 0.2316s	
219/2700 (epoch 4.056), train_loss = 3.34074350, grad/param norm = 1.9043e+00, time/batch = 0.2347s	
220/2700 (epoch 4.074), train_loss = 3.36101657, grad/param norm = 1.8463e+00, time/batch = 0.2355s	
221/2700 (epoch 4.093), train_loss = 3.42502759, grad/param norm = 1.8935e+00, time/batch = 0.2261s	
222/2700 (epoch 4.111), train_loss = 3.40641582, grad/param norm = 2.1670e+00, time/batch = 0.2273s	
223/2700 (epoch 4.130), train_loss = 3.42386550, grad/param norm = 2.1215e+00, time/batch = 0.2138s	
224/2700 (epoch 4.148), train_loss = 3.36077285, grad/param norm = 2.2620e+00, time/batch = 0.2208s	
225/2700 (epoch 4.167), train_loss = 3.39271705, grad/param norm = 2.6980e+00, time/batch = 0.2316s	
226/2700 (epoch 4.185), train_loss = 3.40045742, grad/param norm = 2.4551e+00, time/batch = 0.2355s	
227/2700 (epoch 4.204), train_loss = 3.31343105, grad/param norm = 2.4989e+00, time/batch = 0.2290s	
228/2700 (epoch 4.222), train_loss = 3.28542821, grad/param norm = 2.7403e+00, time/batch = 0.2211s	
229/2700 (epoch 4.241), train_loss = 3.32471628, grad/param norm = 2.6899e+00, time/batch = 0.2187s	
230/2700 (epoch 4.259), train_loss = 3.36719473, grad/param norm = 2.6795e+00, time/batch = 0.2147s	
231/2700 (epoch 4.278), train_loss = 3.41976069, grad/param norm = 2.5363e+00, time/batch = 0.2290s	
232/2700 (epoch 4.296), train_loss = 3.39797824, grad/param norm = 2.2067e+00, time/batch = 0.1997s	
233/2700 (epoch 4.315), train_loss = 3.35395061, grad/param norm = 1.7536e+00, time/batch = 0.2327s	
234/2700 (epoch 4.333), train_loss = 3.40698599, grad/param norm = 1.5801e+00, time/batch = 0.2302s	
235/2700 (epoch 4.352), train_loss = 3.41925595, grad/param norm = 1.6158e+00, time/batch = 0.2247s	
236/2700 (epoch 4.370), train_loss = 3.40493602, grad/param norm = 1.9526e+00, time/batch = 0.2280s	
237/2700 (epoch 4.389), train_loss = 3.35353453, grad/param norm = 2.1715e+00, time/batch = 0.2311s	
238/2700 (epoch 4.407), train_loss = 3.39871884, grad/param norm = 2.2940e+00, time/batch = 0.2277s	
239/2700 (epoch 4.426), train_loss = 3.40512785, grad/param norm = 2.3936e+00, time/batch = 0.2012s	
240/2700 (epoch 4.444), train_loss = 3.33826742, grad/param norm = 2.5345e+00, time/batch = 0.2359s	
241/2700 (epoch 4.463), train_loss = 3.40729281, grad/param norm = 2.6925e+00, time/batch = 0.2134s	
242/2700 (epoch 4.481), train_loss = 3.48861747, grad/param norm = 2.7313e+00, time/batch = 0.2309s	
243/2700 (epoch 4.500), train_loss = 3.52089988, grad/param norm = 2.6557e+00, time/batch = 0.2188s	
244/2700 (epoch 4.519), train_loss = 3.45430345, grad/param norm = 2.5608e+00, time/batch = 0.2341s	
245/2700 (epoch 4.537), train_loss = 3.47120553, grad/param norm = 2.3492e+00, time/batch = 0.2348s	
246/2700 (epoch 4.556), train_loss = 3.44344930, grad/param norm = 2.3082e+00, time/batch = 0.2348s	
247/2700 (epoch 4.574), train_loss = 3.31326471, grad/param norm = 1.7773e+00, time/batch = 0.2355s	
248/2700 (epoch 4.593), train_loss = 3.32253474, grad/param norm = 2.1533e+00, time/batch = 0.2175s	
249/2700 (epoch 4.611), train_loss = 3.28579592, grad/param norm = 2.0521e+00, time/batch = 0.2310s	
250/2700 (epoch 4.630), train_loss = 3.31266469, grad/param norm = 2.2932e+00, time/batch = 0.2246s	
251/2700 (epoch 4.648), train_loss = 3.43363336, grad/param norm = 2.3911e+00, time/batch = 0.2316s	
252/2700 (epoch 4.667), train_loss = 3.35201439, grad/param norm = 2.4366e+00, time/batch = 0.2293s	
253/2700 (epoch 4.685), train_loss = 3.36077236, grad/param norm = 2.3059e+00, time/batch = 0.2244s	
254/2700 (epoch 4.704), train_loss = 3.33974440, grad/param norm = 2.6172e+00, time/batch = 0.2319s	
255/2700 (epoch 4.722), train_loss = 3.36970620, grad/param norm = 2.3919e+00, time/batch = 0.2231s	
256/2700 (epoch 4.741), train_loss = 3.43684564, grad/param norm = 2.1498e+00, time/batch = 0.2227s	
257/2700 (epoch 4.759), train_loss = 3.39336967, grad/param norm = 2.3481e+00, time/batch = 0.2312s	
258/2700 (epoch 4.778), train_loss = 3.38681335, grad/param norm = 2.5166e+00, time/batch = 0.2255s	
259/2700 (epoch 4.796), train_loss = 3.41647258, grad/param norm = 2.4298e+00, time/batch = 0.2288s	
260/2700 (epoch 4.815), train_loss = 3.32559916, grad/param norm = 2.5045e+00, time/batch = 0.2079s	
261/2700 (epoch 4.833), train_loss = 3.40239737, grad/param norm = 2.5584e+00, time/batch = 0.2369s	
262/2700 (epoch 4.852), train_loss = 3.35153996, grad/param norm = 2.5004e+00, time/batch = 0.2178s	
263/2700 (epoch 4.870), train_loss = 3.36269193, grad/param norm = 2.2215e+00, time/batch = 0.2311s	
264/2700 (epoch 4.889), train_loss = 3.35466363, grad/param norm = 2.2460e+00, time/batch = 0.2247s	
265/2700 (epoch 4.907), train_loss = 3.42382143, grad/param norm = 2.3952e+00, time/batch = 0.2190s	
266/2700 (epoch 4.926), train_loss = 3.39399772, grad/param norm = 2.5341e+00, time/batch = 0.2304s	
267/2700 (epoch 4.944), train_loss = 3.42610341, grad/param norm = 2.1361e+00, time/batch = 0.2233s	
268/2700 (epoch 4.963), train_loss = 3.43882364, grad/param norm = 1.8742e+00, time/batch = 0.2260s	
269/2700 (epoch 4.981), train_loss = 3.49233177, grad/param norm = 1.8238e+00, time/batch = 0.1954s	
270/2700 (epoch 5.000), train_loss = 3.41039735, grad/param norm = 1.9547e+00, time/batch = 0.2151s	
271/2700 (epoch 5.019), train_loss = 3.33097728, grad/param norm = 2.1853e+00, time/batch = 0.2327s	
272/2700 (epoch 5.037), train_loss = 3.39094447, grad/param norm = 2.4157e+00, time/batch = 0.2308s	
273/2700 (epoch 5.056), train_loss = 3.36473866, grad/param norm = 2.2347e+00, time/batch = 0.2313s	
274/2700 (epoch 5.074), train_loss = 3.38247118, grad/param norm = 2.1937e+00, time/batch = 0.2315s	
275/2700 (epoch 5.093), train_loss = 3.43234744, grad/param norm = 2.2486e+00, time/batch = 0.2232s	
276/2700 (epoch 5.111), train_loss = 3.41530574, grad/param norm = 2.4020e+00, time/batch = 0.1937s	
277/2700 (epoch 5.130), train_loss = 3.42599895, grad/param norm = 2.5821e+00, time/batch = 0.2167s	
278/2700 (epoch 5.148), train_loss = 3.39748455, grad/param norm = 2.7381e+00, time/batch = 0.2266s	
279/2700 (epoch 5.167), train_loss = 3.40656035, grad/param norm = 2.6421e+00, time/batch = 0.2310s	
280/2700 (epoch 5.185), train_loss = 3.37982909, grad/param norm = 2.4080e+00, time/batch = 0.2367s	
281/2700 (epoch 5.204), train_loss = 3.30223974, grad/param norm = 2.3547e+00, time/batch = 0.2275s	
282/2700 (epoch 5.222), train_loss = 3.28702529, grad/param norm = 2.6787e+00, time/batch = 0.2382s	
283/2700 (epoch 5.241), train_loss = 3.30856643, grad/param norm = 2.4819e+00, time/batch = 0.2276s	
284/2700 (epoch 5.259), train_loss = 3.34763350, grad/param norm = 2.6264e+00, time/batch = 0.2101s	
285/2700 (epoch 5.278), train_loss = 3.44493171, grad/param norm = 2.6696e+00, time/batch = 0.1940s	
286/2700 (epoch 5.296), train_loss = 3.40929314, grad/param norm = 2.3449e+00, time/batch = 0.2153s	
287/2700 (epoch 5.315), train_loss = 3.38094196, grad/param norm = 1.8823e+00, time/batch = 0.2257s	
288/2700 (epoch 5.333), train_loss = 3.42667672, grad/param norm = 1.5986e+00, time/batch = 0.2315s	
289/2700 (epoch 5.352), train_loss = 3.43901477, grad/param norm = 1.6035e+00, time/batch = 0.2228s	
290/2700 (epoch 5.370), train_loss = 3.41331532, grad/param norm = 1.9530e+00, time/batch = 0.2199s	
291/2700 (epoch 5.389), train_loss = 3.36789659, grad/param norm = 2.1329e+00, time/batch = 0.2345s	
292/2700 (epoch 5.407), train_loss = 3.40182730, grad/param norm = 2.1875e+00, time/batch = 0.2299s	
293/2700 (epoch 5.426), train_loss = 3.39904098, grad/param norm = 2.2280e+00, time/batch = 0.2333s	
294/2700 (epoch 5.444), train_loss = 3.32032461, grad/param norm = 2.3470e+00, time/batch = 0.2268s	
295/2700 (epoch 5.463), train_loss = 3.38084035, grad/param norm = 2.5505e+00, time/batch = 0.2324s	
296/2700 (epoch 5.481), train_loss = 3.46186296, grad/param norm = 2.5868e+00, time/batch = 0.2373s	
297/2700 (epoch 5.500), train_loss = 3.49871238, grad/param norm = 2.5786e+00, time/batch = 0.2369s	
298/2700 (epoch 5.519), train_loss = 3.45934256, grad/param norm = 2.6607e+00, time/batch = 0.2273s	
299/2700 (epoch 5.537), train_loss = 3.47019134, grad/param norm = 2.2831e+00, time/batch = 0.2207s	
300/2700 (epoch 5.556), train_loss = 3.39440844, grad/param norm = 2.0471e+00, time/batch = 0.1893s	
301/2700 (epoch 5.574), train_loss = 3.30981057, grad/param norm = 1.7556e+00, time/batch = 0.2180s	
302/2700 (epoch 5.593), train_loss = 3.32520376, grad/param norm = 2.1843e+00, time/batch = 0.2124s	
303/2700 (epoch 5.611), train_loss = 3.30432200, grad/param norm = 2.2165e+00, time/batch = 0.2109s	
304/2700 (epoch 5.630), train_loss = 3.34055546, grad/param norm = 2.4211e+00, time/batch = 0.2235s	
305/2700 (epoch 5.648), train_loss = 3.42989164, grad/param norm = 2.3410e+00, time/batch = 0.2290s	
306/2700 (epoch 5.667), train_loss = 3.33284212, grad/param norm = 2.2895e+00, time/batch = 0.2320s	
307/2700 (epoch 5.685), train_loss = 3.33108370, grad/param norm = 2.1293e+00, time/batch = 0.2311s	
308/2700 (epoch 5.704), train_loss = 3.32648361, grad/param norm = 2.5078e+00, time/batch = 0.2343s	
309/2700 (epoch 5.722), train_loss = 3.36814041, grad/param norm = 2.4490e+00, time/batch = 0.2332s	
310/2700 (epoch 5.741), train_loss = 3.44597893, grad/param norm = 2.2246e+00, time/batch = 0.2313s	
311/2700 (epoch 5.759), train_loss = 3.40492520, grad/param norm = 2.4629e+00, time/batch = 0.2178s	
312/2700 (epoch 5.778), train_loss = 3.39650418, grad/param norm = 2.6298e+00, time/batch = 0.2112s	
313/2700 (epoch 5.796), train_loss = 3.42108451, grad/param norm = 2.4697e+00, time/batch = 0.2004s	
314/2700 (epoch 5.815), train_loss = 3.32522094, grad/param norm = 2.5163e+00, time/batch = 0.2230s	
315/2700 (epoch 5.833), train_loss = 3.40381546, grad/param norm = 2.5569e+00, time/batch = 0.2293s	
316/2700 (epoch 5.852), train_loss = 3.35451514, grad/param norm = 2.5401e+00, time/batch = 0.2307s	
317/2700 (epoch 5.870), train_loss = 3.36863670, grad/param norm = 2.2538e+00, time/batch = 0.2329s	
318/2700 (epoch 5.889), train_loss = 3.35896936, grad/param norm = 2.2963e+00, time/batch = 0.2343s	
319/2700 (epoch 5.907), train_loss = 3.42648860, grad/param norm = 2.4144e+00, time/batch = 0.2291s	
320/2700 (epoch 5.926), train_loss = 3.37959943, grad/param norm = 2.3010e+00, time/batch = 0.2357s	
321/2700 (epoch 5.944), train_loss = 3.41087127, grad/param norm = 2.0943e+00, time/batch = 0.2226s	
322/2700 (epoch 5.963), train_loss = 3.44191227, grad/param norm = 1.9136e+00, time/batch = 0.2128s	
323/2700 (epoch 5.981), train_loss = 3.50324432, grad/param norm = 1.9420e+00, time/batch = 0.2147s	
324/2700 (epoch 6.000), train_loss = 3.42184319, grad/param norm = 2.0724e+00, time/batch = 0.2178s	
325/2700 (epoch 6.019), train_loss = 3.33760491, grad/param norm = 2.2107e+00, time/batch = 0.2205s	
326/2700 (epoch 6.037), train_loss = 3.38621297, grad/param norm = 2.3928e+00, time/batch = 0.2308s	
327/2700 (epoch 6.056), train_loss = 3.36265103, grad/param norm = 2.1006e+00, time/batch = 0.2311s	
328/2700 (epoch 6.074), train_loss = 3.36349545, grad/param norm = 1.9825e+00, time/batch = 0.2202s	
329/2700 (epoch 6.093), train_loss = 3.40359148, grad/param norm = 2.0051e+00, time/batch = 0.2236s	
330/2700 (epoch 6.111), train_loss = 3.39376789, grad/param norm = 2.2551e+00, time/batch = 0.2316s	
331/2700 (epoch 6.130), train_loss = 3.43612504, grad/param norm = 2.4946e+00, time/batch = 0.2171s	
332/2700 (epoch 6.148), train_loss = 3.41506864, grad/param norm = 2.6812e+00, time/batch = 0.2021s	
333/2700 (epoch 6.167), train_loss = 3.41554168, grad/param norm = 2.7516e+00, time/batch = 0.2345s	
334/2700 (epoch 6.185), train_loss = 3.40483453, grad/param norm = 2.6844e+00, time/batch = 0.2299s	
335/2700 (epoch 6.204), train_loss = 3.33948826, grad/param norm = 2.7088e+00, time/batch = 0.2254s	
336/2700 (epoch 6.222), train_loss = 3.29669831, grad/param norm = 2.6275e+00, time/batch = 0.2308s	
337/2700 (epoch 6.241), train_loss = 3.27694468, grad/param norm = 2.5292e+00, time/batch = 0.2309s	
338/2700 (epoch 6.259), train_loss = 3.33907565, grad/param norm = 2.7401e+00, time/batch = 0.2212s	
339/2700 (epoch 6.278), train_loss = 3.42122037, grad/param norm = 2.6431e+00, time/batch = 0.2359s	
340/2700 (epoch 6.296), train_loss = 3.41733933, grad/param norm = 2.3862e+00, time/batch = 0.2320s	
341/2700 (epoch 6.315), train_loss = 3.37462628, grad/param norm = 1.9040e+00, time/batch = 0.1788s	
342/2700 (epoch 6.333), train_loss = 3.42249335, grad/param norm = 1.6985e+00, time/batch = 0.2107s	
343/2700 (epoch 6.352), train_loss = 3.44622615, grad/param norm = 1.6867e+00, time/batch = 0.2260s	
344/2700 (epoch 6.370), train_loss = 3.41890114, grad/param norm = 1.8017e+00, time/batch = 0.2330s	
345/2700 (epoch 6.389), train_loss = 3.34022241, grad/param norm = 1.8762e+00, time/batch = 0.2307s	
346/2700 (epoch 6.407), train_loss = 3.37759932, grad/param norm = 2.0050e+00, time/batch = 0.2341s	
347/2700 (epoch 6.426), train_loss = 3.39099378, grad/param norm = 2.0776e+00, time/batch = 0.2334s	
348/2700 (epoch 6.444), train_loss = 3.30835510, grad/param norm = 2.2589e+00, time/batch = 0.2276s	
349/2700 (epoch 6.463), train_loss = 3.37535621, grad/param norm = 2.5879e+00, time/batch = 0.2252s	
350/2700 (epoch 6.481), train_loss = 3.46262239, grad/param norm = 2.5705e+00, time/batch = 0.2229s	
351/2700 (epoch 6.500), train_loss = 3.49871847, grad/param norm = 2.5139e+00, time/batch = 0.2369s	
352/2700 (epoch 6.519), train_loss = 3.44226287, grad/param norm = 2.4729e+00, time/batch = 0.2323s	
353/2700 (epoch 6.537), train_loss = 3.44006802, grad/param norm = 2.1686e+00, time/batch = 0.2242s	
354/2700 (epoch 6.556), train_loss = 3.39660948, grad/param norm = 2.1720e+00, time/batch = 0.2260s	
355/2700 (epoch 6.574), train_loss = 3.31286712, grad/param norm = 1.8812e+00, time/batch = 0.2275s	
356/2700 (epoch 6.593), train_loss = 3.34935419, grad/param norm = 2.3175e+00, time/batch = 0.2164s	
357/2700 (epoch 6.611), train_loss = 3.29085021, grad/param norm = 2.1761e+00, time/batch = 0.1970s	
358/2700 (epoch 6.630), train_loss = 3.31268264, grad/param norm = 2.2462e+00, time/batch = 0.2338s	
359/2700 (epoch 6.648), train_loss = 3.41004534, grad/param norm = 2.3013e+00, time/batch = 0.2276s	
360/2700 (epoch 6.667), train_loss = 3.34911458, grad/param norm = 2.3752e+00, time/batch = 0.2318s	
361/2700 (epoch 6.685), train_loss = 3.34738590, grad/param norm = 2.1968e+00, time/batch = 0.2233s	
362/2700 (epoch 6.704), train_loss = 3.34381625, grad/param norm = 2.6257e+00, time/batch = 0.2182s	
363/2700 (epoch 6.722), train_loss = 3.38663050, grad/param norm = 2.3021e+00, time/batch = 0.2236s	
364/2700 (epoch 6.741), train_loss = 3.44587588, grad/param norm = 2.1918e+00, time/batch = 0.2304s	
365/2700 (epoch 6.759), train_loss = 3.41361212, grad/param norm = 2.1477e+00, time/batch = 0.2201s	
366/2700 (epoch 6.778), train_loss = 3.37584153, grad/param norm = 2.3198e+00, time/batch = 0.2194s	
367/2700 (epoch 6.796), train_loss = 3.42433121, grad/param norm = 2.2637e+00, time/batch = 0.2299s	
368/2700 (epoch 6.815), train_loss = 3.31745059, grad/param norm = 2.2445e+00, time/batch = 0.2268s	
369/2700 (epoch 6.833), train_loss = 3.39049378, grad/param norm = 2.5325e+00, time/batch = 0.2336s	
370/2700 (epoch 6.852), train_loss = 3.37897098, grad/param norm = 2.5437e+00, time/batch = 0.2329s	
371/2700 (epoch 6.870), train_loss = 3.36239194, grad/param norm = 2.5323e+00, time/batch = 0.2373s	
372/2700 (epoch 6.889), train_loss = 3.38454571, grad/param norm = 2.5254e+00, time/batch = 0.2286s	
373/2700 (epoch 6.907), train_loss = 3.43374916, grad/param norm = 2.4710e+00, time/batch = 0.2232s	
374/2700 (epoch 6.926), train_loss = 3.37047760, grad/param norm = 2.4120e+00, time/batch = 0.2202s	
375/2700 (epoch 6.944), train_loss = 3.38891389, grad/param norm = 2.1225e+00, time/batch = 0.2101s	
376/2700 (epoch 6.963), train_loss = 3.44639585, grad/param norm = 2.0657e+00, time/batch = 0.1764s	
377/2700 (epoch 6.981), train_loss = 3.51270169, grad/param norm = 1.8684e+00, time/batch = 0.2207s	
378/2700 (epoch 7.000), train_loss = 3.40564066, grad/param norm = 1.8145e+00, time/batch = 0.2133s	
379/2700 (epoch 7.019), train_loss = 3.32849117, grad/param norm = 1.8599e+00, time/batch = 0.2288s	
380/2700 (epoch 7.037), train_loss = 3.38239245, grad/param norm = 2.2175e+00, time/batch = 0.2309s	
381/2700 (epoch 7.056), train_loss = 3.39439646, grad/param norm = 2.3522e+00, time/batch = 0.2272s	
382/2700 (epoch 7.074), train_loss = 3.41432234, grad/param norm = 1.8225e+00, time/batch = 0.2308s	
383/2700 (epoch 7.093), train_loss = 3.39833477, grad/param norm = 1.9329e+00, time/batch = 0.2251s	
384/2700 (epoch 7.111), train_loss = 3.41146375, grad/param norm = 2.2709e+00, time/batch = 0.2288s	
385/2700 (epoch 7.130), train_loss = 3.46283457, grad/param norm = 2.6262e+00, time/batch = 0.2327s	
386/2700 (epoch 7.148), train_loss = 3.42544301, grad/param norm = 2.7237e+00, time/batch = 0.2299s	
387/2700 (epoch 7.167), train_loss = 3.39027296, grad/param norm = 2.7208e+00, time/batch = 0.2219s	
388/2700 (epoch 7.185), train_loss = 3.37772838, grad/param norm = 2.5648e+00, time/batch = 0.2360s	
389/2700 (epoch 7.204), train_loss = 3.29060254, grad/param norm = 2.3751e+00, time/batch = 0.2346s	
390/2700 (epoch 7.222), train_loss = 3.27254454, grad/param norm = 2.6834e+00, time/batch = 0.2344s	
391/2700 (epoch 7.241), train_loss = 3.30136347, grad/param norm = 2.5498e+00, time/batch = 0.2267s	
392/2700 (epoch 7.259), train_loss = 3.36139241, grad/param norm = 2.7082e+00, time/batch = 0.2314s	
393/2700 (epoch 7.278), train_loss = 3.41311754, grad/param norm = 2.5603e+00, time/batch = 0.2244s	
394/2700 (epoch 7.296), train_loss = 3.39409592, grad/param norm = 2.2646e+00, time/batch = 0.2304s	
395/2700 (epoch 7.315), train_loss = 3.36403933, grad/param norm = 1.7921e+00, time/batch = 0.2190s	
396/2700 (epoch 7.333), train_loss = 3.40977328, grad/param norm = 1.5420e+00, time/batch = 0.2247s	
397/2700 (epoch 7.352), train_loss = 3.41984775, grad/param norm = 1.5755e+00, time/batch = 0.2332s	
398/2700 (epoch 7.370), train_loss = 3.40161758, grad/param norm = 1.9992e+00, time/batch = 0.2354s	
399/2700 (epoch 7.389), train_loss = 3.36165347, grad/param norm = 2.0526e+00, time/batch = 0.2351s	
400/2700 (epoch 7.407), train_loss = 3.37225479, grad/param norm = 2.0189e+00, time/batch = 0.2355s	
401/2700 (epoch 7.426), train_loss = 3.38789389, grad/param norm = 2.1283e+00, time/batch = 0.2232s	
402/2700 (epoch 7.444), train_loss = 3.32353687, grad/param norm = 2.3835e+00, time/batch = 0.2165s	
403/2700 (epoch 7.463), train_loss = 3.40529071, grad/param norm = 2.7945e+00, time/batch = 0.2204s	
404/2700 (epoch 7.481), train_loss = 3.49934226, grad/param norm = 2.7858e+00, time/batch = 0.2258s	
405/2700 (epoch 7.500), train_loss = 3.50964653, grad/param norm = 2.6075e+00, time/batch = 0.2233s	
406/2700 (epoch 7.519), train_loss = 3.43779312, grad/param norm = 2.3192e+00, time/batch = 0.2313s	
407/2700 (epoch 7.537), train_loss = 3.42566155, grad/param norm = 2.0157e+00, time/batch = 0.2311s	
408/2700 (epoch 7.556), train_loss = 3.37637230, grad/param norm = 2.0054e+00, time/batch = 0.2363s	
409/2700 (epoch 7.574), train_loss = 3.31344015, grad/param norm = 1.8269e+00, time/batch = 0.2361s	
410/2700 (epoch 7.593), train_loss = 3.33624403, grad/param norm = 2.3060e+00, time/batch = 0.2346s	
411/2700 (epoch 7.611), train_loss = 3.30579037, grad/param norm = 2.3143e+00, time/batch = 0.2273s	
412/2700 (epoch 7.630), train_loss = 3.33107346, grad/param norm = 2.2836e+00, time/batch = 0.2283s	
413/2700 (epoch 7.648), train_loss = 3.41156131, grad/param norm = 2.3504e+00, time/batch = 0.2216s	
414/2700 (epoch 7.667), train_loss = 3.35601233, grad/param norm = 2.4111e+00, time/batch = 0.2093s	
415/2700 (epoch 7.685), train_loss = 3.46973322, grad/param norm = 3.3317e+00, time/batch = 0.2028s	
416/2700 (epoch 7.704), train_loss = 3.60311978, grad/param norm = 3.5245e+00, time/batch = 0.2302s	
417/2700 (epoch 7.722), train_loss = 3.83617103, grad/param norm = 3.4059e+00, time/batch = 0.2240s	
418/2700 (epoch 7.741), train_loss = 4.80637578, grad/param norm = 4.3189e+00, time/batch = 0.2254s	
419/2700 (epoch 7.759), train_loss = 4.54197881, grad/param norm = 5.0519e+00, time/batch = 0.2317s	
420/2700 (epoch 7.778), train_loss = 4.03283215, grad/param norm = 4.0466e+00, time/batch = 0.2306s	
421/2700 (epoch 7.796), train_loss = 3.73251158, grad/param norm = 3.3788e+00, time/batch = 0.2204s	
422/2700 (epoch 7.815), train_loss = 3.47360372, grad/param norm = 3.2510e+00, time/batch = 0.2164s	
423/2700 (epoch 7.833), train_loss = 3.44832267, grad/param norm = 2.6140e+00, time/batch = 0.2193s	
424/2700 (epoch 7.852), train_loss = 3.34255641, grad/param norm = 2.1380e+00, time/batch = 0.1865s	
425/2700 (epoch 7.870), train_loss = 3.27208595, grad/param norm = 1.4643e+00, time/batch = 0.2341s	
426/2700 (epoch 7.889), train_loss = 3.28774209, grad/param norm = 1.2633e+00, time/batch = 0.2345s	
427/2700 (epoch 7.907), train_loss = 3.33901579, grad/param norm = 1.3374e+00, time/batch = 0.2289s	
428/2700 (epoch 7.926), train_loss = 3.30719716, grad/param norm = 1.5095e+00, time/batch = 0.2208s	
429/2700 (epoch 7.944), train_loss = 3.32226327, grad/param norm = 1.3569e+00, time/batch = 0.2203s	
430/2700 (epoch 7.963), train_loss = 3.38800618, grad/param norm = 1.3088e+00, time/batch = 0.2240s	
431/2700 (epoch 7.981), train_loss = 3.45559189, grad/param norm = 1.2476e+00, time/batch = 0.2184s	
432/2700 (epoch 8.000), train_loss = 3.36646890, grad/param norm = 1.3305e+00, time/batch = 0.2169s	
433/2700 (epoch 8.019), train_loss = 3.28979739, grad/param norm = 1.5416e+00, time/batch = 0.2271s	
434/2700 (epoch 8.037), train_loss = 3.35210218, grad/param norm = 1.6952e+00, time/batch = 0.2317s	
435/2700 (epoch 8.056), train_loss = 3.31060112, grad/param norm = 1.4517e+00, time/batch = 0.2359s	
436/2700 (epoch 8.074), train_loss = 3.32869272, grad/param norm = 1.3689e+00, time/batch = 0.2362s	
437/2700 (epoch 8.093), train_loss = 3.36307528, grad/param norm = 1.7307e+00, time/batch = 0.2361s	
438/2700 (epoch 8.111), train_loss = 3.37431942, grad/param norm = 2.0621e+00, time/batch = 0.2376s	
439/2700 (epoch 8.130), train_loss = 3.39315663, grad/param norm = 2.3474e+00, time/batch = 0.2356s	
440/2700 (epoch 8.148), train_loss = 3.36110303, grad/param norm = 2.5267e+00, time/batch = 0.2362s	
441/2700 (epoch 8.167), train_loss = 3.38304498, grad/param norm = 2.4751e+00, time/batch = 0.2134s	
442/2700 (epoch 8.185), train_loss = 3.38086382, grad/param norm = 2.4832e+00, time/batch = 0.2148s	
443/2700 (epoch 8.204), train_loss = 3.30786666, grad/param norm = 2.3759e+00, time/batch = 0.1683s	
444/2700 (epoch 8.222), train_loss = 3.26213830, grad/param norm = 2.6083e+00, time/batch = 0.2245s	
445/2700 (epoch 8.241), train_loss = 3.28796057, grad/param norm = 2.3697e+00, time/batch = 0.2184s	
446/2700 (epoch 8.259), train_loss = 3.33804490, grad/param norm = 2.3940e+00, time/batch = 0.2257s	
447/2700 (epoch 8.278), train_loss = 3.44431403, grad/param norm = 2.6281e+00, time/batch = 0.2299s	
448/2700 (epoch 8.296), train_loss = 3.43051077, grad/param norm = 2.3952e+00, time/batch = 0.2326s	
449/2700 (epoch 8.315), train_loss = 3.37410456, grad/param norm = 1.9365e+00, time/batch = 0.2343s	
450/2700 (epoch 8.333), train_loss = 3.42483534, grad/param norm = 1.7103e+00, time/batch = 0.2277s	
451/2700 (epoch 8.352), train_loss = 3.43288924, grad/param norm = 1.7478e+00, time/batch = 0.2222s	
452/2700 (epoch 8.370), train_loss = 3.40344106, grad/param norm = 1.9020e+00, time/batch = 0.2125s	
453/2700 (epoch 8.389), train_loss = 3.33564011, grad/param norm = 2.0260e+00, time/batch = 0.1945s	
454/2700 (epoch 8.407), train_loss = 3.38337593, grad/param norm = 2.1685e+00, time/batch = 0.2141s	
455/2700 (epoch 8.426), train_loss = 3.39595038, grad/param norm = 2.1563e+00, time/batch = 0.2228s	
456/2700 (epoch 8.444), train_loss = 3.32757451, grad/param norm = 2.3231e+00, time/batch = 0.2331s	
457/2700 (epoch 8.463), train_loss = 3.40685208, grad/param norm = 2.7682e+00, time/batch = 0.2314s	
458/2700 (epoch 8.481), train_loss = 3.50747812, grad/param norm = 2.7588e+00, time/batch = 0.2240s	
459/2700 (epoch 8.500), train_loss = 3.50817973, grad/param norm = 2.5344e+00, time/batch = 0.2232s	
460/2700 (epoch 8.519), train_loss = 3.43902941, grad/param norm = 2.2141e+00, time/batch = 0.2325s	
461/2700 (epoch 8.537), train_loss = 3.41676437, grad/param norm = 1.9502e+00, time/batch = 0.2274s	
462/2700 (epoch 8.556), train_loss = 3.39104015, grad/param norm = 2.0028e+00, time/batch = 0.2188s	
463/2700 (epoch 8.574), train_loss = 3.28397261, grad/param norm = 1.4947e+00, time/batch = 0.2321s	
464/2700 (epoch 8.593), train_loss = 3.30019338, grad/param norm = 1.8530e+00, time/batch = 0.2320s	
465/2700 (epoch 8.611), train_loss = 3.25928398, grad/param norm = 1.7678e+00, time/batch = 0.2358s	
466/2700 (epoch 8.630), train_loss = 3.28996666, grad/param norm = 2.0150e+00, time/batch = 0.2367s	
467/2700 (epoch 8.648), train_loss = 3.40697278, grad/param norm = 2.3926e+00, time/batch = 0.2367s	
468/2700 (epoch 8.667), train_loss = 3.37798791, grad/param norm = 2.6271e+00, time/batch = 0.2249s	
469/2700 (epoch 8.685), train_loss = 3.37184725, grad/param norm = 2.2969e+00, time/batch = 0.2218s	
470/2700 (epoch 8.704), train_loss = 3.34059084, grad/param norm = 2.6741e+00, time/batch = 0.2114s	
471/2700 (epoch 8.722), train_loss = 3.39008873, grad/param norm = 2.2566e+00, time/batch = 0.2373s	
472/2700 (epoch 8.741), train_loss = 3.44986554, grad/param norm = 2.1825e+00, time/batch = 0.2313s	
473/2700 (epoch 8.759), train_loss = 3.44410735, grad/param norm = 2.3622e+00, time/batch = 0.2250s	
474/2700 (epoch 8.778), train_loss = 3.40132517, grad/param norm = 2.5647e+00, time/batch = 0.2314s	
475/2700 (epoch 8.796), train_loss = 3.43382834, grad/param norm = 2.3137e+00, time/batch = 0.2319s	
476/2700 (epoch 8.815), train_loss = 3.31945662, grad/param norm = 2.3015e+00, time/batch = 0.2349s	
477/2700 (epoch 8.833), train_loss = 3.41648780, grad/param norm = 2.4250e+00, time/batch = 0.2299s	
478/2700 (epoch 8.852), train_loss = 3.34416708, grad/param norm = 2.2660e+00, time/batch = 0.2356s	
479/2700 (epoch 8.870), train_loss = 3.34163856, grad/param norm = 2.2950e+00, time/batch = 0.2255s	
480/2700 (epoch 8.889), train_loss = 3.37427146, grad/param norm = 2.4026e+00, time/batch = 0.2041s	
481/2700 (epoch 8.907), train_loss = 3.44121967, grad/param norm = 2.4587e+00, time/batch = 0.2072s	
482/2700 (epoch 8.926), train_loss = 3.39014505, grad/param norm = 2.4906e+00, time/batch = 0.2224s	
483/2700 (epoch 8.944), train_loss = 3.41320707, grad/param norm = 2.2536e+00, time/batch = 0.2206s	
484/2700 (epoch 8.963), train_loss = 3.47381072, grad/param norm = 2.1379e+00, time/batch = 0.2288s	
485/2700 (epoch 8.981), train_loss = 3.53377129, grad/param norm = 2.0592e+00, time/batch = 0.2300s	
486/2700 (epoch 9.000), train_loss = 3.42253193, grad/param norm = 1.9972e+00, time/batch = 0.2336s	
487/2700 (epoch 9.019), train_loss = 3.32623891, grad/param norm = 2.0068e+00, time/batch = 0.2341s	
488/2700 (epoch 9.037), train_loss = 3.36983269, grad/param norm = 2.1354e+00, time/batch = 0.2329s	
489/2700 (epoch 9.056), train_loss = 3.35769798, grad/param norm = 1.9792e+00, time/batch = 0.2290s	
490/2700 (epoch 9.074), train_loss = 3.38146409, grad/param norm = 1.9872e+00, time/batch = 0.2358s	
491/2700 (epoch 9.093), train_loss = 3.41468032, grad/param norm = 1.9379e+00, time/batch = 0.2084s	
492/2700 (epoch 9.111), train_loss = 3.41498051, grad/param norm = 2.2432e+00, time/batch = 0.2303s	
493/2700 (epoch 9.130), train_loss = 3.43559351, grad/param norm = 2.4309e+00, time/batch = 0.2129s	
494/2700 (epoch 9.148), train_loss = 3.40627362, grad/param norm = 2.6939e+00, time/batch = 0.2085s	
495/2700 (epoch 9.167), train_loss = 3.42231351, grad/param norm = 2.5684e+00, time/batch = 0.2068s	
496/2700 (epoch 9.185), train_loss = 3.37010171, grad/param norm = 2.3314e+00, time/batch = 0.2245s	
497/2700 (epoch 9.204), train_loss = 3.30002837, grad/param norm = 2.3198e+00, time/batch = 0.2311s	
498/2700 (epoch 9.222), train_loss = 3.27386759, grad/param norm = 2.6038e+00, time/batch = 0.2285s	
499/2700 (epoch 9.241), train_loss = 3.30020726, grad/param norm = 2.4335e+00, time/batch = 0.2314s	
500/2700 (epoch 9.259), train_loss = 3.33995084, grad/param norm = 2.8455e+00, time/batch = 0.2342s	
501/2700 (epoch 9.278), train_loss = 3.44500098, grad/param norm = 2.3622e+00, time/batch = 0.2272s	
502/2700 (epoch 9.296), train_loss = 3.40565605, grad/param norm = 2.1393e+00, time/batch = 0.2265s	
503/2700 (epoch 9.315), train_loss = 3.36618097, grad/param norm = 1.7684e+00, time/batch = 0.2313s	
504/2700 (epoch 9.333), train_loss = 3.41429440, grad/param norm = 1.6888e+00, time/batch = 0.2239s	
505/2700 (epoch 9.352), train_loss = 3.44970526, grad/param norm = 1.6474e+00, time/batch = 0.2215s	
506/2700 (epoch 9.370), train_loss = 3.40297453, grad/param norm = 1.7470e+00, time/batch = 0.2310s	
507/2700 (epoch 9.389), train_loss = 3.36593149, grad/param norm = 1.9936e+00, time/batch = 0.2296s	
508/2700 (epoch 9.407), train_loss = 3.41995297, grad/param norm = 2.0334e+00, time/batch = 0.2306s	
509/2700 (epoch 9.426), train_loss = 3.38776165, grad/param norm = 2.1781e+00, time/batch = 0.2318s	
510/2700 (epoch 9.444), train_loss = 3.32456491, grad/param norm = 2.3368e+00, time/batch = 0.2232s	
511/2700 (epoch 9.463), train_loss = 3.36552360, grad/param norm = 2.3857e+00, time/batch = 0.2244s	
512/2700 (epoch 9.481), train_loss = 3.44366111, grad/param norm = 2.3248e+00, time/batch = 0.2127s	
513/2700 (epoch 9.500), train_loss = 3.49394685, grad/param norm = 2.4422e+00, time/batch = 0.2166s	
514/2700 (epoch 9.519), train_loss = 3.47021240, grad/param norm = 2.7160e+00, time/batch = 0.2183s	
515/2700 (epoch 9.537), train_loss = 3.49287810, grad/param norm = 2.4247e+00, time/batch = 0.2222s	
516/2700 (epoch 9.556), train_loss = 3.41132554, grad/param norm = 2.0539e+00, time/batch = 0.2204s	
517/2700 (epoch 9.574), train_loss = 3.30957842, grad/param norm = 1.8098e+00, time/batch = 0.1942s	
518/2700 (epoch 9.593), train_loss = 3.32805400, grad/param norm = 2.3394e+00, time/batch = 0.2335s	
519/2700 (epoch 9.611), train_loss = 3.29864988, grad/param norm = 2.1877e+00, time/batch = 0.2306s	
520/2700 (epoch 9.630), train_loss = 3.29669830, grad/param norm = 2.1690e+00, time/batch = 0.2220s	
521/2700 (epoch 9.648), train_loss = 3.40982176, grad/param norm = 2.1861e+00, time/batch = 0.2275s	
522/2700 (epoch 9.667), train_loss = 3.32856616, grad/param norm = 2.1675e+00, time/batch = 0.2318s	
523/2700 (epoch 9.685), train_loss = 3.32157340, grad/param norm = 1.9613e+00, time/batch = 0.2203s	
524/2700 (epoch 9.704), train_loss = 3.31152727, grad/param norm = 2.2460e+00, time/batch = 0.2342s	
525/2700 (epoch 9.722), train_loss = 3.35269634, grad/param norm = 2.2772e+00, time/batch = 0.2360s	
526/2700 (epoch 9.741), train_loss = 3.46269847, grad/param norm = 2.4572e+00, time/batch = 0.2264s	
527/2700 (epoch 9.759), train_loss = 3.45489155, grad/param norm = 2.5520e+00, time/batch = 0.2330s	
528/2700 (epoch 9.778), train_loss = 3.40356352, grad/param norm = 2.5470e+00, time/batch = 0.2347s	
529/2700 (epoch 9.796), train_loss = 3.42019690, grad/param norm = 2.3885e+00, time/batch = 0.2238s	
530/2700 (epoch 9.815), train_loss = 3.32491798, grad/param norm = 2.4269e+00, time/batch = 0.2367s	
531/2700 (epoch 9.833), train_loss = 3.40803245, grad/param norm = 2.5992e+00, time/batch = 0.2048s	
532/2700 (epoch 9.852), train_loss = 3.39067813, grad/param norm = 2.7215e+00, time/batch = 0.1807s	
533/2700 (epoch 9.870), train_loss = 3.40743572, grad/param norm = 2.2871e+00, time/batch = 0.2161s	
534/2700 (epoch 9.889), train_loss = 3.34630653, grad/param norm = 2.1143e+00, time/batch = 0.2169s	
535/2700 (epoch 9.907), train_loss = 3.41168092, grad/param norm = 2.2450e+00, time/batch = 0.2238s	
536/2700 (epoch 9.926), train_loss = 3.38850797, grad/param norm = 2.3973e+00, time/batch = 0.2315s	
537/2700 (epoch 9.944), train_loss = 3.40376033, grad/param norm = 2.1762e+00, time/batch = 0.2311s	
538/2700 (epoch 9.963), train_loss = 3.47474667, grad/param norm = 2.3208e+00, time/batch = 0.2360s	
539/2700 (epoch 9.981), train_loss = 3.54400506, grad/param norm = 1.9459e+00, time/batch = 0.2314s	
decayed learning rate by a factor 0.97 to 0.00194	
540/2700 (epoch 10.000), train_loss = 3.41253899, grad/param norm = 1.9297e+00, time/batch = 0.2305s	
541/2700 (epoch 10.019), train_loss = 3.32525301, grad/param norm = 1.9617e+00, time/batch = 0.2155s	
542/2700 (epoch 10.037), train_loss = 3.36454215, grad/param norm = 2.0743e+00, time/batch = 0.2229s	
543/2700 (epoch 10.056), train_loss = 3.35728687, grad/param norm = 1.8923e+00, time/batch = 0.2188s	
544/2700 (epoch 10.074), train_loss = 3.36324402, grad/param norm = 1.6520e+00, time/batch = 0.2241s	
545/2700 (epoch 10.093), train_loss = 3.37974346, grad/param norm = 1.6996e+00, time/batch = 0.2252s	
546/2700 (epoch 10.111), train_loss = 3.37311388, grad/param norm = 1.9855e+00, time/batch = 0.2326s	
547/2700 (epoch 10.130), train_loss = 3.40780551, grad/param norm = 2.1941e+00, time/batch = 0.2339s	
548/2700 (epoch 10.148), train_loss = 3.38051481, grad/param norm = 2.4849e+00, time/batch = 0.2209s	
549/2700 (epoch 10.167), train_loss = 3.39992901, grad/param norm = 2.4319e+00, time/batch = 0.2376s	
550/2700 (epoch 10.185), train_loss = 3.35787972, grad/param norm = 2.2533e+00, time/batch = 0.2280s	
551/2700 (epoch 10.204), train_loss = 3.28497012, grad/param norm = 2.1455e+00, time/batch = 0.2267s	
552/2700 (epoch 10.222), train_loss = 3.24614662, grad/param norm = 2.4442e+00, time/batch = 0.2135s	
553/2700 (epoch 10.241), train_loss = 3.27396977, grad/param norm = 2.0421e+00, time/batch = 0.2144s	
554/2700 (epoch 10.259), train_loss = 3.28212547, grad/param norm = 1.8264e+00, time/batch = 0.1965s	
555/2700 (epoch 10.278), train_loss = 3.38459335, grad/param norm = 2.1751e+00, time/batch = 0.2056s	
556/2700 (epoch 10.296), train_loss = 3.40227972, grad/param norm = 2.2126e+00, time/batch = 0.2347s	
557/2700 (epoch 10.315), train_loss = 3.38680086, grad/param norm = 2.1051e+00, time/batch = 0.2295s	
558/2700 (epoch 10.333), train_loss = 3.46068809, grad/param norm = 1.7833e+00, time/batch = 0.2286s	
559/2700 (epoch 10.352), train_loss = 3.42428422, grad/param norm = 1.7142e+00, time/batch = 0.2261s	
560/2700 (epoch 10.370), train_loss = 3.40163205, grad/param norm = 2.0920e+00, time/batch = 0.2325s	
561/2700 (epoch 10.389), train_loss = 3.35775020, grad/param norm = 2.2125e+00, time/batch = 0.2364s	
562/2700 (epoch 10.407), train_loss = 3.38650713, grad/param norm = 2.1320e+00, time/batch = 0.2215s	
563/2700 (epoch 10.426), train_loss = 3.37652307, grad/param norm = 2.1096e+00, time/batch = 0.1909s	
564/2700 (epoch 10.444), train_loss = 3.32255470, grad/param norm = 2.2266e+00, time/batch = 0.2326s	
565/2700 (epoch 10.463), train_loss = 3.35695378, grad/param norm = 2.3587e+00, time/batch = 0.2259s	
566/2700 (epoch 10.481), train_loss = 3.44084670, grad/param norm = 2.3337e+00, time/batch = 0.2250s	
567/2700 (epoch 10.500), train_loss = 3.48501801, grad/param norm = 2.3735e+00, time/batch = 0.2123s	
568/2700 (epoch 10.519), train_loss = 3.46418349, grad/param norm = 2.6382e+00, time/batch = 0.2244s	
569/2700 (epoch 10.537), train_loss = 3.48912790, grad/param norm = 2.3586e+00, time/batch = 0.2353s	
570/2700 (epoch 10.556), train_loss = 3.43194500, grad/param norm = 2.1244e+00, time/batch = 0.2340s	
571/2700 (epoch 10.574), train_loss = 3.30717885, grad/param norm = 1.7702e+00, time/batch = 0.2237s	
572/2700 (epoch 10.593), train_loss = 3.32999791, grad/param norm = 2.1703e+00, time/batch = 0.2037s	
573/2700 (epoch 10.611), train_loss = 3.29582695, grad/param norm = 2.2330e+00, time/batch = 0.2137s	
574/2700 (epoch 10.630), train_loss = 3.33653728, grad/param norm = 2.4871e+00, time/batch = 0.2337s	
575/2700 (epoch 10.648), train_loss = 3.43842335, grad/param norm = 2.3100e+00, time/batch = 0.2330s	
576/2700 (epoch 10.667), train_loss = 3.34562995, grad/param norm = 2.2772e+00, time/batch = 0.2330s	
577/2700 (epoch 10.685), train_loss = 3.34354853, grad/param norm = 2.0139e+00, time/batch = 0.2189s	
578/2700 (epoch 10.704), train_loss = 3.32940276, grad/param norm = 2.1662e+00, time/batch = 0.2238s	
579/2700 (epoch 10.722), train_loss = 3.33016525, grad/param norm = 1.8745e+00, time/batch = 0.2199s	
580/2700 (epoch 10.741), train_loss = 3.42416545, grad/param norm = 1.7843e+00, time/batch = 0.2316s	
581/2700 (epoch 10.759), train_loss = 3.39553849, grad/param norm = 1.9388e+00, time/batch = 0.2254s	
582/2700 (epoch 10.778), train_loss = 3.38429846, grad/param norm = 2.1155e+00, time/batch = 0.2271s	
583/2700 (epoch 10.796), train_loss = 3.38949733, grad/param norm = 2.0542e+00, time/batch = 0.2313s	
584/2700 (epoch 10.815), train_loss = 3.29142721, grad/param norm = 2.1576e+00, time/batch = 0.2346s	
585/2700 (epoch 10.833), train_loss = 3.37135750, grad/param norm = 2.5514e+00, time/batch = 0.2338s	
586/2700 (epoch 10.852), train_loss = 3.36404119, grad/param norm = 2.6228e+00, time/batch = 0.2168s	
587/2700 (epoch 10.870), train_loss = 3.35204499, grad/param norm = 2.4221e+00, time/batch = 0.2362s	
588/2700 (epoch 10.889), train_loss = 3.36781680, grad/param norm = 2.4408e+00, time/batch = 0.2338s	
589/2700 (epoch 10.907), train_loss = 3.42757868, grad/param norm = 2.4039e+00, time/batch = 0.2332s	
590/2700 (epoch 10.926), train_loss = 3.42509611, grad/param norm = 2.8428e+00, time/batch = 0.2204s	
591/2700 (epoch 10.944), train_loss = 3.45360632, grad/param norm = 2.2586e+00, time/batch = 0.2256s	
592/2700 (epoch 10.963), train_loss = 3.44098804, grad/param norm = 1.8503e+00, time/batch = 0.2268s	
593/2700 (epoch 10.981), train_loss = 3.50035968, grad/param norm = 1.7924e+00, time/batch = 0.2299s	
decayed learning rate by a factor 0.97 to 0.0018818	
594/2700 (epoch 11.000), train_loss = 3.40320913, grad/param norm = 1.8073e+00, time/batch = 0.2313s	
595/2700 (epoch 11.019), train_loss = 3.31910920, grad/param norm = 1.9002e+00, time/batch = 0.2315s	
596/2700 (epoch 11.037), train_loss = 3.36027759, grad/param norm = 2.0055e+00, time/batch = 0.2318s	
597/2700 (epoch 11.056), train_loss = 3.34784999, grad/param norm = 1.7724e+00, time/batch = 0.2354s	
598/2700 (epoch 11.074), train_loss = 3.35274476, grad/param norm = 1.6560e+00, time/batch = 0.2339s	
599/2700 (epoch 11.093), train_loss = 3.38586919, grad/param norm = 1.7611e+00, time/batch = 0.2355s	
600/2700 (epoch 11.111), train_loss = 3.38143871, grad/param norm = 2.0360e+00, time/batch = 0.2294s	
601/2700 (epoch 11.130), train_loss = 3.40898198, grad/param norm = 2.2243e+00, time/batch = 0.2213s	
602/2700 (epoch 11.148), train_loss = 3.37413772, grad/param norm = 2.4754e+00, time/batch = 0.2187s	
603/2700 (epoch 11.167), train_loss = 3.39236200, grad/param norm = 2.4088e+00, time/batch = 0.2331s	
604/2700 (epoch 11.185), train_loss = 3.35321680, grad/param norm = 2.2254e+00, time/batch = 0.2244s	
605/2700 (epoch 11.204), train_loss = 3.27850773, grad/param norm = 2.0945e+00, time/batch = 0.2028s	
606/2700 (epoch 11.222), train_loss = 3.24518399, grad/param norm = 2.4179e+00, time/batch = 0.2341s	
607/2700 (epoch 11.241), train_loss = 3.27631087, grad/param norm = 2.0785e+00, time/batch = 0.2348s	
608/2700 (epoch 11.259), train_loss = 3.29381743, grad/param norm = 1.8537e+00, time/batch = 0.2356s	
609/2700 (epoch 11.278), train_loss = 3.38250669, grad/param norm = 2.1753e+00, time/batch = 0.2273s	
610/2700 (epoch 11.296), train_loss = 3.39281846, grad/param norm = 2.1273e+00, time/batch = 0.2359s	
611/2700 (epoch 11.315), train_loss = 3.35617676, grad/param norm = 1.7783e+00, time/batch = 0.2141s	
612/2700 (epoch 11.333), train_loss = 3.41290129, grad/param norm = 1.5937e+00, time/batch = 0.2157s	
613/2700 (epoch 11.352), train_loss = 3.41870133, grad/param norm = 1.6863e+00, time/batch = 0.2126s	
614/2700 (epoch 11.370), train_loss = 3.40339030, grad/param norm = 2.0348e+00, time/batch = 0.2237s	
615/2700 (epoch 11.389), train_loss = 3.35458723, grad/param norm = 2.2017e+00, time/batch = 0.2013s	
616/2700 (epoch 11.407), train_loss = 3.38978559, grad/param norm = 2.2007e+00, time/batch = 0.2152s	
617/2700 (epoch 11.426), train_loss = 3.38856126, grad/param norm = 2.1695e+00, time/batch = 0.2114s	
618/2700 (epoch 11.444), train_loss = 3.32520817, grad/param norm = 2.2408e+00, time/batch = 0.2288s	
619/2700 (epoch 11.463), train_loss = 3.35747561, grad/param norm = 2.3495e+00, time/batch = 0.2080s	
620/2700 (epoch 11.481), train_loss = 3.43264905, grad/param norm = 2.2963e+00, time/batch = 0.2259s	
621/2700 (epoch 11.500), train_loss = 3.48517408, grad/param norm = 2.3323e+00, time/batch = 0.2246s	
622/2700 (epoch 11.519), train_loss = 3.45282874, grad/param norm = 2.5025e+00, time/batch = 0.2307s	
623/2700 (epoch 11.537), train_loss = 3.46889555, grad/param norm = 2.2830e+00, time/batch = 0.2120s	
624/2700 (epoch 11.556), train_loss = 3.40197696, grad/param norm = 1.9767e+00, time/batch = 0.1970s	
625/2700 (epoch 11.574), train_loss = 3.30208969, grad/param norm = 1.7399e+00, time/batch = 0.1957s	
626/2700 (epoch 11.593), train_loss = 3.32026763, grad/param norm = 2.0927e+00, time/batch = 0.2355s	
627/2700 (epoch 11.611), train_loss = 3.28296017, grad/param norm = 2.1096e+00, time/batch = 0.2344s	
628/2700 (epoch 11.630), train_loss = 3.32602093, grad/param norm = 2.4244e+00, time/batch = 0.2233s	
629/2700 (epoch 11.648), train_loss = 3.43234687, grad/param norm = 2.3209e+00, time/batch = 0.2361s	
630/2700 (epoch 11.667), train_loss = 3.32631468, grad/param norm = 2.2258e+00, time/batch = 0.2335s	
631/2700 (epoch 11.685), train_loss = 3.32356360, grad/param norm = 1.9290e+00, time/batch = 0.2271s	
632/2700 (epoch 11.704), train_loss = 3.30354403, grad/param norm = 2.1542e+00, time/batch = 0.2321s	
633/2700 (epoch 11.722), train_loss = 3.33965060, grad/param norm = 1.9906e+00, time/batch = 0.2358s	
634/2700 (epoch 11.741), train_loss = 3.42522999, grad/param norm = 1.8660e+00, time/batch = 0.2123s	
635/2700 (epoch 11.759), train_loss = 3.39416664, grad/param norm = 2.0488e+00, time/batch = 0.2355s	
636/2700 (epoch 11.778), train_loss = 3.38853118, grad/param norm = 2.2552e+00, time/batch = 0.2371s	
637/2700 (epoch 11.796), train_loss = 3.39736860, grad/param norm = 2.1607e+00, time/batch = 0.2305s	
638/2700 (epoch 11.815), train_loss = 3.28783548, grad/param norm = 2.1769e+00, time/batch = 0.2331s	
639/2700 (epoch 11.833), train_loss = 3.37311074, grad/param norm = 2.3864e+00, time/batch = 0.2358s	
640/2700 (epoch 11.852), train_loss = 3.33891455, grad/param norm = 2.3699e+00, time/batch = 0.2365s	
641/2700 (epoch 11.870), train_loss = 3.34626624, grad/param norm = 2.1453e+00, time/batch = 0.2199s	
642/2700 (epoch 11.889), train_loss = 3.34478139, grad/param norm = 2.0696e+00, time/batch = 0.2137s	
643/2700 (epoch 11.907), train_loss = 3.39085215, grad/param norm = 2.2359e+00, time/batch = 0.2256s	
644/2700 (epoch 11.926), train_loss = 3.40173404, grad/param norm = 2.7550e+00, time/batch = 0.2354s	
645/2700 (epoch 11.944), train_loss = 3.44807810, grad/param norm = 2.1863e+00, time/batch = 0.2318s	
646/2700 (epoch 11.963), train_loss = 3.44163007, grad/param norm = 1.8565e+00, time/batch = 0.2329s	
647/2700 (epoch 11.981), train_loss = 3.51004475, grad/param norm = 1.8184e+00, time/batch = 0.2354s	
decayed learning rate by a factor 0.97 to 0.001825346	
648/2700 (epoch 12.000), train_loss = 3.40750429, grad/param norm = 1.8314e+00, time/batch = 0.2348s	
649/2700 (epoch 12.019), train_loss = 3.32008135, grad/param norm = 1.8471e+00, time/batch = 0.2351s	
650/2700 (epoch 12.037), train_loss = 3.35283178, grad/param norm = 1.8987e+00, time/batch = 0.2362s	
651/2700 (epoch 12.056), train_loss = 3.33607848, grad/param norm = 1.6602e+00, time/batch = 0.2241s	
652/2700 (epoch 12.074), train_loss = 3.34495663, grad/param norm = 1.5498e+00, time/batch = 0.2322s	
653/2700 (epoch 12.093), train_loss = 3.37817454, grad/param norm = 1.6704e+00, time/batch = 0.2073s	
654/2700 (epoch 12.111), train_loss = 3.37133590, grad/param norm = 1.9567e+00, time/batch = 0.2220s	
655/2700 (epoch 12.130), train_loss = 3.40001198, grad/param norm = 2.1677e+00, time/batch = 0.2324s	
656/2700 (epoch 12.148), train_loss = 3.36623095, grad/param norm = 2.3766e+00, time/batch = 0.2226s	
657/2700 (epoch 12.167), train_loss = 3.38163075, grad/param norm = 2.4116e+00, time/batch = 0.2307s	
658/2700 (epoch 12.185), train_loss = 3.35743559, grad/param norm = 2.2640e+00, time/batch = 0.2301s	
659/2700 (epoch 12.204), train_loss = 3.27303739, grad/param norm = 2.1077e+00, time/batch = 0.2328s	
660/2700 (epoch 12.222), train_loss = 3.23899669, grad/param norm = 2.3609e+00, time/batch = 0.2351s	
661/2700 (epoch 12.241), train_loss = 3.26054979, grad/param norm = 1.9829e+00, time/batch = 0.2137s	
662/2700 (epoch 12.259), train_loss = 3.27720191, grad/param norm = 1.7944e+00, time/batch = 0.1872s	
663/2700 (epoch 12.278), train_loss = 3.37728075, grad/param norm = 2.1366e+00, time/batch = 0.1951s	
664/2700 (epoch 12.296), train_loss = 3.40174522, grad/param norm = 2.1169e+00, time/batch = 0.2319s	
665/2700 (epoch 12.315), train_loss = 3.35535304, grad/param norm = 1.7933e+00, time/batch = 0.2058s	
666/2700 (epoch 12.333), train_loss = 3.41796040, grad/param norm = 1.6053e+00, time/batch = 0.2163s	
667/2700 (epoch 12.352), train_loss = 3.41948198, grad/param norm = 1.7176e+00, time/batch = 0.2140s	
668/2700 (epoch 12.370), train_loss = 3.40647694, grad/param norm = 2.0852e+00, time/batch = 0.2243s	
669/2700 (epoch 12.389), train_loss = 3.35134550, grad/param norm = 2.1496e+00, time/batch = 0.2296s	
670/2700 (epoch 12.407), train_loss = 3.37714054, grad/param norm = 2.0776e+00, time/batch = 0.2313s	
671/2700 (epoch 12.426), train_loss = 3.37510736, grad/param norm = 2.0386e+00, time/batch = 0.2247s	
672/2700 (epoch 12.444), train_loss = 3.30974369, grad/param norm = 2.1075e+00, time/batch = 0.2237s	
673/2700 (epoch 12.463), train_loss = 3.34478913, grad/param norm = 2.2971e+00, time/batch = 0.2348s	
674/2700 (epoch 12.481), train_loss = 3.42619045, grad/param norm = 2.2295e+00, time/batch = 0.2329s	
675/2700 (epoch 12.500), train_loss = 3.46423562, grad/param norm = 2.1918e+00, time/batch = 0.2366s	
676/2700 (epoch 12.519), train_loss = 3.44003726, grad/param norm = 2.3820e+00, time/batch = 0.2337s	
677/2700 (epoch 12.537), train_loss = 3.45444982, grad/param norm = 2.1514e+00, time/batch = 0.2281s	
678/2700 (epoch 12.556), train_loss = 3.39317250, grad/param norm = 1.9298e+00, time/batch = 0.2335s	
679/2700 (epoch 12.574), train_loss = 3.29382988, grad/param norm = 1.6437e+00, time/batch = 0.2361s	
680/2700 (epoch 12.593), train_loss = 3.31816234, grad/param norm = 2.0158e+00, time/batch = 0.2333s	
681/2700 (epoch 12.611), train_loss = 3.28434346, grad/param norm = 2.0633e+00, time/batch = 0.2144s	
682/2700 (epoch 12.630), train_loss = 3.33094239, grad/param norm = 2.4226e+00, time/batch = 0.1935s	
683/2700 (epoch 12.648), train_loss = 3.43181952, grad/param norm = 2.3001e+00, time/batch = 0.2313s	
684/2700 (epoch 12.667), train_loss = 3.33026817, grad/param norm = 2.2364e+00, time/batch = 0.2276s	
685/2700 (epoch 12.685), train_loss = 3.32790592, grad/param norm = 1.9327e+00, time/batch = 0.2303s	
686/2700 (epoch 12.704), train_loss = 3.30545953, grad/param norm = 2.1552e+00, time/batch = 0.2309s	
687/2700 (epoch 12.722), train_loss = 3.33888530, grad/param norm = 1.9465e+00, time/batch = 0.2292s	
688/2700 (epoch 12.741), train_loss = 3.41097845, grad/param norm = 1.7352e+00, time/batch = 0.2182s	
689/2700 (epoch 12.759), train_loss = 3.37112292, grad/param norm = 1.9193e+00, time/batch = 0.2159s	
690/2700 (epoch 12.778), train_loss = 3.37203097, grad/param norm = 2.1506e+00, time/batch = 0.2183s	
691/2700 (epoch 12.796), train_loss = 3.38901265, grad/param norm = 2.1225e+00, time/batch = 0.2292s	
692/2700 (epoch 12.815), train_loss = 3.28918051, grad/param norm = 2.1841e+00, time/batch = 0.2219s	
693/2700 (epoch 12.833), train_loss = 3.36881448, grad/param norm = 2.3912e+00, time/batch = 0.2025s	
694/2700 (epoch 12.852), train_loss = 3.33715889, grad/param norm = 2.3809e+00, time/batch = 0.2302s	
695/2700 (epoch 12.870), train_loss = 3.34462252, grad/param norm = 2.1138e+00, time/batch = 0.2205s	
696/2700 (epoch 12.889), train_loss = 3.34205570, grad/param norm = 2.0193e+00, time/batch = 0.2174s	
697/2700 (epoch 12.907), train_loss = 3.37614261, grad/param norm = 2.1541e+00, time/batch = 0.2311s	
698/2700 (epoch 12.926), train_loss = 3.37359580, grad/param norm = 2.4879e+00, time/batch = 0.2352s	
699/2700 (epoch 12.944), train_loss = 3.42543690, grad/param norm = 2.1296e+00, time/batch = 0.2317s	
700/2700 (epoch 12.963), train_loss = 3.43773769, grad/param norm = 1.8235e+00, time/batch = 0.2354s	
701/2700 (epoch 12.981), train_loss = 3.49923174, grad/param norm = 1.8239e+00, time/batch = 0.2191s	
decayed learning rate by a factor 0.97 to 0.00177058562	
702/2700 (epoch 13.000), train_loss = 3.40754733, grad/param norm = 1.8530e+00, time/batch = 0.2326s	
703/2700 (epoch 13.019), train_loss = 3.32078091, grad/param norm = 1.8665e+00, time/batch = 0.2371s	
704/2700 (epoch 13.037), train_loss = 3.34895635, grad/param norm = 1.9037e+00, time/batch = 0.2250s	
705/2700 (epoch 13.056), train_loss = 3.33018694, grad/param norm = 1.6352e+00, time/batch = 0.2057s	
706/2700 (epoch 13.074), train_loss = 3.34109555, grad/param norm = 1.5070e+00, time/batch = 0.2090s	
707/2700 (epoch 13.093), train_loss = 3.37318810, grad/param norm = 1.6298e+00, time/batch = 0.2195s	
708/2700 (epoch 13.111), train_loss = 3.36364663, grad/param norm = 1.8759e+00, time/batch = 0.2228s	
709/2700 (epoch 13.130), train_loss = 3.38868560, grad/param norm = 2.0441e+00, time/batch = 0.2317s	
710/2700 (epoch 13.148), train_loss = 3.35230276, grad/param norm = 2.2458e+00, time/batch = 0.2299s	
711/2700 (epoch 13.167), train_loss = 3.37092497, grad/param norm = 2.3443e+00, time/batch = 0.2307s	
712/2700 (epoch 13.185), train_loss = 3.35691125, grad/param norm = 2.2549e+00, time/batch = 0.2308s	
713/2700 (epoch 13.204), train_loss = 3.27196879, grad/param norm = 2.0941e+00, time/batch = 0.2232s	
714/2700 (epoch 13.222), train_loss = 3.23385385, grad/param norm = 2.3021e+00, time/batch = 0.2317s	
715/2700 (epoch 13.241), train_loss = 3.25313830, grad/param norm = 1.9646e+00, time/batch = 0.2304s	
716/2700 (epoch 13.259), train_loss = 3.27663294, grad/param norm = 1.8323e+00, time/batch = 0.2185s	
717/2700 (epoch 13.278), train_loss = 3.36665169, grad/param norm = 2.2133e+00, time/batch = 0.2224s	
718/2700 (epoch 13.296), train_loss = 3.38085896, grad/param norm = 2.1319e+00, time/batch = 0.2302s	
719/2700 (epoch 13.315), train_loss = 3.35208247, grad/param norm = 1.7855e+00, time/batch = 0.2308s	
720/2700 (epoch 13.333), train_loss = 3.40292094, grad/param norm = 1.5818e+00, time/batch = 0.2270s	
721/2700 (epoch 13.352), train_loss = 3.40525938, grad/param norm = 1.4081e+00, time/batch = 0.2312s	
722/2700 (epoch 13.370), train_loss = 3.35678679, grad/param norm = 1.4369e+00, time/batch = 0.2131s	
723/2700 (epoch 13.389), train_loss = 3.30830933, grad/param norm = 1.5783e+00, time/batch = 0.2159s	
724/2700 (epoch 13.407), train_loss = 3.37077633, grad/param norm = 1.8226e+00, time/batch = 0.2274s	
725/2700 (epoch 13.426), train_loss = 3.37861546, grad/param norm = 1.9267e+00, time/batch = 0.2285s	
726/2700 (epoch 13.444), train_loss = 3.30037852, grad/param norm = 2.0849e+00, time/batch = 0.2219s	
727/2700 (epoch 13.463), train_loss = 3.36766818, grad/param norm = 2.4624e+00, time/batch = 0.2202s	
728/2700 (epoch 13.481), train_loss = 3.46797701, grad/param norm = 2.5396e+00, time/batch = 0.2260s	
729/2700 (epoch 13.500), train_loss = 3.49979548, grad/param norm = 2.3270e+00, time/batch = 0.2255s	
730/2700 (epoch 13.519), train_loss = 3.42293881, grad/param norm = 2.2710e+00, time/batch = 0.2308s	
731/2700 (epoch 13.537), train_loss = 3.43337691, grad/param norm = 2.0258e+00, time/batch = 0.2257s	
732/2700 (epoch 13.556), train_loss = 3.37284348, grad/param norm = 1.8314e+00, time/batch = 0.2267s	
733/2700 (epoch 13.574), train_loss = 3.30214206, grad/param norm = 1.8076e+00, time/batch = 0.2337s	
734/2700 (epoch 13.593), train_loss = 3.34181926, grad/param norm = 2.0681e+00, time/batch = 0.2345s	
735/2700 (epoch 13.611), train_loss = 3.26069276, grad/param norm = 1.9396e+00, time/batch = 0.2324s	
736/2700 (epoch 13.630), train_loss = 3.30586725, grad/param norm = 2.1876e+00, time/batch = 0.2339s	
737/2700 (epoch 13.648), train_loss = 3.40470690, grad/param norm = 2.3308e+00, time/batch = 0.2245s	
738/2700 (epoch 13.667), train_loss = 3.35758728, grad/param norm = 2.3942e+00, time/batch = 0.2203s	
739/2700 (epoch 13.685), train_loss = 3.33209847, grad/param norm = 2.0790e+00, time/batch = 0.1986s	
740/2700 (epoch 13.704), train_loss = 3.28216993, grad/param norm = 2.1067e+00, time/batch = 0.2324s	
741/2700 (epoch 13.722), train_loss = 3.30170097, grad/param norm = 2.0416e+00, time/batch = 0.2202s	
742/2700 (epoch 13.741), train_loss = 3.42286363, grad/param norm = 2.0767e+00, time/batch = 0.2131s	
743/2700 (epoch 13.759), train_loss = 3.40530181, grad/param norm = 2.1699e+00, time/batch = 0.2169s	
744/2700 (epoch 13.778), train_loss = 3.36851182, grad/param norm = 2.4115e+00, time/batch = 0.2142s	
745/2700 (epoch 13.796), train_loss = 3.39948611, grad/param norm = 2.1385e+00, time/batch = 0.2266s	
746/2700 (epoch 13.815), train_loss = 3.26980502, grad/param norm = 1.8730e+00, time/batch = 0.2318s	
747/2700 (epoch 13.833), train_loss = 3.33605015, grad/param norm = 1.8828e+00, time/batch = 0.2246s	
748/2700 (epoch 13.852), train_loss = 3.30594870, grad/param norm = 1.8134e+00, time/batch = 0.2031s	
749/2700 (epoch 13.870), train_loss = 3.31320762, grad/param norm = 1.8543e+00, time/batch = 0.2327s	
750/2700 (epoch 13.889), train_loss = 3.32609273, grad/param norm = 1.8541e+00, time/batch = 0.2311s	
751/2700 (epoch 13.907), train_loss = 3.37455743, grad/param norm = 1.8644e+00, time/batch = 0.2240s	
752/2700 (epoch 13.926), train_loss = 3.42930687, grad/param norm = 2.9705e+00, time/batch = 0.2221s	
753/2700 (epoch 13.944), train_loss = 3.51196499, grad/param norm = 2.6920e+00, time/batch = 0.1954s	
754/2700 (epoch 13.963), train_loss = 3.55717131, grad/param norm = 3.1140e+00, time/batch = 0.2360s	
755/2700 (epoch 13.981), train_loss = 3.75017814, grad/param norm = 3.0391e+00, time/batch = 0.2349s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
756/2700 (epoch 14.000), train_loss = 3.77304350, grad/param norm = 3.3655e+00, time/batch = 0.2218s	
757/2700 (epoch 14.019), train_loss = 3.60220596, grad/param norm = 3.1378e+00, time/batch = 0.2228s	
758/2700 (epoch 14.037), train_loss = 3.62378968, grad/param norm = 2.8528e+00, time/batch = 0.2198s	
759/2700 (epoch 14.056), train_loss = 3.43163849, grad/param norm = 2.5491e+00, time/batch = 0.2355s	
760/2700 (epoch 14.074), train_loss = 3.41545453, grad/param norm = 1.9805e+00, time/batch = 0.2370s	
761/2700 (epoch 14.093), train_loss = 3.37186861, grad/param norm = 1.5972e+00, time/batch = 0.2341s	
762/2700 (epoch 14.111), train_loss = 3.32109783, grad/param norm = 1.3533e+00, time/batch = 0.2003s	
763/2700 (epoch 14.130), train_loss = 3.33013582, grad/param norm = 1.2820e+00, time/batch = 0.2144s	
764/2700 (epoch 14.148), train_loss = 3.28689760, grad/param norm = 1.3990e+00, time/batch = 0.2259s	
765/2700 (epoch 14.167), train_loss = 3.30702153, grad/param norm = 1.4207e+00, time/batch = 0.2320s	
766/2700 (epoch 14.185), train_loss = 3.28983297, grad/param norm = 1.1806e+00, time/batch = 0.2236s	
767/2700 (epoch 14.204), train_loss = 3.20719467, grad/param norm = 1.2515e+00, time/batch = 0.2244s	
768/2700 (epoch 14.222), train_loss = 3.19406709, grad/param norm = 1.5050e+00, time/batch = 0.2319s	
769/2700 (epoch 14.241), train_loss = 3.23231294, grad/param norm = 1.6785e+00, time/batch = 0.2364s	
770/2700 (epoch 14.259), train_loss = 3.27191545, grad/param norm = 2.0165e+00, time/batch = 0.2360s	
771/2700 (epoch 14.278), train_loss = 3.36318437, grad/param norm = 2.0947e+00, time/batch = 0.2256s	
772/2700 (epoch 14.296), train_loss = 3.37084578, grad/param norm = 2.0580e+00, time/batch = 0.2219s	
773/2700 (epoch 14.315), train_loss = 3.32501262, grad/param norm = 1.8048e+00, time/batch = 0.2244s	
774/2700 (epoch 14.333), train_loss = 3.40006948, grad/param norm = 1.6572e+00, time/batch = 0.2319s	
775/2700 (epoch 14.352), train_loss = 3.42185723, grad/param norm = 1.8521e+00, time/batch = 0.2269s	
776/2700 (epoch 14.370), train_loss = 3.39919851, grad/param norm = 1.5707e+00, time/batch = 0.2149s	
777/2700 (epoch 14.389), train_loss = 3.30177572, grad/param norm = 1.3235e+00, time/batch = 0.2142s	
778/2700 (epoch 14.407), train_loss = 3.33856394, grad/param norm = 1.3531e+00, time/batch = 0.2036s	
779/2700 (epoch 14.426), train_loss = 3.34395256, grad/param norm = 1.5157e+00, time/batch = 0.1909s	
780/2700 (epoch 14.444), train_loss = 3.26597111, grad/param norm = 1.5764e+00, time/batch = 0.2312s	
781/2700 (epoch 14.463), train_loss = 3.31235600, grad/param norm = 1.7584e+00, time/batch = 0.2381s	
782/2700 (epoch 14.481), train_loss = 3.39720248, grad/param norm = 1.6722e+00, time/batch = 0.2378s	
783/2700 (epoch 14.500), train_loss = 3.42116438, grad/param norm = 1.3853e+00, time/batch = 0.2253s	
784/2700 (epoch 14.519), train_loss = 3.37087228, grad/param norm = 1.3913e+00, time/batch = 0.2147s	
785/2700 (epoch 14.537), train_loss = 3.38813100, grad/param norm = 1.6981e+00, time/batch = 0.1851s	
786/2700 (epoch 14.556), train_loss = 3.38015953, grad/param norm = 1.9037e+00, time/batch = 0.2151s	
787/2700 (epoch 14.574), train_loss = 3.31505167, grad/param norm = 2.1309e+00, time/batch = 0.2134s	
788/2700 (epoch 14.593), train_loss = 3.36125901, grad/param norm = 2.6202e+00, time/batch = 0.2290s	
789/2700 (epoch 14.611), train_loss = 3.32712364, grad/param norm = 2.6804e+00, time/batch = 0.1882s	
790/2700 (epoch 14.630), train_loss = 3.33459023, grad/param norm = 2.4403e+00, time/batch = 0.2185s	
791/2700 (epoch 14.648), train_loss = 3.38106431, grad/param norm = 2.1123e+00, time/batch = 0.2371s	
792/2700 (epoch 14.667), train_loss = 3.30637180, grad/param norm = 2.1779e+00, time/batch = 0.2351s	
793/2700 (epoch 14.685), train_loss = 3.31434009, grad/param norm = 2.2974e+00, time/batch = 0.2268s	
794/2700 (epoch 14.704), train_loss = 3.30859508, grad/param norm = 2.2446e+00, time/batch = 0.2204s	
795/2700 (epoch 14.722), train_loss = 3.31594337, grad/param norm = 2.2324e+00, time/batch = 0.2312s	
796/2700 (epoch 14.741), train_loss = 3.42559432, grad/param norm = 2.3311e+00, time/batch = 0.2334s	
797/2700 (epoch 14.759), train_loss = 3.35817914, grad/param norm = 2.0544e+00, time/batch = 0.2342s	
798/2700 (epoch 14.778), train_loss = 3.35324386, grad/param norm = 1.7480e+00, time/batch = 0.2112s	
799/2700 (epoch 14.796), train_loss = 3.35305410, grad/param norm = 1.5045e+00, time/batch = 0.2227s	
800/2700 (epoch 14.815), train_loss = 3.27963591, grad/param norm = 1.4731e+00, time/batch = 0.2261s	
801/2700 (epoch 14.833), train_loss = 3.32831539, grad/param norm = 1.5038e+00, time/batch = 0.2337s	
802/2700 (epoch 14.852), train_loss = 3.30714109, grad/param norm = 1.5550e+00, time/batch = 0.2232s	
803/2700 (epoch 14.870), train_loss = 3.31760561, grad/param norm = 1.3793e+00, time/batch = 0.2047s	
804/2700 (epoch 14.889), train_loss = 3.31942892, grad/param norm = 1.4865e+00, time/batch = 0.2234s	
805/2700 (epoch 14.907), train_loss = 3.40490316, grad/param norm = 1.6153e+00, time/batch = 0.2304s	
806/2700 (epoch 14.926), train_loss = 3.33580874, grad/param norm = 1.7193e+00, time/batch = 0.2302s	
807/2700 (epoch 14.944), train_loss = 3.36671621, grad/param norm = 2.1421e+00, time/batch = 0.2237s	
808/2700 (epoch 14.963), train_loss = 3.45797611, grad/param norm = 2.2058e+00, time/batch = 0.2245s	
809/2700 (epoch 14.981), train_loss = 3.49942772, grad/param norm = 2.1334e+00, time/batch = 0.2319s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
810/2700 (epoch 15.000), train_loss = 3.41532361, grad/param norm = 2.1057e+00, time/batch = 0.2290s	
811/2700 (epoch 15.019), train_loss = 3.33120298, grad/param norm = 2.0823e+00, time/batch = 0.2319s	
812/2700 (epoch 15.037), train_loss = 3.34502655, grad/param norm = 2.0265e+00, time/batch = 0.2367s	
813/2700 (epoch 15.056), train_loss = 3.33709438, grad/param norm = 2.0186e+00, time/batch = 0.2214s	
814/2700 (epoch 15.074), train_loss = 3.36945685, grad/param norm = 2.2677e+00, time/batch = 0.2272s	
815/2700 (epoch 15.093), train_loss = 3.40037251, grad/param norm = 2.1052e+00, time/batch = 0.2315s	
816/2700 (epoch 15.111), train_loss = 3.34761032, grad/param norm = 1.6462e+00, time/batch = 0.2351s	
817/2700 (epoch 15.130), train_loss = 3.35204720, grad/param norm = 1.4140e+00, time/batch = 0.2247s	
818/2700 (epoch 15.148), train_loss = 3.29244131, grad/param norm = 1.3822e+00, time/batch = 0.2355s	
819/2700 (epoch 15.167), train_loss = 3.31627251, grad/param norm = 1.7169e+00, time/batch = 0.2364s	
820/2700 (epoch 15.185), train_loss = 3.32782523, grad/param norm = 1.7160e+00, time/batch = 0.2361s	
821/2700 (epoch 15.204), train_loss = 3.24646121, grad/param norm = 1.8344e+00, time/batch = 0.2142s	
822/2700 (epoch 15.222), train_loss = 3.25004786, grad/param norm = 2.0345e+00, time/batch = 0.1922s	
823/2700 (epoch 15.241), train_loss = 3.26177612, grad/param norm = 2.0636e+00, time/batch = 0.2109s	
824/2700 (epoch 15.259), train_loss = 3.30129781, grad/param norm = 2.2207e+00, time/batch = 0.2214s	
825/2700 (epoch 15.278), train_loss = 3.37229119, grad/param norm = 2.1848e+00, time/batch = 0.2315s	
826/2700 (epoch 15.296), train_loss = 3.38975985, grad/param norm = 2.0725e+00, time/batch = 0.2278s	
827/2700 (epoch 15.315), train_loss = 3.34158643, grad/param norm = 1.9084e+00, time/batch = 0.2335s	
828/2700 (epoch 15.333), train_loss = 3.43304962, grad/param norm = 1.7823e+00, time/batch = 0.2339s	
829/2700 (epoch 15.352), train_loss = 3.44251318, grad/param norm = 2.0167e+00, time/batch = 0.2392s	
830/2700 (epoch 15.370), train_loss = 3.41466420, grad/param norm = 1.7651e+00, time/batch = 0.2374s	
831/2700 (epoch 15.389), train_loss = 3.30830824, grad/param norm = 1.3291e+00, time/batch = 0.2196s	
832/2700 (epoch 15.407), train_loss = 3.33541823, grad/param norm = 1.1206e+00, time/batch = 0.2320s	
833/2700 (epoch 15.426), train_loss = 3.33010911, grad/param norm = 1.0749e+00, time/batch = 0.2244s	
834/2700 (epoch 15.444), train_loss = 3.24665821, grad/param norm = 1.0467e+00, time/batch = 0.2179s	
835/2700 (epoch 15.463), train_loss = 3.31722043, grad/param norm = 1.4222e+00, time/batch = 0.2301s	
836/2700 (epoch 15.481), train_loss = 3.39784208, grad/param norm = 1.3201e+00, time/batch = 0.2110s	
837/2700 (epoch 15.500), train_loss = 3.43183473, grad/param norm = 1.2534e+00, time/batch = 0.2350s	
838/2700 (epoch 15.519), train_loss = 3.38515383, grad/param norm = 1.4923e+00, time/batch = 0.2352s	
839/2700 (epoch 15.537), train_loss = 3.41886852, grad/param norm = 1.7945e+00, time/batch = 0.2348s	
840/2700 (epoch 15.556), train_loss = 3.37923202, grad/param norm = 1.9495e+00, time/batch = 0.2282s	
841/2700 (epoch 15.574), train_loss = 3.30360043, grad/param norm = 2.0978e+00, time/batch = 0.2173s	
842/2700 (epoch 15.593), train_loss = 3.33569995, grad/param norm = 2.4357e+00, time/batch = 0.2164s	
843/2700 (epoch 15.611), train_loss = 3.27941908, grad/param norm = 2.3337e+00, time/batch = 0.2161s	
844/2700 (epoch 15.630), train_loss = 3.31631870, grad/param norm = 2.5017e+00, time/batch = 0.2233s	
845/2700 (epoch 15.648), train_loss = 3.39907425, grad/param norm = 2.1762e+00, time/batch = 0.2338s	
846/2700 (epoch 15.667), train_loss = 3.32644024, grad/param norm = 2.2141e+00, time/batch = 0.2111s	
847/2700 (epoch 15.685), train_loss = 3.31589668, grad/param norm = 1.8863e+00, time/batch = 0.2126s	
848/2700 (epoch 15.704), train_loss = 3.28644876, grad/param norm = 2.0405e+00, time/batch = 0.2210s	
849/2700 (epoch 15.722), train_loss = 3.31309566, grad/param norm = 1.9189e+00, time/batch = 0.2316s	
850/2700 (epoch 15.741), train_loss = 3.40606903, grad/param norm = 1.6852e+00, time/batch = 0.2221s	
851/2700 (epoch 15.759), train_loss = 3.34355836, grad/param norm = 1.7787e+00, time/batch = 0.2264s	
852/2700 (epoch 15.778), train_loss = 3.34518081, grad/param norm = 2.0176e+00, time/batch = 0.2334s	
853/2700 (epoch 15.796), train_loss = 3.37120898, grad/param norm = 1.9852e+00, time/batch = 0.2235s	
854/2700 (epoch 15.815), train_loss = 3.27704865, grad/param norm = 2.0331e+00, time/batch = 0.2325s	
855/2700 (epoch 15.833), train_loss = 3.36309822, grad/param norm = 2.1498e+00, time/batch = 0.2203s	
856/2700 (epoch 15.852), train_loss = 3.33128206, grad/param norm = 2.1410e+00, time/batch = 0.2353s	
857/2700 (epoch 15.870), train_loss = 3.32524044, grad/param norm = 1.9574e+00, time/batch = 0.2352s	
858/2700 (epoch 15.889), train_loss = 3.33341435, grad/param norm = 1.9666e+00, time/batch = 0.2292s	
859/2700 (epoch 15.907), train_loss = 3.38803428, grad/param norm = 2.0549e+00, time/batch = 0.2058s	
860/2700 (epoch 15.926), train_loss = 3.34428464, grad/param norm = 1.9736e+00, time/batch = 0.2373s	
861/2700 (epoch 15.944), train_loss = 3.35657681, grad/param norm = 1.7101e+00, time/batch = 0.2225s	
862/2700 (epoch 15.963), train_loss = 3.40297553, grad/param norm = 1.5359e+00, time/batch = 0.2075s	
863/2700 (epoch 15.981), train_loss = 3.46186058, grad/param norm = 1.5020e+00, time/batch = 0.2209s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
864/2700 (epoch 16.000), train_loss = 3.37717499, grad/param norm = 1.6204e+00, time/batch = 0.2148s	
865/2700 (epoch 16.019), train_loss = 3.30422866, grad/param norm = 1.7657e+00, time/batch = 0.1955s	
866/2700 (epoch 16.037), train_loss = 3.34049068, grad/param norm = 1.8299e+00, time/batch = 0.2326s	
867/2700 (epoch 16.056), train_loss = 3.31782257, grad/param norm = 1.5352e+00, time/batch = 0.2336s	
868/2700 (epoch 16.074), train_loss = 3.33702336, grad/param norm = 1.4507e+00, time/batch = 0.2362s	
869/2700 (epoch 16.093), train_loss = 3.37237632, grad/param norm = 1.5903e+00, time/batch = 0.2057s	
870/2700 (epoch 16.111), train_loss = 3.35470560, grad/param norm = 1.8201e+00, time/batch = 0.2085s	
871/2700 (epoch 16.130), train_loss = 3.37811013, grad/param norm = 1.8716e+00, time/batch = 0.2072s	
872/2700 (epoch 16.148), train_loss = 3.32978766, grad/param norm = 2.0085e+00, time/batch = 0.2222s	
873/2700 (epoch 16.167), train_loss = 3.35769544, grad/param norm = 2.0749e+00, time/batch = 0.2297s	
874/2700 (epoch 16.185), train_loss = 3.33856234, grad/param norm = 2.0213e+00, time/batch = 0.2300s	
875/2700 (epoch 16.204), train_loss = 3.26566157, grad/param norm = 1.9737e+00, time/batch = 0.2202s	
876/2700 (epoch 16.222), train_loss = 3.23958366, grad/param norm = 2.1942e+00, time/batch = 0.2168s	
877/2700 (epoch 16.241), train_loss = 3.25332895, grad/param norm = 1.9306e+00, time/batch = 0.2293s	
878/2700 (epoch 16.259), train_loss = 3.28823299, grad/param norm = 1.8481e+00, time/batch = 0.2327s	
879/2700 (epoch 16.278), train_loss = 3.37928530, grad/param norm = 2.1421e+00, time/batch = 0.2345s	
880/2700 (epoch 16.296), train_loss = 3.37839972, grad/param norm = 1.9747e+00, time/batch = 0.2228s	
881/2700 (epoch 16.315), train_loss = 3.33199549, grad/param norm = 1.6237e+00, time/batch = 0.2303s	
882/2700 (epoch 16.333), train_loss = 3.39257142, grad/param norm = 1.3665e+00, time/batch = 0.2285s	
883/2700 (epoch 16.352), train_loss = 3.39456797, grad/param norm = 1.3944e+00, time/batch = 0.2332s	
884/2700 (epoch 16.370), train_loss = 3.36226720, grad/param norm = 1.6329e+00, time/batch = 0.2186s	
885/2700 (epoch 16.389), train_loss = 3.30785802, grad/param norm = 1.6853e+00, time/batch = 0.2263s	
886/2700 (epoch 16.407), train_loss = 3.34922143, grad/param norm = 1.7385e+00, time/batch = 0.2227s	
887/2700 (epoch 16.426), train_loss = 3.34985728, grad/param norm = 1.7523e+00, time/batch = 0.2312s	
888/2700 (epoch 16.444), train_loss = 3.27818506, grad/param norm = 1.8078e+00, time/batch = 0.2317s	
889/2700 (epoch 16.463), train_loss = 3.32371566, grad/param norm = 2.1211e+00, time/batch = 0.2286s	
890/2700 (epoch 16.481), train_loss = 3.42444033, grad/param norm = 2.1320e+00, time/batch = 0.2311s	
891/2700 (epoch 16.500), train_loss = 3.44815353, grad/param norm = 2.0367e+00, time/batch = 0.2178s	
892/2700 (epoch 16.519), train_loss = 3.41327897, grad/param norm = 2.1239e+00, time/batch = 0.2198s	
893/2700 (epoch 16.537), train_loss = 3.42314633, grad/param norm = 1.8603e+00, time/batch = 0.2218s	
894/2700 (epoch 16.556), train_loss = 3.36535651, grad/param norm = 1.6420e+00, time/batch = 0.2023s	
895/2700 (epoch 16.574), train_loss = 3.29451378, grad/param norm = 1.6274e+00, time/batch = 0.2116s	
896/2700 (epoch 16.593), train_loss = 3.33025960, grad/param norm = 1.7020e+00, time/batch = 0.2230s	
897/2700 (epoch 16.611), train_loss = 3.24337861, grad/param norm = 1.5969e+00, time/batch = 0.2349s	
898/2700 (epoch 16.630), train_loss = 3.27972523, grad/param norm = 1.8098e+00, time/batch = 0.2334s	
899/2700 (epoch 16.648), train_loss = 3.37817924, grad/param norm = 1.9711e+00, time/batch = 0.2334s	
900/2700 (epoch 16.667), train_loss = 3.32325910, grad/param norm = 2.1699e+00, time/batch = 0.2341s	
901/2700 (epoch 16.685), train_loss = 3.31403233, grad/param norm = 1.7715e+00, time/batch = 0.2381s	
902/2700 (epoch 16.704), train_loss = 3.27777658, grad/param norm = 1.8649e+00, time/batch = 0.2287s	
903/2700 (epoch 16.722), train_loss = 3.29643232, grad/param norm = 1.7337e+00, time/batch = 0.2003s	
904/2700 (epoch 16.741), train_loss = 3.39498058, grad/param norm = 1.5443e+00, time/batch = 0.2325s	
905/2700 (epoch 16.759), train_loss = 3.33963152, grad/param norm = 1.5746e+00, time/batch = 0.2337s	
906/2700 (epoch 16.778), train_loss = 3.32997972, grad/param norm = 1.7708e+00, time/batch = 0.2360s	
907/2700 (epoch 16.796), train_loss = 3.35202112, grad/param norm = 1.7322e+00, time/batch = 0.2309s	
908/2700 (epoch 16.815), train_loss = 3.25905008, grad/param norm = 1.7332e+00, time/batch = 0.2331s	
909/2700 (epoch 16.833), train_loss = 3.31633147, grad/param norm = 1.9014e+00, time/batch = 0.2369s	
910/2700 (epoch 16.852), train_loss = 3.29147431, grad/param norm = 1.9405e+00, time/batch = 0.2362s	
911/2700 (epoch 16.870), train_loss = 3.30468986, grad/param norm = 2.0027e+00, time/batch = 0.2195s	
912/2700 (epoch 16.889), train_loss = 3.33822692, grad/param norm = 2.0613e+00, time/batch = 0.2254s	
913/2700 (epoch 16.907), train_loss = 3.38835029, grad/param norm = 2.0188e+00, time/batch = 0.2052s	
914/2700 (epoch 16.926), train_loss = 3.35646663, grad/param norm = 2.2100e+00, time/batch = 0.2152s	
915/2700 (epoch 16.944), train_loss = 3.38421181, grad/param norm = 1.9150e+00, time/batch = 0.2267s	
916/2700 (epoch 16.963), train_loss = 3.42224301, grad/param norm = 1.8279e+00, time/batch = 0.2179s	
917/2700 (epoch 16.981), train_loss = 3.50317645, grad/param norm = 1.7641e+00, time/batch = 0.1958s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
918/2700 (epoch 17.000), train_loss = 3.37970280, grad/param norm = 1.5802e+00, time/batch = 0.2353s	
919/2700 (epoch 17.019), train_loss = 3.29863096, grad/param norm = 1.6408e+00, time/batch = 0.2355s	
920/2700 (epoch 17.037), train_loss = 3.33286010, grad/param norm = 1.7047e+00, time/batch = 0.2255s	
921/2700 (epoch 17.056), train_loss = 3.31816799, grad/param norm = 1.3791e+00, time/batch = 0.2322s	
922/2700 (epoch 17.074), train_loss = 3.32623242, grad/param norm = 1.2197e+00, time/batch = 0.2170s	
923/2700 (epoch 17.093), train_loss = 3.35221870, grad/param norm = 1.3147e+00, time/batch = 0.2336s	
924/2700 (epoch 17.111), train_loss = 3.33446742, grad/param norm = 1.5463e+00, time/batch = 0.2362s	
925/2700 (epoch 17.130), train_loss = 3.36388039, grad/param norm = 1.6610e+00, time/batch = 0.2335s	
926/2700 (epoch 17.148), train_loss = 3.32247367, grad/param norm = 1.9016e+00, time/batch = 0.2262s	
927/2700 (epoch 17.167), train_loss = 3.35956951, grad/param norm = 2.0057e+00, time/batch = 0.2352s	
928/2700 (epoch 17.185), train_loss = 3.32824533, grad/param norm = 1.9299e+00, time/batch = 0.2301s	
929/2700 (epoch 17.204), train_loss = 3.25711266, grad/param norm = 1.9489e+00, time/batch = 0.2200s	
930/2700 (epoch 17.222), train_loss = 3.23178130, grad/param norm = 2.2065e+00, time/batch = 0.2187s	
931/2700 (epoch 17.241), train_loss = 3.24584171, grad/param norm = 1.9585e+00, time/batch = 0.2190s	
932/2700 (epoch 17.259), train_loss = 3.28057863, grad/param norm = 1.8728e+00, time/batch = 0.2263s	
933/2700 (epoch 17.278), train_loss = 3.38421709, grad/param norm = 2.2420e+00, time/batch = 0.2257s	
934/2700 (epoch 17.296), train_loss = 3.39029247, grad/param norm = 2.1680e+00, time/batch = 0.2306s	
935/2700 (epoch 17.315), train_loss = 3.34612209, grad/param norm = 1.6838e+00, time/batch = 0.2269s	
936/2700 (epoch 17.333), train_loss = 3.38838396, grad/param norm = 1.2787e+00, time/batch = 0.2335s	
937/2700 (epoch 17.352), train_loss = 3.38889252, grad/param norm = 1.2730e+00, time/batch = 0.2377s	
938/2700 (epoch 17.370), train_loss = 3.35331892, grad/param norm = 1.4696e+00, time/batch = 0.2369s	
939/2700 (epoch 17.389), train_loss = 3.30052752, grad/param norm = 1.5427e+00, time/batch = 0.2367s	
940/2700 (epoch 17.407), train_loss = 3.34668122, grad/param norm = 1.6423e+00, time/batch = 0.2378s	
941/2700 (epoch 17.426), train_loss = 3.34587476, grad/param norm = 1.6967e+00, time/batch = 0.2051s	
942/2700 (epoch 17.444), train_loss = 3.27347138, grad/param norm = 1.7533e+00, time/batch = 0.2180s	
943/2700 (epoch 17.463), train_loss = 3.31239775, grad/param norm = 2.0996e+00, time/batch = 0.2300s	
944/2700 (epoch 17.481), train_loss = 3.41096912, grad/param norm = 2.1059e+00, time/batch = 0.2012s	
945/2700 (epoch 17.500), train_loss = 3.44538999, grad/param norm = 1.9772e+00, time/batch = 0.2209s	
946/2700 (epoch 17.519), train_loss = 3.41299967, grad/param norm = 2.0794e+00, time/batch = 0.2283s	
947/2700 (epoch 17.537), train_loss = 3.42294362, grad/param norm = 1.8945e+00, time/batch = 0.2313s	
948/2700 (epoch 17.556), train_loss = 3.35506381, grad/param norm = 1.6089e+00, time/batch = 0.2340s	
949/2700 (epoch 17.574), train_loss = 3.27060953, grad/param norm = 1.3345e+00, time/batch = 0.2359s	
950/2700 (epoch 17.593), train_loss = 3.28608059, grad/param norm = 1.5922e+00, time/batch = 0.2274s	
951/2700 (epoch 17.611), train_loss = 3.23558790, grad/param norm = 1.5419e+00, time/batch = 0.2062s	
952/2700 (epoch 17.630), train_loss = 3.27864804, grad/param norm = 1.8143e+00, time/batch = 0.2105s	
953/2700 (epoch 17.648), train_loss = 3.37888859, grad/param norm = 1.9080e+00, time/batch = 0.2006s	
954/2700 (epoch 17.667), train_loss = 3.31366234, grad/param norm = 1.9921e+00, time/batch = 0.2219s	
955/2700 (epoch 17.685), train_loss = 3.31395446, grad/param norm = 1.8713e+00, time/batch = 0.2255s	
956/2700 (epoch 17.704), train_loss = 3.29944403, grad/param norm = 2.1159e+00, time/batch = 0.2262s	
957/2700 (epoch 17.722), train_loss = 3.29928356, grad/param norm = 1.7828e+00, time/batch = 0.2312s	
958/2700 (epoch 17.741), train_loss = 3.39732849, grad/param norm = 1.5818e+00, time/batch = 0.2351s	
959/2700 (epoch 17.759), train_loss = 3.34078985, grad/param norm = 1.5270e+00, time/batch = 0.2365s	
960/2700 (epoch 17.778), train_loss = 3.32879991, grad/param norm = 1.7816e+00, time/batch = 0.2268s	
961/2700 (epoch 17.796), train_loss = 3.34874191, grad/param norm = 1.8238e+00, time/batch = 0.2250s	
962/2700 (epoch 17.815), train_loss = 3.26720928, grad/param norm = 1.8444e+00, time/batch = 0.2114s	
963/2700 (epoch 17.833), train_loss = 3.33467093, grad/param norm = 2.0639e+00, time/batch = 0.2027s	
964/2700 (epoch 17.852), train_loss = 3.31679119, grad/param norm = 2.1184e+00, time/batch = 0.2221s	
965/2700 (epoch 17.870), train_loss = 3.31727775, grad/param norm = 1.9724e+00, time/batch = 0.2190s	
966/2700 (epoch 17.889), train_loss = 3.32537091, grad/param norm = 1.8936e+00, time/batch = 0.2232s	
967/2700 (epoch 17.907), train_loss = 3.36736908, grad/param norm = 1.9659e+00, time/batch = 0.2273s	
968/2700 (epoch 17.926), train_loss = 3.35116362, grad/param norm = 2.2033e+00, time/batch = 0.2193s	
969/2700 (epoch 17.944), train_loss = 3.37353184, grad/param norm = 1.8541e+00, time/batch = 0.2210s	
970/2700 (epoch 17.963), train_loss = 3.41296869, grad/param norm = 1.6488e+00, time/batch = 0.1918s	
971/2700 (epoch 17.981), train_loss = 3.47334199, grad/param norm = 1.5576e+00, time/batch = 0.2139s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
972/2700 (epoch 18.000), train_loss = 3.37338524, grad/param norm = 1.4844e+00, time/batch = 0.2141s	
973/2700 (epoch 18.019), train_loss = 3.29127103, grad/param norm = 1.5186e+00, time/batch = 0.2214s	
974/2700 (epoch 18.037), train_loss = 3.32033167, grad/param norm = 1.5685e+00, time/batch = 0.2277s	
975/2700 (epoch 18.056), train_loss = 3.30658892, grad/param norm = 1.2624e+00, time/batch = 0.2311s	
976/2700 (epoch 18.074), train_loss = 3.32227359, grad/param norm = 1.1171e+00, time/batch = 0.2310s	
977/2700 (epoch 18.093), train_loss = 3.34724027, grad/param norm = 1.2496e+00, time/batch = 0.2244s	
978/2700 (epoch 18.111), train_loss = 3.33046091, grad/param norm = 1.4626e+00, time/batch = 0.2237s	
979/2700 (epoch 18.130), train_loss = 3.35709609, grad/param norm = 1.5672e+00, time/batch = 0.2262s	
980/2700 (epoch 18.148), train_loss = 3.31602314, grad/param norm = 1.8070e+00, time/batch = 0.2328s	
981/2700 (epoch 18.167), train_loss = 3.35443769, grad/param norm = 1.9747e+00, time/batch = 0.1979s	
982/2700 (epoch 18.185), train_loss = 3.32825222, grad/param norm = 1.9626e+00, time/batch = 0.2327s	
983/2700 (epoch 18.204), train_loss = 3.25620862, grad/param norm = 1.9668e+00, time/batch = 0.2229s	
984/2700 (epoch 18.222), train_loss = 3.22668491, grad/param norm = 2.2032e+00, time/batch = 0.2189s	
985/2700 (epoch 18.241), train_loss = 3.24162072, grad/param norm = 1.8864e+00, time/batch = 0.2249s	
986/2700 (epoch 18.259), train_loss = 3.26467928, grad/param norm = 1.6921e+00, time/batch = 0.2377s	
987/2700 (epoch 18.278), train_loss = 3.35668799, grad/param norm = 2.0749e+00, time/batch = 0.2309s	
988/2700 (epoch 18.296), train_loss = 3.38698243, grad/param norm = 2.2670e+00, time/batch = 0.2192s	
989/2700 (epoch 18.315), train_loss = 3.35469460, grad/param norm = 1.6535e+00, time/batch = 0.2000s	
990/2700 (epoch 18.333), train_loss = 3.38286132, grad/param norm = 1.1831e+00, time/batch = 0.2158s	
991/2700 (epoch 18.352), train_loss = 3.38502278, grad/param norm = 1.1772e+00, time/batch = 0.2349s	
992/2700 (epoch 18.370), train_loss = 3.34769826, grad/param norm = 1.3866e+00, time/batch = 0.2291s	
993/2700 (epoch 18.389), train_loss = 3.29785385, grad/param norm = 1.4755e+00, time/batch = 0.2212s	
994/2700 (epoch 18.407), train_loss = 3.34240448, grad/param norm = 1.5707e+00, time/batch = 0.2241s	
995/2700 (epoch 18.426), train_loss = 3.33878320, grad/param norm = 1.6520e+00, time/batch = 0.2313s	
996/2700 (epoch 18.444), train_loss = 3.26766885, grad/param norm = 1.7631e+00, time/batch = 0.2319s	
997/2700 (epoch 18.463), train_loss = 3.31579723, grad/param norm = 2.1181e+00, time/batch = 0.2350s	
998/2700 (epoch 18.481), train_loss = 3.41836757, grad/param norm = 2.1267e+00, time/batch = 0.2276s	
999/2700 (epoch 18.500), train_loss = 3.44956685, grad/param norm = 2.0332e+00, time/batch = 0.2301s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch18.52_3.2911.t7	
1000/2700 (epoch 18.519), train_loss = 3.41483830, grad/param norm = 2.1255e+00, time/batch = 0.2307s	
1001/2700 (epoch 18.537), train_loss = 3.41648890, grad/param norm = 1.8551e+00, time/batch = 0.2323s	
1002/2700 (epoch 18.556), train_loss = 3.34875865, grad/param norm = 1.5574e+00, time/batch = 0.2197s	
1003/2700 (epoch 18.574), train_loss = 3.26710038, grad/param norm = 1.2763e+00, time/batch = 0.2246s	
1004/2700 (epoch 18.593), train_loss = 3.28150849, grad/param norm = 1.5582e+00, time/batch = 0.2318s	
1005/2700 (epoch 18.611), train_loss = 3.23530414, grad/param norm = 1.5314e+00, time/batch = 0.2140s	
1006/2700 (epoch 18.630), train_loss = 3.27767769, grad/param norm = 1.7712e+00, time/batch = 0.2257s	
1007/2700 (epoch 18.648), train_loss = 3.37378628, grad/param norm = 1.8591e+00, time/batch = 0.2314s	
1008/2700 (epoch 18.667), train_loss = 3.30607994, grad/param norm = 1.8903e+00, time/batch = 0.2334s	
1009/2700 (epoch 18.685), train_loss = 3.30231105, grad/param norm = 1.7782e+00, time/batch = 0.2282s	
1010/2700 (epoch 18.704), train_loss = 3.29205253, grad/param norm = 2.0892e+00, time/batch = 0.2275s	
1011/2700 (epoch 18.722), train_loss = 3.30109757, grad/param norm = 1.7593e+00, time/batch = 0.2204s	
1012/2700 (epoch 18.741), train_loss = 3.37261918, grad/param norm = 1.4339e+00, time/batch = 0.2222s	
1013/2700 (epoch 18.759), train_loss = 3.33018011, grad/param norm = 1.5391e+00, time/batch = 0.2265s	
1014/2700 (epoch 18.778), train_loss = 3.32071212, grad/param norm = 1.7647e+00, time/batch = 0.2230s	
1015/2700 (epoch 18.796), train_loss = 3.34046590, grad/param norm = 1.8138e+00, time/batch = 0.2096s	
1016/2700 (epoch 18.815), train_loss = 3.26413063, grad/param norm = 1.8201e+00, time/batch = 0.1976s	
1017/2700 (epoch 18.833), train_loss = 3.32684299, grad/param norm = 2.0159e+00, time/batch = 0.2272s	
1018/2700 (epoch 18.852), train_loss = 3.31211675, grad/param norm = 2.0671e+00, time/batch = 0.2233s	
1019/2700 (epoch 18.870), train_loss = 3.30991240, grad/param norm = 1.8889e+00, time/batch = 0.2276s	
1020/2700 (epoch 18.889), train_loss = 3.31668767, grad/param norm = 1.7987e+00, time/batch = 0.2303s	
1021/2700 (epoch 18.907), train_loss = 3.36197098, grad/param norm = 1.8637e+00, time/batch = 0.2323s	
1022/2700 (epoch 18.926), train_loss = 3.34459704, grad/param norm = 2.1147e+00, time/batch = 0.2366s	
1023/2700 (epoch 18.944), train_loss = 3.36870796, grad/param norm = 1.8203e+00, time/batch = 0.2350s	
1024/2700 (epoch 18.963), train_loss = 3.41050263, grad/param norm = 1.6171e+00, time/batch = 0.2209s	
1025/2700 (epoch 18.981), train_loss = 3.46962875, grad/param norm = 1.5317e+00, time/batch = 0.2282s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1026/2700 (epoch 19.000), train_loss = 3.36997407, grad/param norm = 1.4612e+00, time/batch = 0.2338s	
1027/2700 (epoch 19.019), train_loss = 3.28970445, grad/param norm = 1.4960e+00, time/batch = 0.2353s	
1028/2700 (epoch 19.037), train_loss = 3.31952703, grad/param norm = 1.5421e+00, time/batch = 0.2352s	
1029/2700 (epoch 19.056), train_loss = 3.30366257, grad/param norm = 1.2317e+00, time/batch = 0.2293s	
1030/2700 (epoch 19.074), train_loss = 3.32014483, grad/param norm = 1.0807e+00, time/batch = 0.2244s	
1031/2700 (epoch 19.093), train_loss = 3.34413414, grad/param norm = 1.2099e+00, time/batch = 0.2132s	
1032/2700 (epoch 19.111), train_loss = 3.32591682, grad/param norm = 1.4100e+00, time/batch = 0.2145s	
1033/2700 (epoch 19.130), train_loss = 3.35113611, grad/param norm = 1.4972e+00, time/batch = 0.2178s	
1034/2700 (epoch 19.148), train_loss = 3.31001688, grad/param norm = 1.7412e+00, time/batch = 0.1857s	
1035/2700 (epoch 19.167), train_loss = 3.34727867, grad/param norm = 1.9038e+00, time/batch = 0.2344s	
1036/2700 (epoch 19.185), train_loss = 3.32284243, grad/param norm = 1.9009e+00, time/batch = 0.2355s	
1037/2700 (epoch 19.204), train_loss = 3.25235963, grad/param norm = 1.9202e+00, time/batch = 0.2344s	
1038/2700 (epoch 19.222), train_loss = 3.22211381, grad/param norm = 2.1527e+00, time/batch = 0.2265s	
1039/2700 (epoch 19.241), train_loss = 3.23736740, grad/param norm = 1.8549e+00, time/batch = 0.2196s	
1040/2700 (epoch 19.259), train_loss = 3.26267592, grad/param norm = 1.6819e+00, time/batch = 0.2209s	
1041/2700 (epoch 19.278), train_loss = 3.35698152, grad/param norm = 2.0685e+00, time/batch = 0.2152s	
1042/2700 (epoch 19.296), train_loss = 3.38358377, grad/param norm = 2.2325e+00, time/batch = 0.2243s	
1043/2700 (epoch 19.315), train_loss = 3.34782465, grad/param norm = 1.6198e+00, time/batch = 0.2234s	
1044/2700 (epoch 19.333), train_loss = 3.38014853, grad/param norm = 1.1556e+00, time/batch = 0.2096s	
1045/2700 (epoch 19.352), train_loss = 3.38275419, grad/param norm = 1.1582e+00, time/batch = 0.2254s	
1046/2700 (epoch 19.370), train_loss = 3.34517495, grad/param norm = 1.3639e+00, time/batch = 0.2316s	
1047/2700 (epoch 19.389), train_loss = 3.29599821, grad/param norm = 1.4408e+00, time/batch = 0.2348s	
1048/2700 (epoch 19.407), train_loss = 3.33841579, grad/param norm = 1.5179e+00, time/batch = 0.2351s	
1049/2700 (epoch 19.426), train_loss = 3.33353309, grad/param norm = 1.5845e+00, time/batch = 0.2359s	
1050/2700 (epoch 19.444), train_loss = 3.26059176, grad/param norm = 1.6875e+00, time/batch = 0.2358s	
1051/2700 (epoch 19.463), train_loss = 3.30725085, grad/param norm = 2.0376e+00, time/batch = 0.2288s	
1052/2700 (epoch 19.481), train_loss = 3.40815761, grad/param norm = 2.0628e+00, time/batch = 0.2065s	
1053/2700 (epoch 19.500), train_loss = 3.44484914, grad/param norm = 1.9670e+00, time/batch = 0.1948s	
1054/2700 (epoch 19.519), train_loss = 3.40781019, grad/param norm = 2.0392e+00, time/batch = 0.2313s	
1055/2700 (epoch 19.537), train_loss = 3.40600927, grad/param norm = 1.7908e+00, time/batch = 0.2364s	
1056/2700 (epoch 19.556), train_loss = 3.34178112, grad/param norm = 1.5036e+00, time/batch = 0.2355s	
1057/2700 (epoch 19.574), train_loss = 3.26364482, grad/param norm = 1.2347e+00, time/batch = 0.2332s	
1058/2700 (epoch 19.593), train_loss = 3.27948328, grad/param norm = 1.5239e+00, time/batch = 0.2220s	
1059/2700 (epoch 19.611), train_loss = 3.23851583, grad/param norm = 1.5529e+00, time/batch = 0.2127s	
1060/2700 (epoch 19.630), train_loss = 3.28635722, grad/param norm = 1.9136e+00, time/batch = 0.2075s	
1061/2700 (epoch 19.648), train_loss = 3.37901840, grad/param norm = 1.8485e+00, time/batch = 0.2054s	
1062/2700 (epoch 19.667), train_loss = 3.30110249, grad/param norm = 1.8838e+00, time/batch = 0.2261s	
1063/2700 (epoch 19.685), train_loss = 3.30069291, grad/param norm = 1.7345e+00, time/batch = 0.2307s	
1064/2700 (epoch 19.704), train_loss = 3.28283727, grad/param norm = 1.9834e+00, time/batch = 0.2338s	
1065/2700 (epoch 19.722), train_loss = 3.29038092, grad/param norm = 1.6600e+00, time/batch = 0.2270s	
1066/2700 (epoch 19.741), train_loss = 3.36205011, grad/param norm = 1.2904e+00, time/batch = 0.2276s	
1067/2700 (epoch 19.759), train_loss = 3.31602083, grad/param norm = 1.4182e+00, time/batch = 0.2308s	
1068/2700 (epoch 19.778), train_loss = 3.31506907, grad/param norm = 1.6754e+00, time/batch = 0.2337s	
1069/2700 (epoch 19.796), train_loss = 3.33396059, grad/param norm = 1.7333e+00, time/batch = 0.2356s	
1070/2700 (epoch 19.815), train_loss = 3.26027486, grad/param norm = 1.7590e+00, time/batch = 0.2288s	
1071/2700 (epoch 19.833), train_loss = 3.32318310, grad/param norm = 1.9709e+00, time/batch = 0.2301s	
1072/2700 (epoch 19.852), train_loss = 3.30863727, grad/param norm = 2.0383e+00, time/batch = 0.2155s	
1073/2700 (epoch 19.870), train_loss = 3.30697252, grad/param norm = 1.8893e+00, time/batch = 0.2307s	
1074/2700 (epoch 19.889), train_loss = 3.31618165, grad/param norm = 1.7964e+00, time/batch = 0.2340s	
1075/2700 (epoch 19.907), train_loss = 3.35891719, grad/param norm = 1.8621e+00, time/batch = 0.2349s	
1076/2700 (epoch 19.926), train_loss = 3.34209873, grad/param norm = 2.1156e+00, time/batch = 0.2357s	
1077/2700 (epoch 19.944), train_loss = 3.36394697, grad/param norm = 1.7797e+00, time/batch = 0.2297s	
1078/2700 (epoch 19.963), train_loss = 3.40331567, grad/param norm = 1.5321e+00, time/batch = 0.2198s	
1079/2700 (epoch 19.981), train_loss = 3.46181220, grad/param norm = 1.4711e+00, time/batch = 0.2157s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1080/2700 (epoch 20.000), train_loss = 3.36588659, grad/param norm = 1.4192e+00, time/batch = 0.2183s	
1081/2700 (epoch 20.019), train_loss = 3.28702825, grad/param norm = 1.4572e+00, time/batch = 0.2101s	
1082/2700 (epoch 20.037), train_loss = 3.31577158, grad/param norm = 1.4930e+00, time/batch = 0.2329s	
1083/2700 (epoch 20.056), train_loss = 3.29991638, grad/param norm = 1.1716e+00, time/batch = 0.2314s	
1084/2700 (epoch 20.074), train_loss = 3.31740651, grad/param norm = 1.0204e+00, time/batch = 0.2293s	
1085/2700 (epoch 20.093), train_loss = 3.34016367, grad/param norm = 1.1580e+00, time/batch = 0.2228s	
1086/2700 (epoch 20.111), train_loss = 3.32118629, grad/param norm = 1.3418e+00, time/batch = 0.2195s	
1087/2700 (epoch 20.130), train_loss = 3.34553373, grad/param norm = 1.4107e+00, time/batch = 0.2310s	
1088/2700 (epoch 20.148), train_loss = 3.30392678, grad/param norm = 1.6566e+00, time/batch = 0.2307s	
1089/2700 (epoch 20.167), train_loss = 3.34075985, grad/param norm = 1.8234e+00, time/batch = 0.2325s	
1090/2700 (epoch 20.185), train_loss = 3.31695122, grad/param norm = 1.8263e+00, time/batch = 0.2296s	
1091/2700 (epoch 20.204), train_loss = 3.24816743, grad/param norm = 1.8879e+00, time/batch = 0.2235s	
1092/2700 (epoch 20.222), train_loss = 3.21952241, grad/param norm = 2.1334e+00, time/batch = 0.2361s	
1093/2700 (epoch 20.241), train_loss = 3.23436009, grad/param norm = 1.8571e+00, time/batch = 0.2376s	
1094/2700 (epoch 20.259), train_loss = 3.26158261, grad/param norm = 1.6955e+00, time/batch = 0.2224s	
1095/2700 (epoch 20.278), train_loss = 3.35511479, grad/param norm = 2.0620e+00, time/batch = 0.2112s	
1096/2700 (epoch 20.296), train_loss = 3.37900111, grad/param norm = 2.1911e+00, time/batch = 0.2071s	
1097/2700 (epoch 20.315), train_loss = 3.34264175, grad/param norm = 1.5886e+00, time/batch = 0.2195s	
1098/2700 (epoch 20.333), train_loss = 3.37826173, grad/param norm = 1.1304e+00, time/batch = 0.2339s	
1099/2700 (epoch 20.352), train_loss = 3.38070203, grad/param norm = 1.1344e+00, time/batch = 0.2357s	
1100/2700 (epoch 20.370), train_loss = 3.34242119, grad/param norm = 1.3299e+00, time/batch = 0.2339s	
1101/2700 (epoch 20.389), train_loss = 3.29374624, grad/param norm = 1.3930e+00, time/batch = 0.2351s	
1102/2700 (epoch 20.407), train_loss = 3.33404699, grad/param norm = 1.4575e+00, time/batch = 0.2274s	
1103/2700 (epoch 20.426), train_loss = 3.32898726, grad/param norm = 1.5117e+00, time/batch = 0.2328s	
1104/2700 (epoch 20.444), train_loss = 3.25473705, grad/param norm = 1.6145e+00, time/batch = 0.2324s	
1105/2700 (epoch 20.463), train_loss = 3.30450780, grad/param norm = 1.9520e+00, time/batch = 0.2213s	
1106/2700 (epoch 20.481), train_loss = 3.40548993, grad/param norm = 2.0114e+00, time/batch = 0.2166s	
1107/2700 (epoch 20.500), train_loss = 3.44142859, grad/param norm = 1.9461e+00, time/batch = 0.2328s	
1108/2700 (epoch 20.519), train_loss = 3.40140094, grad/param norm = 2.0293e+00, time/batch = 0.2376s	
1109/2700 (epoch 20.537), train_loss = 3.41951075, grad/param norm = 1.8927e+00, time/batch = 0.2279s	
1110/2700 (epoch 20.556), train_loss = 3.36411254, grad/param norm = 1.5138e+00, time/batch = 0.2113s	
1111/2700 (epoch 20.574), train_loss = 3.26095669, grad/param norm = 1.1650e+00, time/batch = 0.2258s	
1112/2700 (epoch 20.593), train_loss = 3.27523256, grad/param norm = 1.4529e+00, time/batch = 0.2102s	
1113/2700 (epoch 20.611), train_loss = 3.22863040, grad/param norm = 1.4252e+00, time/batch = 0.2121s	
1114/2700 (epoch 20.630), train_loss = 3.26318181, grad/param norm = 1.5923e+00, time/batch = 0.2256s	
1115/2700 (epoch 20.648), train_loss = 3.35070375, grad/param norm = 1.6273e+00, time/batch = 0.2301s	
1116/2700 (epoch 20.667), train_loss = 3.28183368, grad/param norm = 1.6680e+00, time/batch = 0.2203s	
1117/2700 (epoch 20.685), train_loss = 3.28216106, grad/param norm = 1.5223e+00, time/batch = 0.2208s	
1118/2700 (epoch 20.704), train_loss = 3.26483956, grad/param norm = 1.7258e+00, time/batch = 0.2004s	
1119/2700 (epoch 20.722), train_loss = 3.27768534, grad/param norm = 1.6182e+00, time/batch = 0.2322s	
1120/2700 (epoch 20.741), train_loss = 3.37092454, grad/param norm = 1.3923e+00, time/batch = 0.2190s	
1121/2700 (epoch 20.759), train_loss = 3.31853850, grad/param norm = 1.4733e+00, time/batch = 0.2288s	
1122/2700 (epoch 20.778), train_loss = 3.32089590, grad/param norm = 1.7131e+00, time/batch = 0.2268s	
1123/2700 (epoch 20.796), train_loss = 3.33971501, grad/param norm = 1.7787e+00, time/batch = 0.2318s	
1124/2700 (epoch 20.815), train_loss = 3.26300256, grad/param norm = 1.8122e+00, time/batch = 0.2311s	
1125/2700 (epoch 20.833), train_loss = 3.32554136, grad/param norm = 2.0181e+00, time/batch = 0.2331s	
1126/2700 (epoch 20.852), train_loss = 3.30532526, grad/param norm = 2.0605e+00, time/batch = 0.2359s	
1127/2700 (epoch 20.870), train_loss = 3.30115510, grad/param norm = 1.8400e+00, time/batch = 0.2267s	
1128/2700 (epoch 20.889), train_loss = 3.30966220, grad/param norm = 1.7054e+00, time/batch = 0.2274s	
1129/2700 (epoch 20.907), train_loss = 3.34717726, grad/param norm = 1.7451e+00, time/batch = 0.2090s	
1130/2700 (epoch 20.926), train_loss = 3.33155261, grad/param norm = 2.0144e+00, time/batch = 0.2358s	
1131/2700 (epoch 20.944), train_loss = 3.36037064, grad/param norm = 1.7275e+00, time/batch = 0.2147s	
1132/2700 (epoch 20.963), train_loss = 3.39641531, grad/param norm = 1.4735e+00, time/batch = 0.2097s	
1133/2700 (epoch 20.981), train_loss = 3.45937743, grad/param norm = 1.4596e+00, time/batch = 0.2279s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1134/2700 (epoch 21.000), train_loss = 3.36441853, grad/param norm = 1.4323e+00, time/batch = 0.2062s	
1135/2700 (epoch 21.019), train_loss = 3.28587005, grad/param norm = 1.4576e+00, time/batch = 0.2253s	
1136/2700 (epoch 21.037), train_loss = 3.31344098, grad/param norm = 1.4614e+00, time/batch = 0.2290s	
1137/2700 (epoch 21.056), train_loss = 3.29847145, grad/param norm = 1.1417e+00, time/batch = 0.2377s	
1138/2700 (epoch 21.074), train_loss = 3.31704011, grad/param norm = 1.0064e+00, time/batch = 0.2312s	
1139/2700 (epoch 21.093), train_loss = 3.33773970, grad/param norm = 1.1195e+00, time/batch = 0.2315s	
1140/2700 (epoch 21.111), train_loss = 3.31650638, grad/param norm = 1.2905e+00, time/batch = 0.2355s	
1141/2700 (epoch 21.130), train_loss = 3.34092576, grad/param norm = 1.3434e+00, time/batch = 0.2242s	
1142/2700 (epoch 21.148), train_loss = 3.29805176, grad/param norm = 1.5938e+00, time/batch = 0.2155s	
1143/2700 (epoch 21.167), train_loss = 3.33488176, grad/param norm = 1.7423e+00, time/batch = 0.1980s	
1144/2700 (epoch 21.185), train_loss = 3.31069771, grad/param norm = 1.7335e+00, time/batch = 0.2303s	
1145/2700 (epoch 21.204), train_loss = 3.24465134, grad/param norm = 1.7965e+00, time/batch = 0.2233s	
1146/2700 (epoch 21.222), train_loss = 3.21587078, grad/param norm = 2.0722e+00, time/batch = 0.2318s	
1147/2700 (epoch 21.241), train_loss = 3.23419907, grad/param norm = 1.8319e+00, time/batch = 0.2345s	
1148/2700 (epoch 21.259), train_loss = 3.25863701, grad/param norm = 1.6447e+00, time/batch = 0.2122s	
1149/2700 (epoch 21.278), train_loss = 3.34455335, grad/param norm = 1.9752e+00, time/batch = 0.2352s	
1150/2700 (epoch 21.296), train_loss = 3.36566238, grad/param norm = 1.9977e+00, time/batch = 0.2372s	
1151/2700 (epoch 21.315), train_loss = 3.33695744, grad/param norm = 1.6016e+00, time/batch = 0.2238s	
1152/2700 (epoch 21.333), train_loss = 3.38065669, grad/param norm = 1.2130e+00, time/batch = 0.1915s	
1153/2700 (epoch 21.352), train_loss = 3.38277189, grad/param norm = 1.2335e+00, time/batch = 0.2132s	
1154/2700 (epoch 21.370), train_loss = 3.34495560, grad/param norm = 1.4249e+00, time/batch = 0.2313s	
1155/2700 (epoch 21.389), train_loss = 3.29762969, grad/param norm = 1.4874e+00, time/batch = 0.2269s	
1156/2700 (epoch 21.407), train_loss = 3.33595689, grad/param norm = 1.5297e+00, time/batch = 0.2272s	
1157/2700 (epoch 21.426), train_loss = 3.32923364, grad/param norm = 1.5292e+00, time/batch = 0.2252s	
1158/2700 (epoch 21.444), train_loss = 3.25258909, grad/param norm = 1.6064e+00, time/batch = 0.2309s	
1159/2700 (epoch 21.463), train_loss = 3.30303153, grad/param norm = 1.8697e+00, time/batch = 0.2350s	
1160/2700 (epoch 21.481), train_loss = 3.40082595, grad/param norm = 1.9459e+00, time/batch = 0.2348s	
1161/2700 (epoch 21.500), train_loss = 3.44390351, grad/param norm = 1.9276e+00, time/batch = 0.2278s	
1162/2700 (epoch 21.519), train_loss = 3.40800531, grad/param norm = 2.0024e+00, time/batch = 0.2243s	
1163/2700 (epoch 21.537), train_loss = 3.40687770, grad/param norm = 1.7894e+00, time/batch = 0.2258s	
1164/2700 (epoch 21.556), train_loss = 3.34213489, grad/param norm = 1.4502e+00, time/batch = 0.2158s	
1165/2700 (epoch 21.574), train_loss = 3.25785850, grad/param norm = 1.1311e+00, time/batch = 0.2155s	
1166/2700 (epoch 21.593), train_loss = 3.27166547, grad/param norm = 1.4123e+00, time/batch = 0.2191s	
1167/2700 (epoch 21.611), train_loss = 3.22434429, grad/param norm = 1.3746e+00, time/batch = 0.1965s	
1168/2700 (epoch 21.630), train_loss = 3.26108862, grad/param norm = 1.5429e+00, time/batch = 0.2365s	
1169/2700 (epoch 21.648), train_loss = 3.34611741, grad/param norm = 1.5977e+00, time/batch = 0.2361s	
1170/2700 (epoch 21.667), train_loss = 3.27797585, grad/param norm = 1.6157e+00, time/batch = 0.2291s	
1171/2700 (epoch 21.685), train_loss = 3.27152395, grad/param norm = 1.4507e+00, time/batch = 0.2209s	
1172/2700 (epoch 21.704), train_loss = 3.24945961, grad/param norm = 1.6235e+00, time/batch = 0.2175s	
1173/2700 (epoch 21.722), train_loss = 3.26104016, grad/param norm = 1.5136e+00, time/batch = 0.2037s	
1174/2700 (epoch 21.741), train_loss = 3.35997429, grad/param norm = 1.3425e+00, time/batch = 0.2258s	
1175/2700 (epoch 21.759), train_loss = 3.31624687, grad/param norm = 1.5094e+00, time/batch = 0.2151s	
1176/2700 (epoch 21.778), train_loss = 3.31606243, grad/param norm = 1.7636e+00, time/batch = 0.2271s	
1177/2700 (epoch 21.796), train_loss = 3.33508280, grad/param norm = 1.8458e+00, time/batch = 0.2344s	
1178/2700 (epoch 21.815), train_loss = 3.26308609, grad/param norm = 1.8318e+00, time/batch = 0.2369s	
1179/2700 (epoch 21.833), train_loss = 3.32484627, grad/param norm = 2.0121e+00, time/batch = 0.2324s	
1180/2700 (epoch 21.852), train_loss = 3.31121512, grad/param norm = 2.0827e+00, time/batch = 0.2361s	
1181/2700 (epoch 21.870), train_loss = 3.31686156, grad/param norm = 1.9074e+00, time/batch = 0.2384s	
1182/2700 (epoch 21.889), train_loss = 3.30796028, grad/param norm = 1.6989e+00, time/batch = 0.2156s	
1183/2700 (epoch 21.907), train_loss = 3.35581799, grad/param norm = 1.7154e+00, time/batch = 0.2192s	
1184/2700 (epoch 21.926), train_loss = 3.32759139, grad/param norm = 1.9066e+00, time/batch = 0.2111s	
1185/2700 (epoch 21.944), train_loss = 3.34662449, grad/param norm = 1.6440e+00, time/batch = 0.2114s	
1186/2700 (epoch 21.963), train_loss = 3.39552632, grad/param norm = 1.4334e+00, time/batch = 0.1865s	
1187/2700 (epoch 21.981), train_loss = 3.45251809, grad/param norm = 1.3795e+00, time/batch = 0.2293s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1188/2700 (epoch 22.000), train_loss = 3.35707627, grad/param norm = 1.3217e+00, time/batch = 0.2286s	
1189/2700 (epoch 22.019), train_loss = 3.28088091, grad/param norm = 1.3689e+00, time/batch = 0.2356s	
1190/2700 (epoch 22.037), train_loss = 3.30873315, grad/param norm = 1.4113e+00, time/batch = 0.2351s	
1191/2700 (epoch 22.056), train_loss = 3.29499861, grad/param norm = 1.0927e+00, time/batch = 0.2109s	
1192/2700 (epoch 22.074), train_loss = 3.31418997, grad/param norm = 9.4133e-01, time/batch = 0.2187s	
1193/2700 (epoch 22.093), train_loss = 3.33480545, grad/param norm = 1.0785e+00, time/batch = 0.2218s	
1194/2700 (epoch 22.111), train_loss = 3.31345488, grad/param norm = 1.2264e+00, time/batch = 0.2328s	
1195/2700 (epoch 22.130), train_loss = 3.33534952, grad/param norm = 1.2400e+00, time/batch = 0.2359s	
1196/2700 (epoch 22.148), train_loss = 3.29106524, grad/param norm = 1.4685e+00, time/batch = 0.2319s	
1197/2700 (epoch 22.167), train_loss = 3.32580555, grad/param norm = 1.6282e+00, time/batch = 0.2261s	
1198/2700 (epoch 22.185), train_loss = 3.30298610, grad/param norm = 1.6169e+00, time/batch = 0.2233s	
1199/2700 (epoch 22.204), train_loss = 3.23792656, grad/param norm = 1.7331e+00, time/batch = 0.2211s	
1200/2700 (epoch 22.222), train_loss = 3.20984075, grad/param norm = 2.0208e+00, time/batch = 0.2327s	
1201/2700 (epoch 22.241), train_loss = 3.22852398, grad/param norm = 1.8745e+00, time/batch = 0.2303s	
1202/2700 (epoch 22.259), train_loss = 3.25975318, grad/param norm = 1.7361e+00, time/batch = 0.2258s	
1203/2700 (epoch 22.278), train_loss = 3.34566176, grad/param norm = 2.0448e+00, time/batch = 0.2321s	
1204/2700 (epoch 22.296), train_loss = 3.36974271, grad/param norm = 2.1189e+00, time/batch = 0.2316s	
1205/2700 (epoch 22.315), train_loss = 3.33626052, grad/param norm = 1.5556e+00, time/batch = 0.2153s	
1206/2700 (epoch 22.333), train_loss = 3.37790829, grad/param norm = 1.1225e+00, time/batch = 0.2311s	
1207/2700 (epoch 22.352), train_loss = 3.37861564, grad/param norm = 1.1214e+00, time/batch = 0.2353s	
1208/2700 (epoch 22.370), train_loss = 3.33919953, grad/param norm = 1.2858e+00, time/batch = 0.2275s	
1209/2700 (epoch 22.389), train_loss = 3.29031974, grad/param norm = 1.3179e+00, time/batch = 0.2151s	
1210/2700 (epoch 22.407), train_loss = 3.32810129, grad/param norm = 1.3573e+00, time/batch = 0.2019s	
1211/2700 (epoch 22.426), train_loss = 3.32133248, grad/param norm = 1.3826e+00, time/batch = 0.2318s	
1212/2700 (epoch 22.444), train_loss = 3.24517207, grad/param norm = 1.4705e+00, time/batch = 0.2257s	
1213/2700 (epoch 22.463), train_loss = 3.29745168, grad/param norm = 1.7944e+00, time/batch = 0.2327s	
1214/2700 (epoch 22.481), train_loss = 3.39666810, grad/param norm = 1.8807e+00, time/batch = 0.2219s	
1215/2700 (epoch 22.500), train_loss = 3.43244432, grad/param norm = 1.8999e+00, time/batch = 0.2336s	
1216/2700 (epoch 22.519), train_loss = 3.39370818, grad/param norm = 1.9734e+00, time/batch = 0.2360s	
1217/2700 (epoch 22.537), train_loss = 3.41021577, grad/param norm = 1.8393e+00, time/batch = 0.2383s	
1218/2700 (epoch 22.556), train_loss = 3.35233316, grad/param norm = 1.4495e+00, time/batch = 0.2289s	
1219/2700 (epoch 22.574), train_loss = 3.25471811, grad/param norm = 1.0978e+00, time/batch = 0.2022s	
1220/2700 (epoch 22.593), train_loss = 3.26782994, grad/param norm = 1.3633e+00, time/batch = 0.2353s	
1221/2700 (epoch 22.611), train_loss = 3.22042214, grad/param norm = 1.3307e+00, time/batch = 0.2240s	
1222/2700 (epoch 22.630), train_loss = 3.25889687, grad/param norm = 1.5025e+00, time/batch = 0.2232s	
1223/2700 (epoch 22.648), train_loss = 3.34318263, grad/param norm = 1.5486e+00, time/batch = 0.2299s	
1224/2700 (epoch 22.667), train_loss = 3.27566085, grad/param norm = 1.5904e+00, time/batch = 0.2080s	
1225/2700 (epoch 22.685), train_loss = 3.27178297, grad/param norm = 1.4326e+00, time/batch = 0.2292s	
1226/2700 (epoch 22.704), train_loss = 3.25218706, grad/param norm = 1.6291e+00, time/batch = 0.2356s	
1227/2700 (epoch 22.722), train_loss = 3.26573842, grad/param norm = 1.5679e+00, time/batch = 0.2350s	
1228/2700 (epoch 22.741), train_loss = 3.36763740, grad/param norm = 1.3539e+00, time/batch = 0.2289s	
1229/2700 (epoch 22.759), train_loss = 3.31126460, grad/param norm = 1.3957e+00, time/batch = 0.2353s	
1230/2700 (epoch 22.778), train_loss = 3.31030521, grad/param norm = 1.6216e+00, time/batch = 0.2346s	
1231/2700 (epoch 22.796), train_loss = 3.32795592, grad/param norm = 1.6873e+00, time/batch = 0.2150s	
1232/2700 (epoch 22.815), train_loss = 3.25393798, grad/param norm = 1.6878e+00, time/batch = 0.2146s	
1233/2700 (epoch 22.833), train_loss = 3.31342986, grad/param norm = 1.8843e+00, time/batch = 0.2342s	
1234/2700 (epoch 22.852), train_loss = 3.29666297, grad/param norm = 1.9552e+00, time/batch = 0.2164s	
1235/2700 (epoch 22.870), train_loss = 3.29209385, grad/param norm = 1.7664e+00, time/batch = 0.2327s	
1236/2700 (epoch 22.889), train_loss = 3.30169103, grad/param norm = 1.6259e+00, time/batch = 0.2325s	
1237/2700 (epoch 22.907), train_loss = 3.34204027, grad/param norm = 1.6511e+00, time/batch = 0.2367s	
1238/2700 (epoch 22.926), train_loss = 3.32155519, grad/param norm = 1.8839e+00, time/batch = 0.2307s	
1239/2700 (epoch 22.944), train_loss = 3.34802044, grad/param norm = 1.6483e+00, time/batch = 0.2338s	
1240/2700 (epoch 22.963), train_loss = 3.39271888, grad/param norm = 1.4636e+00, time/batch = 0.2366s	
1241/2700 (epoch 22.981), train_loss = 3.45806350, grad/param norm = 1.4457e+00, time/batch = 0.2248s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1242/2700 (epoch 23.000), train_loss = 3.35728606, grad/param norm = 1.3613e+00, time/batch = 0.2286s	
1243/2700 (epoch 23.019), train_loss = 3.28061569, grad/param norm = 1.3998e+00, time/batch = 0.1940s	
1244/2700 (epoch 23.037), train_loss = 3.30755792, grad/param norm = 1.3976e+00, time/batch = 0.2219s	
1245/2700 (epoch 23.056), train_loss = 3.29325083, grad/param norm = 1.0701e+00, time/batch = 0.2219s	
1246/2700 (epoch 23.074), train_loss = 3.31354736, grad/param norm = 9.3652e-01, time/batch = 0.2300s	
1247/2700 (epoch 23.093), train_loss = 3.33248354, grad/param norm = 1.0569e+00, time/batch = 0.2158s	
1248/2700 (epoch 23.111), train_loss = 3.30989429, grad/param norm = 1.2037e+00, time/batch = 0.2262s	
1249/2700 (epoch 23.130), train_loss = 3.33284457, grad/param norm = 1.2304e+00, time/batch = 0.2301s	
1250/2700 (epoch 23.148), train_loss = 3.28990289, grad/param norm = 1.4924e+00, time/batch = 0.2317s	
1251/2700 (epoch 23.167), train_loss = 3.32701303, grad/param norm = 1.6426e+00, time/batch = 0.2183s	
1252/2700 (epoch 23.185), train_loss = 3.30142632, grad/param norm = 1.5986e+00, time/batch = 0.1949s	
1253/2700 (epoch 23.204), train_loss = 3.23419219, grad/param norm = 1.6630e+00, time/batch = 0.1952s	
1254/2700 (epoch 23.222), train_loss = 3.20701260, grad/param norm = 1.9540e+00, time/batch = 0.2343s	
1255/2700 (epoch 23.241), train_loss = 3.22644915, grad/param norm = 1.7741e+00, time/batch = 0.2172s	
1256/2700 (epoch 23.259), train_loss = 3.25471653, grad/param norm = 1.6233e+00, time/batch = 0.2066s	
1257/2700 (epoch 23.278), train_loss = 3.34130109, grad/param norm = 1.9743e+00, time/batch = 0.2183s	
1258/2700 (epoch 23.296), train_loss = 3.36432763, grad/param norm = 2.0490e+00, time/batch = 0.2237s	
1259/2700 (epoch 23.315), train_loss = 3.33197403, grad/param norm = 1.5358e+00, time/batch = 0.2319s	
1260/2700 (epoch 23.333), train_loss = 3.37337796, grad/param norm = 1.1046e+00, time/batch = 0.2316s	
1261/2700 (epoch 23.352), train_loss = 3.37631236, grad/param norm = 1.1227e+00, time/batch = 0.2243s	
1262/2700 (epoch 23.370), train_loss = 3.33659556, grad/param norm = 1.3069e+00, time/batch = 0.2231s	
1263/2700 (epoch 23.389), train_loss = 3.29024597, grad/param norm = 1.3448e+00, time/batch = 0.2354s	
1264/2700 (epoch 23.407), train_loss = 3.32523010, grad/param norm = 1.3734e+00, time/batch = 0.2350s	
1265/2700 (epoch 23.426), train_loss = 3.32087918, grad/param norm = 1.3848e+00, time/batch = 0.2331s	
1266/2700 (epoch 23.444), train_loss = 3.24486736, grad/param norm = 1.4764e+00, time/batch = 0.2277s	
1267/2700 (epoch 23.463), train_loss = 3.29909951, grad/param norm = 1.7705e+00, time/batch = 0.2286s	
1268/2700 (epoch 23.481), train_loss = 3.39968216, grad/param norm = 1.8774e+00, time/batch = 0.2316s	
1269/2700 (epoch 23.500), train_loss = 3.43517524, grad/param norm = 1.8979e+00, time/batch = 0.2357s	
1270/2700 (epoch 23.519), train_loss = 3.39427008, grad/param norm = 1.9361e+00, time/batch = 0.2321s	
1271/2700 (epoch 23.537), train_loss = 3.39719251, grad/param norm = 1.7221e+00, time/batch = 0.2147s	
1272/2700 (epoch 23.556), train_loss = 3.33351254, grad/param norm = 1.3911e+00, time/batch = 0.1846s	
1273/2700 (epoch 23.574), train_loss = 3.25292827, grad/param norm = 1.0716e+00, time/batch = 0.2247s	
1274/2700 (epoch 23.593), train_loss = 3.26517239, grad/param norm = 1.3257e+00, time/batch = 0.2323s	
1275/2700 (epoch 23.611), train_loss = 3.21310261, grad/param norm = 1.2746e+00, time/batch = 0.2291s	
1276/2700 (epoch 23.630), train_loss = 3.25108879, grad/param norm = 1.4333e+00, time/batch = 0.2270s	
1277/2700 (epoch 23.648), train_loss = 3.33892727, grad/param norm = 1.5040e+00, time/batch = 0.2180s	
1278/2700 (epoch 23.667), train_loss = 3.27685105, grad/param norm = 1.5513e+00, time/batch = 0.2182s	
1279/2700 (epoch 23.685), train_loss = 3.26521463, grad/param norm = 1.4268e+00, time/batch = 0.2178s	
1280/2700 (epoch 23.704), train_loss = 3.24500512, grad/param norm = 1.5934e+00, time/batch = 0.2304s	
1281/2700 (epoch 23.722), train_loss = 3.25099606, grad/param norm = 1.5478e+00, time/batch = 0.2240s	
1282/2700 (epoch 23.741), train_loss = 3.36611572, grad/param norm = 1.5081e+00, time/batch = 0.2237s	
1283/2700 (epoch 23.759), train_loss = 3.33651711, grad/param norm = 1.7726e+00, time/batch = 0.2238s	
1284/2700 (epoch 23.778), train_loss = 3.32634212, grad/param norm = 1.9892e+00, time/batch = 0.2213s	
1285/2700 (epoch 23.796), train_loss = 3.33777723, grad/param norm = 1.9497e+00, time/batch = 0.2322s	
1286/2700 (epoch 23.815), train_loss = 3.26208058, grad/param norm = 1.8276e+00, time/batch = 0.2305s	
1287/2700 (epoch 23.833), train_loss = 3.31492356, grad/param norm = 1.8363e+00, time/batch = 0.2353s	
1288/2700 (epoch 23.852), train_loss = 3.28913695, grad/param norm = 1.7756e+00, time/batch = 0.2305s	
1289/2700 (epoch 23.870), train_loss = 3.28002446, grad/param norm = 1.5247e+00, time/batch = 0.2345s	
1290/2700 (epoch 23.889), train_loss = 3.28748676, grad/param norm = 1.3649e+00, time/batch = 0.2375s	
1291/2700 (epoch 23.907), train_loss = 3.33603494, grad/param norm = 1.4101e+00, time/batch = 0.2127s	
1292/2700 (epoch 23.926), train_loss = 3.30679642, grad/param norm = 1.6153e+00, time/batch = 0.2259s	
1293/2700 (epoch 23.944), train_loss = 3.32774393, grad/param norm = 1.4506e+00, time/batch = 0.2036s	
1294/2700 (epoch 23.963), train_loss = 3.38671837, grad/param norm = 1.3264e+00, time/batch = 0.2083s	
1295/2700 (epoch 23.981), train_loss = 3.44616369, grad/param norm = 1.3254e+00, time/batch = 0.2098s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1296/2700 (epoch 24.000), train_loss = 3.35250004, grad/param norm = 1.3015e+00, time/batch = 0.2194s	
1297/2700 (epoch 24.019), train_loss = 3.27745581, grad/param norm = 1.3465e+00, time/batch = 0.2150s	
1298/2700 (epoch 24.037), train_loss = 3.30365918, grad/param norm = 1.3524e+00, time/batch = 0.2258s	
1299/2700 (epoch 24.056), train_loss = 3.29027594, grad/param norm = 1.0375e+00, time/batch = 0.2318s	
1300/2700 (epoch 24.074), train_loss = 3.31185162, grad/param norm = 9.0490e-01, time/batch = 0.2298s	
1301/2700 (epoch 24.093), train_loss = 3.33018998, grad/param norm = 1.0335e+00, time/batch = 0.2339s	
1302/2700 (epoch 24.111), train_loss = 3.30738473, grad/param norm = 1.1728e+00, time/batch = 0.2045s	
1303/2700 (epoch 24.130), train_loss = 3.32997113, grad/param norm = 1.1926e+00, time/batch = 0.2315s	
1304/2700 (epoch 24.148), train_loss = 3.28645372, grad/param norm = 1.4584e+00, time/batch = 0.2328s	
1305/2700 (epoch 24.167), train_loss = 3.32346581, grad/param norm = 1.6198e+00, time/batch = 0.2338s	
1306/2700 (epoch 24.185), train_loss = 3.29849932, grad/param norm = 1.5868e+00, time/batch = 0.2143s	
1307/2700 (epoch 24.204), train_loss = 3.23156812, grad/param norm = 1.6764e+00, time/batch = 0.2225s	
1308/2700 (epoch 24.222), train_loss = 3.20634518, grad/param norm = 1.9630e+00, time/batch = 0.2311s	
1309/2700 (epoch 24.241), train_loss = 3.22361894, grad/param norm = 1.7685e+00, time/batch = 0.2301s	
1310/2700 (epoch 24.259), train_loss = 3.25371419, grad/param norm = 1.6214e+00, time/batch = 0.2220s	
1311/2700 (epoch 24.278), train_loss = 3.34155818, grad/param norm = 1.9534e+00, time/batch = 0.2223s	
1312/2700 (epoch 24.296), train_loss = 3.36202652, grad/param norm = 2.0379e+00, time/batch = 0.2214s	
1313/2700 (epoch 24.315), train_loss = 3.32664135, grad/param norm = 1.4784e+00, time/batch = 0.2198s	
1314/2700 (epoch 24.333), train_loss = 3.37007894, grad/param norm = 1.0447e+00, time/batch = 0.2181s	
1315/2700 (epoch 24.352), train_loss = 3.37381294, grad/param norm = 1.0644e+00, time/batch = 0.2153s	
1316/2700 (epoch 24.370), train_loss = 3.33277794, grad/param norm = 1.2372e+00, time/batch = 0.2278s	
1317/2700 (epoch 24.389), train_loss = 3.28675628, grad/param norm = 1.2599e+00, time/batch = 0.2311s	
1318/2700 (epoch 24.407), train_loss = 3.31986910, grad/param norm = 1.2797e+00, time/batch = 0.2248s	
1319/2700 (epoch 24.426), train_loss = 3.31701767, grad/param norm = 1.2960e+00, time/batch = 0.2210s	
1320/2700 (epoch 24.444), train_loss = 3.24092878, grad/param norm = 1.3914e+00, time/batch = 0.2338s	
1321/2700 (epoch 24.463), train_loss = 3.29628004, grad/param norm = 1.7077e+00, time/batch = 0.2277s	
1322/2700 (epoch 24.481), train_loss = 3.39739314, grad/param norm = 1.8324e+00, time/batch = 0.2259s	
1323/2700 (epoch 24.500), train_loss = 3.43127632, grad/param norm = 1.8897e+00, time/batch = 0.2329s	
1324/2700 (epoch 24.519), train_loss = 3.38912260, grad/param norm = 1.9153e+00, time/batch = 0.2352s	
1325/2700 (epoch 24.537), train_loss = 3.39216985, grad/param norm = 1.6808e+00, time/batch = 0.2327s	
1326/2700 (epoch 24.556), train_loss = 3.32833533, grad/param norm = 1.3616e+00, time/batch = 0.2359s	
1327/2700 (epoch 24.574), train_loss = 3.25171615, grad/param norm = 1.0547e+00, time/batch = 0.2283s	
1328/2700 (epoch 24.593), train_loss = 3.26371536, grad/param norm = 1.3000e+00, time/batch = 0.2126s	
1329/2700 (epoch 24.611), train_loss = 3.21012740, grad/param norm = 1.2420e+00, time/batch = 0.1851s	
1330/2700 (epoch 24.630), train_loss = 3.24831777, grad/param norm = 1.3916e+00, time/batch = 0.2028s	
1331/2700 (epoch 24.648), train_loss = 3.33576559, grad/param norm = 1.4719e+00, time/batch = 0.2234s	
1332/2700 (epoch 24.667), train_loss = 3.27460580, grad/param norm = 1.5205e+00, time/batch = 0.2159s	
1333/2700 (epoch 24.685), train_loss = 3.26245350, grad/param norm = 1.4088e+00, time/batch = 0.2185s	
1334/2700 (epoch 24.704), train_loss = 3.24282577, grad/param norm = 1.5787e+00, time/batch = 0.2187s	
1335/2700 (epoch 24.722), train_loss = 3.24743702, grad/param norm = 1.5413e+00, time/batch = 0.2305s	
1336/2700 (epoch 24.741), train_loss = 3.36430972, grad/param norm = 1.5070e+00, time/batch = 0.2321s	
1337/2700 (epoch 24.759), train_loss = 3.33179663, grad/param norm = 1.7318e+00, time/batch = 0.2311s	
1338/2700 (epoch 24.778), train_loss = 3.31917203, grad/param norm = 1.9051e+00, time/batch = 0.2340s	
1339/2700 (epoch 24.796), train_loss = 3.32929535, grad/param norm = 1.8823e+00, time/batch = 0.2264s	
1340/2700 (epoch 24.815), train_loss = 3.25761675, grad/param norm = 1.7719e+00, time/batch = 0.2311s	
1341/2700 (epoch 24.833), train_loss = 3.30900796, grad/param norm = 1.7821e+00, time/batch = 0.2196s	
1342/2700 (epoch 24.852), train_loss = 3.28523409, grad/param norm = 1.7313e+00, time/batch = 0.2147s	
1343/2700 (epoch 24.870), train_loss = 3.27639929, grad/param norm = 1.4827e+00, time/batch = 0.2315s	
1344/2700 (epoch 24.889), train_loss = 3.28533262, grad/param norm = 1.3220e+00, time/batch = 0.2311s	
1345/2700 (epoch 24.907), train_loss = 3.33390059, grad/param norm = 1.3713e+00, time/batch = 0.2345s	
1346/2700 (epoch 24.926), train_loss = 3.30395156, grad/param norm = 1.5791e+00, time/batch = 0.2349s	
1347/2700 (epoch 24.944), train_loss = 3.32407442, grad/param norm = 1.4137e+00, time/batch = 0.2359s	
1348/2700 (epoch 24.963), train_loss = 3.38341118, grad/param norm = 1.2849e+00, time/batch = 0.2222s	
1349/2700 (epoch 24.981), train_loss = 3.44225327, grad/param norm = 1.2840e+00, time/batch = 0.2350s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1350/2700 (epoch 25.000), train_loss = 3.34935151, grad/param norm = 1.2654e+00, time/batch = 0.2346s	
1351/2700 (epoch 25.019), train_loss = 3.27521441, grad/param norm = 1.3157e+00, time/batch = 0.2181s	
1352/2700 (epoch 25.037), train_loss = 3.30096132, grad/param norm = 1.3198e+00, time/batch = 0.2117s	
1353/2700 (epoch 25.056), train_loss = 3.28807505, grad/param norm = 1.0041e+00, time/batch = 0.2133s	
1354/2700 (epoch 25.074), train_loss = 3.31041459, grad/param norm = 8.7511e-01, time/batch = 0.2201s	
1355/2700 (epoch 25.093), train_loss = 3.32808178, grad/param norm = 1.0079e+00, time/batch = 0.2245s	
1356/2700 (epoch 25.111), train_loss = 3.30470681, grad/param norm = 1.1353e+00, time/batch = 0.2229s	
1357/2700 (epoch 25.130), train_loss = 3.32672588, grad/param norm = 1.1424e+00, time/batch = 0.2221s	
1358/2700 (epoch 25.148), train_loss = 3.28301483, grad/param norm = 1.4061e+00, time/batch = 0.1965s	
1359/2700 (epoch 25.167), train_loss = 3.31928655, grad/param norm = 1.5671e+00, time/batch = 0.2307s	
1360/2700 (epoch 25.185), train_loss = 3.29425222, grad/param norm = 1.5207e+00, time/batch = 0.2257s	
1361/2700 (epoch 25.204), train_loss = 3.22715898, grad/param norm = 1.6116e+00, time/batch = 0.2032s	
1362/2700 (epoch 25.222), train_loss = 3.20259405, grad/param norm = 1.9112e+00, time/batch = 0.2335s	
1363/2700 (epoch 25.241), train_loss = 3.22090051, grad/param norm = 1.7523e+00, time/batch = 0.2346s	
1364/2700 (epoch 25.259), train_loss = 3.25256637, grad/param norm = 1.6203e+00, time/batch = 0.2307s	
1365/2700 (epoch 25.278), train_loss = 3.33951014, grad/param norm = 1.9447e+00, time/batch = 0.2247s	
1366/2700 (epoch 25.296), train_loss = 3.35792400, grad/param norm = 2.0006e+00, time/batch = 0.2321s	
1367/2700 (epoch 25.315), train_loss = 3.32239278, grad/param norm = 1.4476e+00, time/batch = 0.2129s	
1368/2700 (epoch 25.333), train_loss = 3.36834692, grad/param norm = 1.0247e+00, time/batch = 0.2354s	
1369/2700 (epoch 25.352), train_loss = 3.37246108, grad/param norm = 1.0488e+00, time/batch = 0.2355s	
1370/2700 (epoch 25.370), train_loss = 3.33069648, grad/param norm = 1.2121e+00, time/batch = 0.2299s	
1371/2700 (epoch 25.389), train_loss = 3.28492130, grad/param norm = 1.2212e+00, time/batch = 0.2227s	
1372/2700 (epoch 25.407), train_loss = 3.31659947, grad/param norm = 1.2298e+00, time/batch = 0.2137s	
1373/2700 (epoch 25.426), train_loss = 3.31435685, grad/param norm = 1.2390e+00, time/batch = 0.2111s	
1374/2700 (epoch 25.444), train_loss = 3.23822924, grad/param norm = 1.3285e+00, time/batch = 0.2183s	
1375/2700 (epoch 25.463), train_loss = 3.29337598, grad/param norm = 1.6405e+00, time/batch = 0.2223s	
1376/2700 (epoch 25.481), train_loss = 3.39284779, grad/param norm = 1.7696e+00, time/batch = 0.2186s	
1377/2700 (epoch 25.500), train_loss = 3.42724887, grad/param norm = 1.8580e+00, time/batch = 0.2151s	
1378/2700 (epoch 25.519), train_loss = 3.38489096, grad/param norm = 1.8818e+00, time/batch = 0.2351s	
1379/2700 (epoch 25.537), train_loss = 3.38754980, grad/param norm = 1.6398e+00, time/batch = 0.2282s	
1380/2700 (epoch 25.556), train_loss = 3.32333143, grad/param norm = 1.3299e+00, time/batch = 0.2348s	
1381/2700 (epoch 25.574), train_loss = 3.25029766, grad/param norm = 1.0342e+00, time/batch = 0.2316s	
1382/2700 (epoch 25.593), train_loss = 3.26203691, grad/param norm = 1.2700e+00, time/batch = 0.2193s	
1383/2700 (epoch 25.611), train_loss = 3.20741331, grad/param norm = 1.2053e+00, time/batch = 0.2243s	
1384/2700 (epoch 25.630), train_loss = 3.24621668, grad/param norm = 1.3507e+00, time/batch = 0.2276s	
1385/2700 (epoch 25.648), train_loss = 3.33270080, grad/param norm = 1.4373e+00, time/batch = 0.2267s	
1386/2700 (epoch 25.667), train_loss = 3.27148890, grad/param norm = 1.4841e+00, time/batch = 0.2120s	
1387/2700 (epoch 25.685), train_loss = 3.25949244, grad/param norm = 1.3787e+00, time/batch = 0.2349s	
1388/2700 (epoch 25.704), train_loss = 3.24006981, grad/param norm = 1.5491e+00, time/batch = 0.2291s	
1389/2700 (epoch 25.722), train_loss = 3.24291410, grad/param norm = 1.5063e+00, time/batch = 0.2366s	
1390/2700 (epoch 25.741), train_loss = 3.36035037, grad/param norm = 1.4531e+00, time/batch = 0.2331s	
1391/2700 (epoch 25.759), train_loss = 3.32567833, grad/param norm = 1.6793e+00, time/batch = 0.2228s	
1392/2700 (epoch 25.778), train_loss = 3.31578866, grad/param norm = 1.8750e+00, time/batch = 0.2133s	
1393/2700 (epoch 25.796), train_loss = 3.32489202, grad/param norm = 1.8469e+00, time/batch = 0.2069s	
1394/2700 (epoch 25.815), train_loss = 3.25354759, grad/param norm = 1.7239e+00, time/batch = 0.2212s	
1395/2700 (epoch 25.833), train_loss = 3.30349814, grad/param norm = 1.7351e+00, time/batch = 0.2325s	
1396/2700 (epoch 25.852), train_loss = 3.28190262, grad/param norm = 1.6988e+00, time/batch = 0.2166s	
1397/2700 (epoch 25.870), train_loss = 3.27330415, grad/param norm = 1.4466e+00, time/batch = 0.2198s	
1398/2700 (epoch 25.889), train_loss = 3.28330974, grad/param norm = 1.2824e+00, time/batch = 0.2320s	
1399/2700 (epoch 25.907), train_loss = 3.33182865, grad/param norm = 1.3338e+00, time/batch = 0.2326s	
1400/2700 (epoch 25.926), train_loss = 3.30082203, grad/param norm = 1.5401e+00, time/batch = 0.2311s	
1401/2700 (epoch 25.944), train_loss = 3.32026780, grad/param norm = 1.3730e+00, time/batch = 0.2312s	
1402/2700 (epoch 25.963), train_loss = 3.38002748, grad/param norm = 1.2402e+00, time/batch = 0.2174s	
1403/2700 (epoch 25.981), train_loss = 3.43845997, grad/param norm = 1.2406e+00, time/batch = 0.2137s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1404/2700 (epoch 26.000), train_loss = 3.34628698, grad/param norm = 1.2288e+00, time/batch = 0.2088s	
1405/2700 (epoch 26.019), train_loss = 3.27306293, grad/param norm = 1.2841e+00, time/batch = 0.2158s	
1406/2700 (epoch 26.037), train_loss = 3.29834732, grad/param norm = 1.2855e+00, time/batch = 0.2276s	
1407/2700 (epoch 26.056), train_loss = 3.28598024, grad/param norm = 9.7008e-01, time/batch = 0.2364s	
1408/2700 (epoch 26.074), train_loss = 3.30912747, grad/param norm = 8.4753e-01, time/batch = 0.2355s	
1409/2700 (epoch 26.093), train_loss = 3.32613063, grad/param norm = 9.8401e-01, time/batch = 0.2359s	
1410/2700 (epoch 26.111), train_loss = 3.30223335, grad/param norm = 1.0988e+00, time/batch = 0.2370s	
1411/2700 (epoch 26.130), train_loss = 3.32370480, grad/param norm = 1.0931e+00, time/batch = 0.2169s	
1412/2700 (epoch 26.148), train_loss = 3.27981417, grad/param norm = 1.3523e+00, time/batch = 0.2160s	
1413/2700 (epoch 26.167), train_loss = 3.31511209, grad/param norm = 1.5112e+00, time/batch = 0.1989s	
1414/2700 (epoch 26.185), train_loss = 3.29001372, grad/param norm = 1.4471e+00, time/batch = 0.2249s	
1415/2700 (epoch 26.204), train_loss = 3.22262790, grad/param norm = 1.5322e+00, time/batch = 0.1973s	
1416/2700 (epoch 26.222), train_loss = 3.19848814, grad/param norm = 1.8482e+00, time/batch = 0.2198s	
1417/2700 (epoch 26.241), train_loss = 3.21849843, grad/param norm = 1.7352e+00, time/batch = 0.2152s	
1418/2700 (epoch 26.259), train_loss = 3.25147150, grad/param norm = 1.6192e+00, time/batch = 0.2141s	
1419/2700 (epoch 26.278), train_loss = 3.33656313, grad/param norm = 1.9400e+00, time/batch = 0.2265s	
1420/2700 (epoch 26.296), train_loss = 3.35435842, grad/param norm = 1.9721e+00, time/batch = 0.2309s	
1421/2700 (epoch 26.315), train_loss = 3.31891912, grad/param norm = 1.4217e+00, time/batch = 0.2290s	
1422/2700 (epoch 26.333), train_loss = 3.36677909, grad/param norm = 1.0093e+00, time/batch = 0.2129s	
1423/2700 (epoch 26.352), train_loss = 3.37130791, grad/param norm = 1.0383e+00, time/batch = 0.2315s	
1424/2700 (epoch 26.370), train_loss = 3.32887252, grad/param norm = 1.1923e+00, time/batch = 0.2271s	
1425/2700 (epoch 26.389), train_loss = 3.28328751, grad/param norm = 1.1882e+00, time/batch = 0.2318s	
1426/2700 (epoch 26.407), train_loss = 3.31367040, grad/param norm = 1.1852e+00, time/batch = 0.2356s	
1427/2700 (epoch 26.426), train_loss = 3.31188896, grad/param norm = 1.1871e+00, time/batch = 0.2360s	
1428/2700 (epoch 26.444), train_loss = 3.23570709, grad/param norm = 1.2685e+00, time/batch = 0.2353s	
1429/2700 (epoch 26.463), train_loss = 3.29009988, grad/param norm = 1.5697e+00, time/batch = 0.2323s	
1430/2700 (epoch 26.481), train_loss = 3.38754336, grad/param norm = 1.7027e+00, time/batch = 0.2224s	
1431/2700 (epoch 26.500), train_loss = 3.42351391, grad/param norm = 1.8178e+00, time/batch = 0.2187s	
1432/2700 (epoch 26.519), train_loss = 3.38134329, grad/param norm = 1.8458e+00, time/batch = 0.2087s	
1433/2700 (epoch 26.537), train_loss = 3.38381197, grad/param norm = 1.6077e+00, time/batch = 0.2275s	
1434/2700 (epoch 26.556), train_loss = 3.31908136, grad/param norm = 1.3014e+00, time/batch = 0.1882s	
1435/2700 (epoch 26.574), train_loss = 3.24872717, grad/param norm = 1.0130e+00, time/batch = 0.2283s	
1436/2700 (epoch 26.593), train_loss = 3.26019873, grad/param norm = 1.2406e+00, time/batch = 0.2229s	
1437/2700 (epoch 26.611), train_loss = 3.20493944, grad/param norm = 1.1713e+00, time/batch = 0.2192s	
1438/2700 (epoch 26.630), train_loss = 3.24430357, grad/param norm = 1.3123e+00, time/batch = 0.2188s	
1439/2700 (epoch 26.648), train_loss = 3.32966802, grad/param norm = 1.4033e+00, time/batch = 0.2252s	
1440/2700 (epoch 26.667), train_loss = 3.26847121, grad/param norm = 1.4504e+00, time/batch = 0.2310s	
1441/2700 (epoch 26.685), train_loss = 3.25670632, grad/param norm = 1.3502e+00, time/batch = 0.2105s	
1442/2700 (epoch 26.704), train_loss = 3.23734329, grad/param norm = 1.5198e+00, time/batch = 0.2172s	
1443/2700 (epoch 26.722), train_loss = 3.23849724, grad/param norm = 1.4697e+00, time/batch = 0.1767s	
1444/2700 (epoch 26.741), train_loss = 3.35668521, grad/param norm = 1.4001e+00, time/batch = 0.2315s	
1445/2700 (epoch 26.759), train_loss = 3.32016557, grad/param norm = 1.6274e+00, time/batch = 0.2310s	
1446/2700 (epoch 26.778), train_loss = 3.31263837, grad/param norm = 1.8449e+00, time/batch = 0.2294s	
1447/2700 (epoch 26.796), train_loss = 3.32076190, grad/param norm = 1.8115e+00, time/batch = 0.2284s	
1448/2700 (epoch 26.815), train_loss = 3.24971052, grad/param norm = 1.6763e+00, time/batch = 0.2312s	
1449/2700 (epoch 26.833), train_loss = 3.29824355, grad/param norm = 1.6884e+00, time/batch = 0.2384s	
1450/2700 (epoch 26.852), train_loss = 3.27879717, grad/param norm = 1.6678e+00, time/batch = 0.2329s	
1451/2700 (epoch 26.870), train_loss = 3.27043017, grad/param norm = 1.4121e+00, time/batch = 0.2298s	
1452/2700 (epoch 26.889), train_loss = 3.28140749, grad/param norm = 1.2446e+00, time/batch = 0.2028s	
1453/2700 (epoch 26.907), train_loss = 3.32990974, grad/param norm = 1.2988e+00, time/batch = 0.1871s	
1454/2700 (epoch 26.926), train_loss = 3.29793639, grad/param norm = 1.5034e+00, time/batch = 0.2329s	
1455/2700 (epoch 26.944), train_loss = 3.31667401, grad/param norm = 1.3346e+00, time/batch = 0.2298s	
1456/2700 (epoch 26.963), train_loss = 3.37690927, grad/param norm = 1.1987e+00, time/batch = 0.2104s	
1457/2700 (epoch 26.981), train_loss = 3.43502960, grad/param norm = 1.1998e+00, time/batch = 0.2133s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1458/2700 (epoch 27.000), train_loss = 3.34341242, grad/param norm = 1.1935e+00, time/batch = 0.2281s	
1459/2700 (epoch 27.019), train_loss = 3.27104681, grad/param norm = 1.2535e+00, time/batch = 0.2245s	
1460/2700 (epoch 27.037), train_loss = 3.29586693, grad/param norm = 1.2527e+00, time/batch = 0.2318s	
1461/2700 (epoch 27.056), train_loss = 3.28404561, grad/param norm = 9.3817e-01, time/batch = 0.2317s	
1462/2700 (epoch 27.074), train_loss = 3.30795260, grad/param norm = 8.2281e-01, time/batch = 0.2114s	
1463/2700 (epoch 27.093), train_loss = 3.32432973, grad/param norm = 9.6292e-01, time/batch = 0.2205s	
1464/2700 (epoch 27.111), train_loss = 3.29996805, grad/param norm = 1.0657e+00, time/batch = 0.2238s	
1465/2700 (epoch 27.130), train_loss = 3.32095105, grad/param norm = 1.0483e+00, time/batch = 0.2302s	
1466/2700 (epoch 27.148), train_loss = 3.27692900, grad/param norm = 1.3012e+00, time/batch = 0.2244s	
1467/2700 (epoch 27.167), train_loss = 3.31109198, grad/param norm = 1.4573e+00, time/batch = 0.2310s	
1468/2700 (epoch 27.185), train_loss = 3.28596730, grad/param norm = 1.3716e+00, time/batch = 0.2272s	
1469/2700 (epoch 27.204), train_loss = 3.21801026, grad/param norm = 1.4419e+00, time/batch = 0.2359s	
1470/2700 (epoch 27.222), train_loss = 3.19392856, grad/param norm = 1.7704e+00, time/batch = 0.2301s	
1471/2700 (epoch 27.241), train_loss = 3.21590875, grad/param norm = 1.7037e+00, time/batch = 0.2233s	
1472/2700 (epoch 27.259), train_loss = 3.25018914, grad/param norm = 1.6108e+00, time/batch = 0.2118s	
1473/2700 (epoch 27.278), train_loss = 3.33370806, grad/param norm = 1.9431e+00, time/batch = 0.2364s	
1474/2700 (epoch 27.296), train_loss = 3.35117025, grad/param norm = 1.9476e+00, time/batch = 0.2211s	
1475/2700 (epoch 27.315), train_loss = 3.31552788, grad/param norm = 1.3968e+00, time/batch = 0.2148s	
1476/2700 (epoch 27.333), train_loss = 3.36520093, grad/param norm = 9.9660e-01, time/batch = 0.2115s	
1477/2700 (epoch 27.352), train_loss = 3.37032599, grad/param norm = 1.0331e+00, time/batch = 0.2149s	
1478/2700 (epoch 27.370), train_loss = 3.32734767, grad/param norm = 1.1796e+00, time/batch = 0.2322s	
1479/2700 (epoch 27.389), train_loss = 3.28190238, grad/param norm = 1.1624e+00, time/batch = 0.2297s	
1480/2700 (epoch 27.407), train_loss = 3.31105127, grad/param norm = 1.1474e+00, time/batch = 0.2355s	
1481/2700 (epoch 27.426), train_loss = 3.30961784, grad/param norm = 1.1413e+00, time/batch = 0.2244s	
1482/2700 (epoch 27.444), train_loss = 3.23340807, grad/param norm = 1.2140e+00, time/batch = 0.2332s	
1483/2700 (epoch 27.463), train_loss = 3.28690911, grad/param norm = 1.5007e+00, time/batch = 0.2210s	
1484/2700 (epoch 27.481), train_loss = 3.38230027, grad/param norm = 1.6360e+00, time/batch = 0.2112s	
1485/2700 (epoch 27.500), train_loss = 3.41994128, grad/param norm = 1.7717e+00, time/batch = 0.2308s	
1486/2700 (epoch 27.519), train_loss = 3.37792875, grad/param norm = 1.8052e+00, time/batch = 0.2294s	
1487/2700 (epoch 27.537), train_loss = 3.38049245, grad/param norm = 1.5785e+00, time/batch = 0.2313s	
1488/2700 (epoch 27.556), train_loss = 3.31539401, grad/param norm = 1.2747e+00, time/batch = 0.2270s	
1489/2700 (epoch 27.574), train_loss = 3.24715690, grad/param norm = 9.9113e-01, time/batch = 0.2370s	
1490/2700 (epoch 27.593), train_loss = 3.25834428, grad/param norm = 1.2113e+00, time/batch = 0.2351s	
1491/2700 (epoch 27.611), train_loss = 3.20262328, grad/param norm = 1.1379e+00, time/batch = 0.2219s	
1492/2700 (epoch 27.630), train_loss = 3.24244457, grad/param norm = 1.2743e+00, time/batch = 0.2307s	
1493/2700 (epoch 27.648), train_loss = 3.32671282, grad/param norm = 1.3692e+00, time/batch = 0.2147s	
1494/2700 (epoch 27.667), train_loss = 3.26560045, grad/param norm = 1.4181e+00, time/batch = 0.2118s	
1495/2700 (epoch 27.685), train_loss = 3.25410032, grad/param norm = 1.3223e+00, time/batch = 0.2083s	
1496/2700 (epoch 27.704), train_loss = 3.23464306, grad/param norm = 1.4900e+00, time/batch = 0.2022s	
1497/2700 (epoch 27.722), train_loss = 3.23415738, grad/param norm = 1.4321e+00, time/batch = 0.2206s	
1498/2700 (epoch 27.741), train_loss = 3.35339441, grad/param norm = 1.3500e+00, time/batch = 0.2321s	
1499/2700 (epoch 27.759), train_loss = 3.31521273, grad/param norm = 1.5766e+00, time/batch = 0.2371s	
1500/2700 (epoch 27.778), train_loss = 3.30964279, grad/param norm = 1.8141e+00, time/batch = 0.2351s	
1501/2700 (epoch 27.796), train_loss = 3.31685503, grad/param norm = 1.7769e+00, time/batch = 0.2302s	
1502/2700 (epoch 27.815), train_loss = 3.24614186, grad/param norm = 1.6304e+00, time/batch = 0.2254s	
1503/2700 (epoch 27.833), train_loss = 3.29325859, grad/param norm = 1.6426e+00, time/batch = 0.2308s	
1504/2700 (epoch 27.852), train_loss = 3.27587587, grad/param norm = 1.6382e+00, time/batch = 0.2257s	
1505/2700 (epoch 27.870), train_loss = 3.26773379, grad/param norm = 1.3791e+00, time/batch = 0.2042s	
1506/2700 (epoch 27.889), train_loss = 3.27960896, grad/param norm = 1.2086e+00, time/batch = 0.2291s	
1507/2700 (epoch 27.907), train_loss = 3.32812984, grad/param norm = 1.2661e+00, time/batch = 0.2260s	
1508/2700 (epoch 27.926), train_loss = 3.29527294, grad/param norm = 1.4687e+00, time/batch = 0.2230s	
1509/2700 (epoch 27.944), train_loss = 3.31327520, grad/param norm = 1.2981e+00, time/batch = 0.2237s	
1510/2700 (epoch 27.963), train_loss = 3.37403493, grad/param norm = 1.1600e+00, time/batch = 0.2203s	
1511/2700 (epoch 27.981), train_loss = 3.43194192, grad/param norm = 1.1615e+00, time/batch = 0.2294s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1512/2700 (epoch 28.000), train_loss = 3.34070792, grad/param norm = 1.1595e+00, time/batch = 0.2129s	
1513/2700 (epoch 28.019), train_loss = 3.26915954, grad/param norm = 1.2240e+00, time/batch = 0.2163s	
1514/2700 (epoch 28.037), train_loss = 3.29351635, grad/param norm = 1.2213e+00, time/batch = 0.2142s	
1515/2700 (epoch 28.056), train_loss = 3.28225410, grad/param norm = 9.0819e-01, time/batch = 0.2273s	
1516/2700 (epoch 28.074), train_loss = 3.30687509, grad/param norm = 8.0074e-01, time/batch = 0.2322s	
1517/2700 (epoch 28.093), train_loss = 3.32265831, grad/param norm = 9.4429e-01, time/batch = 0.2355s	
1518/2700 (epoch 28.111), train_loss = 3.29788494, grad/param norm = 1.0356e+00, time/batch = 0.2340s	
1519/2700 (epoch 28.130), train_loss = 3.31843526, grad/param norm = 1.0076e+00, time/batch = 0.2321s	
1520/2700 (epoch 28.148), train_loss = 3.27433347, grad/param norm = 1.2530e+00, time/batch = 0.2279s	
1521/2700 (epoch 28.167), train_loss = 3.30724944, grad/param norm = 1.4062e+00, time/batch = 0.2298s	
1522/2700 (epoch 28.185), train_loss = 3.28213955, grad/param norm = 1.2956e+00, time/batch = 0.2215s	
1523/2700 (epoch 28.204), train_loss = 3.21338486, grad/param norm = 1.3427e+00, time/batch = 0.2259s	
1524/2700 (epoch 28.222), train_loss = 3.18899906, grad/param norm = 1.6751e+00, time/batch = 0.2288s	
1525/2700 (epoch 28.241), train_loss = 3.21282885, grad/param norm = 1.6449e+00, time/batch = 0.2312s	
1526/2700 (epoch 28.259), train_loss = 3.24833539, grad/param norm = 1.5861e+00, time/batch = 0.2343s	
1527/2700 (epoch 28.278), train_loss = 3.33134269, grad/param norm = 1.9592e+00, time/batch = 0.2331s	
1528/2700 (epoch 28.296), train_loss = 3.34848112, grad/param norm = 1.9280e+00, time/batch = 0.2339s	
1529/2700 (epoch 28.315), train_loss = 3.31202182, grad/param norm = 1.3730e+00, time/batch = 0.2302s	
1530/2700 (epoch 28.333), train_loss = 3.36361035, grad/param norm = 9.8819e-01, time/batch = 0.2359s	
1531/2700 (epoch 28.352), train_loss = 3.36954300, grad/param norm = 1.0348e+00, time/batch = 0.2149s	
1532/2700 (epoch 28.370), train_loss = 3.32617791, grad/param norm = 1.1769e+00, time/batch = 0.2097s	
1533/2700 (epoch 28.389), train_loss = 3.28089758, grad/param norm = 1.1476e+00, time/batch = 0.2233s	
1534/2700 (epoch 28.407), train_loss = 3.30884459, grad/param norm = 1.1198e+00, time/batch = 0.2052s	
1535/2700 (epoch 28.426), train_loss = 3.30758540, grad/param norm = 1.1038e+00, time/batch = 0.2062s	
1536/2700 (epoch 28.444), train_loss = 3.23140445, grad/param norm = 1.1686e+00, time/batch = 0.1913s	
1537/2700 (epoch 28.463), train_loss = 3.28405832, grad/param norm = 1.4385e+00, time/batch = 0.2352s	
1538/2700 (epoch 28.481), train_loss = 3.37743344, grad/param norm = 1.5726e+00, time/batch = 0.2331s	
1539/2700 (epoch 28.500), train_loss = 3.41648733, grad/param norm = 1.7206e+00, time/batch = 0.2330s	
1540/2700 (epoch 28.519), train_loss = 3.37442635, grad/param norm = 1.7578e+00, time/batch = 0.2318s	
1541/2700 (epoch 28.537), train_loss = 3.37726568, grad/param norm = 1.5476e+00, time/batch = 0.2243s	
1542/2700 (epoch 28.556), train_loss = 3.31200369, grad/param norm = 1.2473e+00, time/batch = 0.2039s	
1543/2700 (epoch 28.574), train_loss = 3.24564301, grad/param norm = 9.6775e-01, time/batch = 0.2333s	
1544/2700 (epoch 28.593), train_loss = 3.25652747, grad/param norm = 1.1808e+00, time/batch = 0.2341s	
1545/2700 (epoch 28.611), train_loss = 3.20039611, grad/param norm = 1.1033e+00, time/batch = 0.2289s	
1546/2700 (epoch 28.630), train_loss = 3.24057413, grad/param norm = 1.2351e+00, time/batch = 0.2234s	
1547/2700 (epoch 28.648), train_loss = 3.32382385, grad/param norm = 1.3340e+00, time/batch = 0.2217s	
1548/2700 (epoch 28.667), train_loss = 3.26286961, grad/param norm = 1.3858e+00, time/batch = 0.2191s	
1549/2700 (epoch 28.685), train_loss = 3.25165964, grad/param norm = 1.2943e+00, time/batch = 0.2304s	
1550/2700 (epoch 28.704), train_loss = 3.23197314, grad/param norm = 1.4592e+00, time/batch = 0.2340s	
1551/2700 (epoch 28.722), train_loss = 3.22987276, grad/param norm = 1.3933e+00, time/batch = 0.2163s	
1552/2700 (epoch 28.741), train_loss = 3.35044881, grad/param norm = 1.3031e+00, time/batch = 0.2121s	
1553/2700 (epoch 28.759), train_loss = 3.31076505, grad/param norm = 1.5277e+00, time/batch = 0.2154s	
1554/2700 (epoch 28.778), train_loss = 3.30681975, grad/param norm = 1.7832e+00, time/batch = 0.2155s	
1555/2700 (epoch 28.796), train_loss = 3.31320178, grad/param norm = 1.7443e+00, time/batch = 0.2267s	
1556/2700 (epoch 28.815), train_loss = 3.24288557, grad/param norm = 1.5876e+00, time/batch = 0.2327s	
1557/2700 (epoch 28.833), train_loss = 3.28856987, grad/param norm = 1.5984e+00, time/batch = 0.2300s	
1558/2700 (epoch 28.852), train_loss = 3.27306324, grad/param norm = 1.6090e+00, time/batch = 0.2236s	
1559/2700 (epoch 28.870), train_loss = 3.26514625, grad/param norm = 1.3479e+00, time/batch = 0.2316s	
1560/2700 (epoch 28.889), train_loss = 3.27790734, grad/param norm = 1.1745e+00, time/batch = 0.2312s	
1561/2700 (epoch 28.907), train_loss = 3.32647035, grad/param norm = 1.2353e+00, time/batch = 0.2027s	
1562/2700 (epoch 28.926), train_loss = 3.29280224, grad/param norm = 1.4353e+00, time/batch = 0.2149s	
1563/2700 (epoch 28.944), train_loss = 3.31005386, grad/param norm = 1.2632e+00, time/batch = 0.2283s	
1564/2700 (epoch 28.963), train_loss = 3.37139106, grad/param norm = 1.1236e+00, time/batch = 0.2063s	
1565/2700 (epoch 28.981), train_loss = 3.42917225, grad/param norm = 1.1257e+00, time/batch = 0.2273s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
1566/2700 (epoch 29.000), train_loss = 3.33816819, grad/param norm = 1.1268e+00, time/batch = 0.2295s	
1567/2700 (epoch 29.019), train_loss = 3.26740255, grad/param norm = 1.1955e+00, time/batch = 0.2252s	
1568/2700 (epoch 29.037), train_loss = 3.29129230, grad/param norm = 1.1911e+00, time/batch = 0.2355s	
1569/2700 (epoch 29.056), train_loss = 3.28059524, grad/param norm = 8.7992e-01, time/batch = 0.2353s	
1570/2700 (epoch 29.074), train_loss = 3.30588983, grad/param norm = 7.8124e-01, time/batch = 0.2317s	
1571/2700 (epoch 29.093), train_loss = 3.32110199, grad/param norm = 9.2800e-01, time/batch = 0.2245s	
1572/2700 (epoch 29.111), train_loss = 3.29596465, grad/param norm = 1.0084e+00, time/batch = 0.2134s	
1573/2700 (epoch 29.130), train_loss = 3.31613404, grad/param norm = 9.7120e-01, time/batch = 0.2028s	
1574/2700 (epoch 29.148), train_loss = 3.27200761, grad/param norm = 1.2081e+00, time/batch = 0.2152s	
1575/2700 (epoch 29.167), train_loss = 3.30359962, grad/param norm = 1.3585e+00, time/batch = 0.2347s	
1576/2700 (epoch 29.185), train_loss = 3.27856038, grad/param norm = 1.2204e+00, time/batch = 0.2316s	
1577/2700 (epoch 29.204), train_loss = 3.20885984, grad/param norm = 1.2383e+00, time/batch = 0.2237s	
1578/2700 (epoch 29.222), train_loss = 3.18387365, grad/param norm = 1.5607e+00, time/batch = 0.2306s	
1579/2700 (epoch 29.241), train_loss = 3.20885097, grad/param norm = 1.5403e+00, time/batch = 0.2230s	
1580/2700 (epoch 29.259), train_loss = 3.24513385, grad/param norm = 1.5260e+00, time/batch = 0.2322s	
1581/2700 (epoch 29.278), train_loss = 3.32965508, grad/param norm = 1.9891e+00, time/batch = 0.2249s	
1582/2700 (epoch 29.296), train_loss = 3.34656758, grad/param norm = 1.9176e+00, time/batch = 0.2054s	
1583/2700 (epoch 29.315), train_loss = 3.30835062, grad/param norm = 1.3535e+00, time/batch = 0.2295s	
1584/2700 (epoch 29.333), train_loss = 3.36216180, grad/param norm = 9.8963e-01, time/batch = 0.2255s	
1585/2700 (epoch 29.352), train_loss = 3.36903924, grad/param norm = 1.0465e+00, time/batch = 0.2316s	
1586/2700 (epoch 29.370), train_loss = 3.32542025, grad/param norm = 1.1890e+00, time/batch = 0.2084s	
1587/2700 (epoch 29.389), train_loss = 3.28049199, grad/param norm = 1.1499e+00, time/batch = 0.2232s	
1588/2700 (epoch 29.407), train_loss = 3.30721310, grad/param norm = 1.1079e+00, time/batch = 0.2309s	
1589/2700 (epoch 29.426), train_loss = 3.30589375, grad/param norm = 1.0788e+00, time/batch = 0.2161s	
1590/2700 (epoch 29.444), train_loss = 3.22981418, grad/param norm = 1.1375e+00, time/batch = 0.2327s	
1591/2700 (epoch 29.463), train_loss = 3.28171305, grad/param norm = 1.3890e+00, time/batch = 0.2202s	
1592/2700 (epoch 29.481), train_loss = 3.37313650, grad/param norm = 1.5160e+00, time/batch = 0.2264s	
1593/2700 (epoch 29.500), train_loss = 3.41313828, grad/param norm = 1.6650e+00, time/batch = 0.2227s	
1594/2700 (epoch 29.519), train_loss = 3.37069554, grad/param norm = 1.7013e+00, time/batch = 0.2159s	
1595/2700 (epoch 29.537), train_loss = 3.37390419, grad/param norm = 1.5108e+00, time/batch = 0.2313s	
1596/2700 (epoch 29.556), train_loss = 3.30873476, grad/param norm = 1.2160e+00, time/batch = 0.2059s	
1597/2700 (epoch 29.574), train_loss = 3.24418048, grad/param norm = 9.4122e-01, time/batch = 0.2144s	
1598/2700 (epoch 29.593), train_loss = 3.25475181, grad/param norm = 1.1479e+00, time/batch = 0.1900s	
1599/2700 (epoch 29.611), train_loss = 3.19820938, grad/param norm = 1.0658e+00, time/batch = 0.2322s	
1600/2700 (epoch 29.630), train_loss = 3.23863060, grad/param norm = 1.1926e+00, time/batch = 0.2235s	
1601/2700 (epoch 29.648), train_loss = 3.32092210, grad/param norm = 1.2957e+00, time/batch = 0.2314s	
1602/2700 (epoch 29.667), train_loss = 3.26021066, grad/param norm = 1.3513e+00, time/batch = 0.2311s	
1603/2700 (epoch 29.685), train_loss = 3.24931533, grad/param norm = 1.2648e+00, time/batch = 0.2330s	
1604/2700 (epoch 29.704), train_loss = 3.22930157, grad/param norm = 1.4263e+00, time/batch = 0.2358s	
1605/2700 (epoch 29.722), train_loss = 3.22561738, grad/param norm = 1.3523e+00, time/batch = 0.2250s	
1606/2700 (epoch 29.741), train_loss = 3.34771975, grad/param norm = 1.2585e+00, time/batch = 0.2292s	
1607/2700 (epoch 29.759), train_loss = 3.30671094, grad/param norm = 1.4812e+00, time/batch = 0.2240s	
1608/2700 (epoch 29.778), train_loss = 3.30421331, grad/param norm = 1.7538e+00, time/batch = 0.2363s	
1609/2700 (epoch 29.796), train_loss = 3.30987678, grad/param norm = 1.7158e+00, time/batch = 0.2325s	
1610/2700 (epoch 29.815), train_loss = 3.24000011, grad/param norm = 1.5496e+00, time/batch = 0.2369s	
1611/2700 (epoch 29.833), train_loss = 3.28427475, grad/param norm = 1.5573e+00, time/batch = 0.2209s	
1612/2700 (epoch 29.852), train_loss = 3.27029738, grad/param norm = 1.5794e+00, time/batch = 0.2146s	
1613/2700 (epoch 29.870), train_loss = 3.26259914, grad/param norm = 1.3180e+00, time/batch = 0.2144s	
1614/2700 (epoch 29.889), train_loss = 3.27630897, grad/param norm = 1.1424e+00, time/batch = 0.2315s	
1615/2700 (epoch 29.907), train_loss = 3.32492520, grad/param norm = 1.2059e+00, time/batch = 0.2031s	
1616/2700 (epoch 29.926), train_loss = 3.29050654, grad/param norm = 1.4029e+00, time/batch = 0.2106s	
1617/2700 (epoch 29.944), train_loss = 3.30701204, grad/param norm = 1.2294e+00, time/batch = 0.2135s	
1618/2700 (epoch 29.963), train_loss = 3.36896924, grad/param norm = 1.0894e+00, time/batch = 0.2349s	
1619/2700 (epoch 29.981), train_loss = 3.42669936, grad/param norm = 1.0922e+00, time/batch = 0.2173s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
1620/2700 (epoch 30.000), train_loss = 3.33578684, grad/param norm = 1.0954e+00, time/batch = 0.2309s	
1621/2700 (epoch 30.019), train_loss = 3.26576543, grad/param norm = 1.1678e+00, time/batch = 0.2350s	
1622/2700 (epoch 30.037), train_loss = 3.28919776, grad/param norm = 1.1618e+00, time/batch = 0.2221s	
1623/2700 (epoch 30.056), train_loss = 3.27904587, grad/param norm = 8.5293e-01, time/batch = 0.2252s	
1624/2700 (epoch 30.074), train_loss = 3.30498349, grad/param norm = 7.6411e-01, time/batch = 0.2181s	
1625/2700 (epoch 30.093), train_loss = 3.31964713, grad/param norm = 9.1375e-01, time/batch = 0.2282s	
1626/2700 (epoch 30.111), train_loss = 3.29418276, grad/param norm = 9.8370e-01, time/batch = 0.2252s	
1627/2700 (epoch 30.130), train_loss = 3.31401696, grad/param norm = 9.3867e-01, time/batch = 0.2316s	
1628/2700 (epoch 30.148), train_loss = 3.26991834, grad/param norm = 1.1665e+00, time/batch = 0.2180s	
1629/2700 (epoch 30.167), train_loss = 3.30016263, grad/param norm = 1.3149e+00, time/batch = 0.2304s	
1630/2700 (epoch 30.185), train_loss = 3.27527199, grad/param norm = 1.1483e+00, time/batch = 0.2305s	
1631/2700 (epoch 30.204), train_loss = 3.20458468, grad/param norm = 1.1349e+00, time/batch = 0.2267s	
1632/2700 (epoch 30.222), train_loss = 3.17887646, grad/param norm = 1.4283e+00, time/batch = 0.2196s	
1633/2700 (epoch 30.241), train_loss = 3.20362583, grad/param norm = 1.3687e+00, time/batch = 0.2141s	
1634/2700 (epoch 30.259), train_loss = 3.23935335, grad/param norm = 1.3891e+00, time/batch = 0.1863s	
1635/2700 (epoch 30.278), train_loss = 3.32771668, grad/param norm = 1.9971e+00, time/batch = 0.2048s	
1636/2700 (epoch 30.296), train_loss = 3.34532718, grad/param norm = 1.9143e+00, time/batch = 0.2108s	
1637/2700 (epoch 30.315), train_loss = 3.30482406, grad/param norm = 1.3550e+00, time/batch = 0.1998s	
1638/2700 (epoch 30.333), train_loss = 3.36148608, grad/param norm = 1.0246e+00, time/batch = 0.2313s	
1639/2700 (epoch 30.352), train_loss = 3.36925071, grad/param norm = 1.0838e+00, time/batch = 0.2255s	
1640/2700 (epoch 30.370), train_loss = 3.32538569, grad/param norm = 1.2336e+00, time/batch = 0.2267s	
1641/2700 (epoch 30.389), train_loss = 3.28122335, grad/param norm = 1.1882e+00, time/batch = 0.2375s	
1642/2700 (epoch 30.407), train_loss = 3.30652086, grad/param norm = 1.1288e+00, time/batch = 0.2320s	
1643/2700 (epoch 30.426), train_loss = 3.30482459, grad/param norm = 1.0801e+00, time/batch = 0.2134s	
1644/2700 (epoch 30.444), train_loss = 3.22896536, grad/param norm = 1.1346e+00, time/batch = 0.2018s	
1645/2700 (epoch 30.463), train_loss = 3.28010265, grad/param norm = 1.3628e+00, time/batch = 0.2249s	
1646/2700 (epoch 30.481), train_loss = 3.36967214, grad/param norm = 1.4710e+00, time/batch = 0.2089s	
1647/2700 (epoch 30.500), train_loss = 3.40978825, grad/param norm = 1.6020e+00, time/batch = 0.2316s	
1648/2700 (epoch 30.519), train_loss = 3.36646281, grad/param norm = 1.6294e+00, time/batch = 0.2277s	
1649/2700 (epoch 30.537), train_loss = 3.37007871, grad/param norm = 1.4604e+00, time/batch = 0.2232s	
1650/2700 (epoch 30.556), train_loss = 3.30537103, grad/param norm = 1.1742e+00, time/batch = 0.2316s	
1651/2700 (epoch 30.574), train_loss = 3.24271868, grad/param norm = 9.0704e-01, time/batch = 0.2169s	
1652/2700 (epoch 30.593), train_loss = 3.25299444, grad/param norm = 1.1097e+00, time/batch = 0.2217s	
1653/2700 (epoch 30.611), train_loss = 3.19601268, grad/param norm = 1.0225e+00, time/batch = 0.1947s	
1654/2700 (epoch 30.630), train_loss = 3.23650868, grad/param norm = 1.1416e+00, time/batch = 0.2231s	
1655/2700 (epoch 30.648), train_loss = 3.31780383, grad/param norm = 1.2486e+00, time/batch = 0.2087s	
1656/2700 (epoch 30.667), train_loss = 3.25744053, grad/param norm = 1.3092e+00, time/batch = 0.2200s	
1657/2700 (epoch 30.685), train_loss = 3.24686145, grad/param norm = 1.2293e+00, time/batch = 0.2228s	
1658/2700 (epoch 30.704), train_loss = 3.22646988, grad/param norm = 1.3877e+00, time/batch = 0.2214s	
1659/2700 (epoch 30.722), train_loss = 3.22132096, grad/param norm = 1.3066e+00, time/batch = 0.2225s	
1660/2700 (epoch 30.741), train_loss = 3.34496967, grad/param norm = 1.2134e+00, time/batch = 0.2283s	
1661/2700 (epoch 30.759), train_loss = 3.30288961, grad/param norm = 1.4377e+00, time/batch = 0.2233s	
1662/2700 (epoch 30.778), train_loss = 3.30198446, grad/param norm = 1.7302e+00, time/batch = 0.2161s	
1663/2700 (epoch 30.796), train_loss = 3.30714884, grad/param norm = 1.6959e+00, time/batch = 0.2327s	
1664/2700 (epoch 30.815), train_loss = 3.23761584, grad/param norm = 1.5198e+00, time/batch = 0.2349s	
1665/2700 (epoch 30.833), train_loss = 3.28056452, grad/param norm = 1.5225e+00, time/batch = 0.2337s	
1666/2700 (epoch 30.852), train_loss = 3.26763662, grad/param norm = 1.5507e+00, time/batch = 0.2360s	
1667/2700 (epoch 30.870), train_loss = 3.26005355, grad/param norm = 1.2892e+00, time/batch = 0.2362s	
1668/2700 (epoch 30.889), train_loss = 3.27479002, grad/param norm = 1.1114e+00, time/batch = 0.2359s	
1669/2700 (epoch 30.907), train_loss = 3.32346146, grad/param norm = 1.1768e+00, time/batch = 0.2381s	
1670/2700 (epoch 30.926), train_loss = 3.28834529, grad/param norm = 1.3705e+00, time/batch = 0.2367s	
1671/2700 (epoch 30.944), train_loss = 3.30414806, grad/param norm = 1.1962e+00, time/batch = 0.2164s	
1672/2700 (epoch 30.963), train_loss = 3.36676134, grad/param norm = 1.0566e+00, time/batch = 0.1957s	
1673/2700 (epoch 30.981), train_loss = 3.42448991, grad/param norm = 1.0607e+00, time/batch = 0.2307s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
1674/2700 (epoch 31.000), train_loss = 3.33355197, grad/param norm = 1.0649e+00, time/batch = 0.2301s	
1675/2700 (epoch 31.019), train_loss = 3.26423198, grad/param norm = 1.1404e+00, time/batch = 0.2344s	
1676/2700 (epoch 31.037), train_loss = 3.28721603, grad/param norm = 1.1323e+00, time/batch = 0.2356s	
1677/2700 (epoch 31.056), train_loss = 3.27757844, grad/param norm = 8.2656e-01, time/batch = 0.2349s	
1678/2700 (epoch 31.074), train_loss = 3.30414757, grad/param norm = 7.4937e-01, time/batch = 0.2340s	
1679/2700 (epoch 31.093), train_loss = 3.31829168, grad/param norm = 9.0179e-01, time/batch = 0.2356s	
1680/2700 (epoch 31.111), train_loss = 3.29253038, grad/param norm = 9.6144e-01, time/batch = 0.2301s	
1681/2700 (epoch 31.130), train_loss = 3.31205448, grad/param norm = 9.0971e-01, time/batch = 0.2045s	
1682/2700 (epoch 31.148), train_loss = 3.26804570, grad/param norm = 1.1281e+00, time/batch = 0.1915s	
1683/2700 (epoch 31.167), train_loss = 3.29692727, grad/param norm = 1.2760e+00, time/batch = 0.2015s	
1684/2700 (epoch 31.185), train_loss = 3.27229725, grad/param norm = 1.0808e+00, time/batch = 0.2188s	
1685/2700 (epoch 31.204), train_loss = 3.20068750, grad/param norm = 1.0405e+00, time/batch = 0.2271s	
1686/2700 (epoch 31.222), train_loss = 3.17448387, grad/param norm = 1.2842e+00, time/batch = 0.2253s	
1687/2700 (epoch 31.241), train_loss = 3.19729834, grad/param norm = 1.1231e+00, time/batch = 0.2188s	
1688/2700 (epoch 31.259), train_loss = 3.22996555, grad/param norm = 1.0824e+00, time/batch = 0.2217s	
1689/2700 (epoch 31.278), train_loss = 3.31892533, grad/param norm = 1.7461e+00, time/batch = 0.2301s	
1690/2700 (epoch 31.296), train_loss = 3.33927099, grad/param norm = 1.8334e+00, time/batch = 0.2311s	
1691/2700 (epoch 31.315), train_loss = 3.30411304, grad/param norm = 1.5054e+00, time/batch = 0.2193s	
1692/2700 (epoch 31.333), train_loss = 3.36652965, grad/param norm = 1.2560e+00, time/batch = 0.2017s	
1693/2700 (epoch 31.352), train_loss = 3.37346736, grad/param norm = 1.2682e+00, time/batch = 0.2348s	
1694/2700 (epoch 31.370), train_loss = 3.32937165, grad/param norm = 1.4228e+00, time/batch = 0.2361s	
1695/2700 (epoch 31.389), train_loss = 3.28541432, grad/param norm = 1.3451e+00, time/batch = 0.2273s	
1696/2700 (epoch 31.407), train_loss = 3.30793333, grad/param norm = 1.2329e+00, time/batch = 0.2325s	
1697/2700 (epoch 31.426), train_loss = 3.30435668, grad/param norm = 1.1153e+00, time/batch = 0.2243s	
1698/2700 (epoch 31.444), train_loss = 3.22844837, grad/param norm = 1.1495e+00, time/batch = 0.2225s	
1699/2700 (epoch 31.463), train_loss = 3.27833304, grad/param norm = 1.3184e+00, time/batch = 0.2215s	
1700/2700 (epoch 31.481), train_loss = 3.36554647, grad/param norm = 1.3839e+00, time/batch = 0.2117s	
1701/2700 (epoch 31.500), train_loss = 3.40483856, grad/param norm = 1.4798e+00, time/batch = 0.1937s	
1702/2700 (epoch 31.519), train_loss = 3.36025660, grad/param norm = 1.5003e+00, time/batch = 0.2184s	
1703/2700 (epoch 31.537), train_loss = 3.36493576, grad/param norm = 1.3789e+00, time/batch = 0.2228s	
1704/2700 (epoch 31.556), train_loss = 3.30184185, grad/param norm = 1.1159e+00, time/batch = 0.2244s	
1705/2700 (epoch 31.574), train_loss = 3.24138283, grad/param norm = 8.6550e-01, time/batch = 0.2336s	
1706/2700 (epoch 31.593), train_loss = 3.25130962, grad/param norm = 1.0673e+00, time/batch = 0.2239s	
1707/2700 (epoch 31.611), train_loss = 3.19379795, grad/param norm = 9.7391e-01, time/batch = 0.2259s	
1708/2700 (epoch 31.630), train_loss = 3.23421575, grad/param norm = 1.0821e+00, time/batch = 0.2301s	
1709/2700 (epoch 31.648), train_loss = 3.31460238, grad/param norm = 1.1954e+00, time/batch = 0.2296s	
1710/2700 (epoch 31.667), train_loss = 3.25481208, grad/param norm = 1.2651e+00, time/batch = 0.2182s	
1711/2700 (epoch 31.685), train_loss = 3.24451552, grad/param norm = 1.1945e+00, time/batch = 0.2382s	
1712/2700 (epoch 31.704), train_loss = 3.22373206, grad/param norm = 1.3504e+00, time/batch = 0.2245s	
1713/2700 (epoch 31.722), train_loss = 3.21736629, grad/param norm = 1.2655e+00, time/batch = 0.2246s	
1714/2700 (epoch 31.741), train_loss = 3.34238721, grad/param norm = 1.1771e+00, time/batch = 0.2312s	
1715/2700 (epoch 31.759), train_loss = 3.29966207, grad/param norm = 1.4068e+00, time/batch = 0.2325s	
1716/2700 (epoch 31.778), train_loss = 3.30027743, grad/param norm = 1.7169e+00, time/batch = 0.2259s	
1717/2700 (epoch 31.796), train_loss = 3.30503839, grad/param norm = 1.6868e+00, time/batch = 0.2213s	
1718/2700 (epoch 31.815), train_loss = 3.23569426, grad/param norm = 1.4972e+00, time/batch = 0.2144s	
1719/2700 (epoch 31.833), train_loss = 3.27733152, grad/param norm = 1.4894e+00, time/batch = 0.2080s	
1720/2700 (epoch 31.852), train_loss = 3.26498693, grad/param norm = 1.5184e+00, time/batch = 0.1903s	
1721/2700 (epoch 31.870), train_loss = 3.25737514, grad/param norm = 1.2554e+00, time/batch = 0.2260s	
1722/2700 (epoch 31.889), train_loss = 3.27313650, grad/param norm = 1.0747e+00, time/batch = 0.2191s	
1723/2700 (epoch 31.907), train_loss = 3.32194450, grad/param norm = 1.1428e+00, time/batch = 0.2156s	
1724/2700 (epoch 31.926), train_loss = 3.28621196, grad/param norm = 1.3353e+00, time/batch = 0.2126s	
1725/2700 (epoch 31.944), train_loss = 3.30144198, grad/param norm = 1.1628e+00, time/batch = 0.2338s	
1726/2700 (epoch 31.963), train_loss = 3.36475140, grad/param norm = 1.0248e+00, time/batch = 0.2260s	
1727/2700 (epoch 31.981), train_loss = 3.42252058, grad/param norm = 1.0313e+00, time/batch = 0.2041s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
1728/2700 (epoch 32.000), train_loss = 3.33146385, grad/param norm = 1.0353e+00, time/batch = 0.2300s	
1729/2700 (epoch 32.019), train_loss = 3.26280484, grad/param norm = 1.1132e+00, time/batch = 0.2370s	
1730/2700 (epoch 32.037), train_loss = 3.28535079, grad/param norm = 1.1031e+00, time/batch = 0.1984s	
1731/2700 (epoch 32.056), train_loss = 3.27619201, grad/param norm = 8.0123e-01, time/batch = 0.2052s	
1732/2700 (epoch 32.074), train_loss = 3.30337709, grad/param norm = 7.3719e-01, time/batch = 0.1970s	
1733/2700 (epoch 32.093), train_loss = 3.31703531, grad/param norm = 8.9229e-01, time/batch = 0.2161s	
1734/2700 (epoch 32.111), train_loss = 3.29100934, grad/param norm = 9.4224e-01, time/batch = 0.2136s	
1735/2700 (epoch 32.130), train_loss = 3.31026206, grad/param norm = 8.8546e-01, time/batch = 0.2311s	
1736/2700 (epoch 32.148), train_loss = 3.26640627, grad/param norm = 1.0946e+00, time/batch = 0.2242s	
1737/2700 (epoch 32.167), train_loss = 3.29397444, grad/param norm = 1.2441e+00, time/batch = 0.2262s	
1738/2700 (epoch 32.185), train_loss = 3.26973158, grad/param norm = 1.0250e+00, time/batch = 0.2315s	
1739/2700 (epoch 32.204), train_loss = 3.19750660, grad/param norm = 9.7504e-01, time/batch = 0.2372s	
1740/2700 (epoch 32.222), train_loss = 3.17168260, grad/param norm = 1.1684e+00, time/batch = 0.2346s	
1741/2700 (epoch 32.241), train_loss = 3.19241991, grad/param norm = 9.3889e-01, time/batch = 0.2118s	
1742/2700 (epoch 32.259), train_loss = 3.22346787, grad/param norm = 7.0954e-01, time/batch = 0.2217s	
1743/2700 (epoch 32.278), train_loss = 3.29780068, grad/param norm = 8.7449e-01, time/batch = 0.2227s	
1744/2700 (epoch 32.296), train_loss = 3.30522621, grad/param norm = 9.8297e-01, time/batch = 0.2305s	
1745/2700 (epoch 32.315), train_loss = 3.28362805, grad/param norm = 9.7810e-01, time/batch = 0.2339s	
1746/2700 (epoch 32.333), train_loss = 3.36093353, grad/param norm = 1.0437e+00, time/batch = 0.2326s	
1747/2700 (epoch 32.352), train_loss = 3.38176962, grad/param norm = 1.4265e+00, time/batch = 0.2356s	
1748/2700 (epoch 32.370), train_loss = 3.34868645, grad/param norm = 1.8475e+00, time/batch = 0.2349s	
1749/2700 (epoch 32.389), train_loss = 3.31161821, grad/param norm = 2.1837e+00, time/batch = 0.2344s	
1750/2700 (epoch 32.407), train_loss = 3.34172358, grad/param norm = 1.9334e+00, time/batch = 0.2363s	
1751/2700 (epoch 32.426), train_loss = 3.30883017, grad/param norm = 1.2696e+00, time/batch = 0.2132s	
1752/2700 (epoch 32.444), train_loss = 3.23104014, grad/param norm = 1.2206e+00, time/batch = 0.2227s	
1753/2700 (epoch 32.463), train_loss = 3.27435715, grad/param norm = 1.2364e+00, time/batch = 0.2153s	
1754/2700 (epoch 32.481), train_loss = 3.35678182, grad/param norm = 1.2439e+00, time/batch = 0.2321s	
1755/2700 (epoch 32.500), train_loss = 3.40011932, grad/param norm = 1.3312e+00, time/batch = 0.2298s	
1756/2700 (epoch 32.519), train_loss = 3.35325104, grad/param norm = 1.3309e+00, time/batch = 0.2242s	
1757/2700 (epoch 32.537), train_loss = 3.35833578, grad/param norm = 1.2574e+00, time/batch = 0.2202s	
1758/2700 (epoch 32.556), train_loss = 3.29747763, grad/param norm = 1.0248e+00, time/batch = 0.2208s	
1759/2700 (epoch 32.574), train_loss = 3.24043573, grad/param norm = 8.1201e-01, time/batch = 0.2209s	
1760/2700 (epoch 32.593), train_loss = 3.24981653, grad/param norm = 1.0156e+00, time/batch = 0.2296s	
1761/2700 (epoch 32.611), train_loss = 3.19112474, grad/param norm = 9.0553e-01, time/batch = 0.2155s	
1762/2700 (epoch 32.630), train_loss = 3.23089024, grad/param norm = 9.8041e-01, time/batch = 0.2223s	
1763/2700 (epoch 32.648), train_loss = 3.30982077, grad/param norm = 1.0996e+00, time/batch = 0.2298s	
1764/2700 (epoch 32.667), train_loss = 3.25083595, grad/param norm = 1.1695e+00, time/batch = 0.2119s	
1765/2700 (epoch 32.685), train_loss = 3.24003439, grad/param norm = 1.1010e+00, time/batch = 0.2287s	
1766/2700 (epoch 32.704), train_loss = 3.21866871, grad/param norm = 1.2563e+00, time/batch = 0.2297s	
1767/2700 (epoch 32.722), train_loss = 3.21113575, grad/param norm = 1.1555e+00, time/batch = 0.2370s	
1768/2700 (epoch 32.741), train_loss = 3.33767593, grad/param norm = 1.0760e+00, time/batch = 0.2382s	
1769/2700 (epoch 32.759), train_loss = 3.29403740, grad/param norm = 1.3235e+00, time/batch = 0.2386s	
1770/2700 (epoch 32.778), train_loss = 3.29934336, grad/param norm = 1.7120e+00, time/batch = 0.2285s	
1771/2700 (epoch 32.796), train_loss = 3.30566062, grad/param norm = 1.7127e+00, time/batch = 0.2278s	
1772/2700 (epoch 32.815), train_loss = 3.23555547, grad/param norm = 1.5199e+00, time/batch = 0.2324s	
1773/2700 (epoch 32.833), train_loss = 3.27596514, grad/param norm = 1.5100e+00, time/batch = 0.2284s	
1774/2700 (epoch 32.852), train_loss = 3.26432091, grad/param norm = 1.5324e+00, time/batch = 0.2299s	
1775/2700 (epoch 32.870), train_loss = 3.25575230, grad/param norm = 1.2530e+00, time/batch = 0.2358s	
1776/2700 (epoch 32.889), train_loss = 3.27202687, grad/param norm = 1.0626e+00, time/batch = 0.2249s	
1777/2700 (epoch 32.907), train_loss = 3.32075616, grad/param norm = 1.1207e+00, time/batch = 0.2233s	
1778/2700 (epoch 32.926), train_loss = 3.28430136, grad/param norm = 1.3044e+00, time/batch = 0.2210s	
1779/2700 (epoch 32.944), train_loss = 3.29894060, grad/param norm = 1.1295e+00, time/batch = 0.2176s	
1780/2700 (epoch 32.963), train_loss = 3.36293943, grad/param norm = 9.9312e-01, time/batch = 0.1994s	
1781/2700 (epoch 32.981), train_loss = 3.42091671, grad/param norm = 1.0050e+00, time/batch = 0.2169s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
1782/2700 (epoch 33.000), train_loss = 3.32957524, grad/param norm = 1.0062e+00, time/batch = 0.2010s	
1783/2700 (epoch 33.019), train_loss = 3.26135684, grad/param norm = 1.0829e+00, time/batch = 0.1874s	
1784/2700 (epoch 33.037), train_loss = 3.28344396, grad/param norm = 1.0665e+00, time/batch = 0.2285s	
1785/2700 (epoch 33.056), train_loss = 3.27475627, grad/param norm = 7.7116e-01, time/batch = 0.2296s	
1786/2700 (epoch 33.074), train_loss = 3.30271583, grad/param norm = 7.3036e-01, time/batch = 0.2290s	
1787/2700 (epoch 33.093), train_loss = 3.31591133, grad/param norm = 8.8870e-01, time/batch = 0.2309s	
1788/2700 (epoch 33.111), train_loss = 3.28962377, grad/param norm = 9.2555e-01, time/batch = 0.2354s	
1789/2700 (epoch 33.130), train_loss = 3.30849575, grad/param norm = 8.6450e-01, time/batch = 0.2323s	
1790/2700 (epoch 33.148), train_loss = 3.26496873, grad/param norm = 1.0627e+00, time/batch = 0.2245s	
1791/2700 (epoch 33.167), train_loss = 3.29120110, grad/param norm = 1.2244e+00, time/batch = 0.2352s	
1792/2700 (epoch 33.185), train_loss = 3.26787768, grad/param norm = 9.9099e-01, time/batch = 0.1951s	
1793/2700 (epoch 33.204), train_loss = 3.19557077, grad/param norm = 9.8073e-01, time/batch = 0.2082s	
1794/2700 (epoch 33.222), train_loss = 3.17293395, grad/param norm = 1.1796e+00, time/batch = 0.1977s	
1795/2700 (epoch 33.241), train_loss = 3.19667711, grad/param norm = 1.2191e+00, time/batch = 0.2262s	
1796/2700 (epoch 33.259), train_loss = 3.24428085, grad/param norm = 1.7111e+00, time/batch = 0.2291s	
1797/2700 (epoch 33.278), train_loss = 3.32891682, grad/param norm = 1.8105e+00, time/batch = 0.2284s	
1798/2700 (epoch 33.296), train_loss = 3.32179709, grad/param norm = 1.7771e+00, time/batch = 0.2241s	
1799/2700 (epoch 33.315), train_loss = 3.29542749, grad/param norm = 1.5637e+00, time/batch = 0.2074s	
1800/2700 (epoch 33.333), train_loss = 3.36500619, grad/param norm = 1.2336e+00, time/batch = 0.2301s	
1801/2700 (epoch 33.352), train_loss = 3.37678150, grad/param norm = 1.2390e+00, time/batch = 0.2244s	
1802/2700 (epoch 33.370), train_loss = 3.32510962, grad/param norm = 1.0820e+00, time/batch = 0.2212s	
1803/2700 (epoch 33.389), train_loss = 3.27301797, grad/param norm = 8.7913e-01, time/batch = 0.2101s	
1804/2700 (epoch 33.407), train_loss = 3.29423637, grad/param norm = 7.6713e-01, time/batch = 0.2206s	
1805/2700 (epoch 33.426), train_loss = 3.29722017, grad/param norm = 7.8488e-01, time/batch = 0.2208s	
1806/2700 (epoch 33.444), train_loss = 3.21772422, grad/param norm = 7.4553e-01, time/batch = 0.2328s	
1807/2700 (epoch 33.463), train_loss = 3.26509024, grad/param norm = 7.9692e-01, time/batch = 0.2346s	
1808/2700 (epoch 33.481), train_loss = 3.33950826, grad/param norm = 6.5206e-01, time/batch = 0.2351s	
1809/2700 (epoch 33.500), train_loss = 3.38183459, grad/param norm = 7.2020e-01, time/batch = 0.2307s	
1810/2700 (epoch 33.519), train_loss = 3.33859880, grad/param norm = 8.7751e-01, time/batch = 0.2160s	
1811/2700 (epoch 33.537), train_loss = 3.35134019, grad/param norm = 1.0739e+00, time/batch = 0.2361s	
1812/2700 (epoch 33.556), train_loss = 3.29602471, grad/param norm = 1.0552e+00, time/batch = 0.2331s	
1813/2700 (epoch 33.574), train_loss = 3.24284650, grad/param norm = 1.0022e+00, time/batch = 0.2324s	
1814/2700 (epoch 33.593), train_loss = 3.25568419, grad/param norm = 1.2827e+00, time/batch = 0.2286s	
1815/2700 (epoch 33.611), train_loss = 3.20240447, grad/param norm = 1.3467e+00, time/batch = 0.2242s	
1816/2700 (epoch 33.630), train_loss = 3.24746404, grad/param norm = 1.5576e+00, time/batch = 0.2313s	
1817/2700 (epoch 33.648), train_loss = 3.33078241, grad/param norm = 1.6827e+00, time/batch = 0.2348s	
1818/2700 (epoch 33.667), train_loss = 3.26982319, grad/param norm = 1.7655e+00, time/batch = 0.2261s	
1819/2700 (epoch 33.685), train_loss = 3.25497331, grad/param norm = 1.4584e+00, time/batch = 0.2306s	
1820/2700 (epoch 33.704), train_loss = 3.22534292, grad/param norm = 1.4230e+00, time/batch = 0.2348s	
1821/2700 (epoch 33.722), train_loss = 3.21124121, grad/param norm = 1.1851e+00, time/batch = 0.2153s	
1822/2700 (epoch 33.741), train_loss = 3.33416806, grad/param norm = 9.9026e-01, time/batch = 0.1806s	
1823/2700 (epoch 33.759), train_loss = 3.28649351, grad/param norm = 1.1542e+00, time/batch = 0.2158s	
1824/2700 (epoch 33.778), train_loss = 3.28641915, grad/param norm = 1.4139e+00, time/batch = 0.2142s	
1825/2700 (epoch 33.796), train_loss = 3.28840460, grad/param norm = 1.3811e+00, time/batch = 0.2282s	
1826/2700 (epoch 33.815), train_loss = 3.22598538, grad/param norm = 1.2268e+00, time/batch = 0.2268s	
1827/2700 (epoch 33.833), train_loss = 3.26467713, grad/param norm = 1.2165e+00, time/batch = 0.2241s	
1828/2700 (epoch 33.852), train_loss = 3.25192962, grad/param norm = 1.2506e+00, time/batch = 0.2306s	
1829/2700 (epoch 33.870), train_loss = 3.24966581, grad/param norm = 1.1460e+00, time/batch = 0.2334s	
1830/2700 (epoch 33.889), train_loss = 3.27138755, grad/param norm = 1.0428e+00, time/batch = 0.2357s	
1831/2700 (epoch 33.907), train_loss = 3.32126059, grad/param norm = 1.1622e+00, time/batch = 0.2290s	
1832/2700 (epoch 33.926), train_loss = 3.28500559, grad/param norm = 1.3484e+00, time/batch = 0.2363s	
1833/2700 (epoch 33.944), train_loss = 3.29830314, grad/param norm = 1.1670e+00, time/batch = 0.2289s	
1834/2700 (epoch 33.963), train_loss = 3.36317743, grad/param norm = 1.0415e+00, time/batch = 0.2211s	
1835/2700 (epoch 33.981), train_loss = 3.42145457, grad/param norm = 1.0339e+00, time/batch = 0.2200s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
1836/2700 (epoch 34.000), train_loss = 3.32860488, grad/param norm = 1.0395e+00, time/batch = 0.2189s	
1837/2700 (epoch 34.019), train_loss = 3.26224339, grad/param norm = 1.1280e+00, time/batch = 0.1993s	
1838/2700 (epoch 34.037), train_loss = 3.28339852, grad/param norm = 1.1204e+00, time/batch = 0.2334s	
1839/2700 (epoch 34.056), train_loss = 3.27466434, grad/param norm = 8.0499e-01, time/batch = 0.2345s	
1840/2700 (epoch 34.074), train_loss = 3.30164266, grad/param norm = 7.0942e-01, time/batch = 0.2285s	
1841/2700 (epoch 34.093), train_loss = 3.31460218, grad/param norm = 8.5927e-01, time/batch = 0.2198s	
1842/2700 (epoch 34.111), train_loss = 3.28808569, grad/param norm = 9.2293e-01, time/batch = 0.2194s	
1843/2700 (epoch 34.130), train_loss = 3.30795481, grad/param norm = 8.8206e-01, time/batch = 0.2210s	
1844/2700 (epoch 34.148), train_loss = 3.26440293, grad/param norm = 1.1162e+00, time/batch = 0.2216s	
1845/2700 (epoch 34.167), train_loss = 3.29203068, grad/param norm = 1.2526e+00, time/batch = 0.2234s	
1846/2700 (epoch 34.185), train_loss = 3.26782682, grad/param norm = 1.1028e+00, time/batch = 0.2296s	
1847/2700 (epoch 34.204), train_loss = 3.19797997, grad/param norm = 1.1311e+00, time/batch = 0.2235s	
1848/2700 (epoch 34.222), train_loss = 3.17541227, grad/param norm = 1.4448e+00, time/batch = 0.2214s	
1849/2700 (epoch 34.241), train_loss = 3.19739043, grad/param norm = 1.3692e+00, time/batch = 0.2282s	
1850/2700 (epoch 34.259), train_loss = 3.23445149, grad/param norm = 1.3352e+00, time/batch = 0.2104s	
1851/2700 (epoch 34.278), train_loss = 3.31833853, grad/param norm = 1.7106e+00, time/batch = 0.2362s	
1852/2700 (epoch 34.296), train_loss = 3.32499084, grad/param norm = 1.6305e+00, time/batch = 0.2293s	
1853/2700 (epoch 34.315), train_loss = 3.29107182, grad/param norm = 1.1586e+00, time/batch = 0.2277s	
1854/2700 (epoch 34.333), train_loss = 3.35323411, grad/param norm = 8.4502e-01, time/batch = 0.2256s	
1855/2700 (epoch 34.352), train_loss = 3.36277709, grad/param norm = 9.3998e-01, time/batch = 0.2199s	
1856/2700 (epoch 34.370), train_loss = 3.31646360, grad/param norm = 1.0700e+00, time/batch = 0.2023s	
1857/2700 (epoch 34.389), train_loss = 3.27442959, grad/param norm = 1.0130e+00, time/batch = 0.2351s	
1858/2700 (epoch 34.407), train_loss = 3.29762377, grad/param norm = 9.2498e-01, time/batch = 0.2235s	
1859/2700 (epoch 34.426), train_loss = 3.29663972, grad/param norm = 8.7854e-01, time/batch = 0.1967s	
1860/2700 (epoch 34.444), train_loss = 3.22014139, grad/param norm = 9.1244e-01, time/batch = 0.2211s	
1861/2700 (epoch 34.463), train_loss = 3.26927404, grad/param norm = 1.1268e+00, time/batch = 0.2334s	
1862/2700 (epoch 34.481), train_loss = 3.35524665, grad/param norm = 1.2641e+00, time/batch = 0.2283s	
1863/2700 (epoch 34.500), train_loss = 3.40100753, grad/param norm = 1.4791e+00, time/batch = 0.2252s	
1864/2700 (epoch 34.519), train_loss = 3.35812140, grad/param norm = 1.5217e+00, time/batch = 0.2304s	
1865/2700 (epoch 34.537), train_loss = 3.36127656, grad/param norm = 1.3813e+00, time/batch = 0.2255s	
1866/2700 (epoch 34.556), train_loss = 3.29633261, grad/param norm = 1.1096e+00, time/batch = 0.2321s	
1867/2700 (epoch 34.574), train_loss = 3.24002778, grad/param norm = 8.6398e-01, time/batch = 0.2352s	
1868/2700 (epoch 34.593), train_loss = 3.24908708, grad/param norm = 1.0493e+00, time/batch = 0.2302s	
1869/2700 (epoch 34.611), train_loss = 3.19065183, grad/param norm = 9.4377e-01, time/batch = 0.2355s	
1870/2700 (epoch 34.630), train_loss = 3.23123546, grad/param norm = 1.0380e+00, time/batch = 0.2370s	
1871/2700 (epoch 34.648), train_loss = 3.30995289, grad/param norm = 1.1382e+00, time/batch = 0.2210s	
1872/2700 (epoch 34.667), train_loss = 3.24805857, grad/param norm = 1.1800e+00, time/batch = 0.2161s	
1873/2700 (epoch 34.685), train_loss = 3.23785870, grad/param norm = 1.0933e+00, time/batch = 0.2330s	
1874/2700 (epoch 34.704), train_loss = 3.21558272, grad/param norm = 1.2372e+00, time/batch = 0.2257s	
1875/2700 (epoch 34.722), train_loss = 3.20671038, grad/param norm = 1.1179e+00, time/batch = 0.2113s	
1876/2700 (epoch 34.741), train_loss = 3.33342986, grad/param norm = 1.0097e+00, time/batch = 0.2323s	
1877/2700 (epoch 34.759), train_loss = 3.28843081, grad/param norm = 1.2339e+00, time/batch = 0.2313s	
1878/2700 (epoch 34.778), train_loss = 3.29120717, grad/param norm = 1.5686e+00, time/batch = 0.2339s	
1879/2700 (epoch 34.796), train_loss = 3.29458148, grad/param norm = 1.5598e+00, time/batch = 0.2343s	
1880/2700 (epoch 34.815), train_loss = 3.22857722, grad/param norm = 1.3819e+00, time/batch = 0.2338s	
1881/2700 (epoch 34.833), train_loss = 3.26770591, grad/param norm = 1.3756e+00, time/batch = 0.2189s	
1882/2700 (epoch 34.852), train_loss = 3.25644585, grad/param norm = 1.4059e+00, time/batch = 0.2185s	
1883/2700 (epoch 34.870), train_loss = 3.25032751, grad/param norm = 1.1900e+00, time/batch = 0.1947s	
1884/2700 (epoch 34.889), train_loss = 3.27005717, grad/param norm = 1.0249e+00, time/batch = 0.2173s	
1885/2700 (epoch 34.907), train_loss = 3.31921074, grad/param norm = 1.0988e+00, time/batch = 0.2168s	
1886/2700 (epoch 34.926), train_loss = 3.28164464, grad/param norm = 1.2695e+00, time/batch = 0.2308s	
1887/2700 (epoch 34.944), train_loss = 3.29473707, grad/param norm = 1.0895e+00, time/batch = 0.2114s	
1888/2700 (epoch 34.963), train_loss = 3.36017306, grad/param norm = 9.5959e-01, time/batch = 0.2284s	
1889/2700 (epoch 34.981), train_loss = 3.41837770, grad/param norm = 9.6999e-01, time/batch = 0.2317s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
1890/2700 (epoch 35.000), train_loss = 3.32622385, grad/param norm = 9.7085e-01, time/batch = 0.2360s	
1891/2700 (epoch 35.019), train_loss = 3.25962148, grad/param norm = 1.0525e+00, time/batch = 0.2352s	
1892/2700 (epoch 35.037), train_loss = 3.28060874, grad/param norm = 1.0320e+00, time/batch = 0.2148s	
1893/2700 (epoch 35.056), train_loss = 3.27260946, grad/param norm = 7.3714e-01, time/batch = 0.2278s	
1894/2700 (epoch 35.074), train_loss = 3.30121514, grad/param norm = 7.0591e-01, time/batch = 0.2120s	
1895/2700 (epoch 35.093), train_loss = 3.31356306, grad/param norm = 8.6313e-01, time/batch = 0.2193s	
1896/2700 (epoch 35.111), train_loss = 3.28671076, grad/param norm = 8.9003e-01, time/batch = 0.1928s	
1897/2700 (epoch 35.130), train_loss = 3.30546963, grad/param norm = 8.2509e-01, time/batch = 0.2330s	
1898/2700 (epoch 35.148), train_loss = 3.26223273, grad/param norm = 1.0196e+00, time/batch = 0.2351s	
1899/2700 (epoch 35.167), train_loss = 3.28702178, grad/param norm = 1.1759e+00, time/batch = 0.2347s	
1900/2700 (epoch 35.185), train_loss = 3.26385116, grad/param norm = 9.3373e-01, time/batch = 0.2207s	
1901/2700 (epoch 35.204), train_loss = 3.19197974, grad/param norm = 9.2160e-01, time/batch = 0.2225s	
1902/2700 (epoch 35.222), train_loss = 3.16951148, grad/param norm = 1.1225e+00, time/batch = 0.2304s	
1903/2700 (epoch 35.241), train_loss = 3.19274301, grad/param norm = 1.1396e+00, time/batch = 0.2185s	
1904/2700 (epoch 35.259), train_loss = 3.23797252, grad/param norm = 1.5736e+00, time/batch = 0.1887s	
1905/2700 (epoch 35.278), train_loss = 3.32157422, grad/param norm = 1.7026e+00, time/batch = 0.2225s	
1906/2700 (epoch 35.296), train_loss = 3.31861626, grad/param norm = 1.7439e+00, time/batch = 0.2312s	
1907/2700 (epoch 35.315), train_loss = 3.29305755, grad/param norm = 1.5396e+00, time/batch = 0.2364s	
1908/2700 (epoch 35.333), train_loss = 3.36299783, grad/param norm = 1.2073e+00, time/batch = 0.2302s	
1909/2700 (epoch 35.352), train_loss = 3.37393721, grad/param norm = 1.1937e+00, time/batch = 0.2214s	
1910/2700 (epoch 35.370), train_loss = 3.31941569, grad/param norm = 1.0248e+00, time/batch = 0.2126s	
1911/2700 (epoch 35.389), train_loss = 3.26961690, grad/param norm = 8.2393e-01, time/batch = 0.2239s	
1912/2700 (epoch 35.407), train_loss = 3.29128763, grad/param norm = 7.1741e-01, time/batch = 0.2277s	
1913/2700 (epoch 35.426), train_loss = 3.29436998, grad/param norm = 7.3728e-01, time/batch = 0.2245s	
1914/2700 (epoch 35.444), train_loss = 3.21556290, grad/param norm = 6.9352e-01, time/batch = 0.2368s	
1915/2700 (epoch 35.463), train_loss = 3.26254079, grad/param norm = 7.4934e-01, time/batch = 0.2284s	
1916/2700 (epoch 35.481), train_loss = 3.33712705, grad/param norm = 6.1901e-01, time/batch = 0.2281s	
1917/2700 (epoch 35.500), train_loss = 3.38070015, grad/param norm = 7.3451e-01, time/batch = 0.2328s	
1918/2700 (epoch 35.519), train_loss = 3.33775394, grad/param norm = 8.9553e-01, time/batch = 0.2368s	
1919/2700 (epoch 35.537), train_loss = 3.34932086, grad/param norm = 1.0784e+00, time/batch = 0.2334s	
1920/2700 (epoch 35.556), train_loss = 3.29217672, grad/param norm = 1.0325e+00, time/batch = 0.2362s	
1921/2700 (epoch 35.574), train_loss = 3.24088923, grad/param norm = 9.7197e-01, time/batch = 0.2207s	
1922/2700 (epoch 35.593), train_loss = 3.25348560, grad/param norm = 1.2489e+00, time/batch = 0.2139s	
1923/2700 (epoch 35.611), train_loss = 3.19928804, grad/param norm = 1.2978e+00, time/batch = 0.2011s	
1924/2700 (epoch 35.630), train_loss = 3.24554023, grad/param norm = 1.5204e+00, time/batch = 0.2201s	
1925/2700 (epoch 35.648), train_loss = 3.32760387, grad/param norm = 1.6121e+00, time/batch = 0.2321s	
1926/2700 (epoch 35.667), train_loss = 3.25997293, grad/param norm = 1.5774e+00, time/batch = 0.2274s	
1927/2700 (epoch 35.685), train_loss = 3.24454415, grad/param norm = 1.2975e+00, time/batch = 0.2227s	
1928/2700 (epoch 35.704), train_loss = 3.21779802, grad/param norm = 1.3216e+00, time/batch = 0.2159s	
1929/2700 (epoch 35.722), train_loss = 3.20530838, grad/param norm = 1.1021e+00, time/batch = 0.2185s	
1930/2700 (epoch 35.741), train_loss = 3.32957953, grad/param norm = 9.1343e-01, time/batch = 0.2151s	
1931/2700 (epoch 35.759), train_loss = 3.28189074, grad/param norm = 1.0863e+00, time/batch = 0.2335s	
1932/2700 (epoch 35.778), train_loss = 3.28197515, grad/param norm = 1.3449e+00, time/batch = 0.2143s	
1933/2700 (epoch 35.796), train_loss = 3.28253520, grad/param norm = 1.3170e+00, time/batch = 0.1993s	
1934/2700 (epoch 35.815), train_loss = 3.22205803, grad/param norm = 1.1667e+00, time/batch = 0.2142s	
1935/2700 (epoch 35.833), train_loss = 3.26019073, grad/param norm = 1.1559e+00, time/batch = 0.2101s	
1936/2700 (epoch 35.852), train_loss = 3.24776536, grad/param norm = 1.1928e+00, time/batch = 0.2291s	
1937/2700 (epoch 35.870), train_loss = 3.24526075, grad/param norm = 1.0930e+00, time/batch = 0.2282s	
1938/2700 (epoch 35.889), train_loss = 3.26902210, grad/param norm = 9.9633e-01, time/batch = 0.2384s	
1939/2700 (epoch 35.907), train_loss = 3.31930679, grad/param norm = 1.1211e+00, time/batch = 0.2383s	
1940/2700 (epoch 35.926), train_loss = 3.28182336, grad/param norm = 1.2967e+00, time/batch = 0.2370s	
1941/2700 (epoch 35.944), train_loss = 3.29402715, grad/param norm = 1.1156e+00, time/batch = 0.2300s	
1942/2700 (epoch 35.963), train_loss = 3.36029917, grad/param norm = 9.9468e-01, time/batch = 0.1716s	
1943/2700 (epoch 35.981), train_loss = 3.41861547, grad/param norm = 9.9058e-01, time/batch = 0.2234s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
1944/2700 (epoch 36.000), train_loss = 3.32528083, grad/param norm = 9.9325e-01, time/batch = 0.2339s	
1945/2700 (epoch 36.019), train_loss = 3.26013224, grad/param norm = 1.0838e+00, time/batch = 0.2353s	
1946/2700 (epoch 36.037), train_loss = 3.28029195, grad/param norm = 1.0687e+00, time/batch = 0.2328s	
1947/2700 (epoch 36.056), train_loss = 3.27229097, grad/param norm = 7.5692e-01, time/batch = 0.2330s	
1948/2700 (epoch 36.074), train_loss = 3.30024301, grad/param norm = 6.8233e-01, time/batch = 0.2245s	
1949/2700 (epoch 36.093), train_loss = 3.31232952, grad/param norm = 8.3392e-01, time/batch = 0.2245s	
1950/2700 (epoch 36.111), train_loss = 3.28532978, grad/param norm = 8.8044e-01, time/batch = 0.2258s	
1951/2700 (epoch 36.130), train_loss = 3.30473989, grad/param norm = 8.2948e-01, time/batch = 0.2260s	
1952/2700 (epoch 36.148), train_loss = 3.26154783, grad/param norm = 1.0492e+00, time/batch = 0.2159s	
1953/2700 (epoch 36.167), train_loss = 3.28667485, grad/param norm = 1.1779e+00, time/batch = 0.2124s	
1954/2700 (epoch 36.185), train_loss = 3.26296299, grad/param norm = 9.9231e-01, time/batch = 0.2223s	
1955/2700 (epoch 36.204), train_loss = 3.19276903, grad/param norm = 9.9389e-01, time/batch = 0.2323s	
1956/2700 (epoch 36.222), train_loss = 3.16996484, grad/param norm = 1.3006e+00, time/batch = 0.2312s	
1957/2700 (epoch 36.241), train_loss = 3.19268213, grad/param norm = 1.2308e+00, time/batch = 0.2370s	
1958/2700 (epoch 36.259), train_loss = 3.22978576, grad/param norm = 1.2339e+00, time/batch = 0.2356s	
1959/2700 (epoch 36.278), train_loss = 3.31378044, grad/param norm = 1.6993e+00, time/batch = 0.2366s	
1960/2700 (epoch 36.296), train_loss = 3.32224958, grad/param norm = 1.6230e+00, time/batch = 0.2253s	
1961/2700 (epoch 36.315), train_loss = 3.28704389, grad/param norm = 1.1284e+00, time/batch = 0.2052s	
1962/2700 (epoch 36.333), train_loss = 3.35063386, grad/param norm = 8.2205e-01, time/batch = 0.2220s	
1963/2700 (epoch 36.352), train_loss = 3.36072067, grad/param norm = 9.1718e-01, time/batch = 0.2330s	
1964/2700 (epoch 36.370), train_loss = 3.31384989, grad/param norm = 1.0583e+00, time/batch = 0.2347s	
1965/2700 (epoch 36.389), train_loss = 3.27325801, grad/param norm = 9.9823e-01, time/batch = 0.2307s	
1966/2700 (epoch 36.407), train_loss = 3.29482360, grad/param norm = 8.8667e-01, time/batch = 0.2345s	
1967/2700 (epoch 36.426), train_loss = 3.29389304, grad/param norm = 8.2661e-01, time/batch = 0.2353s	
1968/2700 (epoch 36.444), train_loss = 3.21778071, grad/param norm = 8.5745e-01, time/batch = 0.2340s	
1969/2700 (epoch 36.463), train_loss = 3.26634030, grad/param norm = 1.0579e+00, time/batch = 0.2338s	
1970/2700 (epoch 36.481), train_loss = 3.35054183, grad/param norm = 1.1837e+00, time/batch = 0.2169s	
1971/2700 (epoch 36.500), train_loss = 3.39686934, grad/param norm = 1.3959e+00, time/batch = 0.2031s	
1972/2700 (epoch 36.519), train_loss = 3.35296381, grad/param norm = 1.4279e+00, time/batch = 0.2078s	
1973/2700 (epoch 36.537), train_loss = 3.35619977, grad/param norm = 1.3112e+00, time/batch = 0.2271s	
1974/2700 (epoch 36.556), train_loss = 3.29179194, grad/param norm = 1.0546e+00, time/batch = 0.2340s	
1975/2700 (epoch 36.574), train_loss = 3.23856879, grad/param norm = 8.2477e-01, time/batch = 0.2392s	
1976/2700 (epoch 36.593), train_loss = 3.24695102, grad/param norm = 1.0047e+00, time/batch = 0.2350s	
1977/2700 (epoch 36.611), train_loss = 3.18798262, grad/param norm = 8.9126e-01, time/batch = 0.2373s	
1978/2700 (epoch 36.630), train_loss = 3.22870917, grad/param norm = 9.7707e-01, time/batch = 0.2349s	
1979/2700 (epoch 36.648), train_loss = 3.30650843, grad/param norm = 1.0767e+00, time/batch = 0.2315s	
1980/2700 (epoch 36.667), train_loss = 3.24384736, grad/param norm = 1.1098e+00, time/batch = 0.2261s	
1981/2700 (epoch 36.685), train_loss = 3.23406125, grad/param norm = 1.0244e+00, time/batch = 0.2242s	
1982/2700 (epoch 36.704), train_loss = 3.21098437, grad/param norm = 1.1629e+00, time/batch = 0.2248s	
1983/2700 (epoch 36.722), train_loss = 3.20099383, grad/param norm = 1.0302e+00, time/batch = 0.2231s	
1984/2700 (epoch 36.741), train_loss = 3.32880157, grad/param norm = 9.2601e-01, time/batch = 0.2286s	
1985/2700 (epoch 36.759), train_loss = 3.28340082, grad/param norm = 1.1549e+00, time/batch = 0.2324s	
1986/2700 (epoch 36.778), train_loss = 3.28645649, grad/param norm = 1.4901e+00, time/batch = 0.2346s	
1987/2700 (epoch 36.796), train_loss = 3.28904002, grad/param norm = 1.5027e+00, time/batch = 0.2354s	
1988/2700 (epoch 36.815), train_loss = 3.22521938, grad/param norm = 1.3324e+00, time/batch = 0.2289s	
1989/2700 (epoch 36.833), train_loss = 3.26318975, grad/param norm = 1.3234e+00, time/batch = 0.2358s	
1990/2700 (epoch 36.852), train_loss = 3.25183721, grad/param norm = 1.3448e+00, time/batch = 0.2238s	
1991/2700 (epoch 36.870), train_loss = 3.24580217, grad/param norm = 1.1433e+00, time/batch = 0.2288s	
1992/2700 (epoch 36.889), train_loss = 3.26800726, grad/param norm = 9.8739e-01, time/batch = 0.2092s	
1993/2700 (epoch 36.907), train_loss = 3.31752331, grad/param norm = 1.0638e+00, time/batch = 0.2261s	
1994/2700 (epoch 36.926), train_loss = 3.27874274, grad/param norm = 1.2196e+00, time/batch = 0.2279s	
1995/2700 (epoch 36.944), train_loss = 3.29064861, grad/param norm = 1.0383e+00, time/batch = 0.2175s	
1996/2700 (epoch 36.963), train_loss = 3.35752306, grad/param norm = 9.1603e-01, time/batch = 0.2088s	
1997/2700 (epoch 36.981), train_loss = 3.41603764, grad/param norm = 9.3155e-01, time/batch = 0.2061s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
1998/2700 (epoch 37.000), train_loss = 3.32313273, grad/param norm = 9.3023e-01, time/batch = 0.2180s	
1999/2700 (epoch 37.019), train_loss = 3.25774090, grad/param norm = 1.0120e+00, time/batch = 0.2338s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch37.04_3.1947.t7	
2000/2700 (epoch 37.037), train_loss = 3.27771011, grad/param norm = 9.8331e-01, time/batch = 0.2122s	
2001/2700 (epoch 37.056), train_loss = 3.27053246, grad/param norm = 6.9796e-01, time/batch = 0.2236s	
2002/2700 (epoch 37.074), train_loss = 3.30005480, grad/param norm = 6.9564e-01, time/batch = 0.2206s	
2003/2700 (epoch 37.093), train_loss = 3.31161069, grad/param norm = 8.5182e-01, time/batch = 0.2147s	
2004/2700 (epoch 37.111), train_loss = 3.28424416, grad/param norm = 8.6313e-01, time/batch = 0.2148s	
2005/2700 (epoch 37.130), train_loss = 3.30271143, grad/param norm = 7.9543e-01, time/batch = 0.2241s	
2006/2700 (epoch 37.148), train_loss = 3.26002906, grad/param norm = 9.8007e-01, time/batch = 0.2313s	
2007/2700 (epoch 37.167), train_loss = 3.28310769, grad/param norm = 1.1452e+00, time/batch = 0.2170s	
2008/2700 (epoch 37.185), train_loss = 3.26092089, grad/param norm = 9.0622e-01, time/batch = 0.2003s	
2009/2700 (epoch 37.204), train_loss = 3.19009383, grad/param norm = 9.4512e-01, time/batch = 0.2302s	
2010/2700 (epoch 37.222), train_loss = 3.17028108, grad/param norm = 1.1971e+00, time/batch = 0.2285s	
2011/2700 (epoch 37.241), train_loss = 3.19658066, grad/param norm = 1.3410e+00, time/batch = 0.2242s	
2012/2700 (epoch 37.259), train_loss = 3.24163971, grad/param norm = 1.8010e+00, time/batch = 0.2190s	
2013/2700 (epoch 37.278), train_loss = 3.31810016, grad/param norm = 1.6564e+00, time/batch = 0.2237s	
2014/2700 (epoch 37.296), train_loss = 3.30765322, grad/param norm = 1.4065e+00, time/batch = 0.2044s	
2015/2700 (epoch 37.315), train_loss = 3.28080514, grad/param norm = 1.2400e+00, time/batch = 0.2208s	
2016/2700 (epoch 37.333), train_loss = 3.35791508, grad/param norm = 1.0623e+00, time/batch = 0.2103s	
2017/2700 (epoch 37.352), train_loss = 3.36798180, grad/param norm = 1.0635e+00, time/batch = 0.2215s	
2018/2700 (epoch 37.370), train_loss = 3.31266710, grad/param norm = 9.2980e-01, time/batch = 0.2317s	
2019/2700 (epoch 37.389), train_loss = 3.26631410, grad/param norm = 7.6093e-01, time/batch = 0.2353s	
2020/2700 (epoch 37.407), train_loss = 3.28885913, grad/param norm = 6.7397e-01, time/batch = 0.2354s	
2021/2700 (epoch 37.426), train_loss = 3.29205883, grad/param norm = 6.9825e-01, time/batch = 0.2258s	
2022/2700 (epoch 37.444), train_loss = 3.21451642, grad/param norm = 6.7676e-01, time/batch = 0.2328s	
2023/2700 (epoch 37.463), train_loss = 3.26137764, grad/param norm = 7.4357e-01, time/batch = 0.2258s	
2024/2700 (epoch 37.481), train_loss = 3.33558577, grad/param norm = 6.1949e-01, time/batch = 0.2285s	
2025/2700 (epoch 37.500), train_loss = 3.37990495, grad/param norm = 7.7239e-01, time/batch = 0.2199s	
2026/2700 (epoch 37.519), train_loss = 3.33688330, grad/param norm = 9.2972e-01, time/batch = 0.1987s	
2027/2700 (epoch 37.537), train_loss = 3.34745507, grad/param norm = 1.0981e+00, time/batch = 0.2355s	
2028/2700 (epoch 37.556), train_loss = 3.28940115, grad/param norm = 1.0358e+00, time/batch = 0.2311s	
2029/2700 (epoch 37.574), train_loss = 3.24046334, grad/param norm = 9.6546e-01, time/batch = 0.2127s	
2030/2700 (epoch 37.593), train_loss = 3.25248398, grad/param norm = 1.2333e+00, time/batch = 0.2089s	
2031/2700 (epoch 37.611), train_loss = 3.19721781, grad/param norm = 1.2318e+00, time/batch = 0.2264s	
2032/2700 (epoch 37.630), train_loss = 3.24006446, grad/param norm = 1.3904e+00, time/batch = 0.2175s	
2033/2700 (epoch 37.648), train_loss = 3.31954195, grad/param norm = 1.4636e+00, time/batch = 0.2321s	
2034/2700 (epoch 37.667), train_loss = 3.25116046, grad/param norm = 1.4083e+00, time/batch = 0.2345s	
2035/2700 (epoch 37.685), train_loss = 3.23736563, grad/param norm = 1.1618e+00, time/batch = 0.2268s	
2036/2700 (epoch 37.704), train_loss = 3.21115723, grad/param norm = 1.2153e+00, time/batch = 0.2355s	
2037/2700 (epoch 37.722), train_loss = 3.19984015, grad/param norm = 1.0144e+00, time/batch = 0.2352s	
2038/2700 (epoch 37.741), train_loss = 3.32556829, grad/param norm = 8.4223e-01, time/batch = 0.2353s	
2039/2700 (epoch 37.759), train_loss = 3.27799510, grad/param norm = 1.0276e+00, time/batch = 0.2358s	
2040/2700 (epoch 37.778), train_loss = 3.27819143, grad/param norm = 1.2837e+00, time/batch = 0.2325s	
2041/2700 (epoch 37.796), train_loss = 3.27769111, grad/param norm = 1.2670e+00, time/batch = 0.2250s	
2042/2700 (epoch 37.815), train_loss = 3.21902976, grad/param norm = 1.1266e+00, time/batch = 0.2095s	
2043/2700 (epoch 37.833), train_loss = 3.25689170, grad/param norm = 1.1198e+00, time/batch = 0.2190s	
2044/2700 (epoch 37.852), train_loss = 3.24476341, grad/param norm = 1.1587e+00, time/batch = 0.2145s	
2045/2700 (epoch 37.870), train_loss = 3.24160329, grad/param norm = 1.0581e+00, time/batch = 0.1898s	
2046/2700 (epoch 37.889), train_loss = 3.26708156, grad/param norm = 9.6474e-01, time/batch = 0.2352s	
2047/2700 (epoch 37.907), train_loss = 3.31771111, grad/param norm = 1.0891e+00, time/batch = 0.2362s	
2048/2700 (epoch 37.926), train_loss = 3.27893924, grad/param norm = 1.2476e+00, time/batch = 0.2348s	
2049/2700 (epoch 37.944), train_loss = 3.29006035, grad/param norm = 1.0640e+00, time/batch = 0.2352s	
2050/2700 (epoch 37.963), train_loss = 3.35767828, grad/param norm = 9.4771e-01, time/batch = 0.2254s	
2051/2700 (epoch 37.981), train_loss = 3.41616886, grad/param norm = 9.4936e-01, time/batch = 0.2135s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2052/2700 (epoch 38.000), train_loss = 3.32229000, grad/param norm = 9.4854e-01, time/batch = 0.2294s	
2053/2700 (epoch 38.019), train_loss = 3.25817137, grad/param norm = 1.0385e+00, time/batch = 0.2293s	
2054/2700 (epoch 38.037), train_loss = 3.27734076, grad/param norm = 1.0129e+00, time/batch = 0.2264s	
2055/2700 (epoch 38.056), train_loss = 3.27011706, grad/param norm = 7.0789e-01, time/batch = 0.2270s	
2056/2700 (epoch 38.074), train_loss = 3.29905120, grad/param norm = 6.6284e-01, time/batch = 0.2260s	
2057/2700 (epoch 38.093), train_loss = 3.31029363, grad/param norm = 8.1439e-01, time/batch = 0.2270s	
2058/2700 (epoch 38.111), train_loss = 3.28279955, grad/param norm = 8.4061e-01, time/batch = 0.2303s	
2059/2700 (epoch 38.130), train_loss = 3.30171818, grad/param norm = 7.7918e-01, time/batch = 0.2318s	
2060/2700 (epoch 38.148), train_loss = 3.25898274, grad/param norm = 9.8043e-01, time/batch = 0.2351s	
2061/2700 (epoch 38.167), train_loss = 3.28170384, grad/param norm = 1.1071e+00, time/batch = 0.2263s	
2062/2700 (epoch 38.185), train_loss = 3.25862867, grad/param norm = 8.7411e-01, time/batch = 0.2269s	
2063/2700 (epoch 38.204), train_loss = 3.18781998, grad/param norm = 8.3594e-01, time/batch = 0.2102s	
2064/2700 (epoch 38.222), train_loss = 3.16421683, grad/param norm = 1.0848e+00, time/batch = 0.2141s	
2065/2700 (epoch 38.241), train_loss = 3.18530751, grad/param norm = 9.0194e-01, time/batch = 0.2325s	
2066/2700 (epoch 38.259), train_loss = 3.21879189, grad/param norm = 8.3053e-01, time/batch = 0.2342s	
2067/2700 (epoch 38.278), train_loss = 3.30240480, grad/param norm = 1.3794e+00, time/batch = 0.2336s	
2068/2700 (epoch 38.296), train_loss = 3.31714436, grad/param norm = 1.5506e+00, time/batch = 0.2162s	
2069/2700 (epoch 38.315), train_loss = 3.28794040, grad/param norm = 1.3132e+00, time/batch = 0.2228s	
2070/2700 (epoch 38.333), train_loss = 3.35448140, grad/param norm = 1.0670e+00, time/batch = 0.2240s	
2071/2700 (epoch 38.352), train_loss = 3.36248054, grad/param norm = 1.0808e+00, time/batch = 0.2212s	
2072/2700 (epoch 38.370), train_loss = 3.31518637, grad/param norm = 1.2398e+00, time/batch = 0.2009s	
2073/2700 (epoch 38.389), train_loss = 3.27633626, grad/param norm = 1.1571e+00, time/batch = 0.2280s	
2074/2700 (epoch 38.407), train_loss = 3.29540380, grad/param norm = 1.0111e+00, time/batch = 0.2320s	
2075/2700 (epoch 38.426), train_loss = 3.29362031, grad/param norm = 8.9714e-01, time/batch = 0.2265s	
2076/2700 (epoch 38.444), train_loss = 3.21857693, grad/param norm = 9.3189e-01, time/batch = 0.2253s	
2077/2700 (epoch 38.463), train_loss = 3.26584360, grad/param norm = 1.0733e+00, time/batch = 0.2317s	
2078/2700 (epoch 38.481), train_loss = 3.34744654, grad/param norm = 1.1274e+00, time/batch = 0.2247s	
2079/2700 (epoch 38.500), train_loss = 3.39198977, grad/param norm = 1.2610e+00, time/batch = 0.1978s	
2080/2700 (epoch 38.519), train_loss = 3.34555215, grad/param norm = 1.2503e+00, time/batch = 0.2353s	
2081/2700 (epoch 38.537), train_loss = 3.34932980, grad/param norm = 1.1666e+00, time/batch = 0.2132s	
2082/2700 (epoch 38.556), train_loss = 3.28642392, grad/param norm = 9.3519e-01, time/batch = 0.2258s	
2083/2700 (epoch 38.574), train_loss = 3.23659910, grad/param norm = 7.4272e-01, time/batch = 0.2225s	
2084/2700 (epoch 38.593), train_loss = 3.24442364, grad/param norm = 9.3043e-01, time/batch = 0.2318s	
2085/2700 (epoch 38.611), train_loss = 3.18504430, grad/param norm = 8.1286e-01, time/batch = 0.2328s	
2086/2700 (epoch 38.630), train_loss = 3.22562512, grad/param norm = 8.7815e-01, time/batch = 0.2338s	
2087/2700 (epoch 38.648), train_loss = 3.30196212, grad/param norm = 9.6857e-01, time/batch = 0.2346s	
2088/2700 (epoch 38.667), train_loss = 3.23856387, grad/param norm = 9.8855e-01, time/batch = 0.2210s	
2089/2700 (epoch 38.685), train_loss = 3.22940053, grad/param norm = 9.1765e-01, time/batch = 0.2238s	
2090/2700 (epoch 38.704), train_loss = 3.20586602, grad/param norm = 1.0617e+00, time/batch = 0.2180s	
2091/2700 (epoch 38.722), train_loss = 3.19550467, grad/param norm = 9.1982e-01, time/batch = 0.2336s	
2092/2700 (epoch 38.741), train_loss = 3.32440241, grad/param norm = 8.3272e-01, time/batch = 0.2355s	
2093/2700 (epoch 38.759), train_loss = 3.27856936, grad/param norm = 1.0694e+00, time/batch = 0.2315s	
2094/2700 (epoch 38.778), train_loss = 3.28245631, grad/param norm = 1.4194e+00, time/batch = 0.2273s	
2095/2700 (epoch 38.796), train_loss = 3.28548546, grad/param norm = 1.4779e+00, time/batch = 0.2240s	
2096/2700 (epoch 38.815), train_loss = 3.22351668, grad/param norm = 1.3248e+00, time/batch = 0.2231s	
2097/2700 (epoch 38.833), train_loss = 3.26070423, grad/param norm = 1.3246e+00, time/batch = 0.2280s	
2098/2700 (epoch 38.852), train_loss = 3.24940882, grad/param norm = 1.3332e+00, time/batch = 0.2234s	
2099/2700 (epoch 38.870), train_loss = 3.24215286, grad/param norm = 1.1158e+00, time/batch = 0.2306s	
2100/2700 (epoch 38.889), train_loss = 3.26621599, grad/param norm = 9.5834e-01, time/batch = 0.2228s	
2101/2700 (epoch 38.907), train_loss = 3.31598400, grad/param norm = 1.0281e+00, time/batch = 0.2326s	
2102/2700 (epoch 38.926), train_loss = 3.27590954, grad/param norm = 1.1649e+00, time/batch = 0.2136s	
2103/2700 (epoch 38.944), train_loss = 3.28677356, grad/param norm = 9.8357e-01, time/batch = 0.2359s	
2104/2700 (epoch 38.963), train_loss = 3.35508564, grad/param norm = 8.7088e-01, time/batch = 0.2277s	
2105/2700 (epoch 38.981), train_loss = 3.41405637, grad/param norm = 8.9598e-01, time/batch = 0.2151s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2106/2700 (epoch 39.000), train_loss = 3.32039594, grad/param norm = 8.9234e-01, time/batch = 0.2107s	
2107/2700 (epoch 39.019), train_loss = 3.25590270, grad/param norm = 9.6973e-01, time/batch = 0.2132s	
2108/2700 (epoch 39.037), train_loss = 3.27488968, grad/param norm = 9.2999e-01, time/batch = 0.2266s	
2109/2700 (epoch 39.056), train_loss = 3.26866754, grad/param norm = 6.6211e-01, time/batch = 0.2315s	
2110/2700 (epoch 39.074), train_loss = 3.29918844, grad/param norm = 7.0018e-01, time/batch = 0.2313s	
2111/2700 (epoch 39.093), train_loss = 3.30999695, grad/param norm = 8.5159e-01, time/batch = 0.2245s	
2112/2700 (epoch 39.111), train_loss = 3.28206639, grad/param norm = 8.4475e-01, time/batch = 0.2323s	
2113/2700 (epoch 39.130), train_loss = 3.30022496, grad/param norm = 7.7488e-01, time/batch = 0.2183s	
2114/2700 (epoch 39.148), train_loss = 3.25816626, grad/param norm = 9.4913e-01, time/batch = 0.2143s	
2115/2700 (epoch 39.167), train_loss = 3.27981967, grad/param norm = 1.1277e+00, time/batch = 0.2305s	
2116/2700 (epoch 39.185), train_loss = 3.25862456, grad/param norm = 9.0212e-01, time/batch = 0.2318s	
2117/2700 (epoch 39.204), train_loss = 3.18901250, grad/param norm = 9.8201e-01, time/batch = 0.2307s	
2118/2700 (epoch 39.222), train_loss = 3.17056300, grad/param norm = 1.2507e+00, time/batch = 0.2346s	
2119/2700 (epoch 39.241), train_loss = 3.19645414, grad/param norm = 1.3797e+00, time/batch = 0.2371s	
2120/2700 (epoch 39.259), train_loss = 3.23557535, grad/param norm = 1.6484e+00, time/batch = 0.2355s	
2121/2700 (epoch 39.278), train_loss = 3.30799758, grad/param norm = 1.4630e+00, time/batch = 0.2204s	
2122/2700 (epoch 39.296), train_loss = 3.30313651, grad/param norm = 1.2912e+00, time/batch = 0.2252s	
2123/2700 (epoch 39.315), train_loss = 3.27713575, grad/param norm = 1.1517e+00, time/batch = 0.2064s	
2124/2700 (epoch 39.333), train_loss = 3.35502155, grad/param norm = 1.0034e+00, time/batch = 0.2117s	
2125/2700 (epoch 39.352), train_loss = 3.36412803, grad/param norm = 9.9879e-01, time/batch = 0.1767s	
2126/2700 (epoch 39.370), train_loss = 3.30806967, grad/param norm = 8.7304e-01, time/batch = 0.2203s	
2127/2700 (epoch 39.389), train_loss = 3.26390979, grad/param norm = 7.1423e-01, time/batch = 0.2307s	
2128/2700 (epoch 39.407), train_loss = 3.28670087, grad/param norm = 6.3810e-01, time/batch = 0.2198s	
2129/2700 (epoch 39.426), train_loss = 3.29010064, grad/param norm = 6.6941e-01, time/batch = 0.2199s	
2130/2700 (epoch 39.444), train_loss = 3.21349276, grad/param norm = 6.5629e-01, time/batch = 0.2222s	
2131/2700 (epoch 39.463), train_loss = 3.25996709, grad/param norm = 7.2757e-01, time/batch = 0.2336s	
2132/2700 (epoch 39.481), train_loss = 3.33399898, grad/param norm = 6.0655e-01, time/batch = 0.2275s	
2133/2700 (epoch 39.500), train_loss = 3.37894655, grad/param norm = 7.8315e-01, time/batch = 0.2337s	
2134/2700 (epoch 39.519), train_loss = 3.33585262, grad/param norm = 9.3306e-01, time/batch = 0.2284s	
2135/2700 (epoch 39.537), train_loss = 3.34535856, grad/param norm = 1.0834e+00, time/batch = 0.2346s	
2136/2700 (epoch 39.556), train_loss = 3.28598673, grad/param norm = 9.9883e-01, time/batch = 0.2355s	
2137/2700 (epoch 39.574), train_loss = 3.23920030, grad/param norm = 9.2136e-01, time/batch = 0.2333s	
2138/2700 (epoch 39.593), train_loss = 3.25016649, grad/param norm = 1.1800e+00, time/batch = 0.2250s	
2139/2700 (epoch 39.611), train_loss = 3.19379641, grad/param norm = 1.1527e+00, time/batch = 0.2179s	
2140/2700 (epoch 39.630), train_loss = 3.23576427, grad/param norm = 1.2837e+00, time/batch = 0.1762s	
2141/2700 (epoch 39.648), train_loss = 3.31352234, grad/param norm = 1.3510e+00, time/batch = 0.2201s	
2142/2700 (epoch 39.667), train_loss = 3.24507798, grad/param norm = 1.2960e+00, time/batch = 0.2160s	
2143/2700 (epoch 39.685), train_loss = 3.23257278, grad/param norm = 1.0701e+00, time/batch = 0.2250s	
2144/2700 (epoch 39.704), train_loss = 3.20644651, grad/param norm = 1.1380e+00, time/batch = 0.2293s	
2145/2700 (epoch 39.722), train_loss = 3.19560525, grad/param norm = 9.4482e-01, time/batch = 0.2311s	
2146/2700 (epoch 39.741), train_loss = 3.32230990, grad/param norm = 7.8420e-01, time/batch = 0.2357s	
2147/2700 (epoch 39.759), train_loss = 3.27471002, grad/param norm = 9.7659e-01, time/batch = 0.2359s	
2148/2700 (epoch 39.778), train_loss = 3.27452872, grad/param norm = 1.2202e+00, time/batch = 0.2332s	
2149/2700 (epoch 39.796), train_loss = 3.27304907, grad/param norm = 1.2161e+00, time/batch = 0.2307s	
2150/2700 (epoch 39.815), train_loss = 3.21627434, grad/param norm = 1.0863e+00, time/batch = 0.2318s	
2151/2700 (epoch 39.833), train_loss = 3.25383995, grad/param norm = 1.0799e+00, time/batch = 0.2159s	
2152/2700 (epoch 39.852), train_loss = 3.24179302, grad/param norm = 1.1176e+00, time/batch = 0.2157s	
2153/2700 (epoch 39.870), train_loss = 3.23802025, grad/param norm = 1.0144e+00, time/batch = 0.2006s	
2154/2700 (epoch 39.889), train_loss = 3.26506612, grad/param norm = 9.2554e-01, time/batch = 0.2205s	
2155/2700 (epoch 39.907), train_loss = 3.31617941, grad/param norm = 1.0530e+00, time/batch = 0.2288s	
2156/2700 (epoch 39.926), train_loss = 3.27613724, grad/param norm = 1.1956e+00, time/batch = 0.2311s	
2157/2700 (epoch 39.944), train_loss = 3.28639193, grad/param norm = 1.0138e+00, time/batch = 0.2328s	
2158/2700 (epoch 39.963), train_loss = 3.35545052, grad/param norm = 9.0566e-01, time/batch = 0.2337s	
2159/2700 (epoch 39.981), train_loss = 3.41417934, grad/param norm = 9.1370e-01, time/batch = 0.2286s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2160/2700 (epoch 40.000), train_loss = 3.31962726, grad/param norm = 9.0942e-01, time/batch = 0.2355s	
2161/2700 (epoch 40.019), train_loss = 3.25643664, grad/param norm = 9.9813e-01, time/batch = 0.2280s	
2162/2700 (epoch 40.037), train_loss = 3.27467949, grad/param norm = 9.6214e-01, time/batch = 0.2161s	
2163/2700 (epoch 40.056), train_loss = 3.26825024, grad/param norm = 6.6615e-01, time/batch = 0.2143s	
2164/2700 (epoch 40.074), train_loss = 3.29802559, grad/param norm = 6.5127e-01, time/batch = 0.2156s	
2165/2700 (epoch 40.093), train_loss = 3.30850534, grad/param norm = 8.0060e-01, time/batch = 0.2200s	
2166/2700 (epoch 40.111), train_loss = 3.28055551, grad/param norm = 8.0901e-01, time/batch = 0.2213s	
2167/2700 (epoch 40.130), train_loss = 3.29908366, grad/param norm = 7.4174e-01, time/batch = 0.2295s	
2168/2700 (epoch 40.148), train_loss = 3.25692068, grad/param norm = 9.2762e-01, time/batch = 0.2232s	
2169/2700 (epoch 40.167), train_loss = 3.27771985, grad/param norm = 1.0592e+00, time/batch = 0.2222s	
2170/2700 (epoch 40.185), train_loss = 3.25552733, grad/param norm = 7.9974e-01, time/batch = 0.2330s	
2171/2700 (epoch 40.204), train_loss = 3.18482477, grad/param norm = 7.6543e-01, time/batch = 0.2150s	
2172/2700 (epoch 40.222), train_loss = 3.16187855, grad/param norm = 9.6973e-01, time/batch = 0.2087s	
2173/2700 (epoch 40.241), train_loss = 3.18167687, grad/param norm = 7.8564e-01, time/batch = 0.2101s	
2174/2700 (epoch 40.259), train_loss = 3.21614025, grad/param norm = 7.3963e-01, time/batch = 0.1933s	
2175/2700 (epoch 40.278), train_loss = 3.29233733, grad/param norm = 9.7822e-01, time/batch = 0.1865s	
2176/2700 (epoch 40.296), train_loss = 3.30769031, grad/param norm = 1.4588e+00, time/batch = 0.1864s	
2177/2700 (epoch 40.315), train_loss = 3.29514065, grad/param norm = 1.6045e+00, time/batch = 0.1867s	
2178/2700 (epoch 40.333), train_loss = 3.36577086, grad/param norm = 1.4796e+00, time/batch = 0.1815s	
2179/2700 (epoch 40.352), train_loss = 3.37496801, grad/param norm = 1.3685e+00, time/batch = 0.1887s	
2180/2700 (epoch 40.370), train_loss = 3.31100760, grad/param norm = 1.0109e+00, time/batch = 0.1881s	
2181/2700 (epoch 40.389), train_loss = 3.26308148, grad/param norm = 7.5887e-01, time/batch = 0.1332s	
2182/2700 (epoch 40.407), train_loss = 3.28566873, grad/param norm = 6.4768e-01, time/batch = 0.1573s	
2183/2700 (epoch 40.426), train_loss = 3.28927819, grad/param norm = 6.9731e-01, time/batch = 0.1587s	
2184/2700 (epoch 40.444), train_loss = 3.21202452, grad/param norm = 6.0918e-01, time/batch = 0.1735s	
2185/2700 (epoch 40.463), train_loss = 3.25736463, grad/param norm = 6.5628e-01, time/batch = 0.1792s	
2186/2700 (epoch 40.481), train_loss = 3.33275562, grad/param norm = 5.4932e-01, time/batch = 0.1820s	
2187/2700 (epoch 40.500), train_loss = 3.37891681, grad/param norm = 7.1942e-01, time/batch = 0.1753s	
2188/2700 (epoch 40.519), train_loss = 3.33571511, grad/param norm = 8.2061e-01, time/batch = 0.1794s	
2189/2700 (epoch 40.537), train_loss = 3.34210473, grad/param norm = 9.3315e-01, time/batch = 0.1776s	
2190/2700 (epoch 40.556), train_loss = 3.28121414, grad/param norm = 8.1280e-01, time/batch = 0.1725s	
2191/2700 (epoch 40.574), train_loss = 3.23537406, grad/param norm = 7.4745e-01, time/batch = 0.1832s	
2192/2700 (epoch 40.593), train_loss = 3.24469836, grad/param norm = 1.0131e+00, time/batch = 0.1721s	
2193/2700 (epoch 40.611), train_loss = 3.18776836, grad/param norm = 1.0164e+00, time/batch = 0.1727s	
2194/2700 (epoch 40.630), train_loss = 3.23375135, grad/param norm = 1.2388e+00, time/batch = 0.1794s	
2195/2700 (epoch 40.648), train_loss = 3.31395454, grad/param norm = 1.4304e+00, time/batch = 0.1745s	
2196/2700 (epoch 40.667), train_loss = 3.24873469, grad/param norm = 1.4513e+00, time/batch = 0.1722s	
2197/2700 (epoch 40.685), train_loss = 3.23516863, grad/param norm = 1.2060e+00, time/batch = 0.1541s	
2198/2700 (epoch 40.704), train_loss = 3.20880900, grad/param norm = 1.2485e+00, time/batch = 0.1865s	
2199/2700 (epoch 40.722), train_loss = 3.19692470, grad/param norm = 1.0251e+00, time/batch = 0.1801s	
2200/2700 (epoch 40.741), train_loss = 3.32241739, grad/param norm = 8.2085e-01, time/batch = 0.1860s	
2201/2700 (epoch 40.759), train_loss = 3.27458668, grad/param norm = 9.9615e-01, time/batch = 0.1702s	
2202/2700 (epoch 40.778), train_loss = 3.27259375, grad/param norm = 1.1969e+00, time/batch = 0.1786s	
2203/2700 (epoch 40.796), train_loss = 3.26959416, grad/param norm = 1.1749e+00, time/batch = 0.1791s	
2204/2700 (epoch 40.815), train_loss = 3.21418517, grad/param norm = 1.0393e+00, time/batch = 0.1816s	
2205/2700 (epoch 40.833), train_loss = 3.25139350, grad/param norm = 1.0061e+00, time/batch = 0.1862s	
2206/2700 (epoch 40.852), train_loss = 3.23860059, grad/param norm = 1.0241e+00, time/batch = 0.1842s	
2207/2700 (epoch 40.870), train_loss = 3.23486369, grad/param norm = 9.1215e-01, time/batch = 0.1772s	
2208/2700 (epoch 40.889), train_loss = 3.26245707, grad/param norm = 8.2209e-01, time/batch = 0.1742s	
2209/2700 (epoch 40.907), train_loss = 3.31435051, grad/param norm = 9.7149e-01, time/batch = 0.1458s	
2210/2700 (epoch 40.926), train_loss = 3.27411469, grad/param norm = 1.1376e+00, time/batch = 0.1847s	
2211/2700 (epoch 40.944), train_loss = 3.28491297, grad/param norm = 9.8935e-01, time/batch = 0.1708s	
2212/2700 (epoch 40.963), train_loss = 3.35518226, grad/param norm = 8.9505e-01, time/batch = 0.1760s	
2213/2700 (epoch 40.981), train_loss = 3.41327400, grad/param norm = 8.9635e-01, time/batch = 0.1789s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2214/2700 (epoch 41.000), train_loss = 3.31807089, grad/param norm = 8.8815e-01, time/batch = 0.1870s	
2215/2700 (epoch 41.019), train_loss = 3.25573107, grad/param norm = 9.8469e-01, time/batch = 0.1793s	
2216/2700 (epoch 41.037), train_loss = 3.27358450, grad/param norm = 9.4749e-01, time/batch = 0.1616s	
2217/2700 (epoch 41.056), train_loss = 3.26747274, grad/param norm = 6.5284e-01, time/batch = 0.1856s	
2218/2700 (epoch 41.074), train_loss = 3.29733840, grad/param norm = 6.3640e-01, time/batch = 0.1791s	
2219/2700 (epoch 41.093), train_loss = 3.30758763, grad/param norm = 7.8645e-01, time/batch = 0.1851s	
2220/2700 (epoch 41.111), train_loss = 3.27951014, grad/param norm = 7.9470e-01, time/batch = 0.1868s	
2221/2700 (epoch 41.130), train_loss = 3.29804216, grad/param norm = 7.3001e-01, time/batch = 0.1795s	
2222/2700 (epoch 41.148), train_loss = 3.25617464, grad/param norm = 9.1827e-01, time/batch = 0.1847s	
2223/2700 (epoch 41.167), train_loss = 3.27639662, grad/param norm = 1.0430e+00, time/batch = 0.1853s	
2224/2700 (epoch 41.185), train_loss = 3.25427146, grad/param norm = 7.8367e-01, time/batch = 0.1868s	
2225/2700 (epoch 41.204), train_loss = 3.18393310, grad/param norm = 7.4557e-01, time/batch = 0.1736s	
2226/2700 (epoch 41.222), train_loss = 3.16085257, grad/param norm = 9.6805e-01, time/batch = 0.1714s	
2227/2700 (epoch 41.241), train_loss = 3.18027557, grad/param norm = 7.3702e-01, time/batch = 0.1803s	
2228/2700 (epoch 41.259), train_loss = 3.21263783, grad/param norm = 5.4187e-01, time/batch = 0.1705s	
2229/2700 (epoch 41.278), train_loss = 3.28877638, grad/param norm = 7.8098e-01, time/batch = 0.1795s	
2230/2700 (epoch 41.296), train_loss = 3.29692515, grad/param norm = 9.9674e-01, time/batch = 0.1793s	
2231/2700 (epoch 41.315), train_loss = 3.27750422, grad/param norm = 1.0383e+00, time/batch = 0.1780s	
2232/2700 (epoch 41.333), train_loss = 3.35385419, grad/param norm = 1.0783e+00, time/batch = 0.1693s	
2233/2700 (epoch 41.352), train_loss = 3.36818618, grad/param norm = 1.4085e+00, time/batch = 0.1677s	
2234/2700 (epoch 41.370), train_loss = 3.32580716, grad/param norm = 1.6153e+00, time/batch = 0.1738s	
2235/2700 (epoch 41.389), train_loss = 3.28052754, grad/param norm = 1.4075e+00, time/batch = 0.1654s	
2236/2700 (epoch 41.407), train_loss = 3.29760951, grad/param norm = 1.1890e+00, time/batch = 0.1764s	
2237/2700 (epoch 41.426), train_loss = 3.29249259, grad/param norm = 9.2685e-01, time/batch = 0.1455s	
2238/2700 (epoch 41.444), train_loss = 3.21722097, grad/param norm = 9.1441e-01, time/batch = 0.1795s	
2239/2700 (epoch 41.463), train_loss = 3.26209711, grad/param norm = 9.5921e-01, time/batch = 0.1702s	
2240/2700 (epoch 41.481), train_loss = 3.34043604, grad/param norm = 9.4693e-01, time/batch = 0.1764s	
2241/2700 (epoch 41.500), train_loss = 3.38549277, grad/param norm = 1.0671e+00, time/batch = 0.1831s	
2242/2700 (epoch 41.519), train_loss = 3.33792534, grad/param norm = 1.0461e+00, time/batch = 0.1734s	
2243/2700 (epoch 41.537), train_loss = 3.34268898, grad/param norm = 1.0146e+00, time/batch = 0.1678s	
2244/2700 (epoch 41.556), train_loss = 3.28056773, grad/param norm = 8.0616e-01, time/batch = 0.1510s	
2245/2700 (epoch 41.574), train_loss = 3.23471254, grad/param norm = 6.6564e-01, time/batch = 0.1619s	
2246/2700 (epoch 41.593), train_loss = 3.24180072, grad/param norm = 8.6048e-01, time/batch = 0.1311s	
2247/2700 (epoch 41.611), train_loss = 3.18164447, grad/param norm = 7.3307e-01, time/batch = 0.1793s	
2248/2700 (epoch 41.630), train_loss = 3.22208899, grad/param norm = 7.7169e-01, time/batch = 0.1792s	
2249/2700 (epoch 41.648), train_loss = 3.29694737, grad/param norm = 8.4774e-01, time/batch = 0.1818s	
2250/2700 (epoch 41.667), train_loss = 3.23237019, grad/param norm = 8.4443e-01, time/batch = 0.1860s	
2251/2700 (epoch 41.685), train_loss = 3.22396741, grad/param norm = 7.8368e-01, time/batch = 0.1803s	
2252/2700 (epoch 41.704), train_loss = 3.19952401, grad/param norm = 9.2556e-01, time/batch = 0.1854s	
2253/2700 (epoch 41.722), train_loss = 3.18888296, grad/param norm = 7.5803e-01, time/batch = 0.1779s	
2254/2700 (epoch 41.741), train_loss = 3.31872666, grad/param norm = 6.9426e-01, time/batch = 0.1869s	
2255/2700 (epoch 41.759), train_loss = 3.27111855, grad/param norm = 9.0214e-01, time/batch = 0.1799s	
2256/2700 (epoch 41.778), train_loss = 3.27327538, grad/param norm = 1.1921e+00, time/batch = 0.1856s	
2257/2700 (epoch 41.796), train_loss = 3.27541472, grad/param norm = 1.2941e+00, time/batch = 0.1861s	
2258/2700 (epoch 41.815), train_loss = 3.21872661, grad/param norm = 1.2222e+00, time/batch = 0.1852s	
2259/2700 (epoch 41.833), train_loss = 3.25794210, grad/param norm = 1.3362e+00, time/batch = 0.1866s	
2260/2700 (epoch 41.852), train_loss = 3.24806931, grad/param norm = 1.3694e+00, time/batch = 0.1792s	
2261/2700 (epoch 41.870), train_loss = 3.23900157, grad/param norm = 1.1645e+00, time/batch = 0.1781s	
2262/2700 (epoch 41.889), train_loss = 3.26621881, grad/param norm = 1.0142e+00, time/batch = 0.1671s	
2263/2700 (epoch 41.907), train_loss = 3.31531750, grad/param norm = 1.0422e+00, time/batch = 0.1783s	
2264/2700 (epoch 41.926), train_loss = 3.27296730, grad/param norm = 1.1204e+00, time/batch = 0.1790s	
2265/2700 (epoch 41.944), train_loss = 3.28190661, grad/param norm = 9.2299e-01, time/batch = 0.1797s	
2266/2700 (epoch 41.963), train_loss = 3.35239660, grad/param norm = 8.2566e-01, time/batch = 0.1785s	
2267/2700 (epoch 41.981), train_loss = 3.41207648, grad/param norm = 8.5868e-01, time/batch = 0.1858s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2268/2700 (epoch 42.000), train_loss = 3.31683861, grad/param norm = 8.4996e-01, time/batch = 0.1864s	
2269/2700 (epoch 42.019), train_loss = 3.25357176, grad/param norm = 9.1815e-01, time/batch = 0.1862s	
2270/2700 (epoch 42.037), train_loss = 3.27119762, grad/param norm = 8.6413e-01, time/batch = 0.1869s	
2271/2700 (epoch 42.056), train_loss = 3.26637024, grad/param norm = 6.2116e-01, time/batch = 0.1691s	
2272/2700 (epoch 42.074), train_loss = 3.29796126, grad/param norm = 7.0526e-01, time/batch = 0.1426s	
2273/2700 (epoch 42.093), train_loss = 3.30765326, grad/param norm = 8.3933e-01, time/batch = 0.1693s	
2274/2700 (epoch 42.111), train_loss = 3.27881258, grad/param norm = 8.0509e-01, time/batch = 0.1560s	
2275/2700 (epoch 42.130), train_loss = 3.29652215, grad/param norm = 7.2438e-01, time/batch = 0.1693s	
2276/2700 (epoch 42.148), train_loss = 3.25514409, grad/param norm = 8.8605e-01, time/batch = 0.1684s	
2277/2700 (epoch 42.167), train_loss = 3.27484843, grad/param norm = 1.0619e+00, time/batch = 0.1675s	
2278/2700 (epoch 42.185), train_loss = 3.25427190, grad/param norm = 8.2062e-01, time/batch = 0.1702s	
2279/2700 (epoch 42.204), train_loss = 3.18504733, grad/param norm = 8.7879e-01, time/batch = 0.1742s	
2280/2700 (epoch 42.222), train_loss = 3.16559019, grad/param norm = 1.1151e+00, time/batch = 0.1798s	
2281/2700 (epoch 42.241), train_loss = 3.18801042, grad/param norm = 1.1595e+00, time/batch = 0.1703s	
2282/2700 (epoch 42.259), train_loss = 3.22611385, grad/param norm = 1.3846e+00, time/batch = 0.1710s	
2283/2700 (epoch 42.278), train_loss = 3.30045828, grad/param norm = 1.3063e+00, time/batch = 0.1448s	
2284/2700 (epoch 42.296), train_loss = 3.30061044, grad/param norm = 1.2717e+00, time/batch = 0.1857s	
2285/2700 (epoch 42.315), train_loss = 3.27556352, grad/param norm = 1.1525e+00, time/batch = 0.1846s	
2286/2700 (epoch 42.333), train_loss = 3.35264410, grad/param norm = 9.9148e-01, time/batch = 0.1859s	
2287/2700 (epoch 42.352), train_loss = 3.36064731, grad/param norm = 9.6412e-01, time/batch = 0.1835s	
2288/2700 (epoch 42.370), train_loss = 3.30346981, grad/param norm = 8.2899e-01, time/batch = 0.1721s	
2289/2700 (epoch 42.389), train_loss = 3.26120222, grad/param norm = 6.6119e-01, time/batch = 0.1726s	
2290/2700 (epoch 42.407), train_loss = 3.28396117, grad/param norm = 5.9061e-01, time/batch = 0.1795s	
2291/2700 (epoch 42.426), train_loss = 3.28741367, grad/param norm = 6.2745e-01, time/batch = 0.1525s	
2292/2700 (epoch 42.444), train_loss = 3.21146766, grad/param norm = 5.9430e-01, time/batch = 0.1819s	
2293/2700 (epoch 42.463), train_loss = 3.25712640, grad/param norm = 6.7128e-01, time/batch = 0.1876s	
2294/2700 (epoch 42.481), train_loss = 3.33175269, grad/param norm = 5.7266e-01, time/batch = 0.1859s	
2295/2700 (epoch 42.500), train_loss = 3.37793303, grad/param norm = 7.8900e-01, time/batch = 0.1812s	
2296/2700 (epoch 42.519), train_loss = 3.33491360, grad/param norm = 9.3281e-01, time/batch = 0.1697s	
2297/2700 (epoch 42.537), train_loss = 3.34277083, grad/param norm = 1.0531e+00, time/batch = 0.1680s	
2298/2700 (epoch 42.556), train_loss = 3.28101811, grad/param norm = 9.2961e-01, time/batch = 0.1736s	
2299/2700 (epoch 42.574), train_loss = 3.23694363, grad/param norm = 8.4712e-01, time/batch = 0.1801s	
2300/2700 (epoch 42.593), train_loss = 3.24649885, grad/param norm = 1.0941e+00, time/batch = 0.1781s	
2301/2700 (epoch 42.611), train_loss = 3.18873300, grad/param norm = 1.0371e+00, time/batch = 0.1686s	
2302/2700 (epoch 42.630), train_loss = 3.23046149, grad/param norm = 1.1480e+00, time/batch = 0.1475s	
2303/2700 (epoch 42.648), train_loss = 3.30640222, grad/param norm = 1.2099e+00, time/batch = 0.1851s	
2304/2700 (epoch 42.667), train_loss = 3.23811237, grad/param norm = 1.1636e+00, time/batch = 0.1861s	
2305/2700 (epoch 42.685), train_loss = 3.22733854, grad/param norm = 9.6587e-01, time/batch = 0.1792s	
2306/2700 (epoch 42.704), train_loss = 3.20123400, grad/param norm = 1.0484e+00, time/batch = 0.1713s	
2307/2700 (epoch 42.722), train_loss = 3.19077737, grad/param norm = 8.5977e-01, time/batch = 0.1731s	
2308/2700 (epoch 42.741), train_loss = 3.31856242, grad/param norm = 7.1611e-01, time/batch = 0.1790s	
2309/2700 (epoch 42.759), train_loss = 3.27076404, grad/param norm = 9.1236e-01, time/batch = 0.1829s	
2310/2700 (epoch 42.778), train_loss = 3.26938408, grad/param norm = 1.1245e+00, time/batch = 0.1753s	
2311/2700 (epoch 42.796), train_loss = 3.26663645, grad/param norm = 1.1395e+00, time/batch = 0.1639s	
2312/2700 (epoch 42.815), train_loss = 3.21256310, grad/param norm = 1.0256e+00, time/batch = 0.1693s	
2313/2700 (epoch 42.833), train_loss = 3.24982787, grad/param norm = 1.0195e+00, time/batch = 0.1684s	
2314/2700 (epoch 42.852), train_loss = 3.23769695, grad/param norm = 1.0533e+00, time/batch = 0.1730s	
2315/2700 (epoch 42.870), train_loss = 3.23308822, grad/param norm = 9.4600e-01, time/batch = 0.1800s	
2316/2700 (epoch 42.889), train_loss = 3.26229560, grad/param norm = 8.6691e-01, time/batch = 0.1792s	
2317/2700 (epoch 42.907), train_loss = 3.31417599, grad/param norm = 1.0018e+00, time/batch = 0.1832s	
2318/2700 (epoch 42.926), train_loss = 3.27218632, grad/param norm = 1.1180e+00, time/batch = 0.1874s	
2319/2700 (epoch 42.944), train_loss = 3.28144270, grad/param norm = 9.4243e-01, time/batch = 0.1828s	
2320/2700 (epoch 42.963), train_loss = 3.35266690, grad/param norm = 8.5016e-01, time/batch = 0.1742s	
2321/2700 (epoch 42.981), train_loss = 3.41181537, grad/param norm = 8.6773e-01, time/batch = 0.1634s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
2322/2700 (epoch 43.000), train_loss = 3.31610546, grad/param norm = 8.5862e-01, time/batch = 0.1699s	
2323/2700 (epoch 43.019), train_loss = 3.25407375, grad/param norm = 9.4369e-01, time/batch = 0.1677s	
2324/2700 (epoch 43.037), train_loss = 3.27112729, grad/param norm = 8.9276e-01, time/batch = 0.1702s	
2325/2700 (epoch 43.056), train_loss = 3.26592356, grad/param norm = 6.1483e-01, time/batch = 0.1787s	
2326/2700 (epoch 43.074), train_loss = 3.29675981, grad/param norm = 6.4626e-01, time/batch = 0.1791s	
2327/2700 (epoch 43.093), train_loss = 3.30619936, grad/param norm = 7.8838e-01, time/batch = 0.1821s	
2328/2700 (epoch 43.111), train_loss = 3.27761863, grad/param norm = 7.7254e-01, time/batch = 0.1856s	
2329/2700 (epoch 43.130), train_loss = 3.29563217, grad/param norm = 7.0026e-01, time/batch = 0.1795s	
2330/2700 (epoch 43.148), train_loss = 3.25440294, grad/param norm = 8.6699e-01, time/batch = 0.1788s	
2331/2700 (epoch 43.167), train_loss = 3.27303245, grad/param norm = 1.0144e+00, time/batch = 0.1781s	
2332/2700 (epoch 43.185), train_loss = 3.25234616, grad/param norm = 7.5390e-01, time/batch = 0.1753s	
2333/2700 (epoch 43.204), train_loss = 3.18293646, grad/param norm = 7.8168e-01, time/batch = 0.1696s	
2334/2700 (epoch 43.222), train_loss = 3.16232553, grad/param norm = 1.0167e+00, time/batch = 0.1679s	
2335/2700 (epoch 43.241), train_loss = 3.18480389, grad/param norm = 1.0665e+00, time/batch = 0.1688s	
2336/2700 (epoch 43.259), train_loss = 3.22582549, grad/param norm = 1.4250e+00, time/batch = 0.1739s	
2337/2700 (epoch 43.278), train_loss = 3.30348089, grad/param norm = 1.3995e+00, time/batch = 0.1799s	
2338/2700 (epoch 43.296), train_loss = 3.30165385, grad/param norm = 1.3367e+00, time/batch = 0.1742s	
2339/2700 (epoch 43.315), train_loss = 3.27617673, grad/param norm = 1.1898e+00, time/batch = 0.1716s	
2340/2700 (epoch 43.333), train_loss = 3.35206018, grad/param norm = 9.8898e-01, time/batch = 0.1806s	
2341/2700 (epoch 43.352), train_loss = 3.35955755, grad/param norm = 9.4540e-01, time/batch = 0.1838s	
2342/2700 (epoch 43.370), train_loss = 3.30189736, grad/param norm = 8.0994e-01, time/batch = 0.1725s	
2343/2700 (epoch 43.389), train_loss = 3.26037170, grad/param norm = 6.4064e-01, time/batch = 0.1708s	
2344/2700 (epoch 43.407), train_loss = 3.28310740, grad/param norm = 5.7554e-01, time/batch = 0.1683s	
2345/2700 (epoch 43.426), train_loss = 3.28655312, grad/param norm = 6.1114e-01, time/batch = 0.1748s	
2346/2700 (epoch 43.444), train_loss = 3.21068262, grad/param norm = 5.6776e-01, time/batch = 0.1695s	
2347/2700 (epoch 43.463), train_loss = 3.25612146, grad/param norm = 6.4960e-01, time/batch = 0.1489s	
2348/2700 (epoch 43.481), train_loss = 3.33123448, grad/param norm = 5.7284e-01, time/batch = 0.1755s	
2349/2700 (epoch 43.500), train_loss = 3.37807701, grad/param norm = 8.0712e-01, time/batch = 0.1732s	
2350/2700 (epoch 43.519), train_loss = 3.33490503, grad/param norm = 9.3891e-01, time/batch = 0.1734s	
2351/2700 (epoch 43.537), train_loss = 3.34181007, grad/param norm = 1.0333e+00, time/batch = 0.1831s	
2352/2700 (epoch 43.556), train_loss = 3.27908648, grad/param norm = 8.8497e-01, time/batch = 0.1702s	
2353/2700 (epoch 43.574), train_loss = 3.23578080, grad/param norm = 7.9377e-01, time/batch = 0.1743s	
2354/2700 (epoch 43.593), train_loss = 3.24450356, grad/param norm = 1.0314e+00, time/batch = 0.1791s	
2355/2700 (epoch 43.611), train_loss = 3.18607018, grad/param norm = 9.5662e-01, time/batch = 0.1790s	
2356/2700 (epoch 43.630), train_loss = 3.22783814, grad/param norm = 1.0653e+00, time/batch = 0.1640s	
2357/2700 (epoch 43.648), train_loss = 3.30353239, grad/param norm = 1.1382e+00, time/batch = 0.1728s	
2358/2700 (epoch 43.667), train_loss = 3.23585905, grad/param norm = 1.1128e+00, time/batch = 0.1788s	
2359/2700 (epoch 43.685), train_loss = 3.22607892, grad/param norm = 9.4255e-01, time/batch = 0.1790s	
2360/2700 (epoch 43.704), train_loss = 3.20004021, grad/param norm = 1.0338e+00, time/batch = 0.1780s	
2361/2700 (epoch 43.722), train_loss = 3.18977987, grad/param norm = 8.5321e-01, time/batch = 0.1759s	
2362/2700 (epoch 43.741), train_loss = 3.31782273, grad/param norm = 7.1335e-01, time/batch = 0.1705s	
2363/2700 (epoch 43.759), train_loss = 3.27009978, grad/param norm = 9.1215e-01, time/batch = 0.1678s	
2364/2700 (epoch 43.778), train_loss = 3.26838072, grad/param norm = 1.1191e+00, time/batch = 0.1580s	
2365/2700 (epoch 43.796), train_loss = 3.26538021, grad/param norm = 1.1401e+00, time/batch = 0.1574s	
2366/2700 (epoch 43.815), train_loss = 3.21176996, grad/param norm = 1.0260e+00, time/batch = 0.1274s	
2367/2700 (epoch 43.833), train_loss = 3.24892510, grad/param norm = 1.0150e+00, time/batch = 0.1428s	
2368/2700 (epoch 43.852), train_loss = 3.23670477, grad/param norm = 1.0414e+00, time/batch = 0.1724s	
2369/2700 (epoch 43.870), train_loss = 3.23154884, grad/param norm = 9.1882e-01, time/batch = 0.1696s	
2370/2700 (epoch 43.889), train_loss = 3.26117190, grad/param norm = 8.3488e-01, time/batch = 0.1705s	
2371/2700 (epoch 43.907), train_loss = 3.31329276, grad/param norm = 9.7005e-01, time/batch = 0.1658s	
2372/2700 (epoch 43.926), train_loss = 3.27066294, grad/param norm = 1.0808e+00, time/batch = 0.1664s	
2373/2700 (epoch 43.944), train_loss = 3.27985102, grad/param norm = 9.1299e-01, time/batch = 0.1670s	
2374/2700 (epoch 43.963), train_loss = 3.35182875, grad/param norm = 8.2841e-01, time/batch = 0.1692s	
2375/2700 (epoch 43.981), train_loss = 3.41110878, grad/param norm = 8.5169e-01, time/batch = 0.1740s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
2376/2700 (epoch 44.000), train_loss = 3.31501135, grad/param norm = 8.3932e-01, time/batch = 0.1264s	
2377/2700 (epoch 44.019), train_loss = 3.25322629, grad/param norm = 9.2223e-01, time/batch = 0.1771s	
2378/2700 (epoch 44.037), train_loss = 3.26996669, grad/param norm = 8.6538e-01, time/batch = 0.1741s	
2379/2700 (epoch 44.056), train_loss = 3.26523564, grad/param norm = 5.9919e-01, time/batch = 0.1677s	
2380/2700 (epoch 44.074), train_loss = 3.29647571, grad/param norm = 6.5371e-01, time/batch = 0.1651s	
2381/2700 (epoch 44.093), train_loss = 3.30561471, grad/param norm = 7.9292e-01, time/batch = 0.1787s	
2382/2700 (epoch 44.111), train_loss = 3.27679308, grad/param norm = 7.6704e-01, time/batch = 0.1729s	
2383/2700 (epoch 44.130), train_loss = 3.29459167, grad/param norm = 6.9278e-01, time/batch = 0.1713s	
2384/2700 (epoch 44.148), train_loss = 3.25370164, grad/param norm = 8.5116e-01, time/batch = 0.1754s	
2385/2700 (epoch 44.167), train_loss = 3.27181947, grad/param norm = 1.0118e+00, time/batch = 0.1680s	
2386/2700 (epoch 44.185), train_loss = 3.25176603, grad/param norm = 7.6374e-01, time/batch = 0.1741s	
2387/2700 (epoch 44.204), train_loss = 3.18308447, grad/param norm = 8.2530e-01, time/batch = 0.1782s	
2388/2700 (epoch 44.222), train_loss = 3.16334147, grad/param norm = 1.0756e+00, time/batch = 0.1791s	
2389/2700 (epoch 44.241), train_loss = 3.18651702, grad/param norm = 1.1562e+00, time/batch = 0.1790s	
2390/2700 (epoch 44.259), train_loss = 3.22523813, grad/param norm = 1.4292e+00, time/batch = 0.1791s	
2391/2700 (epoch 44.278), train_loss = 3.29972930, grad/param norm = 1.3112e+00, time/batch = 0.1788s	
2392/2700 (epoch 44.296), train_loss = 3.29827291, grad/param norm = 1.2206e+00, time/batch = 0.1787s	
2393/2700 (epoch 44.315), train_loss = 3.27294205, grad/param norm = 1.0924e+00, time/batch = 0.1792s	
2394/2700 (epoch 44.333), train_loss = 3.35008059, grad/param norm = 9.2961e-01, time/batch = 0.1691s	
2395/2700 (epoch 44.352), train_loss = 3.35739657, grad/param norm = 8.9623e-01, time/batch = 0.1370s	
2396/2700 (epoch 44.370), train_loss = 3.30005026, grad/param norm = 7.8045e-01, time/batch = 0.1478s	
2397/2700 (epoch 44.389), train_loss = 3.25963151, grad/param norm = 6.2276e-01, time/batch = 0.1312s	
2398/2700 (epoch 44.407), train_loss = 3.28243219, grad/param norm = 5.6497e-01, time/batch = 0.1152s	
2399/2700 (epoch 44.426), train_loss = 3.28589813, grad/param norm = 6.0194e-01, time/batch = 0.1058s	
2400/2700 (epoch 44.444), train_loss = 3.21050927, grad/param norm = 5.6725e-01, time/batch = 0.1073s	
2401/2700 (epoch 44.463), train_loss = 3.25580818, grad/param norm = 6.5223e-01, time/batch = 0.1147s	
2402/2700 (epoch 44.481), train_loss = 3.33076258, grad/param norm = 5.7443e-01, time/batch = 0.1066s	
2403/2700 (epoch 44.500), train_loss = 3.37765909, grad/param norm = 8.1370e-01, time/batch = 0.1073s	
2404/2700 (epoch 44.519), train_loss = 3.33431960, grad/param norm = 9.3879e-01, time/batch = 0.0792s	
2405/2700 (epoch 44.537), train_loss = 3.34087020, grad/param norm = 1.0234e+00, time/batch = 0.1156s	
2406/2700 (epoch 44.556), train_loss = 3.27780872, grad/param norm = 8.6695e-01, time/batch = 0.1067s	
2407/2700 (epoch 44.574), train_loss = 3.23555666, grad/param norm = 7.7671e-01, time/batch = 0.1103s	
2408/2700 (epoch 44.593), train_loss = 3.24371344, grad/param norm = 1.0084e+00, time/batch = 0.1155s	
2409/2700 (epoch 44.611), train_loss = 3.18480149, grad/param norm = 9.1809e-01, time/batch = 0.1147s	
2410/2700 (epoch 44.630), train_loss = 3.22607497, grad/param norm = 1.0124e+00, time/batch = 0.1151s	
2411/2700 (epoch 44.648), train_loss = 3.30136105, grad/param norm = 1.0838e+00, time/batch = 0.1068s	
2412/2700 (epoch 44.667), train_loss = 3.23370821, grad/param norm = 1.0601e+00, time/batch = 0.1074s	
2413/2700 (epoch 44.685), train_loss = 3.22448824, grad/param norm = 9.0159e-01, time/batch = 0.0745s	
2414/2700 (epoch 44.704), train_loss = 3.19832931, grad/param norm = 9.9701e-01, time/batch = 0.1147s	
2415/2700 (epoch 44.722), train_loss = 3.18827126, grad/param norm = 8.2065e-01, time/batch = 0.1155s	
2416/2700 (epoch 44.741), train_loss = 3.31676766, grad/param norm = 6.9190e-01, time/batch = 0.1129s	
2417/2700 (epoch 44.759), train_loss = 3.26903000, grad/param norm = 8.9394e-01, time/batch = 0.1066s	
2418/2700 (epoch 44.778), train_loss = 3.26706154, grad/param norm = 1.0956e+00, time/batch = 0.1102s	
2419/2700 (epoch 44.796), train_loss = 3.26378304, grad/param norm = 1.1226e+00, time/batch = 0.1154s	
2420/2700 (epoch 44.815), train_loss = 3.21078936, grad/param norm = 1.0131e+00, time/batch = 0.1149s	
2421/2700 (epoch 44.833), train_loss = 3.24792627, grad/param norm = 1.0052e+00, time/batch = 0.1090s	
2422/2700 (epoch 44.852), train_loss = 3.23576143, grad/param norm = 1.0311e+00, time/batch = 0.0807s	
2423/2700 (epoch 44.870), train_loss = 3.23023353, grad/param norm = 9.0311e-01, time/batch = 0.1154s	
2424/2700 (epoch 44.889), train_loss = 3.26047410, grad/param norm = 8.2094e-01, time/batch = 0.1148s	
2425/2700 (epoch 44.907), train_loss = 3.31275840, grad/param norm = 9.5585e-01, time/batch = 0.1154s	
2426/2700 (epoch 44.926), train_loss = 3.26941459, grad/param norm = 1.0545e+00, time/batch = 0.1151s	
2427/2700 (epoch 44.944), train_loss = 3.27833740, grad/param norm = 8.8782e-01, time/batch = 0.1143s	
2428/2700 (epoch 44.963), train_loss = 3.35094168, grad/param norm = 8.0869e-01, time/batch = 0.1056s	
2429/2700 (epoch 44.981), train_loss = 3.41045635, grad/param norm = 8.3736e-01, time/batch = 0.1049s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
2430/2700 (epoch 45.000), train_loss = 3.31402384, grad/param norm = 8.2432e-01, time/batch = 0.1116s	
2431/2700 (epoch 45.019), train_loss = 3.25246693, grad/param norm = 9.0466e-01, time/batch = 0.0969s	
2432/2700 (epoch 45.037), train_loss = 3.26892550, grad/param norm = 8.4300e-01, time/batch = 0.1147s	
2433/2700 (epoch 45.056), train_loss = 3.26464015, grad/param norm = 5.8739e-01, time/batch = 0.1149s	
2434/2700 (epoch 45.074), train_loss = 3.29621358, grad/param norm = 6.6094e-01, time/batch = 0.1148s	
2435/2700 (epoch 45.093), train_loss = 3.30503306, grad/param norm = 7.9541e-01, time/batch = 0.1147s	
2436/2700 (epoch 45.111), train_loss = 3.27598228, grad/param norm = 7.6064e-01, time/batch = 0.1148s	
2437/2700 (epoch 45.130), train_loss = 3.29360057, grad/param norm = 6.8422e-01, time/batch = 0.1148s	
2438/2700 (epoch 45.148), train_loss = 3.25299646, grad/param norm = 8.3519e-01, time/batch = 0.1074s	
2439/2700 (epoch 45.167), train_loss = 3.27057715, grad/param norm = 1.0026e+00, time/batch = 0.1071s	
2440/2700 (epoch 45.185), train_loss = 3.25098907, grad/param norm = 7.6079e-01, time/batch = 0.1160s	
2441/2700 (epoch 45.204), train_loss = 3.18276139, grad/param norm = 8.3354e-01, time/batch = 0.0877s	
2442/2700 (epoch 45.222), train_loss = 3.16310125, grad/param norm = 1.0790e+00, time/batch = 0.0740s	
2443/2700 (epoch 45.241), train_loss = 3.18565331, grad/param norm = 1.1414e+00, time/batch = 0.0772s	
2444/2700 (epoch 45.259), train_loss = 3.22283442, grad/param norm = 1.3513e+00, time/batch = 0.0610s	
2445/2700 (epoch 45.278), train_loss = 3.29660185, grad/param norm = 1.2324e+00, time/batch = 0.0596s	
2446/2700 (epoch 45.296), train_loss = 3.29668344, grad/param norm = 1.1771e+00, time/batch = 0.0589s	
2447/2700 (epoch 45.315), train_loss = 3.27164909, grad/param norm = 1.0621e+00, time/batch = 0.0603s	
2448/2700 (epoch 45.333), train_loss = 3.34900701, grad/param norm = 9.0901e-01, time/batch = 0.0587s	
2449/2700 (epoch 45.352), train_loss = 3.35609426, grad/param norm = 8.7543e-01, time/batch = 0.0589s	
2450/2700 (epoch 45.370), train_loss = 3.29873255, grad/param norm = 7.6410e-01, time/batch = 0.0591s	
2451/2700 (epoch 45.389), train_loss = 3.25894927, grad/param norm = 6.0763e-01, time/batch = 0.0595s	
2452/2700 (epoch 45.407), train_loss = 3.28176206, grad/param norm = 5.5378e-01, time/batch = 0.0585s	
2453/2700 (epoch 45.426), train_loss = 3.28523984, grad/param norm = 5.9269e-01, time/batch = 0.0584s	
2454/2700 (epoch 45.444), train_loss = 3.21017762, grad/param norm = 5.5758e-01, time/batch = 0.0587s	
2455/2700 (epoch 45.463), train_loss = 3.25525532, grad/param norm = 6.4399e-01, time/batch = 0.0596s	
2456/2700 (epoch 45.481), train_loss = 3.33024704, grad/param norm = 5.6949e-01, time/batch = 0.0585s	
2457/2700 (epoch 45.500), train_loss = 3.37734254, grad/param norm = 8.1596e-01, time/batch = 0.0586s	
2458/2700 (epoch 45.519), train_loss = 3.33388097, grad/param norm = 9.3516e-01, time/batch = 0.0586s	
2459/2700 (epoch 45.537), train_loss = 3.33996747, grad/param norm = 1.0103e+00, time/batch = 0.0593s	
2460/2700 (epoch 45.556), train_loss = 3.27653226, grad/param norm = 8.4714e-01, time/batch = 0.0588s	
2461/2700 (epoch 45.574), train_loss = 3.23521273, grad/param norm = 7.5915e-01, time/batch = 0.0593s	
2462/2700 (epoch 45.593), train_loss = 3.24280059, grad/param norm = 9.8477e-01, time/batch = 0.0584s	
2463/2700 (epoch 45.611), train_loss = 3.18348231, grad/param norm = 8.8144e-01, time/batch = 0.0600s	
2464/2700 (epoch 45.630), train_loss = 3.22459345, grad/param norm = 9.6904e-01, time/batch = 0.0595s	
2465/2700 (epoch 45.648), train_loss = 3.29954407, grad/param norm = 1.0393e+00, time/batch = 0.0591s	
2466/2700 (epoch 45.667), train_loss = 3.23184350, grad/param norm = 1.0158e+00, time/batch = 0.0585s	
2467/2700 (epoch 45.685), train_loss = 3.22313346, grad/param norm = 8.6777e-01, time/batch = 0.0586s	
2468/2700 (epoch 45.704), train_loss = 3.19691622, grad/param norm = 9.6737e-01, time/batch = 0.0593s	
2469/2700 (epoch 45.722), train_loss = 3.18700764, grad/param norm = 7.9346e-01, time/batch = 0.0590s	
2470/2700 (epoch 45.741), train_loss = 3.31587163, grad/param norm = 6.7417e-01, time/batch = 0.0591s	
2471/2700 (epoch 45.759), train_loss = 3.26809935, grad/param norm = 8.7830e-01, time/batch = 0.0595s	
2472/2700 (epoch 45.778), train_loss = 3.26578092, grad/param norm = 1.0723e+00, time/batch = 0.0583s	
2473/2700 (epoch 45.796), train_loss = 3.26219338, grad/param norm = 1.1034e+00, time/batch = 0.0593s	
2474/2700 (epoch 45.815), train_loss = 3.20978422, grad/param norm = 9.9714e-01, time/batch = 0.0587s	
2475/2700 (epoch 45.833), train_loss = 3.24689366, grad/param norm = 9.9136e-01, time/batch = 0.0588s	
2476/2700 (epoch 45.852), train_loss = 3.23473963, grad/param norm = 1.0164e+00, time/batch = 0.0586s	
2477/2700 (epoch 45.870), train_loss = 3.22890541, grad/param norm = 8.8399e-01, time/batch = 0.0588s	
2478/2700 (epoch 45.889), train_loss = 3.25977139, grad/param norm = 8.0494e-01, time/batch = 0.0596s	
2479/2700 (epoch 45.907), train_loss = 3.31223878, grad/param norm = 9.4120e-01, time/batch = 0.0590s	
2480/2700 (epoch 45.926), train_loss = 3.26818655, grad/param norm = 1.0283e+00, time/batch = 0.0585s	
2481/2700 (epoch 45.944), train_loss = 3.27690438, grad/param norm = 8.6385e-01, time/batch = 0.0592s	
2482/2700 (epoch 45.963), train_loss = 3.35013416, grad/param norm = 7.9054e-01, time/batch = 0.0595s	
2483/2700 (epoch 45.981), train_loss = 3.40985226, grad/param norm = 8.2378e-01, time/batch = 0.0586s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
2484/2700 (epoch 46.000), train_loss = 3.31306512, grad/param norm = 8.1028e-01, time/batch = 0.0586s	
2485/2700 (epoch 46.019), train_loss = 3.25173637, grad/param norm = 8.8849e-01, time/batch = 0.0589s	
2486/2700 (epoch 46.037), train_loss = 3.26794995, grad/param norm = 8.2257e-01, time/batch = 0.0587s	
2487/2700 (epoch 46.056), train_loss = 3.26409745, grad/param norm = 5.7732e-01, time/batch = 0.0602s	
2488/2700 (epoch 46.074), train_loss = 3.29595105, grad/param norm = 6.6766e-01, time/batch = 0.0595s	
2489/2700 (epoch 46.093), train_loss = 3.30446367, grad/param norm = 7.9701e-01, time/batch = 0.0595s	
2490/2700 (epoch 46.111), train_loss = 3.27519686, grad/param norm = 7.5379e-01, time/batch = 0.0595s	
2491/2700 (epoch 46.130), train_loss = 3.29264080, grad/param norm = 6.7478e-01, time/batch = 0.0608s	
2492/2700 (epoch 46.148), train_loss = 3.25229497, grad/param norm = 8.1847e-01, time/batch = 0.0604s	
2493/2700 (epoch 46.167), train_loss = 3.26935430, grad/param norm = 9.9023e-01, time/batch = 0.0594s	
2494/2700 (epoch 46.185), train_loss = 3.25014802, grad/param norm = 7.5091e-01, time/batch = 0.0603s	
2495/2700 (epoch 46.204), train_loss = 3.18224647, grad/param norm = 8.2701e-01, time/batch = 0.0589s	
2496/2700 (epoch 46.222), train_loss = 3.16245665, grad/param norm = 1.0641e+00, time/batch = 0.0594s	
2497/2700 (epoch 46.241), train_loss = 3.18424210, grad/param norm = 1.1037e+00, time/batch = 0.0588s	
2498/2700 (epoch 46.259), train_loss = 3.22056870, grad/param norm = 1.2756e+00, time/batch = 0.0588s	
2499/2700 (epoch 46.278), train_loss = 3.29420142, grad/param norm = 1.1696e+00, time/batch = 0.0598s	
2500/2700 (epoch 46.296), train_loss = 3.29545919, grad/param norm = 1.1473e+00, time/batch = 0.0584s	
2501/2700 (epoch 46.315), train_loss = 3.27065621, grad/param norm = 1.0425e+00, time/batch = 0.0599s	
2502/2700 (epoch 46.333), train_loss = 3.34810530, grad/param norm = 8.9461e-01, time/batch = 0.0584s	
2503/2700 (epoch 46.352), train_loss = 3.35499109, grad/param norm = 8.5972e-01, time/batch = 0.0583s	
2504/2700 (epoch 46.370), train_loss = 3.29757066, grad/param norm = 7.5067e-01, time/batch = 0.0584s	
2505/2700 (epoch 46.389), train_loss = 3.25831716, grad/param norm = 5.9352e-01, time/batch = 0.0594s	
2506/2700 (epoch 46.407), train_loss = 3.28112823, grad/param norm = 5.4304e-01, time/batch = 0.0605s	
2507/2700 (epoch 46.426), train_loss = 3.28460039, grad/param norm = 5.8350e-01, time/batch = 0.0588s	
2508/2700 (epoch 46.444), train_loss = 3.20981834, grad/param norm = 5.4573e-01, time/batch = 0.0588s	
2509/2700 (epoch 46.463), train_loss = 3.25466827, grad/param norm = 6.3343e-01, time/batch = 0.0588s	
2510/2700 (epoch 46.481), train_loss = 3.32975858, grad/param norm = 5.6408e-01, time/batch = 0.0593s	
2511/2700 (epoch 46.500), train_loss = 3.37707610, grad/param norm = 8.1810e-01, time/batch = 0.0596s	
2512/2700 (epoch 46.519), train_loss = 3.33348124, grad/param norm = 9.3076e-01, time/batch = 0.0584s	
2513/2700 (epoch 46.537), train_loss = 3.33908322, grad/param norm = 9.9621e-01, time/batch = 0.0582s	
2514/2700 (epoch 46.556), train_loss = 3.27530837, grad/param norm = 8.2704e-01, time/batch = 0.0590s	
2515/2700 (epoch 46.574), train_loss = 3.23487203, grad/param norm = 7.4180e-01, time/batch = 0.0591s	
2516/2700 (epoch 46.593), train_loss = 3.24188293, grad/param norm = 9.6114e-01, time/batch = 0.0586s	
2517/2700 (epoch 46.611), train_loss = 3.18220200, grad/param norm = 8.4498e-01, time/batch = 0.0585s	
2518/2700 (epoch 46.630), train_loss = 3.22322345, grad/param norm = 9.2771e-01, time/batch = 0.0585s	
2519/2700 (epoch 46.648), train_loss = 3.29785780, grad/param norm = 9.9689e-01, time/batch = 0.0601s	
2520/2700 (epoch 46.667), train_loss = 3.23009045, grad/param norm = 9.7241e-01, time/batch = 0.0587s	
2521/2700 (epoch 46.685), train_loss = 3.22187917, grad/param norm = 8.3546e-01, time/batch = 0.0595s	
2522/2700 (epoch 46.704), train_loss = 3.19562820, grad/param norm = 9.3967e-01, time/batch = 0.0583s	
2523/2700 (epoch 46.722), train_loss = 3.18585690, grad/param norm = 7.6794e-01, time/batch = 0.0588s	
2524/2700 (epoch 46.741), train_loss = 3.31506443, grad/param norm = 6.5816e-01, time/batch = 0.0596s	
2525/2700 (epoch 46.759), train_loss = 3.26725431, grad/param norm = 8.6426e-01, time/batch = 0.0588s	
2526/2700 (epoch 46.778), train_loss = 3.26458554, grad/param norm = 1.0509e+00, time/batch = 0.0594s	
2527/2700 (epoch 46.796), train_loss = 3.26071891, grad/param norm = 1.0855e+00, time/batch = 0.0586s	
2528/2700 (epoch 46.815), train_loss = 3.20882323, grad/param norm = 9.8168e-01, time/batch = 0.0595s	
2529/2700 (epoch 46.833), train_loss = 3.24591054, grad/param norm = 9.7801e-01, time/batch = 0.0602s	
2530/2700 (epoch 46.852), train_loss = 3.23376430, grad/param norm = 1.0021e+00, time/batch = 0.0586s	
2531/2700 (epoch 46.870), train_loss = 3.22763337, grad/param norm = 8.6483e-01, time/batch = 0.0592s	
2532/2700 (epoch 46.889), train_loss = 3.25910708, grad/param norm = 7.8914e-01, time/batch = 0.0626s	
2533/2700 (epoch 46.907), train_loss = 3.31174153, grad/param norm = 9.2669e-01, time/batch = 0.0592s	
2534/2700 (epoch 46.926), train_loss = 3.26697945, grad/param norm = 1.0020e+00, time/batch = 0.0585s	
2535/2700 (epoch 46.944), train_loss = 3.27553668, grad/param norm = 8.4023e-01, time/batch = 0.0587s	
2536/2700 (epoch 46.963), train_loss = 3.34936658, grad/param norm = 7.7279e-01, time/batch = 0.0585s	
2537/2700 (epoch 46.981), train_loss = 3.40927950, grad/param norm = 8.1050e-01, time/batch = 0.0590s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
2538/2700 (epoch 47.000), train_loss = 3.31214050, grad/param norm = 7.9680e-01, time/batch = 0.0587s	
2539/2700 (epoch 47.019), train_loss = 3.25101691, grad/param norm = 8.7297e-01, time/batch = 0.0598s	
2540/2700 (epoch 47.037), train_loss = 3.26702649, grad/param norm = 8.0313e-01, time/batch = 0.0590s	
2541/2700 (epoch 47.056), train_loss = 3.26360290, grad/param norm = 5.6892e-01, time/batch = 0.0591s	
2542/2700 (epoch 47.074), train_loss = 3.29571125, grad/param norm = 6.7526e-01, time/batch = 0.0593s	
2543/2700 (epoch 47.093), train_loss = 3.30392282, grad/param norm = 7.9890e-01, time/batch = 0.0588s	
2544/2700 (epoch 47.111), train_loss = 3.27444576, grad/param norm = 7.4703e-01, time/batch = 0.0585s	
2545/2700 (epoch 47.130), train_loss = 3.29170869, grad/param norm = 6.6484e-01, time/batch = 0.0587s	
2546/2700 (epoch 47.148), train_loss = 3.25159962, grad/param norm = 8.0079e-01, time/batch = 0.0585s	
2547/2700 (epoch 47.167), train_loss = 3.26814473, grad/param norm = 9.7552e-01, time/batch = 0.0591s	
2548/2700 (epoch 47.185), train_loss = 3.24928482, grad/param norm = 7.3663e-01, time/batch = 0.0587s	
2549/2700 (epoch 47.204), train_loss = 3.18163984, grad/param norm = 8.1232e-01, time/batch = 0.0586s	
2550/2700 (epoch 47.222), train_loss = 3.16165187, grad/param norm = 1.0410e+00, time/batch = 0.0583s	
2551/2700 (epoch 47.241), train_loss = 3.18268030, grad/param norm = 1.0568e+00, time/batch = 0.0604s	
2552/2700 (epoch 47.259), train_loss = 3.21846719, grad/param norm = 1.2027e+00, time/batch = 0.0585s	
2553/2700 (epoch 47.278), train_loss = 3.29218218, grad/param norm = 1.1148e+00, time/batch = 0.0584s	
2554/2700 (epoch 47.296), train_loss = 3.29439849, grad/param norm = 1.1232e+00, time/batch = 0.0585s	
2555/2700 (epoch 47.315), train_loss = 3.26979696, grad/param norm = 1.0274e+00, time/batch = 0.0589s	
2556/2700 (epoch 47.333), train_loss = 3.34730418, grad/param norm = 8.8339e-01, time/batch = 0.0591s	
2557/2700 (epoch 47.352), train_loss = 3.35401767, grad/param norm = 8.4715e-01, time/batch = 0.0586s	
2558/2700 (epoch 47.370), train_loss = 3.29652320, grad/param norm = 7.3924e-01, time/batch = 0.0585s	
2559/2700 (epoch 47.389), train_loss = 3.25772994, grad/param norm = 5.8035e-01, time/batch = 0.0588s	
2560/2700 (epoch 47.407), train_loss = 3.28052989, grad/param norm = 5.3288e-01, time/batch = 0.0590s	
2561/2700 (epoch 47.426), train_loss = 3.28398725, grad/param norm = 5.7463e-01, time/batch = 0.0594s	
2562/2700 (epoch 47.444), train_loss = 3.20946435, grad/param norm = 5.3317e-01, time/batch = 0.0582s	
2563/2700 (epoch 47.463), train_loss = 3.25408386, grad/param norm = 6.2194e-01, time/batch = 0.0581s	
2564/2700 (epoch 47.481), train_loss = 3.32930242, grad/param norm = 5.5863e-01, time/batch = 0.0583s	
2565/2700 (epoch 47.500), train_loss = 3.37684175, grad/param norm = 8.2005e-01, time/batch = 0.0598s	
2566/2700 (epoch 47.519), train_loss = 3.33309588, grad/param norm = 9.2544e-01, time/batch = 0.0586s	
2567/2700 (epoch 47.537), train_loss = 3.33821187, grad/param norm = 9.8132e-01, time/batch = 0.0584s	
2568/2700 (epoch 47.556), train_loss = 3.27415360, grad/param norm = 8.0735e-01, time/batch = 0.0585s	
2569/2700 (epoch 47.574), train_loss = 3.23456199, grad/param norm = 7.2551e-01, time/batch = 0.0589s	
2570/2700 (epoch 47.593), train_loss = 3.24098705, grad/param norm = 9.3814e-01, time/batch = 0.0586s	
2571/2700 (epoch 47.611), train_loss = 3.18098465, grad/param norm = 8.0923e-01, time/batch = 0.0593s	
2572/2700 (epoch 47.630), train_loss = 3.22196018, grad/param norm = 8.8850e-01, time/batch = 0.0581s	
2573/2700 (epoch 47.648), train_loss = 3.29629480, grad/param norm = 9.5645e-01, time/batch = 0.0582s	
2574/2700 (epoch 47.667), train_loss = 3.22844340, grad/param norm = 9.2992e-01, time/batch = 0.0593s	
2575/2700 (epoch 47.685), train_loss = 3.22070877, grad/param norm = 8.0405e-01, time/batch = 0.0588s	
2576/2700 (epoch 47.704), train_loss = 3.19442926, grad/param norm = 9.1309e-01, time/batch = 0.0585s	
2577/2700 (epoch 47.722), train_loss = 3.18479075, grad/param norm = 7.4329e-01, time/batch = 0.0585s	
2578/2700 (epoch 47.741), train_loss = 3.31432315, grad/param norm = 6.4320e-01, time/batch = 0.0585s	
2579/2700 (epoch 47.759), train_loss = 3.26646913, grad/param norm = 8.5116e-01, time/batch = 0.0594s	
2580/2700 (epoch 47.778), train_loss = 3.26346619, grad/param norm = 1.0308e+00, time/batch = 0.0586s	
2581/2700 (epoch 47.796), train_loss = 3.25934936, grad/param norm = 1.0685e+00, time/batch = 0.0590s	
2582/2700 (epoch 47.815), train_loss = 3.20790608, grad/param norm = 9.6673e-01, time/batch = 0.0581s	
2583/2700 (epoch 47.833), train_loss = 3.24497721, grad/param norm = 9.6535e-01, time/batch = 0.0591s	
2584/2700 (epoch 47.852), train_loss = 3.23283864, grad/param norm = 9.8838e-01, time/batch = 0.0586s	
2585/2700 (epoch 47.870), train_loss = 3.22641830, grad/param norm = 8.4586e-01, time/batch = 0.0587s	
2586/2700 (epoch 47.889), train_loss = 3.25848548, grad/param norm = 7.7379e-01, time/batch = 0.0584s	
2587/2700 (epoch 47.907), train_loss = 3.31126862, grad/param norm = 9.1259e-01, time/batch = 0.0584s	
2588/2700 (epoch 47.926), train_loss = 3.26579993, grad/param norm = 9.7593e-01, time/batch = 0.0592s	
2589/2700 (epoch 47.944), train_loss = 3.27423302, grad/param norm = 8.1701e-01, time/batch = 0.0588s	
2590/2700 (epoch 47.963), train_loss = 3.34862723, grad/param norm = 7.5532e-01, time/batch = 0.0584s	
2591/2700 (epoch 47.981), train_loss = 3.40873105, grad/param norm = 7.9737e-01, time/batch = 0.0601s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
2592/2700 (epoch 48.000), train_loss = 3.31125067, grad/param norm = 7.8386e-01, time/batch = 0.0593s	
2593/2700 (epoch 48.019), train_loss = 3.25031009, grad/param norm = 8.5809e-01, time/batch = 0.0586s	
2594/2700 (epoch 48.037), train_loss = 3.26615312, grad/param norm = 7.8470e-01, time/batch = 0.0585s	
2595/2700 (epoch 48.056), train_loss = 3.26315597, grad/param norm = 5.6206e-01, time/batch = 0.0588s	
2596/2700 (epoch 48.074), train_loss = 3.29548632, grad/param norm = 6.8338e-01, time/batch = 0.0585s	
2597/2700 (epoch 48.093), train_loss = 3.30340195, grad/param norm = 8.0064e-01, time/batch = 0.0592s	
2598/2700 (epoch 48.111), train_loss = 3.27372005, grad/param norm = 7.3985e-01, time/batch = 0.0584s	
2599/2700 (epoch 48.130), train_loss = 3.29080186, grad/param norm = 6.5399e-01, time/batch = 0.0586s	
2600/2700 (epoch 48.148), train_loss = 3.25091500, grad/param norm = 7.8206e-01, time/batch = 0.0587s	
2601/2700 (epoch 48.167), train_loss = 3.26694657, grad/param norm = 9.5843e-01, time/batch = 0.0596s	
2602/2700 (epoch 48.185), train_loss = 3.24840536, grad/param norm = 7.1829e-01, time/batch = 0.0591s	
2603/2700 (epoch 48.204), train_loss = 3.18097823, grad/param norm = 7.9150e-01, time/batch = 0.0583s	
2604/2700 (epoch 48.222), train_loss = 3.16076956, grad/param norm = 1.0134e+00, time/batch = 0.0585s	
2605/2700 (epoch 48.241), train_loss = 3.18111201, grad/param norm = 1.0057e+00, time/batch = 0.0593s	
2606/2700 (epoch 48.259), train_loss = 3.21654071, grad/param norm = 1.1331e+00, time/batch = 0.0593s	
2607/2700 (epoch 48.278), train_loss = 3.29043763, grad/param norm = 1.0660e+00, time/batch = 0.0587s	
2608/2700 (epoch 48.296), train_loss = 3.29345006, grad/param norm = 1.1028e+00, time/batch = 0.0585s	
2609/2700 (epoch 48.315), train_loss = 3.26903149, grad/param norm = 1.0155e+00, time/batch = 0.0587s	
2610/2700 (epoch 48.333), train_loss = 3.34658375, grad/param norm = 8.7464e-01, time/batch = 0.0599s	
2611/2700 (epoch 48.352), train_loss = 3.35314805, grad/param norm = 8.3703e-01, time/batch = 0.0596s	
2612/2700 (epoch 48.370), train_loss = 3.29557116, grad/param norm = 7.2937e-01, time/batch = 0.0584s	
2613/2700 (epoch 48.389), train_loss = 3.25718662, grad/param norm = 5.6811e-01, time/batch = 0.0584s	
2614/2700 (epoch 48.407), train_loss = 3.27997006, grad/param norm = 5.2342e-01, time/batch = 0.0582s	
2615/2700 (epoch 48.426), train_loss = 3.28340149, grad/param norm = 5.6619e-01, time/batch = 0.0594s	
2616/2700 (epoch 48.444), train_loss = 3.20912547, grad/param norm = 5.2054e-01, time/batch = 0.0587s	
2617/2700 (epoch 48.463), train_loss = 3.25352041, grad/param norm = 6.1014e-01, time/batch = 0.0585s	
2618/2700 (epoch 48.481), train_loss = 3.32888359, grad/param norm = 5.5352e-01, time/batch = 0.0584s	
2619/2700 (epoch 48.500), train_loss = 3.37663347, grad/param norm = 8.2188e-01, time/batch = 0.0587s	
2620/2700 (epoch 48.519), train_loss = 3.33270540, grad/param norm = 9.1885e-01, time/batch = 0.0590s	
2621/2700 (epoch 48.537), train_loss = 3.33734818, grad/param norm = 9.6560e-01, time/batch = 0.0590s	
2622/2700 (epoch 48.556), train_loss = 3.27307383, grad/param norm = 7.8840e-01, time/batch = 0.0581s	
2623/2700 (epoch 48.574), train_loss = 3.23429539, grad/param norm = 7.1049e-01, time/batch = 0.0580s	
2624/2700 (epoch 48.593), train_loss = 3.24011557, grad/param norm = 9.1575e-01, time/batch = 0.0589s	
2625/2700 (epoch 48.611), train_loss = 3.17982737, grad/param norm = 7.7408e-01, time/batch = 0.0590s	
2626/2700 (epoch 48.630), train_loss = 3.22078762, grad/param norm = 8.5093e-01, time/batch = 0.0585s	
2627/2700 (epoch 48.648), train_loss = 3.29483483, grad/param norm = 9.1763e-01, time/batch = 0.0584s	
2628/2700 (epoch 48.667), train_loss = 3.22689502, grad/param norm = 8.8810e-01, time/batch = 0.0585s	
2629/2700 (epoch 48.685), train_loss = 3.21960857, grad/param norm = 7.7316e-01, time/batch = 0.0594s	
2630/2700 (epoch 48.704), train_loss = 3.19330236, grad/param norm = 8.8709e-01, time/batch = 0.0586s	
2631/2700 (epoch 48.722), train_loss = 3.18379077, grad/param norm = 7.1894e-01, time/batch = 0.0590s	
2632/2700 (epoch 48.741), train_loss = 3.31363283, grad/param norm = 6.2882e-01, time/batch = 0.0583s	
2633/2700 (epoch 48.759), train_loss = 3.26572403, grad/param norm = 8.3848e-01, time/batch = 0.0586s	
2634/2700 (epoch 48.778), train_loss = 3.26240246, grad/param norm = 1.0115e+00, time/batch = 0.0589s	
2635/2700 (epoch 48.796), train_loss = 3.25806901, grad/param norm = 1.0522e+00, time/batch = 0.0588s	
2636/2700 (epoch 48.815), train_loss = 3.20703872, grad/param norm = 9.5256e-01, time/batch = 0.0584s	
2637/2700 (epoch 48.833), train_loss = 3.24410300, grad/param norm = 9.5396e-01, time/batch = 0.0585s	
2638/2700 (epoch 48.852), train_loss = 3.23197449, grad/param norm = 9.7589e-01, time/batch = 0.0590s	
2639/2700 (epoch 48.870), train_loss = 3.22527089, grad/param norm = 8.2769e-01, time/batch = 0.0588s	
2640/2700 (epoch 48.889), train_loss = 3.25791091, grad/param norm = 7.5930e-01, time/batch = 0.0600s	
2641/2700 (epoch 48.907), train_loss = 3.31081430, grad/param norm = 8.9895e-01, time/batch = 0.0590s	
2642/2700 (epoch 48.926), train_loss = 3.26465314, grad/param norm = 9.5016e-01, time/batch = 0.0582s	
2643/2700 (epoch 48.944), train_loss = 3.27299831, grad/param norm = 7.9442e-01, time/batch = 0.0594s	
2644/2700 (epoch 48.963), train_loss = 3.34792249, grad/param norm = 7.3821e-01, time/batch = 0.0586s	
2645/2700 (epoch 48.981), train_loss = 3.40820212, grad/param norm = 7.8432e-01, time/batch = 0.0597s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
2646/2700 (epoch 49.000), train_loss = 3.31038810, grad/param norm = 7.7137e-01, time/batch = 0.0583s	
2647/2700 (epoch 49.019), train_loss = 3.24961593, grad/param norm = 8.4394e-01, time/batch = 0.0583s	
2648/2700 (epoch 49.037), train_loss = 3.26533007, grad/param norm = 7.6731e-01, time/batch = 0.0590s	
2649/2700 (epoch 49.056), train_loss = 3.26275198, grad/param norm = 5.5657e-01, time/batch = 0.0588s	
2650/2700 (epoch 49.074), train_loss = 3.29527267, grad/param norm = 6.9163e-01, time/batch = 0.0584s	
2651/2700 (epoch 49.093), train_loss = 3.30289360, grad/param norm = 8.0190e-01, time/batch = 0.0596s	
2652/2700 (epoch 49.111), train_loss = 3.27301916, grad/param norm = 7.3188e-01, time/batch = 0.0591s	
2653/2700 (epoch 49.130), train_loss = 3.28991859, grad/param norm = 6.4203e-01, time/batch = 0.0604s	
2654/2700 (epoch 49.148), train_loss = 3.25024426, grad/param norm = 7.6235e-01, time/batch = 0.0588s	
2655/2700 (epoch 49.167), train_loss = 3.26576285, grad/param norm = 9.3917e-01, time/batch = 0.0588s	
2656/2700 (epoch 49.185), train_loss = 3.24752368, grad/param norm = 6.9677e-01, time/batch = 0.0587s	
2657/2700 (epoch 49.204), train_loss = 3.18029520, grad/param norm = 7.6666e-01, time/batch = 0.0604s	
2658/2700 (epoch 49.222), train_loss = 3.15986319, grad/param norm = 9.8393e-01, time/batch = 0.0586s	
2659/2700 (epoch 49.241), train_loss = 3.17960734, grad/param norm = 9.5324e-01, time/batch = 0.0587s	
2660/2700 (epoch 49.259), train_loss = 3.21476890, grad/param norm = 1.0662e+00, time/batch = 0.0598s	
2661/2700 (epoch 49.278), train_loss = 3.28888598, grad/param norm = 1.0211e+00, time/batch = 0.0592s	
2662/2700 (epoch 49.296), train_loss = 3.29257768, grad/param norm = 1.0844e+00, time/batch = 0.0593s	
2663/2700 (epoch 49.315), train_loss = 3.26833356, grad/param norm = 1.0056e+00, time/batch = 0.0597s	
2664/2700 (epoch 49.333), train_loss = 3.34593253, grad/param norm = 8.6789e-01, time/batch = 0.0584s	
2665/2700 (epoch 49.352), train_loss = 3.35236934, grad/param norm = 8.2907e-01, time/batch = 0.0587s	
2666/2700 (epoch 49.370), train_loss = 3.29469911, grad/param norm = 7.2080e-01, time/batch = 0.0589s	
2667/2700 (epoch 49.389), train_loss = 3.25668244, grad/param norm = 5.5670e-01, time/batch = 0.0586s	
2668/2700 (epoch 49.407), train_loss = 3.27944399, grad/param norm = 5.1460e-01, time/batch = 0.0584s	
2669/2700 (epoch 49.426), train_loss = 3.28284313, grad/param norm = 5.5823e-01, time/batch = 0.0587s	
2670/2700 (epoch 49.444), train_loss = 3.20880846, grad/param norm = 5.0817e-01, time/batch = 0.0583s	
2671/2700 (epoch 49.463), train_loss = 3.25298070, grad/param norm = 5.9830e-01, time/batch = 0.0595s	
2672/2700 (epoch 49.481), train_loss = 3.32849933, grad/param norm = 5.4872e-01, time/batch = 0.0583s	
2673/2700 (epoch 49.500), train_loss = 3.37643619, grad/param norm = 8.2334e-01, time/batch = 0.0582s	
2674/2700 (epoch 49.519), train_loss = 3.33229191, grad/param norm = 9.1071e-01, time/batch = 0.0582s	
2675/2700 (epoch 49.537), train_loss = 3.33649419, grad/param norm = 9.4911e-01, time/batch = 0.0593s	
2676/2700 (epoch 49.556), train_loss = 3.27207295, grad/param norm = 7.7043e-01, time/batch = 0.0587s	
2677/2700 (epoch 49.574), train_loss = 3.23407152, grad/param norm = 6.9689e-01, time/batch = 0.0585s	
2678/2700 (epoch 49.593), train_loss = 3.23927306, grad/param norm = 8.9413e-01, time/batch = 0.0585s	
2679/2700 (epoch 49.611), train_loss = 3.17874128, grad/param norm = 7.3989e-01, time/batch = 0.0587s	
2680/2700 (epoch 49.630), train_loss = 3.21971138, grad/param norm = 8.1536e-01, time/batch = 0.0587s	
2681/2700 (epoch 49.648), train_loss = 3.29348206, grad/param norm = 8.8083e-01, time/batch = 0.0610s	
2682/2700 (epoch 49.667), train_loss = 3.22545480, grad/param norm = 8.4753e-01, time/batch = 0.0592s	
2683/2700 (epoch 49.685), train_loss = 3.21858327, grad/param norm = 7.4296e-01, time/batch = 0.0583s	
2684/2700 (epoch 49.704), train_loss = 3.19223958, grad/param norm = 8.6153e-01, time/batch = 0.0589s	
2685/2700 (epoch 49.722), train_loss = 3.18284242, grad/param norm = 6.9443e-01, time/batch = 0.0592s	
2686/2700 (epoch 49.741), train_loss = 3.31297812, grad/param norm = 6.1456e-01, time/batch = 0.0584s	
2687/2700 (epoch 49.759), train_loss = 3.26499857, grad/param norm = 8.2555e-01, time/batch = 0.0584s	
2688/2700 (epoch 49.778), train_loss = 3.26137105, grad/param norm = 9.9210e-01, time/batch = 0.0584s	
2689/2700 (epoch 49.796), train_loss = 3.25685275, grad/param norm = 1.0357e+00, time/batch = 0.0593s	
2690/2700 (epoch 49.815), train_loss = 3.20621114, grad/param norm = 9.3871e-01, time/batch = 0.0594s	
2691/2700 (epoch 49.833), train_loss = 3.24328473, grad/param norm = 9.4367e-01, time/batch = 0.0592s	
2692/2700 (epoch 49.852), train_loss = 3.23116864, grad/param norm = 9.6457e-01, time/batch = 0.0581s	
2693/2700 (epoch 49.870), train_loss = 3.22419267, grad/param norm = 8.1068e-01, time/batch = 0.0582s	
2694/2700 (epoch 49.889), train_loss = 3.25739186, grad/param norm = 7.4616e-01, time/batch = 0.0592s	
2695/2700 (epoch 49.907), train_loss = 3.31038501, grad/param norm = 8.8617e-01, time/batch = 0.0587s	
2696/2700 (epoch 49.926), train_loss = 3.26354849, grad/param norm = 9.2515e-01, time/batch = 0.0584s	
2697/2700 (epoch 49.944), train_loss = 3.27183956, grad/param norm = 7.7275e-01, time/batch = 0.0584s	
2698/2700 (epoch 49.963), train_loss = 3.34725272, grad/param norm = 7.2165e-01, time/batch = 0.0589s	
2699/2700 (epoch 49.981), train_loss = 3.40768889, grad/param norm = 7.7128e-01, time/batch = 0.0590s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch50.00_3.2014.t7	
2700/2700 (epoch 50.000), train_loss = 3.30955096, grad/param norm = 7.5929e-01, time/batch = 0.0583s	
