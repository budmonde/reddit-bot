using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 54, val: 3, test: 0	
vocab size: 91	
creating an rnn with 2 layers	
number of parameters in the model: 73051	
cloning rnn	
cloning criterion	
1/2700 (epoch 0.019), train_loss = 4.49494422, grad/param norm = 1.7762e+00, time/batch = 0.1915s	
2/2700 (epoch 0.037), train_loss = 4.02718385, grad/param norm = 6.1428e+00, time/batch = 0.0409s	
3/2700 (epoch 0.056), train_loss = 3.42164889, grad/param norm = 4.8904e+00, time/batch = 0.0395s	
4/2700 (epoch 0.074), train_loss = 3.38184285, grad/param norm = 3.1152e+00, time/batch = 0.0394s	
5/2700 (epoch 0.093), train_loss = 3.38954134, grad/param norm = 4.2981e+00, time/batch = 0.0397s	
6/2700 (epoch 0.111), train_loss = 3.32246771, grad/param norm = 4.5264e+00, time/batch = 0.0385s	
7/2700 (epoch 0.130), train_loss = 3.33590618, grad/param norm = 3.7484e+00, time/batch = 0.0383s	
8/2700 (epoch 0.148), train_loss = 3.26705522, grad/param norm = 2.1560e+00, time/batch = 0.0379s	
9/2700 (epoch 0.167), train_loss = 3.26779107, grad/param norm = 1.7653e+00, time/batch = 0.0378s	
10/2700 (epoch 0.185), train_loss = 3.25356461, grad/param norm = 1.6811e+00, time/batch = 0.0366s	
11/2700 (epoch 0.204), train_loss = 3.19665378, grad/param norm = 1.9882e+00, time/batch = 0.0364s	
12/2700 (epoch 0.222), train_loss = 3.15914585, grad/param norm = 1.6831e+00, time/batch = 0.0357s	
13/2700 (epoch 0.241), train_loss = 3.17031395, grad/param norm = 1.3807e+00, time/batch = 0.0358s	
14/2700 (epoch 0.259), train_loss = 3.20003211, grad/param norm = 1.0792e+00, time/batch = 0.0349s	
15/2700 (epoch 0.278), train_loss = 3.27031004, grad/param norm = 1.1226e+00, time/batch = 0.0346s	
16/2700 (epoch 0.296), train_loss = 3.27104289, grad/param norm = 1.1574e+00, time/batch = 0.0356s	
17/2700 (epoch 0.315), train_loss = 3.24474911, grad/param norm = 1.0045e+00, time/batch = 0.0350s	
18/2700 (epoch 0.333), train_loss = 3.31970019, grad/param norm = 9.5525e-01, time/batch = 0.0349s	
19/2700 (epoch 0.352), train_loss = 3.32397221, grad/param norm = 1.3368e+00, time/batch = 0.0346s	
20/2700 (epoch 0.370), train_loss = 3.26956685, grad/param norm = 1.3926e+00, time/batch = 0.0345s	
21/2700 (epoch 0.389), train_loss = 3.22903495, grad/param norm = 1.0634e+00, time/batch = 0.0351s	
22/2700 (epoch 0.407), train_loss = 3.24157628, grad/param norm = 9.6699e-01, time/batch = 0.0344s	
23/2700 (epoch 0.426), train_loss = 3.23728220, grad/param norm = 8.9633e-01, time/batch = 0.0343s	
24/2700 (epoch 0.444), train_loss = 3.16065500, grad/param norm = 1.3774e+00, time/batch = 0.0344s	
25/2700 (epoch 0.463), train_loss = 3.21094872, grad/param norm = 2.3215e+00, time/batch = 0.0343s	
26/2700 (epoch 0.481), train_loss = 3.26486631, grad/param norm = 1.9400e+00, time/batch = 0.0351s	
27/2700 (epoch 0.500), train_loss = 3.29106348, grad/param norm = 1.6778e+00, time/batch = 0.0350s	
28/2700 (epoch 0.519), train_loss = 3.21863384, grad/param norm = 1.6229e+00, time/batch = 0.0345s	
29/2700 (epoch 0.537), train_loss = 4.01783867, grad/param norm = 3.4357e+01, time/batch = 0.0346s	
30/2700 (epoch 0.556), train_loss = 4.15958968, grad/param norm = 4.0425e+00, time/batch = 0.0345s	
31/2700 (epoch 0.574), train_loss = 3.23577561, grad/param norm = 2.4193e+00, time/batch = 0.0355s	
32/2700 (epoch 0.593), train_loss = 3.11397571, grad/param norm = 8.9953e-01, time/batch = 0.0345s	
33/2700 (epoch 0.611), train_loss = 3.05778127, grad/param norm = 7.6498e-01, time/batch = 0.0343s	
34/2700 (epoch 0.630), train_loss = 3.08411111, grad/param norm = 8.6596e-01, time/batch = 0.0344s	
35/2700 (epoch 0.648), train_loss = 3.12468226, grad/param norm = 9.0764e-01, time/batch = 0.0345s	
36/2700 (epoch 0.667), train_loss = 3.05846981, grad/param norm = 8.1727e-01, time/batch = 0.0345s	
37/2700 (epoch 0.685), train_loss = 3.06408009, grad/param norm = 9.2413e-01, time/batch = 0.0356s	
38/2700 (epoch 0.704), train_loss = 3.01453925, grad/param norm = 1.0167e+00, time/batch = 0.0348s	
39/2700 (epoch 0.722), train_loss = 2.99782879, grad/param norm = 7.0847e-01, time/batch = 0.0345s	
40/2700 (epoch 0.741), train_loss = 3.13678477, grad/param norm = 9.3032e-01, time/batch = 0.0346s	
41/2700 (epoch 0.759), train_loss = 3.06452991, grad/param norm = 1.0200e+00, time/batch = 0.0348s	
42/2700 (epoch 0.778), train_loss = 3.05021529, grad/param norm = 1.1799e+00, time/batch = 0.0345s	
43/2700 (epoch 0.796), train_loss = 3.05140330, grad/param norm = 1.2095e+00, time/batch = 0.0343s	
44/2700 (epoch 0.815), train_loss = 2.98928335, grad/param norm = 1.2194e+00, time/batch = 0.0342s	
45/2700 (epoch 0.833), train_loss = 3.00009367, grad/param norm = 1.4830e+00, time/batch = 0.0344s	
46/2700 (epoch 0.852), train_loss = 3.00542762, grad/param norm = 1.5979e+00, time/batch = 0.0345s	
47/2700 (epoch 0.870), train_loss = 2.96881467, grad/param norm = 1.5884e+00, time/batch = 0.0349s	
48/2700 (epoch 0.889), train_loss = 3.00028390, grad/param norm = 1.7829e+00, time/batch = 0.0350s	
49/2700 (epoch 0.907), train_loss = 3.05526033, grad/param norm = 1.8091e+00, time/batch = 0.0348s	
50/2700 (epoch 0.926), train_loss = 2.98959185, grad/param norm = 1.7341e+00, time/batch = 0.0347s	
51/2700 (epoch 0.944), train_loss = 3.00196404, grad/param norm = 1.3308e+00, time/batch = 0.0356s	
52/2700 (epoch 0.963), train_loss = 3.06200419, grad/param norm = 1.3138e+00, time/batch = 0.0351s	
53/2700 (epoch 0.981), train_loss = 3.08591972, grad/param norm = 1.1161e+00, time/batch = 0.0343s	
54/2700 (epoch 1.000), train_loss = 3.00491056, grad/param norm = 1.2816e+00, time/batch = 0.0345s	
55/2700 (epoch 1.019), train_loss = 2.91654787, grad/param norm = 1.4113e+00, time/batch = 0.0346s	
56/2700 (epoch 1.037), train_loss = 2.94697136, grad/param norm = 1.4058e+00, time/batch = 0.0345s	
57/2700 (epoch 1.056), train_loss = 2.91658455, grad/param norm = 1.5858e+00, time/batch = 0.0345s	
58/2700 (epoch 1.074), train_loss = 2.95117283, grad/param norm = 1.5795e+00, time/batch = 0.0355s	
59/2700 (epoch 1.093), train_loss = 2.94456203, grad/param norm = 1.5410e+00, time/batch = 0.0345s	
60/2700 (epoch 1.111), train_loss = 2.89619391, grad/param norm = 1.3934e+00, time/batch = 0.0345s	
61/2700 (epoch 1.130), train_loss = 2.90544452, grad/param norm = 1.4286e+00, time/batch = 0.0354s	
62/2700 (epoch 1.148), train_loss = 2.85377196, grad/param norm = 2.2205e+00, time/batch = 0.0347s	
63/2700 (epoch 1.167), train_loss = 2.90659183, grad/param norm = 3.6113e+00, time/batch = 0.0357s	
64/2700 (epoch 1.185), train_loss = 2.87743826, grad/param norm = 3.1156e+00, time/batch = 0.0344s	
65/2700 (epoch 1.204), train_loss = 2.79283490, grad/param norm = 1.9106e+00, time/batch = 0.0344s	
66/2700 (epoch 1.222), train_loss = 2.72367537, grad/param norm = 1.2461e+00, time/batch = 0.0345s	
67/2700 (epoch 1.241), train_loss = 2.72848643, grad/param norm = 1.0592e+00, time/batch = 0.0345s	
68/2700 (epoch 1.259), train_loss = 2.73664560, grad/param norm = 9.0900e-01, time/batch = 0.0350s	
69/2700 (epoch 1.278), train_loss = 2.80815320, grad/param norm = 1.1404e+00, time/batch = 0.0351s	
70/2700 (epoch 1.296), train_loss = 2.80270286, grad/param norm = 1.4963e+00, time/batch = 0.0345s	
71/2700 (epoch 1.315), train_loss = 2.83399656, grad/param norm = 1.8861e+00, time/batch = 0.0355s	
72/2700 (epoch 1.333), train_loss = 2.84753572, grad/param norm = 1.7483e+00, time/batch = 0.0345s	
73/2700 (epoch 1.352), train_loss = 2.85456409, grad/param norm = 1.4546e+00, time/batch = 0.0343s	
74/2700 (epoch 1.370), train_loss = 2.82919691, grad/param norm = 3.5726e+00, time/batch = 0.0344s	
75/2700 (epoch 1.389), train_loss = 2.80576589, grad/param norm = 1.8837e+00, time/batch = 0.0345s	
76/2700 (epoch 1.407), train_loss = 2.76201731, grad/param norm = 1.3824e+00, time/batch = 0.0345s	
77/2700 (epoch 1.426), train_loss = 2.79028346, grad/param norm = 1.8659e+00, time/batch = 0.0344s	
78/2700 (epoch 1.444), train_loss = 2.71507047, grad/param norm = 3.0787e+00, time/batch = 0.0346s	
79/2700 (epoch 1.463), train_loss = 2.82359327, grad/param norm = 2.9926e+00, time/batch = 0.0348s	
80/2700 (epoch 1.481), train_loss = 2.83737911, grad/param norm = 2.0795e+00, time/batch = 0.0345s	
81/2700 (epoch 1.500), train_loss = 2.83337548, grad/param norm = 1.4656e+00, time/batch = 0.0357s	
82/2700 (epoch 1.519), train_loss = 2.76147352, grad/param norm = 1.5016e+00, time/batch = 0.0345s	
83/2700 (epoch 1.537), train_loss = 2.76424251, grad/param norm = 1.6673e+00, time/batch = 0.0345s	
84/2700 (epoch 1.556), train_loss = 2.74255504, grad/param norm = 1.6827e+00, time/batch = 0.0344s	
85/2700 (epoch 1.574), train_loss = 2.67774520, grad/param norm = 1.5526e+00, time/batch = 0.0346s	
86/2700 (epoch 1.593), train_loss = 2.66086207, grad/param norm = 1.2937e+00, time/batch = 0.0347s	
87/2700 (epoch 1.611), train_loss = 2.60888210, grad/param norm = 1.2223e+00, time/batch = 0.0345s	
88/2700 (epoch 1.630), train_loss = 2.64206389, grad/param norm = 1.4080e+00, time/batch = 0.0346s	
89/2700 (epoch 1.648), train_loss = 2.66571454, grad/param norm = 1.1028e+00, time/batch = 0.0366s	
90/2700 (epoch 1.667), train_loss = 2.58892074, grad/param norm = 9.1011e-01, time/batch = 0.0348s	
91/2700 (epoch 1.685), train_loss = 2.62889037, grad/param norm = 8.5195e-01, time/batch = 0.0355s	
92/2700 (epoch 1.704), train_loss = 2.60170431, grad/param norm = 1.1977e+00, time/batch = 0.0345s	
93/2700 (epoch 1.722), train_loss = 2.60538304, grad/param norm = 2.0307e+00, time/batch = 0.0344s	
94/2700 (epoch 1.741), train_loss = 2.81704203, grad/param norm = 2.8468e+00, time/batch = 0.0344s	
95/2700 (epoch 1.759), train_loss = 2.73918671, grad/param norm = 2.5257e+00, time/batch = 0.0345s	
96/2700 (epoch 1.778), train_loss = 2.68195646, grad/param norm = 1.7498e+00, time/batch = 0.0345s	
97/2700 (epoch 1.796), train_loss = 2.65417055, grad/param norm = 1.4765e+00, time/batch = 0.0346s	
98/2700 (epoch 1.815), train_loss = 2.61927438, grad/param norm = 1.2055e+00, time/batch = 0.0346s	
99/2700 (epoch 1.833), train_loss = 2.60917769, grad/param norm = 1.3610e+00, time/batch = 0.0345s	
100/2700 (epoch 1.852), train_loss = 2.64645816, grad/param norm = 1.6304e+00, time/batch = 0.0355s	
101/2700 (epoch 1.870), train_loss = 2.61550610, grad/param norm = 1.6786e+00, time/batch = 0.0369s	
102/2700 (epoch 1.889), train_loss = 2.63801030, grad/param norm = 1.7424e+00, time/batch = 0.0348s	
103/2700 (epoch 1.907), train_loss = 2.74595565, grad/param norm = 2.1182e+00, time/batch = 0.0345s	
104/2700 (epoch 1.926), train_loss = 2.69362734, grad/param norm = 2.8758e+00, time/batch = 0.0345s	
105/2700 (epoch 1.944), train_loss = 2.71500097, grad/param norm = 2.3258e+00, time/batch = 0.0346s	
106/2700 (epoch 1.963), train_loss = 2.77825352, grad/param norm = 2.6184e+00, time/batch = 0.0352s	
107/2700 (epoch 1.981), train_loss = 2.73879486, grad/param norm = 1.6781e+00, time/batch = 0.0346s	
108/2700 (epoch 2.000), train_loss = 2.71409256, grad/param norm = 2.2852e+00, time/batch = 0.0347s	
109/2700 (epoch 2.019), train_loss = 2.60991126, grad/param norm = 9.5633e-01, time/batch = 0.0345s	
110/2700 (epoch 2.037), train_loss = 2.66485595, grad/param norm = 1.0380e+00, time/batch = 0.0351s	
111/2700 (epoch 2.056), train_loss = 2.63735318, grad/param norm = 1.8609e+00, time/batch = 0.0356s	
112/2700 (epoch 2.074), train_loss = 2.68296938, grad/param norm = 2.2278e+00, time/batch = 0.0346s	
113/2700 (epoch 2.093), train_loss = 2.66867661, grad/param norm = 1.8613e+00, time/batch = 0.0344s	
114/2700 (epoch 2.111), train_loss = 2.62130304, grad/param norm = 1.3209e+00, time/batch = 0.0345s	
115/2700 (epoch 2.130), train_loss = 2.62568840, grad/param norm = 7.2621e-01, time/batch = 0.0344s	
116/2700 (epoch 2.148), train_loss = 2.55381791, grad/param norm = 5.9359e-01, time/batch = 0.0346s	
117/2700 (epoch 2.167), train_loss = 2.58683370, grad/param norm = 7.1676e-01, time/batch = 0.0348s	
118/2700 (epoch 2.185), train_loss = 2.54202572, grad/param norm = 7.6414e-01, time/batch = 0.0349s	
119/2700 (epoch 2.204), train_loss = 2.51794073, grad/param norm = 1.0888e+00, time/batch = 0.0348s	
120/2700 (epoch 2.222), train_loss = 2.50230797, grad/param norm = 1.7751e+00, time/batch = 0.0347s	
121/2700 (epoch 2.241), train_loss = 2.52266257, grad/param norm = 1.9388e+00, time/batch = 0.0352s	
122/2700 (epoch 2.259), train_loss = 2.52672366, grad/param norm = 2.0081e+00, time/batch = 0.0345s	
123/2700 (epoch 2.278), train_loss = 2.61653793, grad/param norm = 1.9138e+00, time/batch = 0.0345s	
124/2700 (epoch 2.296), train_loss = 2.58374311, grad/param norm = 1.5802e+00, time/batch = 0.0346s	
125/2700 (epoch 2.315), train_loss = 2.61999360, grad/param norm = 1.7419e+00, time/batch = 0.0346s	
126/2700 (epoch 2.333), train_loss = 2.62661335, grad/param norm = 1.7859e+00, time/batch = 0.0346s	
127/2700 (epoch 2.352), train_loss = 2.66216632, grad/param norm = 1.6934e+00, time/batch = 0.0354s	
128/2700 (epoch 2.370), train_loss = 2.62487097, grad/param norm = 2.6449e+00, time/batch = 0.0346s	
129/2700 (epoch 2.389), train_loss = 2.57922746, grad/param norm = 1.3748e+00, time/batch = 0.0346s	
130/2700 (epoch 2.407), train_loss = 2.54552255, grad/param norm = 1.0264e+00, time/batch = 0.0345s	
131/2700 (epoch 2.426), train_loss = 2.59074169, grad/param norm = 1.2257e+00, time/batch = 0.0370s	
132/2700 (epoch 2.444), train_loss = 2.48421093, grad/param norm = 1.3376e+00, time/batch = 0.0348s	
133/2700 (epoch 2.463), train_loss = 2.56728397, grad/param norm = 1.3200e+00, time/batch = 0.0346s	
134/2700 (epoch 2.481), train_loss = 2.61432348, grad/param norm = 1.4255e+00, time/batch = 0.0346s	
135/2700 (epoch 2.500), train_loss = 2.63432224, grad/param norm = 1.8183e+00, time/batch = 0.0347s	
136/2700 (epoch 2.519), train_loss = 2.57628996, grad/param norm = 2.2061e+00, time/batch = 0.0347s	
137/2700 (epoch 2.537), train_loss = 2.58789444, grad/param norm = 1.8693e+00, time/batch = 0.0346s	
138/2700 (epoch 2.556), train_loss = 2.54621854, grad/param norm = 1.2875e+00, time/batch = 0.0347s	
139/2700 (epoch 2.574), train_loss = 2.49055138, grad/param norm = 9.9473e-01, time/batch = 0.0344s	
140/2700 (epoch 2.593), train_loss = 2.47353638, grad/param norm = 9.5094e-01, time/batch = 0.0346s	
141/2700 (epoch 2.611), train_loss = 2.42606768, grad/param norm = 1.0273e+00, time/batch = 0.0371s	
142/2700 (epoch 2.630), train_loss = 2.47037241, grad/param norm = 1.3004e+00, time/batch = 0.0351s	
143/2700 (epoch 2.648), train_loss = 2.50695710, grad/param norm = 1.9150e+00, time/batch = 0.0347s	
144/2700 (epoch 2.667), train_loss = 2.46799068, grad/param norm = 2.4433e+00, time/batch = 0.0348s	
145/2700 (epoch 2.685), train_loss = 2.53555491, grad/param norm = 2.0652e+00, time/batch = 0.0346s	
146/2700 (epoch 2.704), train_loss = 2.49007502, grad/param norm = 1.4934e+00, time/batch = 0.0347s	
147/2700 (epoch 2.722), train_loss = 2.45931150, grad/param norm = 9.8131e-01, time/batch = 0.0347s	
148/2700 (epoch 2.741), train_loss = 2.61184762, grad/param norm = 7.2249e-01, time/batch = 0.0346s	
149/2700 (epoch 2.759), train_loss = 2.53482782, grad/param norm = 8.1883e-01, time/batch = 0.0346s	
150/2700 (epoch 2.778), train_loss = 2.50992054, grad/param norm = 8.1884e-01, time/batch = 0.0346s	
151/2700 (epoch 2.796), train_loss = 2.47611388, grad/param norm = 8.9336e-01, time/batch = 0.0363s	
152/2700 (epoch 2.815), train_loss = 2.47271875, grad/param norm = 9.0647e-01, time/batch = 0.0351s	
153/2700 (epoch 2.833), train_loss = 2.46066945, grad/param norm = 1.0738e+00, time/batch = 0.0347s	
154/2700 (epoch 2.852), train_loss = 2.49806009, grad/param norm = 1.3874e+00, time/batch = 0.0349s	
155/2700 (epoch 2.870), train_loss = 2.47978768, grad/param norm = 2.0573e+00, time/batch = 0.0347s	
156/2700 (epoch 2.889), train_loss = 2.50954014, grad/param norm = 2.0360e+00, time/batch = 0.0348s	
157/2700 (epoch 2.907), train_loss = 2.61581567, grad/param norm = 1.6541e+00, time/batch = 0.0347s	
158/2700 (epoch 2.926), train_loss = 2.53509875, grad/param norm = 1.5770e+00, time/batch = 0.0347s	
159/2700 (epoch 2.944), train_loss = 2.53725306, grad/param norm = 1.0942e+00, time/batch = 0.0345s	
160/2700 (epoch 2.963), train_loss = 2.56420721, grad/param norm = 9.6092e-01, time/batch = 0.0345s	
161/2700 (epoch 2.981), train_loss = 2.55583994, grad/param norm = 1.1580e+00, time/batch = 0.0363s	
162/2700 (epoch 3.000), train_loss = 2.56882048, grad/param norm = 2.1575e+00, time/batch = 0.0357s	
163/2700 (epoch 3.019), train_loss = 2.50355690, grad/param norm = 1.5841e+00, time/batch = 0.0347s	
164/2700 (epoch 3.037), train_loss = 2.57239484, grad/param norm = 1.8860e+00, time/batch = 0.0347s	
165/2700 (epoch 3.056), train_loss = 2.52028155, grad/param norm = 1.5804e+00, time/batch = 0.0346s	
166/2700 (epoch 3.074), train_loss = 2.51086012, grad/param norm = 1.7261e+00, time/batch = 0.0346s	
167/2700 (epoch 3.093), train_loss = 2.53266258, grad/param norm = 1.8823e+00, time/batch = 0.0347s	
168/2700 (epoch 3.111), train_loss = 2.48757107, grad/param norm = 1.5513e+00, time/batch = 0.0346s	
169/2700 (epoch 3.130), train_loss = 2.49411415, grad/param norm = 1.0330e+00, time/batch = 0.0346s	
170/2700 (epoch 3.148), train_loss = 2.42505407, grad/param norm = 9.1740e-01, time/batch = 0.0346s	
171/2700 (epoch 3.167), train_loss = 2.47354568, grad/param norm = 1.1224e+00, time/batch = 0.0354s	
172/2700 (epoch 3.185), train_loss = 2.41814158, grad/param norm = 1.0128e+00, time/batch = 0.0352s	
173/2700 (epoch 3.204), train_loss = 2.40962177, grad/param norm = 1.2422e+00, time/batch = 0.0368s	
174/2700 (epoch 3.222), train_loss = 2.36560011, grad/param norm = 1.6748e+00, time/batch = 0.0347s	
175/2700 (epoch 3.241), train_loss = 2.37045520, grad/param norm = 1.8573e+00, time/batch = 0.0346s	
176/2700 (epoch 3.259), train_loss = 2.36870556, grad/param norm = 1.5070e+00, time/batch = 0.0357s	
177/2700 (epoch 3.278), train_loss = 2.47324829, grad/param norm = 1.1309e+00, time/batch = 0.0346s	
178/2700 (epoch 3.296), train_loss = 2.44405282, grad/param norm = 9.7676e-01, time/batch = 0.0346s	
179/2700 (epoch 3.315), train_loss = 2.47569125, grad/param norm = 1.1176e+00, time/batch = 0.0354s	
180/2700 (epoch 3.333), train_loss = 2.48120418, grad/param norm = 1.2427e+00, time/batch = 0.0345s	
181/2700 (epoch 3.352), train_loss = 2.52421421, grad/param norm = 1.6237e+00, time/batch = 0.0353s	
182/2700 (epoch 3.370), train_loss = 2.49097487, grad/param norm = 2.3476e+00, time/batch = 0.0346s	
183/2700 (epoch 3.389), train_loss = 2.47865992, grad/param norm = 1.5438e+00, time/batch = 0.0349s	
184/2700 (epoch 3.407), train_loss = 2.43660038, grad/param norm = 1.2059e+00, time/batch = 0.0348s	
185/2700 (epoch 3.426), train_loss = 2.47094338, grad/param norm = 1.3244e+00, time/batch = 0.0346s	
186/2700 (epoch 3.444), train_loss = 2.38365746, grad/param norm = 1.7502e+00, time/batch = 0.0350s	
187/2700 (epoch 3.463), train_loss = 2.49078011, grad/param norm = 1.8467e+00, time/batch = 0.0346s	
188/2700 (epoch 3.481), train_loss = 2.50417540, grad/param norm = 1.3525e+00, time/batch = 0.0346s	
189/2700 (epoch 3.500), train_loss = 2.49554980, grad/param norm = 1.0938e+00, time/batch = 0.0346s	
190/2700 (epoch 3.519), train_loss = 2.42242866, grad/param norm = 1.1178e+00, time/batch = 0.0345s	
191/2700 (epoch 3.537), train_loss = 2.43676650, grad/param norm = 1.0988e+00, time/batch = 0.0354s	
192/2700 (epoch 3.556), train_loss = 2.41644642, grad/param norm = 8.9497e-01, time/batch = 0.0344s	
193/2700 (epoch 3.574), train_loss = 2.37178265, grad/param norm = 8.6350e-01, time/batch = 0.0350s	
194/2700 (epoch 3.593), train_loss = 2.36218266, grad/param norm = 9.8359e-01, time/batch = 0.0351s	
195/2700 (epoch 3.611), train_loss = 2.30708398, grad/param norm = 1.0842e+00, time/batch = 0.0347s	
196/2700 (epoch 3.630), train_loss = 2.36380411, grad/param norm = 1.0351e+00, time/batch = 0.0347s	
197/2700 (epoch 3.648), train_loss = 2.37658542, grad/param norm = 8.0667e-01, time/batch = 0.0346s	
198/2700 (epoch 3.667), train_loss = 2.30606983, grad/param norm = 9.1322e-01, time/batch = 0.0348s	
199/2700 (epoch 3.685), train_loss = 2.37828394, grad/param norm = 1.0865e+00, time/batch = 0.0347s	
200/2700 (epoch 3.704), train_loss = 2.36374767, grad/param norm = 1.3374e+00, time/batch = 0.0345s	
201/2700 (epoch 3.722), train_loss = 2.36425658, grad/param norm = 1.4700e+00, time/batch = 0.0354s	
202/2700 (epoch 3.741), train_loss = 2.50217410, grad/param norm = 1.4246e+00, time/batch = 0.0345s	
203/2700 (epoch 3.759), train_loss = 2.45667789, grad/param norm = 1.7957e+00, time/batch = 0.0346s	
204/2700 (epoch 3.778), train_loss = 2.44787923, grad/param norm = 1.9760e+00, time/batch = 0.0351s	
205/2700 (epoch 3.796), train_loss = 2.41890025, grad/param norm = 1.8812e+00, time/batch = 0.0347s	
206/2700 (epoch 3.815), train_loss = 2.40524277, grad/param norm = 1.5591e+00, time/batch = 0.0347s	
207/2700 (epoch 3.833), train_loss = 2.35825740, grad/param norm = 1.1437e+00, time/batch = 0.0347s	
208/2700 (epoch 3.852), train_loss = 2.39501761, grad/param norm = 1.0453e+00, time/batch = 0.0348s	
209/2700 (epoch 3.870), train_loss = 2.35451201, grad/param norm = 1.1178e+00, time/batch = 0.0347s	
210/2700 (epoch 3.889), train_loss = 2.36277456, grad/param norm = 1.1798e+00, time/batch = 0.0347s	
211/2700 (epoch 3.907), train_loss = 2.47782190, grad/param norm = 1.2984e+00, time/batch = 0.0354s	
212/2700 (epoch 3.926), train_loss = 2.43265892, grad/param norm = 1.6792e+00, time/batch = 0.0345s	
213/2700 (epoch 3.944), train_loss = 2.44111244, grad/param norm = 1.3994e+00, time/batch = 0.0342s	
214/2700 (epoch 3.963), train_loss = 2.45598930, grad/param norm = 1.1959e+00, time/batch = 0.0355s	
215/2700 (epoch 3.981), train_loss = 2.44326480, grad/param norm = 9.2701e-01, time/batch = 0.0353s	
216/2700 (epoch 4.000), train_loss = 2.43864285, grad/param norm = 8.4615e-01, time/batch = 0.0348s	
217/2700 (epoch 4.019), train_loss = 2.38819925, grad/param norm = 9.2940e-01, time/batch = 0.0349s	
218/2700 (epoch 4.037), train_loss = 2.42464183, grad/param norm = 1.0037e+00, time/batch = 0.0348s	
219/2700 (epoch 4.056), train_loss = 2.38405878, grad/param norm = 1.2675e+00, time/batch = 0.0357s	
220/2700 (epoch 4.074), train_loss = 2.39629093, grad/param norm = 1.6397e+00, time/batch = 0.0360s	
221/2700 (epoch 4.093), train_loss = 2.43884291, grad/param norm = 1.4370e+00, time/batch = 0.0355s	
222/2700 (epoch 4.111), train_loss = 2.36962167, grad/param norm = 1.1239e+00, time/batch = 0.0348s	
223/2700 (epoch 4.130), train_loss = 2.38039176, grad/param norm = 8.6197e-01, time/batch = 0.0342s	
224/2700 (epoch 4.148), train_loss = 2.32030609, grad/param norm = 9.1346e-01, time/batch = 0.0350s	
225/2700 (epoch 4.167), train_loss = 2.38218321, grad/param norm = 9.7485e-01, time/batch = 0.0347s	
226/2700 (epoch 4.185), train_loss = 2.31256456, grad/param norm = 8.7642e-01, time/batch = 0.0347s	
227/2700 (epoch 4.204), train_loss = 2.31054607, grad/param norm = 1.0233e+00, time/batch = 0.0346s	
228/2700 (epoch 4.222), train_loss = 2.25530669, grad/param norm = 1.3151e+00, time/batch = 0.0346s	
229/2700 (epoch 4.241), train_loss = 2.25241821, grad/param norm = 1.5765e+00, time/batch = 0.0346s	
230/2700 (epoch 4.259), train_loss = 2.26835938, grad/param norm = 1.3317e+00, time/batch = 0.0345s	
231/2700 (epoch 4.278), train_loss = 2.37301074, grad/param norm = 9.8914e-01, time/batch = 0.0353s	
232/2700 (epoch 4.296), train_loss = 2.34580790, grad/param norm = 8.6579e-01, time/batch = 0.0344s	
233/2700 (epoch 4.315), train_loss = 2.36926996, grad/param norm = 8.5317e-01, time/batch = 0.0343s	
234/2700 (epoch 4.333), train_loss = 2.36871537, grad/param norm = 9.1364e-01, time/batch = 0.0349s	
235/2700 (epoch 4.352), train_loss = 2.40216905, grad/param norm = 1.1898e+00, time/batch = 0.0351s	
236/2700 (epoch 4.370), train_loss = 2.37567218, grad/param norm = 2.0027e+00, time/batch = 0.0347s	
237/2700 (epoch 4.389), train_loss = 2.35999968, grad/param norm = 1.1135e+00, time/batch = 0.0347s	
238/2700 (epoch 4.407), train_loss = 2.33493522, grad/param norm = 7.6366e-01, time/batch = 0.0347s	
239/2700 (epoch 4.426), train_loss = 2.35757966, grad/param norm = 8.7179e-01, time/batch = 0.0346s	
240/2700 (epoch 4.444), train_loss = 2.27423496, grad/param norm = 1.1648e+00, time/batch = 0.0346s	
241/2700 (epoch 4.463), train_loss = 2.37730444, grad/param norm = 1.5678e+00, time/batch = 0.0354s	
242/2700 (epoch 4.481), train_loss = 2.40743919, grad/param norm = 1.5466e+00, time/batch = 0.0346s	
243/2700 (epoch 4.500), train_loss = 2.40330198, grad/param norm = 1.4123e+00, time/batch = 0.0342s	
244/2700 (epoch 4.519), train_loss = 2.33191560, grad/param norm = 1.3421e+00, time/batch = 0.0346s	
245/2700 (epoch 4.537), train_loss = 2.35399579, grad/param norm = 1.0940e+00, time/batch = 0.0350s	
246/2700 (epoch 4.556), train_loss = 2.31824476, grad/param norm = 8.4547e-01, time/batch = 0.0347s	
247/2700 (epoch 4.574), train_loss = 2.28620458, grad/param norm = 8.3135e-01, time/batch = 0.0346s	
248/2700 (epoch 4.593), train_loss = 2.27092002, grad/param norm = 8.9810e-01, time/batch = 0.0360s	
249/2700 (epoch 4.611), train_loss = 2.20552780, grad/param norm = 9.6203e-01, time/batch = 0.0345s	
250/2700 (epoch 4.630), train_loss = 2.27172219, grad/param norm = 9.8522e-01, time/batch = 0.0347s	
251/2700 (epoch 4.648), train_loss = 2.28385746, grad/param norm = 7.6856e-01, time/batch = 0.0354s	
252/2700 (epoch 4.667), train_loss = 2.21666638, grad/param norm = 7.4580e-01, time/batch = 0.0345s	
253/2700 (epoch 4.685), train_loss = 2.27757919, grad/param norm = 9.2709e-01, time/batch = 0.0343s	
254/2700 (epoch 4.704), train_loss = 2.27536726, grad/param norm = 1.2675e+00, time/batch = 0.0344s	
255/2700 (epoch 4.722), train_loss = 2.28370486, grad/param norm = 1.7249e+00, time/batch = 0.0365s	
256/2700 (epoch 4.741), train_loss = 2.43200129, grad/param norm = 1.9153e+00, time/batch = 0.0348s	
257/2700 (epoch 4.759), train_loss = 2.39346059, grad/param norm = 1.6350e+00, time/batch = 0.0347s	
258/2700 (epoch 4.778), train_loss = 2.35006227, grad/param norm = 1.3182e+00, time/batch = 0.0346s	
259/2700 (epoch 4.796), train_loss = 2.30685712, grad/param norm = 1.1787e+00, time/batch = 0.0359s	
260/2700 (epoch 4.815), train_loss = 2.31092729, grad/param norm = 8.7038e-01, time/batch = 0.0346s	
261/2700 (epoch 4.833), train_loss = 2.26763675, grad/param norm = 7.1375e-01, time/batch = 0.0355s	
262/2700 (epoch 4.852), train_loss = 2.28977574, grad/param norm = 5.8392e-01, time/batch = 0.0346s	
263/2700 (epoch 4.870), train_loss = 2.25056502, grad/param norm = 6.8862e-01, time/batch = 0.0344s	
264/2700 (epoch 4.889), train_loss = 2.26546269, grad/param norm = 7.2209e-01, time/batch = 0.0345s	
265/2700 (epoch 4.907), train_loss = 2.38395947, grad/param norm = 8.3724e-01, time/batch = 0.0350s	
266/2700 (epoch 4.926), train_loss = 2.33767009, grad/param norm = 1.0335e+00, time/batch = 0.0348s	
267/2700 (epoch 4.944), train_loss = 2.33081383, grad/param norm = 9.3739e-01, time/batch = 0.0346s	
268/2700 (epoch 4.963), train_loss = 2.36451052, grad/param norm = 9.0271e-01, time/batch = 0.0346s	
269/2700 (epoch 4.981), train_loss = 2.35636978, grad/param norm = 9.7396e-01, time/batch = 0.0348s	
270/2700 (epoch 5.000), train_loss = 2.35183764, grad/param norm = 9.9123e-01, time/batch = 0.0346s	
271/2700 (epoch 5.019), train_loss = 2.30743886, grad/param norm = 1.2398e+00, time/batch = 0.0354s	
272/2700 (epoch 5.037), train_loss = 2.34565973, grad/param norm = 1.3337e+00, time/batch = 0.0353s	
273/2700 (epoch 5.056), train_loss = 2.30796802, grad/param norm = 1.4575e+00, time/batch = 0.0344s	
274/2700 (epoch 5.074), train_loss = 2.29958983, grad/param norm = 1.4689e+00, time/batch = 0.0345s	
275/2700 (epoch 5.093), train_loss = 2.33549018, grad/param norm = 1.2030e+00, time/batch = 0.0344s	
276/2700 (epoch 5.111), train_loss = 2.26819872, grad/param norm = 9.9898e-01, time/batch = 0.0352s	
277/2700 (epoch 5.130), train_loss = 2.28871450, grad/param norm = 8.2446e-01, time/batch = 0.0347s	
278/2700 (epoch 5.148), train_loss = 2.22907727, grad/param norm = 8.2453e-01, time/batch = 0.0347s	
279/2700 (epoch 5.167), train_loss = 2.29241462, grad/param norm = 7.9629e-01, time/batch = 0.0345s	
280/2700 (epoch 5.185), train_loss = 2.21813759, grad/param norm = 6.3349e-01, time/batch = 0.0346s	
281/2700 (epoch 5.204), train_loss = 2.22619208, grad/param norm = 7.3836e-01, time/batch = 0.0359s	
282/2700 (epoch 5.222), train_loss = 2.16528938, grad/param norm = 9.8633e-01, time/batch = 0.0348s	
283/2700 (epoch 5.241), train_loss = 2.15403766, grad/param norm = 1.1495e+00, time/batch = 0.0347s	
284/2700 (epoch 5.259), train_loss = 2.17775471, grad/param norm = 1.0204e+00, time/batch = 0.0346s	
285/2700 (epoch 5.278), train_loss = 2.28061060, grad/param norm = 8.1264e-01, time/batch = 0.0345s	
286/2700 (epoch 5.296), train_loss = 2.25484313, grad/param norm = 7.3115e-01, time/batch = 0.0353s	
287/2700 (epoch 5.315), train_loss = 2.27223388, grad/param norm = 7.1010e-01, time/batch = 0.0352s	
288/2700 (epoch 5.333), train_loss = 2.27017231, grad/param norm = 7.4555e-01, time/batch = 0.0349s	
289/2700 (epoch 5.352), train_loss = 2.30609858, grad/param norm = 9.0915e-01, time/batch = 0.0357s	
290/2700 (epoch 5.370), train_loss = 2.28694247, grad/param norm = 1.0222e+00, time/batch = 0.0348s	
291/2700 (epoch 5.389), train_loss = 2.25557612, grad/param norm = 1.0913e+00, time/batch = 0.0357s	
292/2700 (epoch 5.407), train_loss = 2.25829743, grad/param norm = 9.6681e-01, time/batch = 0.0346s	
293/2700 (epoch 5.426), train_loss = 2.28208939, grad/param norm = 1.1097e+00, time/batch = 0.0344s	
294/2700 (epoch 5.444), train_loss = 2.18610599, grad/param norm = 9.4827e-01, time/batch = 0.0346s	
295/2700 (epoch 5.463), train_loss = 2.26150208, grad/param norm = 8.0154e-01, time/batch = 0.0344s	
296/2700 (epoch 5.481), train_loss = 2.29382973, grad/param norm = 8.2224e-01, time/batch = 0.0349s	
297/2700 (epoch 5.500), train_loss = 2.29777539, grad/param norm = 9.5926e-01, time/batch = 0.0353s	
298/2700 (epoch 5.519), train_loss = 2.24429765, grad/param norm = 1.2674e+00, time/batch = 0.0348s	
299/2700 (epoch 5.537), train_loss = 2.28775004, grad/param norm = 1.3204e+00, time/batch = 0.0347s	
300/2700 (epoch 5.556), train_loss = 2.26151734, grad/param norm = 1.2243e+00, time/batch = 0.0347s	
301/2700 (epoch 5.574), train_loss = 2.23458000, grad/param norm = 1.4951e+00, time/batch = 0.0355s	
302/2700 (epoch 5.593), train_loss = 2.23391269, grad/param norm = 1.4817e+00, time/batch = 0.0346s	
303/2700 (epoch 5.611), train_loss = 2.13213269, grad/param norm = 1.1749e+00, time/batch = 0.0347s	
304/2700 (epoch 5.630), train_loss = 2.19456403, grad/param norm = 1.0067e+00, time/batch = 0.0346s	
305/2700 (epoch 5.648), train_loss = 2.21383693, grad/param norm = 9.0148e-01, time/batch = 0.0352s	
306/2700 (epoch 5.667), train_loss = 2.15324642, grad/param norm = 8.6075e-01, time/batch = 0.0374s	
307/2700 (epoch 5.685), train_loss = 2.19749762, grad/param norm = 8.7182e-01, time/batch = 0.0383s	
308/2700 (epoch 5.704), train_loss = 2.19945435, grad/param norm = 9.0166e-01, time/batch = 0.0388s	
309/2700 (epoch 5.722), train_loss = 2.17797465, grad/param norm = 9.2301e-01, time/batch = 0.0404s	
310/2700 (epoch 5.741), train_loss = 2.30543345, grad/param norm = 1.0705e+00, time/batch = 0.0370s	
311/2700 (epoch 5.759), train_loss = 2.28190087, grad/param norm = 1.1196e+00, time/batch = 0.0371s	
312/2700 (epoch 5.778), train_loss = 2.26125944, grad/param norm = 1.1631e+00, time/batch = 0.0366s	
313/2700 (epoch 5.796), train_loss = 2.21920545, grad/param norm = 1.2410e+00, time/batch = 0.0361s	
314/2700 (epoch 5.815), train_loss = 2.24338941, grad/param norm = 9.4038e-01, time/batch = 0.0399s	
315/2700 (epoch 5.833), train_loss = 2.19831455, grad/param norm = 9.1972e-01, time/batch = 0.0385s	
316/2700 (epoch 5.852), train_loss = 2.22508948, grad/param norm = 1.0334e+00, time/batch = 0.0403s	
317/2700 (epoch 5.870), train_loss = 2.19448610, grad/param norm = 1.1826e+00, time/batch = 0.0402s	
318/2700 (epoch 5.889), train_loss = 2.20573425, grad/param norm = 9.3047e-01, time/batch = 0.0393s	
319/2700 (epoch 5.907), train_loss = 2.30878157, grad/param norm = 7.9851e-01, time/batch = 0.0389s	
320/2700 (epoch 5.926), train_loss = 2.25737147, grad/param norm = 8.8254e-01, time/batch = 0.0369s	
321/2700 (epoch 5.944), train_loss = 2.24308052, grad/param norm = 7.4202e-01, time/batch = 0.0389s	
322/2700 (epoch 5.963), train_loss = 2.27848161, grad/param norm = 7.3401e-01, time/batch = 0.0386s	
323/2700 (epoch 5.981), train_loss = 2.26982930, grad/param norm = 8.2367e-01, time/batch = 0.0385s	
324/2700 (epoch 6.000), train_loss = 2.26680430, grad/param norm = 9.0614e-01, time/batch = 0.0384s	
325/2700 (epoch 6.019), train_loss = 2.22821763, grad/param norm = 9.3861e-01, time/batch = 0.0394s	
326/2700 (epoch 6.037), train_loss = 2.25373280, grad/param norm = 9.3712e-01, time/batch = 0.0360s	
327/2700 (epoch 6.056), train_loss = 2.21927258, grad/param norm = 1.2095e+00, time/batch = 0.0418s	
328/2700 (epoch 6.074), train_loss = 2.20843799, grad/param norm = 1.3231e+00, time/batch = 0.0353s	
329/2700 (epoch 6.093), train_loss = 2.24817147, grad/param norm = 1.1627e+00, time/batch = 0.0354s	
330/2700 (epoch 6.111), train_loss = 2.19480844, grad/param norm = 1.0665e+00, time/batch = 0.0362s	
331/2700 (epoch 6.130), train_loss = 2.21551574, grad/param norm = 8.1038e-01, time/batch = 0.0374s	
332/2700 (epoch 6.148), train_loss = 2.15055955, grad/param norm = 7.5226e-01, time/batch = 0.0354s	
333/2700 (epoch 6.167), train_loss = 2.21673409, grad/param norm = 7.0770e-01, time/batch = 0.0350s	
334/2700 (epoch 6.185), train_loss = 2.14211585, grad/param norm = 5.3385e-01, time/batch = 0.0377s	
335/2700 (epoch 6.204), train_loss = 2.15536216, grad/param norm = 6.0147e-01, time/batch = 0.0385s	
336/2700 (epoch 6.222), train_loss = 2.09083364, grad/param norm = 8.3965e-01, time/batch = 0.0420s	
337/2700 (epoch 6.241), train_loss = 2.07067986, grad/param norm = 9.2864e-01, time/batch = 0.0352s	
338/2700 (epoch 6.259), train_loss = 2.10497800, grad/param norm = 8.1407e-01, time/batch = 0.0398s	
339/2700 (epoch 6.278), train_loss = 2.20473291, grad/param norm = 8.1195e-01, time/batch = 0.0354s	
340/2700 (epoch 6.296), train_loss = 2.18206945, grad/param norm = 9.3971e-01, time/batch = 0.0356s	
341/2700 (epoch 6.315), train_loss = 2.20520111, grad/param norm = 9.8510e-01, time/batch = 0.0358s	
342/2700 (epoch 6.333), train_loss = 2.19705025, grad/param norm = 9.5302e-01, time/batch = 0.0358s	
343/2700 (epoch 6.352), train_loss = 2.23203946, grad/param norm = 9.0948e-01, time/batch = 0.0349s	
344/2700 (epoch 6.370), train_loss = 2.23592066, grad/param norm = 1.2617e+00, time/batch = 0.0363s	
345/2700 (epoch 6.389), train_loss = 2.20990902, grad/param norm = 1.1552e+00, time/batch = 0.0355s	
346/2700 (epoch 6.407), train_loss = 2.19600782, grad/param norm = 9.9716e-01, time/batch = 0.0353s	
347/2700 (epoch 6.426), train_loss = 2.20379320, grad/param norm = 9.1247e-01, time/batch = 0.0356s	
348/2700 (epoch 6.444), train_loss = 2.12267133, grad/param norm = 1.1287e+00, time/batch = 0.0354s	
349/2700 (epoch 6.463), train_loss = 2.21940437, grad/param norm = 1.2116e+00, time/batch = 0.0355s	
350/2700 (epoch 6.481), train_loss = 2.23509869, grad/param norm = 1.1145e+00, time/batch = 0.0356s	
351/2700 (epoch 6.500), train_loss = 2.23088241, grad/param norm = 1.0850e+00, time/batch = 0.0362s	
352/2700 (epoch 6.519), train_loss = 2.16380554, grad/param norm = 8.9576e-01, time/batch = 0.0357s	
353/2700 (epoch 6.537), train_loss = 2.20417662, grad/param norm = 8.3613e-01, time/batch = 0.0356s	
354/2700 (epoch 6.556), train_loss = 2.15963320, grad/param norm = 7.3862e-01, time/batch = 0.0372s	
355/2700 (epoch 6.574), train_loss = 2.14003528, grad/param norm = 7.5090e-01, time/batch = 0.0361s	
356/2700 (epoch 6.593), train_loss = 2.13878007, grad/param norm = 7.7606e-01, time/batch = 0.0396s	
357/2700 (epoch 6.611), train_loss = 2.05430837, grad/param norm = 7.4093e-01, time/batch = 0.0399s	
358/2700 (epoch 6.630), train_loss = 2.11761269, grad/param norm = 7.8658e-01, time/batch = 0.0392s	
359/2700 (epoch 6.648), train_loss = 2.13367548, grad/param norm = 6.5720e-01, time/batch = 0.0387s	
360/2700 (epoch 6.667), train_loss = 2.08171523, grad/param norm = 5.6245e-01, time/batch = 0.0476s	
361/2700 (epoch 6.685), train_loss = 2.12568663, grad/param norm = 7.0357e-01, time/batch = 0.0698s	
362/2700 (epoch 6.704), train_loss = 2.13442040, grad/param norm = 8.6920e-01, time/batch = 0.0780s	
363/2700 (epoch 6.722), train_loss = 2.11117744, grad/param norm = 8.8104e-01, time/batch = 0.0766s	
364/2700 (epoch 6.741), train_loss = 2.22289940, grad/param norm = 8.2726e-01, time/batch = 0.0767s	
365/2700 (epoch 6.759), train_loss = 2.21570652, grad/param norm = 9.1786e-01, time/batch = 0.0764s	
366/2700 (epoch 6.778), train_loss = 2.19375222, grad/param norm = 1.0765e+00, time/batch = 0.0772s	
367/2700 (epoch 6.796), train_loss = 2.16590196, grad/param norm = 1.2668e+00, time/batch = 0.0769s	
368/2700 (epoch 6.815), train_loss = 2.20397887, grad/param norm = 1.4207e+00, time/batch = 0.0768s	
369/2700 (epoch 6.833), train_loss = 2.14532542, grad/param norm = 1.1048e+00, time/batch = 0.0763s	
370/2700 (epoch 6.852), train_loss = 2.16124186, grad/param norm = 7.3600e-01, time/batch = 0.0756s	
371/2700 (epoch 6.870), train_loss = 2.11718319, grad/param norm = 7.1598e-01, time/batch = 0.0781s	
372/2700 (epoch 6.889), train_loss = 2.13944598, grad/param norm = 8.0219e-01, time/batch = 0.0768s	
373/2700 (epoch 6.907), train_loss = 2.24783670, grad/param norm = 8.7610e-01, time/batch = 0.0765s	
374/2700 (epoch 6.926), train_loss = 2.18849561, grad/param norm = 8.7840e-01, time/batch = 0.0765s	
375/2700 (epoch 6.944), train_loss = 2.17500094, grad/param norm = 8.5746e-01, time/batch = 0.0765s	
376/2700 (epoch 6.963), train_loss = 2.21180658, grad/param norm = 8.3057e-01, time/batch = 0.0774s	
377/2700 (epoch 6.981), train_loss = 2.19619913, grad/param norm = 7.3123e-01, time/batch = 0.0768s	
378/2700 (epoch 7.000), train_loss = 2.19946753, grad/param norm = 8.8897e-01, time/batch = 0.0770s	
379/2700 (epoch 7.019), train_loss = 2.17186617, grad/param norm = 8.2106e-01, time/batch = 0.0768s	
380/2700 (epoch 7.037), train_loss = 2.19088949, grad/param norm = 8.3520e-01, time/batch = 0.0709s	
381/2700 (epoch 7.056), train_loss = 2.14614454, grad/param norm = 8.3985e-01, time/batch = 0.0777s	
382/2700 (epoch 7.074), train_loss = 2.12029439, grad/param norm = 8.1979e-01, time/batch = 0.0757s	
383/2700 (epoch 7.093), train_loss = 2.16391233, grad/param norm = 7.7701e-01, time/batch = 0.0757s	
384/2700 (epoch 7.111), train_loss = 2.11881698, grad/param norm = 7.7082e-01, time/batch = 0.0756s	
385/2700 (epoch 7.130), train_loss = 2.14569600, grad/param norm = 7.9880e-01, time/batch = 0.0756s	
386/2700 (epoch 7.148), train_loss = 2.08673402, grad/param norm = 9.3889e-01, time/batch = 0.0765s	
387/2700 (epoch 7.167), train_loss = 2.16311420, grad/param norm = 8.5728e-01, time/batch = 0.0759s	
388/2700 (epoch 7.185), train_loss = 2.09210326, grad/param norm = 8.1818e-01, time/batch = 0.0759s	
389/2700 (epoch 7.204), train_loss = 2.11465450, grad/param norm = 9.4785e-01, time/batch = 0.0755s	
390/2700 (epoch 7.222), train_loss = 2.05097970, grad/param norm = 1.0235e+00, time/batch = 0.0743s	
391/2700 (epoch 7.241), train_loss = 2.01424155, grad/param norm = 8.4307e-01, time/batch = 0.0781s	
392/2700 (epoch 7.259), train_loss = 2.05408307, grad/param norm = 9.5588e-01, time/batch = 0.0764s	
393/2700 (epoch 7.278), train_loss = 2.16545674, grad/param norm = 1.1048e+00, time/batch = 0.0768s	
394/2700 (epoch 7.296), train_loss = 2.12211229, grad/param norm = 9.8061e-01, time/batch = 0.0765s	
395/2700 (epoch 7.315), train_loss = 2.14214790, grad/param norm = 8.7911e-01, time/batch = 0.0767s	
396/2700 (epoch 7.333), train_loss = 2.12243061, grad/param norm = 7.0524e-01, time/batch = 0.0771s	
397/2700 (epoch 7.352), train_loss = 2.14668069, grad/param norm = 5.8068e-01, time/batch = 0.0770s	
398/2700 (epoch 7.370), train_loss = 2.14849636, grad/param norm = 5.7056e-01, time/batch = 0.0769s	
399/2700 (epoch 7.389), train_loss = 2.10794903, grad/param norm = 6.6735e-01, time/batch = 0.0770s	
400/2700 (epoch 7.407), train_loss = 2.12734140, grad/param norm = 8.7264e-01, time/batch = 0.0765s	
401/2700 (epoch 7.426), train_loss = 2.14421988, grad/param norm = 7.2900e-01, time/batch = 0.0777s	
402/2700 (epoch 7.444), train_loss = 2.05125066, grad/param norm = 7.4970e-01, time/batch = 0.0764s	
403/2700 (epoch 7.463), train_loss = 2.14690321, grad/param norm = 8.5021e-01, time/batch = 0.0765s	
404/2700 (epoch 7.481), train_loss = 2.16774486, grad/param norm = 9.1512e-01, time/batch = 0.0763s	
405/2700 (epoch 7.500), train_loss = 2.17024658, grad/param norm = 1.0080e+00, time/batch = 0.0762s	
406/2700 (epoch 7.519), train_loss = 2.10365735, grad/param norm = 8.8014e-01, time/batch = 0.0763s	
407/2700 (epoch 7.537), train_loss = 2.14723351, grad/param norm = 8.5129e-01, time/batch = 0.0755s	
408/2700 (epoch 7.556), train_loss = 2.10233408, grad/param norm = 8.5366e-01, time/batch = 0.0737s	
409/2700 (epoch 7.574), train_loss = 2.09152371, grad/param norm = 8.0443e-01, time/batch = 0.0621s	
410/2700 (epoch 7.593), train_loss = 2.08898988, grad/param norm = 7.6138e-01, time/batch = 0.0566s	
411/2700 (epoch 7.611), train_loss = 1.99990818, grad/param norm = 7.0714e-01, time/batch = 0.0467s	
412/2700 (epoch 7.630), train_loss = 2.06039530, grad/param norm = 7.5851e-01, time/batch = 0.0761s	
413/2700 (epoch 7.648), train_loss = 2.07587968, grad/param norm = 6.7369e-01, time/batch = 0.0755s	
414/2700 (epoch 7.667), train_loss = 2.02898814, grad/param norm = 6.8561e-01, time/batch = 0.0756s	
415/2700 (epoch 7.685), train_loss = 2.07508735, grad/param norm = 9.4809e-01, time/batch = 0.0768s	
416/2700 (epoch 7.704), train_loss = 2.09617175, grad/param norm = 1.2660e+00, time/batch = 0.0763s	
417/2700 (epoch 7.722), train_loss = 2.07557755, grad/param norm = 1.0002e+00, time/batch = 0.0767s	
418/2700 (epoch 7.741), train_loss = 2.16337263, grad/param norm = 8.3015e-01, time/batch = 0.0769s	
419/2700 (epoch 7.759), train_loss = 2.15857887, grad/param norm = 7.9975e-01, time/batch = 0.0774s	
420/2700 (epoch 7.778), train_loss = 2.13226175, grad/param norm = 7.5243e-01, time/batch = 0.0774s	
421/2700 (epoch 7.796), train_loss = 2.08889106, grad/param norm = 7.7414e-01, time/batch = 0.0559s	
422/2700 (epoch 7.815), train_loss = 2.12160098, grad/param norm = 9.1028e-01, time/batch = 0.0627s	
423/2700 (epoch 7.833), train_loss = 2.07441417, grad/param norm = 8.6859e-01, time/batch = 0.0572s	
424/2700 (epoch 7.852), train_loss = 2.09797710, grad/param norm = 6.4436e-01, time/batch = 0.0588s	
425/2700 (epoch 7.870), train_loss = 2.05984615, grad/param norm = 6.4247e-01, time/batch = 0.0656s	
426/2700 (epoch 7.889), train_loss = 2.08567894, grad/param norm = 7.5936e-01, time/batch = 0.0746s	
427/2700 (epoch 7.907), train_loss = 2.19629874, grad/param norm = 9.1306e-01, time/batch = 0.0759s	
428/2700 (epoch 7.926), train_loss = 2.14247429, grad/param norm = 1.1093e+00, time/batch = 0.0755s	
429/2700 (epoch 7.944), train_loss = 2.13439344, grad/param norm = 9.5058e-01, time/batch = 0.0755s	
430/2700 (epoch 7.963), train_loss = 2.16715798, grad/param norm = 9.5165e-01, time/batch = 0.0761s	
431/2700 (epoch 7.981), train_loss = 2.14600247, grad/param norm = 7.2986e-01, time/batch = 0.0641s	
432/2700 (epoch 8.000), train_loss = 2.14362540, grad/param norm = 7.6777e-01, time/batch = 0.0527s	
433/2700 (epoch 8.019), train_loss = 2.10880144, grad/param norm = 6.3001e-01, time/batch = 0.0594s	
434/2700 (epoch 8.037), train_loss = 2.12190428, grad/param norm = 5.3493e-01, time/batch = 0.0561s	
435/2700 (epoch 8.056), train_loss = 2.08057276, grad/param norm = 6.9863e-01, time/batch = 0.0631s	
436/2700 (epoch 8.074), train_loss = 2.05466031, grad/param norm = 7.9040e-01, time/batch = 0.0682s	
437/2700 (epoch 8.093), train_loss = 2.09254778, grad/param norm = 7.3780e-01, time/batch = 0.0743s	
438/2700 (epoch 8.111), train_loss = 2.05654444, grad/param norm = 7.4591e-01, time/batch = 0.0755s	
439/2700 (epoch 8.130), train_loss = 2.08758526, grad/param norm = 6.3662e-01, time/batch = 0.0759s	
440/2700 (epoch 8.148), train_loss = 2.02415231, grad/param norm = 6.9470e-01, time/batch = 0.0760s	
441/2700 (epoch 8.167), train_loss = 2.10631924, grad/param norm = 7.7282e-01, time/batch = 0.0622s	
442/2700 (epoch 8.185), train_loss = 2.02732551, grad/param norm = 6.2890e-01, time/batch = 0.0686s	
443/2700 (epoch 8.204), train_loss = 2.05840943, grad/param norm = 7.3063e-01, time/batch = 0.0590s	
444/2700 (epoch 8.222), train_loss = 1.98706893, grad/param norm = 9.4579e-01, time/batch = 0.0595s	
445/2700 (epoch 8.241), train_loss = 1.95506036, grad/param norm = 1.0534e+00, time/batch = 0.0566s	
446/2700 (epoch 8.259), train_loss = 2.00087831, grad/param norm = 9.5706e-01, time/batch = 0.0641s	
447/2700 (epoch 8.278), train_loss = 2.08525581, grad/param norm = 6.2527e-01, time/batch = 0.0715s	
448/2700 (epoch 8.296), train_loss = 2.05872282, grad/param norm = 6.5545e-01, time/batch = 0.0754s	
449/2700 (epoch 8.315), train_loss = 2.09159889, grad/param norm = 7.6165e-01, time/batch = 0.0753s	
450/2700 (epoch 8.333), train_loss = 2.08862226, grad/param norm = 8.0491e-01, time/batch = 0.0765s	
451/2700 (epoch 8.352), train_loss = 2.10971500, grad/param norm = 8.8004e-01, time/batch = 0.0617s	
452/2700 (epoch 8.370), train_loss = 2.11182726, grad/param norm = 8.8665e-01, time/batch = 0.0665s	
453/2700 (epoch 8.389), train_loss = 2.07633933, grad/param norm = 7.6089e-01, time/batch = 0.0735s	
454/2700 (epoch 8.407), train_loss = 2.07208849, grad/param norm = 5.9005e-01, time/batch = 0.0750s	
455/2700 (epoch 8.426), train_loss = 2.08900525, grad/param norm = 5.3720e-01, time/batch = 0.0562s	
456/2700 (epoch 8.444), train_loss = 1.99576174, grad/param norm = 5.5378e-01, time/batch = 0.0644s	
457/2700 (epoch 8.463), train_loss = 2.09142250, grad/param norm = 6.3282e-01, time/batch = 0.0522s	
458/2700 (epoch 8.481), train_loss = 2.11021894, grad/param norm = 6.8549e-01, time/batch = 0.0883s	
459/2700 (epoch 8.500), train_loss = 2.10740965, grad/param norm = 7.2047e-01, time/batch = 0.0959s	
460/2700 (epoch 8.519), train_loss = 2.04656230, grad/param norm = 6.8945e-01, time/batch = 0.0952s	
461/2700 (epoch 8.537), train_loss = 2.09048099, grad/param norm = 7.5290e-01, time/batch = 0.0953s	
462/2700 (epoch 8.556), train_loss = 2.04966046, grad/param norm = 9.4346e-01, time/batch = 0.0970s	
463/2700 (epoch 8.574), train_loss = 2.04755782, grad/param norm = 9.3829e-01, time/batch = 0.0969s	
464/2700 (epoch 8.593), train_loss = 2.05730114, grad/param norm = 9.2657e-01, time/batch = 0.0963s	
465/2700 (epoch 8.611), train_loss = 1.95629600, grad/param norm = 7.7777e-01, time/batch = 0.0857s	
466/2700 (epoch 8.630), train_loss = 2.01178643, grad/param norm = 8.2483e-01, time/batch = 0.0934s	
467/2700 (epoch 8.648), train_loss = 2.02814497, grad/param norm = 8.0591e-01, time/batch = 0.0691s	
468/2700 (epoch 8.667), train_loss = 1.98850668, grad/param norm = 8.1464e-01, time/batch = 0.0867s	
469/2700 (epoch 8.685), train_loss = 2.03263988, grad/param norm = 9.5307e-01, time/batch = 0.0847s	
470/2700 (epoch 8.704), train_loss = 2.04989177, grad/param norm = 1.0355e+00, time/batch = 0.0779s	
471/2700 (epoch 8.722), train_loss = 2.01674720, grad/param norm = 7.6089e-01, time/batch = 0.0896s	
472/2700 (epoch 8.741), train_loss = 2.09458720, grad/param norm = 5.7798e-01, time/batch = 0.0892s	
473/2700 (epoch 8.759), train_loss = 2.10003541, grad/param norm = 6.3195e-01, time/batch = 0.0885s	
474/2700 (epoch 8.778), train_loss = 2.08177165, grad/param norm = 6.6882e-01, time/batch = 0.0834s	
475/2700 (epoch 8.796), train_loss = 2.04267613, grad/param norm = 7.0467e-01, time/batch = 0.0780s	
476/2700 (epoch 8.815), train_loss = 2.07268760, grad/param norm = 7.2283e-01, time/batch = 0.0795s	
477/2700 (epoch 8.833), train_loss = 2.02271705, grad/param norm = 7.6706e-01, time/batch = 0.0842s	
478/2700 (epoch 8.852), train_loss = 2.04087803, grad/param norm = 6.0175e-01, time/batch = 0.0664s	
479/2700 (epoch 8.870), train_loss = 2.01178826, grad/param norm = 6.2965e-01, time/batch = 0.0826s	
480/2700 (epoch 8.889), train_loss = 2.03709587, grad/param norm = 7.8908e-01, time/batch = 0.0778s	
481/2700 (epoch 8.907), train_loss = 2.15665390, grad/param norm = 9.3702e-01, time/batch = 0.0970s	
482/2700 (epoch 8.926), train_loss = 2.08497164, grad/param norm = 9.2934e-01, time/batch = 0.1038s	
483/2700 (epoch 8.944), train_loss = 2.07833936, grad/param norm = 9.3136e-01, time/batch = 0.1402s	
484/2700 (epoch 8.963), train_loss = 2.10958512, grad/param norm = 8.8841e-01, time/batch = 0.1377s	
485/2700 (epoch 8.981), train_loss = 2.08877472, grad/param norm = 7.2327e-01, time/batch = 0.1390s	
486/2700 (epoch 9.000), train_loss = 2.09178954, grad/param norm = 6.1948e-01, time/batch = 0.1392s	
487/2700 (epoch 9.019), train_loss = 2.06289640, grad/param norm = 6.9535e-01, time/batch = 0.1391s	
488/2700 (epoch 9.037), train_loss = 2.08424067, grad/param norm = 7.5230e-01, time/batch = 0.1233s	
489/2700 (epoch 9.056), train_loss = 2.04191026, grad/param norm = 7.1247e-01, time/batch = 0.0811s	
490/2700 (epoch 9.074), train_loss = 2.00946811, grad/param norm = 6.4401e-01, time/batch = 0.1049s	
491/2700 (epoch 9.093), train_loss = 2.04715150, grad/param norm = 7.1252e-01, time/batch = 0.1082s	
492/2700 (epoch 9.111), train_loss = 2.01260758, grad/param norm = 6.9473e-01, time/batch = 0.1361s	
493/2700 (epoch 9.130), train_loss = 2.04646025, grad/param norm = 7.6088e-01, time/batch = 0.1276s	
494/2700 (epoch 9.148), train_loss = 1.99485724, grad/param norm = 8.5127e-01, time/batch = 0.1216s	
495/2700 (epoch 9.167), train_loss = 2.06710988, grad/param norm = 6.8095e-01, time/batch = 0.1192s	
496/2700 (epoch 9.185), train_loss = 1.97683125, grad/param norm = 5.8963e-01, time/batch = 0.1273s	
497/2700 (epoch 9.204), train_loss = 2.01796459, grad/param norm = 8.3834e-01, time/batch = 0.1328s	
498/2700 (epoch 9.222), train_loss = 1.94161578, grad/param norm = 7.7850e-01, time/batch = 0.1356s	
499/2700 (epoch 9.241), train_loss = 1.90060158, grad/param norm = 6.0751e-01, time/batch = 0.1248s	
500/2700 (epoch 9.259), train_loss = 1.95005450, grad/param norm = 7.8603e-01, time/batch = 0.1340s	
501/2700 (epoch 9.278), train_loss = 2.06557037, grad/param norm = 1.0612e+00, time/batch = 0.1174s	
502/2700 (epoch 9.296), train_loss = 2.02426855, grad/param norm = 9.3164e-01, time/batch = 0.1208s	
503/2700 (epoch 9.315), train_loss = 2.04249955, grad/param norm = 7.7211e-01, time/batch = 0.1231s	
504/2700 (epoch 9.333), train_loss = 2.01874558, grad/param norm = 6.5942e-01, time/batch = 0.1104s	
505/2700 (epoch 9.352), train_loss = 2.03977161, grad/param norm = 5.3306e-01, time/batch = 0.1058s	
506/2700 (epoch 9.370), train_loss = 2.05297500, grad/param norm = 5.7847e-01, time/batch = 0.1128s	
507/2700 (epoch 9.389), train_loss = 2.01724683, grad/param norm = 6.7419e-01, time/batch = 0.1175s	
508/2700 (epoch 9.407), train_loss = 2.03119912, grad/param norm = 6.9129e-01, time/batch = 0.1229s	
509/2700 (epoch 9.426), train_loss = 2.05196301, grad/param norm = 6.5090e-01, time/batch = 0.1229s	
510/2700 (epoch 9.444), train_loss = 1.96216918, grad/param norm = 7.0007e-01, time/batch = 0.1394s	
511/2700 (epoch 9.463), train_loss = 2.05883550, grad/param norm = 7.2626e-01, time/batch = 0.1060s	
512/2700 (epoch 9.481), train_loss = 2.06766726, grad/param norm = 7.3802e-01, time/batch = 0.1203s	
513/2700 (epoch 9.500), train_loss = 2.05920908, grad/param norm = 7.9541e-01, time/batch = 0.1233s	
514/2700 (epoch 9.519), train_loss = 2.00347153, grad/param norm = 6.8211e-01, time/batch = 0.1229s	
515/2700 (epoch 9.537), train_loss = 2.04192802, grad/param norm = 6.6773e-01, time/batch = 0.1243s	
516/2700 (epoch 9.556), train_loss = 1.99672337, grad/param norm = 7.8140e-01, time/batch = 0.1015s	
517/2700 (epoch 9.574), train_loss = 1.99148476, grad/param norm = 7.2983e-01, time/batch = 0.1113s	
518/2700 (epoch 9.593), train_loss = 1.99625507, grad/param norm = 6.9062e-01, time/batch = 0.1242s	
519/2700 (epoch 9.611), train_loss = 1.90236401, grad/param norm = 5.9855e-01, time/batch = 0.1202s	
520/2700 (epoch 9.630), train_loss = 1.95996304, grad/param norm = 6.4469e-01, time/batch = 0.1408s	
521/2700 (epoch 9.648), train_loss = 1.97611626, grad/param norm = 5.8688e-01, time/batch = 0.1245s	
522/2700 (epoch 9.667), train_loss = 1.93788001, grad/param norm = 5.7843e-01, time/batch = 0.1309s	
523/2700 (epoch 9.685), train_loss = 1.98227763, grad/param norm = 7.4398e-01, time/batch = 0.1241s	
524/2700 (epoch 9.704), train_loss = 1.99886488, grad/param norm = 7.5315e-01, time/batch = 0.1183s	
525/2700 (epoch 9.722), train_loss = 1.96576993, grad/param norm = 7.0630e-01, time/batch = 0.1192s	
526/2700 (epoch 9.741), train_loss = 2.05362514, grad/param norm = 7.7752e-01, time/batch = 0.1092s	
527/2700 (epoch 9.759), train_loss = 2.06267929, grad/param norm = 9.1339e-01, time/batch = 0.0864s	
528/2700 (epoch 9.778), train_loss = 2.06099880, grad/param norm = 9.8059e-01, time/batch = 0.1228s	
529/2700 (epoch 9.796), train_loss = 2.01351005, grad/param norm = 9.1232e-01, time/batch = 0.1039s	
530/2700 (epoch 9.815), train_loss = 2.04110963, grad/param norm = 8.2478e-01, time/batch = 0.1262s	
531/2700 (epoch 9.833), train_loss = 1.98275716, grad/param norm = 8.2724e-01, time/batch = 0.1388s	
532/2700 (epoch 9.852), train_loss = 2.00837985, grad/param norm = 8.9032e-01, time/batch = 0.1236s	
533/2700 (epoch 9.870), train_loss = 1.97741105, grad/param norm = 8.1356e-01, time/batch = 0.1135s	
534/2700 (epoch 9.889), train_loss = 1.99993586, grad/param norm = 6.3938e-01, time/batch = 0.1248s	
535/2700 (epoch 9.907), train_loss = 2.10139260, grad/param norm = 5.7578e-01, time/batch = 0.1268s	
536/2700 (epoch 9.926), train_loss = 2.03250496, grad/param norm = 6.1395e-01, time/batch = 0.1251s	
537/2700 (epoch 9.944), train_loss = 2.01983122, grad/param norm = 5.4130e-01, time/batch = 0.1294s	
538/2700 (epoch 9.963), train_loss = 2.05170284, grad/param norm = 5.5617e-01, time/batch = 0.1107s	
539/2700 (epoch 9.981), train_loss = 2.03576602, grad/param norm = 6.1765e-01, time/batch = 0.0988s	
decayed learning rate by a factor 0.97 to 0.00194	
540/2700 (epoch 10.000), train_loss = 2.05118753, grad/param norm = 6.4077e-01, time/batch = 0.1227s	
541/2700 (epoch 10.019), train_loss = 2.01670396, grad/param norm = 7.8339e-01, time/batch = 0.1293s	
542/2700 (epoch 10.037), train_loss = 2.03677540, grad/param norm = 7.1523e-01, time/batch = 0.1209s	
543/2700 (epoch 10.056), train_loss = 2.00131710, grad/param norm = 7.9859e-01, time/batch = 0.1233s	
544/2700 (epoch 10.074), train_loss = 1.96687083, grad/param norm = 7.6006e-01, time/batch = 0.1297s	
545/2700 (epoch 10.093), train_loss = 1.99318562, grad/param norm = 6.3423e-01, time/batch = 0.1311s	
546/2700 (epoch 10.111), train_loss = 1.95776372, grad/param norm = 5.8324e-01, time/batch = 0.1300s	
547/2700 (epoch 10.130), train_loss = 1.99235787, grad/param norm = 6.1635e-01, time/batch = 0.1268s	
548/2700 (epoch 10.148), train_loss = 1.94002054, grad/param norm = 6.6400e-01, time/batch = 0.1289s	
549/2700 (epoch 10.167), train_loss = 2.01826492, grad/param norm = 5.8608e-01, time/batch = 0.1089s	
550/2700 (epoch 10.185), train_loss = 1.93196604, grad/param norm = 5.0277e-01, time/batch = 0.1178s	
551/2700 (epoch 10.204), train_loss = 1.97647146, grad/param norm = 6.0515e-01, time/batch = 0.0979s	
552/2700 (epoch 10.222), train_loss = 1.89400619, grad/param norm = 6.1212e-01, time/batch = 0.1079s	
553/2700 (epoch 10.241), train_loss = 1.85290899, grad/param norm = 5.2241e-01, time/batch = 0.1181s	
554/2700 (epoch 10.259), train_loss = 1.89781287, grad/param norm = 5.3689e-01, time/batch = 0.1266s	
555/2700 (epoch 10.278), train_loss = 1.99108115, grad/param norm = 5.2255e-01, time/batch = 0.1272s	
556/2700 (epoch 10.296), train_loss = 1.96429319, grad/param norm = 5.3236e-01, time/batch = 0.1249s	
557/2700 (epoch 10.315), train_loss = 1.99145821, grad/param norm = 5.3898e-01, time/batch = 0.1246s	
558/2700 (epoch 10.333), train_loss = 1.97462462, grad/param norm = 6.1585e-01, time/batch = 0.1256s	
559/2700 (epoch 10.352), train_loss = 2.00040308, grad/param norm = 7.0071e-01, time/batch = 0.1084s	
560/2700 (epoch 10.370), train_loss = 2.02245963, grad/param norm = 8.3435e-01, time/batch = 0.1162s	
561/2700 (epoch 10.389), train_loss = 1.98845533, grad/param norm = 8.7229e-01, time/batch = 0.0987s	
562/2700 (epoch 10.407), train_loss = 2.00367491, grad/param norm = 7.6998e-01, time/batch = 0.1261s	
563/2700 (epoch 10.426), train_loss = 2.02519316, grad/param norm = 8.0180e-01, time/batch = 0.1261s	
564/2700 (epoch 10.444), train_loss = 1.92324646, grad/param norm = 6.4962e-01, time/batch = 0.1241s	
565/2700 (epoch 10.463), train_loss = 2.00986295, grad/param norm = 6.1334e-01, time/batch = 0.1189s	
566/2700 (epoch 10.481), train_loss = 2.02012149, grad/param norm = 5.7025e-01, time/batch = 0.1131s	
567/2700 (epoch 10.500), train_loss = 2.00503503, grad/param norm = 5.4334e-01, time/batch = 0.1158s	
568/2700 (epoch 10.519), train_loss = 1.96138616, grad/param norm = 6.0340e-01, time/batch = 0.1259s	
569/2700 (epoch 10.537), train_loss = 1.99857789, grad/param norm = 6.3708e-01, time/batch = 0.1163s	
570/2700 (epoch 10.556), train_loss = 1.95930939, grad/param norm = 6.8943e-01, time/batch = 0.1324s	
571/2700 (epoch 10.574), train_loss = 1.96091705, grad/param norm = 9.9446e-01, time/batch = 0.1123s	
572/2700 (epoch 10.593), train_loss = 1.98180075, grad/param norm = 1.0398e+00, time/batch = 0.1014s	
573/2700 (epoch 10.611), train_loss = 1.87885736, grad/param norm = 8.5871e-01, time/batch = 0.1133s	
574/2700 (epoch 10.630), train_loss = 1.92715322, grad/param norm = 7.6188e-01, time/batch = 0.1086s	
575/2700 (epoch 10.648), train_loss = 1.94171947, grad/param norm = 6.7356e-01, time/batch = 0.1186s	
576/2700 (epoch 10.667), train_loss = 1.90391999, grad/param norm = 6.7096e-01, time/batch = 0.1207s	
577/2700 (epoch 10.685), train_loss = 1.94033861, grad/param norm = 7.5241e-01, time/batch = 0.1226s	
578/2700 (epoch 10.704), train_loss = 1.95759212, grad/param norm = 7.1259e-01, time/batch = 0.1280s	
579/2700 (epoch 10.722), train_loss = 1.92348752, grad/param norm = 5.8800e-01, time/batch = 0.1139s	
580/2700 (epoch 10.741), train_loss = 1.99955902, grad/param norm = 5.7173e-01, time/batch = 0.1367s	
581/2700 (epoch 10.759), train_loss = 2.00775717, grad/param norm = 5.6752e-01, time/batch = 0.1174s	
582/2700 (epoch 10.778), train_loss = 1.99627000, grad/param norm = 5.7352e-01, time/batch = 0.1206s	
583/2700 (epoch 10.796), train_loss = 1.95606383, grad/param norm = 5.5057e-01, time/batch = 0.1236s	
584/2700 (epoch 10.815), train_loss = 1.98853946, grad/param norm = 5.8058e-01, time/batch = 0.1011s	
585/2700 (epoch 10.833), train_loss = 1.93478803, grad/param norm = 6.0808e-01, time/batch = 0.1113s	
586/2700 (epoch 10.852), train_loss = 1.96108351, grad/param norm = 6.0194e-01, time/batch = 0.1191s	
587/2700 (epoch 10.870), train_loss = 1.93589282, grad/param norm = 5.6656e-01, time/batch = 0.1280s	
588/2700 (epoch 10.889), train_loss = 1.96077160, grad/param norm = 5.7354e-01, time/batch = 0.1254s	
589/2700 (epoch 10.907), train_loss = 2.07031246, grad/param norm = 7.0441e-01, time/batch = 0.1168s	
590/2700 (epoch 10.926), train_loss = 2.00244580, grad/param norm = 1.0037e+00, time/batch = 0.1386s	
591/2700 (epoch 10.944), train_loss = 1.99921016, grad/param norm = 8.3082e-01, time/batch = 0.1146s	
592/2700 (epoch 10.963), train_loss = 2.03157905, grad/param norm = 8.2579e-01, time/batch = 0.1254s	
593/2700 (epoch 10.981), train_loss = 1.99847125, grad/param norm = 6.8259e-01, time/batch = 0.1264s	
decayed learning rate by a factor 0.97 to 0.0018818	
594/2700 (epoch 11.000), train_loss = 2.01603010, grad/param norm = 6.3419e-01, time/batch = 0.1330s	
595/2700 (epoch 11.019), train_loss = 1.98541847, grad/param norm = 7.0211e-01, time/batch = 0.1045s	
596/2700 (epoch 11.037), train_loss = 1.99861516, grad/param norm = 6.5033e-01, time/batch = 0.1519s	
597/2700 (epoch 11.056), train_loss = 1.95183829, grad/param norm = 5.7555e-01, time/batch = 0.1508s	
598/2700 (epoch 11.074), train_loss = 1.91925227, grad/param norm = 5.0310e-01, time/batch = 0.1510s	
599/2700 (epoch 11.093), train_loss = 1.95048842, grad/param norm = 5.2926e-01, time/batch = 0.1411s	
600/2700 (epoch 11.111), train_loss = 1.91791761, grad/param norm = 5.7923e-01, time/batch = 0.1467s	
601/2700 (epoch 11.130), train_loss = 1.95733895, grad/param norm = 7.4120e-01, time/batch = 0.1491s	
602/2700 (epoch 11.148), train_loss = 1.90848922, grad/param norm = 9.1710e-01, time/batch = 0.1454s	
603/2700 (epoch 11.167), train_loss = 1.99417703, grad/param norm = 7.4139e-01, time/batch = 0.1420s	
604/2700 (epoch 11.185), train_loss = 1.89859888, grad/param norm = 5.8026e-01, time/batch = 0.1460s	
605/2700 (epoch 11.204), train_loss = 1.94195785, grad/param norm = 6.1701e-01, time/batch = 0.1255s	
606/2700 (epoch 11.222), train_loss = 1.85898281, grad/param norm = 6.0231e-01, time/batch = 0.1384s	
607/2700 (epoch 11.241), train_loss = 1.81632279, grad/param norm = 4.6538e-01, time/batch = 0.1227s	
608/2700 (epoch 11.259), train_loss = 1.86115295, grad/param norm = 4.6586e-01, time/batch = 0.1031s	
609/2700 (epoch 11.278), train_loss = 1.95708489, grad/param norm = 5.8087e-01, time/batch = 0.1201s	
610/2700 (epoch 11.296), train_loss = 1.92833651, grad/param norm = 6.1622e-01, time/batch = 0.1164s	
611/2700 (epoch 11.315), train_loss = 1.95568371, grad/param norm = 5.8639e-01, time/batch = 0.1307s	
612/2700 (epoch 11.333), train_loss = 1.93565776, grad/param norm = 5.8897e-01, time/batch = 0.1334s	
613/2700 (epoch 11.352), train_loss = 1.95624226, grad/param norm = 4.8685e-01, time/batch = 0.1372s	
614/2700 (epoch 11.370), train_loss = 1.97183809, grad/param norm = 5.3768e-01, time/batch = 0.1403s	
615/2700 (epoch 11.389), train_loss = 1.93610790, grad/param norm = 6.4171e-01, time/batch = 0.1415s	
616/2700 (epoch 11.407), train_loss = 1.95974430, grad/param norm = 8.9342e-01, time/batch = 0.1247s	
617/2700 (epoch 11.426), train_loss = 1.98101372, grad/param norm = 5.9290e-01, time/batch = 0.1301s	
618/2700 (epoch 11.444), train_loss = 1.88474317, grad/param norm = 6.1074e-01, time/batch = 0.1463s	
619/2700 (epoch 11.463), train_loss = 1.98561391, grad/param norm = 6.9670e-01, time/batch = 0.1534s	
620/2700 (epoch 11.481), train_loss = 1.99780533, grad/param norm = 7.3080e-01, time/batch = 0.1508s	
621/2700 (epoch 11.500), train_loss = 1.97585205, grad/param norm = 8.0414e-01, time/batch = 0.1625s	
622/2700 (epoch 11.519), train_loss = 1.93310683, grad/param norm = 6.2886e-01, time/batch = 0.1733s	
623/2700 (epoch 11.537), train_loss = 1.96182200, grad/param norm = 6.1216e-01, time/batch = 0.1741s	
624/2700 (epoch 11.556), train_loss = 1.91391868, grad/param norm = 6.8643e-01, time/batch = 0.1769s	
625/2700 (epoch 11.574), train_loss = 1.90789757, grad/param norm = 6.0086e-01, time/batch = 0.1782s	
626/2700 (epoch 11.593), train_loss = 1.91458705, grad/param norm = 6.1027e-01, time/batch = 0.1777s	
627/2700 (epoch 11.611), train_loss = 1.82436840, grad/param norm = 5.3107e-01, time/batch = 0.1707s	
628/2700 (epoch 11.630), train_loss = 1.88085375, grad/param norm = 5.6982e-01, time/batch = 0.1754s	
629/2700 (epoch 11.648), train_loss = 1.89554176, grad/param norm = 5.2200e-01, time/batch = 0.1694s	
630/2700 (epoch 11.667), train_loss = 1.86193992, grad/param norm = 5.0440e-01, time/batch = 0.1558s	
631/2700 (epoch 11.685), train_loss = 1.90293769, grad/param norm = 6.4329e-01, time/batch = 0.1584s	
632/2700 (epoch 11.704), train_loss = 1.92489409, grad/param norm = 6.4800e-01, time/batch = 0.1583s	
633/2700 (epoch 11.722), train_loss = 1.89136879, grad/param norm = 5.5160e-01, time/batch = 0.1558s	
634/2700 (epoch 11.741), train_loss = 1.95771340, grad/param norm = 5.2059e-01, time/batch = 0.1474s	
635/2700 (epoch 11.759), train_loss = 1.96746656, grad/param norm = 5.3612e-01, time/batch = 0.1346s	
636/2700 (epoch 11.778), train_loss = 1.95975440, grad/param norm = 5.3880e-01, time/batch = 0.1511s	
637/2700 (epoch 11.796), train_loss = 1.92356210, grad/param norm = 5.5705e-01, time/batch = 0.1638s	
638/2700 (epoch 11.815), train_loss = 1.95426447, grad/param norm = 5.6298e-01, time/batch = 0.1374s	
639/2700 (epoch 11.833), train_loss = 1.89751571, grad/param norm = 5.8772e-01, time/batch = 0.1678s	
640/2700 (epoch 11.852), train_loss = 1.92327644, grad/param norm = 7.2787e-01, time/batch = 0.1632s	
641/2700 (epoch 11.870), train_loss = 1.90518994, grad/param norm = 7.8334e-01, time/batch = 0.1517s	
642/2700 (epoch 11.889), train_loss = 1.93459398, grad/param norm = 6.8184e-01, time/batch = 0.1788s	
643/2700 (epoch 11.907), train_loss = 2.03591486, grad/param norm = 6.2531e-01, time/batch = 0.1801s	
644/2700 (epoch 11.926), train_loss = 1.96405430, grad/param norm = 6.6589e-01, time/batch = 0.1907s	
645/2700 (epoch 11.944), train_loss = 1.94887297, grad/param norm = 6.9400e-01, time/batch = 0.1753s	
646/2700 (epoch 11.963), train_loss = 1.98765876, grad/param norm = 6.9219e-01, time/batch = 0.1704s	
647/2700 (epoch 11.981), train_loss = 1.96227179, grad/param norm = 7.0415e-01, time/batch = 0.1634s	
decayed learning rate by a factor 0.97 to 0.001825346	
648/2700 (epoch 12.000), train_loss = 1.98772346, grad/param norm = 6.7928e-01, time/batch = 0.1450s	
649/2700 (epoch 12.019), train_loss = 1.94918002, grad/param norm = 7.4000e-01, time/batch = 0.1488s	
650/2700 (epoch 12.037), train_loss = 1.96899146, grad/param norm = 6.5306e-01, time/batch = 0.1727s	
651/2700 (epoch 12.056), train_loss = 1.92890972, grad/param norm = 7.3096e-01, time/batch = 0.2267s	
652/2700 (epoch 12.074), train_loss = 1.89448938, grad/param norm = 6.5386e-01, time/batch = 0.1607s	
653/2700 (epoch 12.093), train_loss = 1.91545679, grad/param norm = 5.5143e-01, time/batch = 0.1596s	
654/2700 (epoch 12.111), train_loss = 1.88314247, grad/param norm = 5.0968e-01, time/batch = 0.1678s	
655/2700 (epoch 12.130), train_loss = 1.91827321, grad/param norm = 5.0109e-01, time/batch = 0.1688s	
656/2700 (epoch 12.148), train_loss = 1.86474274, grad/param norm = 5.7117e-01, time/batch = 0.1572s	
657/2700 (epoch 12.167), train_loss = 1.94469026, grad/param norm = 5.3501e-01, time/batch = 0.1480s	
658/2700 (epoch 12.185), train_loss = 1.85768072, grad/param norm = 4.5982e-01, time/batch = 0.1410s	
659/2700 (epoch 12.204), train_loss = 1.90703461, grad/param norm = 5.3550e-01, time/batch = 0.1641s	
660/2700 (epoch 12.222), train_loss = 1.82779522, grad/param norm = 5.7732e-01, time/batch = 0.1503s	
661/2700 (epoch 12.241), train_loss = 1.78944182, grad/param norm = 5.8012e-01, time/batch = 0.1266s	
662/2700 (epoch 12.259), train_loss = 1.83543930, grad/param norm = 6.9798e-01, time/batch = 0.1598s	
663/2700 (epoch 12.278), train_loss = 1.92536937, grad/param norm = 5.4420e-01, time/batch = 0.1671s	
664/2700 (epoch 12.296), train_loss = 1.89438024, grad/param norm = 5.0474e-01, time/batch = 0.1753s	
665/2700 (epoch 12.315), train_loss = 1.92407795, grad/param norm = 5.1173e-01, time/batch = 0.1777s	
666/2700 (epoch 12.333), train_loss = 1.91132579, grad/param norm = 6.1329e-01, time/batch = 0.1771s	
667/2700 (epoch 12.352), train_loss = 1.93768632, grad/param norm = 6.9992e-01, time/batch = 0.1758s	
668/2700 (epoch 12.370), train_loss = 1.95066364, grad/param norm = 7.3480e-01, time/batch = 0.1669s	
669/2700 (epoch 12.389), train_loss = 1.91512168, grad/param norm = 7.6725e-01, time/batch = 0.1773s	
670/2700 (epoch 12.407), train_loss = 1.93292446, grad/param norm = 8.0636e-01, time/batch = 0.1569s	
671/2700 (epoch 12.426), train_loss = 1.95242111, grad/param norm = 5.6153e-01, time/batch = 0.1649s	
672/2700 (epoch 12.444), train_loss = 1.84847461, grad/param norm = 4.6969e-01, time/batch = 0.1516s	
673/2700 (epoch 12.463), train_loss = 1.93892219, grad/param norm = 5.1056e-01, time/batch = 0.1525s	
674/2700 (epoch 12.481), train_loss = 1.95081573, grad/param norm = 5.1895e-01, time/batch = 0.1543s	
675/2700 (epoch 12.500), train_loss = 1.92572435, grad/param norm = 5.0476e-01, time/batch = 0.1491s	
676/2700 (epoch 12.519), train_loss = 1.89435637, grad/param norm = 4.7129e-01, time/batch = 0.1581s	
677/2700 (epoch 12.537), train_loss = 1.92262042, grad/param norm = 4.8091e-01, time/batch = 0.1679s	
678/2700 (epoch 12.556), train_loss = 1.87566537, grad/param norm = 5.2016e-01, time/batch = 0.1646s	
679/2700 (epoch 12.574), train_loss = 1.87038773, grad/param norm = 5.9627e-01, time/batch = 0.1746s	
680/2700 (epoch 12.593), train_loss = 1.88839660, grad/param norm = 7.9908e-01, time/batch = 0.1726s	
681/2700 (epoch 12.611), train_loss = 1.80532742, grad/param norm = 8.2837e-01, time/batch = 0.1374s	
682/2700 (epoch 12.630), train_loss = 1.85849955, grad/param norm = 7.4254e-01, time/batch = 0.1506s	
683/2700 (epoch 12.648), train_loss = 1.87017310, grad/param norm = 6.5798e-01, time/batch = 0.1787s	
684/2700 (epoch 12.667), train_loss = 1.83979913, grad/param norm = 6.4849e-01, time/batch = 0.1781s	
685/2700 (epoch 12.685), train_loss = 1.87403140, grad/param norm = 7.1681e-01, time/batch = 0.1778s	
686/2700 (epoch 12.704), train_loss = 1.89338268, grad/param norm = 6.6659e-01, time/batch = 0.1764s	
687/2700 (epoch 12.722), train_loss = 1.85862425, grad/param norm = 5.5580e-01, time/batch = 0.1706s	
688/2700 (epoch 12.741), train_loss = 1.92356512, grad/param norm = 5.3758e-01, time/batch = 0.1501s	
689/2700 (epoch 12.759), train_loss = 1.93140582, grad/param norm = 5.2448e-01, time/batch = 0.1537s	
690/2700 (epoch 12.778), train_loss = 1.92723146, grad/param norm = 4.9471e-01, time/batch = 0.1589s	
691/2700 (epoch 12.796), train_loss = 1.89016981, grad/param norm = 4.9178e-01, time/batch = 0.1673s	
692/2700 (epoch 12.815), train_loss = 1.92519969, grad/param norm = 5.3485e-01, time/batch = 0.1613s	
693/2700 (epoch 12.833), train_loss = 1.86449769, grad/param norm = 5.4181e-01, time/batch = 0.1790s	
694/2700 (epoch 12.852), train_loss = 1.88898924, grad/param norm = 5.2701e-01, time/batch = 0.1725s	
695/2700 (epoch 12.870), train_loss = 1.87441194, grad/param norm = 5.6375e-01, time/batch = 0.1647s	
696/2700 (epoch 12.889), train_loss = 1.90852515, grad/param norm = 8.5335e-01, time/batch = 0.1658s	
697/2700 (epoch 12.907), train_loss = 2.02984295, grad/param norm = 8.6609e-01, time/batch = 0.1647s	
698/2700 (epoch 12.926), train_loss = 1.94044580, grad/param norm = 6.9452e-01, time/batch = 0.1614s	
699/2700 (epoch 12.944), train_loss = 1.91445825, grad/param norm = 5.7016e-01, time/batch = 0.1413s	
700/2700 (epoch 12.963), train_loss = 1.95083128, grad/param norm = 5.5931e-01, time/batch = 0.1442s	
701/2700 (epoch 12.981), train_loss = 1.91537102, grad/param norm = 5.4294e-01, time/batch = 0.1421s	
decayed learning rate by a factor 0.97 to 0.00177058562	
702/2700 (epoch 13.000), train_loss = 1.95395931, grad/param norm = 6.1295e-01, time/batch = 0.1596s	
703/2700 (epoch 13.019), train_loss = 1.92381108, grad/param norm = 8.2085e-01, time/batch = 0.1320s	
704/2700 (epoch 13.037), train_loss = 1.94261061, grad/param norm = 6.6408e-01, time/batch = 0.1509s	
705/2700 (epoch 13.056), train_loss = 1.89074914, grad/param norm = 5.6157e-01, time/batch = 0.1366s	
706/2700 (epoch 13.074), train_loss = 1.86123005, grad/param norm = 5.0162e-01, time/batch = 0.1410s	
707/2700 (epoch 13.093), train_loss = 1.88551290, grad/param norm = 5.2769e-01, time/batch = 0.1547s	
708/2700 (epoch 13.111), train_loss = 1.85530905, grad/param norm = 5.3863e-01, time/batch = 0.1554s	
709/2700 (epoch 13.130), train_loss = 1.89366484, grad/param norm = 5.9277e-01, time/batch = 0.1513s	
710/2700 (epoch 13.148), train_loss = 1.84088061, grad/param norm = 7.0141e-01, time/batch = 0.1683s	
711/2700 (epoch 13.167), train_loss = 1.92107872, grad/param norm = 5.8998e-01, time/batch = 0.1756s	
712/2700 (epoch 13.185), train_loss = 1.83064766, grad/param norm = 5.0381e-01, time/batch = 0.1710s	
713/2700 (epoch 13.204), train_loss = 1.87908801, grad/param norm = 5.9354e-01, time/batch = 0.1651s	
714/2700 (epoch 13.222), train_loss = 1.80103684, grad/param norm = 5.8996e-01, time/batch = 0.1406s	
715/2700 (epoch 13.241), train_loss = 1.75883498, grad/param norm = 4.7600e-01, time/batch = 0.1517s	
716/2700 (epoch 13.259), train_loss = 1.80401934, grad/param norm = 5.1483e-01, time/batch = 0.1638s	
717/2700 (epoch 13.278), train_loss = 1.90359546, grad/param norm = 6.6556e-01, time/batch = 0.1750s	
718/2700 (epoch 13.296), train_loss = 1.86970174, grad/param norm = 6.6108e-01, time/batch = 0.1758s	
719/2700 (epoch 13.315), train_loss = 1.89720257, grad/param norm = 6.0966e-01, time/batch = 0.1706s	
720/2700 (epoch 13.333), train_loss = 1.87942083, grad/param norm = 6.1410e-01, time/batch = 0.1756s	
721/2700 (epoch 13.352), train_loss = 1.89524312, grad/param norm = 4.7318e-01, time/batch = 0.1733s	
722/2700 (epoch 13.370), train_loss = 1.90933209, grad/param norm = 5.5074e-01, time/batch = 0.1764s	
723/2700 (epoch 13.389), train_loss = 1.87509757, grad/param norm = 6.5726e-01, time/batch = 0.1773s	
724/2700 (epoch 13.407), train_loss = 1.90414773, grad/param norm = 9.7237e-01, time/batch = 0.1710s	
725/2700 (epoch 13.426), train_loss = 1.92635680, grad/param norm = 5.6332e-01, time/batch = 0.1523s	
726/2700 (epoch 13.444), train_loss = 1.82411839, grad/param norm = 5.6508e-01, time/batch = 0.1464s	
727/2700 (epoch 13.463), train_loss = 1.91972855, grad/param norm = 6.2505e-01, time/batch = 0.1433s	
728/2700 (epoch 13.481), train_loss = 1.93004616, grad/param norm = 6.1569e-01, time/batch = 0.1526s	
729/2700 (epoch 13.500), train_loss = 1.89735974, grad/param norm = 6.4258e-01, time/batch = 0.1619s	
730/2700 (epoch 13.519), train_loss = 1.87085146, grad/param norm = 4.9765e-01, time/batch = 0.1774s	
731/2700 (epoch 13.537), train_loss = 1.89424335, grad/param norm = 5.2637e-01, time/batch = 0.1571s	
732/2700 (epoch 13.556), train_loss = 1.84471679, grad/param norm = 5.7962e-01, time/batch = 0.1661s	
733/2700 (epoch 13.574), train_loss = 1.83803757, grad/param norm = 5.0478e-01, time/batch = 0.1654s	
734/2700 (epoch 13.593), train_loss = 1.84758854, grad/param norm = 5.4378e-01, time/batch = 0.1723s	
735/2700 (epoch 13.611), train_loss = 1.75813365, grad/param norm = 4.9028e-01, time/batch = 0.1602s	
736/2700 (epoch 13.630), train_loss = 1.81689432, grad/param norm = 5.1897e-01, time/batch = 0.1712s	
737/2700 (epoch 13.648), train_loss = 1.83054446, grad/param norm = 4.9563e-01, time/batch = 0.1575s	
738/2700 (epoch 13.667), train_loss = 1.80492512, grad/param norm = 5.0981e-01, time/batch = 0.1514s	
739/2700 (epoch 13.685), train_loss = 1.84338938, grad/param norm = 6.1219e-01, time/batch = 0.1633s	
740/2700 (epoch 13.704), train_loss = 1.86620899, grad/param norm = 6.2223e-01, time/batch = 0.1503s	
741/2700 (epoch 13.722), train_loss = 1.83159495, grad/param norm = 5.3786e-01, time/batch = 0.1620s	
742/2700 (epoch 13.741), train_loss = 1.89160885, grad/param norm = 5.2639e-01, time/batch = 0.1719s	
743/2700 (epoch 13.759), train_loss = 1.90062622, grad/param norm = 5.4310e-01, time/batch = 0.1730s	
744/2700 (epoch 13.778), train_loss = 1.90068894, grad/param norm = 5.3130e-01, time/batch = 0.1681s	
745/2700 (epoch 13.796), train_loss = 1.86731230, grad/param norm = 5.6586e-01, time/batch = 0.1674s	
746/2700 (epoch 13.815), train_loss = 1.90248475, grad/param norm = 5.6703e-01, time/batch = 0.1519s	
747/2700 (epoch 13.833), train_loss = 1.83671466, grad/param norm = 5.1388e-01, time/batch = 0.1387s	
748/2700 (epoch 13.852), train_loss = 1.85429393, grad/param norm = 4.5913e-01, time/batch = 0.1281s	
749/2700 (epoch 13.870), train_loss = 1.83833901, grad/param norm = 4.2269e-01, time/batch = 0.1410s	
750/2700 (epoch 13.889), train_loss = 1.86680615, grad/param norm = 5.5193e-01, time/batch = 0.1519s	
751/2700 (epoch 13.907), train_loss = 1.98772637, grad/param norm = 7.3022e-01, time/batch = 0.1501s	
752/2700 (epoch 13.926), train_loss = 1.91396494, grad/param norm = 7.9103e-01, time/batch = 0.1444s	
753/2700 (epoch 13.944), train_loss = 1.89302610, grad/param norm = 6.9023e-01, time/batch = 0.1584s	
754/2700 (epoch 13.963), train_loss = 1.93134934, grad/param norm = 6.4375e-01, time/batch = 0.1653s	
755/2700 (epoch 13.981), train_loss = 1.88928275, grad/param norm = 5.7098e-01, time/batch = 0.1664s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
756/2700 (epoch 14.000), train_loss = 1.92890462, grad/param norm = 6.2264e-01, time/batch = 0.1560s	
757/2700 (epoch 14.019), train_loss = 1.89694017, grad/param norm = 7.5972e-01, time/batch = 0.1710s	
758/2700 (epoch 14.037), train_loss = 1.91329793, grad/param norm = 6.0687e-01, time/batch = 0.1661s	
759/2700 (epoch 14.056), train_loss = 1.85954753, grad/param norm = 5.3444e-01, time/batch = 0.1457s	
760/2700 (epoch 14.074), train_loss = 1.83449045, grad/param norm = 4.8899e-01, time/batch = 0.1484s	
761/2700 (epoch 14.093), train_loss = 1.85565269, grad/param norm = 4.9671e-01, time/batch = 0.1691s	
762/2700 (epoch 14.111), train_loss = 1.82733063, grad/param norm = 5.0179e-01, time/batch = 0.1567s	
763/2700 (epoch 14.130), train_loss = 1.86606993, grad/param norm = 5.5734e-01, time/batch = 0.1538s	
764/2700 (epoch 14.148), train_loss = 1.81135423, grad/param norm = 6.3643e-01, time/batch = 0.1635s	
765/2700 (epoch 14.167), train_loss = 1.89235997, grad/param norm = 5.4940e-01, time/batch = 0.1706s	
766/2700 (epoch 14.185), train_loss = 1.80474097, grad/param norm = 4.8850e-01, time/batch = 0.1738s	
767/2700 (epoch 14.204), train_loss = 1.85290224, grad/param norm = 5.5714e-01, time/batch = 0.1565s	
768/2700 (epoch 14.222), train_loss = 1.77577662, grad/param norm = 5.5207e-01, time/batch = 0.1672s	
769/2700 (epoch 14.241), train_loss = 1.73328722, grad/param norm = 4.6436e-01, time/batch = 0.1582s	
770/2700 (epoch 14.259), train_loss = 1.77688503, grad/param norm = 4.8118e-01, time/batch = 0.1425s	
771/2700 (epoch 14.278), train_loss = 1.87501266, grad/param norm = 5.8597e-01, time/batch = 0.1618s	
772/2700 (epoch 14.296), train_loss = 1.84098453, grad/param norm = 5.9855e-01, time/batch = 0.1588s	
773/2700 (epoch 14.315), train_loss = 1.86878976, grad/param norm = 5.8636e-01, time/batch = 0.1524s	
774/2700 (epoch 14.333), train_loss = 1.85475870, grad/param norm = 6.0931e-01, time/batch = 0.1554s	
775/2700 (epoch 14.352), train_loss = 1.86890687, grad/param norm = 4.7051e-01, time/batch = 0.1649s	
776/2700 (epoch 14.370), train_loss = 1.88306730, grad/param norm = 5.5228e-01, time/batch = 0.1723s	
777/2700 (epoch 14.389), train_loss = 1.84937577, grad/param norm = 6.5471e-01, time/batch = 0.1591s	
778/2700 (epoch 14.407), train_loss = 1.88023838, grad/param norm = 9.0683e-01, time/batch = 0.1624s	
779/2700 (epoch 14.426), train_loss = 1.90335037, grad/param norm = 5.6804e-01, time/batch = 0.1561s	
780/2700 (epoch 14.444), train_loss = 1.79852459, grad/param norm = 5.5266e-01, time/batch = 0.1393s	
781/2700 (epoch 14.463), train_loss = 1.89374614, grad/param norm = 6.1369e-01, time/batch = 0.1618s	
782/2700 (epoch 14.481), train_loss = 1.90210377, grad/param norm = 5.8590e-01, time/batch = 0.1646s	
783/2700 (epoch 14.500), train_loss = 1.86560800, grad/param norm = 5.9681e-01, time/batch = 0.1672s	
784/2700 (epoch 14.519), train_loss = 1.84680500, grad/param norm = 4.7554e-01, time/batch = 0.1697s	
785/2700 (epoch 14.537), train_loss = 1.86701562, grad/param norm = 5.1513e-01, time/batch = 0.1703s	
786/2700 (epoch 14.556), train_loss = 1.81729765, grad/param norm = 5.8118e-01, time/batch = 0.1736s	
787/2700 (epoch 14.574), train_loss = 1.80993208, grad/param norm = 4.9011e-01, time/batch = 0.1720s	
788/2700 (epoch 14.593), train_loss = 1.81932741, grad/param norm = 5.1909e-01, time/batch = 0.1581s	
789/2700 (epoch 14.611), train_loss = 1.73005686, grad/param norm = 4.7996e-01, time/batch = 0.1451s	
790/2700 (epoch 14.630), train_loss = 1.79116270, grad/param norm = 5.1306e-01, time/batch = 0.1370s	
791/2700 (epoch 14.648), train_loss = 1.80401948, grad/param norm = 5.0148e-01, time/batch = 0.1223s	
792/2700 (epoch 14.667), train_loss = 1.78191961, grad/param norm = 5.3214e-01, time/batch = 0.1737s	
793/2700 (epoch 14.685), train_loss = 1.81974915, grad/param norm = 6.1448e-01, time/batch = 0.1761s	
794/2700 (epoch 14.704), train_loss = 1.84200690, grad/param norm = 6.1606e-01, time/batch = 0.1706s	
795/2700 (epoch 14.722), train_loss = 1.80584489, grad/param norm = 5.3053e-01, time/batch = 0.1685s	
796/2700 (epoch 14.741), train_loss = 1.86425736, grad/param norm = 5.1985e-01, time/batch = 0.1632s	
797/2700 (epoch 14.759), train_loss = 1.87147695, grad/param norm = 5.2982e-01, time/batch = 0.1620s	
798/2700 (epoch 14.778), train_loss = 1.87469323, grad/param norm = 5.0604e-01, time/batch = 0.1530s	
799/2700 (epoch 14.796), train_loss = 1.84117180, grad/param norm = 5.2959e-01, time/batch = 0.1713s	
800/2700 (epoch 14.815), train_loss = 1.87754372, grad/param norm = 5.4675e-01, time/batch = 0.1613s	
801/2700 (epoch 14.833), train_loss = 1.81140549, grad/param norm = 5.2262e-01, time/batch = 0.1679s	
802/2700 (epoch 14.852), train_loss = 1.83070721, grad/param norm = 4.9697e-01, time/batch = 0.1477s	
803/2700 (epoch 14.870), train_loss = 1.82201243, grad/param norm = 5.4744e-01, time/batch = 0.1641s	
804/2700 (epoch 14.889), train_loss = 1.85734589, grad/param norm = 9.0548e-01, time/batch = 0.1723s	
805/2700 (epoch 14.907), train_loss = 1.98202759, grad/param norm = 8.3233e-01, time/batch = 0.1749s	
806/2700 (epoch 14.926), train_loss = 1.88995111, grad/param norm = 6.4283e-01, time/batch = 0.1768s	
807/2700 (epoch 14.944), train_loss = 1.85646284, grad/param norm = 5.2331e-01, time/batch = 0.1750s	
808/2700 (epoch 14.963), train_loss = 1.89618931, grad/param norm = 4.9721e-01, time/batch = 0.1737s	
809/2700 (epoch 14.981), train_loss = 1.85604232, grad/param norm = 4.9179e-01, time/batch = 0.1760s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
810/2700 (epoch 15.000), train_loss = 1.90190785, grad/param norm = 4.9903e-01, time/batch = 0.1724s	
811/2700 (epoch 15.019), train_loss = 1.86430351, grad/param norm = 5.1641e-01, time/batch = 0.1667s	
812/2700 (epoch 15.037), train_loss = 1.88406290, grad/param norm = 4.6060e-01, time/batch = 0.1677s	
813/2700 (epoch 15.056), train_loss = 1.83144944, grad/param norm = 5.4332e-01, time/batch = 0.1798s	
814/2700 (epoch 15.074), train_loss = 1.81173843, grad/param norm = 5.3259e-01, time/batch = 0.1790s	
815/2700 (epoch 15.093), train_loss = 1.82883618, grad/param norm = 4.9855e-01, time/batch = 0.1792s	
816/2700 (epoch 15.111), train_loss = 1.80266815, grad/param norm = 4.7276e-01, time/batch = 0.1777s	
817/2700 (epoch 15.130), train_loss = 1.84097895, grad/param norm = 4.9699e-01, time/batch = 0.1792s	
818/2700 (epoch 15.148), train_loss = 1.78716792, grad/param norm = 5.5956e-01, time/batch = 0.1753s	
819/2700 (epoch 15.167), train_loss = 1.86706761, grad/param norm = 5.4047e-01, time/batch = 0.1656s	
820/2700 (epoch 15.185), train_loss = 1.78162146, grad/param norm = 5.0070e-01, time/batch = 0.1517s	
821/2700 (epoch 15.204), train_loss = 1.83272746, grad/param norm = 5.9886e-01, time/batch = 0.1726s	
822/2700 (epoch 15.222), train_loss = 1.76159456, grad/param norm = 7.3747e-01, time/batch = 0.1746s	
823/2700 (epoch 15.241), train_loss = 1.72512875, grad/param norm = 7.7212e-01, time/batch = 0.1487s	
824/2700 (epoch 15.259), train_loss = 1.76369274, grad/param norm = 6.5393e-01, time/batch = 0.1689s	
825/2700 (epoch 15.278), train_loss = 1.84682467, grad/param norm = 4.7171e-01, time/batch = 0.1742s	
826/2700 (epoch 15.296), train_loss = 1.81311622, grad/param norm = 4.5001e-01, time/batch = 0.1708s	
827/2700 (epoch 15.315), train_loss = 1.84230169, grad/param norm = 5.0017e-01, time/batch = 0.1658s	
828/2700 (epoch 15.333), train_loss = 1.83320942, grad/param norm = 5.6303e-01, time/batch = 0.1604s	
829/2700 (epoch 15.352), train_loss = 1.84809074, grad/param norm = 5.2908e-01, time/batch = 0.1462s	
830/2700 (epoch 15.370), train_loss = 1.86207081, grad/param norm = 6.0023e-01, time/batch = 0.1768s	
831/2700 (epoch 15.389), train_loss = 1.82736275, grad/param norm = 6.5506e-01, time/batch = 0.1662s	
832/2700 (epoch 15.407), train_loss = 1.85407233, grad/param norm = 6.5971e-01, time/batch = 0.1691s	
833/2700 (epoch 15.426), train_loss = 1.87626592, grad/param norm = 4.9103e-01, time/batch = 0.1532s	
834/2700 (epoch 15.444), train_loss = 1.77008796, grad/param norm = 4.5793e-01, time/batch = 0.1418s	
835/2700 (epoch 15.463), train_loss = 1.86224111, grad/param norm = 5.0074e-01, time/batch = 0.1404s	
836/2700 (epoch 15.481), train_loss = 1.87154761, grad/param norm = 4.9875e-01, time/batch = 0.1529s	
837/2700 (epoch 15.500), train_loss = 1.83673977, grad/param norm = 5.2081e-01, time/batch = 0.1641s	
838/2700 (epoch 15.519), train_loss = 1.82457406, grad/param norm = 4.4949e-01, time/batch = 0.1655s	
839/2700 (epoch 15.537), train_loss = 1.84190087, grad/param norm = 4.7557e-01, time/batch = 0.1666s	
840/2700 (epoch 15.556), train_loss = 1.79082978, grad/param norm = 5.3189e-01, time/batch = 0.1509s	
841/2700 (epoch 15.574), train_loss = 1.78504970, grad/param norm = 4.8413e-01, time/batch = 0.1683s	
842/2700 (epoch 15.593), train_loss = 1.79574516, grad/param norm = 5.4179e-01, time/batch = 0.1433s	
843/2700 (epoch 15.611), train_loss = 1.70716484, grad/param norm = 5.4305e-01, time/batch = 0.1616s	
844/2700 (epoch 15.630), train_loss = 1.76896319, grad/param norm = 5.6492e-01, time/batch = 0.1549s	
845/2700 (epoch 15.648), train_loss = 1.78228820, grad/param norm = 5.5792e-01, time/batch = 0.1394s	
846/2700 (epoch 15.667), train_loss = 1.76244653, grad/param norm = 5.9110e-01, time/batch = 0.1502s	
847/2700 (epoch 15.685), train_loss = 1.79867535, grad/param norm = 6.2916e-01, time/batch = 0.1647s	
848/2700 (epoch 15.704), train_loss = 1.81909379, grad/param norm = 5.9397e-01, time/batch = 0.1763s	
849/2700 (epoch 15.722), train_loss = 1.78175958, grad/param norm = 4.9868e-01, time/batch = 0.1769s	
850/2700 (epoch 15.741), train_loss = 1.83956064, grad/param norm = 4.9638e-01, time/batch = 0.1692s	
851/2700 (epoch 15.759), train_loss = 1.84484090, grad/param norm = 5.1960e-01, time/batch = 0.1639s	
852/2700 (epoch 15.778), train_loss = 1.85151740, grad/param norm = 4.8977e-01, time/batch = 0.1668s	
853/2700 (epoch 15.796), train_loss = 1.81810845, grad/param norm = 5.0950e-01, time/batch = 0.1809s	
854/2700 (epoch 15.815), train_loss = 1.85633064, grad/param norm = 6.0810e-01, time/batch = 0.1788s	
855/2700 (epoch 15.833), train_loss = 1.79390615, grad/param norm = 6.7531e-01, time/batch = 0.1624s	
856/2700 (epoch 15.852), train_loss = 1.81648401, grad/param norm = 6.4048e-01, time/batch = 0.1782s	
857/2700 (epoch 15.870), train_loss = 1.80941857, grad/param norm = 6.1367e-01, time/batch = 0.1773s	
858/2700 (epoch 15.889), train_loss = 1.83265546, grad/param norm = 7.1392e-01, time/batch = 0.1747s	
859/2700 (epoch 15.907), train_loss = 1.94486241, grad/param norm = 6.5543e-01, time/batch = 0.1642s	
860/2700 (epoch 15.926), train_loss = 1.85822173, grad/param norm = 5.6666e-01, time/batch = 0.1386s	
861/2700 (epoch 15.944), train_loss = 1.82804490, grad/param norm = 4.9376e-01, time/batch = 0.1791s	
862/2700 (epoch 15.963), train_loss = 1.87220295, grad/param norm = 4.7817e-01, time/batch = 0.1613s	
863/2700 (epoch 15.981), train_loss = 1.83056357, grad/param norm = 4.7528e-01, time/batch = 0.1640s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
864/2700 (epoch 16.000), train_loss = 1.87882816, grad/param norm = 4.8419e-01, time/batch = 0.1549s	
865/2700 (epoch 16.019), train_loss = 1.84283839, grad/param norm = 4.9631e-01, time/batch = 0.1482s	
866/2700 (epoch 16.037), train_loss = 1.86370551, grad/param norm = 4.4742e-01, time/batch = 0.1532s	
867/2700 (epoch 16.056), train_loss = 1.80756613, grad/param norm = 5.6420e-01, time/batch = 0.1705s	
868/2700 (epoch 16.074), train_loss = 1.79117902, grad/param norm = 5.5649e-01, time/batch = 0.1635s	
869/2700 (epoch 16.093), train_loss = 1.80464006, grad/param norm = 4.8910e-01, time/batch = 0.1520s	
870/2700 (epoch 16.111), train_loss = 1.77989315, grad/param norm = 4.5804e-01, time/batch = 0.1422s	
871/2700 (epoch 16.130), train_loss = 1.81815310, grad/param norm = 4.7918e-01, time/batch = 0.1666s	
872/2700 (epoch 16.148), train_loss = 1.76344300, grad/param norm = 5.2785e-01, time/batch = 0.1525s	
873/2700 (epoch 16.167), train_loss = 1.84473237, grad/param norm = 5.2839e-01, time/batch = 0.1654s	
874/2700 (epoch 16.185), train_loss = 1.76016007, grad/param norm = 4.8965e-01, time/batch = 0.1600s	
875/2700 (epoch 16.204), train_loss = 1.81127456, grad/param norm = 5.7908e-01, time/batch = 0.1523s	
876/2700 (epoch 16.222), train_loss = 1.74007070, grad/param norm = 6.9019e-01, time/batch = 0.1487s	
877/2700 (epoch 16.241), train_loss = 1.70060240, grad/param norm = 7.1271e-01, time/batch = 0.1425s	
878/2700 (epoch 16.259), train_loss = 1.74112803, grad/param norm = 6.3443e-01, time/batch = 0.1621s	
879/2700 (epoch 16.278), train_loss = 1.82560514, grad/param norm = 4.6068e-01, time/batch = 0.1619s	
880/2700 (epoch 16.296), train_loss = 1.79081522, grad/param norm = 4.4040e-01, time/batch = 0.1579s	
881/2700 (epoch 16.315), train_loss = 1.81981073, grad/param norm = 5.1006e-01, time/batch = 0.1624s	
882/2700 (epoch 16.333), train_loss = 1.81247454, grad/param norm = 5.6231e-01, time/batch = 0.1755s	
883/2700 (epoch 16.352), train_loss = 1.82387228, grad/param norm = 5.0943e-01, time/batch = 0.1641s	
884/2700 (epoch 16.370), train_loss = 1.83956723, grad/param norm = 5.8472e-01, time/batch = 0.1602s	
885/2700 (epoch 16.389), train_loss = 1.80476817, grad/param norm = 6.3587e-01, time/batch = 0.1589s	
886/2700 (epoch 16.407), train_loss = 1.83432715, grad/param norm = 6.3384e-01, time/batch = 0.1478s	
887/2700 (epoch 16.426), train_loss = 1.85539728, grad/param norm = 4.7512e-01, time/batch = 0.1400s	
888/2700 (epoch 16.444), train_loss = 1.74833698, grad/param norm = 4.5870e-01, time/batch = 0.1343s	
889/2700 (epoch 16.463), train_loss = 1.84209881, grad/param norm = 5.0500e-01, time/batch = 0.1633s	
890/2700 (epoch 16.481), train_loss = 1.85058519, grad/param norm = 5.0384e-01, time/batch = 0.1638s	
891/2700 (epoch 16.500), train_loss = 1.81372556, grad/param norm = 5.3712e-01, time/batch = 0.1616s	
892/2700 (epoch 16.519), train_loss = 1.80706441, grad/param norm = 4.5153e-01, time/batch = 0.1491s	
893/2700 (epoch 16.537), train_loss = 1.82002932, grad/param norm = 4.7746e-01, time/batch = 0.1418s	
894/2700 (epoch 16.556), train_loss = 1.76767133, grad/param norm = 5.2871e-01, time/batch = 0.1502s	
895/2700 (epoch 16.574), train_loss = 1.76246841, grad/param norm = 4.7360e-01, time/batch = 0.1484s	
896/2700 (epoch 16.593), train_loss = 1.77311744, grad/param norm = 5.2137e-01, time/batch = 0.1598s	
897/2700 (epoch 16.611), train_loss = 1.68319889, grad/param norm = 5.0972e-01, time/batch = 0.1690s	
898/2700 (epoch 16.630), train_loss = 1.74571392, grad/param norm = 5.2236e-01, time/batch = 0.1738s	
899/2700 (epoch 16.648), train_loss = 1.75843887, grad/param norm = 5.1513e-01, time/batch = 0.1628s	
900/2700 (epoch 16.667), train_loss = 1.73983132, grad/param norm = 5.5428e-01, time/batch = 0.1746s	
901/2700 (epoch 16.685), train_loss = 1.77551144, grad/param norm = 5.8823e-01, time/batch = 0.1673s	
902/2700 (epoch 16.704), train_loss = 1.79789663, grad/param norm = 5.6402e-01, time/batch = 0.1663s	
903/2700 (epoch 16.722), train_loss = 1.76040622, grad/param norm = 4.7933e-01, time/batch = 0.1730s	
904/2700 (epoch 16.741), train_loss = 1.81697807, grad/param norm = 4.8339e-01, time/batch = 0.1748s	
905/2700 (epoch 16.759), train_loss = 1.82037601, grad/param norm = 5.1247e-01, time/batch = 0.1779s	
906/2700 (epoch 16.778), train_loss = 1.82972729, grad/param norm = 4.7721e-01, time/batch = 0.1761s	
907/2700 (epoch 16.796), train_loss = 1.79666028, grad/param norm = 5.0118e-01, time/batch = 0.1812s	
908/2700 (epoch 16.815), train_loss = 1.83690184, grad/param norm = 6.4769e-01, time/batch = 0.1769s	
909/2700 (epoch 16.833), train_loss = 1.77717737, grad/param norm = 7.1638e-01, time/batch = 0.1637s	
910/2700 (epoch 16.852), train_loss = 1.79836601, grad/param norm = 6.5858e-01, time/batch = 0.1374s	
911/2700 (epoch 16.870), train_loss = 1.79034023, grad/param norm = 5.8563e-01, time/batch = 0.1782s	
912/2700 (epoch 16.889), train_loss = 1.81012162, grad/param norm = 6.5103e-01, time/batch = 0.1682s	
913/2700 (epoch 16.907), train_loss = 1.92161609, grad/param norm = 5.9621e-01, time/batch = 0.1686s	
914/2700 (epoch 16.926), train_loss = 1.83677013, grad/param norm = 5.4811e-01, time/batch = 0.1761s	
915/2700 (epoch 16.944), train_loss = 1.80453482, grad/param norm = 4.9320e-01, time/batch = 0.1724s	
916/2700 (epoch 16.963), train_loss = 1.85035318, grad/param norm = 4.7783e-01, time/batch = 0.1672s	
917/2700 (epoch 16.981), train_loss = 1.80808242, grad/param norm = 4.7283e-01, time/batch = 0.1628s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
918/2700 (epoch 17.000), train_loss = 1.85831776, grad/param norm = 4.7977e-01, time/batch = 0.1609s	
919/2700 (epoch 17.019), train_loss = 1.82337186, grad/param norm = 4.9487e-01, time/batch = 0.1663s	
920/2700 (epoch 17.037), train_loss = 1.84549286, grad/param norm = 4.4846e-01, time/batch = 0.1677s	
921/2700 (epoch 17.056), train_loss = 1.78449135, grad/param norm = 5.3942e-01, time/batch = 0.1439s	
922/2700 (epoch 17.074), train_loss = 1.77126657, grad/param norm = 5.2424e-01, time/batch = 0.1409s	
923/2700 (epoch 17.093), train_loss = 1.78185686, grad/param norm = 4.6172e-01, time/batch = 0.1462s	
924/2700 (epoch 17.111), train_loss = 1.75897996, grad/param norm = 4.5100e-01, time/batch = 0.1625s	
925/2700 (epoch 17.130), train_loss = 1.79810517, grad/param norm = 5.0030e-01, time/batch = 0.1648s	
926/2700 (epoch 17.148), train_loss = 1.74247013, grad/param norm = 5.3313e-01, time/batch = 0.1594s	
927/2700 (epoch 17.167), train_loss = 1.82498104, grad/param norm = 4.8590e-01, time/batch = 0.1593s	
928/2700 (epoch 17.185), train_loss = 1.73980774, grad/param norm = 4.6726e-01, time/batch = 0.1605s	
929/2700 (epoch 17.204), train_loss = 1.79112005, grad/param norm = 5.9620e-01, time/batch = 0.1588s	
930/2700 (epoch 17.222), train_loss = 1.71943646, grad/param norm = 5.9438e-01, time/batch = 0.1508s	
931/2700 (epoch 17.241), train_loss = 1.67358065, grad/param norm = 4.8639e-01, time/batch = 0.1704s	
932/2700 (epoch 17.259), train_loss = 1.71773453, grad/param norm = 5.3353e-01, time/batch = 0.1806s	
933/2700 (epoch 17.278), train_loss = 1.81690702, grad/param norm = 6.3779e-01, time/batch = 0.1745s	
934/2700 (epoch 17.296), train_loss = 1.77811162, grad/param norm = 6.0150e-01, time/batch = 0.1542s	
935/2700 (epoch 17.315), train_loss = 1.80293657, grad/param norm = 5.9249e-01, time/batch = 0.1451s	
936/2700 (epoch 17.333), train_loss = 1.79021716, grad/param norm = 5.5522e-01, time/batch = 0.1403s	
937/2700 (epoch 17.352), train_loss = 1.79955986, grad/param norm = 4.5479e-01, time/batch = 0.1398s	
938/2700 (epoch 17.370), train_loss = 1.81843226, grad/param norm = 5.6192e-01, time/batch = 0.1398s	
939/2700 (epoch 17.389), train_loss = 1.78654676, grad/param norm = 6.4147e-01, time/batch = 0.1554s	
940/2700 (epoch 17.407), train_loss = 1.81811254, grad/param norm = 6.9681e-01, time/batch = 0.1628s	
941/2700 (epoch 17.426), train_loss = 1.83654357, grad/param norm = 4.7440e-01, time/batch = 0.1507s	
942/2700 (epoch 17.444), train_loss = 1.72912073, grad/param norm = 4.6605e-01, time/batch = 0.1448s	
943/2700 (epoch 17.463), train_loss = 1.82438957, grad/param norm = 5.0973e-01, time/batch = 0.1619s	
944/2700 (epoch 17.481), train_loss = 1.83164040, grad/param norm = 5.1267e-01, time/batch = 0.1461s	
945/2700 (epoch 17.500), train_loss = 1.79154370, grad/param norm = 5.3670e-01, time/batch = 0.1768s	
946/2700 (epoch 17.519), train_loss = 1.79029284, grad/param norm = 4.5058e-01, time/batch = 0.1774s	
947/2700 (epoch 17.537), train_loss = 1.79913664, grad/param norm = 4.7628e-01, time/batch = 0.1768s	
948/2700 (epoch 17.556), train_loss = 1.74567602, grad/param norm = 5.1511e-01, time/batch = 0.1781s	
949/2700 (epoch 17.574), train_loss = 1.74145663, grad/param norm = 4.6740e-01, time/batch = 0.1772s	
950/2700 (epoch 17.593), train_loss = 1.75325452, grad/param norm = 5.1506e-01, time/batch = 0.1754s	
951/2700 (epoch 17.611), train_loss = 1.66202477, grad/param norm = 4.9487e-01, time/batch = 0.1765s	
952/2700 (epoch 17.630), train_loss = 1.72465075, grad/param norm = 4.9591e-01, time/batch = 0.1696s	
953/2700 (epoch 17.648), train_loss = 1.73758179, grad/param norm = 4.8849e-01, time/batch = 0.1515s	
954/2700 (epoch 17.667), train_loss = 1.71962879, grad/param norm = 5.2784e-01, time/batch = 0.1447s	
955/2700 (epoch 17.685), train_loss = 1.75443925, grad/param norm = 5.6035e-01, time/batch = 0.1482s	
956/2700 (epoch 17.704), train_loss = 1.77829980, grad/param norm = 5.4755e-01, time/batch = 0.1650s	
957/2700 (epoch 17.722), train_loss = 1.74055237, grad/param norm = 4.6760e-01, time/batch = 0.1683s	
958/2700 (epoch 17.741), train_loss = 1.79597649, grad/param norm = 4.7324e-01, time/batch = 0.1772s	
959/2700 (epoch 17.759), train_loss = 1.79767434, grad/param norm = 5.0319e-01, time/batch = 0.1759s	
960/2700 (epoch 17.778), train_loss = 1.80933312, grad/param norm = 4.6295e-01, time/batch = 0.1761s	
961/2700 (epoch 17.796), train_loss = 1.77704272, grad/param norm = 4.9774e-01, time/batch = 0.1618s	
962/2700 (epoch 17.815), train_loss = 1.81906756, grad/param norm = 6.7298e-01, time/batch = 0.1681s	
963/2700 (epoch 17.833), train_loss = 1.76169567, grad/param norm = 7.2748e-01, time/batch = 0.1547s	
964/2700 (epoch 17.852), train_loss = 1.77957068, grad/param norm = 6.5413e-01, time/batch = 0.1641s	
965/2700 (epoch 17.870), train_loss = 1.77108415, grad/param norm = 5.4875e-01, time/batch = 0.1583s	
966/2700 (epoch 17.889), train_loss = 1.78910633, grad/param norm = 5.9820e-01, time/batch = 0.1579s	
967/2700 (epoch 17.907), train_loss = 1.90063637, grad/param norm = 5.5434e-01, time/batch = 0.1510s	
968/2700 (epoch 17.926), train_loss = 1.81726464, grad/param norm = 5.3115e-01, time/batch = 0.1540s	
969/2700 (epoch 17.944), train_loss = 1.78256546, grad/param norm = 4.9021e-01, time/batch = 0.1600s	
970/2700 (epoch 17.963), train_loss = 1.83003957, grad/param norm = 4.8046e-01, time/batch = 0.1525s	
971/2700 (epoch 17.981), train_loss = 1.78751551, grad/param norm = 4.7114e-01, time/batch = 0.1696s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
972/2700 (epoch 18.000), train_loss = 1.83926629, grad/param norm = 4.7755e-01, time/batch = 0.1775s	
973/2700 (epoch 18.019), train_loss = 1.80545081, grad/param norm = 5.0547e-01, time/batch = 0.1757s	
974/2700 (epoch 18.037), train_loss = 1.82874760, grad/param norm = 4.5941e-01, time/batch = 0.1656s	
975/2700 (epoch 18.056), train_loss = 1.76344833, grad/param norm = 5.1413e-01, time/batch = 0.1658s	
976/2700 (epoch 18.074), train_loss = 1.75319901, grad/param norm = 4.9494e-01, time/batch = 0.1601s	
977/2700 (epoch 18.093), train_loss = 1.76177063, grad/param norm = 4.5444e-01, time/batch = 0.1553s	
978/2700 (epoch 18.111), train_loss = 1.74055935, grad/param norm = 4.8066e-01, time/batch = 0.1569s	
979/2700 (epoch 18.130), train_loss = 1.78116171, grad/param norm = 5.5971e-01, time/batch = 0.1412s	
980/2700 (epoch 18.148), train_loss = 1.72535896, grad/param norm = 5.5944e-01, time/batch = 0.1245s	
981/2700 (epoch 18.167), train_loss = 1.80796556, grad/param norm = 4.8662e-01, time/batch = 0.1850s	
982/2700 (epoch 18.185), train_loss = 1.72248997, grad/param norm = 4.6810e-01, time/batch = 0.1768s	
983/2700 (epoch 18.204), train_loss = 1.77151999, grad/param norm = 5.0830e-01, time/batch = 0.1702s	
984/2700 (epoch 18.222), train_loss = 1.69865085, grad/param norm = 5.3262e-01, time/batch = 0.1531s	
985/2700 (epoch 18.241), train_loss = 1.65464140, grad/param norm = 4.6536e-01, time/batch = 0.1299s	
986/2700 (epoch 18.259), train_loss = 1.69792775, grad/param norm = 4.6753e-01, time/batch = 0.1336s	
987/2700 (epoch 18.278), train_loss = 1.79110361, grad/param norm = 5.1164e-01, time/batch = 0.1601s	
988/2700 (epoch 18.296), train_loss = 1.75474127, grad/param norm = 5.0946e-01, time/batch = 0.1560s	
989/2700 (epoch 18.315), train_loss = 1.78131135, grad/param norm = 5.6443e-01, time/batch = 0.1489s	
990/2700 (epoch 18.333), train_loss = 1.77332435, grad/param norm = 5.6275e-01, time/batch = 0.1651s	
991/2700 (epoch 18.352), train_loss = 1.78028159, grad/param norm = 4.6230e-01, time/batch = 0.1507s	
992/2700 (epoch 18.370), train_loss = 1.79993101, grad/param norm = 5.4121e-01, time/batch = 0.1617s	
993/2700 (epoch 18.389), train_loss = 1.76453923, grad/param norm = 5.8545e-01, time/batch = 0.1716s	
994/2700 (epoch 18.407), train_loss = 1.79825104, grad/param norm = 5.8172e-01, time/batch = 0.1739s	
995/2700 (epoch 18.426), train_loss = 1.81619003, grad/param norm = 4.4719e-01, time/batch = 0.1629s	
996/2700 (epoch 18.444), train_loss = 1.71039020, grad/param norm = 4.6669e-01, time/batch = 0.1620s	
997/2700 (epoch 18.463), train_loss = 1.80714489, grad/param norm = 5.1466e-01, time/batch = 0.1369s	
998/2700 (epoch 18.481), train_loss = 1.81400325, grad/param norm = 5.2499e-01, time/batch = 0.1538s	
999/2700 (epoch 18.500), train_loss = 1.77273543, grad/param norm = 5.5758e-01, time/batch = 0.1573s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch18.52_1.8520.t7	
1000/2700 (epoch 18.519), train_loss = 1.77549685, grad/param norm = 4.5786e-01, time/batch = 0.1658s	
1001/2700 (epoch 18.537), train_loss = 1.84708837, grad/param norm = 4.8924e-01, time/batch = 0.1719s	
1002/2700 (epoch 18.556), train_loss = 1.72761287, grad/param norm = 5.3530e-01, time/batch = 0.1720s	
1003/2700 (epoch 18.574), train_loss = 1.72262585, grad/param norm = 4.5372e-01, time/batch = 0.1773s	
1004/2700 (epoch 18.593), train_loss = 1.73470605, grad/param norm = 4.8265e-01, time/batch = 0.1453s	
1005/2700 (epoch 18.611), train_loss = 1.64308314, grad/param norm = 4.7256e-01, time/batch = 0.1734s	
1006/2700 (epoch 18.630), train_loss = 1.70609003, grad/param norm = 4.7930e-01, time/batch = 0.1572s	
1007/2700 (epoch 18.648), train_loss = 1.71996648, grad/param norm = 4.7943e-01, time/batch = 0.1403s	
1008/2700 (epoch 18.667), train_loss = 1.70194627, grad/param norm = 5.1878e-01, time/batch = 0.1405s	
1009/2700 (epoch 18.685), train_loss = 1.73594470, grad/param norm = 5.4744e-01, time/batch = 0.1413s	
1010/2700 (epoch 18.704), train_loss = 1.75991168, grad/param norm = 5.3628e-01, time/batch = 0.1498s	
1011/2700 (epoch 18.722), train_loss = 1.72309651, grad/param norm = 4.6611e-01, time/batch = 0.1778s	
1012/2700 (epoch 18.741), train_loss = 1.77755804, grad/param norm = 4.7391e-01, time/batch = 0.1773s	
1013/2700 (epoch 18.759), train_loss = 1.77686008, grad/param norm = 4.9557e-01, time/batch = 0.1591s	
1014/2700 (epoch 18.778), train_loss = 1.79043293, grad/param norm = 4.5273e-01, time/batch = 0.1563s	
1015/2700 (epoch 18.796), train_loss = 1.75893325, grad/param norm = 4.8648e-01, time/batch = 0.1286s	
1016/2700 (epoch 18.815), train_loss = 1.80090442, grad/param norm = 6.3418e-01, time/batch = 0.1460s	
1017/2700 (epoch 18.833), train_loss = 1.74319731, grad/param norm = 6.8332e-01, time/batch = 0.1454s	
1018/2700 (epoch 18.852), train_loss = 1.75925507, grad/param norm = 6.3094e-01, time/batch = 0.1591s	
1019/2700 (epoch 18.870), train_loss = 1.75346699, grad/param norm = 5.3367e-01, time/batch = 0.1689s	
1020/2700 (epoch 18.889), train_loss = 1.77173396, grad/param norm = 5.9333e-01, time/batch = 0.1724s	
1021/2700 (epoch 18.907), train_loss = 1.88439818, grad/param norm = 5.5971e-01, time/batch = 0.1590s	
1022/2700 (epoch 18.926), train_loss = 1.80137941, grad/param norm = 5.5584e-01, time/batch = 0.1629s	
1023/2700 (epoch 18.944), train_loss = 1.76426525, grad/param norm = 5.1544e-01, time/batch = 0.1579s	
1024/2700 (epoch 18.963), train_loss = 1.81212926, grad/param norm = 4.8733e-01, time/batch = 0.1770s	
1025/2700 (epoch 18.981), train_loss = 1.76814171, grad/param norm = 4.5883e-01, time/batch = 0.1685s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1026/2700 (epoch 19.000), train_loss = 1.82149400, grad/param norm = 4.7195e-01, time/batch = 0.1687s	
1027/2700 (epoch 19.019), train_loss = 1.78913592, grad/param norm = 5.1484e-01, time/batch = 0.1574s	
1028/2700 (epoch 19.037), train_loss = 1.81306730, grad/param norm = 4.6848e-01, time/batch = 0.1510s	
1029/2700 (epoch 19.056), train_loss = 1.74502815, grad/param norm = 5.0325e-01, time/batch = 0.1632s	
1030/2700 (epoch 19.074), train_loss = 1.73709181, grad/param norm = 4.8663e-01, time/batch = 0.1723s	
1031/2700 (epoch 19.093), train_loss = 1.74366597, grad/param norm = 4.5670e-01, time/batch = 0.1581s	
1032/2700 (epoch 19.111), train_loss = 1.72351503, grad/param norm = 5.0290e-01, time/batch = 0.1712s	
1033/2700 (epoch 19.130), train_loss = 1.76471816, grad/param norm = 5.6471e-01, time/batch = 0.1676s	
1034/2700 (epoch 19.148), train_loss = 1.70861365, grad/param norm = 5.3557e-01, time/batch = 0.1779s	
1035/2700 (epoch 19.167), train_loss = 1.79146555, grad/param norm = 4.6897e-01, time/batch = 0.1793s	
1036/2700 (epoch 19.185), train_loss = 1.70602344, grad/param norm = 4.4352e-01, time/batch = 0.1629s	
1037/2700 (epoch 19.204), train_loss = 1.75528063, grad/param norm = 4.7105e-01, time/batch = 0.1551s	
1038/2700 (epoch 19.222), train_loss = 1.68279627, grad/param norm = 5.1650e-01, time/batch = 0.1602s	
1039/2700 (epoch 19.241), train_loss = 1.63889476, grad/param norm = 4.9440e-01, time/batch = 0.1538s	
1040/2700 (epoch 19.259), train_loss = 1.68339393, grad/param norm = 5.1173e-01, time/batch = 0.1596s	
1041/2700 (epoch 19.278), train_loss = 1.77168214, grad/param norm = 4.6128e-01, time/batch = 0.1474s	
1042/2700 (epoch 19.296), train_loss = 1.73627964, grad/param norm = 4.5424e-01, time/batch = 0.1521s	
1043/2700 (epoch 19.315), train_loss = 1.76525853, grad/param norm = 6.1909e-01, time/batch = 0.1572s	
1044/2700 (epoch 19.333), train_loss = 1.76542874, grad/param norm = 5.8765e-01, time/batch = 0.1698s	
1045/2700 (epoch 19.352), train_loss = 1.76537587, grad/param norm = 5.1637e-01, time/batch = 0.1781s	
1046/2700 (epoch 19.370), train_loss = 1.78584242, grad/param norm = 5.8885e-01, time/batch = 0.1676s	
1047/2700 (epoch 19.389), train_loss = 1.74777077, grad/param norm = 5.6057e-01, time/batch = 0.1751s	
1048/2700 (epoch 19.407), train_loss = 1.78053786, grad/param norm = 4.7239e-01, time/batch = 0.1676s	
1049/2700 (epoch 19.426), train_loss = 1.79806801, grad/param norm = 4.5749e-01, time/batch = 0.1793s	
1050/2700 (epoch 19.444), train_loss = 1.69280357, grad/param norm = 4.7083e-01, time/batch = 0.1809s	
1051/2700 (epoch 19.463), train_loss = 1.78815941, grad/param norm = 4.7887e-01, time/batch = 0.1810s	
1052/2700 (epoch 19.481), train_loss = 1.79435437, grad/param norm = 4.9399e-01, time/batch = 0.1805s	
1053/2700 (epoch 19.500), train_loss = 1.75213470, grad/param norm = 4.8681e-01, time/batch = 0.1707s	
1054/2700 (epoch 19.519), train_loss = 1.76038360, grad/param norm = 4.6753e-01, time/batch = 0.1770s	
1055/2700 (epoch 19.537), train_loss = 1.76483023, grad/param norm = 4.6907e-01, time/batch = 0.1748s	
1056/2700 (epoch 19.556), train_loss = 1.70766488, grad/param norm = 4.8559e-01, time/batch = 0.1676s	
1057/2700 (epoch 19.574), train_loss = 1.70973563, grad/param norm = 5.6776e-01, time/batch = 0.1756s	
1058/2700 (epoch 19.593), train_loss = 1.72782165, grad/param norm = 6.6204e-01, time/batch = 0.1783s	
1059/2700 (epoch 19.611), train_loss = 1.63512233, grad/param norm = 6.2947e-01, time/batch = 0.1471s	
1060/2700 (epoch 19.630), train_loss = 1.69122440, grad/param norm = 5.2085e-01, time/batch = 0.1764s	
1061/2700 (epoch 19.648), train_loss = 1.70549339, grad/param norm = 4.9281e-01, time/batch = 0.1672s	
1062/2700 (epoch 19.667), train_loss = 1.68606480, grad/param norm = 5.0844e-01, time/batch = 0.1778s	
1063/2700 (epoch 19.685), train_loss = 1.71733672, grad/param norm = 5.1346e-01, time/batch = 0.1740s	
1064/2700 (epoch 19.704), train_loss = 1.74111098, grad/param norm = 5.0961e-01, time/batch = 0.1772s	
1065/2700 (epoch 19.722), train_loss = 1.70660900, grad/param norm = 4.3721e-01, time/batch = 0.1794s	
1066/2700 (epoch 19.741), train_loss = 1.75998708, grad/param norm = 4.5690e-01, time/batch = 0.1674s	
1067/2700 (epoch 19.759), train_loss = 1.75791569, grad/param norm = 5.0812e-01, time/batch = 0.1760s	
1068/2700 (epoch 19.778), train_loss = 1.77420352, grad/param norm = 4.7471e-01, time/batch = 0.1763s	
1069/2700 (epoch 19.796), train_loss = 1.74413442, grad/param norm = 5.4003e-01, time/batch = 0.1756s	
1070/2700 (epoch 19.815), train_loss = 1.78728800, grad/param norm = 6.8681e-01, time/batch = 0.1464s	
1071/2700 (epoch 19.833), train_loss = 1.72846885, grad/param norm = 6.5637e-01, time/batch = 0.1488s	
1072/2700 (epoch 19.852), train_loss = 1.73924413, grad/param norm = 5.8155e-01, time/batch = 0.1609s	
1073/2700 (epoch 19.870), train_loss = 1.73352244, grad/param norm = 4.7314e-01, time/batch = 0.1606s	
1074/2700 (epoch 19.889), train_loss = 1.75237930, grad/param norm = 5.2873e-01, time/batch = 0.1726s	
1075/2700 (epoch 19.907), train_loss = 1.86512007, grad/param norm = 5.0690e-01, time/batch = 0.1741s	
1076/2700 (epoch 19.926), train_loss = 1.78208200, grad/param norm = 4.9678e-01, time/batch = 0.1788s	
1077/2700 (epoch 19.944), train_loss = 1.74358333, grad/param norm = 4.6789e-01, time/batch = 0.1534s	
1078/2700 (epoch 19.963), train_loss = 1.79292679, grad/param norm = 4.6256e-01, time/batch = 0.1774s	
1079/2700 (epoch 19.981), train_loss = 1.75002915, grad/param norm = 4.5987e-01, time/batch = 0.1774s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1080/2700 (epoch 20.000), train_loss = 1.80442541, grad/param norm = 4.5998e-01, time/batch = 0.1658s	
1081/2700 (epoch 20.019), train_loss = 1.77138371, grad/param norm = 4.6664e-01, time/batch = 0.1580s	
1082/2700 (epoch 20.037), train_loss = 1.79816501, grad/param norm = 4.6993e-01, time/batch = 0.1666s	
1083/2700 (epoch 20.056), train_loss = 1.73307117, grad/param norm = 6.3090e-01, time/batch = 0.1512s	
1084/2700 (epoch 20.074), train_loss = 1.72568871, grad/param norm = 5.9104e-01, time/batch = 0.1533s	
1085/2700 (epoch 20.093), train_loss = 1.72837232, grad/param norm = 4.6667e-01, time/batch = 0.1561s	
1086/2700 (epoch 20.111), train_loss = 1.70712667, grad/param norm = 4.5535e-01, time/batch = 0.1650s	
1087/2700 (epoch 20.130), train_loss = 1.74622161, grad/param norm = 4.6153e-01, time/batch = 0.1566s	
1088/2700 (epoch 20.148), train_loss = 1.69265181, grad/param norm = 4.8011e-01, time/batch = 0.1657s	
1089/2700 (epoch 20.167), train_loss = 1.77765162, grad/param norm = 5.1529e-01, time/batch = 0.1631s	
1090/2700 (epoch 20.185), train_loss = 1.69450372, grad/param norm = 5.1892e-01, time/batch = 0.1552s	
1091/2700 (epoch 20.204), train_loss = 1.75056959, grad/param norm = 6.2775e-01, time/batch = 0.1728s	
1092/2700 (epoch 20.222), train_loss = 1.67951765, grad/param norm = 6.7673e-01, time/batch = 0.1799s	
1093/2700 (epoch 20.241), train_loss = 1.62923239, grad/param norm = 6.0346e-01, time/batch = 0.1817s	
1094/2700 (epoch 20.259), train_loss = 1.67029318, grad/param norm = 5.2304e-01, time/batch = 0.1792s	
1095/2700 (epoch 20.278), train_loss = 1.75271858, grad/param norm = 4.3845e-01, time/batch = 0.1788s	
1096/2700 (epoch 20.296), train_loss = 1.72048728, grad/param norm = 4.5700e-01, time/batch = 0.1805s	
1097/2700 (epoch 20.315), train_loss = 1.74612169, grad/param norm = 5.6695e-01, time/batch = 0.1716s	
1098/2700 (epoch 20.333), train_loss = 1.74299429, grad/param norm = 5.3883e-01, time/batch = 0.1742s	
1099/2700 (epoch 20.352), train_loss = 1.74597721, grad/param norm = 4.8767e-01, time/batch = 0.1640s	
1100/2700 (epoch 20.370), train_loss = 1.76755790, grad/param norm = 5.5098e-01, time/batch = 0.1507s	
1101/2700 (epoch 20.389), train_loss = 1.73088018, grad/param norm = 5.4852e-01, time/batch = 0.1733s	
1102/2700 (epoch 20.407), train_loss = 1.76644522, grad/param norm = 4.9397e-01, time/batch = 0.1572s	
1103/2700 (epoch 20.426), train_loss = 1.78034410, grad/param norm = 4.2954e-01, time/batch = 0.1433s	
1104/2700 (epoch 20.444), train_loss = 1.67570037, grad/param norm = 4.5458e-01, time/batch = 0.1587s	
1105/2700 (epoch 20.463), train_loss = 1.77296450, grad/param norm = 4.8501e-01, time/batch = 0.1634s	
1106/2700 (epoch 20.481), train_loss = 1.77794999, grad/param norm = 4.9921e-01, time/batch = 0.1532s	
1107/2700 (epoch 20.500), train_loss = 1.73466854, grad/param norm = 4.9315e-01, time/batch = 0.1565s	
1108/2700 (epoch 20.519), train_loss = 1.74611264, grad/param norm = 4.4526e-01, time/batch = 0.1478s	
1109/2700 (epoch 20.537), train_loss = 1.74662876, grad/param norm = 4.6084e-01, time/batch = 0.1592s	
1110/2700 (epoch 20.556), train_loss = 1.68911290, grad/param norm = 4.8023e-01, time/batch = 0.1613s	
1111/2700 (epoch 20.574), train_loss = 1.69018028, grad/param norm = 4.7227e-01, time/batch = 0.1686s	
1112/2700 (epoch 20.593), train_loss = 1.70642082, grad/param norm = 5.2418e-01, time/batch = 0.1681s	
1113/2700 (epoch 20.611), train_loss = 1.61198456, grad/param norm = 4.9638e-01, time/batch = 0.1343s	
1114/2700 (epoch 20.630), train_loss = 1.67246204, grad/param norm = 4.6580e-01, time/batch = 0.1558s	
1115/2700 (epoch 20.648), train_loss = 1.68817728, grad/param norm = 4.5272e-01, time/batch = 0.1775s	
1116/2700 (epoch 20.667), train_loss = 1.66968066, grad/param norm = 4.8496e-01, time/batch = 0.1787s	
1117/2700 (epoch 20.685), train_loss = 1.70179458, grad/param norm = 5.1408e-01, time/batch = 0.1785s	
1118/2700 (epoch 20.704), train_loss = 1.72640989, grad/param norm = 5.1721e-01, time/batch = 0.1875s	
1119/2700 (epoch 20.722), train_loss = 1.69284389, grad/param norm = 4.4311e-01, time/batch = 0.1580s	
1120/2700 (epoch 20.741), train_loss = 1.74434592, grad/param norm = 4.6408e-01, time/batch = 0.1463s	
1121/2700 (epoch 20.759), train_loss = 1.74120116, grad/param norm = 5.2268e-01, time/batch = 0.1735s	
1122/2700 (epoch 20.778), train_loss = 1.75951824, grad/param norm = 4.9256e-01, time/batch = 0.1827s	
1123/2700 (epoch 20.796), train_loss = 1.72980227, grad/param norm = 5.6862e-01, time/batch = 0.1862s	
1124/2700 (epoch 20.815), train_loss = 1.77391892, grad/param norm = 7.0776e-01, time/batch = 0.1213s	
1125/2700 (epoch 20.833), train_loss = 1.71518173, grad/param norm = 6.6066e-01, time/batch = 0.1719s	
1126/2700 (epoch 20.852), train_loss = 1.72324219, grad/param norm = 5.7463e-01, time/batch = 0.1735s	
1127/2700 (epoch 20.870), train_loss = 1.71880224, grad/param norm = 4.6444e-01, time/batch = 0.1940s	
1128/2700 (epoch 20.889), train_loss = 1.73794394, grad/param norm = 5.2413e-01, time/batch = 0.1723s	
1129/2700 (epoch 20.907), train_loss = 1.85066691, grad/param norm = 5.0371e-01, time/batch = 0.1628s	
1130/2700 (epoch 20.926), train_loss = 1.76683976, grad/param norm = 4.9524e-01, time/batch = 0.1601s	
1131/2700 (epoch 20.944), train_loss = 1.72700092, grad/param norm = 4.6634e-01, time/batch = 0.1682s	
1132/2700 (epoch 20.963), train_loss = 1.77674301, grad/param norm = 4.5446e-01, time/batch = 0.1601s	
1133/2700 (epoch 20.981), train_loss = 1.73387691, grad/param norm = 4.5561e-01, time/batch = 0.1714s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1134/2700 (epoch 21.000), train_loss = 1.78879402, grad/param norm = 4.5497e-01, time/batch = 0.1459s	
1135/2700 (epoch 21.019), train_loss = 1.75712465, grad/param norm = 4.6499e-01, time/batch = 0.1460s	
1136/2700 (epoch 21.037), train_loss = 1.78427608, grad/param norm = 4.7405e-01, time/batch = 0.1468s	
1137/2700 (epoch 21.056), train_loss = 1.71725824, grad/param norm = 6.1539e-01, time/batch = 0.1554s	
1138/2700 (epoch 21.074), train_loss = 1.71046287, grad/param norm = 5.6760e-01, time/batch = 0.1569s	
1139/2700 (epoch 21.093), train_loss = 1.71219040, grad/param norm = 4.5492e-01, time/batch = 0.1552s	
1140/2700 (epoch 21.111), train_loss = 1.69152864, grad/param norm = 4.5899e-01, time/batch = 0.1771s	
1141/2700 (epoch 21.130), train_loss = 1.73077994, grad/param norm = 4.6639e-01, time/batch = 0.1616s	
1142/2700 (epoch 21.148), train_loss = 1.67777071, grad/param norm = 4.6153e-01, time/batch = 0.1722s	
1143/2700 (epoch 21.167), train_loss = 1.76231385, grad/param norm = 4.6287e-01, time/batch = 0.1760s	
1144/2700 (epoch 21.185), train_loss = 1.67833252, grad/param norm = 4.5045e-01, time/batch = 0.1747s	
1145/2700 (epoch 21.204), train_loss = 1.73317596, grad/param norm = 5.4082e-01, time/batch = 0.1609s	
1146/2700 (epoch 21.222), train_loss = 1.66286130, grad/param norm = 6.3905e-01, time/batch = 0.1766s	
1147/2700 (epoch 21.241), train_loss = 1.61484740, grad/param norm = 6.2359e-01, time/batch = 0.1784s	
1148/2700 (epoch 21.259), train_loss = 1.65819707, grad/param norm = 5.4338e-01, time/batch = 0.1746s	
1149/2700 (epoch 21.278), train_loss = 1.73851014, grad/param norm = 4.4340e-01, time/batch = 0.1682s	
1150/2700 (epoch 21.296), train_loss = 1.70690985, grad/param norm = 4.6593e-01, time/batch = 0.1748s	
1151/2700 (epoch 21.315), train_loss = 1.73087018, grad/param norm = 5.8565e-01, time/batch = 0.1806s	
1152/2700 (epoch 21.333), train_loss = 1.72922338, grad/param norm = 5.3954e-01, time/batch = 0.1775s	
1153/2700 (epoch 21.352), train_loss = 1.73036812, grad/param norm = 4.9448e-01, time/batch = 0.1780s	
1154/2700 (epoch 21.370), train_loss = 1.75268182, grad/param norm = 5.4383e-01, time/batch = 0.1682s	
1155/2700 (epoch 21.389), train_loss = 1.71547976, grad/param norm = 5.2270e-01, time/batch = 0.1763s	
1156/2700 (epoch 21.407), train_loss = 1.75259810, grad/param norm = 4.6734e-01, time/batch = 0.1478s	
1157/2700 (epoch 21.426), train_loss = 1.76477445, grad/param norm = 4.3777e-01, time/batch = 0.1735s	
1158/2700 (epoch 21.444), train_loss = 1.66097961, grad/param norm = 4.5683e-01, time/batch = 0.1768s	
1159/2700 (epoch 21.463), train_loss = 1.75837327, grad/param norm = 4.7804e-01, time/batch = 0.1676s	
1160/2700 (epoch 21.481), train_loss = 1.76237317, grad/param norm = 4.9908e-01, time/batch = 0.1786s	
1161/2700 (epoch 21.500), train_loss = 1.71775099, grad/param norm = 4.8444e-01, time/batch = 0.1729s	
1162/2700 (epoch 21.519), train_loss = 1.73324107, grad/param norm = 4.4634e-01, time/batch = 0.1807s	
1163/2700 (epoch 21.537), train_loss = 1.73121665, grad/param norm = 4.5784e-01, time/batch = 0.1790s	
1164/2700 (epoch 21.556), train_loss = 1.67308587, grad/param norm = 4.7285e-01, time/batch = 0.1831s	
1165/2700 (epoch 21.574), train_loss = 1.67622021, grad/param norm = 4.8839e-01, time/batch = 0.1769s	
1166/2700 (epoch 21.593), train_loss = 1.69464813, grad/param norm = 5.4025e-01, time/batch = 0.1642s	
1167/2700 (epoch 21.611), train_loss = 1.59823970, grad/param norm = 5.0520e-01, time/batch = 0.1763s	
1168/2700 (epoch 21.630), train_loss = 1.65789786, grad/param norm = 4.6419e-01, time/batch = 0.1774s	
1169/2700 (epoch 21.648), train_loss = 1.67469896, grad/param norm = 4.5674e-01, time/batch = 0.1684s	
1170/2700 (epoch 21.667), train_loss = 1.65592601, grad/param norm = 4.8211e-01, time/batch = 0.1799s	
1171/2700 (epoch 21.685), train_loss = 1.68709800, grad/param norm = 5.0752e-01, time/batch = 0.1804s	
1172/2700 (epoch 21.704), train_loss = 1.71104491, grad/param norm = 5.1025e-01, time/batch = 0.1795s	
1173/2700 (epoch 21.722), train_loss = 1.67901081, grad/param norm = 4.4018e-01, time/batch = 0.1795s	
1174/2700 (epoch 21.741), train_loss = 1.72917496, grad/param norm = 4.5975e-01, time/batch = 0.1723s	
1175/2700 (epoch 21.759), train_loss = 1.72428592, grad/param norm = 5.1493e-01, time/batch = 0.1782s	
1176/2700 (epoch 21.778), train_loss = 1.74440338, grad/param norm = 4.8438e-01, time/batch = 0.1740s	
1177/2700 (epoch 21.796), train_loss = 1.71438458, grad/param norm = 5.6071e-01, time/batch = 0.1530s	
1178/2700 (epoch 21.815), train_loss = 1.75835379, grad/param norm = 6.7572e-01, time/batch = 0.1635s	
1179/2700 (epoch 21.833), train_loss = 1.69921239, grad/param norm = 6.2145e-01, time/batch = 0.1676s	
1180/2700 (epoch 21.852), train_loss = 1.70643229, grad/param norm = 5.4812e-01, time/batch = 0.1569s	
1181/2700 (epoch 21.870), train_loss = 1.70414920, grad/param norm = 4.5171e-01, time/batch = 0.1585s	
1182/2700 (epoch 21.889), train_loss = 1.72405107, grad/param norm = 5.1801e-01, time/batch = 0.1690s	
1183/2700 (epoch 21.907), train_loss = 1.83705746, grad/param norm = 5.0338e-01, time/batch = 0.1696s	
1184/2700 (epoch 21.926), train_loss = 1.75251927, grad/param norm = 4.9694e-01, time/batch = 0.1566s	
1185/2700 (epoch 21.944), train_loss = 1.71208911, grad/param norm = 4.7093e-01, time/batch = 0.1613s	
1186/2700 (epoch 21.963), train_loss = 1.76221205, grad/param norm = 4.5415e-01, time/batch = 0.1550s	
1187/2700 (epoch 21.981), train_loss = 1.71884078, grad/param norm = 4.5055e-01, time/batch = 0.1469s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1188/2700 (epoch 22.000), train_loss = 1.77433096, grad/param norm = 4.5011e-01, time/batch = 0.1360s	
1189/2700 (epoch 22.019), train_loss = 1.74444209, grad/param norm = 4.6535e-01, time/batch = 0.1429s	
1190/2700 (epoch 22.037), train_loss = 1.77085313, grad/param norm = 4.6835e-01, time/batch = 0.1370s	
1191/2700 (epoch 22.056), train_loss = 1.70193320, grad/param norm = 5.8234e-01, time/batch = 0.1532s	
1192/2700 (epoch 22.074), train_loss = 1.69627528, grad/param norm = 5.4666e-01, time/batch = 0.1614s	
1193/2700 (epoch 22.093), train_loss = 1.69711997, grad/param norm = 4.5090e-01, time/batch = 0.1679s	
1194/2700 (epoch 22.111), train_loss = 1.67693130, grad/param norm = 4.6731e-01, time/batch = 0.1614s	
1195/2700 (epoch 22.130), train_loss = 1.71654577, grad/param norm = 4.7735e-01, time/batch = 0.1443s	
1196/2700 (epoch 22.148), train_loss = 1.66497816, grad/param norm = 4.6370e-01, time/batch = 0.1636s	
1197/2700 (epoch 22.167), train_loss = 1.74922091, grad/param norm = 4.4914e-01, time/batch = 0.1599s	
1198/2700 (epoch 22.185), train_loss = 1.66479696, grad/param norm = 4.3140e-01, time/batch = 0.1634s	
1199/2700 (epoch 22.204), train_loss = 1.71957438, grad/param norm = 4.9446e-01, time/batch = 0.1399s	
1200/2700 (epoch 22.222), train_loss = 1.64803298, grad/param norm = 5.7546e-01, time/batch = 0.1594s	
1201/2700 (epoch 22.241), train_loss = 1.59904061, grad/param norm = 5.8650e-01, time/batch = 0.1308s	
1202/2700 (epoch 22.259), train_loss = 1.64561851, grad/param norm = 5.5738e-01, time/batch = 0.1653s	
1203/2700 (epoch 22.278), train_loss = 1.72543749, grad/param norm = 4.5375e-01, time/batch = 0.1741s	
1204/2700 (epoch 22.296), train_loss = 1.69412806, grad/param norm = 4.7108e-01, time/batch = 0.1774s	
1205/2700 (epoch 22.315), train_loss = 1.71536520, grad/param norm = 5.8085e-01, time/batch = 0.1716s	
1206/2700 (epoch 22.333), train_loss = 1.71485070, grad/param norm = 5.3036e-01, time/batch = 0.1711s	
1207/2700 (epoch 22.352), train_loss = 1.71551095, grad/param norm = 4.9755e-01, time/batch = 0.1665s	
1208/2700 (epoch 22.370), train_loss = 1.73859160, grad/param norm = 5.3875e-01, time/batch = 0.1650s	
1209/2700 (epoch 22.389), train_loss = 1.70147025, grad/param norm = 5.0558e-01, time/batch = 0.1611s	
1210/2700 (epoch 22.407), train_loss = 1.73979948, grad/param norm = 4.5648e-01, time/batch = 0.1445s	
1211/2700 (epoch 22.426), train_loss = 1.75031339, grad/param norm = 4.4656e-01, time/batch = 0.1745s	
1212/2700 (epoch 22.444), train_loss = 1.64713110, grad/param norm = 4.5761e-01, time/batch = 0.1786s	
1213/2700 (epoch 22.463), train_loss = 1.74476820, grad/param norm = 4.7155e-01, time/batch = 0.1769s	
1214/2700 (epoch 22.481), train_loss = 1.74772894, grad/param norm = 4.9999e-01, time/batch = 0.1708s	
1215/2700 (epoch 22.500), train_loss = 1.70164884, grad/param norm = 4.7931e-01, time/batch = 0.1576s	
1216/2700 (epoch 22.519), train_loss = 1.72102403, grad/param norm = 4.4711e-01, time/batch = 0.1508s	
1217/2700 (epoch 22.537), train_loss = 1.71672478, grad/param norm = 4.5672e-01, time/batch = 0.1343s	
1218/2700 (epoch 22.556), train_loss = 1.65821946, grad/param norm = 4.6972e-01, time/batch = 0.1388s	
1219/2700 (epoch 22.574), train_loss = 1.66260647, grad/param norm = 4.9331e-01, time/batch = 0.1497s	
1220/2700 (epoch 22.593), train_loss = 1.68335347, grad/param norm = 5.4000e-01, time/batch = 0.1433s	
1221/2700 (epoch 22.611), train_loss = 1.58489786, grad/param norm = 4.9972e-01, time/batch = 0.1603s	
1222/2700 (epoch 22.630), train_loss = 1.64437875, grad/param norm = 4.6070e-01, time/batch = 0.1619s	
1223/2700 (epoch 22.648), train_loss = 1.66207579, grad/param norm = 4.5876e-01, time/batch = 0.1771s	
1224/2700 (epoch 22.667), train_loss = 1.64303575, grad/param norm = 4.7765e-01, time/batch = 0.1778s	
1225/2700 (epoch 22.685), train_loss = 1.67362065, grad/param norm = 5.0585e-01, time/batch = 0.1780s	
1226/2700 (epoch 22.704), train_loss = 1.69715188, grad/param norm = 5.0758e-01, time/batch = 0.1659s	
1227/2700 (epoch 22.722), train_loss = 1.66620521, grad/param norm = 4.3956e-01, time/batch = 0.1471s	
1228/2700 (epoch 22.741), train_loss = 1.71504663, grad/param norm = 4.5823e-01, time/batch = 0.1390s	
1229/2700 (epoch 22.759), train_loss = 1.70865468, grad/param norm = 5.1419e-01, time/batch = 0.1499s	
1230/2700 (epoch 22.778), train_loss = 1.73081092, grad/param norm = 4.8494e-01, time/batch = 0.1548s	
1231/2700 (epoch 22.796), train_loss = 1.70041535, grad/param norm = 5.6233e-01, time/batch = 0.1525s	
1232/2700 (epoch 22.815), train_loss = 1.74417603, grad/param norm = 6.5671e-01, time/batch = 0.1781s	
1233/2700 (epoch 22.833), train_loss = 1.68479802, grad/param norm = 5.9499e-01, time/batch = 0.1643s	
1234/2700 (epoch 22.852), train_loss = 1.69118105, grad/param norm = 5.2952e-01, time/batch = 0.1603s	
1235/2700 (epoch 22.870), train_loss = 1.69048010, grad/param norm = 4.4266e-01, time/batch = 0.1648s	
1236/2700 (epoch 22.889), train_loss = 1.71108284, grad/param norm = 5.1220e-01, time/batch = 0.1494s	
1237/2700 (epoch 22.907), train_loss = 1.82414745, grad/param norm = 5.0168e-01, time/batch = 0.1423s	
1238/2700 (epoch 22.926), train_loss = 1.73873001, grad/param norm = 4.9660e-01, time/batch = 0.1375s	
1239/2700 (epoch 22.944), train_loss = 1.69819607, grad/param norm = 4.7177e-01, time/batch = 0.1508s	
1240/2700 (epoch 22.963), train_loss = 1.74857030, grad/param norm = 4.5085e-01, time/batch = 0.1592s	
1241/2700 (epoch 22.981), train_loss = 1.70496899, grad/param norm = 4.5100e-01, time/batch = 0.1634s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1242/2700 (epoch 23.000), train_loss = 1.76096853, grad/param norm = 4.4885e-01, time/batch = 0.1585s	
1243/2700 (epoch 23.019), train_loss = 1.73266228, grad/param norm = 4.6561e-01, time/batch = 0.1647s	
1244/2700 (epoch 23.037), train_loss = 1.75843422, grad/param norm = 4.7378e-01, time/batch = 0.1718s	
1245/2700 (epoch 23.056), train_loss = 1.68846219, grad/param norm = 5.7434e-01, time/batch = 0.1576s	
1246/2700 (epoch 23.074), train_loss = 1.68351880, grad/param norm = 5.3662e-01, time/batch = 0.1243s	
1247/2700 (epoch 23.093), train_loss = 1.68288564, grad/param norm = 4.4925e-01, time/batch = 0.1609s	
1248/2700 (epoch 23.111), train_loss = 1.66322617, grad/param norm = 4.7414e-01, time/batch = 0.1608s	
1249/2700 (epoch 23.130), train_loss = 1.70297276, grad/param norm = 4.8378e-01, time/batch = 0.1605s	
1250/2700 (epoch 23.148), train_loss = 1.65317993, grad/param norm = 4.6555e-01, time/batch = 0.1643s	
1251/2700 (epoch 23.167), train_loss = 1.73724461, grad/param norm = 4.4780e-01, time/batch = 0.1774s	
1252/2700 (epoch 23.185), train_loss = 1.65249218, grad/param norm = 4.3078e-01, time/batch = 0.1696s	
1253/2700 (epoch 23.204), train_loss = 1.70817068, grad/param norm = 4.8966e-01, time/batch = 0.1514s	
1254/2700 (epoch 23.222), train_loss = 1.63648923, grad/param norm = 5.5892e-01, time/batch = 0.1345s	
1255/2700 (epoch 23.241), train_loss = 1.58527775, grad/param norm = 5.5810e-01, time/batch = 0.1586s	
1256/2700 (epoch 23.259), train_loss = 1.63264502, grad/param norm = 5.3302e-01, time/batch = 0.1522s	
1257/2700 (epoch 23.278), train_loss = 1.71254259, grad/param norm = 4.5846e-01, time/batch = 0.1653s	
1258/2700 (epoch 23.296), train_loss = 1.68228804, grad/param norm = 4.7856e-01, time/batch = 0.1714s	
1259/2700 (epoch 23.315), train_loss = 1.70008380, grad/param norm = 5.6048e-01, time/batch = 0.1718s	
1260/2700 (epoch 23.333), train_loss = 1.69968574, grad/param norm = 5.1033e-01, time/batch = 0.1715s	
1261/2700 (epoch 23.352), train_loss = 1.70129246, grad/param norm = 4.9218e-01, time/batch = 0.1670s	
1262/2700 (epoch 23.370), train_loss = 1.72465665, grad/param norm = 5.2844e-01, time/batch = 0.1746s	
1263/2700 (epoch 23.389), train_loss = 1.68857774, grad/param norm = 4.9891e-01, time/batch = 0.1743s	
1264/2700 (epoch 23.407), train_loss = 1.72781147, grad/param norm = 4.5862e-01, time/batch = 0.1650s	
1265/2700 (epoch 23.426), train_loss = 1.73648586, grad/param norm = 4.4603e-01, time/batch = 0.1741s	
1266/2700 (epoch 23.444), train_loss = 1.63409320, grad/param norm = 4.5762e-01, time/batch = 0.1628s	
1267/2700 (epoch 23.463), train_loss = 1.73237731, grad/param norm = 4.7160e-01, time/batch = 0.1587s	
1268/2700 (epoch 23.481), train_loss = 1.73396797, grad/param norm = 5.0196e-01, time/batch = 0.1598s	
1269/2700 (epoch 23.500), train_loss = 1.68633823, grad/param norm = 4.7752e-01, time/batch = 0.1534s	
1270/2700 (epoch 23.519), train_loss = 1.70937742, grad/param norm = 4.4787e-01, time/batch = 0.1402s	
1271/2700 (epoch 23.537), train_loss = 1.70287451, grad/param norm = 4.5710e-01, time/batch = 0.1657s	
1272/2700 (epoch 23.556), train_loss = 1.64426365, grad/param norm = 4.6882e-01, time/batch = 0.1633s	
1273/2700 (epoch 23.574), train_loss = 1.64915321, grad/param norm = 4.8524e-01, time/batch = 0.1581s	
1274/2700 (epoch 23.593), train_loss = 1.67221037, grad/param norm = 5.2355e-01, time/batch = 0.1536s	
1275/2700 (epoch 23.611), train_loss = 1.57188016, grad/param norm = 4.7997e-01, time/batch = 0.1193s	
1276/2700 (epoch 23.630), train_loss = 1.63178126, grad/param norm = 4.5494e-01, time/batch = 0.1737s	
1277/2700 (epoch 23.648), train_loss = 1.64995909, grad/param norm = 4.5550e-01, time/batch = 0.1525s	
1278/2700 (epoch 23.667), train_loss = 1.63060222, grad/param norm = 4.6787e-01, time/batch = 0.1727s	
1279/2700 (epoch 23.685), train_loss = 1.66108360, grad/param norm = 5.0560e-01, time/batch = 0.1677s	
1280/2700 (epoch 23.704), train_loss = 1.68464378, grad/param norm = 5.0924e-01, time/batch = 0.1528s	
1281/2700 (epoch 23.722), train_loss = 1.65431478, grad/param norm = 4.4101e-01, time/batch = 0.1785s	
1282/2700 (epoch 23.741), train_loss = 1.70182903, grad/param norm = 4.5821e-01, time/batch = 0.1783s	
1283/2700 (epoch 23.759), train_loss = 1.69414255, grad/param norm = 5.2070e-01, time/batch = 0.1779s	
1284/2700 (epoch 23.778), train_loss = 1.71871222, grad/param norm = 4.9831e-01, time/batch = 0.1783s	
1285/2700 (epoch 23.796), train_loss = 1.68800819, grad/param norm = 5.7896e-01, time/batch = 0.1681s	
1286/2700 (epoch 23.815), train_loss = 1.73165643, grad/param norm = 6.5247e-01, time/batch = 0.1439s	
1287/2700 (epoch 23.833), train_loss = 1.67184000, grad/param norm = 5.7757e-01, time/batch = 0.1540s	
1288/2700 (epoch 23.852), train_loss = 1.67719867, grad/param norm = 5.1554e-01, time/batch = 0.1642s	
1289/2700 (epoch 23.870), train_loss = 1.67758770, grad/param norm = 4.3556e-01, time/batch = 0.1588s	
1290/2700 (epoch 23.889), train_loss = 1.69886845, grad/param norm = 5.0546e-01, time/batch = 0.1602s	
1291/2700 (epoch 23.907), train_loss = 1.81183631, grad/param norm = 4.9729e-01, time/batch = 0.1736s	
1292/2700 (epoch 23.926), train_loss = 1.72537772, grad/param norm = 4.9302e-01, time/batch = 0.1758s	
1293/2700 (epoch 23.944), train_loss = 1.68514769, grad/param norm = 4.6840e-01, time/batch = 0.1725s	
1294/2700 (epoch 23.963), train_loss = 1.73566550, grad/param norm = 4.4630e-01, time/batch = 0.1680s	
1295/2700 (epoch 23.981), train_loss = 1.69225704, grad/param norm = 4.5899e-01, time/batch = 0.1617s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1296/2700 (epoch 24.000), train_loss = 1.74871861, grad/param norm = 4.5321e-01, time/batch = 0.1401s	
1297/2700 (epoch 24.019), train_loss = 1.72172139, grad/param norm = 4.6721e-01, time/batch = 0.1486s	
1298/2700 (epoch 24.037), train_loss = 1.74666140, grad/param norm = 4.8243e-01, time/batch = 0.1437s	
1299/2700 (epoch 24.056), train_loss = 1.67596003, grad/param norm = 5.7353e-01, time/batch = 0.1478s	
1300/2700 (epoch 24.074), train_loss = 1.67159117, grad/param norm = 5.2801e-01, time/batch = 0.1626s	
1301/2700 (epoch 24.093), train_loss = 1.66933706, grad/param norm = 4.4881e-01, time/batch = 0.1564s	
1302/2700 (epoch 24.111), train_loss = 1.65043773, grad/param norm = 4.8104e-01, time/batch = 0.1661s	
1303/2700 (epoch 24.130), train_loss = 1.69005272, grad/param norm = 4.8847e-01, time/batch = 0.1606s	
1304/2700 (epoch 24.148), train_loss = 1.64214646, grad/param norm = 4.6514e-01, time/batch = 0.1584s	
1305/2700 (epoch 24.167), train_loss = 1.72595000, grad/param norm = 4.4936e-01, time/batch = 0.1621s	
1306/2700 (epoch 24.185), train_loss = 1.64092564, grad/param norm = 4.3420e-01, time/batch = 0.1642s	
1307/2700 (epoch 24.204), train_loss = 1.69778374, grad/param norm = 4.9730e-01, time/batch = 0.1473s	
1308/2700 (epoch 24.222), train_loss = 1.62653477, grad/param norm = 5.6099e-01, time/batch = 0.1404s	
1309/2700 (epoch 24.241), train_loss = 1.57299883, grad/param norm = 5.4760e-01, time/batch = 0.1623s	
1310/2700 (epoch 24.259), train_loss = 1.62069148, grad/param norm = 5.1193e-01, time/batch = 0.1702s	
1311/2700 (epoch 24.278), train_loss = 1.70041697, grad/param norm = 4.6364e-01, time/batch = 0.1556s	
1312/2700 (epoch 24.296), train_loss = 1.67124715, grad/param norm = 4.8627e-01, time/batch = 0.1674s	
1313/2700 (epoch 24.315), train_loss = 1.68559507, grad/param norm = 5.4045e-01, time/batch = 0.1732s	
1314/2700 (epoch 24.333), train_loss = 1.68524556, grad/param norm = 4.8817e-01, time/batch = 0.1775s	
1315/2700 (epoch 24.352), train_loss = 1.68824903, grad/param norm = 4.8740e-01, time/batch = 0.1760s	
1316/2700 (epoch 24.370), train_loss = 1.71136557, grad/param norm = 5.2130e-01, time/batch = 0.1780s	
1317/2700 (epoch 24.389), train_loss = 1.67672846, grad/param norm = 5.0278e-01, time/batch = 0.1689s	
1318/2700 (epoch 24.407), train_loss = 1.71653060, grad/param norm = 4.6987e-01, time/batch = 0.1660s	
1319/2700 (epoch 24.426), train_loss = 1.72348840, grad/param norm = 4.4178e-01, time/batch = 0.1676s	
1320/2700 (epoch 24.444), train_loss = 1.62196723, grad/param norm = 4.6011e-01, time/batch = 0.1657s	
1321/2700 (epoch 24.463), train_loss = 1.72117975, grad/param norm = 4.7861e-01, time/batch = 0.1794s	
1322/2700 (epoch 24.481), train_loss = 1.72118541, grad/param norm = 5.0500e-01, time/batch = 0.1791s	
1323/2700 (epoch 24.500), train_loss = 1.67165112, grad/param norm = 4.7667e-01, time/batch = 0.1792s	
1324/2700 (epoch 24.519), train_loss = 1.69842195, grad/param norm = 4.5211e-01, time/batch = 0.1790s	
1325/2700 (epoch 24.537), train_loss = 1.68981060, grad/param norm = 4.5983e-01, time/batch = 0.1804s	
1326/2700 (epoch 24.556), train_loss = 1.63118536, grad/param norm = 4.6947e-01, time/batch = 0.1781s	
1327/2700 (epoch 24.574), train_loss = 1.63630332, grad/param norm = 4.7765e-01, time/batch = 0.1774s	
1328/2700 (epoch 24.593), train_loss = 1.66175812, grad/param norm = 5.0694e-01, time/batch = 0.1501s	
1329/2700 (epoch 24.611), train_loss = 1.55977848, grad/param norm = 4.5958e-01, time/batch = 0.1372s	
1330/2700 (epoch 24.630), train_loss = 1.62023279, grad/param norm = 4.5272e-01, time/batch = 0.1611s	
1331/2700 (epoch 24.648), train_loss = 1.63863633, grad/param norm = 4.5404e-01, time/batch = 0.1443s	
1332/2700 (epoch 24.667), train_loss = 1.61879675, grad/param norm = 4.5788e-01, time/batch = 0.1642s	
1333/2700 (epoch 24.685), train_loss = 1.64944412, grad/param norm = 5.0565e-01, time/batch = 0.1715s	
1334/2700 (epoch 24.704), train_loss = 1.67316361, grad/param norm = 5.1384e-01, time/batch = 0.1770s	
1335/2700 (epoch 24.722), train_loss = 1.64316541, grad/param norm = 4.4474e-01, time/batch = 0.1762s	
1336/2700 (epoch 24.741), train_loss = 1.68942137, grad/param norm = 4.5926e-01, time/batch = 0.1760s	
1337/2700 (epoch 24.759), train_loss = 1.68055377, grad/param norm = 5.3216e-01, time/batch = 0.1708s	
1338/2700 (epoch 24.778), train_loss = 1.70773592, grad/param norm = 5.1937e-01, time/batch = 0.1571s	
1339/2700 (epoch 24.796), train_loss = 1.67642745, grad/param norm = 5.9534e-01, time/batch = 0.1275s	
1340/2700 (epoch 24.815), train_loss = 1.71929607, grad/param norm = 6.3822e-01, time/batch = 0.1397s	
1341/2700 (epoch 24.833), train_loss = 1.65915525, grad/param norm = 5.5455e-01, time/batch = 0.1727s	
1342/2700 (epoch 24.852), train_loss = 1.66372105, grad/param norm = 5.0150e-01, time/batch = 0.1583s	
1343/2700 (epoch 24.870), train_loss = 1.66527809, grad/param norm = 4.3031e-01, time/batch = 0.1405s	
1344/2700 (epoch 24.889), train_loss = 1.68734738, grad/param norm = 4.9873e-01, time/batch = 0.1406s	
1345/2700 (epoch 24.907), train_loss = 1.80018669, grad/param norm = 4.9258e-01, time/batch = 0.1620s	
1346/2700 (epoch 24.926), train_loss = 1.71271809, grad/param norm = 4.9067e-01, time/batch = 0.1661s	
1347/2700 (epoch 24.944), train_loss = 1.67308146, grad/param norm = 4.6578e-01, time/batch = 0.1677s	
1348/2700 (epoch 24.963), train_loss = 1.72355877, grad/param norm = 4.4390e-01, time/batch = 0.1701s	
1349/2700 (epoch 24.981), train_loss = 1.68046331, grad/param norm = 4.6922e-01, time/batch = 0.1619s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1350/2700 (epoch 25.000), train_loss = 1.73733900, grad/param norm = 4.5818e-01, time/batch = 0.1590s	
1351/2700 (epoch 25.019), train_loss = 1.71167822, grad/param norm = 4.6932e-01, time/batch = 0.1770s	
1352/2700 (epoch 25.037), train_loss = 1.73514228, grad/param norm = 4.8435e-01, time/batch = 0.1772s	
1353/2700 (epoch 25.056), train_loss = 1.66342521, grad/param norm = 5.5693e-01, time/batch = 0.1748s	
1354/2700 (epoch 25.074), train_loss = 1.66012790, grad/param norm = 5.1230e-01, time/batch = 0.1750s	
1355/2700 (epoch 25.093), train_loss = 1.65651625, grad/param norm = 4.5117e-01, time/batch = 0.1749s	
1356/2700 (epoch 25.111), train_loss = 1.63869742, grad/param norm = 4.9668e-01, time/batch = 0.1709s	
1357/2700 (epoch 25.130), train_loss = 1.67832411, grad/param norm = 5.0400e-01, time/batch = 0.1574s	
1358/2700 (epoch 25.148), train_loss = 1.63192947, grad/param norm = 4.6868e-01, time/batch = 0.1520s	
1359/2700 (epoch 25.167), train_loss = 1.71514826, grad/param norm = 4.5020e-01, time/batch = 0.1563s	
1360/2700 (epoch 25.185), train_loss = 1.62981932, grad/param norm = 4.3440e-01, time/batch = 0.1458s	
1361/2700 (epoch 25.204), train_loss = 1.68733383, grad/param norm = 4.9283e-01, time/batch = 0.1478s	
1362/2700 (epoch 25.222), train_loss = 1.61629026, grad/param norm = 5.4430e-01, time/batch = 0.1776s	
1363/2700 (epoch 25.241), train_loss = 1.56066642, grad/param norm = 5.2108e-01, time/batch = 0.1794s	
1364/2700 (epoch 25.259), train_loss = 1.60930423, grad/param norm = 4.9340e-01, time/batch = 0.1778s	
1365/2700 (epoch 25.278), train_loss = 1.68941557, grad/param norm = 4.7385e-01, time/batch = 0.1811s	
1366/2700 (epoch 25.296), train_loss = 1.66097088, grad/param norm = 4.9405e-01, time/batch = 0.1780s	
1367/2700 (epoch 25.315), train_loss = 1.67213398, grad/param norm = 5.2713e-01, time/batch = 0.1711s	
1368/2700 (epoch 25.333), train_loss = 1.67207763, grad/param norm = 4.7236e-01, time/batch = 0.1574s	
1369/2700 (epoch 25.352), train_loss = 1.67647295, grad/param norm = 4.8587e-01, time/batch = 0.1546s	
1370/2700 (epoch 25.370), train_loss = 1.69902817, grad/param norm = 5.2144e-01, time/batch = 0.1393s	
1371/2700 (epoch 25.389), train_loss = 1.66581513, grad/param norm = 5.1302e-01, time/batch = 0.1503s	
1372/2700 (epoch 25.407), train_loss = 1.70579601, grad/param norm = 4.8424e-01, time/batch = 0.1383s	
1373/2700 (epoch 25.426), train_loss = 1.71155587, grad/param norm = 4.4144e-01, time/batch = 0.1537s	
1374/2700 (epoch 25.444), train_loss = 1.61074260, grad/param norm = 4.6495e-01, time/batch = 0.1477s	
1375/2700 (epoch 25.463), train_loss = 1.71077274, grad/param norm = 4.8560e-01, time/batch = 0.1321s	
1376/2700 (epoch 25.481), train_loss = 1.70920852, grad/param norm = 5.0701e-01, time/batch = 0.1351s	
1377/2700 (epoch 25.500), train_loss = 1.65773949, grad/param norm = 4.7269e-01, time/batch = 0.1527s	
1378/2700 (epoch 25.519), train_loss = 1.68802040, grad/param norm = 4.5599e-01, time/batch = 0.1660s	
1379/2700 (epoch 25.537), train_loss = 1.67765692, grad/param norm = 4.6159e-01, time/batch = 0.1630s	
1380/2700 (epoch 25.556), train_loss = 1.61884697, grad/param norm = 4.6750e-01, time/batch = 0.1527s	
1381/2700 (epoch 25.574), train_loss = 1.62454027, grad/param norm = 4.8361e-01, time/batch = 0.1636s	
1382/2700 (epoch 25.593), train_loss = 1.65256200, grad/param norm = 5.0677e-01, time/batch = 0.1717s	
1383/2700 (epoch 25.611), train_loss = 1.54912739, grad/param norm = 4.5593e-01, time/batch = 0.1515s	
1384/2700 (epoch 25.630), train_loss = 1.60944354, grad/param norm = 4.5516e-01, time/batch = 0.1447s	
1385/2700 (epoch 25.648), train_loss = 1.62815497, grad/param norm = 4.5811e-01, time/batch = 0.1478s	
1386/2700 (epoch 25.667), train_loss = 1.60792229, grad/param norm = 4.5757e-01, time/batch = 0.1635s	
1387/2700 (epoch 25.685), train_loss = 1.63895625, grad/param norm = 5.0902e-01, time/batch = 0.1731s	
1388/2700 (epoch 25.704), train_loss = 1.66205419, grad/param norm = 5.1419e-01, time/batch = 0.1770s	
1389/2700 (epoch 25.722), train_loss = 1.63225632, grad/param norm = 4.4437e-01, time/batch = 0.1767s	
1390/2700 (epoch 25.741), train_loss = 1.67750851, grad/param norm = 4.5639e-01, time/batch = 0.1689s	
1391/2700 (epoch 25.759), train_loss = 1.66705634, grad/param norm = 5.2464e-01, time/batch = 0.1602s	
1392/2700 (epoch 25.778), train_loss = 1.69586377, grad/param norm = 5.0262e-01, time/batch = 0.1703s	
1393/2700 (epoch 25.796), train_loss = 1.66299951, grad/param norm = 5.7192e-01, time/batch = 0.1737s	
1394/2700 (epoch 25.815), train_loss = 1.70608479, grad/param norm = 6.0345e-01, time/batch = 0.1518s	
1395/2700 (epoch 25.833), train_loss = 1.64672705, grad/param norm = 5.3532e-01, time/batch = 0.1605s	
1396/2700 (epoch 25.852), train_loss = 1.65113119, grad/param norm = 4.9271e-01, time/batch = 0.1486s	
1397/2700 (epoch 25.870), train_loss = 1.65379603, grad/param norm = 4.2975e-01, time/batch = 0.1365s	
1398/2700 (epoch 25.889), train_loss = 1.67665830, grad/param norm = 4.9493e-01, time/batch = 0.1483s	
1399/2700 (epoch 25.907), train_loss = 1.78927169, grad/param norm = 4.9046e-01, time/batch = 0.1647s	
1400/2700 (epoch 25.926), train_loss = 1.70093213, grad/param norm = 4.9290e-01, time/batch = 0.1637s	
1401/2700 (epoch 25.944), train_loss = 1.66226420, grad/param norm = 4.6812e-01, time/batch = 0.1487s	
1402/2700 (epoch 25.963), train_loss = 1.71231483, grad/param norm = 4.4561e-01, time/batch = 0.1549s	
1403/2700 (epoch 25.981), train_loss = 1.66924928, grad/param norm = 4.7313e-01, time/batch = 0.1474s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1404/2700 (epoch 26.000), train_loss = 1.72649863, grad/param norm = 4.5668e-01, time/batch = 0.1515s	
1405/2700 (epoch 26.019), train_loss = 1.70253343, grad/param norm = 4.7057e-01, time/batch = 0.1527s	
1406/2700 (epoch 26.037), train_loss = 1.72405329, grad/param norm = 4.8184e-01, time/batch = 0.1615s	
1407/2700 (epoch 26.056), train_loss = 1.65112695, grad/param norm = 5.2891e-01, time/batch = 0.1469s	
1408/2700 (epoch 26.074), train_loss = 1.64938727, grad/param norm = 4.9548e-01, time/batch = 0.1405s	
1409/2700 (epoch 26.093), train_loss = 1.64450033, grad/param norm = 4.5776e-01, time/batch = 0.1504s	
1410/2700 (epoch 26.111), train_loss = 1.62792949, grad/param norm = 5.2043e-01, time/batch = 0.1583s	
1411/2700 (epoch 26.130), train_loss = 1.66797526, grad/param norm = 5.3004e-01, time/batch = 0.1448s	
1412/2700 (epoch 26.148), train_loss = 1.62259969, grad/param norm = 4.7723e-01, time/batch = 0.1724s	
1413/2700 (epoch 26.167), train_loss = 1.70499758, grad/param norm = 4.5194e-01, time/batch = 0.1711s	
1414/2700 (epoch 26.185), train_loss = 1.61925986, grad/param norm = 4.3403e-01, time/batch = 0.1653s	
1415/2700 (epoch 26.204), train_loss = 1.67724523, grad/param norm = 4.8698e-01, time/batch = 0.1557s	
1416/2700 (epoch 26.222), train_loss = 1.60662910, grad/param norm = 5.2939e-01, time/batch = 0.1474s	
1417/2700 (epoch 26.241), train_loss = 1.54931177, grad/param norm = 5.0271e-01, time/batch = 0.1423s	
1418/2700 (epoch 26.259), train_loss = 1.59894939, grad/param norm = 4.8445e-01, time/batch = 0.1455s	
1419/2700 (epoch 26.278), train_loss = 1.67929690, grad/param norm = 4.8853e-01, time/batch = 0.1611s	
1420/2700 (epoch 26.296), train_loss = 1.65148287, grad/param norm = 5.0465e-01, time/batch = 0.1710s	
1421/2700 (epoch 26.315), train_loss = 1.65978558, grad/param norm = 5.2486e-01, time/batch = 0.1455s	
1422/2700 (epoch 26.333), train_loss = 1.66035008, grad/param norm = 4.6859e-01, time/batch = 0.1683s	
1423/2700 (epoch 26.352), train_loss = 1.66603455, grad/param norm = 4.9161e-01, time/batch = 0.1701s	
1424/2700 (epoch 26.370), train_loss = 1.68755071, grad/param norm = 5.2822e-01, time/batch = 0.1712s	
1425/2700 (epoch 26.389), train_loss = 1.65548805, grad/param norm = 5.2444e-01, time/batch = 0.1608s	
1426/2700 (epoch 26.407), train_loss = 1.69541563, grad/param norm = 4.9234e-01, time/batch = 0.1774s	
1427/2700 (epoch 26.426), train_loss = 1.70051893, grad/param norm = 4.4444e-01, time/batch = 0.1702s	
1428/2700 (epoch 26.444), train_loss = 1.60003139, grad/param norm = 4.6587e-01, time/batch = 0.1538s	
1429/2700 (epoch 26.463), train_loss = 1.70064809, grad/param norm = 4.8485e-01, time/batch = 0.1539s	
1430/2700 (epoch 26.481), train_loss = 1.69766079, grad/param norm = 5.0524e-01, time/batch = 0.1658s	
1431/2700 (epoch 26.500), train_loss = 1.64464176, grad/param norm = 4.6543e-01, time/batch = 0.1502s	
1432/2700 (epoch 26.519), train_loss = 1.67816521, grad/param norm = 4.5943e-01, time/batch = 0.1590s	
1433/2700 (epoch 26.537), train_loss = 1.66626913, grad/param norm = 4.6187e-01, time/batch = 0.1631s	
1434/2700 (epoch 26.556), train_loss = 1.60712982, grad/param norm = 4.6360e-01, time/batch = 0.1581s	
1435/2700 (epoch 26.574), train_loss = 1.61361476, grad/param norm = 4.9840e-01, time/batch = 0.1576s	
1436/2700 (epoch 26.593), train_loss = 1.64411914, grad/param norm = 5.1468e-01, time/batch = 0.1548s	
1437/2700 (epoch 26.611), train_loss = 1.53947075, grad/param norm = 4.5919e-01, time/batch = 0.1426s	
1438/2700 (epoch 26.630), train_loss = 1.59927203, grad/param norm = 4.5852e-01, time/batch = 0.1472s	
1439/2700 (epoch 26.648), train_loss = 1.61840708, grad/param norm = 4.6227e-01, time/batch = 0.1353s	
1440/2700 (epoch 26.667), train_loss = 1.59770055, grad/param norm = 4.5993e-01, time/batch = 0.1551s	
1441/2700 (epoch 26.685), train_loss = 1.62938325, grad/param norm = 5.1333e-01, time/batch = 0.1358s	
1442/2700 (epoch 26.704), train_loss = 1.65155684, grad/param norm = 5.1387e-01, time/batch = 0.1456s	
1443/2700 (epoch 26.722), train_loss = 1.62182437, grad/param norm = 4.4331e-01, time/batch = 0.1678s	
1444/2700 (epoch 26.741), train_loss = 1.66624593, grad/param norm = 4.5343e-01, time/batch = 0.1745s	
1445/2700 (epoch 26.759), train_loss = 1.65427619, grad/param norm = 5.1552e-01, time/batch = 0.1725s	
1446/2700 (epoch 26.778), train_loss = 1.68453666, grad/param norm = 4.8491e-01, time/batch = 0.1612s	
1447/2700 (epoch 26.796), train_loss = 1.65032421, grad/param norm = 5.4798e-01, time/batch = 0.1705s	
1448/2700 (epoch 26.815), train_loss = 1.69379386, grad/param norm = 5.6686e-01, time/batch = 0.1734s	
1449/2700 (epoch 26.833), train_loss = 1.63514325, grad/param norm = 5.1998e-01, time/batch = 0.1590s	
1450/2700 (epoch 26.852), train_loss = 1.63936150, grad/param norm = 4.8759e-01, time/batch = 0.1514s	
1451/2700 (epoch 26.870), train_loss = 1.64292991, grad/param norm = 4.3237e-01, time/batch = 0.1630s	
1452/2700 (epoch 26.889), train_loss = 1.66653150, grad/param norm = 4.9036e-01, time/batch = 0.1594s	
1453/2700 (epoch 26.907), train_loss = 1.77873925, grad/param norm = 4.8617e-01, time/batch = 0.1626s	
1454/2700 (epoch 26.926), train_loss = 1.68962449, grad/param norm = 4.9383e-01, time/batch = 0.1459s	
1455/2700 (epoch 26.944), train_loss = 1.65212751, grad/param norm = 4.6856e-01, time/batch = 0.1526s	
1456/2700 (epoch 26.963), train_loss = 1.70151925, grad/param norm = 4.4801e-01, time/batch = 0.1583s	
1457/2700 (epoch 26.981), train_loss = 1.65872843, grad/param norm = 4.8052e-01, time/batch = 0.1485s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1458/2700 (epoch 27.000), train_loss = 1.71647912, grad/param norm = 4.5806e-01, time/batch = 0.1757s	
1459/2700 (epoch 27.019), train_loss = 1.69394639, grad/param norm = 4.7305e-01, time/batch = 0.1760s	
1460/2700 (epoch 27.037), train_loss = 1.71354332, grad/param norm = 4.8326e-01, time/batch = 0.1616s	
1461/2700 (epoch 27.056), train_loss = 1.63987274, grad/param norm = 5.1265e-01, time/batch = 0.1754s	
1462/2700 (epoch 27.074), train_loss = 1.63946625, grad/param norm = 4.8596e-01, time/batch = 0.1696s	
1463/2700 (epoch 27.093), train_loss = 1.63313317, grad/param norm = 4.6500e-01, time/batch = 0.1770s	
1464/2700 (epoch 27.111), train_loss = 1.61760739, grad/param norm = 5.3456e-01, time/batch = 0.1757s	
1465/2700 (epoch 27.130), train_loss = 1.65772460, grad/param norm = 5.4111e-01, time/batch = 0.1794s	
1466/2700 (epoch 27.148), train_loss = 1.61360578, grad/param norm = 4.7821e-01, time/batch = 0.1781s	
1467/2700 (epoch 27.167), train_loss = 1.69541667, grad/param norm = 4.5475e-01, time/batch = 0.1695s	
1468/2700 (epoch 27.185), train_loss = 1.60941253, grad/param norm = 4.3765e-01, time/batch = 0.1749s	
1469/2700 (epoch 27.204), train_loss = 1.66828161, grad/param norm = 4.9697e-01, time/batch = 0.1594s	
1470/2700 (epoch 27.222), train_loss = 1.59847785, grad/param norm = 5.3567e-01, time/batch = 0.1562s	
1471/2700 (epoch 27.241), train_loss = 1.53942804, grad/param norm = 5.0736e-01, time/batch = 0.1457s	
1472/2700 (epoch 27.259), train_loss = 1.58959919, grad/param norm = 4.8687e-01, time/batch = 0.1700s	
1473/2700 (epoch 27.278), train_loss = 1.66931336, grad/param norm = 4.9460e-01, time/batch = 0.1781s	
1474/2700 (epoch 27.296), train_loss = 1.64221246, grad/param norm = 5.0464e-01, time/batch = 0.1770s	
1475/2700 (epoch 27.315), train_loss = 1.64757908, grad/param norm = 5.1598e-01, time/batch = 0.1719s	
1476/2700 (epoch 27.333), train_loss = 1.64934110, grad/param norm = 4.6528e-01, time/batch = 0.1676s	
1477/2700 (epoch 27.352), train_loss = 1.65593442, grad/param norm = 4.9832e-01, time/batch = 0.1576s	
1478/2700 (epoch 27.370), train_loss = 1.67595742, grad/param norm = 5.2312e-01, time/batch = 0.1538s	
1479/2700 (epoch 27.389), train_loss = 1.64422060, grad/param norm = 5.0998e-01, time/batch = 0.1494s	
1480/2700 (epoch 27.407), train_loss = 1.68477258, grad/param norm = 4.7422e-01, time/batch = 0.1362s	
1481/2700 (epoch 27.426), train_loss = 1.69027655, grad/param norm = 4.5643e-01, time/batch = 0.1670s	
1482/2700 (epoch 27.444), train_loss = 1.58952605, grad/param norm = 4.5999e-01, time/batch = 0.1288s	
1483/2700 (epoch 27.463), train_loss = 1.69030584, grad/param norm = 4.7281e-01, time/batch = 0.1437s	
1484/2700 (epoch 27.481), train_loss = 1.68636632, grad/param norm = 5.0108e-01, time/batch = 0.1603s	
1485/2700 (epoch 27.500), train_loss = 1.63258665, grad/param norm = 4.6133e-01, time/batch = 0.1590s	
1486/2700 (epoch 27.519), train_loss = 1.66907646, grad/param norm = 4.6734e-01, time/batch = 0.1635s	
1487/2700 (epoch 27.537), train_loss = 1.65568292, grad/param norm = 4.6465e-01, time/batch = 0.1592s	
1488/2700 (epoch 27.556), train_loss = 1.59619476, grad/param norm = 4.6265e-01, time/batch = 0.1355s	
1489/2700 (epoch 27.574), train_loss = 1.60350815, grad/param norm = 5.1897e-01, time/batch = 0.1606s	
1490/2700 (epoch 27.593), train_loss = 1.63617542, grad/param norm = 5.2604e-01, time/batch = 0.1685s	
1491/2700 (epoch 27.611), train_loss = 1.53062253, grad/param norm = 4.6338e-01, time/batch = 0.1597s	
1492/2700 (epoch 27.630), train_loss = 1.58962622, grad/param norm = 4.6133e-01, time/batch = 0.1701s	
1493/2700 (epoch 27.648), train_loss = 1.60931889, grad/param norm = 4.6459e-01, time/batch = 0.1642s	
1494/2700 (epoch 27.667), train_loss = 1.58797688, grad/param norm = 4.6269e-01, time/batch = 0.1757s	
1495/2700 (epoch 27.685), train_loss = 1.62056685, grad/param norm = 5.1755e-01, time/batch = 0.1738s	
1496/2700 (epoch 27.704), train_loss = 1.64184578, grad/param norm = 5.1478e-01, time/batch = 0.1712s	
1497/2700 (epoch 27.722), train_loss = 1.61194798, grad/param norm = 4.4336e-01, time/batch = 0.1654s	
1498/2700 (epoch 27.741), train_loss = 1.65572779, grad/param norm = 4.5215e-01, time/batch = 0.1605s	
1499/2700 (epoch 27.759), train_loss = 1.64235917, grad/param norm = 5.1168e-01, time/batch = 0.1632s	
1500/2700 (epoch 27.778), train_loss = 1.67416206, grad/param norm = 4.7686e-01, time/batch = 0.1602s	
1501/2700 (epoch 27.796), train_loss = 1.63885143, grad/param norm = 5.3524e-01, time/batch = 0.1794s	
1502/2700 (epoch 27.815), train_loss = 1.68281823, grad/param norm = 5.4226e-01, time/batch = 0.1792s	
1503/2700 (epoch 27.833), train_loss = 1.62456238, grad/param norm = 5.1264e-01, time/batch = 0.1690s	
1504/2700 (epoch 27.852), train_loss = 1.62853544, grad/param norm = 4.8772e-01, time/batch = 0.1463s	
1505/2700 (epoch 27.870), train_loss = 1.63268855, grad/param norm = 4.3837e-01, time/batch = 0.1713s	
1506/2700 (epoch 27.889), train_loss = 1.65687776, grad/param norm = 4.8651e-01, time/batch = 0.1770s	
1507/2700 (epoch 27.907), train_loss = 1.76863666, grad/param norm = 4.8211e-01, time/batch = 0.1758s	
1508/2700 (epoch 27.926), train_loss = 1.67883459, grad/param norm = 4.9543e-01, time/batch = 0.1731s	
1509/2700 (epoch 27.944), train_loss = 1.64263603, grad/param norm = 4.6857e-01, time/batch = 0.1686s	
1510/2700 (epoch 27.963), train_loss = 1.69115244, grad/param norm = 4.5122e-01, time/batch = 0.1639s	
1511/2700 (epoch 27.981), train_loss = 1.64868229, grad/param norm = 4.8891e-01, time/batch = 0.1756s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1512/2700 (epoch 28.000), train_loss = 1.70717414, grad/param norm = 4.5948e-01, time/batch = 0.1745s	
1513/2700 (epoch 28.019), train_loss = 1.68583200, grad/param norm = 4.7616e-01, time/batch = 0.1692s	
1514/2700 (epoch 28.037), train_loss = 1.70352512, grad/param norm = 4.8619e-01, time/batch = 0.1684s	
1515/2700 (epoch 28.056), train_loss = 1.62932090, grad/param norm = 5.0000e-01, time/batch = 0.1795s	
1516/2700 (epoch 28.074), train_loss = 1.63020103, grad/param norm = 4.7930e-01, time/batch = 0.1797s	
1517/2700 (epoch 28.093), train_loss = 1.62259308, grad/param norm = 4.7658e-01, time/batch = 0.1801s	
1518/2700 (epoch 28.111), train_loss = 1.60806389, grad/param norm = 5.4944e-01, time/batch = 0.1796s	
1519/2700 (epoch 28.130), train_loss = 1.64792040, grad/param norm = 5.4616e-01, time/batch = 0.1552s	
1520/2700 (epoch 28.148), train_loss = 1.60490454, grad/param norm = 4.7372e-01, time/batch = 0.1704s	
1521/2700 (epoch 28.167), train_loss = 1.68635886, grad/param norm = 4.5853e-01, time/batch = 0.1616s	
1522/2700 (epoch 28.185), train_loss = 1.60022435, grad/param norm = 4.4449e-01, time/batch = 0.1655s	
1523/2700 (epoch 28.204), train_loss = 1.65988413, grad/param norm = 5.1185e-01, time/batch = 0.1506s	
1524/2700 (epoch 28.222), train_loss = 1.59087753, grad/param norm = 5.4201e-01, time/batch = 0.1565s	
1525/2700 (epoch 28.241), train_loss = 1.52999928, grad/param norm = 5.0631e-01, time/batch = 0.1356s	
1526/2700 (epoch 28.259), train_loss = 1.58059935, grad/param norm = 4.8623e-01, time/batch = 0.1693s	
1527/2700 (epoch 28.278), train_loss = 1.66009924, grad/param norm = 5.0523e-01, time/batch = 0.1625s	
1528/2700 (epoch 28.296), train_loss = 1.63355849, grad/param norm = 5.0784e-01, time/batch = 0.1601s	
1529/2700 (epoch 28.315), train_loss = 1.63635125, grad/param norm = 5.1362e-01, time/batch = 0.1544s	
1530/2700 (epoch 28.333), train_loss = 1.63926272, grad/param norm = 4.7042e-01, time/batch = 0.1587s	
1531/2700 (epoch 28.352), train_loss = 1.64687628, grad/param norm = 5.0922e-01, time/batch = 0.1793s	
1532/2700 (epoch 28.370), train_loss = 1.66509293, grad/param norm = 5.2419e-01, time/batch = 0.1777s	
1533/2700 (epoch 28.389), train_loss = 1.63378367, grad/param norm = 5.0490e-01, time/batch = 0.1791s	
1534/2700 (epoch 28.407), train_loss = 1.67492569, grad/param norm = 4.6773e-01, time/batch = 0.1586s	
1535/2700 (epoch 28.426), train_loss = 1.68086636, grad/param norm = 4.6798e-01, time/batch = 0.1673s	
1536/2700 (epoch 28.444), train_loss = 1.57974848, grad/param norm = 4.5854e-01, time/batch = 0.1387s	
1537/2700 (epoch 28.463), train_loss = 1.68091802, grad/param norm = 4.7032e-01, time/batch = 0.1586s	
1538/2700 (epoch 28.481), train_loss = 1.67606431, grad/param norm = 5.0010e-01, time/batch = 0.1626s	
1539/2700 (epoch 28.500), train_loss = 1.62113391, grad/param norm = 4.6087e-01, time/batch = 0.1637s	
1540/2700 (epoch 28.519), train_loss = 1.66049879, grad/param norm = 4.7384e-01, time/batch = 0.1491s	
1541/2700 (epoch 28.537), train_loss = 1.64527917, grad/param norm = 4.6653e-01, time/batch = 0.1549s	
1542/2700 (epoch 28.556), train_loss = 1.58569114, grad/param norm = 4.6203e-01, time/batch = 0.1607s	
1543/2700 (epoch 28.574), train_loss = 1.59274637, grad/param norm = 5.1240e-01, time/batch = 0.1681s	
1544/2700 (epoch 28.593), train_loss = 1.62725127, grad/param norm = 5.1227e-01, time/batch = 0.1599s	
1545/2700 (epoch 28.611), train_loss = 1.52186160, grad/param norm = 4.5387e-01, time/batch = 0.1775s	
1546/2700 (epoch 28.630), train_loss = 1.58073894, grad/param norm = 4.6494e-01, time/batch = 0.1775s	
1547/2700 (epoch 28.648), train_loss = 1.60076526, grad/param norm = 4.6543e-01, time/batch = 0.1496s	
1548/2700 (epoch 28.667), train_loss = 1.57850582, grad/param norm = 4.6335e-01, time/batch = 0.1736s	
1549/2700 (epoch 28.685), train_loss = 1.61220707, grad/param norm = 5.2053e-01, time/batch = 0.1771s	
1550/2700 (epoch 28.704), train_loss = 1.63294392, grad/param norm = 5.1737e-01, time/batch = 0.1678s	
1551/2700 (epoch 28.722), train_loss = 1.60257361, grad/param norm = 4.4477e-01, time/batch = 0.1570s	
1552/2700 (epoch 28.741), train_loss = 1.64588627, grad/param norm = 4.5223e-01, time/batch = 0.1640s	
1553/2700 (epoch 28.759), train_loss = 1.63125440, grad/param norm = 5.1384e-01, time/batch = 0.1621s	
1554/2700 (epoch 28.778), train_loss = 1.66462590, grad/param norm = 4.7701e-01, time/batch = 0.1519s	
1555/2700 (epoch 28.796), train_loss = 1.62834140, grad/param norm = 5.3210e-01, time/batch = 0.1609s	
1556/2700 (epoch 28.815), train_loss = 1.67288627, grad/param norm = 5.3162e-01, time/batch = 0.1573s	
1557/2700 (epoch 28.833), train_loss = 1.61474782, grad/param norm = 5.1102e-01, time/batch = 0.1660s	
1558/2700 (epoch 28.852), train_loss = 1.61837849, grad/param norm = 4.8837e-01, time/batch = 0.1396s	
1559/2700 (epoch 28.870), train_loss = 1.62297454, grad/param norm = 4.4222e-01, time/batch = 0.1615s	
1560/2700 (epoch 28.889), train_loss = 1.64747877, grad/param norm = 4.8205e-01, time/batch = 0.1727s	
1561/2700 (epoch 28.907), train_loss = 1.75906881, grad/param norm = 4.8072e-01, time/batch = 0.1413s	
1562/2700 (epoch 28.926), train_loss = 1.66872179, grad/param norm = 5.0072e-01, time/batch = 0.1734s	
1563/2700 (epoch 28.944), train_loss = 1.63387714, grad/param norm = 4.7238e-01, time/batch = 0.1773s	
1564/2700 (epoch 28.963), train_loss = 1.68139276, grad/param norm = 4.5830e-01, time/batch = 0.1740s	
1565/2700 (epoch 28.981), train_loss = 1.63903983, grad/param norm = 4.9472e-01, time/batch = 0.1675s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
1566/2700 (epoch 29.000), train_loss = 1.69840432, grad/param norm = 4.5790e-01, time/batch = 0.1634s	
1567/2700 (epoch 29.019), train_loss = 1.67820078, grad/param norm = 4.8228e-01, time/batch = 0.1583s	
1568/2700 (epoch 29.037), train_loss = 1.69406920, grad/param norm = 4.9456e-01, time/batch = 0.1619s	
1569/2700 (epoch 29.056), train_loss = 1.61926903, grad/param norm = 4.8691e-01, time/batch = 0.1334s	
1570/2700 (epoch 29.074), train_loss = 1.62159423, grad/param norm = 4.7635e-01, time/batch = 0.1229s	
1571/2700 (epoch 29.093), train_loss = 1.61322056, grad/param norm = 4.9947e-01, time/batch = 0.1342s	
1572/2700 (epoch 29.111), train_loss = 1.59941083, grad/param norm = 5.6900e-01, time/batch = 0.1620s	
1573/2700 (epoch 29.130), train_loss = 1.63855007, grad/param norm = 5.4507e-01, time/batch = 0.1658s	
1574/2700 (epoch 29.148), train_loss = 1.59652875, grad/param norm = 4.6549e-01, time/batch = 0.1622s	
1575/2700 (epoch 29.167), train_loss = 1.67787569, grad/param norm = 4.6478e-01, time/batch = 0.1742s	
1576/2700 (epoch 29.185), train_loss = 1.59170183, grad/param norm = 4.5462e-01, time/batch = 0.1767s	
1577/2700 (epoch 29.204), train_loss = 1.65177510, grad/param norm = 5.2592e-01, time/batch = 0.1727s	
1578/2700 (epoch 29.222), train_loss = 1.58341537, grad/param norm = 5.4133e-01, time/batch = 0.1626s	
1579/2700 (epoch 29.241), train_loss = 1.52088593, grad/param norm = 4.9893e-01, time/batch = 0.1465s	
1580/2700 (epoch 29.259), train_loss = 1.57198877, grad/param norm = 4.8678e-01, time/batch = 0.1520s	
1581/2700 (epoch 29.278), train_loss = 1.65170197, grad/param norm = 5.2026e-01, time/batch = 0.1513s	
1582/2700 (epoch 29.296), train_loss = 1.62540575, grad/param norm = 5.1193e-01, time/batch = 0.1431s	
1583/2700 (epoch 29.315), train_loss = 1.62593493, grad/param norm = 5.1493e-01, time/batch = 0.1581s	
1584/2700 (epoch 29.333), train_loss = 1.62985104, grad/param norm = 4.7996e-01, time/batch = 0.1637s	
1585/2700 (epoch 29.352), train_loss = 1.63829509, grad/param norm = 5.2030e-01, time/batch = 0.1527s	
1586/2700 (epoch 29.370), train_loss = 1.65447050, grad/param norm = 5.2057e-01, time/batch = 0.1436s	
1587/2700 (epoch 29.389), train_loss = 1.62359375, grad/param norm = 4.9542e-01, time/batch = 0.1358s	
1588/2700 (epoch 29.407), train_loss = 1.66554010, grad/param norm = 4.6188e-01, time/batch = 0.1464s	
1589/2700 (epoch 29.426), train_loss = 1.67223324, grad/param norm = 4.8331e-01, time/batch = 0.1612s	
1590/2700 (epoch 29.444), train_loss = 1.57055963, grad/param norm = 4.5823e-01, time/batch = 0.1665s	
1591/2700 (epoch 29.463), train_loss = 1.67204685, grad/param norm = 4.6927e-01, time/batch = 0.1649s	
1592/2700 (epoch 29.481), train_loss = 1.66644443, grad/param norm = 4.9976e-01, time/batch = 0.1711s	
1593/2700 (epoch 29.500), train_loss = 1.61036349, grad/param norm = 4.6145e-01, time/batch = 0.1485s	
1594/2700 (epoch 29.519), train_loss = 1.65237990, grad/param norm = 4.7845e-01, time/batch = 0.1504s	
1595/2700 (epoch 29.537), train_loss = 1.63531986, grad/param norm = 4.6838e-01, time/batch = 0.1217s	
1596/2700 (epoch 29.556), train_loss = 1.57574961, grad/param norm = 4.6218e-01, time/batch = 0.1536s	
1597/2700 (epoch 29.574), train_loss = 1.58244371, grad/param norm = 5.0513e-01, time/batch = 0.1498s	
1598/2700 (epoch 29.593), train_loss = 1.61865587, grad/param norm = 5.0003e-01, time/batch = 0.1610s	
1599/2700 (epoch 29.611), train_loss = 1.51386938, grad/param norm = 4.4790e-01, time/batch = 0.1699s	
1600/2700 (epoch 29.630), train_loss = 1.57232648, grad/param norm = 4.7000e-01, time/batch = 0.1736s	
1601/2700 (epoch 29.648), train_loss = 1.59271996, grad/param norm = 4.6668e-01, time/batch = 0.1645s	
1602/2700 (epoch 29.667), train_loss = 1.56942046, grad/param norm = 4.6552e-01, time/batch = 0.1713s	
1603/2700 (epoch 29.685), train_loss = 1.60431802, grad/param norm = 5.2280e-01, time/batch = 0.1787s	
1604/2700 (epoch 29.704), train_loss = 1.62447148, grad/param norm = 5.1876e-01, time/batch = 0.1440s	
1605/2700 (epoch 29.722), train_loss = 1.59354629, grad/param norm = 4.4504e-01, time/batch = 0.1780s	
1606/2700 (epoch 29.741), train_loss = 1.63654169, grad/param norm = 4.5207e-01, time/batch = 0.1801s	
1607/2700 (epoch 29.759), train_loss = 1.62057297, grad/param norm = 5.1159e-01, time/batch = 0.1693s	
1608/2700 (epoch 29.778), train_loss = 1.65531818, grad/param norm = 4.7092e-01, time/batch = 0.1633s	
1609/2700 (epoch 29.796), train_loss = 1.61820835, grad/param norm = 5.2212e-01, time/batch = 0.1571s	
1610/2700 (epoch 29.815), train_loss = 1.66337370, grad/param norm = 5.1582e-01, time/batch = 0.1575s	
1611/2700 (epoch 29.833), train_loss = 1.60548530, grad/param norm = 5.1347e-01, time/batch = 0.1643s	
1612/2700 (epoch 29.852), train_loss = 1.60901132, grad/param norm = 4.9546e-01, time/batch = 0.1525s	
1613/2700 (epoch 29.870), train_loss = 1.61389388, grad/param norm = 4.5186e-01, time/batch = 0.1627s	
1614/2700 (epoch 29.889), train_loss = 1.63873279, grad/param norm = 4.7940e-01, time/batch = 0.1770s	
1615/2700 (epoch 29.907), train_loss = 1.74996596, grad/param norm = 4.7859e-01, time/batch = 0.1388s	
1616/2700 (epoch 29.926), train_loss = 1.65904966, grad/param norm = 5.0399e-01, time/batch = 0.1486s	
1617/2700 (epoch 29.944), train_loss = 1.62548040, grad/param norm = 4.7327e-01, time/batch = 0.1542s	
1618/2700 (epoch 29.963), train_loss = 1.67188721, grad/param norm = 4.6230e-01, time/batch = 0.1527s	
1619/2700 (epoch 29.981), train_loss = 1.62977597, grad/param norm = 4.9951e-01, time/batch = 0.1401s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
1620/2700 (epoch 30.000), train_loss = 1.69022008, grad/param norm = 4.5873e-01, time/batch = 0.1421s	
1621/2700 (epoch 30.019), train_loss = 1.67074341, grad/param norm = 4.8570e-01, time/batch = 0.1336s	
1622/2700 (epoch 30.037), train_loss = 1.68484733, grad/param norm = 4.9620e-01, time/batch = 0.1450s	
1623/2700 (epoch 30.056), train_loss = 1.60996771, grad/param norm = 4.8396e-01, time/batch = 0.1611s	
1624/2700 (epoch 30.074), train_loss = 1.61337793, grad/param norm = 4.7691e-01, time/batch = 0.1622s	
1625/2700 (epoch 30.093), train_loss = 1.60355748, grad/param norm = 4.9966e-01, time/batch = 0.1671s	
1626/2700 (epoch 30.111), train_loss = 1.58980188, grad/param norm = 5.4847e-01, time/batch = 0.1317s	
1627/2700 (epoch 30.130), train_loss = 1.62849967, grad/param norm = 5.2510e-01, time/batch = 0.1389s	
1628/2700 (epoch 30.148), train_loss = 1.58873540, grad/param norm = 4.6110e-01, time/batch = 0.1482s	
1629/2700 (epoch 30.167), train_loss = 1.66996139, grad/param norm = 4.7265e-01, time/batch = 0.1643s	
1630/2700 (epoch 30.185), train_loss = 1.58376640, grad/param norm = 4.6775e-01, time/batch = 0.1740s	
1631/2700 (epoch 30.204), train_loss = 1.64439125, grad/param norm = 5.4738e-01, time/batch = 0.1537s	
1632/2700 (epoch 30.222), train_loss = 1.57671125, grad/param norm = 5.4893e-01, time/batch = 0.1701s	
1633/2700 (epoch 30.241), train_loss = 1.51268945, grad/param norm = 5.0049e-01, time/batch = 0.1676s	
1634/2700 (epoch 30.259), train_loss = 1.56401580, grad/param norm = 4.8972e-01, time/batch = 0.1698s	
1635/2700 (epoch 30.278), train_loss = 1.64348146, grad/param norm = 5.2367e-01, time/batch = 0.1726s	
1636/2700 (epoch 30.296), train_loss = 1.61739449, grad/param norm = 5.0691e-01, time/batch = 0.1676s	
1637/2700 (epoch 30.315), train_loss = 1.61568038, grad/param norm = 5.0628e-01, time/batch = 0.1558s	
1638/2700 (epoch 30.333), train_loss = 1.62015201, grad/param norm = 4.7479e-01, time/batch = 0.1356s	
1639/2700 (epoch 30.352), train_loss = 1.62916795, grad/param norm = 5.2069e-01, time/batch = 0.1252s	
1640/2700 (epoch 30.370), train_loss = 1.64395562, grad/param norm = 5.1146e-01, time/batch = 0.1600s	
1641/2700 (epoch 30.389), train_loss = 1.61411076, grad/param norm = 4.8764e-01, time/batch = 0.1567s	
1642/2700 (epoch 30.407), train_loss = 1.65684048, grad/param norm = 4.6135e-01, time/batch = 0.1700s	
1643/2700 (epoch 30.426), train_loss = 1.66412563, grad/param norm = 4.9355e-01, time/batch = 0.1747s	
1644/2700 (epoch 30.444), train_loss = 1.56185793, grad/param norm = 4.5870e-01, time/batch = 0.1776s	
1645/2700 (epoch 30.463), train_loss = 1.66372358, grad/param norm = 4.7153e-01, time/batch = 0.1767s	
1646/2700 (epoch 30.481), train_loss = 1.65744491, grad/param norm = 4.9936e-01, time/batch = 0.1770s	
1647/2700 (epoch 30.500), train_loss = 1.60023828, grad/param norm = 4.6230e-01, time/batch = 0.1607s	
1648/2700 (epoch 30.519), train_loss = 1.64469138, grad/param norm = 4.8115e-01, time/batch = 0.1494s	
1649/2700 (epoch 30.537), train_loss = 1.62573106, grad/param norm = 4.7034e-01, time/batch = 0.1535s	
1650/2700 (epoch 30.556), train_loss = 1.56639152, grad/param norm = 4.6314e-01, time/batch = 0.1340s	
1651/2700 (epoch 30.574), train_loss = 1.57270663, grad/param norm = 4.9898e-01, time/batch = 0.1588s	
1652/2700 (epoch 30.593), train_loss = 1.61053886, grad/param norm = 4.9267e-01, time/batch = 0.1539s	
1653/2700 (epoch 30.611), train_loss = 1.50662292, grad/param norm = 4.4620e-01, time/batch = 0.1489s	
1654/2700 (epoch 30.630), train_loss = 1.56424305, grad/param norm = 4.7396e-01, time/batch = 0.1531s	
1655/2700 (epoch 30.648), train_loss = 1.58512093, grad/param norm = 4.6744e-01, time/batch = 0.1625s	
1656/2700 (epoch 30.667), train_loss = 1.56070840, grad/param norm = 4.6827e-01, time/batch = 0.1580s	
1657/2700 (epoch 30.685), train_loss = 1.59680302, grad/param norm = 5.2427e-01, time/batch = 0.1537s	
1658/2700 (epoch 30.704), train_loss = 1.61643263, grad/param norm = 5.1926e-01, time/batch = 0.1550s	
1659/2700 (epoch 30.722), train_loss = 1.58495333, grad/param norm = 4.4504e-01, time/batch = 0.1381s	
1660/2700 (epoch 30.741), train_loss = 1.62770184, grad/param norm = 4.5233e-01, time/batch = 0.1199s	
1661/2700 (epoch 30.759), train_loss = 1.61046718, grad/param norm = 5.0891e-01, time/batch = 0.1786s	
1662/2700 (epoch 30.778), train_loss = 1.64650402, grad/param norm = 4.6689e-01, time/batch = 0.1777s	
1663/2700 (epoch 30.796), train_loss = 1.60874404, grad/param norm = 5.1644e-01, time/batch = 0.1728s	
1664/2700 (epoch 30.815), train_loss = 1.65452425, grad/param norm = 5.0706e-01, time/batch = 0.1549s	
1665/2700 (epoch 30.833), train_loss = 1.59669457, grad/param norm = 5.1719e-01, time/batch = 0.1406s	
1666/2700 (epoch 30.852), train_loss = 1.60021015, grad/param norm = 5.0162e-01, time/batch = 0.1470s	
1667/2700 (epoch 30.870), train_loss = 1.60522576, grad/param norm = 4.5936e-01, time/batch = 0.1612s	
1668/2700 (epoch 30.889), train_loss = 1.63030880, grad/param norm = 4.7709e-01, time/batch = 0.1507s	
1669/2700 (epoch 30.907), train_loss = 1.74139348, grad/param norm = 4.7888e-01, time/batch = 0.1739s	
1670/2700 (epoch 30.926), train_loss = 1.64994005, grad/param norm = 5.0867e-01, time/batch = 0.1635s	
1671/2700 (epoch 30.944), train_loss = 1.61760484, grad/param norm = 4.7578e-01, time/batch = 0.1653s	
1672/2700 (epoch 30.963), train_loss = 1.66285735, grad/param norm = 4.6722e-01, time/batch = 0.1656s	
1673/2700 (epoch 30.981), train_loss = 1.62081123, grad/param norm = 5.0278e-01, time/batch = 0.1791s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
1674/2700 (epoch 31.000), train_loss = 1.68250696, grad/param norm = 4.5885e-01, time/batch = 0.1700s	
1675/2700 (epoch 31.019), train_loss = 1.66364103, grad/param norm = 4.9130e-01, time/batch = 0.1723s	
1676/2700 (epoch 31.037), train_loss = 1.67622389, grad/param norm = 5.0150e-01, time/batch = 0.1686s	
1677/2700 (epoch 31.056), train_loss = 1.60120741, grad/param norm = 4.8105e-01, time/batch = 0.1602s	
1678/2700 (epoch 31.074), train_loss = 1.60568475, grad/param norm = 4.7916e-01, time/batch = 0.1285s	
1679/2700 (epoch 31.093), train_loss = 1.59479825, grad/param norm = 5.0600e-01, time/batch = 0.1401s	
1680/2700 (epoch 31.111), train_loss = 1.58112763, grad/param norm = 5.3968e-01, time/batch = 0.1441s	
1681/2700 (epoch 31.130), train_loss = 1.61941428, grad/param norm = 5.1361e-01, time/batch = 0.1314s	
1682/2700 (epoch 31.148), train_loss = 1.58133373, grad/param norm = 4.5743e-01, time/batch = 0.1716s	
1683/2700 (epoch 31.167), train_loss = 1.66249640, grad/param norm = 4.8077e-01, time/batch = 0.1724s	
1684/2700 (epoch 31.185), train_loss = 1.57620750, grad/param norm = 4.7839e-01, time/batch = 0.1754s	
1685/2700 (epoch 31.204), train_loss = 1.63684218, grad/param norm = 5.5751e-01, time/batch = 0.1668s	
1686/2700 (epoch 31.222), train_loss = 1.56979744, grad/param norm = 5.4513e-01, time/batch = 0.1516s	
1687/2700 (epoch 31.241), train_loss = 1.50470490, grad/param norm = 4.9758e-01, time/batch = 0.1416s	
1688/2700 (epoch 31.259), train_loss = 1.55638591, grad/param norm = 4.9350e-01, time/batch = 0.1510s	
1689/2700 (epoch 31.278), train_loss = 1.63591052, grad/param norm = 5.3076e-01, time/batch = 0.1576s	
1690/2700 (epoch 31.296), train_loss = 1.60989673, grad/param norm = 5.0567e-01, time/batch = 0.1799s	
1691/2700 (epoch 31.315), train_loss = 1.60624329, grad/param norm = 5.0409e-01, time/batch = 0.1510s	
1692/2700 (epoch 31.333), train_loss = 1.61118569, grad/param norm = 4.7699e-01, time/batch = 0.1559s	
1693/2700 (epoch 31.352), train_loss = 1.62077342, grad/param norm = 5.2505e-01, time/batch = 0.1746s	
1694/2700 (epoch 31.370), train_loss = 1.63405704, grad/param norm = 5.0768e-01, time/batch = 0.1728s	
1695/2700 (epoch 31.389), train_loss = 1.60533062, grad/param norm = 4.8625e-01, time/batch = 0.1769s	
1696/2700 (epoch 31.407), train_loss = 1.64848011, grad/param norm = 4.6331e-01, time/batch = 0.1756s	
1697/2700 (epoch 31.426), train_loss = 1.65631650, grad/param norm = 4.9799e-01, time/batch = 0.1636s	
1698/2700 (epoch 31.444), train_loss = 1.55357071, grad/param norm = 4.5897e-01, time/batch = 0.1502s	
1699/2700 (epoch 31.463), train_loss = 1.65590426, grad/param norm = 4.7558e-01, time/batch = 0.1469s	
1700/2700 (epoch 31.481), train_loss = 1.64895970, grad/param norm = 4.9843e-01, time/batch = 0.1654s	
1701/2700 (epoch 31.500), train_loss = 1.59065065, grad/param norm = 4.6322e-01, time/batch = 0.1582s	
1702/2700 (epoch 31.519), train_loss = 1.63738419, grad/param norm = 4.8383e-01, time/batch = 0.1555s	
1703/2700 (epoch 31.537), train_loss = 1.61660784, grad/param norm = 4.7269e-01, time/batch = 0.1431s	
1704/2700 (epoch 31.556), train_loss = 1.55752372, grad/param norm = 4.6476e-01, time/batch = 0.1569s	
1705/2700 (epoch 31.574), train_loss = 1.56343466, grad/param norm = 4.9397e-01, time/batch = 0.1530s	
1706/2700 (epoch 31.593), train_loss = 1.60274966, grad/param norm = 4.8715e-01, time/batch = 0.1506s	
1707/2700 (epoch 31.611), train_loss = 1.49990079, grad/param norm = 4.4610e-01, time/batch = 0.1335s	
1708/2700 (epoch 31.630), train_loss = 1.55649751, grad/param norm = 4.7778e-01, time/batch = 0.1519s	
1709/2700 (epoch 31.648), train_loss = 1.57788574, grad/param norm = 4.6735e-01, time/batch = 0.1646s	
1710/2700 (epoch 31.667), train_loss = 1.55232602, grad/param norm = 4.7104e-01, time/batch = 0.1611s	
1711/2700 (epoch 31.685), train_loss = 1.58961563, grad/param norm = 5.2509e-01, time/batch = 0.1659s	
1712/2700 (epoch 31.704), train_loss = 1.60879642, grad/param norm = 5.1984e-01, time/batch = 0.1640s	
1713/2700 (epoch 31.722), train_loss = 1.57677010, grad/param norm = 4.4482e-01, time/batch = 0.1718s	
1714/2700 (epoch 31.741), train_loss = 1.61926651, grad/param norm = 4.5309e-01, time/batch = 0.1577s	
1715/2700 (epoch 31.759), train_loss = 1.60086371, grad/param norm = 5.0607e-01, time/batch = 0.1774s	
1716/2700 (epoch 31.778), train_loss = 1.63810858, grad/param norm = 4.6389e-01, time/batch = 0.1772s	
1717/2700 (epoch 31.796), train_loss = 1.59985976, grad/param norm = 5.1273e-01, time/batch = 0.1724s	
1718/2700 (epoch 31.815), train_loss = 1.64612452, grad/param norm = 5.0054e-01, time/batch = 0.1544s	
1719/2700 (epoch 31.833), train_loss = 1.58830556, grad/param norm = 5.2189e-01, time/batch = 0.1538s	
1720/2700 (epoch 31.852), train_loss = 1.59189456, grad/param norm = 5.0850e-01, time/batch = 0.1524s	
1721/2700 (epoch 31.870), train_loss = 1.59694463, grad/param norm = 4.6571e-01, time/batch = 0.1600s	
1722/2700 (epoch 31.889), train_loss = 1.62216794, grad/param norm = 4.7476e-01, time/batch = 0.1676s	
1723/2700 (epoch 31.907), train_loss = 1.73327321, grad/param norm = 4.8078e-01, time/batch = 0.1575s	
1724/2700 (epoch 31.926), train_loss = 1.64134255, grad/param norm = 5.1369e-01, time/batch = 0.1596s	
1725/2700 (epoch 31.944), train_loss = 1.61006433, grad/param norm = 4.7794e-01, time/batch = 0.1351s	
1726/2700 (epoch 31.963), train_loss = 1.65414440, grad/param norm = 4.7043e-01, time/batch = 0.1369s	
1727/2700 (epoch 31.981), train_loss = 1.61212157, grad/param norm = 5.0473e-01, time/batch = 0.1333s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
1728/2700 (epoch 32.000), train_loss = 1.67520066, grad/param norm = 4.5950e-01, time/batch = 0.1508s	
1729/2700 (epoch 32.019), train_loss = 1.65672743, grad/param norm = 4.9587e-01, time/batch = 0.1640s	
1730/2700 (epoch 32.037), train_loss = 1.66791081, grad/param norm = 5.0432e-01, time/batch = 0.1727s	
1731/2700 (epoch 32.056), train_loss = 1.59296078, grad/param norm = 4.8006e-01, time/batch = 0.1477s	
1732/2700 (epoch 32.074), train_loss = 1.59830237, grad/param norm = 4.8117e-01, time/batch = 0.1619s	
1733/2700 (epoch 32.093), train_loss = 1.58637742, grad/param norm = 5.0716e-01, time/batch = 0.1601s	
1734/2700 (epoch 32.111), train_loss = 1.57274187, grad/param norm = 5.2679e-01, time/batch = 0.1778s	
1735/2700 (epoch 32.130), train_loss = 1.61074530, grad/param norm = 5.0251e-01, time/batch = 0.1785s	
1736/2700 (epoch 32.148), train_loss = 1.57435604, grad/param norm = 4.5576e-01, time/batch = 0.1655s	
1737/2700 (epoch 32.167), train_loss = 1.65547635, grad/param norm = 4.8956e-01, time/batch = 0.1606s	
1738/2700 (epoch 32.185), train_loss = 1.56904942, grad/param norm = 4.8852e-01, time/batch = 0.1521s	
1739/2700 (epoch 32.204), train_loss = 1.62952997, grad/param norm = 5.6531e-01, time/batch = 0.1566s	
1740/2700 (epoch 32.222), train_loss = 1.56311721, grad/param norm = 5.4081e-01, time/batch = 0.1667s	
1741/2700 (epoch 32.241), train_loss = 1.49724428, grad/param norm = 4.9689e-01, time/batch = 0.1502s	
1742/2700 (epoch 32.259), train_loss = 1.54908137, grad/param norm = 4.9736e-01, time/batch = 0.1596s	
1743/2700 (epoch 32.278), train_loss = 1.62866834, grad/param norm = 5.3444e-01, time/batch = 0.1563s	
1744/2700 (epoch 32.296), train_loss = 1.60271379, grad/param norm = 5.0254e-01, time/batch = 0.1583s	
1745/2700 (epoch 32.315), train_loss = 1.59717403, grad/param norm = 4.9963e-01, time/batch = 0.1635s	
1746/2700 (epoch 32.333), train_loss = 1.60237592, grad/param norm = 4.7538e-01, time/batch = 0.1722s	
1747/2700 (epoch 32.352), train_loss = 1.61251919, grad/param norm = 5.2671e-01, time/batch = 0.1620s	
1748/2700 (epoch 32.370), train_loss = 1.62449142, grad/param norm = 5.0342e-01, time/batch = 0.1598s	
1749/2700 (epoch 32.389), train_loss = 1.59712354, grad/param norm = 4.8638e-01, time/batch = 0.1483s	
1750/2700 (epoch 32.407), train_loss = 1.64047514, grad/param norm = 4.6589e-01, time/batch = 0.1598s	
1751/2700 (epoch 32.426), train_loss = 1.64889838, grad/param norm = 5.0123e-01, time/batch = 0.1403s	
1752/2700 (epoch 32.444), train_loss = 1.54571273, grad/param norm = 4.5980e-01, time/batch = 0.1472s	
1753/2700 (epoch 32.463), train_loss = 1.64845412, grad/param norm = 4.7960e-01, time/batch = 0.1703s	
1754/2700 (epoch 32.481), train_loss = 1.64092700, grad/param norm = 4.9786e-01, time/batch = 0.1521s	
1755/2700 (epoch 32.500), train_loss = 1.58161412, grad/param norm = 4.6480e-01, time/batch = 0.1598s	
1756/2700 (epoch 32.519), train_loss = 1.63044279, grad/param norm = 4.8630e-01, time/batch = 0.1630s	
1757/2700 (epoch 32.537), train_loss = 1.60794122, grad/param norm = 4.7531e-01, time/batch = 0.1639s	
1758/2700 (epoch 32.556), train_loss = 1.54914535, grad/param norm = 4.6639e-01, time/batch = 0.1540s	
1759/2700 (epoch 32.574), train_loss = 1.55473550, grad/param norm = 4.9182e-01, time/batch = 0.1463s	
1760/2700 (epoch 32.593), train_loss = 1.59533603, grad/param norm = 4.8474e-01, time/batch = 0.1364s	
1761/2700 (epoch 32.611), train_loss = 1.49365205, grad/param norm = 4.4736e-01, time/batch = 0.1421s	
1762/2700 (epoch 32.630), train_loss = 1.54898926, grad/param norm = 4.8027e-01, time/batch = 0.1480s	
1763/2700 (epoch 32.648), train_loss = 1.57101056, grad/param norm = 4.6667e-01, time/batch = 0.1551s	
1764/2700 (epoch 32.667), train_loss = 1.54429997, grad/param norm = 4.7410e-01, time/batch = 0.1693s	
1765/2700 (epoch 32.685), train_loss = 1.58274179, grad/param norm = 5.2540e-01, time/batch = 0.1771s	
1766/2700 (epoch 32.704), train_loss = 1.60157290, grad/param norm = 5.2078e-01, time/batch = 0.1764s	
1767/2700 (epoch 32.722), train_loss = 1.56901942, grad/param norm = 4.4479e-01, time/batch = 0.1759s	
1768/2700 (epoch 32.741), train_loss = 1.61122542, grad/param norm = 4.5443e-01, time/batch = 0.1752s	
1769/2700 (epoch 32.759), train_loss = 1.59176392, grad/param norm = 5.0396e-01, time/batch = 0.1609s	
1770/2700 (epoch 32.778), train_loss = 1.63015406, grad/param norm = 4.6295e-01, time/batch = 0.1651s	
1771/2700 (epoch 32.796), train_loss = 1.59150696, grad/param norm = 5.1199e-01, time/batch = 0.1730s	
1772/2700 (epoch 32.815), train_loss = 1.63814225, grad/param norm = 4.9737e-01, time/batch = 0.1757s	
1773/2700 (epoch 32.833), train_loss = 1.58024767, grad/param norm = 5.2452e-01, time/batch = 0.1679s	
1774/2700 (epoch 32.852), train_loss = 1.58388157, grad/param norm = 5.1102e-01, time/batch = 0.1665s	
1775/2700 (epoch 32.870), train_loss = 1.58892970, grad/param norm = 4.6723e-01, time/batch = 0.1682s	
1776/2700 (epoch 32.889), train_loss = 1.61429470, grad/param norm = 4.7267e-01, time/batch = 0.1635s	
1777/2700 (epoch 32.907), train_loss = 1.72562103, grad/param norm = 4.8522e-01, time/batch = 0.1480s	
1778/2700 (epoch 32.926), train_loss = 1.63324963, grad/param norm = 5.1932e-01, time/batch = 0.1556s	
1779/2700 (epoch 32.944), train_loss = 1.60283335, grad/param norm = 4.8027e-01, time/batch = 0.1691s	
1780/2700 (epoch 32.963), train_loss = 1.64578590, grad/param norm = 4.7290e-01, time/batch = 0.1444s	
1781/2700 (epoch 32.981), train_loss = 1.60371675, grad/param norm = 5.0625e-01, time/batch = 0.1792s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
1782/2700 (epoch 33.000), train_loss = 1.66826995, grad/param norm = 4.6040e-01, time/batch = 0.1781s	
1783/2700 (epoch 33.019), train_loss = 1.65009590, grad/param norm = 5.0082e-01, time/batch = 0.1734s	
1784/2700 (epoch 33.037), train_loss = 1.66003297, grad/param norm = 5.0701e-01, time/batch = 0.1609s	
1785/2700 (epoch 33.056), train_loss = 1.58508731, grad/param norm = 4.8002e-01, time/batch = 0.1614s	
1786/2700 (epoch 33.074), train_loss = 1.59125920, grad/param norm = 4.8358e-01, time/batch = 0.1620s	
1787/2700 (epoch 33.093), train_loss = 1.57843478, grad/param norm = 5.0835e-01, time/batch = 0.1680s	
1788/2700 (epoch 33.111), train_loss = 1.56492429, grad/param norm = 5.1695e-01, time/batch = 0.1687s	
1789/2700 (epoch 33.130), train_loss = 1.60266077, grad/param norm = 4.9536e-01, time/batch = 0.1735s	
1790/2700 (epoch 33.148), train_loss = 1.56767599, grad/param norm = 4.5523e-01, time/batch = 0.1687s	
1791/2700 (epoch 33.167), train_loss = 1.64877369, grad/param norm = 4.9705e-01, time/batch = 0.1425s	
1792/2700 (epoch 33.185), train_loss = 1.56209517, grad/param norm = 4.9482e-01, time/batch = 0.1487s	
1793/2700 (epoch 33.204), train_loss = 1.62227822, grad/param norm = 5.6618e-01, time/batch = 0.1650s	
1794/2700 (epoch 33.222), train_loss = 1.55659091, grad/param norm = 5.3426e-01, time/batch = 0.1520s	
1795/2700 (epoch 33.241), train_loss = 1.49016784, grad/param norm = 4.9708e-01, time/batch = 0.1674s	
1796/2700 (epoch 33.259), train_loss = 1.54208708, grad/param norm = 5.0100e-01, time/batch = 0.1670s	
1797/2700 (epoch 33.278), train_loss = 1.62174320, grad/param norm = 5.3650e-01, time/batch = 0.1646s	
1798/2700 (epoch 33.296), train_loss = 1.59589795, grad/param norm = 4.9963e-01, time/batch = 0.1596s	
1799/2700 (epoch 33.315), train_loss = 1.58856137, grad/param norm = 4.9578e-01, time/batch = 0.1587s	
1800/2700 (epoch 33.333), train_loss = 1.59393658, grad/param norm = 4.7416e-01, time/batch = 0.1598s	
1801/2700 (epoch 33.352), train_loss = 1.60457000, grad/param norm = 5.2799e-01, time/batch = 0.1689s	
1802/2700 (epoch 33.370), train_loss = 1.61534683, grad/param norm = 5.0062e-01, time/batch = 0.1794s	
1803/2700 (epoch 33.389), train_loss = 1.58943469, grad/param norm = 4.8855e-01, time/batch = 0.1757s	
1804/2700 (epoch 33.407), train_loss = 1.63272874, grad/param norm = 4.6836e-01, time/batch = 0.1679s	
1805/2700 (epoch 33.426), train_loss = 1.64178299, grad/param norm = 5.0240e-01, time/batch = 0.1748s	
1806/2700 (epoch 33.444), train_loss = 1.53820719, grad/param norm = 4.6095e-01, time/batch = 0.1684s	
1807/2700 (epoch 33.463), train_loss = 1.64138143, grad/param norm = 4.8387e-01, time/batch = 0.1585s	
1808/2700 (epoch 33.481), train_loss = 1.63327900, grad/param norm = 4.9727e-01, time/batch = 0.1537s	
1809/2700 (epoch 33.500), train_loss = 1.57306348, grad/param norm = 4.6663e-01, time/batch = 0.1621s	
1810/2700 (epoch 33.519), train_loss = 1.62382517, grad/param norm = 4.8837e-01, time/batch = 0.1611s	
1811/2700 (epoch 33.537), train_loss = 1.59969754, grad/param norm = 4.7809e-01, time/batch = 0.1672s	
1812/2700 (epoch 33.556), train_loss = 1.54122203, grad/param norm = 4.6803e-01, time/batch = 0.1650s	
1813/2700 (epoch 33.574), train_loss = 1.54649287, grad/param norm = 4.9039e-01, time/batch = 0.1791s	
1814/2700 (epoch 33.593), train_loss = 1.58821461, grad/param norm = 4.8353e-01, time/batch = 0.1755s	
1815/2700 (epoch 33.611), train_loss = 1.48777493, grad/param norm = 4.4901e-01, time/batch = 0.1593s	
1816/2700 (epoch 33.630), train_loss = 1.54178384, grad/param norm = 4.8238e-01, time/batch = 0.1668s	
1817/2700 (epoch 33.648), train_loss = 1.56448855, grad/param norm = 4.6613e-01, time/batch = 0.1697s	
1818/2700 (epoch 33.667), train_loss = 1.53661097, grad/param norm = 4.7727e-01, time/batch = 0.1752s	
1819/2700 (epoch 33.685), train_loss = 1.57612805, grad/param norm = 5.2520e-01, time/batch = 0.1674s	
1820/2700 (epoch 33.704), train_loss = 1.59473912, grad/param norm = 5.2230e-01, time/batch = 0.1550s	
1821/2700 (epoch 33.722), train_loss = 1.56169705, grad/param norm = 4.4498e-01, time/batch = 0.1686s	
1822/2700 (epoch 33.741), train_loss = 1.60353883, grad/param norm = 4.5622e-01, time/batch = 0.1763s	
1823/2700 (epoch 33.759), train_loss = 1.58311723, grad/param norm = 5.0271e-01, time/batch = 0.1440s	
1824/2700 (epoch 33.778), train_loss = 1.62261192, grad/param norm = 4.6348e-01, time/batch = 0.1690s	
1825/2700 (epoch 33.796), train_loss = 1.58361213, grad/param norm = 5.1300e-01, time/batch = 0.1609s	
1826/2700 (epoch 33.815), train_loss = 1.63048360, grad/param norm = 4.9613e-01, time/batch = 0.1718s	
1827/2700 (epoch 33.833), train_loss = 1.57251460, grad/param norm = 5.2431e-01, time/batch = 0.1655s	
1828/2700 (epoch 33.852), train_loss = 1.57609986, grad/param norm = 5.0879e-01, time/batch = 0.1628s	
1829/2700 (epoch 33.870), train_loss = 1.58120411, grad/param norm = 4.6478e-01, time/batch = 0.1622s	
1830/2700 (epoch 33.889), train_loss = 1.60672667, grad/param norm = 4.7158e-01, time/batch = 0.1553s	
1831/2700 (epoch 33.907), train_loss = 1.71838207, grad/param norm = 4.9171e-01, time/batch = 0.1786s	
1832/2700 (epoch 33.926), train_loss = 1.62559194, grad/param norm = 5.2487e-01, time/batch = 0.1765s	
1833/2700 (epoch 33.944), train_loss = 1.59584899, grad/param norm = 4.8218e-01, time/batch = 0.1652s	
1834/2700 (epoch 33.963), train_loss = 1.63774951, grad/param norm = 4.7449e-01, time/batch = 0.1654s	
1835/2700 (epoch 33.981), train_loss = 1.59559469, grad/param norm = 5.0775e-01, time/batch = 0.1647s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
1836/2700 (epoch 34.000), train_loss = 1.66168920, grad/param norm = 4.6159e-01, time/batch = 0.1274s	
1837/2700 (epoch 34.019), train_loss = 1.64376441, grad/param norm = 5.0602e-01, time/batch = 0.1622s	
1838/2700 (epoch 34.037), train_loss = 1.65250706, grad/param norm = 5.1045e-01, time/batch = 0.1707s	
1839/2700 (epoch 34.056), train_loss = 1.57790621, grad/param norm = 4.8026e-01, time/batch = 0.1675s	
1840/2700 (epoch 34.074), train_loss = 1.58449636, grad/param norm = 4.8566e-01, time/batch = 0.1637s	
1841/2700 (epoch 34.093), train_loss = 1.57099716, grad/param norm = 5.0967e-01, time/batch = 0.1633s	
1842/2700 (epoch 34.111), train_loss = 1.55755609, grad/param norm = 5.0952e-01, time/batch = 0.1704s	
1843/2700 (epoch 34.130), train_loss = 1.59496532, grad/param norm = 4.9098e-01, time/batch = 0.1680s	
1844/2700 (epoch 34.148), train_loss = 1.56126019, grad/param norm = 4.5525e-01, time/batch = 0.1499s	
1845/2700 (epoch 34.167), train_loss = 1.64235570, grad/param norm = 5.0292e-01, time/batch = 0.1417s	
1846/2700 (epoch 34.185), train_loss = 1.55538287, grad/param norm = 4.9763e-01, time/batch = 0.1412s	
1847/2700 (epoch 34.204), train_loss = 1.61504374, grad/param norm = 5.6242e-01, time/batch = 0.1591s	
1848/2700 (epoch 34.222), train_loss = 1.55020610, grad/param norm = 5.2750e-01, time/batch = 0.1574s	
1849/2700 (epoch 34.241), train_loss = 1.48354105, grad/param norm = 4.9870e-01, time/batch = 0.1631s	
1850/2700 (epoch 34.259), train_loss = 1.53533234, grad/param norm = 5.0410e-01, time/batch = 0.1629s	
1851/2700 (epoch 34.278), train_loss = 1.61516177, grad/param norm = 5.3704e-01, time/batch = 0.1691s	
1852/2700 (epoch 34.296), train_loss = 1.58939645, grad/param norm = 4.9676e-01, time/batch = 0.1735s	
1853/2700 (epoch 34.315), train_loss = 1.58031346, grad/param norm = 4.9216e-01, time/batch = 0.1754s	
1854/2700 (epoch 34.333), train_loss = 1.58575522, grad/param norm = 4.7311e-01, time/batch = 0.1680s	
1855/2700 (epoch 34.352), train_loss = 1.59695744, grad/param norm = 5.2863e-01, time/batch = 0.1418s	
1856/2700 (epoch 34.370), train_loss = 1.60654578, grad/param norm = 4.9850e-01, time/batch = 0.1402s	
1857/2700 (epoch 34.389), train_loss = 1.58221002, grad/param norm = 4.9167e-01, time/batch = 0.1316s	
1858/2700 (epoch 34.407), train_loss = 1.62529299, grad/param norm = 4.7069e-01, time/batch = 0.1638s	
1859/2700 (epoch 34.426), train_loss = 1.63492734, grad/param norm = 5.0296e-01, time/batch = 0.1719s	
1860/2700 (epoch 34.444), train_loss = 1.53114735, grad/param norm = 4.6275e-01, time/batch = 0.1770s	
1861/2700 (epoch 34.463), train_loss = 1.63461073, grad/param norm = 4.8772e-01, time/batch = 0.1650s	
1862/2700 (epoch 34.481), train_loss = 1.62598125, grad/param norm = 4.9666e-01, time/batch = 0.1764s	
1863/2700 (epoch 34.500), train_loss = 1.56494404, grad/param norm = 4.6879e-01, time/batch = 0.1764s	
1864/2700 (epoch 34.519), train_loss = 1.61748770, grad/param norm = 4.9009e-01, time/batch = 0.1777s	
1865/2700 (epoch 34.537), train_loss = 1.59184177, grad/param norm = 4.8088e-01, time/batch = 0.1712s	
1866/2700 (epoch 34.556), train_loss = 1.53369023, grad/param norm = 4.6955e-01, time/batch = 0.1632s	
1867/2700 (epoch 34.574), train_loss = 1.53869746, grad/param norm = 4.8971e-01, time/batch = 0.1770s	
1868/2700 (epoch 34.593), train_loss = 1.58138014, grad/param norm = 4.8329e-01, time/batch = 0.1560s	
1869/2700 (epoch 34.611), train_loss = 1.48225434, grad/param norm = 4.5084e-01, time/batch = 0.1676s	
1870/2700 (epoch 34.630), train_loss = 1.53482816, grad/param norm = 4.8410e-01, time/batch = 0.1659s	
1871/2700 (epoch 34.648), train_loss = 1.55830271, grad/param norm = 4.6579e-01, time/batch = 0.1608s	
1872/2700 (epoch 34.667), train_loss = 1.52928475, grad/param norm = 4.8060e-01, time/batch = 0.1640s	
1873/2700 (epoch 34.685), train_loss = 1.56979441, grad/param norm = 5.2455e-01, time/batch = 0.1575s	
1874/2700 (epoch 34.704), train_loss = 1.58828066, grad/param norm = 5.2448e-01, time/batch = 0.1490s	
1875/2700 (epoch 34.722), train_loss = 1.55477473, grad/param norm = 4.4563e-01, time/batch = 0.1562s	
1876/2700 (epoch 34.741), train_loss = 1.59620619, grad/param norm = 4.5823e-01, time/batch = 0.1579s	
1877/2700 (epoch 34.759), train_loss = 1.57491996, grad/param norm = 5.0229e-01, time/batch = 0.1462s	
1878/2700 (epoch 34.778), train_loss = 1.61544695, grad/param norm = 4.6502e-01, time/batch = 0.1558s	
1879/2700 (epoch 34.796), train_loss = 1.57609862, grad/param norm = 5.1474e-01, time/batch = 0.1541s	
1880/2700 (epoch 34.815), train_loss = 1.62309603, grad/param norm = 4.9581e-01, time/batch = 0.1595s	
1881/2700 (epoch 34.833), train_loss = 1.56511949, grad/param norm = 5.2205e-01, time/batch = 0.1629s	
1882/2700 (epoch 34.852), train_loss = 1.56862260, grad/param norm = 5.0356e-01, time/batch = 0.1641s	
1883/2700 (epoch 34.870), train_loss = 1.57380005, grad/param norm = 4.6047e-01, time/batch = 0.1608s	
1884/2700 (epoch 34.889), train_loss = 1.59950211, grad/param norm = 4.7216e-01, time/batch = 0.1557s	
1885/2700 (epoch 34.907), train_loss = 1.71150071, grad/param norm = 4.9950e-01, time/batch = 0.1444s	
1886/2700 (epoch 34.926), train_loss = 1.61831076, grad/param norm = 5.2973e-01, time/batch = 0.1275s	
1887/2700 (epoch 34.944), train_loss = 1.58904857, grad/param norm = 4.8330e-01, time/batch = 0.1504s	
1888/2700 (epoch 34.963), train_loss = 1.63004269, grad/param norm = 4.7532e-01, time/batch = 0.1482s	
1889/2700 (epoch 34.981), train_loss = 1.58777376, grad/param norm = 5.0951e-01, time/batch = 0.1535s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
1890/2700 (epoch 35.000), train_loss = 1.65541102, grad/param norm = 4.6299e-01, time/batch = 0.1755s	
1891/2700 (epoch 35.019), train_loss = 1.63774349, grad/param norm = 5.1242e-01, time/batch = 0.1786s	
1892/2700 (epoch 35.037), train_loss = 1.64548306, grad/param norm = 5.1201e-01, time/batch = 0.1755s	
1893/2700 (epoch 35.056), train_loss = 1.57057389, grad/param norm = 4.8174e-01, time/batch = 0.1780s	
1894/2700 (epoch 35.074), train_loss = 1.57807855, grad/param norm = 4.8837e-01, time/batch = 0.1761s	
1895/2700 (epoch 35.093), train_loss = 1.56379357, grad/param norm = 5.1042e-01, time/batch = 0.1776s	
1896/2700 (epoch 35.111), train_loss = 1.55071454, grad/param norm = 5.0390e-01, time/batch = 0.1680s	
1897/2700 (epoch 35.130), train_loss = 1.58782049, grad/param norm = 4.8878e-01, time/batch = 0.1669s	
1898/2700 (epoch 35.148), train_loss = 1.55504912, grad/param norm = 4.5592e-01, time/batch = 0.1531s	
1899/2700 (epoch 35.167), train_loss = 1.63617574, grad/param norm = 5.0721e-01, time/batch = 0.1280s	
1900/2700 (epoch 35.185), train_loss = 1.54875845, grad/param norm = 4.9851e-01, time/batch = 0.1598s	
1901/2700 (epoch 35.204), train_loss = 1.60823428, grad/param norm = 5.5757e-01, time/batch = 0.1781s	
1902/2700 (epoch 35.222), train_loss = 1.54425453, grad/param norm = 5.2234e-01, time/batch = 0.1767s	
1903/2700 (epoch 35.241), train_loss = 1.47716042, grad/param norm = 5.0038e-01, time/batch = 0.1766s	
1904/2700 (epoch 35.259), train_loss = 1.52887782, grad/param norm = 5.0616e-01, time/batch = 0.1842s	
1905/2700 (epoch 35.278), train_loss = 1.60871941, grad/param norm = 5.3544e-01, time/batch = 0.1808s	
1906/2700 (epoch 35.296), train_loss = 1.58321031, grad/param norm = 4.9372e-01, time/batch = 0.1770s	
1907/2700 (epoch 35.315), train_loss = 1.57244932, grad/param norm = 4.8860e-01, time/batch = 0.1790s	
1908/2700 (epoch 35.333), train_loss = 1.57804013, grad/param norm = 4.7244e-01, time/batch = 0.1788s	
1909/2700 (epoch 35.352), train_loss = 1.58957293, grad/param norm = 5.2905e-01, time/batch = 0.1678s	
1910/2700 (epoch 35.370), train_loss = 1.59815609, grad/param norm = 4.9722e-01, time/batch = 0.1376s	
1911/2700 (epoch 35.389), train_loss = 1.57539451, grad/param norm = 4.9556e-01, time/batch = 0.1637s	
1912/2700 (epoch 35.407), train_loss = 1.61809118, grad/param norm = 4.7240e-01, time/batch = 0.1602s	
1913/2700 (epoch 35.426), train_loss = 1.62844642, grad/param norm = 5.0344e-01, time/batch = 0.1460s	
1914/2700 (epoch 35.444), train_loss = 1.52427416, grad/param norm = 4.6437e-01, time/batch = 0.1469s	
1915/2700 (epoch 35.463), train_loss = 1.62817225, grad/param norm = 4.9148e-01, time/batch = 0.1547s	
1916/2700 (epoch 35.481), train_loss = 1.61895799, grad/param norm = 4.9606e-01, time/batch = 0.1562s	
1917/2700 (epoch 35.500), train_loss = 1.55723632, grad/param norm = 4.7087e-01, time/batch = 0.1621s	
1918/2700 (epoch 35.519), train_loss = 1.61143466, grad/param norm = 4.9145e-01, time/batch = 0.1687s	
1919/2700 (epoch 35.537), train_loss = 1.58436405, grad/param norm = 4.8388e-01, time/batch = 0.1612s	
1920/2700 (epoch 35.556), train_loss = 1.52655791, grad/param norm = 4.7101e-01, time/batch = 0.1440s	
1921/2700 (epoch 35.574), train_loss = 1.53130565, grad/param norm = 4.8919e-01, time/batch = 0.1761s	
1922/2700 (epoch 35.593), train_loss = 1.57478655, grad/param norm = 4.8351e-01, time/batch = 0.1775s	
1923/2700 (epoch 35.611), train_loss = 1.47693620, grad/param norm = 4.5263e-01, time/batch = 0.1753s	
1924/2700 (epoch 35.630), train_loss = 1.52822745, grad/param norm = 4.8606e-01, time/batch = 0.1746s	
1925/2700 (epoch 35.648), train_loss = 1.55241419, grad/param norm = 4.6595e-01, time/batch = 0.1721s	
1926/2700 (epoch 35.667), train_loss = 1.52222637, grad/param norm = 4.8391e-01, time/batch = 0.1548s	
1927/2700 (epoch 35.685), train_loss = 1.56362306, grad/param norm = 5.2361e-01, time/batch = 0.1437s	
1928/2700 (epoch 35.704), train_loss = 1.58211312, grad/param norm = 5.2702e-01, time/batch = 0.1548s	
1929/2700 (epoch 35.722), train_loss = 1.54824898, grad/param norm = 4.4615e-01, time/batch = 0.1577s	
1930/2700 (epoch 35.741), train_loss = 1.58913283, grad/param norm = 4.6043e-01, time/batch = 0.1606s	
1931/2700 (epoch 35.759), train_loss = 1.56707235, grad/param norm = 5.0206e-01, time/batch = 0.1606s	
1932/2700 (epoch 35.778), train_loss = 1.60863093, grad/param norm = 4.6683e-01, time/batch = 0.1783s	
1933/2700 (epoch 35.796), train_loss = 1.56899743, grad/param norm = 5.1660e-01, time/batch = 0.1798s	
1934/2700 (epoch 35.815), train_loss = 1.61597188, grad/param norm = 4.9578e-01, time/batch = 0.1793s	
1935/2700 (epoch 35.833), train_loss = 1.55810220, grad/param norm = 5.1883e-01, time/batch = 0.1792s	
1936/2700 (epoch 35.852), train_loss = 1.56139253, grad/param norm = 4.9747e-01, time/batch = 0.1732s	
1937/2700 (epoch 35.870), train_loss = 1.56679725, grad/param norm = 4.5626e-01, time/batch = 0.1715s	
1938/2700 (epoch 35.889), train_loss = 1.59260535, grad/param norm = 4.7419e-01, time/batch = 0.1618s	
1939/2700 (epoch 35.907), train_loss = 1.70489284, grad/param norm = 5.0756e-01, time/batch = 0.1489s	
1940/2700 (epoch 35.926), train_loss = 1.61131991, grad/param norm = 5.3344e-01, time/batch = 0.1561s	
1941/2700 (epoch 35.944), train_loss = 1.58245028, grad/param norm = 4.8364e-01, time/batch = 0.1416s	
1942/2700 (epoch 35.963), train_loss = 1.62262893, grad/param norm = 4.7569e-01, time/batch = 0.1457s	
1943/2700 (epoch 35.981), train_loss = 1.58021298, grad/param norm = 5.1140e-01, time/batch = 0.1670s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
1944/2700 (epoch 36.000), train_loss = 1.64942109, grad/param norm = 4.6441e-01, time/batch = 0.1671s	
1945/2700 (epoch 36.019), train_loss = 1.63196474, grad/param norm = 5.1768e-01, time/batch = 0.1502s	
1946/2700 (epoch 36.037), train_loss = 1.63859611, grad/param norm = 5.1625e-01, time/batch = 0.1569s	
1947/2700 (epoch 36.056), train_loss = 1.56447139, grad/param norm = 4.8252e-01, time/batch = 0.1551s	
1948/2700 (epoch 36.074), train_loss = 1.57180486, grad/param norm = 4.8989e-01, time/batch = 0.1685s	
1949/2700 (epoch 36.093), train_loss = 1.55714980, grad/param norm = 5.1174e-01, time/batch = 0.1664s	
1950/2700 (epoch 36.111), train_loss = 1.54408458, grad/param norm = 4.9965e-01, time/batch = 0.1692s	
1951/2700 (epoch 36.130), train_loss = 1.58075554, grad/param norm = 4.8745e-01, time/batch = 0.1624s	
1952/2700 (epoch 36.148), train_loss = 1.54903250, grad/param norm = 4.5621e-01, time/batch = 0.1662s	
1953/2700 (epoch 36.167), train_loss = 1.63020190, grad/param norm = 5.1056e-01, time/batch = 0.1495s	
1954/2700 (epoch 36.185), train_loss = 1.54249549, grad/param norm = 4.9788e-01, time/batch = 0.1638s	
1955/2700 (epoch 36.204), train_loss = 1.60134989, grad/param norm = 5.5091e-01, time/batch = 0.1470s	
1956/2700 (epoch 36.222), train_loss = 1.53829973, grad/param norm = 5.1761e-01, time/batch = 0.1344s	
1957/2700 (epoch 36.241), train_loss = 1.47123212, grad/param norm = 5.0332e-01, time/batch = 0.1270s	
1958/2700 (epoch 36.259), train_loss = 1.52259866, grad/param norm = 5.0769e-01, time/batch = 0.1561s	
1959/2700 (epoch 36.278), train_loss = 1.60271477, grad/param norm = 5.3366e-01, time/batch = 0.1628s	
1960/2700 (epoch 36.296), train_loss = 1.57728412, grad/param norm = 4.9114e-01, time/batch = 0.1685s	
1961/2700 (epoch 36.315), train_loss = 1.56487986, grad/param norm = 4.8570e-01, time/batch = 0.1705s	
1962/2700 (epoch 36.333), train_loss = 1.57046836, grad/param norm = 4.7244e-01, time/batch = 0.1522s	
1963/2700 (epoch 36.352), train_loss = 1.58260977, grad/param norm = 5.2914e-01, time/batch = 0.1757s	
1964/2700 (epoch 36.370), train_loss = 1.59004316, grad/param norm = 4.9649e-01, time/batch = 0.1628s	
1965/2700 (epoch 36.389), train_loss = 1.56894674, grad/param norm = 4.9972e-01, time/batch = 0.1700s	
1966/2700 (epoch 36.407), train_loss = 1.61125452, grad/param norm = 4.7418e-01, time/batch = 0.1572s	
1967/2700 (epoch 36.426), train_loss = 1.62210005, grad/param norm = 5.0383e-01, time/batch = 0.1493s	
1968/2700 (epoch 36.444), train_loss = 1.51798575, grad/param norm = 4.6705e-01, time/batch = 0.1453s	
1969/2700 (epoch 36.463), train_loss = 1.62197196, grad/param norm = 4.9469e-01, time/batch = 0.1592s	
1970/2700 (epoch 36.481), train_loss = 1.61226916, grad/param norm = 4.9537e-01, time/batch = 0.1628s	
1971/2700 (epoch 36.500), train_loss = 1.54987970, grad/param norm = 4.7333e-01, time/batch = 0.1648s	
1972/2700 (epoch 36.519), train_loss = 1.60559395, grad/param norm = 4.9258e-01, time/batch = 0.1681s	
1973/2700 (epoch 36.537), train_loss = 1.57722055, grad/param norm = 4.8681e-01, time/batch = 0.1743s	
1974/2700 (epoch 36.556), train_loss = 1.51969329, grad/param norm = 4.7229e-01, time/batch = 0.1711s	
1975/2700 (epoch 36.574), train_loss = 1.52430324, grad/param norm = 4.8945e-01, time/batch = 0.1553s	
1976/2700 (epoch 36.593), train_loss = 1.56848567, grad/param norm = 4.8436e-01, time/batch = 0.1564s	
1977/2700 (epoch 36.611), train_loss = 1.47194284, grad/param norm = 4.5435e-01, time/batch = 0.1556s	
1978/2700 (epoch 36.630), train_loss = 1.52178600, grad/param norm = 4.8746e-01, time/batch = 0.1255s	
1979/2700 (epoch 36.648), train_loss = 1.54681120, grad/param norm = 4.6616e-01, time/batch = 0.1292s	
1980/2700 (epoch 36.667), train_loss = 1.51556530, grad/param norm = 4.8756e-01, time/batch = 0.1518s	
1981/2700 (epoch 36.685), train_loss = 1.55776309, grad/param norm = 5.2246e-01, time/batch = 0.1439s	
1982/2700 (epoch 36.704), train_loss = 1.57627924, grad/param norm = 5.3023e-01, time/batch = 0.1623s	
1983/2700 (epoch 36.722), train_loss = 1.54205052, grad/param norm = 4.4729e-01, time/batch = 0.1524s	
1984/2700 (epoch 36.741), train_loss = 1.58240634, grad/param norm = 4.6254e-01, time/batch = 0.1616s	
1985/2700 (epoch 36.759), train_loss = 1.55967219, grad/param norm = 5.0258e-01, time/batch = 0.1579s	
1986/2700 (epoch 36.778), train_loss = 1.60214018, grad/param norm = 4.6921e-01, time/batch = 0.1505s	
1987/2700 (epoch 36.796), train_loss = 1.56218124, grad/param norm = 5.1847e-01, time/batch = 0.1515s	
1988/2700 (epoch 36.815), train_loss = 1.60908244, grad/param norm = 4.9588e-01, time/batch = 0.1318s	
1989/2700 (epoch 36.833), train_loss = 1.55141430, grad/param norm = 5.1519e-01, time/batch = 0.1479s	
1990/2700 (epoch 36.852), train_loss = 1.55457244, grad/param norm = 4.9154e-01, time/batch = 0.1639s	
1991/2700 (epoch 36.870), train_loss = 1.56012720, grad/param norm = 4.5286e-01, time/batch = 0.1607s	
1992/2700 (epoch 36.889), train_loss = 1.58603959, grad/param norm = 4.7780e-01, time/batch = 0.1673s	
1993/2700 (epoch 36.907), train_loss = 1.69854056, grad/param norm = 5.1540e-01, time/batch = 0.1611s	
1994/2700 (epoch 36.926), train_loss = 1.60461024, grad/param norm = 5.3583e-01, time/batch = 0.1440s	
1995/2700 (epoch 36.944), train_loss = 1.57598365, grad/param norm = 4.8314e-01, time/batch = 0.1755s	
1996/2700 (epoch 36.963), train_loss = 1.61554278, grad/param norm = 4.7575e-01, time/batch = 0.1776s	
1997/2700 (epoch 36.981), train_loss = 1.57296311, grad/param norm = 5.1361e-01, time/batch = 0.1721s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
1998/2700 (epoch 37.000), train_loss = 1.64365411, grad/param norm = 4.6591e-01, time/batch = 0.1490s	
1999/2700 (epoch 37.019), train_loss = 1.62627185, grad/param norm = 5.2320e-01, time/batch = 0.1478s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch37.04_1.7775.t7	
2000/2700 (epoch 37.037), train_loss = 1.63225931, grad/param norm = 5.1745e-01, time/batch = 0.1548s	
2001/2700 (epoch 37.056), train_loss = 1.66775312, grad/param norm = 4.9206e-01, time/batch = 0.1605s	
2002/2700 (epoch 37.074), train_loss = 1.56469145, grad/param norm = 4.9625e-01, time/batch = 0.1446s	
2003/2700 (epoch 37.093), train_loss = 1.55135250, grad/param norm = 5.1916e-01, time/batch = 0.1538s	
2004/2700 (epoch 37.111), train_loss = 1.53853519, grad/param norm = 5.0045e-01, time/batch = 0.1646s	
2005/2700 (epoch 37.130), train_loss = 1.57391587, grad/param norm = 4.8709e-01, time/batch = 0.1697s	
2006/2700 (epoch 37.148), train_loss = 1.54297013, grad/param norm = 4.5695e-01, time/batch = 0.1348s	
2007/2700 (epoch 37.167), train_loss = 1.62481054, grad/param norm = 5.1484e-01, time/batch = 0.1612s	
2008/2700 (epoch 37.185), train_loss = 1.53607525, grad/param norm = 4.9562e-01, time/batch = 0.1682s	
2009/2700 (epoch 37.204), train_loss = 1.59498977, grad/param norm = 5.4052e-01, time/batch = 0.1743s	
2010/2700 (epoch 37.222), train_loss = 1.53299462, grad/param norm = 5.1304e-01, time/batch = 0.1771s	
2011/2700 (epoch 37.241), train_loss = 1.46505976, grad/param norm = 5.0488e-01, time/batch = 0.1683s	
2012/2700 (epoch 37.259), train_loss = 1.51650553, grad/param norm = 5.0839e-01, time/batch = 0.1647s	
2013/2700 (epoch 37.278), train_loss = 1.59657168, grad/param norm = 5.3167e-01, time/batch = 0.1757s	
2014/2700 (epoch 37.296), train_loss = 1.57172471, grad/param norm = 4.8788e-01, time/batch = 0.1780s	
2015/2700 (epoch 37.315), train_loss = 1.55764723, grad/param norm = 4.8164e-01, time/batch = 0.1757s	
2016/2700 (epoch 37.333), train_loss = 1.56355793, grad/param norm = 4.7273e-01, time/batch = 0.1532s	
2017/2700 (epoch 37.352), train_loss = 1.57580990, grad/param norm = 5.2949e-01, time/batch = 0.1761s	
2018/2700 (epoch 37.370), train_loss = 1.58252983, grad/param norm = 4.9648e-01, time/batch = 0.1785s	
2019/2700 (epoch 37.389), train_loss = 1.56273653, grad/param norm = 5.0287e-01, time/batch = 0.1548s	
2020/2700 (epoch 37.407), train_loss = 1.60449193, grad/param norm = 4.7472e-01, time/batch = 0.1443s	
2021/2700 (epoch 37.426), train_loss = 1.61609335, grad/param norm = 5.0401e-01, time/batch = 0.1770s	
2022/2700 (epoch 37.444), train_loss = 1.51175797, grad/param norm = 4.6940e-01, time/batch = 0.1746s	
2023/2700 (epoch 37.463), train_loss = 1.61614739, grad/param norm = 4.9719e-01, time/batch = 0.1667s	
2024/2700 (epoch 37.481), train_loss = 1.60573127, grad/param norm = 4.9405e-01, time/batch = 0.1563s	
2025/2700 (epoch 37.500), train_loss = 1.54291617, grad/param norm = 4.7493e-01, time/batch = 0.1446s	
2026/2700 (epoch 37.519), train_loss = 1.59996178, grad/param norm = 4.9316e-01, time/batch = 0.1347s	
2027/2700 (epoch 37.537), train_loss = 1.57055631, grad/param norm = 4.8980e-01, time/batch = 0.1271s	
2028/2700 (epoch 37.556), train_loss = 1.51323800, grad/param norm = 4.7375e-01, time/batch = 0.1502s	
2029/2700 (epoch 37.574), train_loss = 1.51768273, grad/param norm = 4.8909e-01, time/batch = 0.1489s	
2030/2700 (epoch 37.593), train_loss = 1.56224954, grad/param norm = 4.8492e-01, time/batch = 0.1420s	
2031/2700 (epoch 37.611), train_loss = 1.46705763, grad/param norm = 4.5624e-01, time/batch = 0.1730s	
2032/2700 (epoch 37.630), train_loss = 1.51565304, grad/param norm = 4.8945e-01, time/batch = 0.1708s	
2033/2700 (epoch 37.648), train_loss = 1.54153295, grad/param norm = 4.6690e-01, time/batch = 0.1546s	
2034/2700 (epoch 37.667), train_loss = 1.50896816, grad/param norm = 4.9201e-01, time/batch = 0.1561s	
2035/2700 (epoch 37.685), train_loss = 1.55207243, grad/param norm = 5.2176e-01, time/batch = 0.1564s	
2036/2700 (epoch 37.704), train_loss = 1.57075218, grad/param norm = 5.3369e-01, time/batch = 0.1662s	
2037/2700 (epoch 37.722), train_loss = 1.53618774, grad/param norm = 4.4782e-01, time/batch = 0.1470s	
2038/2700 (epoch 37.741), train_loss = 1.57588324, grad/param norm = 4.6480e-01, time/batch = 0.1514s	
2039/2700 (epoch 37.759), train_loss = 1.55249385, grad/param norm = 5.0291e-01, time/batch = 0.1486s	
2040/2700 (epoch 37.778), train_loss = 1.59583858, grad/param norm = 4.7122e-01, time/batch = 0.1360s	
2041/2700 (epoch 37.796), train_loss = 1.55563805, grad/param norm = 5.1963e-01, time/batch = 0.1794s	
2042/2700 (epoch 37.815), train_loss = 1.60245944, grad/param norm = 4.9559e-01, time/batch = 0.1688s	
2043/2700 (epoch 37.833), train_loss = 1.54506782, grad/param norm = 5.1138e-01, time/batch = 0.1480s	
2044/2700 (epoch 37.852), train_loss = 1.54805749, grad/param norm = 4.8643e-01, time/batch = 0.1293s	
2045/2700 (epoch 37.870), train_loss = 1.55368840, grad/param norm = 4.5085e-01, time/batch = 0.1654s	
2046/2700 (epoch 37.889), train_loss = 1.57980127, grad/param norm = 4.8226e-01, time/batch = 0.1743s	
2047/2700 (epoch 37.907), train_loss = 1.69243955, grad/param norm = 5.2186e-01, time/batch = 0.1704s	
2048/2700 (epoch 37.926), train_loss = 1.59805825, grad/param norm = 5.3634e-01, time/batch = 0.1750s	
2049/2700 (epoch 37.944), train_loss = 1.56961896, grad/param norm = 4.8176e-01, time/batch = 0.1519s	
2050/2700 (epoch 37.963), train_loss = 1.60862962, grad/param norm = 4.7541e-01, time/batch = 0.1477s	
2051/2700 (epoch 37.981), train_loss = 1.56596539, grad/param norm = 5.1536e-01, time/batch = 0.1698s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2052/2700 (epoch 38.000), train_loss = 1.63821244, grad/param norm = 4.6741e-01, time/batch = 0.1776s	
2053/2700 (epoch 38.019), train_loss = 1.62079622, grad/param norm = 5.2898e-01, time/batch = 0.1741s	
2054/2700 (epoch 38.037), train_loss = 1.62601683, grad/param norm = 5.2117e-01, time/batch = 0.1686s	
2055/2700 (epoch 38.056), train_loss = 1.55340431, grad/param norm = 4.8676e-01, time/batch = 0.1750s	
2056/2700 (epoch 38.074), train_loss = 1.56013869, grad/param norm = 4.9377e-01, time/batch = 0.1641s	
2057/2700 (epoch 38.093), train_loss = 1.54434889, grad/param norm = 5.1176e-01, time/batch = 0.1487s	
2058/2700 (epoch 38.111), train_loss = 1.53192776, grad/param norm = 4.9310e-01, time/batch = 0.1543s	
2059/2700 (epoch 38.130), train_loss = 1.56777546, grad/param norm = 4.8627e-01, time/batch = 0.1580s	
2060/2700 (epoch 38.148), train_loss = 1.53755252, grad/param norm = 4.5787e-01, time/batch = 0.1388s	
2061/2700 (epoch 38.167), train_loss = 1.61887820, grad/param norm = 5.1549e-01, time/batch = 0.1801s	
2062/2700 (epoch 38.185), train_loss = 1.53040453, grad/param norm = 4.9601e-01, time/batch = 0.1779s	
2063/2700 (epoch 38.204), train_loss = 1.58872243, grad/param norm = 5.3986e-01, time/batch = 0.1804s	
2064/2700 (epoch 38.222), train_loss = 1.52747576, grad/param norm = 5.1315e-01, time/batch = 0.1763s	
2065/2700 (epoch 38.241), train_loss = 1.45991776, grad/param norm = 5.0727e-01, time/batch = 0.1662s	
2066/2700 (epoch 38.259), train_loss = 1.51082958, grad/param norm = 5.0696e-01, time/batch = 0.1594s	
2067/2700 (epoch 38.278), train_loss = 1.59109978, grad/param norm = 5.2527e-01, time/batch = 0.1490s	
2068/2700 (epoch 38.296), train_loss = 1.56620778, grad/param norm = 4.8494e-01, time/batch = 0.1519s	
2069/2700 (epoch 38.315), train_loss = 1.55063387, grad/param norm = 4.8013e-01, time/batch = 0.1440s	
2070/2700 (epoch 38.333), train_loss = 1.55659753, grad/param norm = 4.7421e-01, time/batch = 0.1529s	
2071/2700 (epoch 38.352), train_loss = 1.56940072, grad/param norm = 5.2935e-01, time/batch = 0.1351s	
2072/2700 (epoch 38.370), train_loss = 1.57490431, grad/param norm = 4.9713e-01, time/batch = 0.1723s	
2073/2700 (epoch 38.389), train_loss = 1.55699329, grad/param norm = 5.0792e-01, time/batch = 0.1715s	
2074/2700 (epoch 38.407), train_loss = 1.59825793, grad/param norm = 4.7590e-01, time/batch = 0.1694s	
2075/2700 (epoch 38.426), train_loss = 1.61034074, grad/param norm = 5.0445e-01, time/batch = 0.1652s	
2076/2700 (epoch 38.444), train_loss = 1.50612295, grad/param norm = 4.7248e-01, time/batch = 0.1837s	
2077/2700 (epoch 38.463), train_loss = 1.61038422, grad/param norm = 5.0040e-01, time/batch = 0.1793s	
2078/2700 (epoch 38.481), train_loss = 1.59952738, grad/param norm = 4.9395e-01, time/batch = 0.1580s	
2079/2700 (epoch 38.500), train_loss = 1.53617809, grad/param norm = 4.7769e-01, time/batch = 0.1570s	
2080/2700 (epoch 38.519), train_loss = 1.59454586, grad/param norm = 4.9392e-01, time/batch = 0.1515s	
2081/2700 (epoch 38.537), train_loss = 1.56401726, grad/param norm = 4.9297e-01, time/batch = 0.1615s	
2082/2700 (epoch 38.556), train_loss = 1.50690062, grad/param norm = 4.7441e-01, time/batch = 0.1267s	
2083/2700 (epoch 38.574), train_loss = 1.51138249, grad/param norm = 4.9053e-01, time/batch = 0.1623s	
2084/2700 (epoch 38.593), train_loss = 1.55649582, grad/param norm = 4.8646e-01, time/batch = 0.1609s	
2085/2700 (epoch 38.611), train_loss = 1.46243098, grad/param norm = 4.5734e-01, time/batch = 0.1590s	
2086/2700 (epoch 38.630), train_loss = 1.50969606, grad/param norm = 4.9072e-01, time/batch = 0.1475s	
2087/2700 (epoch 38.648), train_loss = 1.53644097, grad/param norm = 4.6767e-01, time/batch = 0.1781s	
2088/2700 (epoch 38.667), train_loss = 1.50296088, grad/param norm = 4.9540e-01, time/batch = 0.1673s	
2089/2700 (epoch 38.685), train_loss = 1.54651373, grad/param norm = 5.2005e-01, time/batch = 0.1710s	
2090/2700 (epoch 38.704), train_loss = 1.56535432, grad/param norm = 5.3716e-01, time/batch = 0.1568s	
2091/2700 (epoch 38.722), train_loss = 1.53059439, grad/param norm = 4.4918e-01, time/batch = 0.1749s	
2092/2700 (epoch 38.741), train_loss = 1.56965496, grad/param norm = 4.6680e-01, time/batch = 0.1754s	
2093/2700 (epoch 38.759), train_loss = 1.54581664, grad/param norm = 5.0352e-01, time/batch = 0.1487s	
2094/2700 (epoch 38.778), train_loss = 1.59003081, grad/param norm = 4.7393e-01, time/batch = 0.1786s	
2095/2700 (epoch 38.796), train_loss = 1.54956866, grad/param norm = 5.2138e-01, time/batch = 0.1756s	
2096/2700 (epoch 38.815), train_loss = 1.59602238, grad/param norm = 4.9572e-01, time/batch = 0.1727s	
2097/2700 (epoch 38.833), train_loss = 1.53907438, grad/param norm = 5.0856e-01, time/batch = 0.1633s	
2098/2700 (epoch 38.852), train_loss = 1.54187476, grad/param norm = 4.8315e-01, time/batch = 0.1552s	
2099/2700 (epoch 38.870), train_loss = 1.54785744, grad/param norm = 4.5075e-01, time/batch = 0.1717s	
2100/2700 (epoch 38.889), train_loss = 1.57375674, grad/param norm = 4.8592e-01, time/batch = 0.1732s	
2101/2700 (epoch 38.907), train_loss = 1.68639332, grad/param norm = 5.2623e-01, time/batch = 0.1624s	
2102/2700 (epoch 38.926), train_loss = 1.59179923, grad/param norm = 5.3602e-01, time/batch = 0.1671s	
2103/2700 (epoch 38.944), train_loss = 1.56355323, grad/param norm = 4.8091e-01, time/batch = 0.1607s	
2104/2700 (epoch 38.963), train_loss = 1.60218388, grad/param norm = 4.7610e-01, time/batch = 0.1485s	
2105/2700 (epoch 38.981), train_loss = 1.55922882, grad/param norm = 5.1753e-01, time/batch = 0.1552s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2106/2700 (epoch 39.000), train_loss = 1.63284153, grad/param norm = 4.6868e-01, time/batch = 0.1652s	
2107/2700 (epoch 39.019), train_loss = 1.61555307, grad/param norm = 5.3512e-01, time/batch = 0.1642s	
2108/2700 (epoch 39.037), train_loss = 1.62024042, grad/param norm = 5.2349e-01, time/batch = 0.1668s	
2109/2700 (epoch 39.056), train_loss = 1.54712178, grad/param norm = 4.8941e-01, time/batch = 0.1780s	
2110/2700 (epoch 39.074), train_loss = 1.55472811, grad/param norm = 4.9640e-01, time/batch = 0.1779s	
2111/2700 (epoch 39.093), train_loss = 1.53826438, grad/param norm = 5.1279e-01, time/batch = 0.1685s	
2112/2700 (epoch 39.111), train_loss = 1.52641933, grad/param norm = 4.9241e-01, time/batch = 0.1763s	
2113/2700 (epoch 39.130), train_loss = 1.56175481, grad/param norm = 4.8776e-01, time/batch = 0.1763s	
2114/2700 (epoch 39.148), train_loss = 1.53200776, grad/param norm = 4.5795e-01, time/batch = 0.1710s	
2115/2700 (epoch 39.167), train_loss = 1.61346468, grad/param norm = 5.1567e-01, time/batch = 0.1792s	
2116/2700 (epoch 39.185), train_loss = 1.52462315, grad/param norm = 4.9405e-01, time/batch = 0.1787s	
2117/2700 (epoch 39.204), train_loss = 1.58286000, grad/param norm = 5.3428e-01, time/batch = 0.1801s	
2118/2700 (epoch 39.222), train_loss = 1.52235701, grad/param norm = 5.1272e-01, time/batch = 0.1486s	
2119/2700 (epoch 39.241), train_loss = 1.45460068, grad/param norm = 5.0888e-01, time/batch = 0.1753s	
2120/2700 (epoch 39.259), train_loss = 1.50528718, grad/param norm = 5.0647e-01, time/batch = 0.1762s	
2121/2700 (epoch 39.278), train_loss = 1.58562727, grad/param norm = 5.2146e-01, time/batch = 0.1712s	
2122/2700 (epoch 39.296), train_loss = 1.56098436, grad/param norm = 4.8307e-01, time/batch = 0.1744s	
2123/2700 (epoch 39.315), train_loss = 1.54390065, grad/param norm = 4.7853e-01, time/batch = 0.1774s	
2124/2700 (epoch 39.333), train_loss = 1.55012417, grad/param norm = 4.7642e-01, time/batch = 0.1692s	
2125/2700 (epoch 39.352), train_loss = 1.56314570, grad/param norm = 5.2986e-01, time/batch = 0.1508s	
2126/2700 (epoch 39.370), train_loss = 1.56784659, grad/param norm = 4.9892e-01, time/batch = 0.1629s	
2127/2700 (epoch 39.389), train_loss = 1.55150001, grad/param norm = 5.1202e-01, time/batch = 0.1740s	
2128/2700 (epoch 39.407), train_loss = 1.59214539, grad/param norm = 4.7619e-01, time/batch = 0.1575s	
2129/2700 (epoch 39.426), train_loss = 1.60484770, grad/param norm = 5.0466e-01, time/batch = 0.1785s	
2130/2700 (epoch 39.444), train_loss = 1.50051595, grad/param norm = 4.7547e-01, time/batch = 0.1775s	
2131/2700 (epoch 39.463), train_loss = 1.60492733, grad/param norm = 5.0335e-01, time/batch = 0.1679s	
2132/2700 (epoch 39.481), train_loss = 1.59358486, grad/param norm = 4.9391e-01, time/batch = 0.1776s	
2133/2700 (epoch 39.500), train_loss = 1.52976496, grad/param norm = 4.8002e-01, time/batch = 0.1792s	
2134/2700 (epoch 39.519), train_loss = 1.58935608, grad/param norm = 4.9458e-01, time/batch = 0.1753s	
2135/2700 (epoch 39.537), train_loss = 1.55780248, grad/param norm = 4.9629e-01, time/batch = 0.1631s	
2136/2700 (epoch 39.556), train_loss = 1.50087868, grad/param norm = 4.7518e-01, time/batch = 0.1789s	
2137/2700 (epoch 39.574), train_loss = 1.50537423, grad/param norm = 4.9152e-01, time/batch = 0.1785s	
2138/2700 (epoch 39.593), train_loss = 1.55088192, grad/param norm = 4.8776e-01, time/batch = 0.1688s	
2139/2700 (epoch 39.611), train_loss = 1.45784660, grad/param norm = 4.5868e-01, time/batch = 0.1453s	
2140/2700 (epoch 39.630), train_loss = 1.50409766, grad/param norm = 4.9258e-01, time/batch = 0.1521s	
2141/2700 (epoch 39.648), train_loss = 1.53152610, grad/param norm = 4.6867e-01, time/batch = 0.1623s	
2142/2700 (epoch 39.667), train_loss = 1.49710941, grad/param norm = 4.9913e-01, time/batch = 0.1627s	
2143/2700 (epoch 39.685), train_loss = 1.54107695, grad/param norm = 5.1844e-01, time/batch = 0.1577s	
2144/2700 (epoch 39.704), train_loss = 1.56016912, grad/param norm = 5.4069e-01, time/batch = 0.1521s	
2145/2700 (epoch 39.722), train_loss = 1.52531665, grad/param norm = 4.5027e-01, time/batch = 0.1630s	
2146/2700 (epoch 39.741), train_loss = 1.56360787, grad/param norm = 4.6885e-01, time/batch = 0.1589s	
2147/2700 (epoch 39.759), train_loss = 1.53938375, grad/param norm = 5.0382e-01, time/batch = 0.1759s	
2148/2700 (epoch 39.778), train_loss = 1.58443915, grad/param norm = 4.7649e-01, time/batch = 0.1754s	
2149/2700 (epoch 39.796), train_loss = 1.54377172, grad/param norm = 5.2281e-01, time/batch = 0.1493s	
2150/2700 (epoch 39.815), train_loss = 1.58978842, grad/param norm = 4.9562e-01, time/batch = 0.1767s	
2151/2700 (epoch 39.833), train_loss = 1.53341623, grad/param norm = 5.0599e-01, time/batch = 0.1617s	
2152/2700 (epoch 39.852), train_loss = 1.53590882, grad/param norm = 4.8101e-01, time/batch = 0.1660s	
2153/2700 (epoch 39.870), train_loss = 1.54228960, grad/param norm = 4.5159e-01, time/batch = 0.1685s	
2154/2700 (epoch 39.889), train_loss = 1.56793704, grad/param norm = 4.8925e-01, time/batch = 0.1714s	
2155/2700 (epoch 39.907), train_loss = 1.68048013, grad/param norm = 5.2925e-01, time/batch = 0.1664s	
2156/2700 (epoch 39.926), train_loss = 1.58571647, grad/param norm = 5.3492e-01, time/batch = 0.1573s	
2157/2700 (epoch 39.944), train_loss = 1.55771080, grad/param norm = 4.8023e-01, time/batch = 0.1336s	
2158/2700 (epoch 39.963), train_loss = 1.59601231, grad/param norm = 4.7692e-01, time/batch = 0.1672s	
2159/2700 (epoch 39.981), train_loss = 1.55272300, grad/param norm = 5.1920e-01, time/batch = 0.1496s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2160/2700 (epoch 40.000), train_loss = 1.62767296, grad/param norm = 4.7003e-01, time/batch = 0.1479s	
2161/2700 (epoch 40.019), train_loss = 1.61059943, grad/param norm = 5.4253e-01, time/batch = 0.1761s	
2162/2700 (epoch 40.037), train_loss = 1.61451739, grad/param norm = 5.2701e-01, time/batch = 0.1770s	
2163/2700 (epoch 40.056), train_loss = 1.54192984, grad/param norm = 4.9180e-01, time/batch = 0.1774s	
2164/2700 (epoch 40.074), train_loss = 1.54937547, grad/param norm = 4.9796e-01, time/batch = 0.1768s	
2165/2700 (epoch 40.093), train_loss = 1.53250232, grad/param norm = 5.1307e-01, time/batch = 0.1787s	
2166/2700 (epoch 40.111), train_loss = 1.52099128, grad/param norm = 4.9134e-01, time/batch = 0.1783s	
2167/2700 (epoch 40.130), train_loss = 1.55576427, grad/param norm = 4.8881e-01, time/batch = 0.1765s	
2168/2700 (epoch 40.148), train_loss = 1.52666657, grad/param norm = 4.5819e-01, time/batch = 0.1466s	
2169/2700 (epoch 40.167), train_loss = 1.60819565, grad/param norm = 5.1679e-01, time/batch = 0.1683s	
2170/2700 (epoch 40.185), train_loss = 1.51916910, grad/param norm = 4.9342e-01, time/batch = 0.1734s	
2171/2700 (epoch 40.204), train_loss = 1.57708106, grad/param norm = 5.3029e-01, time/batch = 0.1624s	
2172/2700 (epoch 40.222), train_loss = 1.51726718, grad/param norm = 5.1312e-01, time/batch = 0.1732s	
2173/2700 (epoch 40.241), train_loss = 1.44955458, grad/param norm = 5.1065e-01, time/batch = 0.1760s	
2174/2700 (epoch 40.259), train_loss = 1.49991255, grad/param norm = 5.0511e-01, time/batch = 0.1719s	
2175/2700 (epoch 40.278), train_loss = 1.58046846, grad/param norm = 5.1752e-01, time/batch = 0.1634s	
2176/2700 (epoch 40.296), train_loss = 1.55595726, grad/param norm = 4.8144e-01, time/batch = 0.1588s	
2177/2700 (epoch 40.315), train_loss = 1.53741781, grad/param norm = 4.7737e-01, time/batch = 0.1689s	
2178/2700 (epoch 40.333), train_loss = 1.54379718, grad/param norm = 4.7880e-01, time/batch = 0.1597s	
2179/2700 (epoch 40.352), train_loss = 1.55721417, grad/param norm = 5.2998e-01, time/batch = 0.1389s	
2180/2700 (epoch 40.370), train_loss = 1.56105579, grad/param norm = 5.0147e-01, time/batch = 0.1541s	
2181/2700 (epoch 40.389), train_loss = 1.54621930, grad/param norm = 5.1591e-01, time/batch = 0.1318s	
2182/2700 (epoch 40.407), train_loss = 1.58632852, grad/param norm = 4.7654e-01, time/batch = 0.1580s	
2183/2700 (epoch 40.426), train_loss = 1.59949656, grad/param norm = 5.0523e-01, time/batch = 0.1616s	
2184/2700 (epoch 40.444), train_loss = 1.49535421, grad/param norm = 4.7908e-01, time/batch = 0.1672s	
2185/2700 (epoch 40.463), train_loss = 1.59966421, grad/param norm = 5.0568e-01, time/batch = 0.1656s	
2186/2700 (epoch 40.481), train_loss = 1.58790549, grad/param norm = 4.9415e-01, time/batch = 0.1656s	
2187/2700 (epoch 40.500), train_loss = 1.52362924, grad/param norm = 4.8240e-01, time/batch = 0.1543s	
2188/2700 (epoch 40.519), train_loss = 1.58430810, grad/param norm = 4.9495e-01, time/batch = 0.1494s	
2189/2700 (epoch 40.537), train_loss = 1.55187956, grad/param norm = 4.9969e-01, time/batch = 0.1423s	
2190/2700 (epoch 40.556), train_loss = 1.49504760, grad/param norm = 4.7578e-01, time/batch = 0.1241s	
2191/2700 (epoch 40.574), train_loss = 1.49962530, grad/param norm = 4.9292e-01, time/batch = 0.1523s	
2192/2700 (epoch 40.593), train_loss = 1.54551227, grad/param norm = 4.8917e-01, time/batch = 0.1273s	
2193/2700 (epoch 40.611), train_loss = 1.45347592, grad/param norm = 4.5988e-01, time/batch = 0.1615s	
2194/2700 (epoch 40.630), train_loss = 1.49861195, grad/param norm = 4.9384e-01, time/batch = 0.1703s	
2195/2700 (epoch 40.648), train_loss = 1.52681162, grad/param norm = 4.6975e-01, time/batch = 0.1791s	
2196/2700 (epoch 40.667), train_loss = 1.49157095, grad/param norm = 5.0310e-01, time/batch = 0.1754s	
2197/2700 (epoch 40.685), train_loss = 1.53587167, grad/param norm = 5.1688e-01, time/batch = 0.1790s	
2198/2700 (epoch 40.704), train_loss = 1.55522490, grad/param norm = 5.4442e-01, time/batch = 0.1787s	
2199/2700 (epoch 40.722), train_loss = 1.52024668, grad/param norm = 4.5153e-01, time/batch = 0.1799s	
2200/2700 (epoch 40.741), train_loss = 1.55783476, grad/param norm = 4.7074e-01, time/batch = 0.1606s	
2201/2700 (epoch 40.759), train_loss = 1.53329834, grad/param norm = 5.0437e-01, time/batch = 0.1729s	
2202/2700 (epoch 40.778), train_loss = 1.57907819, grad/param norm = 4.7921e-01, time/batch = 0.1647s	
2203/2700 (epoch 40.796), train_loss = 1.53817377, grad/param norm = 5.2416e-01, time/batch = 0.1744s	
2204/2700 (epoch 40.815), train_loss = 1.58377214, grad/param norm = 4.9549e-01, time/batch = 0.1768s	
2205/2700 (epoch 40.833), train_loss = 1.52803567, grad/param norm = 5.0386e-01, time/batch = 0.1748s	
2206/2700 (epoch 40.852), train_loss = 1.53028553, grad/param norm = 4.7994e-01, time/batch = 0.1722s	
2207/2700 (epoch 40.870), train_loss = 1.53695138, grad/param norm = 4.5315e-01, time/batch = 0.1601s	
2208/2700 (epoch 40.889), train_loss = 1.56230901, grad/param norm = 4.9188e-01, time/batch = 0.1531s	
2209/2700 (epoch 40.907), train_loss = 1.67470945, grad/param norm = 5.3080e-01, time/batch = 0.1477s	
2210/2700 (epoch 40.926), train_loss = 1.57985130, grad/param norm = 5.3337e-01, time/batch = 0.1476s	
2211/2700 (epoch 40.944), train_loss = 1.55205381, grad/param norm = 4.7970e-01, time/batch = 0.1451s	
2212/2700 (epoch 40.963), train_loss = 1.59011719, grad/param norm = 4.7790e-01, time/batch = 0.1778s	
2213/2700 (epoch 40.981), train_loss = 1.54646918, grad/param norm = 5.2070e-01, time/batch = 0.1563s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2214/2700 (epoch 41.000), train_loss = 1.62266778, grad/param norm = 4.7153e-01, time/batch = 0.1719s	
2215/2700 (epoch 41.019), train_loss = 1.60575018, grad/param norm = 5.4920e-01, time/batch = 0.1758s	
2216/2700 (epoch 41.037), train_loss = 1.60925469, grad/param norm = 5.2866e-01, time/batch = 0.1753s	
2217/2700 (epoch 41.056), train_loss = 1.53641771, grad/param norm = 4.9529e-01, time/batch = 0.1700s	
2218/2700 (epoch 41.074), train_loss = 1.54438367, grad/param norm = 5.0048e-01, time/batch = 0.1740s	
2219/2700 (epoch 41.093), train_loss = 1.52679754, grad/param norm = 5.1339e-01, time/batch = 0.1455s	
2220/2700 (epoch 41.111), train_loss = 1.51589814, grad/param norm = 4.9110e-01, time/batch = 0.1695s	
2221/2700 (epoch 41.130), train_loss = 1.55014563, grad/param norm = 4.9021e-01, time/batch = 0.1604s	
2222/2700 (epoch 41.148), train_loss = 1.52151442, grad/param norm = 4.5881e-01, time/batch = 0.1541s	
2223/2700 (epoch 41.167), train_loss = 1.60314459, grad/param norm = 5.1766e-01, time/batch = 0.1634s	
2224/2700 (epoch 41.185), train_loss = 1.51380255, grad/param norm = 4.9308e-01, time/batch = 0.1573s	
2225/2700 (epoch 41.204), train_loss = 1.57169447, grad/param norm = 5.2727e-01, time/batch = 0.1449s	
2226/2700 (epoch 41.222), train_loss = 1.51254042, grad/param norm = 5.1472e-01, time/batch = 0.1387s	
2227/2700 (epoch 41.241), train_loss = 1.44460912, grad/param norm = 5.1128e-01, time/batch = 0.1303s	
2228/2700 (epoch 41.259), train_loss = 1.49476837, grad/param norm = 5.0353e-01, time/batch = 0.1371s	
2229/2700 (epoch 41.278), train_loss = 1.57537137, grad/param norm = 5.1333e-01, time/batch = 0.1523s	
2230/2700 (epoch 41.296), train_loss = 1.55111305, grad/param norm = 4.7993e-01, time/batch = 0.1679s	
2231/2700 (epoch 41.315), train_loss = 1.53116248, grad/param norm = 4.7640e-01, time/batch = 0.1436s	
2232/2700 (epoch 41.333), train_loss = 1.53789464, grad/param norm = 4.8185e-01, time/batch = 0.1611s	
2233/2700 (epoch 41.352), train_loss = 1.55142349, grad/param norm = 5.3024e-01, time/batch = 0.1521s	
2234/2700 (epoch 41.370), train_loss = 1.55459538, grad/param norm = 5.0443e-01, time/batch = 0.1547s	
2235/2700 (epoch 41.389), train_loss = 1.54119282, grad/param norm = 5.1931e-01, time/batch = 0.1523s	
2236/2700 (epoch 41.407), train_loss = 1.58071326, grad/param norm = 4.7672e-01, time/batch = 0.1577s	
2237/2700 (epoch 41.426), train_loss = 1.59447796, grad/param norm = 5.0594e-01, time/batch = 0.1657s	
2238/2700 (epoch 41.444), train_loss = 1.49026234, grad/param norm = 4.8230e-01, time/batch = 0.1724s	
2239/2700 (epoch 41.463), train_loss = 1.59459368, grad/param norm = 5.0774e-01, time/batch = 0.1693s	
2240/2700 (epoch 41.481), train_loss = 1.58239169, grad/param norm = 4.9459e-01, time/batch = 0.1617s	
2241/2700 (epoch 41.500), train_loss = 1.51777156, grad/param norm = 4.8450e-01, time/batch = 0.1596s	
2242/2700 (epoch 41.519), train_loss = 1.57945030, grad/param norm = 4.9536e-01, time/batch = 0.1751s	
2243/2700 (epoch 41.537), train_loss = 1.54623399, grad/param norm = 5.0310e-01, time/batch = 0.1704s	
2244/2700 (epoch 41.556), train_loss = 1.48946632, grad/param norm = 4.7633e-01, time/batch = 0.1507s	
2245/2700 (epoch 41.574), train_loss = 1.49413898, grad/param norm = 4.9418e-01, time/batch = 0.1333s	
2246/2700 (epoch 41.593), train_loss = 1.54031314, grad/param norm = 4.9046e-01, time/batch = 0.1527s	
2247/2700 (epoch 41.611), train_loss = 1.44916747, grad/param norm = 4.6107e-01, time/batch = 0.1659s	
2248/2700 (epoch 41.630), train_loss = 1.49339406, grad/param norm = 4.9540e-01, time/batch = 0.1702s	
2249/2700 (epoch 41.648), train_loss = 1.52229705, grad/param norm = 4.7113e-01, time/batch = 0.1825s	
2250/2700 (epoch 41.667), train_loss = 1.48620361, grad/param norm = 5.0684e-01, time/batch = 0.1784s	
2251/2700 (epoch 41.685), train_loss = 1.53074064, grad/param norm = 5.1532e-01, time/batch = 0.1563s	
2252/2700 (epoch 41.704), train_loss = 1.55042469, grad/param norm = 5.4785e-01, time/batch = 0.1728s	
2253/2700 (epoch 41.722), train_loss = 1.51542202, grad/param norm = 4.5266e-01, time/batch = 0.1786s	
2254/2700 (epoch 41.741), train_loss = 1.55221832, grad/param norm = 4.7259e-01, time/batch = 0.1774s	
2255/2700 (epoch 41.759), train_loss = 1.52744043, grad/param norm = 5.0446e-01, time/batch = 0.1435s	
2256/2700 (epoch 41.778), train_loss = 1.57396927, grad/param norm = 4.8190e-01, time/batch = 0.1684s	
2257/2700 (epoch 41.796), train_loss = 1.53287274, grad/param norm = 5.2528e-01, time/batch = 0.1446s	
2258/2700 (epoch 41.815), train_loss = 1.57796091, grad/param norm = 4.9530e-01, time/batch = 0.1417s	
2259/2700 (epoch 41.833), train_loss = 1.52295354, grad/param norm = 5.0216e-01, time/batch = 0.1414s	
2260/2700 (epoch 41.852), train_loss = 1.52486821, grad/param norm = 4.7977e-01, time/batch = 0.1487s	
2261/2700 (epoch 41.870), train_loss = 1.53188528, grad/param norm = 4.5516e-01, time/batch = 0.1656s	
2262/2700 (epoch 41.889), train_loss = 1.55687386, grad/param norm = 4.9352e-01, time/batch = 0.1625s	
2263/2700 (epoch 41.907), train_loss = 1.66909128, grad/param norm = 5.3139e-01, time/batch = 0.1561s	
2264/2700 (epoch 41.926), train_loss = 1.57418686, grad/param norm = 5.3174e-01, time/batch = 0.1485s	
2265/2700 (epoch 41.944), train_loss = 1.54663765, grad/param norm = 4.7972e-01, time/batch = 0.1458s	
2266/2700 (epoch 41.963), train_loss = 1.58447596, grad/param norm = 4.7915e-01, time/batch = 0.1311s	
2267/2700 (epoch 41.981), train_loss = 1.54042442, grad/param norm = 5.2176e-01, time/batch = 0.1435s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2268/2700 (epoch 42.000), train_loss = 1.61784983, grad/param norm = 4.7327e-01, time/batch = 0.1453s	
2269/2700 (epoch 42.019), train_loss = 1.60116320, grad/param norm = 5.5689e-01, time/batch = 0.1599s	
2270/2700 (epoch 42.037), train_loss = 1.60396046, grad/param norm = 5.3133e-01, time/batch = 0.1697s	
2271/2700 (epoch 42.056), train_loss = 1.53172600, grad/param norm = 4.9842e-01, time/batch = 0.1507s	
2272/2700 (epoch 42.074), train_loss = 1.53943146, grad/param norm = 5.0210e-01, time/batch = 0.1491s	
2273/2700 (epoch 42.093), train_loss = 1.52137337, grad/param norm = 5.1322e-01, time/batch = 0.1774s	
2274/2700 (epoch 42.111), train_loss = 1.51090546, grad/param norm = 4.9078e-01, time/batch = 0.1780s	
2275/2700 (epoch 42.130), train_loss = 1.54458797, grad/param norm = 4.9164e-01, time/batch = 0.1750s	
2276/2700 (epoch 42.148), train_loss = 1.51653040, grad/param norm = 4.5930e-01, time/batch = 0.1701s	
2277/2700 (epoch 42.167), train_loss = 1.59818200, grad/param norm = 5.1861e-01, time/batch = 0.1439s	
2278/2700 (epoch 42.185), train_loss = 1.50874481, grad/param norm = 4.9341e-01, time/batch = 0.1530s	
2279/2700 (epoch 42.204), train_loss = 1.56635958, grad/param norm = 5.2504e-01, time/batch = 0.1655s	
2280/2700 (epoch 42.222), train_loss = 1.50779412, grad/param norm = 5.1673e-01, time/batch = 0.1716s	
2281/2700 (epoch 42.241), train_loss = 1.43990525, grad/param norm = 5.1205e-01, time/batch = 0.1605s	
2282/2700 (epoch 42.259), train_loss = 1.48979978, grad/param norm = 5.0169e-01, time/batch = 0.1626s	
2283/2700 (epoch 42.278), train_loss = 1.57059615, grad/param norm = 5.0986e-01, time/batch = 0.1792s	
2284/2700 (epoch 42.296), train_loss = 1.54645497, grad/param norm = 4.7923e-01, time/batch = 0.1673s	
2285/2700 (epoch 42.315), train_loss = 1.52512776, grad/param norm = 4.7619e-01, time/batch = 0.1776s	
2286/2700 (epoch 42.333), train_loss = 1.53209022, grad/param norm = 4.8430e-01, time/batch = 0.1754s	
2287/2700 (epoch 42.352), train_loss = 1.54589102, grad/param norm = 5.2966e-01, time/batch = 0.1719s	
2288/2700 (epoch 42.370), train_loss = 1.54836761, grad/param norm = 5.0850e-01, time/batch = 0.1799s	
2289/2700 (epoch 42.389), train_loss = 1.53634344, grad/param norm = 5.2258e-01, time/batch = 0.1479s	
2290/2700 (epoch 42.407), train_loss = 1.57538197, grad/param norm = 4.7708e-01, time/batch = 0.1778s	
2291/2700 (epoch 42.426), train_loss = 1.58958875, grad/param norm = 5.0695e-01, time/batch = 0.1690s	
2292/2700 (epoch 42.444), train_loss = 1.48556359, grad/param norm = 4.8580e-01, time/batch = 0.1704s	
2293/2700 (epoch 42.463), train_loss = 1.58969162, grad/param norm = 5.0920e-01, time/batch = 0.1773s	
2294/2700 (epoch 42.481), train_loss = 1.57713228, grad/param norm = 4.9544e-01, time/batch = 0.1789s	
2295/2700 (epoch 42.500), train_loss = 1.51213655, grad/param norm = 4.8660e-01, time/batch = 0.1783s	
2296/2700 (epoch 42.519), train_loss = 1.57471539, grad/param norm = 4.9548e-01, time/batch = 0.1777s	
2297/2700 (epoch 42.537), train_loss = 1.54083329, grad/param norm = 5.0662e-01, time/batch = 0.1708s	
2298/2700 (epoch 42.556), train_loss = 1.48405154, grad/param norm = 4.7670e-01, time/batch = 0.1778s	
2299/2700 (epoch 42.574), train_loss = 1.48886514, grad/param norm = 4.9585e-01, time/batch = 0.1741s	
2300/2700 (epoch 42.593), train_loss = 1.53534932, grad/param norm = 4.9180e-01, time/batch = 0.1803s	
2301/2700 (epoch 42.611), train_loss = 1.44504573, grad/param norm = 4.6207e-01, time/batch = 0.1815s	
2302/2700 (epoch 42.630), train_loss = 1.48827097, grad/param norm = 4.9633e-01, time/batch = 0.1769s	
2303/2700 (epoch 42.648), train_loss = 1.51795754, grad/param norm = 4.7266e-01, time/batch = 0.1788s	
2304/2700 (epoch 42.667), train_loss = 1.48112810, grad/param norm = 5.1049e-01, time/batch = 0.1806s	
2305/2700 (epoch 42.685), train_loss = 1.52581333, grad/param norm = 5.1380e-01, time/batch = 0.1796s	
2306/2700 (epoch 42.704), train_loss = 1.54582943, grad/param norm = 5.5126e-01, time/batch = 0.1769s	
2307/2700 (epoch 42.722), train_loss = 1.51076307, grad/param norm = 4.5388e-01, time/batch = 0.1713s	
2308/2700 (epoch 42.741), train_loss = 1.54684214, grad/param norm = 4.7426e-01, time/batch = 0.1756s	
2309/2700 (epoch 42.759), train_loss = 1.52189182, grad/param norm = 5.0474e-01, time/batch = 0.1772s	
2310/2700 (epoch 42.778), train_loss = 1.56906707, grad/param norm = 4.8469e-01, time/batch = 0.1463s	
2311/2700 (epoch 42.796), train_loss = 1.52773850, grad/param norm = 5.2634e-01, time/batch = 0.1594s	
2312/2700 (epoch 42.815), train_loss = 1.57236390, grad/param norm = 4.9519e-01, time/batch = 0.1628s	
2313/2700 (epoch 42.833), train_loss = 1.51812141, grad/param norm = 5.0096e-01, time/batch = 0.1763s	
2314/2700 (epoch 42.852), train_loss = 1.51975296, grad/param norm = 4.8028e-01, time/batch = 0.1766s	
2315/2700 (epoch 42.870), train_loss = 1.52701977, grad/param norm = 4.5730e-01, time/batch = 0.1757s	
2316/2700 (epoch 42.889), train_loss = 1.55159384, grad/param norm = 4.9447e-01, time/batch = 0.1760s	
2317/2700 (epoch 42.907), train_loss = 1.66362017, grad/param norm = 5.3133e-01, time/batch = 0.1766s	
2318/2700 (epoch 42.926), train_loss = 1.56875861, grad/param norm = 5.3019e-01, time/batch = 0.1534s	
2319/2700 (epoch 42.944), train_loss = 1.54141386, grad/param norm = 4.7994e-01, time/batch = 0.1762s	
2320/2700 (epoch 42.963), train_loss = 1.57908315, grad/param norm = 4.8049e-01, time/batch = 0.1712s	
2321/2700 (epoch 42.981), train_loss = 1.53460757, grad/param norm = 5.2268e-01, time/batch = 0.1660s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
2322/2700 (epoch 43.000), train_loss = 1.61318132, grad/param norm = 4.7528e-01, time/batch = 0.1648s	
2323/2700 (epoch 43.019), train_loss = 1.59666533, grad/param norm = 5.6348e-01, time/batch = 0.1670s	
2324/2700 (epoch 43.037), train_loss = 1.59911389, grad/param norm = 5.3240e-01, time/batch = 0.1567s	
2325/2700 (epoch 43.056), train_loss = 1.52669128, grad/param norm = 5.0248e-01, time/batch = 0.1555s	
2326/2700 (epoch 43.074), train_loss = 1.53484535, grad/param norm = 5.0472e-01, time/batch = 0.1638s	
2327/2700 (epoch 43.093), train_loss = 1.51602727, grad/param norm = 5.1337e-01, time/batch = 0.1708s	
2328/2700 (epoch 43.111), train_loss = 1.50620358, grad/param norm = 4.9115e-01, time/batch = 0.1641s	
2329/2700 (epoch 43.130), train_loss = 1.53935948, grad/param norm = 4.9324e-01, time/batch = 0.1708s	
2330/2700 (epoch 43.148), train_loss = 1.51173581, grad/param norm = 4.6010e-01, time/batch = 0.1587s	
2331/2700 (epoch 43.167), train_loss = 1.59344895, grad/param norm = 5.1949e-01, time/batch = 0.1666s	
2332/2700 (epoch 43.185), train_loss = 1.50377520, grad/param norm = 4.9400e-01, time/batch = 0.1735s	
2333/2700 (epoch 43.204), train_loss = 1.56135824, grad/param norm = 5.2351e-01, time/batch = 0.1781s	
2334/2700 (epoch 43.222), train_loss = 1.50337574, grad/param norm = 5.1952e-01, time/batch = 0.1716s	
2335/2700 (epoch 43.241), train_loss = 1.43529921, grad/param norm = 5.1189e-01, time/batch = 0.1662s	
2336/2700 (epoch 43.259), train_loss = 1.48504480, grad/param norm = 5.0011e-01, time/batch = 0.1622s	
2337/2700 (epoch 43.278), train_loss = 1.56587563, grad/param norm = 5.0653e-01, time/batch = 0.1552s	
2338/2700 (epoch 43.296), train_loss = 1.54195019, grad/param norm = 4.7868e-01, time/batch = 0.1506s	
2339/2700 (epoch 43.315), train_loss = 1.51929945, grad/param norm = 4.7602e-01, time/batch = 0.1284s	
2340/2700 (epoch 43.333), train_loss = 1.52666021, grad/param norm = 4.8718e-01, time/batch = 0.1430s	
2341/2700 (epoch 43.352), train_loss = 1.54047433, grad/param norm = 5.2928e-01, time/batch = 0.1337s	
2342/2700 (epoch 43.370), train_loss = 1.54243282, grad/param norm = 5.1279e-01, time/batch = 0.1316s	
2343/2700 (epoch 43.389), train_loss = 1.53172198, grad/param norm = 5.2534e-01, time/batch = 0.1497s	
2344/2700 (epoch 43.407), train_loss = 1.57025510, grad/param norm = 4.7758e-01, time/batch = 0.1651s	
2345/2700 (epoch 43.426), train_loss = 1.58499329, grad/param norm = 5.0805e-01, time/batch = 0.1558s	
2346/2700 (epoch 43.444), train_loss = 1.48090736, grad/param norm = 4.8883e-01, time/batch = 0.1554s	
2347/2700 (epoch 43.463), train_loss = 1.58495718, grad/param norm = 5.1042e-01, time/batch = 0.1638s	
2348/2700 (epoch 43.481), train_loss = 1.57202845, grad/param norm = 4.9644e-01, time/batch = 0.1712s	
2349/2700 (epoch 43.500), train_loss = 1.50674729, grad/param norm = 4.8838e-01, time/batch = 0.1683s	
2350/2700 (epoch 43.519), train_loss = 1.57015245, grad/param norm = 4.9573e-01, time/batch = 0.1783s	
2351/2700 (epoch 43.537), train_loss = 1.53567127, grad/param norm = 5.1002e-01, time/batch = 0.1654s	
2352/2700 (epoch 43.556), train_loss = 1.47885506, grad/param norm = 4.7702e-01, time/batch = 0.1776s	
2353/2700 (epoch 43.574), train_loss = 1.48382031, grad/param norm = 4.9740e-01, time/batch = 0.1652s	
2354/2700 (epoch 43.593), train_loss = 1.53054229, grad/param norm = 4.9299e-01, time/batch = 0.1781s	
2355/2700 (epoch 43.611), train_loss = 1.44097870, grad/param norm = 4.6311e-01, time/batch = 0.1743s	
2356/2700 (epoch 43.630), train_loss = 1.48339015, grad/param norm = 4.9748e-01, time/batch = 0.1687s	
2357/2700 (epoch 43.648), train_loss = 1.51379974, grad/param norm = 4.7446e-01, time/batch = 0.1690s	
2358/2700 (epoch 43.667), train_loss = 1.47619946, grad/param norm = 5.1380e-01, time/batch = 0.1632s	
2359/2700 (epoch 43.685), train_loss = 1.52095437, grad/param norm = 5.1236e-01, time/batch = 0.1577s	
2360/2700 (epoch 43.704), train_loss = 1.54134767, grad/param norm = 5.5426e-01, time/batch = 0.1496s	
2361/2700 (epoch 43.722), train_loss = 1.50631841, grad/param norm = 4.5506e-01, time/batch = 0.1804s	
2362/2700 (epoch 43.741), train_loss = 1.54159731, grad/param norm = 4.7584e-01, time/batch = 0.1810s	
2363/2700 (epoch 43.759), train_loss = 1.51654567, grad/param norm = 5.0465e-01, time/batch = 0.1725s	
2364/2700 (epoch 43.778), train_loss = 1.56439105, grad/param norm = 4.8748e-01, time/batch = 0.1508s	
2365/2700 (epoch 43.796), train_loss = 1.52286318, grad/param norm = 5.2715e-01, time/batch = 0.1720s	
2366/2700 (epoch 43.815), train_loss = 1.56696797, grad/param norm = 4.9513e-01, time/batch = 0.1711s	
2367/2700 (epoch 43.833), train_loss = 1.51355187, grad/param norm = 5.0012e-01, time/batch = 0.1716s	
2368/2700 (epoch 43.852), train_loss = 1.51480867, grad/param norm = 4.8122e-01, time/batch = 0.1648s	
2369/2700 (epoch 43.870), train_loss = 1.52238071, grad/param norm = 4.5945e-01, time/batch = 0.1630s	
2370/2700 (epoch 43.889), train_loss = 1.54649490, grad/param norm = 4.9488e-01, time/batch = 0.1446s	
2371/2700 (epoch 43.907), train_loss = 1.65832295, grad/param norm = 5.3114e-01, time/batch = 0.1796s	
2372/2700 (epoch 43.926), train_loss = 1.56353458, grad/param norm = 5.2885e-01, time/batch = 0.1786s	
2373/2700 (epoch 43.944), train_loss = 1.53642062, grad/param norm = 4.8062e-01, time/batch = 0.1738s	
2374/2700 (epoch 43.963), train_loss = 1.57391464, grad/param norm = 4.8200e-01, time/batch = 0.1549s	
2375/2700 (epoch 43.981), train_loss = 1.52898054, grad/param norm = 5.2331e-01, time/batch = 0.1622s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
2376/2700 (epoch 44.000), train_loss = 1.60869119, grad/param norm = 4.7764e-01, time/batch = 0.1359s	
2377/2700 (epoch 44.019), train_loss = 1.59240827, grad/param norm = 5.7062e-01, time/batch = 0.1252s	
2378/2700 (epoch 44.037), train_loss = 1.59415971, grad/param norm = 5.3404e-01, time/batch = 0.1368s	
2379/2700 (epoch 44.056), train_loss = 1.52238171, grad/param norm = 5.0623e-01, time/batch = 0.1535s	
2380/2700 (epoch 44.074), train_loss = 1.53027243, grad/param norm = 5.0642e-01, time/batch = 0.1505s	
2381/2700 (epoch 44.093), train_loss = 1.51093438, grad/param norm = 5.1306e-01, time/batch = 0.1733s	
2382/2700 (epoch 44.111), train_loss = 1.50159328, grad/param norm = 4.9146e-01, time/batch = 0.1792s	
2383/2700 (epoch 44.130), train_loss = 1.53419567, grad/param norm = 4.9495e-01, time/batch = 0.1782s	
2384/2700 (epoch 44.148), train_loss = 1.50709785, grad/param norm = 4.6085e-01, time/batch = 0.1601s	
2385/2700 (epoch 44.167), train_loss = 1.58878645, grad/param norm = 5.2040e-01, time/batch = 0.1505s	
2386/2700 (epoch 44.185), train_loss = 1.49910145, grad/param norm = 4.9524e-01, time/batch = 0.1545s	
2387/2700 (epoch 44.204), train_loss = 1.55641136, grad/param norm = 5.2259e-01, time/batch = 0.1470s	
2388/2700 (epoch 44.222), train_loss = 1.49892211, grad/param norm = 5.2250e-01, time/batch = 0.1526s	
2389/2700 (epoch 44.241), train_loss = 1.43091790, grad/param norm = 5.1187e-01, time/batch = 0.1640s	
2390/2700 (epoch 44.259), train_loss = 1.48045743, grad/param norm = 4.9848e-01, time/batch = 0.1632s	
2391/2700 (epoch 44.278), train_loss = 1.56145788, grad/param norm = 5.0408e-01, time/batch = 0.1510s	
2392/2700 (epoch 44.296), train_loss = 1.53761843, grad/param norm = 4.7884e-01, time/batch = 0.1528s	
2393/2700 (epoch 44.315), train_loss = 1.51366159, grad/param norm = 4.7637e-01, time/batch = 0.1464s	
2394/2700 (epoch 44.333), train_loss = 1.52129122, grad/param norm = 4.8906e-01, time/batch = 0.1361s	
2395/2700 (epoch 44.352), train_loss = 1.53529701, grad/param norm = 5.2820e-01, time/batch = 0.1655s	
2396/2700 (epoch 44.370), train_loss = 1.53671334, grad/param norm = 5.1817e-01, time/batch = 0.1606s	
2397/2700 (epoch 44.389), train_loss = 1.52725691, grad/param norm = 5.2800e-01, time/batch = 0.1457s	
2398/2700 (epoch 44.407), train_loss = 1.56539896, grad/param norm = 4.7842e-01, time/batch = 0.1535s	
2399/2700 (epoch 44.426), train_loss = 1.58051053, grad/param norm = 5.0947e-01, time/batch = 0.1676s	
2400/2700 (epoch 44.444), train_loss = 1.47659945, grad/param norm = 4.9186e-01, time/batch = 0.1750s	
2401/2700 (epoch 44.463), train_loss = 1.58038565, grad/param norm = 5.1113e-01, time/batch = 0.1420s	
2402/2700 (epoch 44.481), train_loss = 1.56716792, grad/param norm = 4.9786e-01, time/batch = 0.1731s	
2403/2700 (epoch 44.500), train_loss = 1.50154617, grad/param norm = 4.9009e-01, time/batch = 0.1766s	
2404/2700 (epoch 44.519), train_loss = 1.56569609, grad/param norm = 4.9569e-01, time/batch = 0.1708s	
2405/2700 (epoch 44.537), train_loss = 1.53071500, grad/param norm = 5.1352e-01, time/batch = 0.1744s	
2406/2700 (epoch 44.556), train_loss = 1.47380976, grad/param norm = 4.7715e-01, time/batch = 0.1682s	
2407/2700 (epoch 44.574), train_loss = 1.47895549, grad/param norm = 4.9933e-01, time/batch = 0.1542s	
2408/2700 (epoch 44.593), train_loss = 1.52595846, grad/param norm = 4.9416e-01, time/batch = 0.1420s	
2409/2700 (epoch 44.611), train_loss = 1.43707967, grad/param norm = 4.6396e-01, time/batch = 0.1370s	
2410/2700 (epoch 44.630), train_loss = 1.47858543, grad/param norm = 4.9806e-01, time/batch = 0.1507s	
2411/2700 (epoch 44.648), train_loss = 1.50979091, grad/param norm = 4.7642e-01, time/batch = 0.1420s	
2412/2700 (epoch 44.667), train_loss = 1.47153070, grad/param norm = 5.1683e-01, time/batch = 0.1432s	
2413/2700 (epoch 44.685), train_loss = 1.51628479, grad/param norm = 5.1102e-01, time/batch = 0.1435s	
2414/2700 (epoch 44.704), train_loss = 1.53704926, grad/param norm = 5.5711e-01, time/batch = 0.1495s	
2415/2700 (epoch 44.722), train_loss = 1.50201483, grad/param norm = 4.5630e-01, time/batch = 0.1479s	
2416/2700 (epoch 44.741), train_loss = 1.53656715, grad/param norm = 4.7724e-01, time/batch = 0.1719s	
2417/2700 (epoch 44.759), train_loss = 1.51146985, grad/param norm = 5.0474e-01, time/batch = 0.1715s	
2418/2700 (epoch 44.778), train_loss = 1.55989044, grad/param norm = 4.9032e-01, time/batch = 0.1724s	
2419/2700 (epoch 44.796), train_loss = 1.51812475, grad/param norm = 5.2799e-01, time/batch = 0.1495s	
2420/2700 (epoch 44.815), train_loss = 1.56178619, grad/param norm = 4.9524e-01, time/batch = 0.1613s	
2421/2700 (epoch 44.833), train_loss = 1.50920336, grad/param norm = 4.9974e-01, time/batch = 0.1560s	
2422/2700 (epoch 44.852), train_loss = 1.51012885, grad/param norm = 4.8244e-01, time/batch = 0.1522s	
2423/2700 (epoch 44.870), train_loss = 1.51790578, grad/param norm = 4.6145e-01, time/batch = 0.1634s	
2424/2700 (epoch 44.889), train_loss = 1.54153650, grad/param norm = 4.9502e-01, time/batch = 0.1726s	
2425/2700 (epoch 44.907), train_loss = 1.65317242, grad/param norm = 5.3088e-01, time/batch = 0.1698s	
2426/2700 (epoch 44.926), train_loss = 1.55853786, grad/param norm = 5.2772e-01, time/batch = 0.1736s	
2427/2700 (epoch 44.944), train_loss = 1.53160761, grad/param norm = 4.8137e-01, time/batch = 0.1684s	
2428/2700 (epoch 44.963), train_loss = 1.56896516, grad/param norm = 4.8353e-01, time/batch = 0.1638s	
2429/2700 (epoch 44.981), train_loss = 1.52355495, grad/param norm = 5.2382e-01, time/batch = 0.1506s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
2430/2700 (epoch 45.000), train_loss = 1.60434174, grad/param norm = 4.8028e-01, time/batch = 0.1534s	
2431/2700 (epoch 45.019), train_loss = 1.58822420, grad/param norm = 5.7653e-01, time/batch = 0.1794s	
2432/2700 (epoch 45.037), train_loss = 1.58966012, grad/param norm = 5.3451e-01, time/batch = 0.1781s	
2433/2700 (epoch 45.056), train_loss = 1.51773548, grad/param norm = 5.1065e-01, time/batch = 0.1560s	
2434/2700 (epoch 45.074), train_loss = 1.52606548, grad/param norm = 5.0917e-01, time/batch = 0.1718s	
2435/2700 (epoch 45.093), train_loss = 1.50593430, grad/param norm = 5.1319e-01, time/batch = 0.1479s	
2436/2700 (epoch 45.111), train_loss = 1.49723642, grad/param norm = 4.9231e-01, time/batch = 0.1436s	
2437/2700 (epoch 45.130), train_loss = 1.52933221, grad/param norm = 4.9668e-01, time/batch = 0.1548s	
2438/2700 (epoch 45.148), train_loss = 1.50264775, grad/param norm = 4.6189e-01, time/batch = 0.1579s	
2439/2700 (epoch 45.167), train_loss = 1.58436486, grad/param norm = 5.2140e-01, time/batch = 0.1603s	
2440/2700 (epoch 45.185), train_loss = 1.49450849, grad/param norm = 4.9666e-01, time/batch = 0.1493s	
2441/2700 (epoch 45.204), train_loss = 1.55175745, grad/param norm = 5.2211e-01, time/batch = 0.1734s	
2442/2700 (epoch 45.222), train_loss = 1.49477766, grad/param norm = 5.2595e-01, time/batch = 0.1772s	
2443/2700 (epoch 45.241), train_loss = 1.42663250, grad/param norm = 5.1113e-01, time/batch = 0.1691s	
2444/2700 (epoch 45.259), train_loss = 1.47606658, grad/param norm = 4.9735e-01, time/batch = 0.1815s	
2445/2700 (epoch 45.278), train_loss = 1.55707880, grad/param norm = 5.0181e-01, time/batch = 0.1698s	
2446/2700 (epoch 45.296), train_loss = 1.53342051, grad/param norm = 4.7904e-01, time/batch = 0.1682s	
2447/2700 (epoch 45.315), train_loss = 1.50822192, grad/param norm = 4.7660e-01, time/batch = 0.1496s	
2448/2700 (epoch 45.333), train_loss = 1.51626637, grad/param norm = 4.9137e-01, time/batch = 0.1481s	
2449/2700 (epoch 45.352), train_loss = 1.53022789, grad/param norm = 5.2747e-01, time/batch = 0.1528s	
2450/2700 (epoch 45.370), train_loss = 1.53125490, grad/param norm = 5.2354e-01, time/batch = 0.1502s	
2451/2700 (epoch 45.389), train_loss = 1.52298424, grad/param norm = 5.3006e-01, time/batch = 0.1499s	
2452/2700 (epoch 45.407), train_loss = 1.56073005, grad/param norm = 4.7950e-01, time/batch = 0.1787s	
2453/2700 (epoch 45.426), train_loss = 1.57627575, grad/param norm = 5.1068e-01, time/batch = 0.1802s	
2454/2700 (epoch 45.444), train_loss = 1.47231323, grad/param norm = 4.9463e-01, time/batch = 0.1593s	
2455/2700 (epoch 45.463), train_loss = 1.57596907, grad/param norm = 5.1178e-01, time/batch = 0.1552s	
2456/2700 (epoch 45.481), train_loss = 1.56245481, grad/param norm = 4.9931e-01, time/batch = 0.1328s	
2457/2700 (epoch 45.500), train_loss = 1.49657001, grad/param norm = 4.9152e-01, time/batch = 0.1385s	
2458/2700 (epoch 45.519), train_loss = 1.56139826, grad/param norm = 4.9588e-01, time/batch = 0.1290s	
2459/2700 (epoch 45.537), train_loss = 1.52596607, grad/param norm = 5.1677e-01, time/batch = 0.1377s	
2460/2700 (epoch 45.556), train_loss = 1.46896135, grad/param norm = 4.7726e-01, time/batch = 0.1503s	
2461/2700 (epoch 45.574), train_loss = 1.47429727, grad/param norm = 5.0112e-01, time/batch = 0.1584s	
2462/2700 (epoch 45.593), train_loss = 1.52151555, grad/param norm = 4.9519e-01, time/batch = 0.1368s	
2463/2700 (epoch 45.611), train_loss = 1.43323144, grad/param norm = 4.6488e-01, time/batch = 0.1435s	
2464/2700 (epoch 45.630), train_loss = 1.47400450, grad/param norm = 4.9884e-01, time/batch = 0.1336s	
2465/2700 (epoch 45.648), train_loss = 1.50594760, grad/param norm = 4.7858e-01, time/batch = 0.1291s	
2466/2700 (epoch 45.667), train_loss = 1.46698502, grad/param norm = 5.1949e-01, time/batch = 0.1457s	
2467/2700 (epoch 45.685), train_loss = 1.51168358, grad/param norm = 5.0983e-01, time/batch = 0.1628s	
2468/2700 (epoch 45.704), train_loss = 1.53284544, grad/param norm = 5.5947e-01, time/batch = 0.1783s	
2469/2700 (epoch 45.722), train_loss = 1.49790917, grad/param norm = 4.5756e-01, time/batch = 0.1776s	
2470/2700 (epoch 45.741), train_loss = 1.53164822, grad/param norm = 4.7854e-01, time/batch = 0.1776s	
2471/2700 (epoch 45.759), train_loss = 1.50657442, grad/param norm = 5.0457e-01, time/batch = 0.1601s	
2472/2700 (epoch 45.778), train_loss = 1.55558886, grad/param norm = 4.9320e-01, time/batch = 0.1652s	
2473/2700 (epoch 45.796), train_loss = 1.51361590, grad/param norm = 5.2860e-01, time/batch = 0.1494s	
2474/2700 (epoch 45.815), train_loss = 1.55680306, grad/param norm = 4.9548e-01, time/batch = 0.1642s	
2475/2700 (epoch 45.833), train_loss = 1.50508228, grad/param norm = 4.9962e-01, time/batch = 0.1532s	
2476/2700 (epoch 45.852), train_loss = 1.50559179, grad/param norm = 4.8380e-01, time/batch = 0.1296s	
2477/2700 (epoch 45.870), train_loss = 1.51361881, grad/param norm = 4.6333e-01, time/batch = 0.1448s	
2478/2700 (epoch 45.889), train_loss = 1.53675507, grad/param norm = 4.9508e-01, time/batch = 0.1464s	
2479/2700 (epoch 45.907), train_loss = 1.64820047, grad/param norm = 5.3087e-01, time/batch = 0.1733s	
2480/2700 (epoch 45.926), train_loss = 1.55372969, grad/param norm = 5.2685e-01, time/batch = 0.1755s	
2481/2700 (epoch 45.944), train_loss = 1.52700640, grad/param norm = 4.8242e-01, time/batch = 0.1705s	
2482/2700 (epoch 45.963), train_loss = 1.56421230, grad/param norm = 4.8516e-01, time/batch = 0.1783s	
2483/2700 (epoch 45.981), train_loss = 1.51830021, grad/param norm = 5.2413e-01, time/batch = 0.1782s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
2484/2700 (epoch 46.000), train_loss = 1.60016203, grad/param norm = 4.8327e-01, time/batch = 0.1661s	
2485/2700 (epoch 46.019), train_loss = 1.58425828, grad/param norm = 5.8247e-01, time/batch = 0.1681s	
2486/2700 (epoch 46.037), train_loss = 1.58499282, grad/param norm = 5.3535e-01, time/batch = 0.1499s	
2487/2700 (epoch 46.056), train_loss = 1.51375231, grad/param norm = 5.1469e-01, time/batch = 0.1577s	
2488/2700 (epoch 46.074), train_loss = 1.52184401, grad/param norm = 5.1095e-01, time/batch = 0.1553s	
2489/2700 (epoch 46.093), train_loss = 1.50116954, grad/param norm = 5.1292e-01, time/batch = 0.1772s	
2490/2700 (epoch 46.111), train_loss = 1.49295898, grad/param norm = 4.9312e-01, time/batch = 0.1783s	
2491/2700 (epoch 46.130), train_loss = 1.52453032, grad/param norm = 4.9857e-01, time/batch = 0.1636s	
2492/2700 (epoch 46.148), train_loss = 1.49833853, grad/param norm = 4.6291e-01, time/batch = 0.1750s	
2493/2700 (epoch 46.167), train_loss = 1.57999690, grad/param norm = 5.2233e-01, time/batch = 0.1787s	
2494/2700 (epoch 46.185), train_loss = 1.49019871, grad/param norm = 4.9865e-01, time/batch = 0.1772s	
2495/2700 (epoch 46.204), train_loss = 1.54716202, grad/param norm = 5.2203e-01, time/batch = 0.1722s	
2496/2700 (epoch 46.222), train_loss = 1.49058616, grad/param norm = 5.2947e-01, time/batch = 0.1737s	
2497/2700 (epoch 46.241), train_loss = 1.42256386, grad/param norm = 5.1058e-01, time/batch = 0.1784s	
2498/2700 (epoch 46.259), train_loss = 1.47183117, grad/param norm = 4.9620e-01, time/batch = 0.1704s	
2499/2700 (epoch 46.278), train_loss = 1.55298281, grad/param norm = 5.0035e-01, time/batch = 0.1603s	
2500/2700 (epoch 46.296), train_loss = 1.52938367, grad/param norm = 4.7977e-01, time/batch = 0.1505s	
2501/2700 (epoch 46.315), train_loss = 1.50294966, grad/param norm = 4.7720e-01, time/batch = 0.1818s	
2502/2700 (epoch 46.333), train_loss = 1.51128093, grad/param norm = 4.9267e-01, time/batch = 0.1799s	
2503/2700 (epoch 46.352), train_loss = 1.52539576, grad/param norm = 5.2636e-01, time/batch = 0.1798s	
2504/2700 (epoch 46.370), train_loss = 1.52599374, grad/param norm = 5.2980e-01, time/batch = 0.1796s	
2505/2700 (epoch 46.389), train_loss = 1.51884393, grad/param norm = 5.3196e-01, time/batch = 0.1745s	
2506/2700 (epoch 46.407), train_loss = 1.55630785, grad/param norm = 4.8097e-01, time/batch = 0.1437s	
2507/2700 (epoch 46.426), train_loss = 1.57213167, grad/param norm = 5.1211e-01, time/batch = 0.1700s	
2508/2700 (epoch 46.444), train_loss = 1.46834422, grad/param norm = 4.9728e-01, time/batch = 0.1643s	
2509/2700 (epoch 46.463), train_loss = 1.57171582, grad/param norm = 5.1208e-01, time/batch = 0.1548s	
2510/2700 (epoch 46.481), train_loss = 1.55797230, grad/param norm = 5.0112e-01, time/batch = 0.1442s	
2511/2700 (epoch 46.500), train_loss = 1.49175366, grad/param norm = 4.9286e-01, time/batch = 0.1801s	
2512/2700 (epoch 46.519), train_loss = 1.55719679, grad/param norm = 4.9579e-01, time/batch = 0.1789s	
2513/2700 (epoch 46.537), train_loss = 1.52139098, grad/param norm = 5.2010e-01, time/batch = 0.1794s	
2514/2700 (epoch 46.556), train_loss = 1.46425268, grad/param norm = 4.7720e-01, time/batch = 0.1789s	
2515/2700 (epoch 46.574), train_loss = 1.46979649, grad/param norm = 5.0323e-01, time/batch = 0.1782s	
2516/2700 (epoch 46.593), train_loss = 1.51728666, grad/param norm = 4.9619e-01, time/batch = 0.1692s	
2517/2700 (epoch 46.611), train_loss = 1.42953659, grad/param norm = 4.6563e-01, time/batch = 0.1717s	
2518/2700 (epoch 46.630), train_loss = 1.46948583, grad/param norm = 4.9912e-01, time/batch = 0.1623s	
2519/2700 (epoch 46.648), train_loss = 1.50222979, grad/param norm = 4.8088e-01, time/batch = 0.1546s	
2520/2700 (epoch 46.667), train_loss = 1.46267425, grad/param norm = 5.2178e-01, time/batch = 0.1442s	
2521/2700 (epoch 46.685), train_loss = 1.50726254, grad/param norm = 5.0881e-01, time/batch = 0.1803s	
2522/2700 (epoch 46.704), train_loss = 1.52881251, grad/param norm = 5.6165e-01, time/batch = 0.1798s	
2523/2700 (epoch 46.722), train_loss = 1.49393091, grad/param norm = 4.5889e-01, time/batch = 0.1800s	
2524/2700 (epoch 46.741), train_loss = 1.52692456, grad/param norm = 4.7968e-01, time/batch = 0.1796s	
2525/2700 (epoch 46.759), train_loss = 1.50191478, grad/param norm = 5.0461e-01, time/batch = 0.1788s	
2526/2700 (epoch 46.778), train_loss = 1.55143445, grad/param norm = 4.9608e-01, time/batch = 0.1676s	
2527/2700 (epoch 46.796), train_loss = 1.50922141, grad/param norm = 5.2931e-01, time/batch = 0.1391s	
2528/2700 (epoch 46.815), train_loss = 1.55203011, grad/param norm = 4.9595e-01, time/batch = 0.1774s	
2529/2700 (epoch 46.833), train_loss = 1.50115192, grad/param norm = 4.9990e-01, time/batch = 0.1622s	
2530/2700 (epoch 46.852), train_loss = 1.50129063, grad/param norm = 4.8518e-01, time/batch = 0.1617s	
2531/2700 (epoch 46.870), train_loss = 1.50946934, grad/param norm = 4.6502e-01, time/batch = 0.1765s	
2532/2700 (epoch 46.889), train_loss = 1.53210601, grad/param norm = 4.9518e-01, time/batch = 0.1771s	
2533/2700 (epoch 46.907), train_loss = 1.64336271, grad/param norm = 5.3099e-01, time/batch = 0.1777s	
2534/2700 (epoch 46.926), train_loss = 1.54912798, grad/param norm = 5.2615e-01, time/batch = 0.1759s	
2535/2700 (epoch 46.944), train_loss = 1.52256693, grad/param norm = 4.8342e-01, time/batch = 0.1694s	
2536/2700 (epoch 46.963), train_loss = 1.55965245, grad/param norm = 4.8675e-01, time/batch = 0.1591s	
2537/2700 (epoch 46.981), train_loss = 1.51322503, grad/param norm = 5.2429e-01, time/batch = 0.1609s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
2538/2700 (epoch 47.000), train_loss = 1.59611250, grad/param norm = 4.8647e-01, time/batch = 0.1530s	
2539/2700 (epoch 47.019), train_loss = 1.58035310, grad/param norm = 5.8730e-01, time/batch = 0.1204s	
2540/2700 (epoch 47.037), train_loss = 1.58079777, grad/param norm = 5.3548e-01, time/batch = 0.1519s	
2541/2700 (epoch 47.056), train_loss = 1.50943709, grad/param norm = 5.1908e-01, time/batch = 0.1552s	
2542/2700 (epoch 47.074), train_loss = 1.51798744, grad/param norm = 5.1382e-01, time/batch = 0.1634s	
2543/2700 (epoch 47.093), train_loss = 1.49650508, grad/param norm = 5.1306e-01, time/batch = 0.1662s	
2544/2700 (epoch 47.111), train_loss = 1.48890674, grad/param norm = 4.9433e-01, time/batch = 0.1635s	
2545/2700 (epoch 47.130), train_loss = 1.52000941, grad/param norm = 5.0037e-01, time/batch = 0.1588s	
2546/2700 (epoch 47.148), train_loss = 1.49421214, grad/param norm = 4.6417e-01, time/batch = 0.1516s	
2547/2700 (epoch 47.167), train_loss = 1.57588046, grad/param norm = 5.2344e-01, time/batch = 0.1360s	
2548/2700 (epoch 47.185), train_loss = 1.48595706, grad/param norm = 5.0066e-01, time/batch = 0.1600s	
2549/2700 (epoch 47.204), train_loss = 1.54283023, grad/param norm = 5.2217e-01, time/batch = 0.1427s	
2550/2700 (epoch 47.222), train_loss = 1.48669132, grad/param norm = 5.3323e-01, time/batch = 0.1369s	
2551/2700 (epoch 47.241), train_loss = 1.41858684, grad/param norm = 5.0952e-01, time/batch = 0.1588s	
2552/2700 (epoch 47.259), train_loss = 1.46777519, grad/param norm = 4.9565e-01, time/batch = 0.1579s	
2553/2700 (epoch 47.278), train_loss = 1.54890806, grad/param norm = 4.9899e-01, time/batch = 0.1653s	
2554/2700 (epoch 47.296), train_loss = 1.52546846, grad/param norm = 4.8043e-01, time/batch = 0.1746s	
2555/2700 (epoch 47.315), train_loss = 1.49787314, grad/param norm = 4.7760e-01, time/batch = 0.1767s	
2556/2700 (epoch 47.333), train_loss = 1.50662172, grad/param norm = 4.9455e-01, time/batch = 0.1785s	
2557/2700 (epoch 47.352), train_loss = 1.52066668, grad/param norm = 5.2561e-01, time/batch = 0.1728s	
2558/2700 (epoch 47.370), train_loss = 1.52096284, grad/param norm = 5.3581e-01, time/batch = 0.1755s	
2559/2700 (epoch 47.389), train_loss = 1.51485943, grad/param norm = 5.3322e-01, time/batch = 0.1602s	
2560/2700 (epoch 47.407), train_loss = 1.55204742, grad/param norm = 4.8268e-01, time/batch = 0.1395s	
2561/2700 (epoch 47.426), train_loss = 1.56819857, grad/param norm = 5.1307e-01, time/batch = 0.1804s	
2562/2700 (epoch 47.444), train_loss = 1.46437940, grad/param norm = 4.9991e-01, time/batch = 0.1797s	
2563/2700 (epoch 47.463), train_loss = 1.56760255, grad/param norm = 5.1244e-01, time/batch = 0.1801s	
2564/2700 (epoch 47.481), train_loss = 1.55362534, grad/param norm = 5.0283e-01, time/batch = 0.1794s	
2565/2700 (epoch 47.500), train_loss = 1.48714569, grad/param norm = 4.9397e-01, time/batch = 0.1759s	
2566/2700 (epoch 47.519), train_loss = 1.55314485, grad/param norm = 4.9600e-01, time/batch = 0.1619s	
2567/2700 (epoch 47.537), train_loss = 1.51699869, grad/param norm = 5.2309e-01, time/batch = 0.1494s	
2568/2700 (epoch 47.556), train_loss = 1.45972695, grad/param norm = 4.7716e-01, time/batch = 0.1546s	
2569/2700 (epoch 47.574), train_loss = 1.46548717, grad/param norm = 5.0514e-01, time/batch = 0.1624s	
2570/2700 (epoch 47.593), train_loss = 1.51318114, grad/param norm = 4.9708e-01, time/batch = 0.1494s	
2571/2700 (epoch 47.611), train_loss = 1.42589073, grad/param norm = 4.6647e-01, time/batch = 0.1794s	
2572/2700 (epoch 47.630), train_loss = 1.46518046, grad/param norm = 4.9961e-01, time/batch = 0.1790s	
2573/2700 (epoch 47.648), train_loss = 1.49866505, grad/param norm = 4.8331e-01, time/batch = 0.1783s	
2574/2700 (epoch 47.667), train_loss = 1.45846829, grad/param norm = 5.2375e-01, time/batch = 0.1799s	
2575/2700 (epoch 47.685), train_loss = 1.50291287, grad/param norm = 5.0801e-01, time/batch = 0.1790s	
2576/2700 (epoch 47.704), train_loss = 1.52486128, grad/param norm = 5.6333e-01, time/batch = 0.1789s	
2577/2700 (epoch 47.722), train_loss = 1.49014116, grad/param norm = 4.6028e-01, time/batch = 0.1771s	
2578/2700 (epoch 47.741), train_loss = 1.52229722, grad/param norm = 4.8070e-01, time/batch = 0.1804s	
2579/2700 (epoch 47.759), train_loss = 1.49741722, grad/param norm = 5.0446e-01, time/batch = 0.1795s	
2580/2700 (epoch 47.778), train_loss = 1.54745505, grad/param norm = 4.9900e-01, time/batch = 0.1674s	
2581/2700 (epoch 47.796), train_loss = 1.50503401, grad/param norm = 5.2980e-01, time/batch = 0.1491s	
2582/2700 (epoch 47.815), train_loss = 1.54744705, grad/param norm = 4.9659e-01, time/batch = 0.1648s	
2583/2700 (epoch 47.833), train_loss = 1.49741497, grad/param norm = 5.0035e-01, time/batch = 0.1729s	
2584/2700 (epoch 47.852), train_loss = 1.49711289, grad/param norm = 4.8656e-01, time/batch = 0.1768s	
2585/2700 (epoch 47.870), train_loss = 1.50548019, grad/param norm = 4.6661e-01, time/batch = 0.1778s	
2586/2700 (epoch 47.889), train_loss = 1.52762962, grad/param norm = 4.9542e-01, time/batch = 0.1753s	
2587/2700 (epoch 47.907), train_loss = 1.63869617, grad/param norm = 5.3145e-01, time/batch = 0.1695s	
2588/2700 (epoch 47.926), train_loss = 1.54469226, grad/param norm = 5.2567e-01, time/batch = 0.1783s	
2589/2700 (epoch 47.944), train_loss = 1.51831889, grad/param norm = 4.8462e-01, time/batch = 0.1782s	
2590/2700 (epoch 47.963), train_loss = 1.55526567, grad/param norm = 4.8842e-01, time/batch = 0.1780s	
2591/2700 (epoch 47.981), train_loss = 1.50830699, grad/param norm = 5.2435e-01, time/batch = 0.1464s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
2592/2700 (epoch 48.000), train_loss = 1.59222100, grad/param norm = 4.8995e-01, time/batch = 0.1644s	
2593/2700 (epoch 48.019), train_loss = 1.57664662, grad/param norm = 5.9171e-01, time/batch = 0.1534s	
2594/2700 (epoch 48.037), train_loss = 1.57638973, grad/param norm = 5.3592e-01, time/batch = 0.1395s	
2595/2700 (epoch 48.056), train_loss = 1.50573617, grad/param norm = 5.2295e-01, time/batch = 0.1478s	
2596/2700 (epoch 48.074), train_loss = 1.51408979, grad/param norm = 5.1564e-01, time/batch = 0.1554s	
2597/2700 (epoch 48.093), train_loss = 1.49206133, grad/param norm = 5.1284e-01, time/batch = 0.1608s	
2598/2700 (epoch 48.111), train_loss = 1.48491845, grad/param norm = 4.9550e-01, time/batch = 0.1747s	
2599/2700 (epoch 48.130), train_loss = 1.51554173, grad/param norm = 5.0235e-01, time/batch = 0.1745s	
2600/2700 (epoch 48.148), train_loss = 1.49020855, grad/param norm = 4.6543e-01, time/batch = 0.1744s	
2601/2700 (epoch 48.167), train_loss = 1.57180192, grad/param norm = 5.2437e-01, time/batch = 0.1518s	
2602/2700 (epoch 48.185), train_loss = 1.48198397, grad/param norm = 5.0316e-01, time/batch = 0.1643s	
2603/2700 (epoch 48.204), train_loss = 1.53855909, grad/param norm = 5.2257e-01, time/batch = 0.1780s	
2604/2700 (epoch 48.222), train_loss = 1.48274080, grad/param norm = 5.3699e-01, time/batch = 0.1780s	
2605/2700 (epoch 48.241), train_loss = 1.41482038, grad/param norm = 5.0868e-01, time/batch = 0.1787s	
2606/2700 (epoch 48.259), train_loss = 1.46385924, grad/param norm = 4.9500e-01, time/batch = 0.1781s	
2607/2700 (epoch 48.278), train_loss = 1.54509877, grad/param norm = 4.9829e-01, time/batch = 0.1630s	
2608/2700 (epoch 48.296), train_loss = 1.52170254, grad/param norm = 4.8146e-01, time/batch = 0.1551s	
2609/2700 (epoch 48.315), train_loss = 1.49294659, grad/param norm = 4.7831e-01, time/batch = 0.1456s	
2610/2700 (epoch 48.333), train_loss = 1.50198825, grad/param norm = 4.9561e-01, time/batch = 0.1504s	
2611/2700 (epoch 48.352), train_loss = 1.51617338, grad/param norm = 5.2471e-01, time/batch = 0.1520s	
2612/2700 (epoch 48.370), train_loss = 1.51611119, grad/param norm = 5.4238e-01, time/batch = 0.1559s	
2613/2700 (epoch 48.389), train_loss = 1.51098590, grad/param norm = 5.3427e-01, time/batch = 0.1397s	
2614/2700 (epoch 48.407), train_loss = 1.54800685, grad/param norm = 4.8474e-01, time/batch = 0.1557s	
2615/2700 (epoch 48.426), train_loss = 1.56433769, grad/param norm = 5.1419e-01, time/batch = 0.1435s	
2616/2700 (epoch 48.444), train_loss = 1.46070917, grad/param norm = 5.0235e-01, time/batch = 0.1364s	
2617/2700 (epoch 48.463), train_loss = 1.56365253, grad/param norm = 5.1261e-01, time/batch = 0.1421s	
2618/2700 (epoch 48.481), train_loss = 1.54949132, grad/param norm = 5.0481e-01, time/batch = 0.1505s	
2619/2700 (epoch 48.500), train_loss = 1.48267328, grad/param norm = 4.9503e-01, time/batch = 0.1777s	
2620/2700 (epoch 48.519), train_loss = 1.54918487, grad/param norm = 4.9597e-01, time/batch = 0.1750s	
2621/2700 (epoch 48.537), train_loss = 1.51275557, grad/param norm = 5.2616e-01, time/batch = 0.1547s	
2622/2700 (epoch 48.556), train_loss = 1.45533075, grad/param norm = 4.7698e-01, time/batch = 0.1499s	
2623/2700 (epoch 48.574), train_loss = 1.46131812, grad/param norm = 5.0728e-01, time/batch = 0.1626s	
2624/2700 (epoch 48.593), train_loss = 1.50928211, grad/param norm = 4.9796e-01, time/batch = 0.1497s	
2625/2700 (epoch 48.611), train_loss = 1.42238656, grad/param norm = 4.6714e-01, time/batch = 0.1684s	
2626/2700 (epoch 48.630), train_loss = 1.46092818, grad/param norm = 4.9969e-01, time/batch = 0.1631s	
2627/2700 (epoch 48.648), train_loss = 1.49520531, grad/param norm = 4.8583e-01, time/batch = 0.1456s	
2628/2700 (epoch 48.667), train_loss = 1.45447970, grad/param norm = 5.2536e-01, time/batch = 0.1321s	
2629/2700 (epoch 48.685), train_loss = 1.49873661, grad/param norm = 5.0742e-01, time/batch = 0.1486s	
2630/2700 (epoch 48.704), train_loss = 1.52107126, grad/param norm = 5.6482e-01, time/batch = 0.1630s	
2631/2700 (epoch 48.722), train_loss = 1.48646901, grad/param norm = 4.6173e-01, time/batch = 0.1607s	
2632/2700 (epoch 48.741), train_loss = 1.51785089, grad/param norm = 4.8161e-01, time/batch = 0.1639s	
2633/2700 (epoch 48.759), train_loss = 1.49312514, grad/param norm = 5.0449e-01, time/batch = 0.1456s	
2634/2700 (epoch 48.778), train_loss = 1.54359880, grad/param norm = 5.0187e-01, time/batch = 0.1789s	
2635/2700 (epoch 48.796), train_loss = 1.50094391, grad/param norm = 5.3045e-01, time/batch = 0.1698s	
2636/2700 (epoch 48.815), train_loss = 1.54306334, grad/param norm = 4.9744e-01, time/batch = 0.1574s	
2637/2700 (epoch 48.833), train_loss = 1.49383888, grad/param norm = 5.0112e-01, time/batch = 0.1566s	
2638/2700 (epoch 48.852), train_loss = 1.49314925, grad/param norm = 4.8786e-01, time/batch = 0.1602s	
2639/2700 (epoch 48.870), train_loss = 1.50161186, grad/param norm = 4.6807e-01, time/batch = 0.1674s	
2640/2700 (epoch 48.889), train_loss = 1.52327845, grad/param norm = 4.9584e-01, time/batch = 0.1680s	
2641/2700 (epoch 48.907), train_loss = 1.63414706, grad/param norm = 5.3205e-01, time/batch = 0.1639s	
2642/2700 (epoch 48.926), train_loss = 1.54044057, grad/param norm = 5.2531e-01, time/batch = 0.1747s	
2643/2700 (epoch 48.944), train_loss = 1.51421390, grad/param norm = 4.8571e-01, time/batch = 0.1681s	
2644/2700 (epoch 48.963), train_loss = 1.55104976, grad/param norm = 4.9003e-01, time/batch = 0.1786s	
2645/2700 (epoch 48.981), train_loss = 1.50355340, grad/param norm = 5.2427e-01, time/batch = 0.1786s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
2646/2700 (epoch 49.000), train_loss = 1.58844692, grad/param norm = 4.9356e-01, time/batch = 0.1686s	
2647/2700 (epoch 49.019), train_loss = 1.57299570, grad/param norm = 5.9531e-01, time/batch = 0.1784s	
2648/2700 (epoch 49.037), train_loss = 1.57246934, grad/param norm = 5.3604e-01, time/batch = 0.1796s	
2649/2700 (epoch 49.056), train_loss = 1.50171070, grad/param norm = 5.2688e-01, time/batch = 0.1781s	
2650/2700 (epoch 49.074), train_loss = 1.51055339, grad/param norm = 5.1862e-01, time/batch = 0.1639s	
2651/2700 (epoch 49.093), train_loss = 1.48772140, grad/param norm = 5.1294e-01, time/batch = 0.1816s	
2652/2700 (epoch 49.111), train_loss = 1.48113430, grad/param norm = 4.9696e-01, time/batch = 0.1809s	
2653/2700 (epoch 49.130), train_loss = 1.51134091, grad/param norm = 5.0418e-01, time/batch = 0.1741s	
2654/2700 (epoch 49.148), train_loss = 1.48638197, grad/param norm = 4.6688e-01, time/batch = 0.1801s	
2655/2700 (epoch 49.167), train_loss = 1.56798239, grad/param norm = 5.2555e-01, time/batch = 0.1793s	
2656/2700 (epoch 49.185), train_loss = 1.47806415, grad/param norm = 5.0552e-01, time/batch = 0.1794s	
2657/2700 (epoch 49.204), train_loss = 1.53452575, grad/param norm = 5.2306e-01, time/batch = 0.1525s	
2658/2700 (epoch 49.222), train_loss = 1.47907506, grad/param norm = 5.4083e-01, time/batch = 0.1520s	
2659/2700 (epoch 49.241), train_loss = 1.41113812, grad/param norm = 5.0754e-01, time/batch = 0.1166s	
2660/2700 (epoch 49.259), train_loss = 1.46010534, grad/param norm = 4.9493e-01, time/batch = 0.1185s	
2661/2700 (epoch 49.278), train_loss = 1.54129601, grad/param norm = 4.9759e-01, time/batch = 0.1371s	
2662/2700 (epoch 49.296), train_loss = 1.51805063, grad/param norm = 4.8237e-01, time/batch = 0.1761s	
2663/2700 (epoch 49.315), train_loss = 1.48821349, grad/param norm = 4.7880e-01, time/batch = 0.1753s	
2664/2700 (epoch 49.333), train_loss = 1.49766548, grad/param norm = 4.9736e-01, time/batch = 0.1644s	
2665/2700 (epoch 49.352), train_loss = 1.51177728, grad/param norm = 5.2409e-01, time/batch = 0.1636s	
2666/2700 (epoch 49.370), train_loss = 1.51146196, grad/param norm = 5.4857e-01, time/batch = 0.1675s	
2667/2700 (epoch 49.389), train_loss = 1.50723992, grad/param norm = 5.3477e-01, time/batch = 0.1679s	
2668/2700 (epoch 49.407), train_loss = 1.54410054, grad/param norm = 4.8701e-01, time/batch = 0.1723s	
2669/2700 (epoch 49.426), train_loss = 1.56066331, grad/param norm = 5.1473e-01, time/batch = 0.1741s	
2670/2700 (epoch 49.444), train_loss = 1.45702873, grad/param norm = 5.0488e-01, time/batch = 0.1707s	
2671/2700 (epoch 49.463), train_loss = 1.55982432, grad/param norm = 5.1287e-01, time/batch = 0.1702s	
2672/2700 (epoch 49.481), train_loss = 1.54547742, grad/param norm = 5.0660e-01, time/batch = 0.1800s	
2673/2700 (epoch 49.500), train_loss = 1.47839449, grad/param norm = 4.9596e-01, time/batch = 0.1809s	
2674/2700 (epoch 49.519), train_loss = 1.54536693, grad/param norm = 4.9629e-01, time/batch = 0.1586s	
2675/2700 (epoch 49.537), train_loss = 1.50867589, grad/param norm = 5.2883e-01, time/batch = 0.1651s	
2676/2700 (epoch 49.556), train_loss = 1.45110830, grad/param norm = 4.7690e-01, time/batch = 0.1535s	
2677/2700 (epoch 49.574), train_loss = 1.45732864, grad/param norm = 5.0917e-01, time/batch = 0.1526s	
2678/2700 (epoch 49.593), train_loss = 1.50548794, grad/param norm = 4.9876e-01, time/batch = 0.1604s	
2679/2700 (epoch 49.611), train_loss = 1.41893147, grad/param norm = 4.6790e-01, time/batch = 0.1693s	
2680/2700 (epoch 49.630), train_loss = 1.45688277, grad/param norm = 4.9997e-01, time/batch = 0.1734s	
2681/2700 (epoch 49.648), train_loss = 1.49189014, grad/param norm = 4.8840e-01, time/batch = 0.1427s	
2682/2700 (epoch 49.667), train_loss = 1.45058319, grad/param norm = 5.2673e-01, time/batch = 0.1717s	
2683/2700 (epoch 49.685), train_loss = 1.49463726, grad/param norm = 5.0708e-01, time/batch = 0.1666s	
2684/2700 (epoch 49.704), train_loss = 1.51735286, grad/param norm = 5.6583e-01, time/batch = 0.1540s	
2685/2700 (epoch 49.722), train_loss = 1.48297660, grad/param norm = 4.6328e-01, time/batch = 0.1545s	
2686/2700 (epoch 49.741), train_loss = 1.51349043, grad/param norm = 4.8242e-01, time/batch = 0.1500s	
2687/2700 (epoch 49.759), train_loss = 1.48897915, grad/param norm = 5.0442e-01, time/batch = 0.1472s	
2688/2700 (epoch 49.778), train_loss = 1.53989800, grad/param norm = 5.0475e-01, time/batch = 0.1452s	
2689/2700 (epoch 49.796), train_loss = 1.49704382, grad/param norm = 5.3090e-01, time/batch = 0.1399s	
2690/2700 (epoch 49.815), train_loss = 1.53885466, grad/param norm = 4.9845e-01, time/batch = 0.1529s	
2691/2700 (epoch 49.833), train_loss = 1.49042648, grad/param norm = 5.0196e-01, time/batch = 0.1319s	
2692/2700 (epoch 49.852), train_loss = 1.48929601, grad/param norm = 4.8914e-01, time/batch = 0.1257s	
2693/2700 (epoch 49.870), train_loss = 1.49788429, grad/param norm = 4.6948e-01, time/batch = 0.1733s	
2694/2700 (epoch 49.889), train_loss = 1.51909364, grad/param norm = 4.9643e-01, time/batch = 0.1705s	
2695/2700 (epoch 49.907), train_loss = 1.62975797, grad/param norm = 5.3292e-01, time/batch = 0.1535s	
2696/2700 (epoch 49.926), train_loss = 1.53633276, grad/param norm = 5.2510e-01, time/batch = 0.1499s	
2697/2700 (epoch 49.944), train_loss = 1.51028157, grad/param norm = 4.8691e-01, time/batch = 0.1617s	
2698/2700 (epoch 49.963), train_loss = 1.54698797, grad/param norm = 4.9171e-01, time/batch = 0.1675s	
2699/2700 (epoch 49.981), train_loss = 1.49894853, grad/param norm = 5.2416e-01, time/batch = 0.1743s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch50.00_1.7793.t7	
2700/2700 (epoch 50.000), train_loss = 1.58481669, grad/param norm = 4.9737e-01, time/batch = 0.1750s	
