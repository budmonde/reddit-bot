using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 54, val: 3, test: 0	
vocab size: 91	
creating an rnn with 3 layers	
number of parameters in the model: 106075	
cloning rnn	
cloning criterion	
1/2700 (epoch 0.019), train_loss = 4.50991729, grad/param norm = 1.3425e+00, time/batch = 0.2810s	
2/2700 (epoch 0.037), train_loss = 4.25461493, grad/param norm = 4.6524e+00, time/batch = 0.0782s	
3/2700 (epoch 0.056), train_loss = 3.47791972, grad/param norm = 3.1538e+00, time/batch = 0.0769s	
4/2700 (epoch 0.074), train_loss = 3.39779465, grad/param norm = 3.3910e+00, time/batch = 0.0770s	
5/2700 (epoch 0.093), train_loss = 3.45459920, grad/param norm = 4.6689e+00, time/batch = 0.0766s	
6/2700 (epoch 0.111), train_loss = 3.31845956, grad/param norm = 2.0767e+00, time/batch = 0.0765s	
7/2700 (epoch 0.130), train_loss = 3.32495823, grad/param norm = 1.9778e+00, time/batch = 0.0771s	
8/2700 (epoch 0.148), train_loss = 3.26442442, grad/param norm = 1.9037e+00, time/batch = 0.0768s	
9/2700 (epoch 0.167), train_loss = 3.27093852, grad/param norm = 1.9239e+00, time/batch = 0.0764s	
10/2700 (epoch 0.185), train_loss = 3.25030158, grad/param norm = 1.4990e+00, time/batch = 0.0767s	
11/2700 (epoch 0.204), train_loss = 3.18439067, grad/param norm = 1.1942e+00, time/batch = 0.0500s	
12/2700 (epoch 0.222), train_loss = 3.15533958, grad/param norm = 1.5096e+00, time/batch = 0.0778s	
13/2700 (epoch 0.241), train_loss = 3.17701205, grad/param norm = 1.2269e+00, time/batch = 0.0769s	
14/2700 (epoch 0.259), train_loss = 3.20362914, grad/param norm = 8.4351e-01, time/batch = 0.0767s	
15/2700 (epoch 0.278), train_loss = 3.62578070, grad/param norm = 3.0479e+01, time/batch = 0.0766s	
16/2700 (epoch 0.296), train_loss = 3.73144449, grad/param norm = 1.5439e+00, time/batch = 0.0767s	
17/2700 (epoch 0.315), train_loss = 3.74463141, grad/param norm = 1.2988e+00, time/batch = 0.0776s	
18/2700 (epoch 0.333), train_loss = 3.76249938, grad/param norm = 1.0474e+00, time/batch = 0.0768s	
19/2700 (epoch 0.352), train_loss = 3.73187428, grad/param norm = 1.1150e+00, time/batch = 0.0761s	
20/2700 (epoch 0.370), train_loss = 3.67768211, grad/param norm = 1.9482e+00, time/batch = 0.0766s	
21/2700 (epoch 0.389), train_loss = 3.64326498, grad/param norm = 1.4233e+00, time/batch = 0.0486s	
22/2700 (epoch 0.407), train_loss = 3.66598587, grad/param norm = 1.4270e+00, time/batch = 0.0783s	
23/2700 (epoch 0.426), train_loss = 3.39065220, grad/param norm = 1.9718e+00, time/batch = 0.0775s	
24/2700 (epoch 0.444), train_loss = 3.23935939, grad/param norm = 1.8472e+00, time/batch = 0.0774s	
25/2700 (epoch 0.463), train_loss = 3.26813438, grad/param norm = 1.8092e+00, time/batch = 0.0773s	
26/2700 (epoch 0.481), train_loss = 3.33548298, grad/param norm = 1.6816e+00, time/batch = 0.0779s	
27/2700 (epoch 0.500), train_loss = 3.37336030, grad/param norm = 1.6166e+00, time/batch = 0.0780s	
28/2700 (epoch 0.519), train_loss = 3.32579185, grad/param norm = 1.2952e+00, time/batch = 0.0777s	
29/2700 (epoch 0.537), train_loss = 3.32633267, grad/param norm = 1.3208e+00, time/batch = 0.0772s	
30/2700 (epoch 0.556), train_loss = 3.26491292, grad/param norm = 1.0976e+00, time/batch = 0.0772s	
31/2700 (epoch 0.574), train_loss = 3.22821467, grad/param norm = 1.2523e+00, time/batch = 0.0561s	
32/2700 (epoch 0.593), train_loss = 3.23044757, grad/param norm = 1.4446e+00, time/batch = 0.0768s	
33/2700 (epoch 0.611), train_loss = 3.17043983, grad/param norm = 1.2768e+00, time/batch = 0.0767s	
34/2700 (epoch 0.630), train_loss = 3.20135489, grad/param norm = 1.3049e+00, time/batch = 0.0769s	
35/2700 (epoch 0.648), train_loss = 3.27244389, grad/param norm = 1.6633e+00, time/batch = 0.0765s	
36/2700 (epoch 0.667), train_loss = 3.20804306, grad/param norm = 1.9860e+00, time/batch = 0.0776s	
37/2700 (epoch 0.685), train_loss = 3.23267201, grad/param norm = 2.8259e+00, time/batch = 0.0769s	
38/2700 (epoch 0.704), train_loss = 3.20970654, grad/param norm = 2.9519e+00, time/batch = 0.0762s	
39/2700 (epoch 0.722), train_loss = 3.17732781, grad/param norm = 2.2969e+00, time/batch = 0.0769s	
40/2700 (epoch 0.741), train_loss = 3.28965886, grad/param norm = 1.5914e+00, time/batch = 0.0763s	
41/2700 (epoch 0.759), train_loss = 3.22755344, grad/param norm = 1.2388e+00, time/batch = 0.0553s	
42/2700 (epoch 0.778), train_loss = 3.21523833, grad/param norm = 9.3265e-01, time/batch = 0.0779s	
43/2700 (epoch 0.796), train_loss = 3.20109908, grad/param norm = 1.0870e+00, time/batch = 0.0766s	
44/2700 (epoch 0.815), train_loss = 3.15271859, grad/param norm = 1.2747e+00, time/batch = 0.0765s	
45/2700 (epoch 0.833), train_loss = 3.18370153, grad/param norm = 1.5242e+00, time/batch = 0.0775s	
46/2700 (epoch 0.852), train_loss = 3.17184325, grad/param norm = 1.5449e+00, time/batch = 0.0776s	
47/2700 (epoch 0.870), train_loss = 3.15059876, grad/param norm = 1.4465e+00, time/batch = 0.0768s	
48/2700 (epoch 0.889), train_loss = 3.18037730, grad/param norm = 1.8292e+00, time/batch = 0.0772s	
49/2700 (epoch 0.907), train_loss = 3.26702333, grad/param norm = 3.2180e+00, time/batch = 0.0736s	
50/2700 (epoch 0.926), train_loss = 3.27958312, grad/param norm = 4.0408e+00, time/batch = 0.0647s	
51/2700 (epoch 0.944), train_loss = 3.21340389, grad/param norm = 2.6472e+00, time/batch = 0.0774s	
52/2700 (epoch 0.963), train_loss = 3.24089467, grad/param norm = 1.0421e+00, time/batch = 0.0769s	
53/2700 (epoch 0.981), train_loss = 3.27319296, grad/param norm = 1.0229e+00, time/batch = 0.0771s	
54/2700 (epoch 1.000), train_loss = 3.19114497, grad/param norm = 1.1724e+00, time/batch = 0.0775s	
55/2700 (epoch 1.019), train_loss = 3.10488881, grad/param norm = 1.2352e+00, time/batch = 0.0775s	
56/2700 (epoch 1.037), train_loss = 3.10809711, grad/param norm = 9.7242e-01, time/batch = 0.0769s	
57/2700 (epoch 1.056), train_loss = 3.08333396, grad/param norm = 9.3198e-01, time/batch = 0.0766s	
58/2700 (epoch 1.074), train_loss = 3.12693982, grad/param norm = 8.5316e-01, time/batch = 0.0760s	
59/2700 (epoch 1.093), train_loss = 3.11509603, grad/param norm = 8.5287e-01, time/batch = 0.0776s	
60/2700 (epoch 1.111), train_loss = 3.06215739, grad/param norm = 1.0911e+00, time/batch = 0.0641s	
61/2700 (epoch 1.130), train_loss = 3.11315063, grad/param norm = 2.7770e+00, time/batch = 0.0691s	
62/2700 (epoch 1.148), train_loss = 3.23621263, grad/param norm = 4.3964e+00, time/batch = 0.0621s	
63/2700 (epoch 1.167), train_loss = 3.09258979, grad/param norm = 2.1600e+00, time/batch = 0.0680s	
64/2700 (epoch 1.185), train_loss = 3.02604365, grad/param norm = 9.7428e-01, time/batch = 0.0773s	
65/2700 (epoch 1.204), train_loss = 2.94214879, grad/param norm = 9.0464e-01, time/batch = 0.0777s	
66/2700 (epoch 1.222), train_loss = 2.89852662, grad/param norm = 9.5082e-01, time/batch = 0.0770s	
67/2700 (epoch 1.241), train_loss = 2.90807801, grad/param norm = 8.1336e-01, time/batch = 0.0773s	
68/2700 (epoch 1.259), train_loss = 2.92560169, grad/param norm = 8.3684e-01, time/batch = 0.0773s	
69/2700 (epoch 1.278), train_loss = 3.00007490, grad/param norm = 9.1460e-01, time/batch = 0.0727s	
70/2700 (epoch 1.296), train_loss = 2.97473607, grad/param norm = 8.2133e-01, time/batch = 0.0730s	
71/2700 (epoch 1.315), train_loss = 2.96174180, grad/param norm = 8.4819e-01, time/batch = 0.0691s	
72/2700 (epoch 1.333), train_loss = 2.99977781, grad/param norm = 1.3026e+00, time/batch = 0.0654s	
73/2700 (epoch 1.352), train_loss = 3.07316337, grad/param norm = 2.4395e+00, time/batch = 0.0712s	
74/2700 (epoch 1.370), train_loss = 3.05639322, grad/param norm = 3.5419e+00, time/batch = 0.0763s	
75/2700 (epoch 1.389), train_loss = 2.95294912, grad/param norm = 1.6444e+00, time/batch = 0.0777s	
76/2700 (epoch 1.407), train_loss = 2.91824259, grad/param norm = 1.2477e+00, time/batch = 0.0771s	
77/2700 (epoch 1.426), train_loss = 2.92347941, grad/param norm = 1.3311e+00, time/batch = 0.0771s	
78/2700 (epoch 1.444), train_loss = 2.81390194, grad/param norm = 1.6149e+00, time/batch = 0.0739s	
79/2700 (epoch 1.463), train_loss = 2.89487023, grad/param norm = 2.3044e+00, time/batch = 0.0710s	
80/2700 (epoch 1.481), train_loss = 2.97916504, grad/param norm = 2.3625e+00, time/batch = 0.0775s	
81/2700 (epoch 1.500), train_loss = 2.95907538, grad/param norm = 1.5258e+00, time/batch = 0.0682s	
82/2700 (epoch 1.519), train_loss = 2.87028113, grad/param norm = 1.5763e+00, time/batch = 0.0664s	
83/2700 (epoch 1.537), train_loss = 2.91851633, grad/param norm = 1.1323e+00, time/batch = 0.0747s	
84/2700 (epoch 1.556), train_loss = 2.83542790, grad/param norm = 1.0871e+00, time/batch = 0.0776s	
85/2700 (epoch 1.574), train_loss = 2.76820704, grad/param norm = 1.5943e+00, time/batch = 0.0772s	
86/2700 (epoch 1.593), train_loss = 2.76538726, grad/param norm = 1.9797e+00, time/batch = 0.0771s	
87/2700 (epoch 1.611), train_loss = 2.71237329, grad/param norm = 2.2153e+00, time/batch = 0.0742s	
88/2700 (epoch 1.630), train_loss = 2.74193043, grad/param norm = 1.6955e+00, time/batch = 0.0719s	
89/2700 (epoch 1.648), train_loss = 2.75433977, grad/param norm = 1.3465e+00, time/batch = 0.0893s	
90/2700 (epoch 1.667), train_loss = 2.67475650, grad/param norm = 1.4158e+00, time/batch = 0.0934s	
91/2700 (epoch 1.685), train_loss = 2.72402557, grad/param norm = 1.8611e+00, time/batch = 0.1038s	
92/2700 (epoch 1.704), train_loss = 2.70169367, grad/param norm = 2.0379e+00, time/batch = 0.1173s	
93/2700 (epoch 1.722), train_loss = 2.66943280, grad/param norm = 1.5970e+00, time/batch = 0.1018s	
94/2700 (epoch 1.741), train_loss = 2.84031510, grad/param norm = 1.4281e+00, time/batch = 0.1036s	
95/2700 (epoch 1.759), train_loss = 2.73995248, grad/param norm = 1.3257e+00, time/batch = 0.0941s	
96/2700 (epoch 1.778), train_loss = 2.71538541, grad/param norm = 1.2761e+00, time/batch = 0.1011s	
97/2700 (epoch 1.796), train_loss = 2.70267771, grad/param norm = 1.5530e+00, time/batch = 0.0965s	
98/2700 (epoch 1.815), train_loss = 2.68569116, grad/param norm = 1.9814e+00, time/batch = 0.1045s	
99/2700 (epoch 1.833), train_loss = 2.69352678, grad/param norm = 1.9958e+00, time/batch = 0.1048s	
100/2700 (epoch 1.852), train_loss = 2.69334352, grad/param norm = 1.6104e+00, time/batch = 0.1028s	
101/2700 (epoch 1.870), train_loss = 2.64995548, grad/param norm = 1.7289e+00, time/batch = 0.1040s	
102/2700 (epoch 1.889), train_loss = 2.67918177, grad/param norm = 2.1138e+00, time/batch = 0.1044s	
103/2700 (epoch 1.907), train_loss = 2.80788485, grad/param norm = 1.8609e+00, time/batch = 0.0919s	
104/2700 (epoch 1.926), train_loss = 2.78394323, grad/param norm = 3.5588e+00, time/batch = 0.0791s	
105/2700 (epoch 1.944), train_loss = 2.75661623, grad/param norm = 1.3613e+00, time/batch = 0.0956s	
106/2700 (epoch 1.963), train_loss = 2.81159754, grad/param norm = 1.3102e+00, time/batch = 0.0972s	
107/2700 (epoch 1.981), train_loss = 2.82913496, grad/param norm = 1.6501e+00, time/batch = 0.0951s	
108/2700 (epoch 2.000), train_loss = 2.79408489, grad/param norm = 1.5739e+00, time/batch = 0.0921s	
109/2700 (epoch 2.019), train_loss = 2.65610772, grad/param norm = 1.1853e+00, time/batch = 0.0864s	
110/2700 (epoch 2.037), train_loss = 2.69720345, grad/param norm = 1.1870e+00, time/batch = 0.0881s	
111/2700 (epoch 2.056), train_loss = 2.66614272, grad/param norm = 1.4855e+00, time/batch = 0.0942s	
112/2700 (epoch 2.074), train_loss = 2.71113438, grad/param norm = 2.3384e+00, time/batch = 0.0886s	
113/2700 (epoch 2.093), train_loss = 2.75085766, grad/param norm = 2.5251e+00, time/batch = 0.0817s	
114/2700 (epoch 2.111), train_loss = 2.68684870, grad/param norm = 1.9041e+00, time/batch = 0.1039s	
115/2700 (epoch 2.130), train_loss = 2.68906256, grad/param norm = 1.6646e+00, time/batch = 0.1142s	
116/2700 (epoch 2.148), train_loss = 2.62197380, grad/param norm = 1.3155e+00, time/batch = 0.1355s	
117/2700 (epoch 2.167), train_loss = 2.63293016, grad/param norm = 1.0676e+00, time/batch = 0.1353s	
118/2700 (epoch 2.185), train_loss = 2.58761648, grad/param norm = 1.0186e+00, time/batch = 0.1286s	
119/2700 (epoch 2.204), train_loss = 2.55448622, grad/param norm = 1.0944e+00, time/batch = 0.1300s	
120/2700 (epoch 2.222), train_loss = 2.51412596, grad/param norm = 1.3241e+00, time/batch = 0.1311s	
121/2700 (epoch 2.241), train_loss = 2.53016025, grad/param norm = 1.7588e+00, time/batch = 0.1495s	
122/2700 (epoch 2.259), train_loss = 2.56437763, grad/param norm = 1.8143e+00, time/batch = 0.1411s	
123/2700 (epoch 2.278), train_loss = 2.64988469, grad/param norm = 1.8390e+00, time/batch = 0.1280s	
124/2700 (epoch 2.296), train_loss = 2.64420784, grad/param norm = 1.7073e+00, time/batch = 0.1129s	
125/2700 (epoch 2.315), train_loss = 2.64239666, grad/param norm = 1.4459e+00, time/batch = 0.0817s	
126/2700 (epoch 2.333), train_loss = 2.64182572, grad/param norm = 1.3357e+00, time/batch = 0.1275s	
127/2700 (epoch 2.352), train_loss = 2.68928712, grad/param norm = 1.5800e+00, time/batch = 0.1281s	
128/2700 (epoch 2.370), train_loss = 2.66037251, grad/param norm = 2.1343e+00, time/batch = 0.1227s	
129/2700 (epoch 2.389), train_loss = 2.63721966, grad/param norm = 1.9388e+00, time/batch = 0.1132s	
130/2700 (epoch 2.407), train_loss = 2.58707191, grad/param norm = 1.6818e+00, time/batch = 0.1056s	
131/2700 (epoch 2.426), train_loss = 2.63300899, grad/param norm = 1.8957e+00, time/batch = 0.1276s	
132/2700 (epoch 2.444), train_loss = 2.53952171, grad/param norm = 1.4900e+00, time/batch = 0.1060s	
133/2700 (epoch 2.463), train_loss = 2.60955510, grad/param norm = 1.3755e+00, time/batch = 0.1057s	
134/2700 (epoch 2.481), train_loss = 2.65018184, grad/param norm = 1.1938e+00, time/batch = 0.1026s	
135/2700 (epoch 2.500), train_loss = 2.66170929, grad/param norm = 1.3387e+00, time/batch = 0.1059s	
136/2700 (epoch 2.519), train_loss = 2.59183404, grad/param norm = 1.6534e+00, time/batch = 0.0881s	
137/2700 (epoch 2.537), train_loss = 2.60712595, grad/param norm = 1.9182e+00, time/batch = 0.1157s	
138/2700 (epoch 2.556), train_loss = 2.58446775, grad/param norm = 1.7474e+00, time/batch = 0.1041s	
139/2700 (epoch 2.574), train_loss = 2.53268771, grad/param norm = 1.4126e+00, time/batch = 0.1048s	
140/2700 (epoch 2.593), train_loss = 2.51009105, grad/param norm = 1.3760e+00, time/batch = 0.1057s	
141/2700 (epoch 2.611), train_loss = 2.46627208, grad/param norm = 1.4899e+00, time/batch = 0.1015s	
142/2700 (epoch 2.630), train_loss = 2.50732836, grad/param norm = 1.5254e+00, time/batch = 0.1071s	
143/2700 (epoch 2.648), train_loss = 2.51724903, grad/param norm = 1.1260e+00, time/batch = 0.1060s	
144/2700 (epoch 2.667), train_loss = 2.44032739, grad/param norm = 9.0001e-01, time/batch = 0.1164s	
145/2700 (epoch 2.685), train_loss = 2.49896013, grad/param norm = 9.4437e-01, time/batch = 0.1162s	
146/2700 (epoch 2.704), train_loss = 2.48223273, grad/param norm = 1.5372e+00, time/batch = 0.1179s	
147/2700 (epoch 2.722), train_loss = 2.49165592, grad/param norm = 1.7816e+00, time/batch = 0.1123s	
148/2700 (epoch 2.741), train_loss = 2.66090724, grad/param norm = 1.7743e+00, time/batch = 0.1026s	
149/2700 (epoch 2.759), train_loss = 2.58364727, grad/param norm = 2.0954e+00, time/batch = 0.0988s	
150/2700 (epoch 2.778), train_loss = 2.56292174, grad/param norm = 1.9298e+00, time/batch = 0.1103s	
151/2700 (epoch 2.796), train_loss = 2.53451026, grad/param norm = 1.5916e+00, time/batch = 0.1049s	
152/2700 (epoch 2.815), train_loss = 2.50608936, grad/param norm = 1.2953e+00, time/batch = 0.1191s	
153/2700 (epoch 2.833), train_loss = 2.46903600, grad/param norm = 1.1525e+00, time/batch = 0.1051s	
154/2700 (epoch 2.852), train_loss = 2.51575222, grad/param norm = 1.2461e+00, time/batch = 0.1217s	
155/2700 (epoch 2.870), train_loss = 2.48508397, grad/param norm = 1.5924e+00, time/batch = 0.1182s	
156/2700 (epoch 2.889), train_loss = 2.50380979, grad/param norm = 2.2476e+00, time/batch = 0.1133s	
157/2700 (epoch 2.907), train_loss = 2.64438262, grad/param norm = 1.8394e+00, time/batch = 0.1153s	
158/2700 (epoch 2.926), train_loss = 2.54101102, grad/param norm = 1.7719e+00, time/batch = 0.1204s	
159/2700 (epoch 2.944), train_loss = 2.55935833, grad/param norm = 1.3314e+00, time/batch = 0.0735s	
160/2700 (epoch 2.963), train_loss = 2.58447999, grad/param norm = 9.7121e-01, time/batch = 0.1211s	
161/2700 (epoch 2.981), train_loss = 2.56744684, grad/param norm = 1.1365e+00, time/batch = 0.1284s	
162/2700 (epoch 3.000), train_loss = 2.58382419, grad/param norm = 2.3952e+00, time/batch = 0.1204s	
163/2700 (epoch 3.019), train_loss = 2.53671532, grad/param norm = 1.4646e+00, time/batch = 0.1210s	
164/2700 (epoch 3.037), train_loss = 2.56127321, grad/param norm = 1.4556e+00, time/batch = 0.1261s	
165/2700 (epoch 3.056), train_loss = 2.51928796, grad/param norm = 1.9878e+00, time/batch = 0.1220s	
166/2700 (epoch 3.074), train_loss = 2.54192936, grad/param norm = 2.2743e+00, time/batch = 0.1072s	
167/2700 (epoch 3.093), train_loss = 2.55549036, grad/param norm = 1.6205e+00, time/batch = 0.1023s	
168/2700 (epoch 3.111), train_loss = 2.47775096, grad/param norm = 9.6971e-01, time/batch = 0.1043s	
169/2700 (epoch 3.130), train_loss = 2.48739961, grad/param norm = 7.1443e-01, time/batch = 0.1087s	
170/2700 (epoch 3.148), train_loss = 2.43760763, grad/param norm = 7.3988e-01, time/batch = 0.0901s	
171/2700 (epoch 3.167), train_loss = 2.47571040, grad/param norm = 8.9788e-01, time/batch = 0.1283s	
172/2700 (epoch 3.185), train_loss = 2.42336978, grad/param norm = 9.3746e-01, time/batch = 0.1203s	
173/2700 (epoch 3.204), train_loss = 2.41582296, grad/param norm = 1.0030e+00, time/batch = 0.1271s	
174/2700 (epoch 3.222), train_loss = 2.37230377, grad/param norm = 1.5718e+00, time/batch = 0.1260s	
175/2700 (epoch 3.241), train_loss = 2.39837350, grad/param norm = 1.7096e+00, time/batch = 0.1204s	
176/2700 (epoch 3.259), train_loss = 2.41582960, grad/param norm = 1.7363e+00, time/batch = 0.1149s	
177/2700 (epoch 3.278), train_loss = 2.50056749, grad/param norm = 1.6989e+00, time/batch = 0.1057s	
178/2700 (epoch 3.296), train_loss = 2.47280343, grad/param norm = 1.5943e+00, time/batch = 0.1040s	
179/2700 (epoch 3.315), train_loss = 2.50535628, grad/param norm = 1.6015e+00, time/batch = 0.1044s	
180/2700 (epoch 3.333), train_loss = 2.48960365, grad/param norm = 1.3660e+00, time/batch = 0.1109s	
181/2700 (epoch 3.352), train_loss = 2.52778327, grad/param norm = 1.3731e+00, time/batch = 0.0858s	
182/2700 (epoch 3.370), train_loss = 2.47113285, grad/param norm = 1.2179e+00, time/batch = 0.1243s	
183/2700 (epoch 3.389), train_loss = 2.42876090, grad/param norm = 1.0908e+00, time/batch = 0.1030s	
184/2700 (epoch 3.407), train_loss = 2.41540830, grad/param norm = 9.3845e-01, time/batch = 0.1011s	
185/2700 (epoch 3.426), train_loss = 2.46543360, grad/param norm = 9.3453e-01, time/batch = 0.1041s	
186/2700 (epoch 3.444), train_loss = 2.36679327, grad/param norm = 1.1093e+00, time/batch = 0.1134s	
187/2700 (epoch 3.463), train_loss = 2.45237107, grad/param norm = 1.3066e+00, time/batch = 0.1167s	
188/2700 (epoch 3.481), train_loss = 2.49595752, grad/param norm = 1.4397e+00, time/batch = 0.1177s	
189/2700 (epoch 3.500), train_loss = 2.51646101, grad/param norm = 2.2127e+00, time/batch = 0.1161s	
190/2700 (epoch 3.519), train_loss = 2.48496901, grad/param norm = 1.8434e+00, time/batch = 0.1171s	
191/2700 (epoch 3.537), train_loss = 2.45427088, grad/param norm = 1.3844e+00, time/batch = 0.1294s	
192/2700 (epoch 3.556), train_loss = 2.42565119, grad/param norm = 9.9222e-01, time/batch = 0.1112s	
193/2700 (epoch 3.574), train_loss = 2.37068141, grad/param norm = 8.6271e-01, time/batch = 0.0903s	
194/2700 (epoch 3.593), train_loss = 2.35696582, grad/param norm = 1.0045e+00, time/batch = 0.1179s	
195/2700 (epoch 3.611), train_loss = 2.28870935, grad/param norm = 1.1152e+00, time/batch = 0.1164s	
196/2700 (epoch 3.630), train_loss = 2.35114526, grad/param norm = 1.6088e+00, time/batch = 0.1178s	
197/2700 (epoch 3.648), train_loss = 2.41405731, grad/param norm = 2.1055e+00, time/batch = 0.1202s	
198/2700 (epoch 3.667), train_loss = 2.37256585, grad/param norm = 2.0862e+00, time/batch = 0.1194s	
199/2700 (epoch 3.685), train_loss = 2.39328023, grad/param norm = 1.5892e+00, time/batch = 0.1125s	
200/2700 (epoch 3.704), train_loss = 2.34691061, grad/param norm = 1.3163e+00, time/batch = 0.1042s	
201/2700 (epoch 3.722), train_loss = 2.32643097, grad/param norm = 9.8708e-01, time/batch = 0.1280s	
202/2700 (epoch 3.741), train_loss = 2.48320463, grad/param norm = 8.4095e-01, time/batch = 0.1130s	
203/2700 (epoch 3.759), train_loss = 2.42831848, grad/param norm = 9.2522e-01, time/batch = 0.1156s	
204/2700 (epoch 3.778), train_loss = 2.39882234, grad/param norm = 8.6005e-01, time/batch = 0.0712s	
205/2700 (epoch 3.796), train_loss = 2.36399795, grad/param norm = 9.0395e-01, time/batch = 0.1198s	
206/2700 (epoch 3.815), train_loss = 2.37319403, grad/param norm = 9.7857e-01, time/batch = 0.1087s	
207/2700 (epoch 3.833), train_loss = 2.34329670, grad/param norm = 9.9921e-01, time/batch = 0.1022s	
208/2700 (epoch 3.852), train_loss = 2.39060882, grad/param norm = 9.0742e-01, time/batch = 0.1039s	
209/2700 (epoch 3.870), train_loss = 2.35363398, grad/param norm = 1.0497e+00, time/batch = 0.1084s	
210/2700 (epoch 3.889), train_loss = 2.35313309, grad/param norm = 1.2018e+00, time/batch = 0.1137s	
211/2700 (epoch 3.907), train_loss = 2.48483195, grad/param norm = 1.4716e+00, time/batch = 0.1120s	
212/2700 (epoch 3.926), train_loss = 2.41759487, grad/param norm = 1.4508e+00, time/batch = 0.1215s	
213/2700 (epoch 3.944), train_loss = 2.40082577, grad/param norm = 1.2780e+00, time/batch = 0.1137s	
214/2700 (epoch 3.963), train_loss = 2.45818193, grad/param norm = 1.1600e+00, time/batch = 0.1170s	
215/2700 (epoch 3.981), train_loss = 2.45768110, grad/param norm = 1.3976e+00, time/batch = 0.1100s	
216/2700 (epoch 4.000), train_loss = 2.46442246, grad/param norm = 2.3651e+00, time/batch = 0.1105s	
217/2700 (epoch 4.019), train_loss = 2.40213254, grad/param norm = 1.5070e+00, time/batch = 0.0988s	
218/2700 (epoch 4.037), train_loss = 2.44432483, grad/param norm = 1.7046e+00, time/batch = 0.1050s	
219/2700 (epoch 4.056), train_loss = 2.40017956, grad/param norm = 1.7554e+00, time/batch = 0.1139s	
220/2700 (epoch 4.074), train_loss = 2.38171401, grad/param norm = 1.6319e+00, time/batch = 0.1175s	
221/2700 (epoch 4.093), train_loss = 2.39948526, grad/param norm = 1.2117e+00, time/batch = 0.1177s	
222/2700 (epoch 4.111), train_loss = 2.33206240, grad/param norm = 8.8762e-01, time/batch = 0.1225s	
223/2700 (epoch 4.130), train_loss = 2.34518410, grad/param norm = 7.4025e-01, time/batch = 0.1151s	
224/2700 (epoch 4.148), train_loss = 2.30891904, grad/param norm = 8.0884e-01, time/batch = 0.1358s	
225/2700 (epoch 4.167), train_loss = 2.35937454, grad/param norm = 8.3237e-01, time/batch = 0.1426s	
226/2700 (epoch 4.185), train_loss = 2.28883919, grad/param norm = 7.0868e-01, time/batch = 0.1577s	
227/2700 (epoch 4.204), train_loss = 2.29196612, grad/param norm = 8.1025e-01, time/batch = 0.1304s	
228/2700 (epoch 4.222), train_loss = 2.23072852, grad/param norm = 1.0774e+00, time/batch = 0.1276s	
229/2700 (epoch 4.241), train_loss = 2.22241627, grad/param norm = 1.1225e+00, time/batch = 0.1367s	
230/2700 (epoch 4.259), train_loss = 2.25090844, grad/param norm = 9.3921e-01, time/batch = 0.1407s	
231/2700 (epoch 4.278), train_loss = 2.35262773, grad/param norm = 9.3051e-01, time/batch = 0.1535s	
232/2700 (epoch 4.296), train_loss = 2.32594946, grad/param norm = 1.0337e+00, time/batch = 0.1395s	
233/2700 (epoch 4.315), train_loss = 2.34578353, grad/param norm = 1.0083e+00, time/batch = 0.1566s	
234/2700 (epoch 4.333), train_loss = 2.34108471, grad/param norm = 1.0551e+00, time/batch = 0.1533s	
235/2700 (epoch 4.352), train_loss = 2.39703425, grad/param norm = 1.1418e+00, time/batch = 0.1561s	
236/2700 (epoch 4.370), train_loss = 2.37642550, grad/param norm = 1.3962e+00, time/batch = 0.1461s	
237/2700 (epoch 4.389), train_loss = 2.36293547, grad/param norm = 1.5907e+00, time/batch = 0.1305s	
238/2700 (epoch 4.407), train_loss = 2.32341311, grad/param norm = 1.4530e+00, time/batch = 0.1277s	
239/2700 (epoch 4.426), train_loss = 2.36611320, grad/param norm = 1.3712e+00, time/batch = 0.1161s	
240/2700 (epoch 4.444), train_loss = 2.27089435, grad/param norm = 1.4301e+00, time/batch = 0.1252s	
241/2700 (epoch 4.463), train_loss = 2.34868223, grad/param norm = 1.5597e+00, time/batch = 0.1247s	
242/2700 (epoch 4.481), train_loss = 2.38190227, grad/param norm = 1.4795e+00, time/batch = 0.1267s	
243/2700 (epoch 4.500), train_loss = 2.36725117, grad/param norm = 1.1851e+00, time/batch = 0.1249s	
244/2700 (epoch 4.519), train_loss = 2.31209143, grad/param norm = 1.2578e+00, time/batch = 0.1219s	
245/2700 (epoch 4.537), train_loss = 2.32658371, grad/param norm = 1.2191e+00, time/batch = 0.1270s	
246/2700 (epoch 4.556), train_loss = 2.31005107, grad/param norm = 1.3835e+00, time/batch = 0.1405s	
247/2700 (epoch 4.574), train_loss = 2.26105294, grad/param norm = 1.0068e+00, time/batch = 0.1226s	
248/2700 (epoch 4.593), train_loss = 2.25030089, grad/param norm = 1.0190e+00, time/batch = 0.1548s	
249/2700 (epoch 4.611), train_loss = 2.18061564, grad/param norm = 1.2673e+00, time/batch = 0.1698s	
250/2700 (epoch 4.630), train_loss = 2.25083609, grad/param norm = 1.3711e+00, time/batch = 0.1644s	
251/2700 (epoch 4.648), train_loss = 2.29236905, grad/param norm = 1.4073e+00, time/batch = 0.1743s	
252/2700 (epoch 4.667), train_loss = 2.23664804, grad/param norm = 1.3841e+00, time/batch = 0.1797s	
253/2700 (epoch 4.685), train_loss = 2.26836951, grad/param norm = 1.2613e+00, time/batch = 0.1785s	
254/2700 (epoch 4.704), train_loss = 2.26005589, grad/param norm = 1.4037e+00, time/batch = 0.1796s	
255/2700 (epoch 4.722), train_loss = 2.24609337, grad/param norm = 1.6489e+00, time/batch = 0.1822s	
256/2700 (epoch 4.741), train_loss = 2.39149222, grad/param norm = 1.7609e+00, time/batch = 0.1748s	
257/2700 (epoch 4.759), train_loss = 2.34699582, grad/param norm = 1.5204e+00, time/batch = 0.1719s	
258/2700 (epoch 4.778), train_loss = 2.30673589, grad/param norm = 8.6165e-01, time/batch = 0.1378s	
259/2700 (epoch 4.796), train_loss = 2.25378374, grad/param norm = 7.6118e-01, time/batch = 0.1561s	
260/2700 (epoch 4.815), train_loss = 2.27077273, grad/param norm = 7.7509e-01, time/batch = 0.1605s	
261/2700 (epoch 4.833), train_loss = 2.23944617, grad/param norm = 7.6560e-01, time/batch = 0.1646s	
262/2700 (epoch 4.852), train_loss = 2.27786224, grad/param norm = 6.9343e-01, time/batch = 0.1848s	
263/2700 (epoch 4.870), train_loss = 2.24033383, grad/param norm = 6.6671e-01, time/batch = 0.1677s	
264/2700 (epoch 4.889), train_loss = 2.23699167, grad/param norm = 7.4636e-01, time/batch = 0.1559s	
265/2700 (epoch 4.907), train_loss = 2.37284342, grad/param norm = 1.0552e+00, time/batch = 0.1616s	
266/2700 (epoch 4.926), train_loss = 2.31556963, grad/param norm = 1.2995e+00, time/batch = 0.1458s	
267/2700 (epoch 4.944), train_loss = 2.30326753, grad/param norm = 1.0679e+00, time/batch = 0.1445s	
268/2700 (epoch 4.963), train_loss = 2.34852894, grad/param norm = 1.0998e+00, time/batch = 0.1130s	
269/2700 (epoch 4.981), train_loss = 2.33963180, grad/param norm = 1.1280e+00, time/batch = 0.1791s	
270/2700 (epoch 5.000), train_loss = 2.32473968, grad/param norm = 1.1140e+00, time/batch = 0.1783s	
271/2700 (epoch 5.019), train_loss = 2.29663677, grad/param norm = 1.0278e+00, time/batch = 0.1810s	
272/2700 (epoch 5.037), train_loss = 2.30307242, grad/param norm = 9.8477e-01, time/batch = 0.1792s	
273/2700 (epoch 5.056), train_loss = 2.24404021, grad/param norm = 8.6580e-01, time/batch = 0.1773s	
274/2700 (epoch 5.074), train_loss = 2.22621264, grad/param norm = 7.8577e-01, time/batch = 0.1668s	
275/2700 (epoch 5.093), train_loss = 2.27696687, grad/param norm = 7.3862e-01, time/batch = 0.1665s	
276/2700 (epoch 5.111), train_loss = 2.22542279, grad/param norm = 7.7549e-01, time/batch = 0.1672s	
277/2700 (epoch 5.130), train_loss = 2.24486710, grad/param norm = 8.7223e-01, time/batch = 0.1709s	
278/2700 (epoch 5.148), train_loss = 2.21633272, grad/param norm = 9.8502e-01, time/batch = 0.1482s	
279/2700 (epoch 5.167), train_loss = 2.27136536, grad/param norm = 8.4119e-01, time/batch = 0.1423s	
280/2700 (epoch 5.185), train_loss = 2.19225957, grad/param norm = 8.0271e-01, time/batch = 0.1768s	
281/2700 (epoch 5.204), train_loss = 2.21814304, grad/param norm = 1.0840e+00, time/batch = 0.1443s	
282/2700 (epoch 5.222), train_loss = 2.15040150, grad/param norm = 1.2873e+00, time/batch = 0.1650s	
283/2700 (epoch 5.241), train_loss = 2.12554142, grad/param norm = 1.1311e+00, time/batch = 0.1633s	
284/2700 (epoch 5.259), train_loss = 2.15913623, grad/param norm = 8.9143e-01, time/batch = 0.1655s	
285/2700 (epoch 5.278), train_loss = 2.26047858, grad/param norm = 1.1175e+00, time/batch = 0.1643s	
286/2700 (epoch 5.296), train_loss = 2.24096168, grad/param norm = 1.3808e+00, time/batch = 0.1614s	
287/2700 (epoch 5.315), train_loss = 2.27526695, grad/param norm = 1.5186e+00, time/batch = 0.1616s	
288/2700 (epoch 5.333), train_loss = 2.25542183, grad/param norm = 1.2484e+00, time/batch = 0.1541s	
289/2700 (epoch 5.352), train_loss = 2.28118674, grad/param norm = 1.0104e+00, time/batch = 0.1569s	
290/2700 (epoch 5.370), train_loss = 2.27707036, grad/param norm = 1.1881e+00, time/batch = 0.1566s	
291/2700 (epoch 5.389), train_loss = 2.25511491, grad/param norm = 1.1062e+00, time/batch = 0.1832s	
292/2700 (epoch 5.407), train_loss = 2.21108384, grad/param norm = 8.7198e-01, time/batch = 0.1838s	
293/2700 (epoch 5.426), train_loss = 2.25253468, grad/param norm = 8.5800e-01, time/batch = 0.1814s	
294/2700 (epoch 5.444), train_loss = 2.15585953, grad/param norm = 1.0138e+00, time/batch = 0.1821s	
295/2700 (epoch 5.463), train_loss = 2.22846485, grad/param norm = 1.0861e+00, time/batch = 0.1809s	
296/2700 (epoch 5.481), train_loss = 2.27169230, grad/param norm = 1.0700e+00, time/batch = 0.1820s	
297/2700 (epoch 5.500), train_loss = 2.26086933, grad/param norm = 1.0277e+00, time/batch = 0.1733s	
298/2700 (epoch 5.519), train_loss = 2.20709176, grad/param norm = 1.1220e+00, time/batch = 0.1796s	
299/2700 (epoch 5.537), train_loss = 2.24298504, grad/param norm = 1.1376e+00, time/batch = 0.1760s	
300/2700 (epoch 5.556), train_loss = 2.21156696, grad/param norm = 9.6677e-01, time/batch = 0.1407s	
301/2700 (epoch 5.574), train_loss = 2.17124336, grad/param norm = 8.4728e-01, time/batch = 0.1700s	
302/2700 (epoch 5.593), train_loss = 2.16327404, grad/param norm = 8.2451e-01, time/batch = 0.1612s	
303/2700 (epoch 5.611), train_loss = 2.08754536, grad/param norm = 8.1583e-01, time/batch = 0.1592s	
304/2700 (epoch 5.630), train_loss = 2.13320761, grad/param norm = 8.4592e-01, time/batch = 0.1634s	
305/2700 (epoch 5.648), train_loss = 2.17806368, grad/param norm = 7.8757e-01, time/batch = 0.1603s	
306/2700 (epoch 5.667), train_loss = 2.13213668, grad/param norm = 7.2745e-01, time/batch = 0.1512s	
307/2700 (epoch 5.685), train_loss = 2.16325111, grad/param norm = 6.9936e-01, time/batch = 0.1451s	
308/2700 (epoch 5.704), train_loss = 2.15252481, grad/param norm = 7.8507e-01, time/batch = 0.1619s	
309/2700 (epoch 5.722), train_loss = 2.11777984, grad/param norm = 6.1281e-01, time/batch = 0.1671s	
310/2700 (epoch 5.741), train_loss = 2.24894467, grad/param norm = 5.7246e-01, time/batch = 0.1500s	
311/2700 (epoch 5.759), train_loss = 2.22885745, grad/param norm = 8.3099e-01, time/batch = 0.1803s	
312/2700 (epoch 5.778), train_loss = 2.21703243, grad/param norm = 9.3219e-01, time/batch = 0.1815s	
313/2700 (epoch 5.796), train_loss = 2.19281264, grad/param norm = 1.0204e+00, time/batch = 0.1773s	
314/2700 (epoch 5.815), train_loss = 2.21684447, grad/param norm = 1.0853e+00, time/batch = 0.1726s	
315/2700 (epoch 5.833), train_loss = 2.18405406, grad/param norm = 1.1100e+00, time/batch = 0.1665s	
316/2700 (epoch 5.852), train_loss = 2.21748441, grad/param norm = 1.2046e+00, time/batch = 0.1712s	
317/2700 (epoch 5.870), train_loss = 2.20066442, grad/param norm = 1.6793e+00, time/batch = 0.1590s	
318/2700 (epoch 5.889), train_loss = 2.21621176, grad/param norm = 1.4753e+00, time/batch = 0.1787s	
319/2700 (epoch 5.907), train_loss = 2.32279242, grad/param norm = 1.6111e+00, time/batch = 0.1720s	
320/2700 (epoch 5.926), train_loss = 2.23984071, grad/param norm = 1.3829e+00, time/batch = 0.1761s	
321/2700 (epoch 5.944), train_loss = 2.21595382, grad/param norm = 1.2795e+00, time/batch = 0.1734s	
322/2700 (epoch 5.963), train_loss = 2.26230122, grad/param norm = 1.0300e+00, time/batch = 0.1809s	
323/2700 (epoch 5.981), train_loss = 2.24657678, grad/param norm = 9.3216e-01, time/batch = 0.1760s	
324/2700 (epoch 6.000), train_loss = 2.24189483, grad/param norm = 1.1178e+00, time/batch = 0.1728s	
325/2700 (epoch 6.019), train_loss = 2.21738885, grad/param norm = 9.8604e-01, time/batch = 0.1765s	
326/2700 (epoch 6.037), train_loss = 2.21117655, grad/param norm = 8.6364e-01, time/batch = 0.1742s	
327/2700 (epoch 6.056), train_loss = 2.16258282, grad/param norm = 9.3627e-01, time/batch = 0.1761s	
328/2700 (epoch 6.074), train_loss = 2.14553803, grad/param norm = 1.0801e+00, time/batch = 0.1694s	
329/2700 (epoch 6.093), train_loss = 2.20027338, grad/param norm = 9.2109e-01, time/batch = 0.1539s	
330/2700 (epoch 6.111), train_loss = 2.14156896, grad/param norm = 8.0058e-01, time/batch = 0.1616s	
331/2700 (epoch 6.130), train_loss = 2.15694529, grad/param norm = 7.7008e-01, time/batch = 0.1550s	
332/2700 (epoch 6.148), train_loss = 2.12356974, grad/param norm = 9.3284e-01, time/batch = 0.1787s	
333/2700 (epoch 6.167), train_loss = 2.19089885, grad/param norm = 8.1255e-01, time/batch = 0.1829s	
334/2700 (epoch 6.185), train_loss = 2.11470366, grad/param norm = 7.5676e-01, time/batch = 0.1774s	
335/2700 (epoch 6.204), train_loss = 2.14212626, grad/param norm = 7.4133e-01, time/batch = 0.1644s	
336/2700 (epoch 6.222), train_loss = 2.04796118, grad/param norm = 8.4308e-01, time/batch = 0.1595s	
337/2700 (epoch 6.241), train_loss = 2.02092111, grad/param norm = 8.3423e-01, time/batch = 0.1790s	
338/2700 (epoch 6.259), train_loss = 2.07398328, grad/param norm = 7.1427e-01, time/batch = 0.1634s	
339/2700 (epoch 6.278), train_loss = 2.16279026, grad/param norm = 7.5306e-01, time/batch = 0.1787s	
340/2700 (epoch 6.296), train_loss = 2.13926963, grad/param norm = 8.2352e-01, time/batch = 0.1757s	
341/2700 (epoch 6.315), train_loss = 2.16440383, grad/param norm = 8.7618e-01, time/batch = 0.1604s	
342/2700 (epoch 6.333), train_loss = 2.15112991, grad/param norm = 8.9597e-01, time/batch = 0.1706s	
343/2700 (epoch 6.352), train_loss = 2.19408276, grad/param norm = 9.7556e-01, time/batch = 0.1738s	
344/2700 (epoch 6.370), train_loss = 2.22272403, grad/param norm = 1.6105e+00, time/batch = 0.1827s	
345/2700 (epoch 6.389), train_loss = 2.19967228, grad/param norm = 9.4088e-01, time/batch = 0.1817s	
346/2700 (epoch 6.407), train_loss = 2.15001514, grad/param norm = 8.2931e-01, time/batch = 0.1721s	
347/2700 (epoch 6.426), train_loss = 2.18374307, grad/param norm = 1.0203e+00, time/batch = 0.1737s	
348/2700 (epoch 6.444), train_loss = 2.09772151, grad/param norm = 1.2558e+00, time/batch = 0.1834s	
349/2700 (epoch 6.463), train_loss = 2.17349773, grad/param norm = 1.3149e+00, time/batch = 0.1859s	
350/2700 (epoch 6.481), train_loss = 2.21533807, grad/param norm = 1.2693e+00, time/batch = 0.1807s	
351/2700 (epoch 6.500), train_loss = 2.20089239, grad/param norm = 1.2827e+00, time/batch = 0.1645s	
352/2700 (epoch 6.519), train_loss = 2.14078359, grad/param norm = 1.1012e+00, time/batch = 0.1690s	
353/2700 (epoch 6.537), train_loss = 2.16116191, grad/param norm = 8.4770e-01, time/batch = 0.1662s	
354/2700 (epoch 6.556), train_loss = 2.11992147, grad/param norm = 6.7607e-01, time/batch = 0.1582s	
355/2700 (epoch 6.574), train_loss = 2.08909282, grad/param norm = 6.4960e-01, time/batch = 0.1479s	
356/2700 (epoch 6.593), train_loss = 2.08624442, grad/param norm = 6.7894e-01, time/batch = 0.1674s	
357/2700 (epoch 6.611), train_loss = 2.00839631, grad/param norm = 7.0030e-01, time/batch = 0.1614s	
358/2700 (epoch 6.630), train_loss = 2.06082571, grad/param norm = 7.8005e-01, time/batch = 0.1708s	
359/2700 (epoch 6.648), train_loss = 2.10131100, grad/param norm = 8.3730e-01, time/batch = 0.1743s	
360/2700 (epoch 6.667), train_loss = 2.07212286, grad/param norm = 9.6604e-01, time/batch = 0.1759s	
361/2700 (epoch 6.685), train_loss = 2.09906374, grad/param norm = 8.7929e-01, time/batch = 0.1717s	
362/2700 (epoch 6.704), train_loss = 2.09193866, grad/param norm = 8.9183e-01, time/batch = 0.1694s	
363/2700 (epoch 6.722), train_loss = 2.06407701, grad/param norm = 1.0535e+00, time/batch = 0.1803s	
364/2700 (epoch 6.741), train_loss = 2.19758718, grad/param norm = 1.3547e+00, time/batch = 0.1819s	
365/2700 (epoch 6.759), train_loss = 2.18613703, grad/param norm = 1.5105e+00, time/batch = 0.1749s	
366/2700 (epoch 6.778), train_loss = 2.16769482, grad/param norm = 1.1716e+00, time/batch = 0.1761s	
367/2700 (epoch 6.796), train_loss = 2.11391210, grad/param norm = 1.0079e+00, time/batch = 0.1816s	
368/2700 (epoch 6.815), train_loss = 2.14206813, grad/param norm = 8.9422e-01, time/batch = 0.1794s	
369/2700 (epoch 6.833), train_loss = 2.10924088, grad/param norm = 9.1927e-01, time/batch = 0.1802s	
370/2700 (epoch 6.852), train_loss = 2.13010187, grad/param norm = 8.3217e-01, time/batch = 0.1794s	
371/2700 (epoch 6.870), train_loss = 2.09641727, grad/param norm = 7.2341e-01, time/batch = 0.1557s	
372/2700 (epoch 6.889), train_loss = 2.09318625, grad/param norm = 6.2495e-01, time/batch = 0.1493s	
373/2700 (epoch 6.907), train_loss = 2.20324450, grad/param norm = 7.5083e-01, time/batch = 0.1660s	
374/2700 (epoch 6.926), train_loss = 2.14804354, grad/param norm = 9.5353e-01, time/batch = 0.1686s	
375/2700 (epoch 6.944), train_loss = 2.13663488, grad/param norm = 8.0233e-01, time/batch = 0.1526s	
376/2700 (epoch 6.963), train_loss = 2.18128973, grad/param norm = 9.0877e-01, time/batch = 0.1381s	
377/2700 (epoch 6.981), train_loss = 2.17023796, grad/param norm = 8.7063e-01, time/batch = 0.1355s	
378/2700 (epoch 7.000), train_loss = 2.16545626, grad/param norm = 7.9524e-01, time/batch = 0.1381s	
379/2700 (epoch 7.019), train_loss = 2.14672777, grad/param norm = 8.6304e-01, time/batch = 0.1494s	
380/2700 (epoch 7.037), train_loss = 2.13682155, grad/param norm = 8.4011e-01, time/batch = 0.1593s	
381/2700 (epoch 7.056), train_loss = 2.08196516, grad/param norm = 6.6123e-01, time/batch = 0.1641s	
382/2700 (epoch 7.074), train_loss = 2.05591849, grad/param norm = 5.9833e-01, time/batch = 0.1675s	
383/2700 (epoch 7.093), train_loss = 2.11385962, grad/param norm = 6.4005e-01, time/batch = 0.1586s	
384/2700 (epoch 7.111), train_loss = 2.06795897, grad/param norm = 7.9120e-01, time/batch = 0.1773s	
385/2700 (epoch 7.130), train_loss = 2.09916816, grad/param norm = 9.2355e-01, time/batch = 0.1758s	
386/2700 (epoch 7.148), train_loss = 2.06919156, grad/param norm = 1.2968e+00, time/batch = 0.1809s	
387/2700 (epoch 7.167), train_loss = 2.14946784, grad/param norm = 9.9512e-01, time/batch = 0.1808s	
388/2700 (epoch 7.185), train_loss = 2.05489033, grad/param norm = 8.9328e-01, time/batch = 0.1818s	
389/2700 (epoch 7.204), train_loss = 2.10239849, grad/param norm = 1.0781e+00, time/batch = 0.1801s	
390/2700 (epoch 7.222), train_loss = 1.99164011, grad/param norm = 9.9648e-01, time/batch = 0.1792s	
391/2700 (epoch 7.241), train_loss = 1.95005696, grad/param norm = 7.6131e-01, time/batch = 0.1717s	
392/2700 (epoch 7.259), train_loss = 2.00822475, grad/param norm = 6.0234e-01, time/batch = 0.1771s	
393/2700 (epoch 7.278), train_loss = 2.09185548, grad/param norm = 6.6712e-01, time/batch = 0.1644s	
394/2700 (epoch 7.296), train_loss = 2.06763982, grad/param norm = 6.8773e-01, time/batch = 0.1771s	
395/2700 (epoch 7.315), train_loss = 2.09032056, grad/param norm = 7.6033e-01, time/batch = 0.1744s	
396/2700 (epoch 7.333), train_loss = 2.07783445, grad/param norm = 8.0617e-01, time/batch = 0.1828s	
397/2700 (epoch 7.352), train_loss = 2.11077747, grad/param norm = 8.3445e-01, time/batch = 0.1820s	
398/2700 (epoch 7.370), train_loss = 2.12305320, grad/param norm = 9.1356e-01, time/batch = 0.1827s	
399/2700 (epoch 7.389), train_loss = 2.10237672, grad/param norm = 9.5155e-01, time/batch = 0.1788s	
400/2700 (epoch 7.407), train_loss = 2.08155550, grad/param norm = 9.4745e-01, time/batch = 0.1795s	
401/2700 (epoch 7.426), train_loss = 2.11983534, grad/param norm = 8.7325e-01, time/batch = 0.1715s	
402/2700 (epoch 7.444), train_loss = 2.03116134, grad/param norm = 9.7301e-01, time/batch = 0.1643s	
403/2700 (epoch 7.463), train_loss = 2.10771591, grad/param norm = 1.1739e+00, time/batch = 0.1481s	
404/2700 (epoch 7.481), train_loss = 2.14402310, grad/param norm = 1.1158e+00, time/batch = 0.1199s	
405/2700 (epoch 7.500), train_loss = 2.11364769, grad/param norm = 1.0600e+00, time/batch = 0.1667s	
406/2700 (epoch 7.519), train_loss = 2.06500765, grad/param norm = 9.2187e-01, time/batch = 0.1597s	
407/2700 (epoch 7.537), train_loss = 2.09918995, grad/param norm = 7.7836e-01, time/batch = 0.1564s	
408/2700 (epoch 7.556), train_loss = 2.05392235, grad/param norm = 6.9773e-01, time/batch = 0.1634s	
409/2700 (epoch 7.574), train_loss = 2.03496964, grad/param norm = 6.4788e-01, time/batch = 0.1685s	
410/2700 (epoch 7.593), train_loss = 2.02475916, grad/param norm = 6.4976e-01, time/batch = 0.1736s	
411/2700 (epoch 7.611), train_loss = 1.94668913, grad/param norm = 6.1909e-01, time/batch = 0.1633s	
412/2700 (epoch 7.630), train_loss = 1.99555459, grad/param norm = 6.9691e-01, time/batch = 0.1502s	
413/2700 (epoch 7.648), train_loss = 2.03596391, grad/param norm = 8.3180e-01, time/batch = 0.1476s	
414/2700 (epoch 7.667), train_loss = 2.01581379, grad/param norm = 1.0334e+00, time/batch = 0.1123s	
415/2700 (epoch 7.685), train_loss = 2.04417336, grad/param norm = 9.4454e-01, time/batch = 0.1783s	
416/2700 (epoch 7.704), train_loss = 2.04103343, grad/param norm = 9.8170e-01, time/batch = 0.1799s	
417/2700 (epoch 7.722), train_loss = 2.01903496, grad/param norm = 1.1529e+00, time/batch = 0.1787s	
418/2700 (epoch 7.741), train_loss = 2.13386337, grad/param norm = 1.3345e+00, time/batch = 0.1788s	
419/2700 (epoch 7.759), train_loss = 2.12271245, grad/param norm = 1.4893e+00, time/batch = 0.1720s	
420/2700 (epoch 7.778), train_loss = 2.10180464, grad/param norm = 9.9204e-01, time/batch = 0.1741s	
421/2700 (epoch 7.796), train_loss = 2.04720360, grad/param norm = 8.1041e-01, time/batch = 0.1821s	
422/2700 (epoch 7.815), train_loss = 2.07894354, grad/param norm = 7.5674e-01, time/batch = 0.1828s	
423/2700 (epoch 7.833), train_loss = 2.04472679, grad/param norm = 7.5259e-01, time/batch = 0.1720s	
424/2700 (epoch 7.852), train_loss = 2.05790263, grad/param norm = 6.2891e-01, time/batch = 0.1526s	
425/2700 (epoch 7.870), train_loss = 2.02753950, grad/param norm = 5.5403e-01, time/batch = 0.1815s	
426/2700 (epoch 7.889), train_loss = 2.02976052, grad/param norm = 5.7740e-01, time/batch = 0.1828s	
427/2700 (epoch 7.907), train_loss = 2.14482112, grad/param norm = 7.0602e-01, time/batch = 0.1798s	
428/2700 (epoch 7.926), train_loss = 2.08634723, grad/param norm = 8.7768e-01, time/batch = 0.1809s	
429/2700 (epoch 7.944), train_loss = 2.08167282, grad/param norm = 8.0292e-01, time/batch = 0.1792s	
430/2700 (epoch 7.963), train_loss = 2.11523868, grad/param norm = 8.3797e-01, time/batch = 0.1790s	
431/2700 (epoch 7.981), train_loss = 2.09851430, grad/param norm = 7.6711e-01, time/batch = 0.1790s	
432/2700 (epoch 8.000), train_loss = 2.09942709, grad/param norm = 6.4683e-01, time/batch = 0.1779s	
433/2700 (epoch 8.019), train_loss = 2.08249061, grad/param norm = 7.5099e-01, time/batch = 0.1669s	
434/2700 (epoch 8.037), train_loss = 2.08064136, grad/param norm = 7.3582e-01, time/batch = 0.1597s	
435/2700 (epoch 8.056), train_loss = 2.02274440, grad/param norm = 7.5126e-01, time/batch = 0.1539s	
436/2700 (epoch 8.074), train_loss = 1.99765810, grad/param norm = 7.5284e-01, time/batch = 0.1632s	
437/2700 (epoch 8.093), train_loss = 2.05037166, grad/param norm = 8.2366e-01, time/batch = 0.1630s	
438/2700 (epoch 8.111), train_loss = 2.01147287, grad/param norm = 8.7884e-01, time/batch = 0.1591s	
439/2700 (epoch 8.130), train_loss = 2.03160784, grad/param norm = 7.3036e-01, time/batch = 0.1555s	
440/2700 (epoch 8.148), train_loss = 1.98884548, grad/param norm = 7.3574e-01, time/batch = 0.1536s	
441/2700 (epoch 8.167), train_loss = 2.06054046, grad/param norm = 7.4175e-01, time/batch = 0.1724s	
442/2700 (epoch 8.185), train_loss = 1.98554550, grad/param norm = 8.0047e-01, time/batch = 0.1688s	
443/2700 (epoch 8.204), train_loss = 2.04759466, grad/param norm = 9.1588e-01, time/batch = 0.1401s	
444/2700 (epoch 8.222), train_loss = 1.92949389, grad/param norm = 8.4167e-01, time/batch = 0.1595s	
445/2700 (epoch 8.241), train_loss = 1.88673038, grad/param norm = 7.9167e-01, time/batch = 0.1452s	
446/2700 (epoch 8.259), train_loss = 1.94873077, grad/param norm = 6.2203e-01, time/batch = 0.1804s	
447/2700 (epoch 8.278), train_loss = 2.03082008, grad/param norm = 5.7489e-01, time/batch = 0.1798s	
448/2700 (epoch 8.296), train_loss = 2.01353450, grad/param norm = 6.3008e-01, time/batch = 0.1771s	
449/2700 (epoch 8.315), train_loss = 2.03606332, grad/param norm = 7.4778e-01, time/batch = 0.1742s	
450/2700 (epoch 8.333), train_loss = 2.03099599, grad/param norm = 7.6132e-01, time/batch = 0.1696s	
451/2700 (epoch 8.352), train_loss = 2.06221616, grad/param norm = 1.0424e+00, time/batch = 0.1739s	
452/2700 (epoch 8.370), train_loss = 2.09704952, grad/param norm = 1.1986e+00, time/batch = 0.1748s	
453/2700 (epoch 8.389), train_loss = 2.06509224, grad/param norm = 9.9687e-01, time/batch = 0.1718s	
454/2700 (epoch 8.407), train_loss = 2.04100679, grad/param norm = 8.7218e-01, time/batch = 0.1810s	
455/2700 (epoch 8.426), train_loss = 2.06559301, grad/param norm = 9.7713e-01, time/batch = 0.1698s	
456/2700 (epoch 8.444), train_loss = 1.97421069, grad/param norm = 9.0852e-01, time/batch = 0.1838s	
457/2700 (epoch 8.463), train_loss = 2.02740629, grad/param norm = 7.1124e-01, time/batch = 0.1844s	
458/2700 (epoch 8.481), train_loss = 2.07008041, grad/param norm = 6.1262e-01, time/batch = 0.1847s	
459/2700 (epoch 8.500), train_loss = 2.03643733, grad/param norm = 6.3127e-01, time/batch = 0.1829s	
460/2700 (epoch 8.519), train_loss = 2.00702888, grad/param norm = 7.4365e-01, time/batch = 0.1804s	
461/2700 (epoch 8.537), train_loss = 2.04442400, grad/param norm = 7.3157e-01, time/batch = 0.1635s	
462/2700 (epoch 8.556), train_loss = 1.99902596, grad/param norm = 6.8291e-01, time/batch = 0.1535s	
463/2700 (epoch 8.574), train_loss = 1.99897666, grad/param norm = 8.2926e-01, time/batch = 0.1593s	
464/2700 (epoch 8.593), train_loss = 1.99289094, grad/param norm = 8.5703e-01, time/batch = 0.1710s	
465/2700 (epoch 8.611), train_loss = 1.90721569, grad/param norm = 8.7737e-01, time/batch = 0.1653s	
466/2700 (epoch 8.630), train_loss = 1.96360561, grad/param norm = 9.7667e-01, time/batch = 0.1635s	
467/2700 (epoch 8.648), train_loss = 1.99823599, grad/param norm = 1.0492e+00, time/batch = 0.1673s	
468/2700 (epoch 8.667), train_loss = 1.97402299, grad/param norm = 1.0355e+00, time/batch = 0.1580s	
469/2700 (epoch 8.685), train_loss = 1.98313481, grad/param norm = 8.3265e-01, time/batch = 0.1564s	
470/2700 (epoch 8.704), train_loss = 1.97927916, grad/param norm = 8.5726e-01, time/batch = 0.1607s	
471/2700 (epoch 8.722), train_loss = 1.95862456, grad/param norm = 8.8893e-01, time/batch = 0.1642s	
472/2700 (epoch 8.741), train_loss = 2.04787411, grad/param norm = 9.0895e-01, time/batch = 0.1682s	
473/2700 (epoch 8.759), train_loss = 2.04362220, grad/param norm = 9.4740e-01, time/batch = 0.1517s	
474/2700 (epoch 8.778), train_loss = 2.03076805, grad/param norm = 8.0254e-01, time/batch = 0.1550s	
475/2700 (epoch 8.796), train_loss = 1.98514813, grad/param norm = 6.8494e-01, time/batch = 0.1604s	
476/2700 (epoch 8.815), train_loss = 2.01632289, grad/param norm = 6.5161e-01, time/batch = 0.1501s	
477/2700 (epoch 8.833), train_loss = 1.98020857, grad/param norm = 6.6887e-01, time/batch = 0.1836s	
478/2700 (epoch 8.852), train_loss = 1.99690430, grad/param norm = 5.5874e-01, time/batch = 0.1824s	
479/2700 (epoch 8.870), train_loss = 1.97016925, grad/param norm = 5.0542e-01, time/batch = 0.1830s	
480/2700 (epoch 8.889), train_loss = 1.97286554, grad/param norm = 5.4564e-01, time/batch = 0.1827s	
481/2700 (epoch 8.907), train_loss = 2.09060725, grad/param norm = 6.7366e-01, time/batch = 0.1669s	
482/2700 (epoch 8.926), train_loss = 2.03384360, grad/param norm = 7.8857e-01, time/batch = 0.1630s	
483/2700 (epoch 8.944), train_loss = 2.01922134, grad/param norm = 6.7943e-01, time/batch = 0.1565s	
484/2700 (epoch 8.963), train_loss = 2.05208898, grad/param norm = 7.8874e-01, time/batch = 0.1821s	
485/2700 (epoch 8.981), train_loss = 2.03895693, grad/param norm = 7.6810e-01, time/batch = 0.1821s	
486/2700 (epoch 9.000), train_loss = 2.05092734, grad/param norm = 7.5201e-01, time/batch = 0.1692s	
487/2700 (epoch 9.019), train_loss = 2.03697290, grad/param norm = 9.8659e-01, time/batch = 0.1674s	
488/2700 (epoch 9.037), train_loss = 2.03232370, grad/param norm = 7.5497e-01, time/batch = 0.1565s	
489/2700 (epoch 9.056), train_loss = 1.96366769, grad/param norm = 6.2891e-01, time/batch = 0.1403s	
490/2700 (epoch 9.074), train_loss = 1.94032800, grad/param norm = 5.7090e-01, time/batch = 0.1360s	
491/2700 (epoch 9.093), train_loss = 1.98931438, grad/param norm = 6.1838e-01, time/batch = 0.1709s	
492/2700 (epoch 9.111), train_loss = 1.95067336, grad/param norm = 7.6867e-01, time/batch = 0.1635s	
493/2700 (epoch 9.130), train_loss = 1.99022135, grad/param norm = 9.3120e-01, time/batch = 0.1716s	
494/2700 (epoch 9.148), train_loss = 1.95333814, grad/param norm = 1.1693e+00, time/batch = 0.1772s	
495/2700 (epoch 9.167), train_loss = 2.03977530, grad/param norm = 9.1697e-01, time/batch = 0.1761s	
496/2700 (epoch 9.185), train_loss = 1.94954234, grad/param norm = 7.6682e-01, time/batch = 0.1739s	
497/2700 (epoch 9.204), train_loss = 1.99216567, grad/param norm = 6.8645e-01, time/batch = 0.1454s	
498/2700 (epoch 9.222), train_loss = 1.87610338, grad/param norm = 6.7718e-01, time/batch = 0.1800s	
499/2700 (epoch 9.241), train_loss = 1.82895061, grad/param norm = 5.9581e-01, time/batch = 0.1797s	
500/2700 (epoch 9.259), train_loss = 1.90306123, grad/param norm = 6.1792e-01, time/batch = 0.1770s	
501/2700 (epoch 9.278), train_loss = 1.99030350, grad/param norm = 7.4740e-01, time/batch = 0.1707s	
502/2700 (epoch 9.296), train_loss = 1.97239651, grad/param norm = 8.5745e-01, time/batch = 0.1701s	
503/2700 (epoch 9.315), train_loss = 1.99584513, grad/param norm = 8.3246e-01, time/batch = 0.1759s	
504/2700 (epoch 9.333), train_loss = 1.97123005, grad/param norm = 7.2927e-01, time/batch = 0.1767s	
505/2700 (epoch 9.352), train_loss = 1.99175113, grad/param norm = 6.5195e-01, time/batch = 0.1781s	
506/2700 (epoch 9.370), train_loss = 2.01013886, grad/param norm = 7.7930e-01, time/batch = 0.1815s	
507/2700 (epoch 9.389), train_loss = 1.99175980, grad/param norm = 9.7521e-01, time/batch = 0.1671s	
508/2700 (epoch 9.407), train_loss = 1.99074854, grad/param norm = 8.4585e-01, time/batch = 0.1788s	
509/2700 (epoch 9.426), train_loss = 2.00848071, grad/param norm = 8.5495e-01, time/batch = 0.1764s	
510/2700 (epoch 9.444), train_loss = 1.92369699, grad/param norm = 9.0108e-01, time/batch = 0.1561s	
511/2700 (epoch 9.463), train_loss = 1.97521588, grad/param norm = 7.6038e-01, time/batch = 0.1622s	
512/2700 (epoch 9.481), train_loss = 2.01717584, grad/param norm = 8.4090e-01, time/batch = 0.1535s	
513/2700 (epoch 9.500), train_loss = 1.99025875, grad/param norm = 8.2012e-01, time/batch = 0.1805s	
514/2700 (epoch 9.519), train_loss = 1.96139234, grad/param norm = 6.7918e-01, time/batch = 0.1788s	
515/2700 (epoch 9.537), train_loss = 2.00136554, grad/param norm = 6.6537e-01, time/batch = 0.1783s	
516/2700 (epoch 9.556), train_loss = 1.94036407, grad/param norm = 6.3214e-01, time/batch = 0.1735s	
517/2700 (epoch 9.574), train_loss = 1.93924682, grad/param norm = 5.8456e-01, time/batch = 0.1650s	
518/2700 (epoch 9.593), train_loss = 1.91765596, grad/param norm = 5.8160e-01, time/batch = 0.1411s	
519/2700 (epoch 9.611), train_loss = 1.84230089, grad/param norm = 5.6842e-01, time/batch = 0.1784s	
520/2700 (epoch 9.630), train_loss = 1.89209917, grad/param norm = 6.2650e-01, time/batch = 0.1826s	
521/2700 (epoch 9.648), train_loss = 1.92957671, grad/param norm = 6.6267e-01, time/batch = 0.1673s	
522/2700 (epoch 9.667), train_loss = 1.90277735, grad/param norm = 6.1760e-01, time/batch = 0.1596s	
523/2700 (epoch 9.685), train_loss = 1.92635783, grad/param norm = 5.7461e-01, time/batch = 0.1781s	
524/2700 (epoch 9.704), train_loss = 1.92577861, grad/param norm = 6.5690e-01, time/batch = 0.1827s	
525/2700 (epoch 9.722), train_loss = 1.91061617, grad/param norm = 6.0162e-01, time/batch = 0.1813s	
526/2700 (epoch 9.741), train_loss = 1.98161142, grad/param norm = 5.5614e-01, time/batch = 0.1814s	
527/2700 (epoch 9.759), train_loss = 1.98903251, grad/param norm = 7.0307e-01, time/batch = 0.1771s	
528/2700 (epoch 9.778), train_loss = 1.99248594, grad/param norm = 9.2172e-01, time/batch = 0.1560s	
529/2700 (epoch 9.796), train_loss = 1.97106853, grad/param norm = 1.0168e+00, time/batch = 0.1497s	
530/2700 (epoch 9.815), train_loss = 2.00243696, grad/param norm = 1.2568e+00, time/batch = 0.1505s	
531/2700 (epoch 9.833), train_loss = 1.97031786, grad/param norm = 1.2948e+00, time/batch = 0.1758s	
532/2700 (epoch 9.852), train_loss = 1.99498186, grad/param norm = 1.0872e+00, time/batch = 0.1798s	
533/2700 (epoch 9.870), train_loss = 1.96340303, grad/param norm = 9.0628e-01, time/batch = 0.1804s	
534/2700 (epoch 9.889), train_loss = 1.94460817, grad/param norm = 7.8353e-01, time/batch = 0.1774s	
535/2700 (epoch 9.907), train_loss = 2.05311427, grad/param norm = 6.9359e-01, time/batch = 0.1718s	
536/2700 (epoch 9.926), train_loss = 1.98689679, grad/param norm = 6.6992e-01, time/batch = 0.1730s	
537/2700 (epoch 9.944), train_loss = 1.96657768, grad/param norm = 5.7072e-01, time/batch = 0.1787s	
538/2700 (epoch 9.963), train_loss = 1.99883005, grad/param norm = 6.1651e-01, time/batch = 0.1839s	
539/2700 (epoch 9.981), train_loss = 1.98795468, grad/param norm = 5.7087e-01, time/batch = 0.1589s	
decayed learning rate by a factor 0.97 to 0.00194	
540/2700 (epoch 10.000), train_loss = 2.00524537, grad/param norm = 5.7287e-01, time/batch = 0.1613s	
541/2700 (epoch 10.019), train_loss = 1.97642239, grad/param norm = 6.3903e-01, time/batch = 0.1691s	
542/2700 (epoch 10.037), train_loss = 1.98113888, grad/param norm = 5.9395e-01, time/batch = 0.1807s	
543/2700 (epoch 10.056), train_loss = 1.91944813, grad/param norm = 7.6803e-01, time/batch = 0.1820s	
544/2700 (epoch 10.074), train_loss = 1.90329596, grad/param norm = 7.6337e-01, time/batch = 0.1817s	
545/2700 (epoch 10.093), train_loss = 1.93885432, grad/param norm = 6.9502e-01, time/batch = 0.1825s	
546/2700 (epoch 10.111), train_loss = 1.89895533, grad/param norm = 6.9082e-01, time/batch = 0.1797s	
547/2700 (epoch 10.130), train_loss = 1.92569767, grad/param norm = 5.9501e-01, time/batch = 0.1728s	
548/2700 (epoch 10.148), train_loss = 1.87341516, grad/param norm = 5.9252e-01, time/batch = 0.1557s	
549/2700 (epoch 10.167), train_loss = 1.95466951, grad/param norm = 5.1954e-01, time/batch = 0.1456s	
550/2700 (epoch 10.185), train_loss = 1.87265501, grad/param norm = 5.5156e-01, time/batch = 0.1431s	
551/2700 (epoch 10.204), train_loss = 1.93627717, grad/param norm = 5.7201e-01, time/batch = 0.1554s	
552/2700 (epoch 10.222), train_loss = 1.82440280, grad/param norm = 6.0853e-01, time/batch = 0.1570s	
553/2700 (epoch 10.241), train_loss = 1.78355312, grad/param norm = 6.7062e-01, time/batch = 0.1738s	
554/2700 (epoch 10.259), train_loss = 1.86906968, grad/param norm = 6.7933e-01, time/batch = 0.1824s	
555/2700 (epoch 10.278), train_loss = 1.94815018, grad/param norm = 6.3385e-01, time/batch = 0.1832s	
556/2700 (epoch 10.296), train_loss = 1.93455419, grad/param norm = 6.8216e-01, time/batch = 0.1809s	
557/2700 (epoch 10.315), train_loss = 1.94628723, grad/param norm = 7.6475e-01, time/batch = 0.1806s	
558/2700 (epoch 10.333), train_loss = 1.93836906, grad/param norm = 6.9775e-01, time/batch = 0.1844s	
559/2700 (epoch 10.352), train_loss = 1.94632000, grad/param norm = 6.5814e-01, time/batch = 0.1551s	
560/2700 (epoch 10.370), train_loss = 1.96287071, grad/param norm = 7.2156e-01, time/batch = 0.1637s	
561/2700 (epoch 10.389), train_loss = 1.94747667, grad/param norm = 7.3138e-01, time/batch = 0.1742s	
562/2700 (epoch 10.407), train_loss = 1.92943949, grad/param norm = 7.1450e-01, time/batch = 0.1637s	
563/2700 (epoch 10.426), train_loss = 1.95698179, grad/param norm = 7.1417e-01, time/batch = 0.1575s	
564/2700 (epoch 10.444), train_loss = 1.86854322, grad/param norm = 6.4626e-01, time/batch = 0.1560s	
565/2700 (epoch 10.463), train_loss = 1.93472491, grad/param norm = 6.6352e-01, time/batch = 0.1603s	
566/2700 (epoch 10.481), train_loss = 1.97448701, grad/param norm = 6.1557e-01, time/batch = 0.1656s	
567/2700 (epoch 10.500), train_loss = 1.92851202, grad/param norm = 6.0933e-01, time/batch = 0.1596s	
568/2700 (epoch 10.519), train_loss = 1.91467407, grad/param norm = 6.0349e-01, time/batch = 0.1679s	
569/2700 (epoch 10.537), train_loss = 1.95752154, grad/param norm = 6.1082e-01, time/batch = 0.1598s	
570/2700 (epoch 10.556), train_loss = 1.89032026, grad/param norm = 6.8036e-01, time/batch = 0.1798s	
571/2700 (epoch 10.574), train_loss = 1.89694546, grad/param norm = 6.1871e-01, time/batch = 0.1794s	
572/2700 (epoch 10.593), train_loss = 1.87871917, grad/param norm = 6.3886e-01, time/batch = 0.1731s	
573/2700 (epoch 10.611), train_loss = 1.80797112, grad/param norm = 6.6384e-01, time/batch = 0.1764s	
574/2700 (epoch 10.630), train_loss = 1.85864162, grad/param norm = 6.9208e-01, time/batch = 0.1711s	
575/2700 (epoch 10.648), train_loss = 1.88621390, grad/param norm = 6.6250e-01, time/batch = 0.1707s	
576/2700 (epoch 10.667), train_loss = 1.86430955, grad/param norm = 6.2963e-01, time/batch = 0.1796s	
577/2700 (epoch 10.685), train_loss = 1.88379159, grad/param norm = 5.9574e-01, time/batch = 0.1648s	
578/2700 (epoch 10.704), train_loss = 1.88214808, grad/param norm = 6.3693e-01, time/batch = 0.1742s	
579/2700 (epoch 10.722), train_loss = 1.86868958, grad/param norm = 6.5369e-01, time/batch = 0.1652s	
580/2700 (epoch 10.741), train_loss = 1.93933621, grad/param norm = 7.7008e-01, time/batch = 0.1742s	
581/2700 (epoch 10.759), train_loss = 1.95632476, grad/param norm = 9.6239e-01, time/batch = 0.1849s	
582/2700 (epoch 10.778), train_loss = 1.96780030, grad/param norm = 1.0268e+00, time/batch = 0.1763s	
583/2700 (epoch 10.796), train_loss = 1.92838607, grad/param norm = 1.0266e+00, time/batch = 0.1682s	
584/2700 (epoch 10.815), train_loss = 1.96084261, grad/param norm = 9.3802e-01, time/batch = 0.1592s	
585/2700 (epoch 10.833), train_loss = 1.91902134, grad/param norm = 8.7236e-01, time/batch = 0.1575s	
586/2700 (epoch 10.852), train_loss = 1.92173599, grad/param norm = 7.3225e-01, time/batch = 0.1473s	
587/2700 (epoch 10.870), train_loss = 1.89469585, grad/param norm = 6.9383e-01, time/batch = 0.1730s	
588/2700 (epoch 10.889), train_loss = 1.88750290, grad/param norm = 5.7189e-01, time/batch = 0.1709s	
589/2700 (epoch 10.907), train_loss = 2.00514564, grad/param norm = 5.5832e-01, time/batch = 0.1640s	
590/2700 (epoch 10.926), train_loss = 1.94287321, grad/param norm = 6.2450e-01, time/batch = 0.1468s	
591/2700 (epoch 10.944), train_loss = 1.91889030, grad/param norm = 5.9516e-01, time/batch = 0.1603s	
592/2700 (epoch 10.963), train_loss = 1.95687798, grad/param norm = 5.9810e-01, time/batch = 0.1555s	
593/2700 (epoch 10.981), train_loss = 1.94164309, grad/param norm = 5.6885e-01, time/batch = 0.1526s	
decayed learning rate by a factor 0.97 to 0.0018818	
594/2700 (epoch 11.000), train_loss = 1.96812030, grad/param norm = 5.2090e-01, time/batch = 0.1519s	
595/2700 (epoch 11.019), train_loss = 1.93155807, grad/param norm = 6.1866e-01, time/batch = 0.1496s	
596/2700 (epoch 11.037), train_loss = 1.95057323, grad/param norm = 7.9867e-01, time/batch = 0.1309s	
597/2700 (epoch 11.056), train_loss = 1.88657120, grad/param norm = 8.3414e-01, time/batch = 0.1558s	
598/2700 (epoch 11.074), train_loss = 1.86989583, grad/param norm = 7.4627e-01, time/batch = 0.1619s	
599/2700 (epoch 11.093), train_loss = 1.89399432, grad/param norm = 6.4287e-01, time/batch = 0.1667s	
600/2700 (epoch 11.111), train_loss = 1.84767558, grad/param norm = 5.9680e-01, time/batch = 0.1462s	
601/2700 (epoch 11.130), train_loss = 1.87920424, grad/param norm = 5.3010e-01, time/batch = 0.1806s	
602/2700 (epoch 11.148), train_loss = 1.82717994, grad/param norm = 6.2513e-01, time/batch = 0.1816s	
603/2700 (epoch 11.167), train_loss = 1.91642048, grad/param norm = 5.3553e-01, time/batch = 0.1811s	
604/2700 (epoch 11.185), train_loss = 1.82647858, grad/param norm = 4.6606e-01, time/batch = 0.1841s	
605/2700 (epoch 11.204), train_loss = 1.89938493, grad/param norm = 5.3372e-01, time/batch = 0.1789s	
606/2700 (epoch 11.222), train_loss = 1.79455748, grad/param norm = 6.3106e-01, time/batch = 0.1848s	
607/2700 (epoch 11.241), train_loss = 1.74620162, grad/param norm = 5.9619e-01, time/batch = 0.1847s	
608/2700 (epoch 11.259), train_loss = 1.82574908, grad/param norm = 6.0834e-01, time/batch = 0.1846s	
609/2700 (epoch 11.278), train_loss = 1.90409436, grad/param norm = 6.1595e-01, time/batch = 0.1707s	
610/2700 (epoch 11.296), train_loss = 1.88127859, grad/param norm = 6.8150e-01, time/batch = 0.1799s	
611/2700 (epoch 11.315), train_loss = 1.89843475, grad/param norm = 6.7306e-01, time/batch = 0.1782s	
612/2700 (epoch 11.333), train_loss = 1.88610975, grad/param norm = 6.2449e-01, time/batch = 0.1797s	
613/2700 (epoch 11.352), train_loss = 1.89639673, grad/param norm = 5.3884e-01, time/batch = 0.1726s	
614/2700 (epoch 11.370), train_loss = 1.91455353, grad/param norm = 5.7930e-01, time/batch = 0.1685s	
615/2700 (epoch 11.389), train_loss = 1.89672456, grad/param norm = 6.4171e-01, time/batch = 0.1513s	
616/2700 (epoch 11.407), train_loss = 1.89167749, grad/param norm = 6.6391e-01, time/batch = 0.1473s	
617/2700 (epoch 11.426), train_loss = 1.92223945, grad/param norm = 6.5064e-01, time/batch = 0.1249s	
618/2700 (epoch 11.444), train_loss = 1.84288600, grad/param norm = 8.6422e-01, time/batch = 0.1553s	
619/2700 (epoch 11.463), train_loss = 1.91583151, grad/param norm = 8.6369e-01, time/batch = 0.1416s	
620/2700 (epoch 11.481), train_loss = 1.94041541, grad/param norm = 7.9975e-01, time/batch = 0.1554s	
621/2700 (epoch 11.500), train_loss = 1.90060247, grad/param norm = 8.0240e-01, time/batch = 0.1399s	
622/2700 (epoch 11.519), train_loss = 1.88591123, grad/param norm = 7.1079e-01, time/batch = 0.1642s	
623/2700 (epoch 11.537), train_loss = 1.91542306, grad/param norm = 6.2520e-01, time/batch = 0.1638s	
624/2700 (epoch 11.556), train_loss = 1.83462004, grad/param norm = 5.0205e-01, time/batch = 0.1573s	
625/2700 (epoch 11.574), train_loss = 1.84737968, grad/param norm = 5.4505e-01, time/batch = 0.1532s	
626/2700 (epoch 11.593), train_loss = 1.83914788, grad/param norm = 5.9048e-01, time/batch = 0.1555s	
627/2700 (epoch 11.611), train_loss = 1.75805117, grad/param norm = 5.1119e-01, time/batch = 0.1444s	
628/2700 (epoch 11.630), train_loss = 1.80519807, grad/param norm = 5.5881e-01, time/batch = 0.1634s	
629/2700 (epoch 11.648), train_loss = 1.84206212, grad/param norm = 6.3261e-01, time/batch = 0.1569s	
630/2700 (epoch 11.667), train_loss = 1.82785057, grad/param norm = 6.9858e-01, time/batch = 0.1813s	
631/2700 (epoch 11.685), train_loss = 1.85340892, grad/param norm = 7.0707e-01, time/batch = 0.1544s	
632/2700 (epoch 11.704), train_loss = 1.85909315, grad/param norm = 7.2285e-01, time/batch = 0.1773s	
633/2700 (epoch 11.722), train_loss = 1.83783033, grad/param norm = 6.9920e-01, time/batch = 0.1751s	
634/2700 (epoch 11.741), train_loss = 1.89376878, grad/param norm = 7.9292e-01, time/batch = 0.1770s	
635/2700 (epoch 11.759), train_loss = 1.91945704, grad/param norm = 9.1832e-01, time/batch = 0.1739s	
636/2700 (epoch 11.778), train_loss = 1.92486621, grad/param norm = 8.4395e-01, time/batch = 0.1633s	
637/2700 (epoch 11.796), train_loss = 1.88366244, grad/param norm = 7.5147e-01, time/batch = 0.1604s	
638/2700 (epoch 11.815), train_loss = 1.89818830, grad/param norm = 6.3194e-01, time/batch = 0.1558s	
639/2700 (epoch 11.833), train_loss = 1.84910052, grad/param norm = 5.6109e-01, time/batch = 0.1530s	
640/2700 (epoch 11.852), train_loss = 1.86080153, grad/param norm = 4.7175e-01, time/batch = 0.1603s	
641/2700 (epoch 11.870), train_loss = 1.84941838, grad/param norm = 4.5296e-01, time/batch = 0.1564s	
642/2700 (epoch 11.889), train_loss = 1.83909115, grad/param norm = 4.3712e-01, time/batch = 0.1505s	
643/2700 (epoch 11.907), train_loss = 1.96452730, grad/param norm = 5.0861e-01, time/batch = 0.1833s	
644/2700 (epoch 11.926), train_loss = 1.90445710, grad/param norm = 5.8782e-01, time/batch = 0.1823s	
645/2700 (epoch 11.944), train_loss = 1.87975668, grad/param norm = 6.2310e-01, time/batch = 0.1809s	
646/2700 (epoch 11.963), train_loss = 1.92831226, grad/param norm = 8.6631e-01, time/batch = 0.1773s	
647/2700 (epoch 11.981), train_loss = 1.91231828, grad/param norm = 7.8573e-01, time/batch = 0.1849s	
decayed learning rate by a factor 0.97 to 0.001825346	
648/2700 (epoch 12.000), train_loss = 1.93803281, grad/param norm = 6.2714e-01, time/batch = 0.1781s	
649/2700 (epoch 12.019), train_loss = 1.90790179, grad/param norm = 9.3223e-01, time/batch = 0.1827s	
650/2700 (epoch 12.037), train_loss = 1.91982160, grad/param norm = 5.8596e-01, time/batch = 0.1802s	
651/2700 (epoch 12.056), train_loss = 1.84343907, grad/param norm = 5.9478e-01, time/batch = 0.1761s	
652/2700 (epoch 12.074), train_loss = 1.83144719, grad/param norm = 5.7316e-01, time/batch = 0.1598s	
653/2700 (epoch 12.093), train_loss = 1.84986315, grad/param norm = 5.8140e-01, time/batch = 0.1767s	
654/2700 (epoch 12.111), train_loss = 1.81339920, grad/param norm = 6.9961e-01, time/batch = 0.1704s	
655/2700 (epoch 12.130), train_loss = 1.85748967, grad/param norm = 8.2115e-01, time/batch = 0.1712s	
656/2700 (epoch 12.148), train_loss = 1.80941348, grad/param norm = 9.4150e-01, time/batch = 0.1574s	
657/2700 (epoch 12.167), train_loss = 1.89277447, grad/param norm = 6.7579e-01, time/batch = 0.1516s	
658/2700 (epoch 12.185), train_loss = 1.79454508, grad/param norm = 5.1181e-01, time/batch = 0.1397s	
659/2700 (epoch 12.204), train_loss = 1.86206675, grad/param norm = 4.8045e-01, time/batch = 0.1535s	
660/2700 (epoch 12.222), train_loss = 1.75017077, grad/param norm = 5.1089e-01, time/batch = 0.1630s	
661/2700 (epoch 12.241), train_loss = 1.70069672, grad/param norm = 4.9948e-01, time/batch = 0.1792s	
662/2700 (epoch 12.259), train_loss = 1.78645510, grad/param norm = 5.7934e-01, time/batch = 0.1820s	
663/2700 (epoch 12.278), train_loss = 1.86823198, grad/param norm = 5.9466e-01, time/batch = 0.1479s	
664/2700 (epoch 12.296), train_loss = 1.84772372, grad/param norm = 6.7510e-01, time/batch = 0.1487s	
665/2700 (epoch 12.315), train_loss = 1.86030817, grad/param norm = 6.6560e-01, time/batch = 0.1383s	
666/2700 (epoch 12.333), train_loss = 1.84827836, grad/param norm = 5.5069e-01, time/batch = 0.1522s	
667/2700 (epoch 12.352), train_loss = 1.85470441, grad/param norm = 4.8528e-01, time/batch = 0.1595s	
668/2700 (epoch 12.370), train_loss = 1.87045109, grad/param norm = 5.0124e-01, time/batch = 0.1561s	
669/2700 (epoch 12.389), train_loss = 1.85117569, grad/param norm = 5.2977e-01, time/batch = 0.1809s	
670/2700 (epoch 12.407), train_loss = 1.84790745, grad/param norm = 5.6252e-01, time/batch = 0.1785s	
671/2700 (epoch 12.426), train_loss = 1.87622360, grad/param norm = 5.7174e-01, time/batch = 0.1603s	
672/2700 (epoch 12.444), train_loss = 1.79264735, grad/param norm = 5.6971e-01, time/batch = 0.1718s	
673/2700 (epoch 12.463), train_loss = 1.85903883, grad/param norm = 5.8438e-01, time/batch = 0.1574s	
674/2700 (epoch 12.481), train_loss = 1.89365690, grad/param norm = 5.4895e-01, time/batch = 0.1742s	
675/2700 (epoch 12.500), train_loss = 1.84459229, grad/param norm = 4.8210e-01, time/batch = 0.1708s	
676/2700 (epoch 12.519), train_loss = 1.83456754, grad/param norm = 4.8172e-01, time/batch = 0.1756s	
677/2700 (epoch 12.537), train_loss = 1.87579157, grad/param norm = 5.5480e-01, time/batch = 0.1657s	
678/2700 (epoch 12.556), train_loss = 1.80906255, grad/param norm = 6.9814e-01, time/batch = 0.1434s	
679/2700 (epoch 12.574), train_loss = 1.83461825, grad/param norm = 7.9065e-01, time/batch = 0.1546s	
680/2700 (epoch 12.593), train_loss = 1.83167673, grad/param norm = 8.4440e-01, time/batch = 0.1643s	
681/2700 (epoch 12.611), train_loss = 1.74958084, grad/param norm = 8.7145e-01, time/batch = 0.1620s	
682/2700 (epoch 12.630), train_loss = 1.79488492, grad/param norm = 8.0125e-01, time/batch = 0.1739s	
683/2700 (epoch 12.648), train_loss = 1.80957453, grad/param norm = 6.9143e-01, time/batch = 0.1730s	
684/2700 (epoch 12.667), train_loss = 1.79160897, grad/param norm = 6.7697e-01, time/batch = 0.1621s	
685/2700 (epoch 12.685), train_loss = 1.81437838, grad/param norm = 5.9497e-01, time/batch = 0.1781s	
686/2700 (epoch 12.704), train_loss = 1.81528520, grad/param norm = 5.9809e-01, time/batch = 0.1834s	
687/2700 (epoch 12.722), train_loss = 1.79513480, grad/param norm = 5.8568e-01, time/batch = 0.1747s	
688/2700 (epoch 12.741), train_loss = 1.84537172, grad/param norm = 6.1662e-01, time/batch = 0.1811s	
689/2700 (epoch 12.759), train_loss = 1.87039747, grad/param norm = 6.8591e-01, time/batch = 0.1780s	
690/2700 (epoch 12.778), train_loss = 1.87290723, grad/param norm = 5.9622e-01, time/batch = 0.1793s	
691/2700 (epoch 12.796), train_loss = 1.83987950, grad/param norm = 6.3146e-01, time/batch = 0.1794s	
692/2700 (epoch 12.815), train_loss = 1.85987174, grad/param norm = 5.9555e-01, time/batch = 0.1805s	
693/2700 (epoch 12.833), train_loss = 1.80964687, grad/param norm = 5.6882e-01, time/batch = 0.1792s	
694/2700 (epoch 12.852), train_loss = 1.82399743, grad/param norm = 5.1524e-01, time/batch = 0.1698s	
695/2700 (epoch 12.870), train_loss = 1.82299051, grad/param norm = 4.8962e-01, time/batch = 0.1717s	
696/2700 (epoch 12.889), train_loss = 1.81426416, grad/param norm = 5.5829e-01, time/batch = 0.1762s	
697/2700 (epoch 12.907), train_loss = 1.94727602, grad/param norm = 6.6409e-01, time/batch = 0.1730s	
698/2700 (epoch 12.926), train_loss = 1.87931051, grad/param norm = 7.3339e-01, time/batch = 0.1821s	
699/2700 (epoch 12.944), train_loss = 1.85183337, grad/param norm = 6.9886e-01, time/batch = 0.1805s	
700/2700 (epoch 12.963), train_loss = 1.89737335, grad/param norm = 8.2256e-01, time/batch = 0.1807s	
701/2700 (epoch 12.981), train_loss = 1.87553408, grad/param norm = 7.0564e-01, time/batch = 0.1758s	
decayed learning rate by a factor 0.97 to 0.00177058562	
702/2700 (epoch 13.000), train_loss = 1.90808342, grad/param norm = 6.3087e-01, time/batch = 0.1646s	
703/2700 (epoch 13.019), train_loss = 1.87028948, grad/param norm = 6.3564e-01, time/batch = 0.1590s	
704/2700 (epoch 13.037), train_loss = 1.87800810, grad/param norm = 5.2236e-01, time/batch = 0.1369s	
705/2700 (epoch 13.056), train_loss = 1.79911375, grad/param norm = 5.3662e-01, time/batch = 0.1569s	
706/2700 (epoch 13.074), train_loss = 1.78526903, grad/param norm = 4.8288e-01, time/batch = 0.1649s	
707/2700 (epoch 13.093), train_loss = 1.80373421, grad/param norm = 4.9506e-01, time/batch = 0.1488s	
708/2700 (epoch 13.111), train_loss = 1.77623914, grad/param norm = 7.0748e-01, time/batch = 0.1394s	
709/2700 (epoch 13.130), train_loss = 1.82797909, grad/param norm = 8.2604e-01, time/batch = 0.1430s	
710/2700 (epoch 13.148), train_loss = 1.77171351, grad/param norm = 7.8413e-01, time/batch = 0.1467s	
711/2700 (epoch 13.167), train_loss = 1.85341543, grad/param norm = 5.6595e-01, time/batch = 0.1835s	
712/2700 (epoch 13.185), train_loss = 1.76212918, grad/param norm = 4.9773e-01, time/batch = 0.1768s	
713/2700 (epoch 13.204), train_loss = 1.82730025, grad/param norm = 4.6269e-01, time/batch = 0.1743s	
714/2700 (epoch 13.222), train_loss = 1.72153271, grad/param norm = 5.0950e-01, time/batch = 0.1548s	
715/2700 (epoch 13.241), train_loss = 1.67364821, grad/param norm = 5.3256e-01, time/batch = 0.1487s	
716/2700 (epoch 13.259), train_loss = 1.75840231, grad/param norm = 5.8153e-01, time/batch = 0.1784s	
717/2700 (epoch 13.278), train_loss = 1.83777152, grad/param norm = 5.5244e-01, time/batch = 0.1738s	
718/2700 (epoch 13.296), train_loss = 1.81196533, grad/param norm = 5.7286e-01, time/batch = 0.1665s	
719/2700 (epoch 13.315), train_loss = 1.82220773, grad/param norm = 5.4607e-01, time/batch = 0.1742s	
720/2700 (epoch 13.333), train_loss = 1.81614247, grad/param norm = 5.3208e-01, time/batch = 0.1793s	
721/2700 (epoch 13.352), train_loss = 1.82222281, grad/param norm = 5.0013e-01, time/batch = 0.1737s	
722/2700 (epoch 13.370), train_loss = 1.84064303, grad/param norm = 5.1983e-01, time/batch = 0.1784s	
723/2700 (epoch 13.389), train_loss = 1.82172751, grad/param norm = 5.7327e-01, time/batch = 0.1737s	
724/2700 (epoch 13.407), train_loss = 1.82283253, grad/param norm = 5.8418e-01, time/batch = 0.1899s	
725/2700 (epoch 13.426), train_loss = 1.85334132, grad/param norm = 7.3275e-01, time/batch = 0.1635s	
726/2700 (epoch 13.444), train_loss = 1.76789882, grad/param norm = 6.5330e-01, time/batch = 0.1707s	
727/2700 (epoch 13.463), train_loss = 1.82486438, grad/param norm = 5.0098e-01, time/batch = 0.1670s	
728/2700 (epoch 13.481), train_loss = 1.85875177, grad/param norm = 5.1895e-01, time/batch = 0.1634s	
729/2700 (epoch 13.500), train_loss = 1.81312481, grad/param norm = 5.5502e-01, time/batch = 0.1573s	
730/2700 (epoch 13.519), train_loss = 1.81091133, grad/param norm = 5.9704e-01, time/batch = 0.1823s	
731/2700 (epoch 13.537), train_loss = 1.84889799, grad/param norm = 5.8812e-01, time/batch = 0.1747s	
732/2700 (epoch 13.556), train_loss = 1.77637178, grad/param norm = 6.7184e-01, time/batch = 0.1570s	
733/2700 (epoch 13.574), train_loss = 1.81228490, grad/param norm = 8.6145e-01, time/batch = 0.1359s	
734/2700 (epoch 13.593), train_loss = 1.81282441, grad/param norm = 8.2156e-01, time/batch = 0.1590s	
735/2700 (epoch 13.611), train_loss = 1.71337504, grad/param norm = 7.3783e-01, time/batch = 0.1713s	
736/2700 (epoch 13.630), train_loss = 1.75206236, grad/param norm = 6.8817e-01, time/batch = 0.1380s	
737/2700 (epoch 13.648), train_loss = 1.77057314, grad/param norm = 6.0698e-01, time/batch = 0.1790s	
738/2700 (epoch 13.667), train_loss = 1.75567886, grad/param norm = 6.5250e-01, time/batch = 0.1787s	
739/2700 (epoch 13.685), train_loss = 1.78423172, grad/param norm = 5.9667e-01, time/batch = 0.1825s	
740/2700 (epoch 13.704), train_loss = 1.78460370, grad/param norm = 5.6701e-01, time/batch = 0.1768s	
741/2700 (epoch 13.722), train_loss = 1.76030874, grad/param norm = 5.1191e-01, time/batch = 0.1734s	
742/2700 (epoch 13.741), train_loss = 1.80652578, grad/param norm = 5.1357e-01, time/batch = 0.1773s	
743/2700 (epoch 13.759), train_loss = 1.83114105, grad/param norm = 5.3791e-01, time/batch = 0.1670s	
744/2700 (epoch 13.778), train_loss = 1.83599497, grad/param norm = 4.9876e-01, time/batch = 0.1787s	
745/2700 (epoch 13.796), train_loss = 1.80513797, grad/param norm = 5.9067e-01, time/batch = 0.1709s	
746/2700 (epoch 13.815), train_loss = 1.82657583, grad/param norm = 6.3051e-01, time/batch = 0.1530s	
747/2700 (epoch 13.833), train_loss = 1.78185368, grad/param norm = 6.9221e-01, time/batch = 0.1583s	
748/2700 (epoch 13.852), train_loss = 1.79338533, grad/param norm = 6.1012e-01, time/batch = 0.1488s	
749/2700 (epoch 13.870), train_loss = 1.80379855, grad/param norm = 6.4292e-01, time/batch = 0.1491s	
750/2700 (epoch 13.889), train_loss = 1.79893452, grad/param norm = 7.9687e-01, time/batch = 0.1550s	
751/2700 (epoch 13.907), train_loss = 1.92859746, grad/param norm = 8.1257e-01, time/batch = 0.1789s	
752/2700 (epoch 13.926), train_loss = 1.85166834, grad/param norm = 7.4357e-01, time/batch = 0.1649s	
753/2700 (epoch 13.944), train_loss = 1.81919275, grad/param norm = 6.7813e-01, time/batch = 0.1623s	
754/2700 (epoch 13.963), train_loss = 1.85800186, grad/param norm = 7.0108e-01, time/batch = 0.1564s	
755/2700 (epoch 13.981), train_loss = 1.83856344, grad/param norm = 5.6897e-01, time/batch = 0.1448s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
756/2700 (epoch 14.000), train_loss = 1.87257036, grad/param norm = 5.5188e-01, time/batch = 0.1351s	
757/2700 (epoch 14.019), train_loss = 1.83844051, grad/param norm = 6.1155e-01, time/batch = 0.1493s	
758/2700 (epoch 14.037), train_loss = 1.85143247, grad/param norm = 7.4446e-01, time/batch = 0.1824s	
759/2700 (epoch 14.056), train_loss = 1.78011875, grad/param norm = 6.9811e-01, time/batch = 0.1818s	
760/2700 (epoch 14.074), train_loss = 1.76935938, grad/param norm = 5.6850e-01, time/batch = 0.1815s	
761/2700 (epoch 14.093), train_loss = 1.77897366, grad/param norm = 5.5163e-01, time/batch = 0.1675s	
762/2700 (epoch 14.111), train_loss = 1.74330960, grad/param norm = 5.8658e-01, time/batch = 0.1581s	
763/2700 (epoch 14.130), train_loss = 1.78411342, grad/param norm = 5.7325e-01, time/batch = 0.1624s	
764/2700 (epoch 14.148), train_loss = 1.73040452, grad/param norm = 5.7629e-01, time/batch = 0.1622s	
765/2700 (epoch 14.167), train_loss = 1.81564676, grad/param norm = 4.9681e-01, time/batch = 0.1649s	
766/2700 (epoch 14.185), train_loss = 1.73158177, grad/param norm = 4.8221e-01, time/batch = 0.1552s	
767/2700 (epoch 14.204), train_loss = 1.80855925, grad/param norm = 5.5356e-01, time/batch = 0.1682s	
768/2700 (epoch 14.222), train_loss = 1.70811102, grad/param norm = 6.1455e-01, time/batch = 0.1825s	
769/2700 (epoch 14.241), train_loss = 1.65144603, grad/param norm = 5.8198e-01, time/batch = 0.1724s	
770/2700 (epoch 14.259), train_loss = 1.72749589, grad/param norm = 5.2783e-01, time/batch = 0.1586s	
771/2700 (epoch 14.278), train_loss = 1.80473144, grad/param norm = 4.9314e-01, time/batch = 0.1639s	
772/2700 (epoch 14.296), train_loss = 1.77612980, grad/param norm = 4.8473e-01, time/batch = 0.1486s	
773/2700 (epoch 14.315), train_loss = 1.78752052, grad/param norm = 4.4221e-01, time/batch = 0.1571s	
774/2700 (epoch 14.333), train_loss = 1.78750177, grad/param norm = 5.1916e-01, time/batch = 0.1464s	
775/2700 (epoch 14.352), train_loss = 1.79808029, grad/param norm = 5.7039e-01, time/batch = 0.1386s	
776/2700 (epoch 14.370), train_loss = 1.82019406, grad/param norm = 6.2089e-01, time/batch = 0.1355s	
777/2700 (epoch 14.389), train_loss = 1.79288842, grad/param norm = 5.9713e-01, time/batch = 0.1640s	
778/2700 (epoch 14.407), train_loss = 1.79311055, grad/param norm = 5.5161e-01, time/batch = 0.1513s	
779/2700 (epoch 14.426), train_loss = 1.82164489, grad/param norm = 6.3337e-01, time/batch = 0.1802s	
780/2700 (epoch 14.444), train_loss = 1.73966139, grad/param norm = 5.9657e-01, time/batch = 0.1819s	
781/2700 (epoch 14.463), train_loss = 1.79838235, grad/param norm = 5.6902e-01, time/batch = 0.1738s	
782/2700 (epoch 14.481), train_loss = 1.82611289, grad/param norm = 5.5084e-01, time/batch = 0.1653s	
783/2700 (epoch 14.500), train_loss = 1.77801496, grad/param norm = 4.6720e-01, time/batch = 0.1636s	
784/2700 (epoch 14.519), train_loss = 1.77243265, grad/param norm = 4.5460e-01, time/batch = 0.1644s	
785/2700 (epoch 14.537), train_loss = 1.81452605, grad/param norm = 5.0090e-01, time/batch = 0.1667s	
786/2700 (epoch 14.556), train_loss = 1.73180890, grad/param norm = 5.4927e-01, time/batch = 0.1616s	
787/2700 (epoch 14.574), train_loss = 1.75563184, grad/param norm = 5.7404e-01, time/batch = 0.1870s	
788/2700 (epoch 14.593), train_loss = 1.75315571, grad/param norm = 6.5002e-01, time/batch = 0.1627s	
789/2700 (epoch 14.611), train_loss = 1.68187075, grad/param norm = 7.4408e-01, time/batch = 0.1712s	
790/2700 (epoch 14.630), train_loss = 1.72961646, grad/param norm = 7.0455e-01, time/batch = 0.1785s	
791/2700 (epoch 14.648), train_loss = 1.74282476, grad/param norm = 6.1355e-01, time/batch = 0.1749s	
792/2700 (epoch 14.667), train_loss = 1.72694226, grad/param norm = 6.0780e-01, time/batch = 0.1585s	
793/2700 (epoch 14.685), train_loss = 1.75909576, grad/param norm = 5.6984e-01, time/batch = 0.1802s	
794/2700 (epoch 14.704), train_loss = 1.76081169, grad/param norm = 5.4331e-01, time/batch = 0.1778s	
795/2700 (epoch 14.722), train_loss = 1.73626458, grad/param norm = 4.9834e-01, time/batch = 0.1680s	
796/2700 (epoch 14.741), train_loss = 1.77791710, grad/param norm = 5.0399e-01, time/batch = 0.1650s	
797/2700 (epoch 14.759), train_loss = 1.80249171, grad/param norm = 5.3547e-01, time/batch = 0.1735s	
798/2700 (epoch 14.778), train_loss = 1.80778601, grad/param norm = 5.2132e-01, time/batch = 0.1719s	
799/2700 (epoch 14.796), train_loss = 1.77648000, grad/param norm = 6.2482e-01, time/batch = 0.1832s	
800/2700 (epoch 14.815), train_loss = 1.80463406, grad/param norm = 7.7066e-01, time/batch = 0.1837s	
801/2700 (epoch 14.833), train_loss = 1.76709624, grad/param norm = 8.5585e-01, time/batch = 0.1796s	
802/2700 (epoch 14.852), train_loss = 1.77815760, grad/param norm = 7.4667e-01, time/batch = 0.1812s	
803/2700 (epoch 14.870), train_loss = 1.78920475, grad/param norm = 7.2483e-01, time/batch = 0.1802s	
804/2700 (epoch 14.889), train_loss = 1.77589097, grad/param norm = 7.8286e-01, time/batch = 0.1747s	
805/2700 (epoch 14.907), train_loss = 1.89779778, grad/param norm = 7.3384e-01, time/batch = 0.1601s	
806/2700 (epoch 14.926), train_loss = 1.81442344, grad/param norm = 6.4617e-01, time/batch = 0.1713s	
807/2700 (epoch 14.944), train_loss = 1.78406703, grad/param norm = 5.7369e-01, time/batch = 0.1720s	
808/2700 (epoch 14.963), train_loss = 1.82032219, grad/param norm = 5.8095e-01, time/batch = 0.1698s	
809/2700 (epoch 14.981), train_loss = 1.80301283, grad/param norm = 4.9886e-01, time/batch = 0.1685s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
810/2700 (epoch 15.000), train_loss = 1.84312274, grad/param norm = 5.2953e-01, time/batch = 0.1699s	
811/2700 (epoch 15.019), train_loss = 1.81019768, grad/param norm = 5.9006e-01, time/batch = 0.1729s	
812/2700 (epoch 15.037), train_loss = 1.82092722, grad/param norm = 6.5521e-01, time/batch = 0.1693s	
813/2700 (epoch 15.056), train_loss = 1.75178235, grad/param norm = 7.7877e-01, time/batch = 0.1662s	
814/2700 (epoch 15.074), train_loss = 1.74126181, grad/param norm = 5.6253e-01, time/batch = 0.1641s	
815/2700 (epoch 15.093), train_loss = 1.74763026, grad/param norm = 5.1313e-01, time/batch = 0.1554s	
816/2700 (epoch 15.111), train_loss = 1.71353751, grad/param norm = 5.3924e-01, time/batch = 0.1812s	
817/2700 (epoch 15.130), train_loss = 1.75256009, grad/param norm = 5.4475e-01, time/batch = 0.1812s	
818/2700 (epoch 15.148), train_loss = 1.70363979, grad/param norm = 5.6465e-01, time/batch = 0.1829s	
819/2700 (epoch 15.167), train_loss = 1.78824585, grad/param norm = 4.8204e-01, time/batch = 0.1502s	
820/2700 (epoch 15.185), train_loss = 1.70682793, grad/param norm = 4.8951e-01, time/batch = 0.1405s	
821/2700 (epoch 15.204), train_loss = 1.77872457, grad/param norm = 5.2663e-01, time/batch = 0.1823s	
822/2700 (epoch 15.222), train_loss = 1.68100081, grad/param norm = 5.7307e-01, time/batch = 0.1840s	
823/2700 (epoch 15.241), train_loss = 1.62239562, grad/param norm = 5.4543e-01, time/batch = 0.1791s	
824/2700 (epoch 15.259), train_loss = 1.69953110, grad/param norm = 5.2529e-01, time/batch = 0.1592s	
825/2700 (epoch 15.278), train_loss = 1.78134607, grad/param norm = 5.1194e-01, time/batch = 0.1552s	
826/2700 (epoch 15.296), train_loss = 1.75279296, grad/param norm = 5.1948e-01, time/batch = 0.1584s	
827/2700 (epoch 15.315), train_loss = 1.76416608, grad/param norm = 5.2408e-01, time/batch = 0.1546s	
828/2700 (epoch 15.333), train_loss = 1.76229997, grad/param norm = 5.4955e-01, time/batch = 0.1605s	
829/2700 (epoch 15.352), train_loss = 1.76372856, grad/param norm = 5.2866e-01, time/batch = 0.1485s	
830/2700 (epoch 15.370), train_loss = 1.78730233, grad/param norm = 5.2028e-01, time/batch = 0.1761s	
831/2700 (epoch 15.389), train_loss = 1.75988232, grad/param norm = 5.4997e-01, time/batch = 0.1791s	
832/2700 (epoch 15.407), train_loss = 1.77220056, grad/param norm = 6.0689e-01, time/batch = 0.1812s	
833/2700 (epoch 15.426), train_loss = 1.79793226, grad/param norm = 6.8544e-01, time/batch = 0.1811s	
834/2700 (epoch 15.444), train_loss = 1.71565927, grad/param norm = 6.6681e-01, time/batch = 0.1766s	
835/2700 (epoch 15.463), train_loss = 1.77630524, grad/param norm = 5.7410e-01, time/batch = 0.1825s	
836/2700 (epoch 15.481), train_loss = 1.79932261, grad/param norm = 5.4442e-01, time/batch = 0.1822s	
837/2700 (epoch 15.500), train_loss = 1.74955337, grad/param norm = 4.6153e-01, time/batch = 0.1823s	
838/2700 (epoch 15.519), train_loss = 1.74329636, grad/param norm = 4.3487e-01, time/batch = 0.1839s	
839/2700 (epoch 15.537), train_loss = 1.78240054, grad/param norm = 4.3479e-01, time/batch = 0.1506s	
840/2700 (epoch 15.556), train_loss = 1.69717215, grad/param norm = 4.9711e-01, time/batch = 0.1574s	
841/2700 (epoch 15.574), train_loss = 1.73103794, grad/param norm = 6.2916e-01, time/batch = 0.1736s	
842/2700 (epoch 15.593), train_loss = 1.73329673, grad/param norm = 6.2798e-01, time/batch = 0.1720s	
843/2700 (epoch 15.611), train_loss = 1.65123498, grad/param norm = 5.8610e-01, time/batch = 0.1722s	
844/2700 (epoch 15.630), train_loss = 1.69157925, grad/param norm = 5.9344e-01, time/batch = 0.1821s	
845/2700 (epoch 15.648), train_loss = 1.71369508, grad/param norm = 5.5092e-01, time/batch = 0.1841s	
846/2700 (epoch 15.667), train_loss = 1.69951756, grad/param norm = 6.3103e-01, time/batch = 0.1832s	
847/2700 (epoch 15.685), train_loss = 1.73806478, grad/param norm = 6.0878e-01, time/batch = 0.1825s	
848/2700 (epoch 15.704), train_loss = 1.74089639, grad/param norm = 5.7491e-01, time/batch = 0.1725s	
849/2700 (epoch 15.722), train_loss = 1.71333752, grad/param norm = 5.5802e-01, time/batch = 0.1691s	
850/2700 (epoch 15.741), train_loss = 1.75925449, grad/param norm = 5.8367e-01, time/batch = 0.1431s	
851/2700 (epoch 15.759), train_loss = 1.78900544, grad/param norm = 6.2464e-01, time/batch = 0.1721s	
852/2700 (epoch 15.778), train_loss = 1.79542998, grad/param norm = 5.7753e-01, time/batch = 0.1797s	
853/2700 (epoch 15.796), train_loss = 1.75521561, grad/param norm = 5.7300e-01, time/batch = 0.1690s	
854/2700 (epoch 15.815), train_loss = 1.77043160, grad/param norm = 5.0277e-01, time/batch = 0.1800s	
855/2700 (epoch 15.833), train_loss = 1.72169104, grad/param norm = 4.9679e-01, time/batch = 0.1699s	
856/2700 (epoch 15.852), train_loss = 1.72950521, grad/param norm = 4.8310e-01, time/batch = 0.1727s	
857/2700 (epoch 15.870), train_loss = 1.74129196, grad/param norm = 4.9081e-01, time/batch = 0.1780s	
858/2700 (epoch 15.889), train_loss = 1.73586840, grad/param norm = 4.9378e-01, time/batch = 0.1663s	
859/2700 (epoch 15.907), train_loss = 1.85691328, grad/param norm = 5.3463e-01, time/batch = 0.1815s	
860/2700 (epoch 15.926), train_loss = 1.78091774, grad/param norm = 5.2755e-01, time/batch = 0.1623s	
861/2700 (epoch 15.944), train_loss = 1.75643620, grad/param norm = 5.7762e-01, time/batch = 0.1665s	
862/2700 (epoch 15.963), train_loss = 1.79755269, grad/param norm = 5.7334e-01, time/batch = 0.1664s	
863/2700 (epoch 15.981), train_loss = 1.77555588, grad/param norm = 5.3042e-01, time/batch = 0.1563s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
864/2700 (epoch 16.000), train_loss = 1.82240010, grad/param norm = 6.0634e-01, time/batch = 0.1817s	
865/2700 (epoch 16.019), train_loss = 1.79203648, grad/param norm = 7.8211e-01, time/batch = 0.1806s	
866/2700 (epoch 16.037), train_loss = 1.81536811, grad/param norm = 8.9976e-01, time/batch = 0.1814s	
867/2700 (epoch 16.056), train_loss = 1.73876483, grad/param norm = 7.7590e-01, time/batch = 0.1747s	
868/2700 (epoch 16.074), train_loss = 1.72021244, grad/param norm = 5.7591e-01, time/batch = 0.1794s	
869/2700 (epoch 16.093), train_loss = 1.72206487, grad/param norm = 5.0231e-01, time/batch = 0.1794s	
870/2700 (epoch 16.111), train_loss = 1.68747010, grad/param norm = 5.3019e-01, time/batch = 0.1798s	
871/2700 (epoch 16.130), train_loss = 1.72679154, grad/param norm = 4.8807e-01, time/batch = 0.1779s	
872/2700 (epoch 16.148), train_loss = 1.67499756, grad/param norm = 4.5820e-01, time/batch = 0.1741s	
873/2700 (epoch 16.167), train_loss = 1.76236895, grad/param norm = 4.5490e-01, time/batch = 0.1629s	
874/2700 (epoch 16.185), train_loss = 1.68250836, grad/param norm = 4.8571e-01, time/batch = 0.1673s	
875/2700 (epoch 16.204), train_loss = 1.75237046, grad/param norm = 5.0648e-01, time/batch = 0.1715s	
876/2700 (epoch 16.222), train_loss = 1.66033977, grad/param norm = 5.6407e-01, time/batch = 0.1848s	
877/2700 (epoch 16.241), train_loss = 1.60185633, grad/param norm = 5.5402e-01, time/batch = 0.1729s	
878/2700 (epoch 16.259), train_loss = 1.67840542, grad/param norm = 5.1983e-01, time/batch = 0.1735s	
879/2700 (epoch 16.278), train_loss = 1.75743894, grad/param norm = 5.0407e-01, time/batch = 0.1797s	
880/2700 (epoch 16.296), train_loss = 1.72297046, grad/param norm = 4.8891e-01, time/batch = 0.1793s	
881/2700 (epoch 16.315), train_loss = 1.73559617, grad/param norm = 4.5569e-01, time/batch = 0.1779s	
882/2700 (epoch 16.333), train_loss = 1.73764444, grad/param norm = 5.0444e-01, time/batch = 0.1647s	
883/2700 (epoch 16.352), train_loss = 1.74274941, grad/param norm = 5.6467e-01, time/batch = 0.1742s	
884/2700 (epoch 16.370), train_loss = 1.76613240, grad/param norm = 6.0976e-01, time/batch = 0.1651s	
885/2700 (epoch 16.389), train_loss = 1.73657702, grad/param norm = 5.8441e-01, time/batch = 0.1568s	
886/2700 (epoch 16.407), train_loss = 1.74682961, grad/param norm = 5.8224e-01, time/batch = 0.1343s	
887/2700 (epoch 16.426), train_loss = 1.77360599, grad/param norm = 6.3571e-01, time/batch = 0.1607s	
888/2700 (epoch 16.444), train_loss = 1.69432916, grad/param norm = 5.7952e-01, time/batch = 0.1657s	
889/2700 (epoch 16.463), train_loss = 1.75269402, grad/param norm = 5.4957e-01, time/batch = 0.1672s	
890/2700 (epoch 16.481), train_loss = 1.76833960, grad/param norm = 5.1622e-01, time/batch = 0.1712s	
891/2700 (epoch 16.500), train_loss = 1.72308839, grad/param norm = 4.5409e-01, time/batch = 0.1489s	
892/2700 (epoch 16.519), train_loss = 1.72010232, grad/param norm = 4.5054e-01, time/batch = 0.1771s	
893/2700 (epoch 16.537), train_loss = 1.76355128, grad/param norm = 5.0576e-01, time/batch = 0.1742s	
894/2700 (epoch 16.556), train_loss = 1.67457600, grad/param norm = 5.3216e-01, time/batch = 0.1688s	
895/2700 (epoch 16.574), train_loss = 1.70037205, grad/param norm = 5.7634e-01, time/batch = 0.1689s	
896/2700 (epoch 16.593), train_loss = 1.70271768, grad/param norm = 6.1810e-01, time/batch = 0.1616s	
897/2700 (epoch 16.611), train_loss = 1.62865465, grad/param norm = 6.4690e-01, time/batch = 0.1815s	
898/2700 (epoch 16.630), train_loss = 1.66870984, grad/param norm = 6.0171e-01, time/batch = 0.1804s	
899/2700 (epoch 16.648), train_loss = 1.68848372, grad/param norm = 5.1921e-01, time/batch = 0.1757s	
900/2700 (epoch 16.667), train_loss = 1.67202191, grad/param norm = 5.7584e-01, time/batch = 0.1707s	
901/2700 (epoch 16.685), train_loss = 1.71360891, grad/param norm = 5.6615e-01, time/batch = 0.1644s	
902/2700 (epoch 16.704), train_loss = 1.71563834, grad/param norm = 5.2458e-01, time/batch = 0.1746s	
903/2700 (epoch 16.722), train_loss = 1.68385536, grad/param norm = 4.7857e-01, time/batch = 0.1829s	
904/2700 (epoch 16.741), train_loss = 1.72240013, grad/param norm = 4.8093e-01, time/batch = 0.1815s	
905/2700 (epoch 16.759), train_loss = 1.74777176, grad/param norm = 5.1297e-01, time/batch = 0.1753s	
906/2700 (epoch 16.778), train_loss = 1.75857896, grad/param norm = 4.8489e-01, time/batch = 0.1802s	
907/2700 (epoch 16.796), train_loss = 1.72325832, grad/param norm = 5.2149e-01, time/batch = 0.1800s	
908/2700 (epoch 16.815), train_loss = 1.74370798, grad/param norm = 5.1963e-01, time/batch = 0.1811s	
909/2700 (epoch 16.833), train_loss = 1.69775405, grad/param norm = 5.3725e-01, time/batch = 0.1808s	
910/2700 (epoch 16.852), train_loss = 1.70368879, grad/param norm = 5.0847e-01, time/batch = 0.1812s	
911/2700 (epoch 16.870), train_loss = 1.72287683, grad/param norm = 5.1408e-01, time/batch = 0.1625s	
912/2700 (epoch 16.889), train_loss = 1.71769667, grad/param norm = 6.2457e-01, time/batch = 0.1556s	
913/2700 (epoch 16.907), train_loss = 1.84482915, grad/param norm = 7.1698e-01, time/batch = 0.1809s	
914/2700 (epoch 16.926), train_loss = 1.76936765, grad/param norm = 7.2611e-01, time/batch = 0.1691s	
915/2700 (epoch 16.944), train_loss = 1.74241675, grad/param norm = 7.0077e-01, time/batch = 0.1732s	
916/2700 (epoch 16.963), train_loss = 1.78312757, grad/param norm = 6.8899e-01, time/batch = 0.1676s	
917/2700 (epoch 16.981), train_loss = 1.75683989, grad/param norm = 5.9136e-01, time/batch = 0.1698s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
918/2700 (epoch 17.000), train_loss = 1.79779689, grad/param norm = 5.4832e-01, time/batch = 0.1703s	
919/2700 (epoch 17.019), train_loss = 1.76054871, grad/param norm = 5.3963e-01, time/batch = 0.1689s	
920/2700 (epoch 17.037), train_loss = 1.76995987, grad/param norm = 4.7276e-01, time/batch = 0.1694s	
921/2700 (epoch 17.056), train_loss = 1.68972943, grad/param norm = 4.6693e-01, time/batch = 0.1681s	
922/2700 (epoch 17.074), train_loss = 1.68595856, grad/param norm = 4.5612e-01, time/batch = 0.1490s	
923/2700 (epoch 17.093), train_loss = 1.69517756, grad/param norm = 5.4403e-01, time/batch = 0.1652s	
924/2700 (epoch 17.111), train_loss = 1.66909498, grad/param norm = 6.5572e-01, time/batch = 0.1612s	
925/2700 (epoch 17.130), train_loss = 1.71432746, grad/param norm = 7.1300e-01, time/batch = 0.1621s	
926/2700 (epoch 17.148), train_loss = 1.66552947, grad/param norm = 6.5634e-01, time/batch = 0.1545s	
927/2700 (epoch 17.167), train_loss = 1.74671871, grad/param norm = 5.0073e-01, time/batch = 0.1485s	
928/2700 (epoch 17.185), train_loss = 1.66042494, grad/param norm = 4.6485e-01, time/batch = 0.1580s	
929/2700 (epoch 17.204), train_loss = 1.72850119, grad/param norm = 4.6650e-01, time/batch = 0.1588s	
930/2700 (epoch 17.222), train_loss = 1.63713834, grad/param norm = 5.1119e-01, time/batch = 0.1630s	
931/2700 (epoch 17.241), train_loss = 1.57649221, grad/param norm = 4.9274e-01, time/batch = 0.1671s	
932/2700 (epoch 17.259), train_loss = 1.65416965, grad/param norm = 5.2326e-01, time/batch = 0.1741s	
933/2700 (epoch 17.278), train_loss = 1.73922001, grad/param norm = 5.3792e-01, time/batch = 0.1747s	
934/2700 (epoch 17.296), train_loss = 1.70532996, grad/param norm = 5.2880e-01, time/batch = 0.1750s	
935/2700 (epoch 17.315), train_loss = 1.71521531, grad/param norm = 5.1838e-01, time/batch = 0.1737s	
936/2700 (epoch 17.333), train_loss = 1.71390939, grad/param norm = 5.0653e-01, time/batch = 0.1706s	
937/2700 (epoch 17.352), train_loss = 1.70989492, grad/param norm = 4.7580e-01, time/batch = 0.1704s	
938/2700 (epoch 17.370), train_loss = 1.73482368, grad/param norm = 4.7612e-01, time/batch = 0.1700s	
939/2700 (epoch 17.389), train_loss = 1.70384905, grad/param norm = 5.1282e-01, time/batch = 0.1662s	
940/2700 (epoch 17.407), train_loss = 1.72754969, grad/param norm = 6.0424e-01, time/batch = 0.1643s	
941/2700 (epoch 17.426), train_loss = 1.75102818, grad/param norm = 6.4185e-01, time/batch = 0.1646s	
942/2700 (epoch 17.444), train_loss = 1.67175231, grad/param norm = 6.2869e-01, time/batch = 0.1686s	
943/2700 (epoch 17.463), train_loss = 1.73156122, grad/param norm = 5.5811e-01, time/batch = 0.1483s	
944/2700 (epoch 17.481), train_loss = 1.74503039, grad/param norm = 5.0504e-01, time/batch = 0.1494s	
945/2700 (epoch 17.500), train_loss = 1.69922117, grad/param norm = 4.6231e-01, time/batch = 0.1535s	
946/2700 (epoch 17.519), train_loss = 1.69819512, grad/param norm = 4.5589e-01, time/batch = 0.1530s	
947/2700 (epoch 17.537), train_loss = 1.73623800, grad/param norm = 4.4418e-01, time/batch = 0.1647s	
948/2700 (epoch 17.556), train_loss = 1.64743297, grad/param norm = 4.8945e-01, time/batch = 0.1729s	
949/2700 (epoch 17.574), train_loss = 1.67985724, grad/param norm = 6.0330e-01, time/batch = 0.1770s	
950/2700 (epoch 17.593), train_loss = 1.68539406, grad/param norm = 5.9881e-01, time/batch = 0.1805s	
951/2700 (epoch 17.611), train_loss = 1.60438241, grad/param norm = 5.1418e-01, time/batch = 0.1570s	
952/2700 (epoch 17.630), train_loss = 1.64140475, grad/param norm = 4.9898e-01, time/batch = 0.1621s	
953/2700 (epoch 17.648), train_loss = 1.66562157, grad/param norm = 4.6951e-01, time/batch = 0.1820s	
954/2700 (epoch 17.667), train_loss = 1.64777909, grad/param norm = 5.3973e-01, time/batch = 0.1806s	
955/2700 (epoch 17.685), train_loss = 1.69460155, grad/param norm = 5.6770e-01, time/batch = 0.1810s	
956/2700 (epoch 17.704), train_loss = 1.69884838, grad/param norm = 5.3430e-01, time/batch = 0.1792s	
957/2700 (epoch 17.722), train_loss = 1.66222050, grad/param norm = 4.8130e-01, time/batch = 0.1799s	
958/2700 (epoch 17.741), train_loss = 1.70335566, grad/param norm = 5.0108e-01, time/batch = 0.1804s	
959/2700 (epoch 17.759), train_loss = 1.72829033, grad/param norm = 5.3608e-01, time/batch = 0.1806s	
960/2700 (epoch 17.778), train_loss = 1.74036529, grad/param norm = 5.1731e-01, time/batch = 0.1810s	
961/2700 (epoch 17.796), train_loss = 1.70428663, grad/param norm = 5.5228e-01, time/batch = 0.1599s	
962/2700 (epoch 17.815), train_loss = 1.72175602, grad/param norm = 5.1193e-01, time/batch = 0.1500s	
963/2700 (epoch 17.833), train_loss = 1.67380139, grad/param norm = 5.0416e-01, time/batch = 0.1553s	
964/2700 (epoch 17.852), train_loss = 1.67885152, grad/param norm = 4.7478e-01, time/batch = 0.1499s	
965/2700 (epoch 17.870), train_loss = 1.69726014, grad/param norm = 4.5864e-01, time/batch = 0.1428s	
966/2700 (epoch 17.889), train_loss = 1.69414408, grad/param norm = 4.9860e-01, time/batch = 0.1462s	
967/2700 (epoch 17.907), train_loss = 1.81310428, grad/param norm = 5.3747e-01, time/batch = 0.1497s	
968/2700 (epoch 17.926), train_loss = 1.73210419, grad/param norm = 5.4310e-01, time/batch = 0.1569s	
969/2700 (epoch 17.944), train_loss = 1.71397789, grad/param norm = 5.6569e-01, time/batch = 0.1624s	
970/2700 (epoch 17.963), train_loss = 1.75682292, grad/param norm = 6.2394e-01, time/batch = 0.1673s	
971/2700 (epoch 17.981), train_loss = 1.72477892, grad/param norm = 5.3876e-01, time/batch = 0.1478s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
972/2700 (epoch 18.000), train_loss = 1.77132069, grad/param norm = 4.8309e-01, time/batch = 0.1459s	
973/2700 (epoch 18.019), train_loss = 1.73698324, grad/param norm = 5.2909e-01, time/batch = 0.1490s	
974/2700 (epoch 18.037), train_loss = 1.75338301, grad/param norm = 5.4088e-01, time/batch = 0.1602s	
975/2700 (epoch 18.056), train_loss = 1.67534489, grad/param norm = 6.0042e-01, time/batch = 0.1647s	
976/2700 (epoch 18.074), train_loss = 1.66954730, grad/param norm = 5.0396e-01, time/batch = 0.1710s	
977/2700 (epoch 18.093), train_loss = 1.67273914, grad/param norm = 5.0296e-01, time/batch = 0.1655s	
978/2700 (epoch 18.111), train_loss = 1.64545464, grad/param norm = 5.9060e-01, time/batch = 0.1583s	
979/2700 (epoch 18.130), train_loss = 1.68902415, grad/param norm = 6.7226e-01, time/batch = 0.1636s	
980/2700 (epoch 18.148), train_loss = 1.64757708, grad/param norm = 6.9641e-01, time/batch = 0.1656s	
981/2700 (epoch 18.167), train_loss = 1.73129953, grad/param norm = 5.2995e-01, time/batch = 0.1712s	
982/2700 (epoch 18.185), train_loss = 1.64071292, grad/param norm = 4.7505e-01, time/batch = 0.1678s	
983/2700 (epoch 18.204), train_loss = 1.70895316, grad/param norm = 4.6762e-01, time/batch = 0.1588s	
984/2700 (epoch 18.222), train_loss = 1.61905329, grad/param norm = 5.1503e-01, time/batch = 0.1455s	
985/2700 (epoch 18.241), train_loss = 1.55746625, grad/param norm = 4.8898e-01, time/batch = 0.1834s	
986/2700 (epoch 18.259), train_loss = 1.63515797, grad/param norm = 5.0867e-01, time/batch = 0.1830s	
987/2700 (epoch 18.278), train_loss = 1.72101604, grad/param norm = 5.4247e-01, time/batch = 0.1818s	
988/2700 (epoch 18.296), train_loss = 1.68490253, grad/param norm = 5.4713e-01, time/batch = 0.1809s	
989/2700 (epoch 18.315), train_loss = 1.69318131, grad/param norm = 5.1856e-01, time/batch = 0.1808s	
990/2700 (epoch 18.333), train_loss = 1.69359161, grad/param norm = 4.9700e-01, time/batch = 0.1746s	
991/2700 (epoch 18.352), train_loss = 1.69068064, grad/param norm = 4.7669e-01, time/batch = 0.1612s	
992/2700 (epoch 18.370), train_loss = 1.71055446, grad/param norm = 4.6978e-01, time/batch = 0.1799s	
993/2700 (epoch 18.389), train_loss = 1.67974902, grad/param norm = 4.9125e-01, time/batch = 0.1790s	
994/2700 (epoch 18.407), train_loss = 1.70630543, grad/param norm = 5.8120e-01, time/batch = 0.1624s	
995/2700 (epoch 18.426), train_loss = 1.72968511, grad/param norm = 6.1712e-01, time/batch = 0.1596s	
996/2700 (epoch 18.444), train_loss = 1.65262074, grad/param norm = 5.6247e-01, time/batch = 0.1553s	
997/2700 (epoch 18.463), train_loss = 1.71150354, grad/param norm = 5.2410e-01, time/batch = 0.1547s	
998/2700 (epoch 18.481), train_loss = 1.72025491, grad/param norm = 4.9899e-01, time/batch = 0.1517s	
999/2700 (epoch 18.500), train_loss = 1.67497469, grad/param norm = 4.6210e-01, time/batch = 0.1560s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch18.52_1.7963.t7	
1000/2700 (epoch 18.519), train_loss = 1.67942952, grad/param norm = 4.5647e-01, time/batch = 0.1560s	
1001/2700 (epoch 18.537), train_loss = 1.80080433, grad/param norm = 5.0062e-01, time/batch = 0.1760s	
1002/2700 (epoch 18.556), train_loss = 1.63110922, grad/param norm = 5.0892e-01, time/batch = 0.1679s	
1003/2700 (epoch 18.574), train_loss = 1.64963625, grad/param norm = 5.1585e-01, time/batch = 0.1831s	
1004/2700 (epoch 18.593), train_loss = 1.65616762, grad/param norm = 5.5973e-01, time/batch = 0.1839s	
1005/2700 (epoch 18.611), train_loss = 1.58263539, grad/param norm = 5.5352e-01, time/batch = 0.1843s	
1006/2700 (epoch 18.630), train_loss = 1.62256607, grad/param norm = 5.1874e-01, time/batch = 0.1826s	
1007/2700 (epoch 18.648), train_loss = 1.64641113, grad/param norm = 4.8119e-01, time/batch = 0.1647s	
1008/2700 (epoch 18.667), train_loss = 1.62827777, grad/param norm = 5.6028e-01, time/batch = 0.1825s	
1009/2700 (epoch 18.685), train_loss = 1.67709303, grad/param norm = 5.8491e-01, time/batch = 0.1820s	
1010/2700 (epoch 18.704), train_loss = 1.68021824, grad/param norm = 5.3534e-01, time/batch = 0.1808s	
1011/2700 (epoch 18.722), train_loss = 1.64261159, grad/param norm = 4.7852e-01, time/batch = 0.1757s	
1012/2700 (epoch 18.741), train_loss = 1.67732126, grad/param norm = 4.8516e-01, time/batch = 0.1596s	
1013/2700 (epoch 18.759), train_loss = 1.69782360, grad/param norm = 5.1092e-01, time/batch = 0.1538s	
1014/2700 (epoch 18.778), train_loss = 1.71446624, grad/param norm = 4.7421e-01, time/batch = 0.1527s	
1015/2700 (epoch 18.796), train_loss = 1.68035952, grad/param norm = 4.7892e-01, time/batch = 0.1505s	
1016/2700 (epoch 18.815), train_loss = 1.69881294, grad/param norm = 4.5790e-01, time/batch = 0.1562s	
1017/2700 (epoch 18.833), train_loss = 1.65284480, grad/param norm = 4.8257e-01, time/batch = 0.1389s	
1018/2700 (epoch 18.852), train_loss = 1.65648297, grad/param norm = 4.9606e-01, time/batch = 0.1662s	
1019/2700 (epoch 18.870), train_loss = 1.67547664, grad/param norm = 4.5691e-01, time/batch = 0.1757s	
1020/2700 (epoch 18.889), train_loss = 1.66974891, grad/param norm = 4.7196e-01, time/batch = 0.1773s	
1021/2700 (epoch 18.907), train_loss = 1.78934396, grad/param norm = 5.0920e-01, time/batch = 0.1630s	
1022/2700 (epoch 18.926), train_loss = 1.71352076, grad/param norm = 5.6049e-01, time/batch = 0.1716s	
1023/2700 (epoch 18.944), train_loss = 1.68944135, grad/param norm = 5.5079e-01, time/batch = 0.1640s	
1024/2700 (epoch 18.963), train_loss = 1.72681256, grad/param norm = 5.5927e-01, time/batch = 0.1811s	
1025/2700 (epoch 18.981), train_loss = 1.70415291, grad/param norm = 5.5896e-01, time/batch = 0.1797s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1026/2700 (epoch 19.000), train_loss = 1.76497177, grad/param norm = 6.4630e-01, time/batch = 0.1721s	
1027/2700 (epoch 19.019), train_loss = 1.72562791, grad/param norm = 6.3288e-01, time/batch = 0.1681s	
1028/2700 (epoch 19.037), train_loss = 1.74161465, grad/param norm = 7.5667e-01, time/batch = 0.1814s	
1029/2700 (epoch 19.056), train_loss = 1.66924481, grad/param norm = 7.8650e-01, time/batch = 0.1805s	
1030/2700 (epoch 19.074), train_loss = 1.66344239, grad/param norm = 6.1814e-01, time/batch = 0.1800s	
1031/2700 (epoch 19.093), train_loss = 1.65664149, grad/param norm = 5.2039e-01, time/batch = 0.1613s	
1032/2700 (epoch 19.111), train_loss = 1.62343543, grad/param norm = 5.1830e-01, time/batch = 0.1564s	
1033/2700 (epoch 19.130), train_loss = 1.66296198, grad/param norm = 4.8666e-01, time/batch = 0.1635s	
1034/2700 (epoch 19.148), train_loss = 1.61525443, grad/param norm = 4.4999e-01, time/batch = 0.1719s	
1035/2700 (epoch 19.167), train_loss = 1.70778521, grad/param norm = 4.8062e-01, time/batch = 0.1696s	
1036/2700 (epoch 19.185), train_loss = 1.62529227, grad/param norm = 4.9325e-01, time/batch = 0.1676s	
1037/2700 (epoch 19.204), train_loss = 1.69516232, grad/param norm = 5.2007e-01, time/batch = 0.1584s	
1038/2700 (epoch 19.222), train_loss = 1.60687307, grad/param norm = 5.4399e-01, time/batch = 0.1632s	
1039/2700 (epoch 19.241), train_loss = 1.54001770, grad/param norm = 5.2576e-01, time/batch = 0.1606s	
1040/2700 (epoch 19.259), train_loss = 1.61427381, grad/param norm = 4.6469e-01, time/batch = 0.1573s	
1041/2700 (epoch 19.278), train_loss = 1.69608349, grad/param norm = 4.8180e-01, time/batch = 0.1830s	
1042/2700 (epoch 19.296), train_loss = 1.66234146, grad/param norm = 4.6676e-01, time/batch = 0.1802s	
1043/2700 (epoch 19.315), train_loss = 1.66946437, grad/param norm = 4.4694e-01, time/batch = 0.1784s	
1044/2700 (epoch 19.333), train_loss = 1.67704670, grad/param norm = 5.2349e-01, time/batch = 0.1499s	
1045/2700 (epoch 19.352), train_loss = 1.67685014, grad/param norm = 5.9485e-01, time/batch = 0.1353s	
1046/2700 (epoch 19.370), train_loss = 1.69557554, grad/param norm = 5.5125e-01, time/batch = 0.1555s	
1047/2700 (epoch 19.389), train_loss = 1.66140099, grad/param norm = 5.0837e-01, time/batch = 0.1692s	
1048/2700 (epoch 19.407), train_loss = 1.68862109, grad/param norm = 5.2358e-01, time/batch = 0.1723s	
1049/2700 (epoch 19.426), train_loss = 1.70767095, grad/param norm = 5.7835e-01, time/batch = 0.1736s	
1050/2700 (epoch 19.444), train_loss = 1.63026362, grad/param norm = 5.0728e-01, time/batch = 0.1678s	
1051/2700 (epoch 19.463), train_loss = 1.68819869, grad/param norm = 4.6930e-01, time/batch = 0.1634s	
1052/2700 (epoch 19.481), train_loss = 1.70054521, grad/param norm = 4.6392e-01, time/batch = 0.1714s	
1053/2700 (epoch 19.500), train_loss = 1.65652406, grad/param norm = 4.9670e-01, time/batch = 0.1757s	
1054/2700 (epoch 19.519), train_loss = 1.66416357, grad/param norm = 5.2538e-01, time/batch = 0.1598s	
1055/2700 (epoch 19.537), train_loss = 1.70168842, grad/param norm = 5.0690e-01, time/batch = 0.1846s	
1056/2700 (epoch 19.556), train_loss = 1.60765528, grad/param norm = 4.9825e-01, time/batch = 0.1767s	
1057/2700 (epoch 19.574), train_loss = 1.63605773, grad/param norm = 5.8594e-01, time/batch = 0.1801s	
1058/2700 (epoch 19.593), train_loss = 1.64463694, grad/param norm = 5.9641e-01, time/batch = 0.1801s	
1059/2700 (epoch 19.611), train_loss = 1.56617103, grad/param norm = 5.1790e-01, time/batch = 0.1809s	
1060/2700 (epoch 19.630), train_loss = 1.60088548, grad/param norm = 4.7207e-01, time/batch = 0.1813s	
1061/2700 (epoch 19.648), train_loss = 1.62673048, grad/param norm = 4.4938e-01, time/batch = 0.1729s	
1062/2700 (epoch 19.667), train_loss = 1.60616656, grad/param norm = 5.0347e-01, time/batch = 0.1681s	
1063/2700 (epoch 19.685), train_loss = 1.65519110, grad/param norm = 5.3057e-01, time/batch = 0.1689s	
1064/2700 (epoch 19.704), train_loss = 1.66277974, grad/param norm = 5.1298e-01, time/batch = 0.1428s	
1065/2700 (epoch 19.722), train_loss = 1.62249053, grad/param norm = 4.6189e-01, time/batch = 0.1553s	
1066/2700 (epoch 19.741), train_loss = 1.65929087, grad/param norm = 4.8184e-01, time/batch = 0.1417s	
1067/2700 (epoch 19.759), train_loss = 1.67827212, grad/param norm = 5.1347e-01, time/batch = 0.1586s	
1068/2700 (epoch 19.778), train_loss = 1.69699673, grad/param norm = 5.2251e-01, time/batch = 0.1568s	
1069/2700 (epoch 19.796), train_loss = 1.66296607, grad/param norm = 5.7548e-01, time/batch = 0.1623s	
1070/2700 (epoch 19.815), train_loss = 1.68107403, grad/param norm = 5.4784e-01, time/batch = 0.1668s	
1071/2700 (epoch 19.833), train_loss = 1.63554450, grad/param norm = 5.3674e-01, time/batch = 0.1705s	
1072/2700 (epoch 19.852), train_loss = 1.63751446, grad/param norm = 5.0762e-01, time/batch = 0.1574s	
1073/2700 (epoch 19.870), train_loss = 1.65999788, grad/param norm = 4.9383e-01, time/batch = 0.1459s	
1074/2700 (epoch 19.889), train_loss = 1.65578371, grad/param norm = 5.6070e-01, time/batch = 0.1344s	
1075/2700 (epoch 19.907), train_loss = 1.77457642, grad/param norm = 5.9646e-01, time/batch = 0.1427s	
1076/2700 (epoch 19.926), train_loss = 1.69202474, grad/param norm = 5.7259e-01, time/batch = 0.1560s	
1077/2700 (epoch 19.944), train_loss = 1.66817053, grad/param norm = 5.2709e-01, time/batch = 0.1694s	
1078/2700 (epoch 19.963), train_loss = 1.70740948, grad/param norm = 5.4167e-01, time/batch = 0.1710s	
1079/2700 (epoch 19.981), train_loss = 1.67460479, grad/param norm = 4.6554e-01, time/batch = 0.1746s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1080/2700 (epoch 20.000), train_loss = 1.73338251, grad/param norm = 4.7133e-01, time/batch = 0.1787s	
1081/2700 (epoch 20.019), train_loss = 1.70010971, grad/param norm = 5.2294e-01, time/batch = 0.1765s	
1082/2700 (epoch 20.037), train_loss = 1.71571398, grad/param norm = 6.0504e-01, time/batch = 0.1693s	
1083/2700 (epoch 20.056), train_loss = 1.63927568, grad/param norm = 6.7190e-01, time/batch = 0.1584s	
1084/2700 (epoch 20.074), train_loss = 1.63538242, grad/param norm = 5.2383e-01, time/batch = 0.1649s	
1085/2700 (epoch 20.093), train_loss = 1.63327832, grad/param norm = 4.6974e-01, time/batch = 0.1602s	
1086/2700 (epoch 20.111), train_loss = 1.60385808, grad/param norm = 4.8955e-01, time/batch = 0.1465s	
1087/2700 (epoch 20.130), train_loss = 1.64248443, grad/param norm = 4.7250e-01, time/batch = 0.1602s	
1088/2700 (epoch 20.148), train_loss = 1.59816099, grad/param norm = 4.7214e-01, time/batch = 0.1559s	
1089/2700 (epoch 20.167), train_loss = 1.69436448, grad/param norm = 4.7841e-01, time/batch = 0.1639s	
1090/2700 (epoch 20.185), train_loss = 1.60843161, grad/param norm = 4.8330e-01, time/batch = 0.1725s	
1091/2700 (epoch 20.204), train_loss = 1.67753698, grad/param norm = 4.8848e-01, time/batch = 0.1589s	
1092/2700 (epoch 20.222), train_loss = 1.58817919, grad/param norm = 5.1157e-01, time/batch = 0.1504s	
1093/2700 (epoch 20.241), train_loss = 1.52074414, grad/param norm = 5.0039e-01, time/batch = 0.1433s	
1094/2700 (epoch 20.259), train_loss = 1.59737467, grad/param norm = 4.7285e-01, time/batch = 0.1530s	
1095/2700 (epoch 20.278), train_loss = 1.68352110, grad/param norm = 4.9967e-01, time/batch = 0.1533s	
1096/2700 (epoch 20.296), train_loss = 1.64779887, grad/param norm = 4.9680e-01, time/batch = 0.1403s	
1097/2700 (epoch 20.315), train_loss = 1.65311939, grad/param norm = 4.8969e-01, time/batch = 0.1774s	
1098/2700 (epoch 20.333), train_loss = 1.65642781, grad/param norm = 4.8587e-01, time/batch = 0.1791s	
1099/2700 (epoch 20.352), train_loss = 1.65147184, grad/param norm = 4.8692e-01, time/batch = 0.1760s	
1100/2700 (epoch 20.370), train_loss = 1.67230375, grad/param norm = 4.6431e-01, time/batch = 0.1763s	
1101/2700 (epoch 20.389), train_loss = 1.63972906, grad/param norm = 4.8359e-01, time/batch = 0.1757s	
1102/2700 (epoch 20.407), train_loss = 1.67259368, grad/param norm = 5.4885e-01, time/batch = 0.1720s	
1103/2700 (epoch 20.426), train_loss = 1.69030858, grad/param norm = 5.8904e-01, time/batch = 0.1577s	
1104/2700 (epoch 20.444), train_loss = 1.61461599, grad/param norm = 5.5166e-01, time/batch = 0.1805s	
1105/2700 (epoch 20.463), train_loss = 1.67416130, grad/param norm = 5.1830e-01, time/batch = 0.1791s	
1106/2700 (epoch 20.481), train_loss = 1.68193702, grad/param norm = 4.8188e-01, time/batch = 0.1625s	
1107/2700 (epoch 20.500), train_loss = 1.63344334, grad/param norm = 4.5565e-01, time/batch = 0.1628s	
1108/2700 (epoch 20.519), train_loss = 1.64642174, grad/param norm = 4.7041e-01, time/batch = 0.1642s	
1109/2700 (epoch 20.537), train_loss = 1.68183317, grad/param norm = 4.7497e-01, time/batch = 0.1577s	
1110/2700 (epoch 20.556), train_loss = 1.58783858, grad/param norm = 4.7066e-01, time/batch = 0.1651s	
1111/2700 (epoch 20.574), train_loss = 1.61256411, grad/param norm = 5.2204e-01, time/batch = 0.1811s	
1112/2700 (epoch 20.593), train_loss = 1.62124338, grad/param norm = 5.5225e-01, time/batch = 0.1815s	
1113/2700 (epoch 20.611), train_loss = 1.54526795, grad/param norm = 4.6662e-01, time/batch = 0.1726s	
1114/2700 (epoch 20.630), train_loss = 1.58264014, grad/param norm = 4.4876e-01, time/batch = 0.1752s	
1115/2700 (epoch 20.648), train_loss = 1.60894751, grad/param norm = 4.5302e-01, time/batch = 0.1740s	
1116/2700 (epoch 20.667), train_loss = 1.58875237, grad/param norm = 4.9216e-01, time/batch = 0.1834s	
1117/2700 (epoch 20.685), train_loss = 1.64083209, grad/param norm = 5.4370e-01, time/batch = 0.1573s	
1118/2700 (epoch 20.704), train_loss = 1.64966737, grad/param norm = 5.2685e-01, time/batch = 0.1621s	
1119/2700 (epoch 20.722), train_loss = 1.60761096, grad/param norm = 4.5550e-01, time/batch = 0.1669s	
1120/2700 (epoch 20.741), train_loss = 1.63956218, grad/param norm = 4.8788e-01, time/batch = 0.1705s	
1121/2700 (epoch 20.759), train_loss = 1.65631782, grad/param norm = 5.3259e-01, time/batch = 0.1646s	
1122/2700 (epoch 20.778), train_loss = 1.67869580, grad/param norm = 5.1611e-01, time/batch = 0.1466s	
1123/2700 (epoch 20.796), train_loss = 1.64573524, grad/param norm = 5.4282e-01, time/batch = 0.1570s	
1124/2700 (epoch 20.815), train_loss = 1.66436356, grad/param norm = 5.3852e-01, time/batch = 0.1641s	
1125/2700 (epoch 20.833), train_loss = 1.62078496, grad/param norm = 5.5296e-01, time/batch = 0.1632s	
1126/2700 (epoch 20.852), train_loss = 1.62057372, grad/param norm = 5.5082e-01, time/batch = 0.1748s	
1127/2700 (epoch 20.870), train_loss = 1.64268315, grad/param norm = 5.0242e-01, time/batch = 0.1701s	
1128/2700 (epoch 20.889), train_loss = 1.63527668, grad/param norm = 5.5084e-01, time/batch = 0.1845s	
1129/2700 (epoch 20.907), train_loss = 1.75652138, grad/param norm = 6.1412e-01, time/batch = 0.1837s	
1130/2700 (epoch 20.926), train_loss = 1.67676288, grad/param norm = 6.0551e-01, time/batch = 0.1774s	
1131/2700 (epoch 20.944), train_loss = 1.64971508, grad/param norm = 5.2247e-01, time/batch = 0.1605s	
1132/2700 (epoch 20.963), train_loss = 1.68541752, grad/param norm = 5.2688e-01, time/batch = 0.1685s	
1133/2700 (epoch 20.981), train_loss = 1.65424518, grad/param norm = 4.6726e-01, time/batch = 0.1757s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1134/2700 (epoch 21.000), train_loss = 1.71990595, grad/param norm = 5.1727e-01, time/batch = 0.1816s	
1135/2700 (epoch 21.019), train_loss = 1.68397440, grad/param norm = 5.6374e-01, time/batch = 0.1632s	
1136/2700 (epoch 21.037), train_loss = 1.69903352, grad/param norm = 6.3768e-01, time/batch = 0.1630s	
1137/2700 (epoch 21.056), train_loss = 1.61910922, grad/param norm = 6.0999e-01, time/batch = 0.1530s	
1138/2700 (epoch 21.074), train_loss = 1.61885994, grad/param norm = 5.1872e-01, time/batch = 0.1755s	
1139/2700 (epoch 21.093), train_loss = 1.61785080, grad/param norm = 5.0725e-01, time/batch = 0.1725s	
1140/2700 (epoch 21.111), train_loss = 1.58840829, grad/param norm = 5.3872e-01, time/batch = 0.1782s	
1141/2700 (epoch 21.130), train_loss = 1.63081876, grad/param norm = 5.1436e-01, time/batch = 0.1819s	
1142/2700 (epoch 21.148), train_loss = 1.57933820, grad/param norm = 4.5938e-01, time/batch = 0.1813s	
1143/2700 (epoch 21.167), train_loss = 1.67679262, grad/param norm = 4.6184e-01, time/batch = 0.1815s	
1144/2700 (epoch 21.185), train_loss = 1.59051793, grad/param norm = 4.5104e-01, time/batch = 0.1678s	
1145/2700 (epoch 21.204), train_loss = 1.66159568, grad/param norm = 4.9827e-01, time/batch = 0.1706s	
1146/2700 (epoch 21.222), train_loss = 1.57565118, grad/param norm = 5.2689e-01, time/batch = 0.1729s	
1147/2700 (epoch 21.241), train_loss = 1.50691456, grad/param norm = 4.9238e-01, time/batch = 0.1706s	
1148/2700 (epoch 21.259), train_loss = 1.58248154, grad/param norm = 4.7157e-01, time/batch = 0.1673s	
1149/2700 (epoch 21.278), train_loss = 1.66890522, grad/param norm = 5.1845e-01, time/batch = 0.1658s	
1150/2700 (epoch 21.296), train_loss = 1.63058501, grad/param norm = 4.8663e-01, time/batch = 0.1586s	
1151/2700 (epoch 21.315), train_loss = 1.63390523, grad/param norm = 4.5707e-01, time/batch = 0.1796s	
1152/2700 (epoch 21.333), train_loss = 1.64201651, grad/param norm = 5.0140e-01, time/batch = 0.1750s	
1153/2700 (epoch 21.352), train_loss = 1.63689050, grad/param norm = 5.2902e-01, time/batch = 0.1704s	
1154/2700 (epoch 21.370), train_loss = 1.65422590, grad/param norm = 4.7680e-01, time/batch = 0.1594s	
1155/2700 (epoch 21.389), train_loss = 1.62008500, grad/param norm = 4.6740e-01, time/batch = 0.1811s	
1156/2700 (epoch 21.407), train_loss = 1.65449540, grad/param norm = 5.1542e-01, time/batch = 0.1817s	
1157/2700 (epoch 21.426), train_loss = 1.67251194, grad/param norm = 5.6734e-01, time/batch = 0.1819s	
1158/2700 (epoch 21.444), train_loss = 1.60040000, grad/param norm = 5.4843e-01, time/batch = 0.1608s	
1159/2700 (epoch 21.463), train_loss = 1.65946459, grad/param norm = 5.1677e-01, time/batch = 0.1570s	
1160/2700 (epoch 21.481), train_loss = 1.66524506, grad/param norm = 4.9256e-01, time/batch = 0.1131s	
1161/2700 (epoch 21.500), train_loss = 1.61681939, grad/param norm = 4.9419e-01, time/batch = 0.1770s	
1162/2700 (epoch 21.519), train_loss = 1.63376324, grad/param norm = 5.1435e-01, time/batch = 0.1787s	
1163/2700 (epoch 21.537), train_loss = 1.66618847, grad/param norm = 5.1948e-01, time/batch = 0.1764s	
1164/2700 (epoch 21.556), train_loss = 1.57118586, grad/param norm = 4.7042e-01, time/batch = 0.1854s	
1165/2700 (epoch 21.574), train_loss = 1.59304133, grad/param norm = 5.1277e-01, time/batch = 0.1845s	
1166/2700 (epoch 21.593), train_loss = 1.60369952, grad/param norm = 5.5827e-01, time/batch = 0.1843s	
1167/2700 (epoch 21.611), train_loss = 1.53005580, grad/param norm = 4.8448e-01, time/batch = 0.1849s	
1168/2700 (epoch 21.630), train_loss = 1.56628997, grad/param norm = 4.4464e-01, time/batch = 0.1847s	
1169/2700 (epoch 21.648), train_loss = 1.59268270, grad/param norm = 4.3406e-01, time/batch = 0.1802s	
1170/2700 (epoch 21.667), train_loss = 1.57254276, grad/param norm = 5.0199e-01, time/batch = 0.1705s	
1171/2700 (epoch 21.685), train_loss = 1.62284000, grad/param norm = 5.3159e-01, time/batch = 0.1761s	
1172/2700 (epoch 21.704), train_loss = 1.63254782, grad/param norm = 5.0459e-01, time/batch = 0.1757s	
1173/2700 (epoch 21.722), train_loss = 1.59090002, grad/param norm = 4.5011e-01, time/batch = 0.1848s	
1174/2700 (epoch 21.741), train_loss = 1.62074361, grad/param norm = 4.7577e-01, time/batch = 0.1835s	
1175/2700 (epoch 21.759), train_loss = 1.63506476, grad/param norm = 4.9534e-01, time/batch = 0.1871s	
1176/2700 (epoch 21.778), train_loss = 1.65962703, grad/param norm = 4.7489e-01, time/batch = 0.1852s	
1177/2700 (epoch 21.796), train_loss = 1.62475212, grad/param norm = 4.9370e-01, time/batch = 0.1831s	
1178/2700 (epoch 21.815), train_loss = 1.64334785, grad/param norm = 4.5769e-01, time/batch = 0.1762s	
1179/2700 (epoch 21.833), train_loss = 1.60188479, grad/param norm = 4.9099e-01, time/batch = 0.1788s	
1180/2700 (epoch 21.852), train_loss = 1.60033403, grad/param norm = 5.0197e-01, time/batch = 0.1779s	
1181/2700 (epoch 21.870), train_loss = 1.62384420, grad/param norm = 5.1487e-01, time/batch = 0.1619s	
1182/2700 (epoch 21.889), train_loss = 1.62411622, grad/param norm = 5.6939e-01, time/batch = 0.1524s	
1183/2700 (epoch 21.907), train_loss = 1.73947432, grad/param norm = 6.0999e-01, time/batch = 0.1824s	
1184/2700 (epoch 21.926), train_loss = 1.66148916, grad/param norm = 6.0207e-01, time/batch = 0.1811s	
1185/2700 (epoch 21.944), train_loss = 1.64123700, grad/param norm = 6.6326e-01, time/batch = 0.1811s	
1186/2700 (epoch 21.963), train_loss = 1.67830243, grad/param norm = 6.3648e-01, time/batch = 0.1781s	
1187/2700 (epoch 21.981), train_loss = 1.64395361, grad/param norm = 5.7809e-01, time/batch = 0.1647s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1188/2700 (epoch 22.000), train_loss = 1.71263577, grad/param norm = 6.5091e-01, time/batch = 0.1670s	
1189/2700 (epoch 22.019), train_loss = 1.67379855, grad/param norm = 6.4377e-01, time/batch = 0.1588s	
1190/2700 (epoch 22.037), train_loss = 1.68579443, grad/param norm = 6.5106e-01, time/batch = 0.1556s	
1191/2700 (epoch 22.056), train_loss = 1.60305171, grad/param norm = 5.7470e-01, time/batch = 0.1396s	
1192/2700 (epoch 22.074), train_loss = 1.60018346, grad/param norm = 4.7012e-01, time/batch = 0.1731s	
1193/2700 (epoch 22.093), train_loss = 1.59829271, grad/param norm = 4.8746e-01, time/batch = 0.1828s	
1194/2700 (epoch 22.111), train_loss = 1.56877726, grad/param norm = 4.9580e-01, time/batch = 0.1853s	
1195/2700 (epoch 22.130), train_loss = 1.61098017, grad/param norm = 4.6779e-01, time/batch = 0.1757s	
1196/2700 (epoch 22.148), train_loss = 1.56148962, grad/param norm = 4.3681e-01, time/batch = 0.1697s	
1197/2700 (epoch 22.167), train_loss = 1.66350202, grad/param norm = 4.8847e-01, time/batch = 0.1607s	
1198/2700 (epoch 22.185), train_loss = 1.57735397, grad/param norm = 4.7512e-01, time/batch = 0.1673s	
1199/2700 (epoch 22.204), train_loss = 1.64695020, grad/param norm = 4.8098e-01, time/batch = 0.1702s	
1200/2700 (epoch 22.222), train_loss = 1.55775998, grad/param norm = 4.9304e-01, time/batch = 0.1771s	
1201/2700 (epoch 22.241), train_loss = 1.48914540, grad/param norm = 4.7771e-01, time/batch = 0.1480s	
1202/2700 (epoch 22.259), train_loss = 1.56650842, grad/param norm = 4.6508e-01, time/batch = 0.1745s	
1203/2700 (epoch 22.278), train_loss = 1.65477628, grad/param norm = 5.0621e-01, time/batch = 0.1818s	
1204/2700 (epoch 22.296), train_loss = 1.61647349, grad/param norm = 4.7907e-01, time/batch = 0.1830s	
1205/2700 (epoch 22.315), train_loss = 1.61933532, grad/param norm = 4.9680e-01, time/batch = 0.1825s	
1206/2700 (epoch 22.333), train_loss = 1.62472630, grad/param norm = 4.9437e-01, time/batch = 0.1843s	
1207/2700 (epoch 22.352), train_loss = 1.61773664, grad/param norm = 4.9701e-01, time/batch = 0.1846s	
1208/2700 (epoch 22.370), train_loss = 1.63690140, grad/param norm = 4.5387e-01, time/batch = 0.1840s	
1209/2700 (epoch 22.389), train_loss = 1.60455045, grad/param norm = 4.8209e-01, time/batch = 0.1815s	
1210/2700 (epoch 22.407), train_loss = 1.64079485, grad/param norm = 5.3161e-01, time/batch = 0.1802s	
1211/2700 (epoch 22.426), train_loss = 1.65536661, grad/param norm = 5.5359e-01, time/batch = 0.1462s	
1212/2700 (epoch 22.444), train_loss = 1.58335277, grad/param norm = 5.2947e-01, time/batch = 0.1644s	
1213/2700 (epoch 22.463), train_loss = 1.64182658, grad/param norm = 5.1794e-01, time/batch = 0.1692s	
1214/2700 (epoch 22.481), train_loss = 1.64853905, grad/param norm = 4.7052e-01, time/batch = 0.1603s	
1215/2700 (epoch 22.500), train_loss = 1.59912269, grad/param norm = 4.9342e-01, time/batch = 0.1574s	
1216/2700 (epoch 22.519), train_loss = 1.61790122, grad/param norm = 4.9817e-01, time/batch = 0.1555s	
1217/2700 (epoch 22.537), train_loss = 1.64764495, grad/param norm = 4.6927e-01, time/batch = 0.1622s	
1218/2700 (epoch 22.556), train_loss = 1.55453727, grad/param norm = 4.6883e-01, time/batch = 0.1756s	
1219/2700 (epoch 22.574), train_loss = 1.57819166, grad/param norm = 5.4579e-01, time/batch = 0.1822s	
1220/2700 (epoch 22.593), train_loss = 1.59002151, grad/param norm = 5.6902e-01, time/batch = 0.1790s	
1221/2700 (epoch 22.611), train_loss = 1.51429930, grad/param norm = 4.4783e-01, time/batch = 0.1632s	
1222/2700 (epoch 22.630), train_loss = 1.55095726, grad/param norm = 4.4238e-01, time/batch = 0.1361s	
1223/2700 (epoch 22.648), train_loss = 1.57833471, grad/param norm = 4.4337e-01, time/batch = 0.1613s	
1224/2700 (epoch 22.667), train_loss = 1.55639016, grad/param norm = 4.5574e-01, time/batch = 0.1604s	
1225/2700 (epoch 22.685), train_loss = 1.60703254, grad/param norm = 4.8999e-01, time/batch = 0.1750s	
1226/2700 (epoch 22.704), train_loss = 1.62038843, grad/param norm = 5.0869e-01, time/batch = 0.1799s	
1227/2700 (epoch 22.722), train_loss = 1.57837760, grad/param norm = 4.5958e-01, time/batch = 0.1773s	
1228/2700 (epoch 22.741), train_loss = 1.60577428, grad/param norm = 5.0814e-01, time/batch = 0.1766s	
1229/2700 (epoch 22.759), train_loss = 1.61998040, grad/param norm = 5.6611e-01, time/batch = 0.1708s	
1230/2700 (epoch 22.778), train_loss = 1.64808307, grad/param norm = 6.1547e-01, time/batch = 0.1694s	
1231/2700 (epoch 22.796), train_loss = 1.61602097, grad/param norm = 6.3482e-01, time/batch = 0.1704s	
1232/2700 (epoch 22.815), train_loss = 1.63062445, grad/param norm = 5.5121e-01, time/batch = 0.1587s	
1233/2700 (epoch 22.833), train_loss = 1.58709459, grad/param norm = 5.1804e-01, time/batch = 0.1799s	
1234/2700 (epoch 22.852), train_loss = 1.58252473, grad/param norm = 4.8614e-01, time/batch = 0.1832s	
1235/2700 (epoch 22.870), train_loss = 1.60536967, grad/param norm = 4.6569e-01, time/batch = 0.1780s	
1236/2700 (epoch 22.889), train_loss = 1.60102956, grad/param norm = 5.1131e-01, time/batch = 0.1851s	
1237/2700 (epoch 22.907), train_loss = 1.72002063, grad/param norm = 5.6809e-01, time/batch = 0.1826s	
1238/2700 (epoch 22.926), train_loss = 1.63822437, grad/param norm = 5.6420e-01, time/batch = 0.1826s	
1239/2700 (epoch 22.944), train_loss = 1.61395129, grad/param norm = 4.9055e-01, time/batch = 0.1833s	
1240/2700 (epoch 22.963), train_loss = 1.65093507, grad/param norm = 5.0918e-01, time/batch = 0.1816s	
1241/2700 (epoch 22.981), train_loss = 1.61829100, grad/param norm = 4.7600e-01, time/batch = 0.1700s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1242/2700 (epoch 23.000), train_loss = 1.68981069, grad/param norm = 5.2402e-01, time/batch = 0.1566s	
1243/2700 (epoch 23.019), train_loss = 1.65081370, grad/param norm = 5.0489e-01, time/batch = 0.1336s	
1244/2700 (epoch 23.037), train_loss = 1.66340226, grad/param norm = 5.0772e-01, time/batch = 0.1410s	
1245/2700 (epoch 23.056), train_loss = 1.58178713, grad/param norm = 4.8379e-01, time/batch = 0.1554s	
1246/2700 (epoch 23.074), train_loss = 1.58603127, grad/param norm = 4.6891e-01, time/batch = 0.1611s	
1247/2700 (epoch 23.093), train_loss = 1.58418304, grad/param norm = 5.0297e-01, time/batch = 0.1633s	
1248/2700 (epoch 23.111), train_loss = 1.55569191, grad/param norm = 5.3373e-01, time/batch = 0.1629s	
1249/2700 (epoch 23.130), train_loss = 1.60060958, grad/param norm = 5.1808e-01, time/batch = 0.1595s	
1250/2700 (epoch 23.148), train_loss = 1.54663736, grad/param norm = 4.5797e-01, time/batch = 0.1671s	
1251/2700 (epoch 23.167), train_loss = 1.64894480, grad/param norm = 4.6471e-01, time/batch = 0.1587s	
1252/2700 (epoch 23.185), train_loss = 1.56063728, grad/param norm = 4.4787e-01, time/batch = 0.1679s	
1253/2700 (epoch 23.204), train_loss = 1.63256819, grad/param norm = 4.7437e-01, time/batch = 0.1527s	
1254/2700 (epoch 23.222), train_loss = 1.54487975, grad/param norm = 4.8846e-01, time/batch = 0.1796s	
1255/2700 (epoch 23.241), train_loss = 1.47582570, grad/param norm = 4.6883e-01, time/batch = 0.1814s	
1256/2700 (epoch 23.259), train_loss = 1.55250764, grad/param norm = 4.6213e-01, time/batch = 0.1782s	
1257/2700 (epoch 23.278), train_loss = 1.64263420, grad/param norm = 5.1436e-01, time/batch = 0.1824s	
1258/2700 (epoch 23.296), train_loss = 1.60172781, grad/param norm = 4.8151e-01, time/batch = 0.1820s	
1259/2700 (epoch 23.315), train_loss = 1.60277976, grad/param norm = 4.8249e-01, time/batch = 0.1833s	
1260/2700 (epoch 23.333), train_loss = 1.60980855, grad/param norm = 4.8108e-01, time/batch = 0.1835s	
1261/2700 (epoch 23.352), train_loss = 1.60250844, grad/param norm = 4.8774e-01, time/batch = 0.1783s	
1262/2700 (epoch 23.370), train_loss = 1.62030859, grad/param norm = 4.5352e-01, time/batch = 0.1591s	
1263/2700 (epoch 23.389), train_loss = 1.58800179, grad/param norm = 4.7439e-01, time/batch = 0.1234s	
1264/2700 (epoch 23.407), train_loss = 1.62574021, grad/param norm = 5.2284e-01, time/batch = 0.1727s	
1265/2700 (epoch 23.426), train_loss = 1.64165220, grad/param norm = 5.5373e-01, time/batch = 0.1654s	
1266/2700 (epoch 23.444), train_loss = 1.57103390, grad/param norm = 5.2832e-01, time/batch = 0.1584s	
1267/2700 (epoch 23.463), train_loss = 1.62877277, grad/param norm = 5.1264e-01, time/batch = 0.1581s	
1268/2700 (epoch 23.481), train_loss = 1.63476707, grad/param norm = 4.8677e-01, time/batch = 0.1660s	
1269/2700 (epoch 23.500), train_loss = 1.58344418, grad/param norm = 5.1125e-01, time/batch = 0.1612s	
1270/2700 (epoch 23.519), train_loss = 1.60591715, grad/param norm = 5.2318e-01, time/batch = 0.1603s	
1271/2700 (epoch 23.537), train_loss = 1.63465245, grad/param norm = 5.1685e-01, time/batch = 0.1524s	
1272/2700 (epoch 23.556), train_loss = 1.54086514, grad/param norm = 4.7385e-01, time/batch = 0.1575s	
1273/2700 (epoch 23.574), train_loss = 1.56032287, grad/param norm = 5.2035e-01, time/batch = 0.1402s	
1274/2700 (epoch 23.593), train_loss = 1.57320805, grad/param norm = 5.5704e-01, time/batch = 0.1504s	
1275/2700 (epoch 23.611), train_loss = 1.50160605, grad/param norm = 4.6028e-01, time/batch = 0.1805s	
1276/2700 (epoch 23.630), train_loss = 1.53639868, grad/param norm = 4.3122e-01, time/batch = 0.1809s	
1277/2700 (epoch 23.648), train_loss = 1.56445424, grad/param norm = 4.2762e-01, time/batch = 0.1804s	
1278/2700 (epoch 23.667), train_loss = 1.54303186, grad/param norm = 4.8253e-01, time/batch = 0.1801s	
1279/2700 (epoch 23.685), train_loss = 1.59402442, grad/param norm = 5.1397e-01, time/batch = 0.1798s	
1280/2700 (epoch 23.704), train_loss = 1.60709679, grad/param norm = 5.0344e-01, time/batch = 0.1819s	
1281/2700 (epoch 23.722), train_loss = 1.56436925, grad/param norm = 4.3441e-01, time/batch = 0.1741s	
1282/2700 (epoch 23.741), train_loss = 1.58680481, grad/param norm = 4.7426e-01, time/batch = 0.1611s	
1283/2700 (epoch 23.759), train_loss = 1.59850289, grad/param norm = 4.9934e-01, time/batch = 0.1594s	
1284/2700 (epoch 23.778), train_loss = 1.62918229, grad/param norm = 4.8907e-01, time/batch = 0.1703s	
1285/2700 (epoch 23.796), train_loss = 1.59431176, grad/param norm = 4.9250e-01, time/batch = 0.1745s	
1286/2700 (epoch 23.815), train_loss = 1.61383271, grad/param norm = 4.5128e-01, time/batch = 0.1591s	
1287/2700 (epoch 23.833), train_loss = 1.57291492, grad/param norm = 4.8539e-01, time/batch = 0.1468s	
1288/2700 (epoch 23.852), train_loss = 1.56602537, grad/param norm = 4.8843e-01, time/batch = 0.1461s	
1289/2700 (epoch 23.870), train_loss = 1.58846805, grad/param norm = 4.7443e-01, time/batch = 0.1566s	
1290/2700 (epoch 23.889), train_loss = 1.58704269, grad/param norm = 4.9793e-01, time/batch = 0.1673s	
1291/2700 (epoch 23.907), train_loss = 1.70275173, grad/param norm = 5.1390e-01, time/batch = 0.1564s	
1292/2700 (epoch 23.926), train_loss = 1.62095413, grad/param norm = 5.2680e-01, time/batch = 0.1473s	
1293/2700 (epoch 23.944), train_loss = 1.60218456, grad/param norm = 5.9323e-01, time/batch = 0.1484s	
1294/2700 (epoch 23.963), train_loss = 1.63961918, grad/param norm = 6.0045e-01, time/batch = 0.1743s	
1295/2700 (epoch 23.981), train_loss = 1.60641405, grad/param norm = 5.3479e-01, time/batch = 0.1659s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1296/2700 (epoch 24.000), train_loss = 1.68122869, grad/param norm = 6.1172e-01, time/batch = 0.1820s	
1297/2700 (epoch 24.019), train_loss = 1.64189438, grad/param norm = 6.1852e-01, time/batch = 0.1825s	
1298/2700 (epoch 24.037), train_loss = 1.65649712, grad/param norm = 6.4856e-01, time/batch = 0.1834s	
1299/2700 (epoch 24.056), train_loss = 1.57539148, grad/param norm = 5.8119e-01, time/batch = 0.1821s	
1300/2700 (epoch 24.074), train_loss = 1.57301964, grad/param norm = 4.7780e-01, time/batch = 0.1826s	
1301/2700 (epoch 24.093), train_loss = 1.56710655, grad/param norm = 4.6444e-01, time/batch = 0.1576s	
1302/2700 (epoch 24.111), train_loss = 1.53760539, grad/param norm = 4.6867e-01, time/batch = 0.1658s	
1303/2700 (epoch 24.130), train_loss = 1.58309271, grad/param norm = 4.5018e-01, time/batch = 0.1578s	
1304/2700 (epoch 24.148), train_loss = 1.53228300, grad/param norm = 4.3421e-01, time/batch = 0.1828s	
1305/2700 (epoch 24.167), train_loss = 1.63826769, grad/param norm = 5.1756e-01, time/batch = 0.1749s	
1306/2700 (epoch 24.185), train_loss = 1.55044101, grad/param norm = 4.8908e-01, time/batch = 0.1486s	
1307/2700 (epoch 24.204), train_loss = 1.62245770, grad/param norm = 5.0464e-01, time/batch = 0.1444s	
1308/2700 (epoch 24.222), train_loss = 1.53243014, grad/param norm = 5.0275e-01, time/batch = 0.1438s	
1309/2700 (epoch 24.241), train_loss = 1.46335873, grad/param norm = 4.6949e-01, time/batch = 0.1495s	
1310/2700 (epoch 24.259), train_loss = 1.53858591, grad/param norm = 4.4832e-01, time/batch = 0.1526s	
1311/2700 (epoch 24.278), train_loss = 1.62921056, grad/param norm = 5.0171e-01, time/batch = 0.1708s	
1312/2700 (epoch 24.296), train_loss = 1.58719869, grad/param norm = 4.5710e-01, time/batch = 0.1605s	
1313/2700 (epoch 24.315), train_loss = 1.58761909, grad/param norm = 4.8182e-01, time/batch = 0.1577s	
1314/2700 (epoch 24.333), train_loss = 1.59638772, grad/param norm = 4.9050e-01, time/batch = 0.1531s	
1315/2700 (epoch 24.352), train_loss = 1.58807443, grad/param norm = 5.0123e-01, time/batch = 0.1598s	
1316/2700 (epoch 24.370), train_loss = 1.60595472, grad/param norm = 4.5859e-01, time/batch = 0.1488s	
1317/2700 (epoch 24.389), train_loss = 1.57264849, grad/param norm = 4.7505e-01, time/batch = 0.1808s	
1318/2700 (epoch 24.407), train_loss = 1.61191164, grad/param norm = 5.1172e-01, time/batch = 0.1843s	
1319/2700 (epoch 24.426), train_loss = 1.62610290, grad/param norm = 5.2834e-01, time/batch = 0.1833s	
1320/2700 (epoch 24.444), train_loss = 1.55576155, grad/param norm = 4.9985e-01, time/batch = 0.1757s	
1321/2700 (epoch 24.463), train_loss = 1.61204787, grad/param norm = 4.9312e-01, time/batch = 0.1835s	
1322/2700 (epoch 24.481), train_loss = 1.61964143, grad/param norm = 4.6456e-01, time/batch = 0.1649s	
1323/2700 (epoch 24.500), train_loss = 1.56865051, grad/param norm = 5.2175e-01, time/batch = 0.1706s	
1324/2700 (epoch 24.519), train_loss = 1.59244656, grad/param norm = 5.1971e-01, time/batch = 0.1764s	
1325/2700 (epoch 24.537), train_loss = 1.61902287, grad/param norm = 4.8657e-01, time/batch = 0.1768s	
1326/2700 (epoch 24.556), train_loss = 1.52665752, grad/param norm = 4.7257e-01, time/batch = 0.1624s	
1327/2700 (epoch 24.574), train_loss = 1.54712325, grad/param norm = 5.4992e-01, time/batch = 0.1786s	
1328/2700 (epoch 24.593), train_loss = 1.56073597, grad/param norm = 5.6449e-01, time/batch = 0.1759s	
1329/2700 (epoch 24.611), train_loss = 1.48854076, grad/param norm = 4.3869e-01, time/batch = 0.1720s	
1330/2700 (epoch 24.630), train_loss = 1.52343802, grad/param norm = 4.3938e-01, time/batch = 0.1637s	
1331/2700 (epoch 24.648), train_loss = 1.55211126, grad/param norm = 4.4345e-01, time/batch = 0.1809s	
1332/2700 (epoch 24.667), train_loss = 1.52929669, grad/param norm = 4.5970e-01, time/batch = 0.1768s	
1333/2700 (epoch 24.685), train_loss = 1.57997072, grad/param norm = 4.9050e-01, time/batch = 0.1812s	
1334/2700 (epoch 24.704), train_loss = 1.59587350, grad/param norm = 5.0870e-01, time/batch = 0.1812s	
1335/2700 (epoch 24.722), train_loss = 1.55279554, grad/param norm = 4.4308e-01, time/batch = 0.1821s	
1336/2700 (epoch 24.741), train_loss = 1.57251741, grad/param norm = 4.9068e-01, time/batch = 0.1750s	
1337/2700 (epoch 24.759), train_loss = 1.58432026, grad/param norm = 5.3576e-01, time/batch = 0.1512s	
1338/2700 (epoch 24.778), train_loss = 1.61711685, grad/param norm = 5.6765e-01, time/batch = 0.1462s	
1339/2700 (epoch 24.796), train_loss = 1.58302891, grad/param norm = 5.7489e-01, time/batch = 0.1495s	
1340/2700 (epoch 24.815), train_loss = 1.60082176, grad/param norm = 5.1011e-01, time/batch = 0.1607s	
1341/2700 (epoch 24.833), train_loss = 1.55901767, grad/param norm = 4.9731e-01, time/batch = 0.1509s	
1342/2700 (epoch 24.852), train_loss = 1.55126898, grad/param norm = 4.6657e-01, time/batch = 0.1485s	
1343/2700 (epoch 24.870), train_loss = 1.57387535, grad/param norm = 4.6058e-01, time/batch = 0.1666s	
1344/2700 (epoch 24.889), train_loss = 1.57206749, grad/param norm = 4.9812e-01, time/batch = 0.1707s	
1345/2700 (epoch 24.907), train_loss = 1.68986959, grad/param norm = 5.6485e-01, time/batch = 0.1758s	
1346/2700 (epoch 24.926), train_loss = 1.60615356, grad/param norm = 5.6290e-01, time/batch = 0.1742s	
1347/2700 (epoch 24.944), train_loss = 1.58356659, grad/param norm = 4.9658e-01, time/batch = 0.1669s	
1348/2700 (epoch 24.963), train_loss = 1.61974818, grad/param norm = 5.2710e-01, time/batch = 0.1811s	
1349/2700 (epoch 24.981), train_loss = 1.58564760, grad/param norm = 4.6674e-01, time/batch = 0.1838s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1350/2700 (epoch 25.000), train_loss = 1.66024021, grad/param norm = 4.8624e-01, time/batch = 0.1820s	
1351/2700 (epoch 25.019), train_loss = 1.62156273, grad/param norm = 4.7662e-01, time/batch = 0.1629s	
1352/2700 (epoch 25.037), train_loss = 1.63488320, grad/param norm = 4.7429e-01, time/batch = 0.1551s	
1353/2700 (epoch 25.056), train_loss = 1.55520134, grad/param norm = 4.6354e-01, time/batch = 0.1831s	
1354/2700 (epoch 25.074), train_loss = 1.56182186, grad/param norm = 4.8555e-01, time/batch = 0.1828s	
1355/2700 (epoch 25.093), train_loss = 1.55890091, grad/param norm = 5.5358e-01, time/batch = 0.1824s	
1356/2700 (epoch 25.111), train_loss = 1.52819997, grad/param norm = 5.4775e-01, time/batch = 0.1798s	
1357/2700 (epoch 25.130), train_loss = 1.57516497, grad/param norm = 5.2751e-01, time/batch = 0.1667s	
1358/2700 (epoch 25.148), train_loss = 1.52004568, grad/param norm = 4.6518e-01, time/batch = 0.1362s	
1359/2700 (epoch 25.167), train_loss = 1.62448825, grad/param norm = 4.8555e-01, time/batch = 0.1586s	
1360/2700 (epoch 25.185), train_loss = 1.53433084, grad/param norm = 4.5881e-01, time/batch = 0.1579s	
1361/2700 (epoch 25.204), train_loss = 1.60795995, grad/param norm = 4.8260e-01, time/batch = 0.1757s	
1362/2700 (epoch 25.222), train_loss = 1.51958196, grad/param norm = 4.8539e-01, time/batch = 0.1727s	
1363/2700 (epoch 25.241), train_loss = 1.45199062, grad/param norm = 4.6384e-01, time/batch = 0.1758s	
1364/2700 (epoch 25.259), train_loss = 1.52807616, grad/param norm = 4.7547e-01, time/batch = 0.1786s	
1365/2700 (epoch 25.278), train_loss = 1.62058121, grad/param norm = 5.3095e-01, time/batch = 0.1802s	
1366/2700 (epoch 25.296), train_loss = 1.57574195, grad/param norm = 4.7507e-01, time/batch = 0.1822s	
1367/2700 (epoch 25.315), train_loss = 1.57382942, grad/param norm = 4.8747e-01, time/batch = 0.1782s	
1368/2700 (epoch 25.333), train_loss = 1.58267773, grad/param norm = 4.7858e-01, time/batch = 0.1577s	
1369/2700 (epoch 25.352), train_loss = 1.57307714, grad/param norm = 4.7727e-01, time/batch = 0.1541s	
1370/2700 (epoch 25.370), train_loss = 1.59105560, grad/param norm = 4.5830e-01, time/batch = 0.1533s	
1371/2700 (epoch 25.389), train_loss = 1.55913282, grad/param norm = 4.9912e-01, time/batch = 0.1678s	
1372/2700 (epoch 25.407), train_loss = 1.60094987, grad/param norm = 5.5674e-01, time/batch = 0.1807s	
1373/2700 (epoch 25.426), train_loss = 1.61431155, grad/param norm = 5.4628e-01, time/batch = 0.1806s	
1374/2700 (epoch 25.444), train_loss = 1.54439218, grad/param norm = 5.1056e-01, time/batch = 0.1833s	
1375/2700 (epoch 25.463), train_loss = 1.59954262, grad/param norm = 4.9913e-01, time/batch = 0.1829s	
1376/2700 (epoch 25.481), train_loss = 1.60667230, grad/param norm = 4.7185e-01, time/batch = 0.1824s	
1377/2700 (epoch 25.500), train_loss = 1.55308536, grad/param norm = 5.1406e-01, time/batch = 0.1673s	
1378/2700 (epoch 25.519), train_loss = 1.57942222, grad/param norm = 5.0525e-01, time/batch = 0.1455s	
1379/2700 (epoch 25.537), train_loss = 1.60504050, grad/param norm = 4.8441e-01, time/batch = 0.1814s	
1380/2700 (epoch 25.556), train_loss = 1.51353155, grad/param norm = 4.7066e-01, time/batch = 0.1795s	
1381/2700 (epoch 25.574), train_loss = 1.53211887, grad/param norm = 5.4137e-01, time/batch = 0.1460s	
1382/2700 (epoch 25.593), train_loss = 1.54601157, grad/param norm = 5.5557e-01, time/batch = 0.1817s	
1383/2700 (epoch 25.611), train_loss = 1.47689962, grad/param norm = 4.3418e-01, time/batch = 0.1775s	
1384/2700 (epoch 25.630), train_loss = 1.51080520, grad/param norm = 4.3536e-01, time/batch = 0.1732s	
1385/2700 (epoch 25.648), train_loss = 1.53987479, grad/param norm = 4.3627e-01, time/batch = 0.1681s	
1386/2700 (epoch 25.667), train_loss = 1.51677706, grad/param norm = 4.6480e-01, time/batch = 0.1590s	
1387/2700 (epoch 25.685), train_loss = 1.56802967, grad/param norm = 4.9621e-01, time/batch = 0.1488s	
1388/2700 (epoch 25.704), train_loss = 1.58474869, grad/param norm = 5.0822e-01, time/batch = 0.1582s	
1389/2700 (epoch 25.722), train_loss = 1.54101115, grad/param norm = 4.3091e-01, time/batch = 0.1678s	
1390/2700 (epoch 25.741), train_loss = 1.55692585, grad/param norm = 4.7869e-01, time/batch = 0.1677s	
1391/2700 (epoch 25.759), train_loss = 1.56780120, grad/param norm = 5.0905e-01, time/batch = 0.1766s	
1392/2700 (epoch 25.778), train_loss = 1.60212144, grad/param norm = 5.1855e-01, time/batch = 0.1777s	
1393/2700 (epoch 25.796), train_loss = 1.56681916, grad/param norm = 5.1570e-01, time/batch = 0.1822s	
1394/2700 (epoch 25.815), train_loss = 1.58760131, grad/param norm = 4.6798e-01, time/batch = 0.1812s	
1395/2700 (epoch 25.833), train_loss = 1.54635381, grad/param norm = 4.8143e-01, time/batch = 0.1827s	
1396/2700 (epoch 25.852), train_loss = 1.53741973, grad/param norm = 4.6790e-01, time/batch = 0.1813s	
1397/2700 (epoch 25.870), train_loss = 1.55865187, grad/param norm = 4.5019e-01, time/batch = 0.1825s	
1398/2700 (epoch 25.889), train_loss = 1.55780430, grad/param norm = 4.4963e-01, time/batch = 0.1755s	
1399/2700 (epoch 25.907), train_loss = 1.67157476, grad/param norm = 4.8237e-01, time/batch = 0.1762s	
1400/2700 (epoch 25.926), train_loss = 1.58776120, grad/param norm = 4.8735e-01, time/batch = 0.1634s	
1401/2700 (epoch 25.944), train_loss = 1.56879010, grad/param norm = 4.9954e-01, time/batch = 0.1801s	
1402/2700 (epoch 25.963), train_loss = 1.60488203, grad/param norm = 5.4889e-01, time/batch = 0.1749s	
1403/2700 (epoch 25.981), train_loss = 1.57127821, grad/param norm = 4.6410e-01, time/batch = 0.1641s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1404/2700 (epoch 26.000), train_loss = 1.65005381, grad/param norm = 5.2583e-01, time/batch = 0.1587s	
1405/2700 (epoch 26.019), train_loss = 1.61083013, grad/param norm = 5.4099e-01, time/batch = 0.1546s	
1406/2700 (epoch 26.037), train_loss = 1.62549842, grad/param norm = 5.5370e-01, time/batch = 0.1472s	
1407/2700 (epoch 26.056), train_loss = 1.54706249, grad/param norm = 5.3668e-01, time/batch = 0.1757s	
1408/2700 (epoch 26.074), train_loss = 1.54857525, grad/param norm = 4.9712e-01, time/batch = 0.1877s	
1409/2700 (epoch 26.093), train_loss = 1.54088926, grad/param norm = 4.6061e-01, time/batch = 0.1481s	
1410/2700 (epoch 26.111), train_loss = 1.51079748, grad/param norm = 4.6294e-01, time/batch = 0.1546s	
1411/2700 (epoch 26.130), train_loss = 1.55919643, grad/param norm = 4.5031e-01, time/batch = 0.1664s	
1412/2700 (epoch 26.148), train_loss = 1.50729982, grad/param norm = 4.4013e-01, time/batch = 0.1605s	
1413/2700 (epoch 26.167), train_loss = 1.61481982, grad/param norm = 5.3978e-01, time/batch = 0.1581s	
1414/2700 (epoch 26.185), train_loss = 1.52508264, grad/param norm = 5.1101e-01, time/batch = 0.1618s	
1415/2700 (epoch 26.204), train_loss = 1.60217843, grad/param norm = 5.5201e-01, time/batch = 0.1690s	
1416/2700 (epoch 26.222), train_loss = 1.51155256, grad/param norm = 5.3922e-01, time/batch = 0.1615s	
1417/2700 (epoch 26.241), train_loss = 1.44267108, grad/param norm = 4.8142e-01, time/batch = 0.1683s	
1418/2700 (epoch 26.259), train_loss = 1.51473737, grad/param norm = 4.5115e-01, time/batch = 0.1754s	
1419/2700 (epoch 26.278), train_loss = 1.60745828, grad/param norm = 5.0702e-01, time/batch = 0.1663s	
1420/2700 (epoch 26.296), train_loss = 1.56254297, grad/param norm = 4.4904e-01, time/batch = 0.1721s	
1421/2700 (epoch 26.315), train_loss = 1.55969562, grad/param norm = 4.7670e-01, time/batch = 0.1842s	
1422/2700 (epoch 26.333), train_loss = 1.57140749, grad/param norm = 4.9875e-01, time/batch = 0.1841s	
1423/2700 (epoch 26.352), train_loss = 1.56111851, grad/param norm = 5.0358e-01, time/batch = 0.1733s	
1424/2700 (epoch 26.370), train_loss = 1.57856061, grad/param norm = 4.6149e-01, time/batch = 0.1705s	
1425/2700 (epoch 26.389), train_loss = 1.54422625, grad/param norm = 4.7704e-01, time/batch = 0.1626s	
1426/2700 (epoch 26.407), train_loss = 1.58772686, grad/param norm = 5.2858e-01, time/batch = 0.1824s	
1427/2700 (epoch 26.426), train_loss = 1.60057343, grad/param norm = 5.2432e-01, time/batch = 0.1841s	
1428/2700 (epoch 26.444), train_loss = 1.53161002, grad/param norm = 4.8870e-01, time/batch = 0.1794s	
1429/2700 (epoch 26.463), train_loss = 1.58524959, grad/param norm = 4.7702e-01, time/batch = 0.1539s	
1430/2700 (epoch 26.481), train_loss = 1.59367731, grad/param norm = 4.6644e-01, time/batch = 0.1609s	
1431/2700 (epoch 26.500), train_loss = 1.54005451, grad/param norm = 5.3179e-01, time/batch = 0.1763s	
1432/2700 (epoch 26.519), train_loss = 1.56832346, grad/param norm = 5.1826e-01, time/batch = 0.1700s	
1433/2700 (epoch 26.537), train_loss = 1.59278800, grad/param norm = 4.8740e-01, time/batch = 0.1652s	
1434/2700 (epoch 26.556), train_loss = 1.50156928, grad/param norm = 4.7817e-01, time/batch = 0.1554s	
1435/2700 (epoch 26.574), train_loss = 1.51938361, grad/param norm = 5.5579e-01, time/batch = 0.1734s	
1436/2700 (epoch 26.593), train_loss = 1.53314555, grad/param norm = 5.5339e-01, time/batch = 0.1817s	
1437/2700 (epoch 26.611), train_loss = 1.46577003, grad/param norm = 4.2990e-01, time/batch = 0.1820s	
1438/2700 (epoch 26.630), train_loss = 1.49860302, grad/param norm = 4.3559e-01, time/batch = 0.1816s	
1439/2700 (epoch 26.648), train_loss = 1.52840699, grad/param norm = 4.4124e-01, time/batch = 0.1813s	
1440/2700 (epoch 26.667), train_loss = 1.50521065, grad/param norm = 4.7001e-01, time/batch = 0.1594s	
1441/2700 (epoch 26.685), train_loss = 1.55585499, grad/param norm = 4.9863e-01, time/batch = 0.1772s	
1442/2700 (epoch 26.704), train_loss = 1.57398020, grad/param norm = 5.1151e-01, time/batch = 0.1807s	
1443/2700 (epoch 26.722), train_loss = 1.53008340, grad/param norm = 4.2777e-01, time/batch = 0.1827s	
1444/2700 (epoch 26.741), train_loss = 1.54302286, grad/param norm = 4.7344e-01, time/batch = 0.1760s	
1445/2700 (epoch 26.759), train_loss = 1.55371235, grad/param norm = 4.9979e-01, time/batch = 0.1798s	
1446/2700 (epoch 26.778), train_loss = 1.58933953, grad/param norm = 5.1711e-01, time/batch = 0.1814s	
1447/2700 (epoch 26.796), train_loss = 1.55316111, grad/param norm = 5.1088e-01, time/batch = 0.1801s	
1448/2700 (epoch 26.815), train_loss = 1.57544954, grad/param norm = 4.6538e-01, time/batch = 0.1739s	
1449/2700 (epoch 26.833), train_loss = 1.53459333, grad/param norm = 4.8579e-01, time/batch = 0.1804s	
1450/2700 (epoch 26.852), train_loss = 1.52506046, grad/param norm = 4.7492e-01, time/batch = 0.1556s	
1451/2700 (epoch 26.870), train_loss = 1.54596102, grad/param norm = 4.6386e-01, time/batch = 0.1786s	
1452/2700 (epoch 26.889), train_loss = 1.54592920, grad/param norm = 4.5275e-01, time/batch = 0.1698s	
1453/2700 (epoch 26.907), train_loss = 1.65733394, grad/param norm = 4.7745e-01, time/batch = 0.1493s	
1454/2700 (epoch 26.926), train_loss = 1.57336979, grad/param norm = 4.7628e-01, time/batch = 0.1676s	
1455/2700 (epoch 26.944), train_loss = 1.55415774, grad/param norm = 4.8249e-01, time/batch = 0.1604s	
1456/2700 (epoch 26.963), train_loss = 1.58938081, grad/param norm = 5.2942e-01, time/batch = 0.1562s	
1457/2700 (epoch 26.981), train_loss = 1.55706323, grad/param norm = 4.5768e-01, time/batch = 0.1616s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1458/2700 (epoch 27.000), train_loss = 1.63672652, grad/param norm = 5.1661e-01, time/batch = 0.1524s	
1459/2700 (epoch 27.019), train_loss = 1.59782627, grad/param norm = 5.2775e-01, time/batch = 0.1597s	
1460/2700 (epoch 27.037), train_loss = 1.61149324, grad/param norm = 5.3094e-01, time/batch = 0.1526s	
1461/2700 (epoch 27.056), train_loss = 1.53455145, grad/param norm = 5.0239e-01, time/batch = 0.1816s	
1462/2700 (epoch 27.074), train_loss = 1.53751452, grad/param norm = 4.8339e-01, time/batch = 0.1736s	
1463/2700 (epoch 27.093), train_loss = 1.52901209, grad/param norm = 4.8367e-01, time/batch = 0.1752s	
1464/2700 (epoch 27.111), train_loss = 1.49842092, grad/param norm = 4.7428e-01, time/batch = 0.1694s	
1465/2700 (epoch 27.130), train_loss = 1.54889562, grad/param norm = 4.7016e-01, time/batch = 0.1675s	
1466/2700 (epoch 27.148), train_loss = 1.49522452, grad/param norm = 4.5237e-01, time/batch = 0.1626s	
1467/2700 (epoch 27.167), train_loss = 1.60106847, grad/param norm = 4.9160e-01, time/batch = 0.1641s	
1468/2700 (epoch 27.185), train_loss = 1.50920787, grad/param norm = 4.6013e-01, time/batch = 0.1549s	
1469/2700 (epoch 27.204), train_loss = 1.58725677, grad/param norm = 5.0886e-01, time/batch = 0.1829s	
1470/2700 (epoch 27.222), train_loss = 1.49833154, grad/param norm = 5.0321e-01, time/batch = 0.1738s	
1471/2700 (epoch 27.241), train_loss = 1.43162267, grad/param norm = 4.6101e-01, time/batch = 0.1691s	
1472/2700 (epoch 27.259), train_loss = 1.50540017, grad/param norm = 4.6907e-01, time/batch = 0.1448s	
1473/2700 (epoch 27.278), train_loss = 1.59947106, grad/param norm = 5.3190e-01, time/batch = 0.1677s	
1474/2700 (epoch 27.296), train_loss = 1.55228304, grad/param norm = 4.7638e-01, time/batch = 0.1746s	
1475/2700 (epoch 27.315), train_loss = 1.54803592, grad/param norm = 4.9515e-01, time/batch = 0.1793s	
1476/2700 (epoch 27.333), train_loss = 1.55785288, grad/param norm = 4.7574e-01, time/batch = 0.1792s	
1477/2700 (epoch 27.352), train_loss = 1.54638603, grad/param norm = 4.6432e-01, time/batch = 0.1738s	
1478/2700 (epoch 27.370), train_loss = 1.56639678, grad/param norm = 4.8475e-01, time/batch = 0.1602s	
1479/2700 (epoch 27.389), train_loss = 1.53510989, grad/param norm = 5.5303e-01, time/batch = 0.1592s	
1480/2700 (epoch 27.407), train_loss = 1.58017568, grad/param norm = 6.0786e-01, time/batch = 0.1667s	
1481/2700 (epoch 27.426), train_loss = 1.59005728, grad/param norm = 5.5108e-01, time/batch = 0.1463s	
1482/2700 (epoch 27.444), train_loss = 1.52127925, grad/param norm = 5.0052e-01, time/batch = 0.1411s	
1483/2700 (epoch 27.463), train_loss = 1.57400066, grad/param norm = 4.8612e-01, time/batch = 0.1656s	
1484/2700 (epoch 27.481), train_loss = 1.58157414, grad/param norm = 4.7097e-01, time/batch = 0.1659s	
1485/2700 (epoch 27.500), train_loss = 1.52581449, grad/param norm = 5.1264e-01, time/batch = 0.1635s	
1486/2700 (epoch 27.519), train_loss = 1.55627740, grad/param norm = 4.8954e-01, time/batch = 0.1668s	
1487/2700 (epoch 27.537), train_loss = 1.58026041, grad/param norm = 4.6893e-01, time/batch = 0.1656s	
1488/2700 (epoch 27.556), train_loss = 1.48968181, grad/param norm = 4.7374e-01, time/batch = 0.1799s	
1489/2700 (epoch 27.574), train_loss = 1.50611102, grad/param norm = 5.5007e-01, time/batch = 0.1809s	
1490/2700 (epoch 27.593), train_loss = 1.52000027, grad/param norm = 5.4731e-01, time/batch = 0.1782s	
1491/2700 (epoch 27.611), train_loss = 1.45562345, grad/param norm = 4.2530e-01, time/batch = 0.1575s	
1492/2700 (epoch 27.630), train_loss = 1.48739747, grad/param norm = 4.4213e-01, time/batch = 0.1808s	
1493/2700 (epoch 27.648), train_loss = 1.51753290, grad/param norm = 4.4189e-01, time/batch = 0.1815s	
1494/2700 (epoch 27.667), train_loss = 1.49379095, grad/param norm = 4.6923e-01, time/batch = 0.1823s	
1495/2700 (epoch 27.685), train_loss = 1.54463132, grad/param norm = 4.9743e-01, time/batch = 0.1808s	
1496/2700 (epoch 27.704), train_loss = 1.56394919, grad/param norm = 5.1161e-01, time/batch = 0.1749s	
1497/2700 (epoch 27.722), train_loss = 1.51986590, grad/param norm = 4.2834e-01, time/batch = 0.1656s	
1498/2700 (epoch 27.741), train_loss = 1.53017287, grad/param norm = 4.7454e-01, time/batch = 0.1807s	
1499/2700 (epoch 27.759), train_loss = 1.54124687, grad/param norm = 4.9910e-01, time/batch = 0.1806s	
1500/2700 (epoch 27.778), train_loss = 1.57721859, grad/param norm = 5.1746e-01, time/batch = 0.1810s	
1501/2700 (epoch 27.796), train_loss = 1.54024069, grad/param norm = 5.0565e-01, time/batch = 0.1348s	
1502/2700 (epoch 27.815), train_loss = 1.56397463, grad/param norm = 4.6464e-01, time/batch = 0.1511s	
1503/2700 (epoch 27.833), train_loss = 1.52321558, grad/param norm = 4.8806e-01, time/batch = 0.1584s	
1504/2700 (epoch 27.852), train_loss = 1.51339418, grad/param norm = 4.8119e-01, time/batch = 0.1576s	
1505/2700 (epoch 27.870), train_loss = 1.53326391, grad/param norm = 4.6439e-01, time/batch = 0.1506s	
1506/2700 (epoch 27.889), train_loss = 1.53425556, grad/param norm = 4.4844e-01, time/batch = 0.1489s	
1507/2700 (epoch 27.907), train_loss = 1.64427388, grad/param norm = 4.8046e-01, time/batch = 0.1487s	
1508/2700 (epoch 27.926), train_loss = 1.56058721, grad/param norm = 4.7505e-01, time/batch = 0.1540s	
1509/2700 (epoch 27.944), train_loss = 1.54133350, grad/param norm = 4.7830e-01, time/batch = 0.1605s	
1510/2700 (epoch 27.963), train_loss = 1.57559262, grad/param norm = 5.2190e-01, time/batch = 0.1623s	
1511/2700 (epoch 27.981), train_loss = 1.54378709, grad/param norm = 4.5627e-01, time/batch = 0.1514s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1512/2700 (epoch 28.000), train_loss = 1.62459632, grad/param norm = 5.1020e-01, time/batch = 0.1546s	
1513/2700 (epoch 28.019), train_loss = 1.58544823, grad/param norm = 5.0651e-01, time/batch = 0.1763s	
1514/2700 (epoch 28.037), train_loss = 1.59796394, grad/param norm = 4.9517e-01, time/batch = 0.1791s	
1515/2700 (epoch 28.056), train_loss = 1.52225602, grad/param norm = 4.6953e-01, time/batch = 0.1787s	
1516/2700 (epoch 28.074), train_loss = 1.52700302, grad/param norm = 4.7543e-01, time/batch = 0.1624s	
1517/2700 (epoch 28.093), train_loss = 1.51778866, grad/param norm = 5.0022e-01, time/batch = 0.1607s	
1518/2700 (epoch 28.111), train_loss = 1.48638614, grad/param norm = 4.8042e-01, time/batch = 0.1571s	
1519/2700 (epoch 28.130), train_loss = 1.53899986, grad/param norm = 4.8884e-01, time/batch = 0.1640s	
1520/2700 (epoch 28.148), train_loss = 1.48443139, grad/param norm = 4.6588e-01, time/batch = 0.1655s	
1521/2700 (epoch 28.167), train_loss = 1.59003162, grad/param norm = 4.8571e-01, time/batch = 0.1807s	
1522/2700 (epoch 28.185), train_loss = 1.49675821, grad/param norm = 4.5176e-01, time/batch = 0.1819s	
1523/2700 (epoch 28.204), train_loss = 1.57648211, grad/param norm = 5.0544e-01, time/batch = 0.1555s	
1524/2700 (epoch 28.222), train_loss = 1.48669763, grad/param norm = 4.9564e-01, time/batch = 0.1703s	
1525/2700 (epoch 28.241), train_loss = 1.42139006, grad/param norm = 4.5276e-01, time/batch = 0.1740s	
1526/2700 (epoch 28.259), train_loss = 1.49528150, grad/param norm = 4.7571e-01, time/batch = 0.1585s	
1527/2700 (epoch 28.278), train_loss = 1.58985039, grad/param norm = 5.3659e-01, time/batch = 0.1653s	
1528/2700 (epoch 28.296), train_loss = 1.54154862, grad/param norm = 4.7782e-01, time/batch = 0.1737s	
1529/2700 (epoch 28.315), train_loss = 1.53602260, grad/param norm = 5.0014e-01, time/batch = 0.1779s	
1530/2700 (epoch 28.333), train_loss = 1.54676751, grad/param norm = 4.7906e-01, time/batch = 0.1642s	
1531/2700 (epoch 28.352), train_loss = 1.53441916, grad/param norm = 4.6470e-01, time/batch = 0.1714s	
1532/2700 (epoch 28.370), train_loss = 1.55468138, grad/param norm = 4.8874e-01, time/batch = 0.1736s	
1533/2700 (epoch 28.389), train_loss = 1.52256713, grad/param norm = 5.4567e-01, time/batch = 0.1603s	
1534/2700 (epoch 28.407), train_loss = 1.56873847, grad/param norm = 5.8774e-01, time/batch = 0.1812s	
1535/2700 (epoch 28.426), train_loss = 1.57777449, grad/param norm = 5.2893e-01, time/batch = 0.1835s	
1536/2700 (epoch 28.444), train_loss = 1.51031075, grad/param norm = 4.8514e-01, time/batch = 0.1801s	
1537/2700 (epoch 28.463), train_loss = 1.56163196, grad/param norm = 4.7273e-01, time/batch = 0.1831s	
1538/2700 (epoch 28.481), train_loss = 1.56984423, grad/param norm = 4.7048e-01, time/batch = 0.1815s	
1539/2700 (epoch 28.500), train_loss = 1.51407924, grad/param norm = 5.2970e-01, time/batch = 0.1754s	
1540/2700 (epoch 28.519), train_loss = 1.54652500, grad/param norm = 5.0250e-01, time/batch = 0.1780s	
1541/2700 (epoch 28.537), train_loss = 1.56948270, grad/param norm = 4.7439e-01, time/batch = 0.1650s	
1542/2700 (epoch 28.556), train_loss = 1.47876255, grad/param norm = 4.7680e-01, time/batch = 0.1655s	
1543/2700 (epoch 28.574), train_loss = 1.49381707, grad/param norm = 5.5133e-01, time/batch = 0.1526s	
1544/2700 (epoch 28.593), train_loss = 1.50724037, grad/param norm = 5.3682e-01, time/batch = 0.1554s	
1545/2700 (epoch 28.611), train_loss = 1.44584007, grad/param norm = 4.2541e-01, time/batch = 0.1462s	
1546/2700 (epoch 28.630), train_loss = 1.47599083, grad/param norm = 4.3907e-01, time/batch = 0.1518s	
1547/2700 (epoch 28.648), train_loss = 1.50709402, grad/param norm = 4.4479e-01, time/batch = 0.1606s	
1548/2700 (epoch 28.667), train_loss = 1.48322186, grad/param norm = 4.8040e-01, time/batch = 0.1671s	
1549/2700 (epoch 28.685), train_loss = 1.53395483, grad/param norm = 5.0619e-01, time/batch = 0.1540s	
1550/2700 (epoch 28.704), train_loss = 1.55410532, grad/param norm = 5.1474e-01, time/batch = 0.1680s	
1551/2700 (epoch 28.722), train_loss = 1.50995066, grad/param norm = 4.2527e-01, time/batch = 0.1842s	
1552/2700 (epoch 28.741), train_loss = 1.51768331, grad/param norm = 4.6733e-01, time/batch = 0.1827s	
1553/2700 (epoch 28.759), train_loss = 1.52946620, grad/param norm = 4.9232e-01, time/batch = 0.1831s	
1554/2700 (epoch 28.778), train_loss = 1.56556904, grad/param norm = 5.1545e-01, time/batch = 0.1545s	
1555/2700 (epoch 28.796), train_loss = 1.52777589, grad/param norm = 5.0063e-01, time/batch = 0.1453s	
1556/2700 (epoch 28.815), train_loss = 1.55342592, grad/param norm = 4.6592e-01, time/batch = 0.1573s	
1557/2700 (epoch 28.833), train_loss = 1.51293506, grad/param norm = 4.9828e-01, time/batch = 0.1662s	
1558/2700 (epoch 28.852), train_loss = 1.50251363, grad/param norm = 4.9393e-01, time/batch = 0.1620s	
1559/2700 (epoch 28.870), train_loss = 1.52179449, grad/param norm = 4.7686e-01, time/batch = 0.1742s	
1560/2700 (epoch 28.889), train_loss = 1.52367009, grad/param norm = 4.5240e-01, time/batch = 0.1703s	
1561/2700 (epoch 28.907), train_loss = 1.63145323, grad/param norm = 4.7568e-01, time/batch = 0.1692s	
1562/2700 (epoch 28.926), train_loss = 1.54802920, grad/param norm = 4.6337e-01, time/batch = 0.1781s	
1563/2700 (epoch 28.944), train_loss = 1.52917086, grad/param norm = 4.8117e-01, time/batch = 0.1783s	
1564/2700 (epoch 28.963), train_loss = 1.56242489, grad/param norm = 5.2120e-01, time/batch = 0.1679s	
1565/2700 (epoch 28.981), train_loss = 1.53201409, grad/param norm = 4.6390e-01, time/batch = 0.1756s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
1566/2700 (epoch 29.000), train_loss = 1.61410542, grad/param norm = 5.2405e-01, time/batch = 0.1822s	
1567/2700 (epoch 29.019), train_loss = 1.57491332, grad/param norm = 5.2063e-01, time/batch = 0.1822s	
1568/2700 (epoch 29.037), train_loss = 1.58696191, grad/param norm = 5.0887e-01, time/batch = 0.1643s	
1569/2700 (epoch 29.056), train_loss = 1.51280792, grad/param norm = 4.7991e-01, time/batch = 0.1668s	
1570/2700 (epoch 29.074), train_loss = 1.51750352, grad/param norm = 4.8072e-01, time/batch = 0.1605s	
1571/2700 (epoch 29.093), train_loss = 1.50508953, grad/param norm = 4.8624e-01, time/batch = 0.1593s	
1572/2700 (epoch 29.111), train_loss = 1.47376031, grad/param norm = 4.6163e-01, time/batch = 0.1663s	
1573/2700 (epoch 29.130), train_loss = 1.52740642, grad/param norm = 4.6708e-01, time/batch = 0.1713s	
1574/2700 (epoch 29.148), train_loss = 1.47345694, grad/param norm = 4.4815e-01, time/batch = 0.1716s	
1575/2700 (epoch 29.167), train_loss = 1.58056661, grad/param norm = 5.0328e-01, time/batch = 0.1643s	
1576/2700 (epoch 29.185), train_loss = 1.48626673, grad/param norm = 4.6914e-01, time/batch = 0.1812s	
1577/2700 (epoch 29.204), train_loss = 1.56876121, grad/param norm = 5.3837e-01, time/batch = 0.1786s	
1578/2700 (epoch 29.222), train_loss = 1.47743334, grad/param norm = 5.1976e-01, time/batch = 0.1742s	
1579/2700 (epoch 29.241), train_loss = 1.41240219, grad/param norm = 4.5579e-01, time/batch = 0.1575s	
1580/2700 (epoch 29.259), train_loss = 1.48477275, grad/param norm = 4.6298e-01, time/batch = 0.1543s	
1581/2700 (epoch 29.278), train_loss = 1.57906299, grad/param norm = 5.1972e-01, time/batch = 0.1818s	
1582/2700 (epoch 29.296), train_loss = 1.53027565, grad/param norm = 4.5906e-01, time/batch = 0.1833s	
1583/2700 (epoch 29.315), train_loss = 1.52357599, grad/param norm = 4.8955e-01, time/batch = 0.1798s	
1584/2700 (epoch 29.333), train_loss = 1.53653374, grad/param norm = 4.8916e-01, time/batch = 0.1707s	
1585/2700 (epoch 29.352), train_loss = 1.52349390, grad/param norm = 4.7935e-01, time/batch = 0.1588s	
1586/2700 (epoch 29.370), train_loss = 1.54336111, grad/param norm = 4.7924e-01, time/batch = 0.1559s	
1587/2700 (epoch 29.389), train_loss = 1.51014998, grad/param norm = 5.2172e-01, time/batch = 0.1603s	
1588/2700 (epoch 29.407), train_loss = 1.55758913, grad/param norm = 5.6794e-01, time/batch = 0.1625s	
1589/2700 (epoch 29.426), train_loss = 1.56610162, grad/param norm = 5.1707e-01, time/batch = 0.1524s	
1590/2700 (epoch 29.444), train_loss = 1.50009541, grad/param norm = 4.7420e-01, time/batch = 0.1748s	
1591/2700 (epoch 29.463), train_loss = 1.55017815, grad/param norm = 4.6273e-01, time/batch = 0.1594s	
1592/2700 (epoch 29.481), train_loss = 1.55875082, grad/param norm = 4.7449e-01, time/batch = 0.1508s	
1593/2700 (epoch 29.500), train_loss = 1.50246442, grad/param norm = 5.4072e-01, time/batch = 0.1483s	
1594/2700 (epoch 29.519), train_loss = 1.53668914, grad/param norm = 5.0809e-01, time/batch = 0.1438s	
1595/2700 (epoch 29.537), train_loss = 1.55919853, grad/param norm = 4.7854e-01, time/batch = 0.1384s	
1596/2700 (epoch 29.556), train_loss = 1.46830878, grad/param norm = 4.8234e-01, time/batch = 0.1798s	
1597/2700 (epoch 29.574), train_loss = 1.48178797, grad/param norm = 5.4925e-01, time/batch = 0.1843s	
1598/2700 (epoch 29.593), train_loss = 1.49500378, grad/param norm = 5.2968e-01, time/batch = 0.1807s	
1599/2700 (epoch 29.611), train_loss = 1.43672520, grad/param norm = 4.2767e-01, time/batch = 0.1823s	
1600/2700 (epoch 29.630), train_loss = 1.46534878, grad/param norm = 4.4120e-01, time/batch = 0.1826s	
1601/2700 (epoch 29.648), train_loss = 1.49705409, grad/param norm = 4.4682e-01, time/batch = 0.1847s	
1602/2700 (epoch 29.667), train_loss = 1.47296929, grad/param norm = 4.8586e-01, time/batch = 0.1776s	
1603/2700 (epoch 29.685), train_loss = 1.52320760, grad/param norm = 5.0901e-01, time/batch = 0.1697s	
1604/2700 (epoch 29.704), train_loss = 1.54457184, grad/param norm = 5.1578e-01, time/batch = 0.1542s	
1605/2700 (epoch 29.722), train_loss = 1.50069975, grad/param norm = 4.2642e-01, time/batch = 0.1624s	
1606/2700 (epoch 29.741), train_loss = 1.50617324, grad/param norm = 4.6507e-01, time/batch = 0.1552s	
1607/2700 (epoch 29.759), train_loss = 1.51857845, grad/param norm = 4.9117e-01, time/batch = 0.1504s	
1608/2700 (epoch 29.778), train_loss = 1.55429874, grad/param norm = 5.1709e-01, time/batch = 0.1399s	
1609/2700 (epoch 29.796), train_loss = 1.51587785, grad/param norm = 4.9715e-01, time/batch = 0.1571s	
1610/2700 (epoch 29.815), train_loss = 1.54291785, grad/param norm = 4.6898e-01, time/batch = 0.1654s	
1611/2700 (epoch 29.833), train_loss = 1.50244942, grad/param norm = 5.0078e-01, time/batch = 0.1787s	
1612/2700 (epoch 29.852), train_loss = 1.49138320, grad/param norm = 4.9232e-01, time/batch = 0.1731s	
1613/2700 (epoch 29.870), train_loss = 1.51036186, grad/param norm = 4.7107e-01, time/batch = 0.1688s	
1614/2700 (epoch 29.889), train_loss = 1.51318195, grad/param norm = 4.4909e-01, time/batch = 0.1520s	
1615/2700 (epoch 29.907), train_loss = 1.61984556, grad/param norm = 4.8596e-01, time/batch = 0.1566s	
1616/2700 (epoch 29.926), train_loss = 1.53698973, grad/param norm = 4.6985e-01, time/batch = 0.1494s	
1617/2700 (epoch 29.944), train_loss = 1.51775072, grad/param norm = 4.7501e-01, time/batch = 0.1794s	
1618/2700 (epoch 29.963), train_loss = 1.54988014, grad/param norm = 5.1466e-01, time/batch = 0.1826s	
1619/2700 (epoch 29.981), train_loss = 1.52009213, grad/param norm = 4.6360e-01, time/batch = 0.1834s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
1620/2700 (epoch 30.000), train_loss = 1.60226939, grad/param norm = 5.0677e-01, time/batch = 0.1811s	
1621/2700 (epoch 30.019), train_loss = 1.56380322, grad/param norm = 4.9807e-01, time/batch = 0.1662s	
1622/2700 (epoch 30.037), train_loss = 1.57461417, grad/param norm = 4.8616e-01, time/batch = 0.1691s	
1623/2700 (epoch 30.056), train_loss = 1.50206799, grad/param norm = 4.6477e-01, time/batch = 0.1728s	
1624/2700 (epoch 30.074), train_loss = 1.50923852, grad/param norm = 4.9333e-01, time/batch = 0.1622s	
1625/2700 (epoch 30.093), train_loss = 1.49641392, grad/param norm = 5.3172e-01, time/batch = 0.1767s	
1626/2700 (epoch 30.111), train_loss = 1.46350493, grad/param norm = 4.7795e-01, time/batch = 0.1531s	
1627/2700 (epoch 30.130), train_loss = 1.51834374, grad/param norm = 4.9265e-01, time/batch = 0.1411s	
1628/2700 (epoch 30.148), train_loss = 1.46375612, grad/param norm = 4.6217e-01, time/batch = 0.1734s	
1629/2700 (epoch 30.167), train_loss = 1.57005393, grad/param norm = 4.8656e-01, time/batch = 0.1715s	
1630/2700 (epoch 30.185), train_loss = 1.47422009, grad/param norm = 4.4828e-01, time/batch = 0.1635s	
1631/2700 (epoch 30.204), train_loss = 1.55752407, grad/param norm = 5.1910e-01, time/batch = 0.1736s	
1632/2700 (epoch 30.222), train_loss = 1.46590788, grad/param norm = 4.9821e-01, time/batch = 0.1692s	
1633/2700 (epoch 30.241), train_loss = 1.40313571, grad/param norm = 4.4720e-01, time/batch = 0.1659s	
1634/2700 (epoch 30.259), train_loss = 1.47696973, grad/param norm = 4.9432e-01, time/batch = 0.1811s	
1635/2700 (epoch 30.278), train_loss = 1.57107529, grad/param norm = 5.4386e-01, time/batch = 0.1780s	
1636/2700 (epoch 30.296), train_loss = 1.52086723, grad/param norm = 4.7110e-01, time/batch = 0.1757s	
1637/2700 (epoch 30.315), train_loss = 1.51279034, grad/param norm = 4.9133e-01, time/batch = 0.1449s	
1638/2700 (epoch 30.333), train_loss = 1.52614692, grad/param norm = 4.8000e-01, time/batch = 0.1806s	
1639/2700 (epoch 30.352), train_loss = 1.51205831, grad/param norm = 4.6900e-01, time/batch = 0.1798s	
1640/2700 (epoch 30.370), train_loss = 1.53327129, grad/param norm = 5.0381e-01, time/batch = 0.1821s	
1641/2700 (epoch 30.389), train_loss = 1.50128046, grad/param norm = 5.5633e-01, time/batch = 0.1708s	
1642/2700 (epoch 30.407), train_loss = 1.54836732, grad/param norm = 5.7916e-01, time/batch = 0.1769s	
1643/2700 (epoch 30.426), train_loss = 1.55547970, grad/param norm = 5.1419e-01, time/batch = 0.1687s	
1644/2700 (epoch 30.444), train_loss = 1.49081177, grad/param norm = 4.7161e-01, time/batch = 0.1763s	
1645/2700 (epoch 30.463), train_loss = 1.53980664, grad/param norm = 4.6111e-01, time/batch = 0.1777s	
1646/2700 (epoch 30.481), train_loss = 1.54807242, grad/param norm = 4.7832e-01, time/batch = 0.1754s	
1647/2700 (epoch 30.500), train_loss = 1.49078885, grad/param norm = 5.3370e-01, time/batch = 0.1685s	
1648/2700 (epoch 30.519), train_loss = 1.52664515, grad/param norm = 4.9719e-01, time/batch = 0.1824s	
1649/2700 (epoch 30.537), train_loss = 1.54881198, grad/param norm = 4.7404e-01, time/batch = 0.1774s	
1650/2700 (epoch 30.556), train_loss = 1.45808457, grad/param norm = 4.8172e-01, time/batch = 0.1688s	
1651/2700 (epoch 30.574), train_loss = 1.47000118, grad/param norm = 5.4389e-01, time/batch = 0.1647s	
1652/2700 (epoch 30.593), train_loss = 1.48319052, grad/param norm = 5.2343e-01, time/batch = 0.1701s	
1653/2700 (epoch 30.611), train_loss = 1.42805845, grad/param norm = 4.3069e-01, time/batch = 0.1555s	
1654/2700 (epoch 30.630), train_loss = 1.45537585, grad/param norm = 4.4573e-01, time/batch = 0.1805s	
1655/2700 (epoch 30.648), train_loss = 1.48741183, grad/param norm = 4.4951e-01, time/batch = 0.1778s	
1656/2700 (epoch 30.667), train_loss = 1.46296055, grad/param norm = 4.8963e-01, time/batch = 0.1844s	
1657/2700 (epoch 30.685), train_loss = 1.51308238, grad/param norm = 5.1089e-01, time/batch = 0.1664s	
1658/2700 (epoch 30.704), train_loss = 1.53545577, grad/param norm = 5.1608e-01, time/batch = 0.1758s	
1659/2700 (epoch 30.722), train_loss = 1.49198244, grad/param norm = 4.3043e-01, time/batch = 0.1881s	
1660/2700 (epoch 30.741), train_loss = 1.49535748, grad/param norm = 4.6485e-01, time/batch = 0.1878s	
1661/2700 (epoch 30.759), train_loss = 1.50854196, grad/param norm = 4.9362e-01, time/batch = 0.1781s	
1662/2700 (epoch 30.778), train_loss = 1.54347043, grad/param norm = 5.1900e-01, time/batch = 0.1755s	
1663/2700 (epoch 30.796), train_loss = 1.50446836, grad/param norm = 4.9338e-01, time/batch = 0.1808s	
1664/2700 (epoch 30.815), train_loss = 1.53282809, grad/param norm = 4.7137e-01, time/batch = 0.1832s	
1665/2700 (epoch 30.833), train_loss = 1.49243081, grad/param norm = 5.0116e-01, time/batch = 0.1760s	
1666/2700 (epoch 30.852), train_loss = 1.48081936, grad/param norm = 4.8987e-01, time/batch = 0.1761s	
1667/2700 (epoch 30.870), train_loss = 1.49963431, grad/param norm = 4.6716e-01, time/batch = 0.1630s	
1668/2700 (epoch 30.889), train_loss = 1.50338549, grad/param norm = 4.5266e-01, time/batch = 0.1858s	
1669/2700 (epoch 30.907), train_loss = 1.60880668, grad/param norm = 4.9996e-01, time/batch = 0.1798s	
1670/2700 (epoch 30.926), train_loss = 1.52664112, grad/param norm = 4.7692e-01, time/batch = 0.1742s	
1671/2700 (epoch 30.944), train_loss = 1.50724637, grad/param norm = 4.7766e-01, time/batch = 0.1787s	
1672/2700 (epoch 30.963), train_loss = 1.53800203, grad/param norm = 5.1359e-01, time/batch = 0.1643s	
1673/2700 (epoch 30.981), train_loss = 1.50908929, grad/param norm = 4.6788e-01, time/batch = 0.1642s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
1674/2700 (epoch 31.000), train_loss = 1.59206251, grad/param norm = 5.1000e-01, time/batch = 0.1575s	
1675/2700 (epoch 31.019), train_loss = 1.55380178, grad/param norm = 4.9962e-01, time/batch = 0.1658s	
1676/2700 (epoch 31.037), train_loss = 1.56390588, grad/param norm = 4.8704e-01, time/batch = 0.1647s	
1677/2700 (epoch 31.056), train_loss = 1.49280147, grad/param norm = 4.6578e-01, time/batch = 0.1689s	
1678/2700 (epoch 31.074), train_loss = 1.50050270, grad/param norm = 4.9103e-01, time/batch = 0.1684s	
1679/2700 (epoch 31.093), train_loss = 1.48409990, grad/param norm = 5.0527e-01, time/batch = 0.1809s	
1680/2700 (epoch 31.111), train_loss = 1.45225098, grad/param norm = 4.6392e-01, time/batch = 0.1782s	
1681/2700 (epoch 31.130), train_loss = 1.50775944, grad/param norm = 4.7415e-01, time/batch = 0.1809s	
1682/2700 (epoch 31.148), train_loss = 1.45392715, grad/param norm = 4.4492e-01, time/batch = 0.1865s	
1683/2700 (epoch 31.167), train_loss = 1.56165226, grad/param norm = 5.0950e-01, time/batch = 0.1832s	
1684/2700 (epoch 31.185), train_loss = 1.46495454, grad/param norm = 4.7123e-01, time/batch = 0.1831s	
1685/2700 (epoch 31.204), train_loss = 1.55037952, grad/param norm = 5.4887e-01, time/batch = 0.1834s	
1686/2700 (epoch 31.222), train_loss = 1.45719606, grad/param norm = 5.1770e-01, time/batch = 0.1817s	
1687/2700 (epoch 31.241), train_loss = 1.39496307, grad/param norm = 4.4904e-01, time/batch = 0.1678s	
1688/2700 (epoch 31.259), train_loss = 1.46759078, grad/param norm = 4.8458e-01, time/batch = 0.1773s	
1689/2700 (epoch 31.278), train_loss = 1.56103729, grad/param norm = 5.2821e-01, time/batch = 0.1691s	
1690/2700 (epoch 31.296), train_loss = 1.51084158, grad/param norm = 4.5920e-01, time/batch = 0.1646s	
1691/2700 (epoch 31.315), train_loss = 1.50199347, grad/param norm = 4.8629e-01, time/batch = 0.1607s	
1692/2700 (epoch 31.333), train_loss = 1.51704366, grad/param norm = 4.9109e-01, time/batch = 0.1618s	
1693/2700 (epoch 31.352), train_loss = 1.50219691, grad/param norm = 4.7865e-01, time/batch = 0.1552s	
1694/2700 (epoch 31.370), train_loss = 1.52301399, grad/param norm = 4.9694e-01, time/batch = 0.1665s	
1695/2700 (epoch 31.389), train_loss = 1.49056718, grad/param norm = 5.3824e-01, time/batch = 0.1761s	
1696/2700 (epoch 31.407), train_loss = 1.53815157, grad/param norm = 5.6204e-01, time/batch = 0.1792s	
1697/2700 (epoch 31.426), train_loss = 1.54498499, grad/param norm = 5.0498e-01, time/batch = 0.1812s	
1698/2700 (epoch 31.444), train_loss = 1.48196401, grad/param norm = 4.6922e-01, time/batch = 0.1595s	
1699/2700 (epoch 31.463), train_loss = 1.52974073, grad/param norm = 4.6017e-01, time/batch = 0.1556s	
1700/2700 (epoch 31.481), train_loss = 1.53811289, grad/param norm = 4.8154e-01, time/batch = 0.1587s	
1701/2700 (epoch 31.500), train_loss = 1.48031122, grad/param norm = 5.4234e-01, time/batch = 0.1846s	
1702/2700 (epoch 31.519), train_loss = 1.51747376, grad/param norm = 4.9878e-01, time/batch = 0.1822s	
1703/2700 (epoch 31.537), train_loss = 1.53891264, grad/param norm = 4.7215e-01, time/batch = 0.1811s	
1704/2700 (epoch 31.556), train_loss = 1.44827129, grad/param norm = 4.8090e-01, time/batch = 0.1814s	
1705/2700 (epoch 31.574), train_loss = 1.45912999, grad/param norm = 5.4134e-01, time/batch = 0.1819s	
1706/2700 (epoch 31.593), train_loss = 1.47188493, grad/param norm = 5.1348e-01, time/batch = 0.1797s	
1707/2700 (epoch 31.611), train_loss = 1.41962404, grad/param norm = 4.3485e-01, time/batch = 0.1809s	
1708/2700 (epoch 31.630), train_loss = 1.44552364, grad/param norm = 4.4622e-01, time/batch = 0.1531s	
1709/2700 (epoch 31.648), train_loss = 1.47801618, grad/param norm = 4.5489e-01, time/batch = 0.1650s	
1710/2700 (epoch 31.667), train_loss = 1.45350383, grad/param norm = 4.9713e-01, time/batch = 0.1637s	
1711/2700 (epoch 31.685), train_loss = 1.50338830, grad/param norm = 5.1651e-01, time/batch = 0.1722s	
1712/2700 (epoch 31.704), train_loss = 1.52660457, grad/param norm = 5.1772e-01, time/batch = 0.1620s	
1713/2700 (epoch 31.722), train_loss = 1.48374286, grad/param norm = 4.3520e-01, time/batch = 0.1645s	
1714/2700 (epoch 31.741), train_loss = 1.48511872, grad/param norm = 4.6446e-01, time/batch = 0.1567s	
1715/2700 (epoch 31.759), train_loss = 1.49890754, grad/param norm = 4.9539e-01, time/batch = 0.1628s	
1716/2700 (epoch 31.778), train_loss = 1.53299536, grad/param norm = 5.1915e-01, time/batch = 0.1687s	
1717/2700 (epoch 31.796), train_loss = 1.49361861, grad/param norm = 4.8947e-01, time/batch = 0.1710s	
1718/2700 (epoch 31.815), train_loss = 1.52313949, grad/param norm = 4.7523e-01, time/batch = 0.1634s	
1719/2700 (epoch 31.833), train_loss = 1.48294167, grad/param norm = 5.0328e-01, time/batch = 0.1759s	
1720/2700 (epoch 31.852), train_loss = 1.47070327, grad/param norm = 4.8953e-01, time/batch = 0.1595s	
1721/2700 (epoch 31.870), train_loss = 1.48969551, grad/param norm = 4.6760e-01, time/batch = 0.1751s	
1722/2700 (epoch 31.889), train_loss = 1.49410959, grad/param norm = 4.5746e-01, time/batch = 0.1775s	
1723/2700 (epoch 31.907), train_loss = 1.59767455, grad/param norm = 5.0466e-01, time/batch = 0.1814s	
1724/2700 (epoch 31.926), train_loss = 1.51633120, grad/param norm = 4.7428e-01, time/batch = 0.1796s	
1725/2700 (epoch 31.944), train_loss = 1.49713376, grad/param norm = 4.7894e-01, time/batch = 0.1827s	
1726/2700 (epoch 31.963), train_loss = 1.52633564, grad/param norm = 5.1113e-01, time/batch = 0.1724s	
1727/2700 (epoch 31.981), train_loss = 1.49884710, grad/param norm = 4.7265e-01, time/batch = 0.1769s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
1728/2700 (epoch 32.000), train_loss = 1.58244051, grad/param norm = 5.1951e-01, time/batch = 0.1660s	
1729/2700 (epoch 32.019), train_loss = 1.54427009, grad/param norm = 5.0504e-01, time/batch = 0.1830s	
1730/2700 (epoch 32.037), train_loss = 1.55344144, grad/param norm = 4.8809e-01, time/batch = 0.1733s	
1731/2700 (epoch 32.056), train_loss = 1.48352265, grad/param norm = 4.6276e-01, time/batch = 0.1636s	
1732/2700 (epoch 32.074), train_loss = 1.49157880, grad/param norm = 4.8744e-01, time/batch = 0.1844s	
1733/2700 (epoch 32.093), train_loss = 1.47333878, grad/param norm = 4.9332e-01, time/batch = 0.1817s	
1734/2700 (epoch 32.111), train_loss = 1.44232873, grad/param norm = 4.6655e-01, time/batch = 0.1808s	
1735/2700 (epoch 32.130), train_loss = 1.49821591, grad/param norm = 4.7450e-01, time/batch = 0.1755s	
1736/2700 (epoch 32.148), train_loss = 1.44509593, grad/param norm = 4.4355e-01, time/batch = 0.1741s	
1737/2700 (epoch 32.167), train_loss = 1.55316756, grad/param norm = 5.2153e-01, time/batch = 0.1776s	
1738/2700 (epoch 32.185), train_loss = 1.45525499, grad/param norm = 4.7651e-01, time/batch = 0.1642s	
1739/2700 (epoch 32.204), train_loss = 1.54172799, grad/param norm = 5.5133e-01, time/batch = 0.1696s	
1740/2700 (epoch 32.222), train_loss = 1.44748314, grad/param norm = 5.1427e-01, time/batch = 0.1758s	
1741/2700 (epoch 32.241), train_loss = 1.38691681, grad/param norm = 4.4741e-01, time/batch = 0.1835s	
1742/2700 (epoch 32.259), train_loss = 1.45963575, grad/param norm = 4.9870e-01, time/batch = 0.1804s	
1743/2700 (epoch 32.278), train_loss = 1.55225820, grad/param norm = 5.3280e-01, time/batch = 0.1809s	
1744/2700 (epoch 32.296), train_loss = 1.50171604, grad/param norm = 4.6065e-01, time/batch = 0.1768s	
1745/2700 (epoch 32.315), train_loss = 1.49186615, grad/param norm = 4.8163e-01, time/batch = 0.1706s	
1746/2700 (epoch 32.333), train_loss = 1.50783968, grad/param norm = 4.8866e-01, time/batch = 0.1642s	
1747/2700 (epoch 32.352), train_loss = 1.49238109, grad/param norm = 4.7778e-01, time/batch = 0.1562s	
1748/2700 (epoch 32.370), train_loss = 1.51365450, grad/param norm = 5.1012e-01, time/batch = 0.1658s	
1749/2700 (epoch 32.389), train_loss = 1.48163047, grad/param norm = 5.4663e-01, time/batch = 0.1558s	
1750/2700 (epoch 32.407), train_loss = 1.52869483, grad/param norm = 5.5605e-01, time/batch = 0.1557s	
1751/2700 (epoch 32.426), train_loss = 1.53497283, grad/param norm = 4.9999e-01, time/batch = 0.1682s	
1752/2700 (epoch 32.444), train_loss = 1.47368030, grad/param norm = 4.6861e-01, time/batch = 0.1631s	
1753/2700 (epoch 32.463), train_loss = 1.52021777, grad/param norm = 4.6047e-01, time/batch = 0.1653s	
1754/2700 (epoch 32.481), train_loss = 1.52850880, grad/param norm = 4.8528e-01, time/batch = 0.1681s	
1755/2700 (epoch 32.500), train_loss = 1.46978071, grad/param norm = 5.3796e-01, time/batch = 0.1791s	
1756/2700 (epoch 32.519), train_loss = 1.50837225, grad/param norm = 4.9360e-01, time/batch = 0.1808s	
1757/2700 (epoch 32.537), train_loss = 1.52930826, grad/param norm = 4.7229e-01, time/batch = 0.1805s	
1758/2700 (epoch 32.556), train_loss = 1.43895485, grad/param norm = 4.8128e-01, time/batch = 0.1791s	
1759/2700 (epoch 32.574), train_loss = 1.44859921, grad/param norm = 5.3803e-01, time/batch = 0.1426s	
1760/2700 (epoch 32.593), train_loss = 1.46132845, grad/param norm = 5.0822e-01, time/batch = 0.1764s	
1761/2700 (epoch 32.611), train_loss = 1.41170562, grad/param norm = 4.4019e-01, time/batch = 0.1577s	
1762/2700 (epoch 32.630), train_loss = 1.43619224, grad/param norm = 4.4877e-01, time/batch = 0.1653s	
1763/2700 (epoch 32.648), train_loss = 1.46891070, grad/param norm = 4.5793e-01, time/batch = 0.1707s	
1764/2700 (epoch 32.667), train_loss = 1.44438782, grad/param norm = 5.0138e-01, time/batch = 0.1747s	
1765/2700 (epoch 32.685), train_loss = 1.49399156, grad/param norm = 5.1816e-01, time/batch = 0.1734s	
1766/2700 (epoch 32.704), train_loss = 1.51806341, grad/param norm = 5.1784e-01, time/batch = 0.1748s	
1767/2700 (epoch 32.722), train_loss = 1.47587212, grad/param norm = 4.4193e-01, time/batch = 0.1739s	
1768/2700 (epoch 32.741), train_loss = 1.47545414, grad/param norm = 4.6582e-01, time/batch = 0.1652s	
1769/2700 (epoch 32.759), train_loss = 1.48980915, grad/param norm = 4.9816e-01, time/batch = 0.1372s	
1770/2700 (epoch 32.778), train_loss = 1.52295891, grad/param norm = 5.1792e-01, time/batch = 0.1764s	
1771/2700 (epoch 32.796), train_loss = 1.48320784, grad/param norm = 4.8500e-01, time/batch = 0.1817s	
1772/2700 (epoch 32.815), train_loss = 1.51382016, grad/param norm = 4.7923e-01, time/batch = 0.1812s	
1773/2700 (epoch 32.833), train_loss = 1.47382763, grad/param norm = 5.0466e-01, time/batch = 0.1831s	
1774/2700 (epoch 32.852), train_loss = 1.46102288, grad/param norm = 4.8776e-01, time/batch = 0.1819s	
1775/2700 (epoch 32.870), train_loss = 1.48018291, grad/param norm = 4.6691e-01, time/batch = 0.1804s	
1776/2700 (epoch 32.889), train_loss = 1.48525472, grad/param norm = 4.6512e-01, time/batch = 0.1819s	
1777/2700 (epoch 32.907), train_loss = 1.58713641, grad/param norm = 5.1384e-01, time/batch = 0.1916s	
1778/2700 (epoch 32.926), train_loss = 1.50670561, grad/param norm = 4.7557e-01, time/batch = 0.1678s	
1779/2700 (epoch 32.944), train_loss = 1.48770896, grad/param norm = 4.8119e-01, time/batch = 0.1759s	
1780/2700 (epoch 32.963), train_loss = 1.51521256, grad/param norm = 5.0863e-01, time/batch = 0.1602s	
1781/2700 (epoch 32.981), train_loss = 1.48900214, grad/param norm = 4.7832e-01, time/batch = 0.1685s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
1782/2700 (epoch 33.000), train_loss = 1.57292051, grad/param norm = 5.2549e-01, time/batch = 0.1544s	
1783/2700 (epoch 33.019), train_loss = 1.53516078, grad/param norm = 5.0460e-01, time/batch = 0.1584s	
1784/2700 (epoch 33.037), train_loss = 1.54350455, grad/param norm = 4.8777e-01, time/batch = 0.1621s	
1785/2700 (epoch 33.056), train_loss = 1.47506605, grad/param norm = 4.6561e-01, time/batch = 0.1585s	
1786/2700 (epoch 33.074), train_loss = 1.48424001, grad/param norm = 4.9677e-01, time/batch = 0.1552s	
1787/2700 (epoch 33.093), train_loss = 1.46345347, grad/param norm = 4.9484e-01, time/batch = 0.1581s	
1788/2700 (epoch 33.111), train_loss = 1.43277649, grad/param norm = 4.6797e-01, time/batch = 0.1412s	
1789/2700 (epoch 33.130), train_loss = 1.48888144, grad/param norm = 4.7301e-01, time/batch = 0.1528s	
1790/2700 (epoch 33.148), train_loss = 1.43630142, grad/param norm = 4.4310e-01, time/batch = 0.1460s	
1791/2700 (epoch 33.167), train_loss = 1.54455677, grad/param norm = 5.1998e-01, time/batch = 0.1815s	
1792/2700 (epoch 33.185), train_loss = 1.44533436, grad/param norm = 4.6801e-01, time/batch = 0.1828s	
1793/2700 (epoch 33.204), train_loss = 1.53261507, grad/param norm = 5.4339e-01, time/batch = 0.1835s	
1794/2700 (epoch 33.222), train_loss = 1.43799087, grad/param norm = 5.0654e-01, time/batch = 0.1863s	
1795/2700 (epoch 33.241), train_loss = 1.37929680, grad/param norm = 4.4871e-01, time/batch = 0.1834s	
1796/2700 (epoch 33.259), train_loss = 1.45209450, grad/param norm = 5.1419e-01, time/batch = 0.1744s	
1797/2700 (epoch 33.278), train_loss = 1.54378530, grad/param norm = 5.3699e-01, time/batch = 0.1582s	
1798/2700 (epoch 33.296), train_loss = 1.49294021, grad/param norm = 4.6209e-01, time/batch = 0.1825s	
1799/2700 (epoch 33.315), train_loss = 1.48238325, grad/param norm = 4.7875e-01, time/batch = 0.1817s	
1800/2700 (epoch 33.333), train_loss = 1.49923540, grad/param norm = 4.9010e-01, time/batch = 0.1640s	
1801/2700 (epoch 33.352), train_loss = 1.48326981, grad/param norm = 4.7934e-01, time/batch = 0.1714s	
1802/2700 (epoch 33.370), train_loss = 1.50467029, grad/param norm = 5.1863e-01, time/batch = 0.1701s	
1803/2700 (epoch 33.389), train_loss = 1.47259569, grad/param norm = 5.4396e-01, time/batch = 0.1652s	
1804/2700 (epoch 33.407), train_loss = 1.51948167, grad/param norm = 5.4592e-01, time/batch = 0.1643s	
1805/2700 (epoch 33.426), train_loss = 1.52551341, grad/param norm = 4.9554e-01, time/batch = 0.1643s	
1806/2700 (epoch 33.444), train_loss = 1.46581209, grad/param norm = 4.7040e-01, time/batch = 0.1650s	
1807/2700 (epoch 33.463), train_loss = 1.51105791, grad/param norm = 4.6215e-01, time/batch = 0.1571s	
1808/2700 (epoch 33.481), train_loss = 1.51931115, grad/param norm = 4.8726e-01, time/batch = 0.1744s	
1809/2700 (epoch 33.500), train_loss = 1.45994392, grad/param norm = 5.3848e-01, time/batch = 0.1659s	
1810/2700 (epoch 33.519), train_loss = 1.49988642, grad/param norm = 4.9207e-01, time/batch = 0.1585s	
1811/2700 (epoch 33.537), train_loss = 1.52002618, grad/param norm = 4.7216e-01, time/batch = 0.1421s	
1812/2700 (epoch 33.556), train_loss = 1.43005693, grad/param norm = 4.8024e-01, time/batch = 0.1479s	
1813/2700 (epoch 33.574), train_loss = 1.43877662, grad/param norm = 5.3565e-01, time/batch = 0.1462s	
1814/2700 (epoch 33.593), train_loss = 1.45123239, grad/param norm = 5.0259e-01, time/batch = 0.1542s	
1815/2700 (epoch 33.611), train_loss = 1.40411764, grad/param norm = 4.4611e-01, time/batch = 0.1613s	
1816/2700 (epoch 33.630), train_loss = 1.42707479, grad/param norm = 4.5019e-01, time/batch = 0.1507s	
1817/2700 (epoch 33.648), train_loss = 1.46013135, grad/param norm = 4.6248e-01, time/batch = 0.1612s	
1818/2700 (epoch 33.667), train_loss = 1.43561669, grad/param norm = 5.0626e-01, time/batch = 0.1799s	
1819/2700 (epoch 33.685), train_loss = 1.48513764, grad/param norm = 5.2045e-01, time/batch = 0.1646s	
1820/2700 (epoch 33.704), train_loss = 1.50978420, grad/param norm = 5.1851e-01, time/batch = 0.1570s	
1821/2700 (epoch 33.722), train_loss = 1.46831954, grad/param norm = 4.4901e-01, time/batch = 0.1641s	
1822/2700 (epoch 33.741), train_loss = 1.46619147, grad/param norm = 4.6737e-01, time/batch = 0.1847s	
1823/2700 (epoch 33.759), train_loss = 1.48106834, grad/param norm = 5.0136e-01, time/batch = 0.1838s	
1824/2700 (epoch 33.778), train_loss = 1.51328088, grad/param norm = 5.1617e-01, time/batch = 0.1834s	
1825/2700 (epoch 33.796), train_loss = 1.47327758, grad/param norm = 4.8173e-01, time/batch = 0.1809s	
1826/2700 (epoch 33.815), train_loss = 1.50486430, grad/param norm = 4.8444e-01, time/batch = 0.1741s	
1827/2700 (epoch 33.833), train_loss = 1.46514393, grad/param norm = 5.0647e-01, time/batch = 0.1822s	
1828/2700 (epoch 33.852), train_loss = 1.45179551, grad/param norm = 4.8742e-01, time/batch = 0.1835s	
1829/2700 (epoch 33.870), train_loss = 1.47114118, grad/param norm = 4.6809e-01, time/batch = 0.1806s	
1830/2700 (epoch 33.889), train_loss = 1.47673802, grad/param norm = 4.7161e-01, time/batch = 0.1809s	
1831/2700 (epoch 33.907), train_loss = 1.57656382, grad/param norm = 5.1670e-01, time/batch = 0.1634s	
1832/2700 (epoch 33.926), train_loss = 1.49725437, grad/param norm = 4.7292e-01, time/batch = 0.1767s	
1833/2700 (epoch 33.944), train_loss = 1.47878020, grad/param norm = 4.8491e-01, time/batch = 0.1701s	
1834/2700 (epoch 33.963), train_loss = 1.50457456, grad/param norm = 5.0700e-01, time/batch = 0.1532s	
1835/2700 (epoch 33.981), train_loss = 1.47950008, grad/param norm = 4.8345e-01, time/batch = 0.1581s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
1836/2700 (epoch 34.000), train_loss = 1.56365290, grad/param norm = 5.3087e-01, time/batch = 0.1331s	
1837/2700 (epoch 34.019), train_loss = 1.52610345, grad/param norm = 5.0495e-01, time/batch = 0.1537s	
1838/2700 (epoch 34.037), train_loss = 1.53385313, grad/param norm = 4.9204e-01, time/batch = 0.1775s	
1839/2700 (epoch 34.056), train_loss = 1.46667764, grad/param norm = 4.6917e-01, time/batch = 0.1821s	
1840/2700 (epoch 34.074), train_loss = 1.47645804, grad/param norm = 5.0427e-01, time/batch = 0.1822s	
1841/2700 (epoch 34.093), train_loss = 1.45463186, grad/param norm = 5.0462e-01, time/batch = 0.1637s	
1842/2700 (epoch 34.111), train_loss = 1.42384941, grad/param norm = 4.7133e-01, time/batch = 0.1538s	
1843/2700 (epoch 34.130), train_loss = 1.47989626, grad/param norm = 4.7482e-01, time/batch = 0.1675s	
1844/2700 (epoch 34.148), train_loss = 1.42801124, grad/param norm = 4.4460e-01, time/batch = 0.1658s	
1845/2700 (epoch 34.167), train_loss = 1.53625258, grad/param norm = 5.1871e-01, time/batch = 0.1747s	
1846/2700 (epoch 34.185), train_loss = 1.43574570, grad/param norm = 4.5993e-01, time/batch = 0.1513s	
1847/2700 (epoch 34.204), train_loss = 1.52391865, grad/param norm = 5.3576e-01, time/batch = 0.1646s	
1848/2700 (epoch 34.222), train_loss = 1.42873710, grad/param norm = 5.0049e-01, time/batch = 0.1568s	
1849/2700 (epoch 34.241), train_loss = 1.37211888, grad/param norm = 4.5284e-01, time/batch = 0.1593s	
1850/2700 (epoch 34.259), train_loss = 1.44464765, grad/param norm = 5.2726e-01, time/batch = 0.1630s	
1851/2700 (epoch 34.278), train_loss = 1.53515718, grad/param norm = 5.3664e-01, time/batch = 0.1717s	
1852/2700 (epoch 34.296), train_loss = 1.48442448, grad/param norm = 4.6244e-01, time/batch = 0.1699s	
1853/2700 (epoch 34.315), train_loss = 1.47331484, grad/param norm = 4.7807e-01, time/batch = 0.1444s	
1854/2700 (epoch 34.333), train_loss = 1.49109337, grad/param norm = 4.9433e-01, time/batch = 0.1348s	
1855/2700 (epoch 34.352), train_loss = 1.47468995, grad/param norm = 4.8177e-01, time/batch = 0.1509s	
1856/2700 (epoch 34.370), train_loss = 1.49591524, grad/param norm = 5.2561e-01, time/batch = 0.1505s	
1857/2700 (epoch 34.389), train_loss = 1.46359587, grad/param norm = 5.3629e-01, time/batch = 0.1581s	
1858/2700 (epoch 34.407), train_loss = 1.51034859, grad/param norm = 5.3441e-01, time/batch = 0.1629s	
1859/2700 (epoch 34.426), train_loss = 1.51648398, grad/param norm = 4.9273e-01, time/batch = 0.1635s	
1860/2700 (epoch 34.444), train_loss = 1.45839071, grad/param norm = 4.7355e-01, time/batch = 0.1662s	
1861/2700 (epoch 34.463), train_loss = 1.50216626, grad/param norm = 4.6430e-01, time/batch = 0.1623s	
1862/2700 (epoch 34.481), train_loss = 1.51056153, grad/param norm = 4.8950e-01, time/batch = 0.1685s	
1863/2700 (epoch 34.500), train_loss = 1.45054021, grad/param norm = 5.3815e-01, time/batch = 0.1581s	
1864/2700 (epoch 34.519), train_loss = 1.49170776, grad/param norm = 4.9040e-01, time/batch = 0.1794s	
1865/2700 (epoch 34.537), train_loss = 1.51105501, grad/param norm = 4.7307e-01, time/batch = 0.1791s	
1866/2700 (epoch 34.556), train_loss = 1.42152642, grad/param norm = 4.7985e-01, time/batch = 0.1800s	
1867/2700 (epoch 34.574), train_loss = 1.42953258, grad/param norm = 5.3449e-01, time/batch = 0.1815s	
1868/2700 (epoch 34.593), train_loss = 1.44177220, grad/param norm = 4.9875e-01, time/batch = 0.1786s	
1869/2700 (epoch 34.611), train_loss = 1.39680576, grad/param norm = 4.5179e-01, time/batch = 0.1812s	
1870/2700 (epoch 34.630), train_loss = 1.41830174, grad/param norm = 4.5208e-01, time/batch = 0.1814s	
1871/2700 (epoch 34.648), train_loss = 1.45162322, grad/param norm = 4.6700e-01, time/batch = 0.1838s	
1872/2700 (epoch 34.667), train_loss = 1.42726587, grad/param norm = 5.1007e-01, time/batch = 0.1821s	
1873/2700 (epoch 34.685), train_loss = 1.47672170, grad/param norm = 5.2182e-01, time/batch = 0.1690s	
1874/2700 (epoch 34.704), train_loss = 1.50177827, grad/param norm = 5.1950e-01, time/batch = 0.1763s	
1875/2700 (epoch 34.722), train_loss = 1.46097054, grad/param norm = 4.5622e-01, time/batch = 0.1659s	
1876/2700 (epoch 34.741), train_loss = 1.45731883, grad/param norm = 4.6921e-01, time/batch = 0.1829s	
1877/2700 (epoch 34.759), train_loss = 1.47268383, grad/param norm = 5.0491e-01, time/batch = 0.1840s	
1878/2700 (epoch 34.778), train_loss = 1.50410833, grad/param norm = 5.1512e-01, time/batch = 0.1815s	
1879/2700 (epoch 34.796), train_loss = 1.46381243, grad/param norm = 4.7948e-01, time/batch = 0.1837s	
1880/2700 (epoch 34.815), train_loss = 1.49629256, grad/param norm = 4.9014e-01, time/batch = 0.1826s	
1881/2700 (epoch 34.833), train_loss = 1.45681654, grad/param norm = 5.0862e-01, time/batch = 0.1712s	
1882/2700 (epoch 34.852), train_loss = 1.44296351, grad/param norm = 4.8663e-01, time/batch = 0.1597s	
1883/2700 (epoch 34.870), train_loss = 1.46245725, grad/param norm = 4.6893e-01, time/batch = 0.1397s	
1884/2700 (epoch 34.889), train_loss = 1.46852757, grad/param norm = 4.7940e-01, time/batch = 0.1561s	
1885/2700 (epoch 34.907), train_loss = 1.56646071, grad/param norm = 5.2104e-01, time/batch = 0.1357s	
1886/2700 (epoch 34.926), train_loss = 1.48830119, grad/param norm = 4.7216e-01, time/batch = 0.1583s	
1887/2700 (epoch 34.944), train_loss = 1.47042297, grad/param norm = 4.8917e-01, time/batch = 0.1614s	
1888/2700 (epoch 34.963), train_loss = 1.49440671, grad/param norm = 5.0524e-01, time/batch = 0.1663s	
1889/2700 (epoch 34.981), train_loss = 1.47034207, grad/param norm = 4.8831e-01, time/batch = 0.1690s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
1890/2700 (epoch 35.000), train_loss = 1.55454619, grad/param norm = 5.3462e-01, time/batch = 0.1745s	
1891/2700 (epoch 35.019), train_loss = 1.51768778, grad/param norm = 5.0459e-01, time/batch = 0.1467s	
1892/2700 (epoch 35.037), train_loss = 1.52468938, grad/param norm = 4.9312e-01, time/batch = 0.1525s	
1893/2700 (epoch 35.056), train_loss = 1.45888332, grad/param norm = 4.7184e-01, time/batch = 0.1454s	
1894/2700 (epoch 35.074), train_loss = 1.46942532, grad/param norm = 5.0692e-01, time/batch = 0.1371s	
1895/2700 (epoch 35.093), train_loss = 1.44526596, grad/param norm = 4.9588e-01, time/batch = 0.1512s	
1896/2700 (epoch 35.111), train_loss = 1.41538732, grad/param norm = 4.7605e-01, time/batch = 0.1804s	
1897/2700 (epoch 35.130), train_loss = 1.47123117, grad/param norm = 4.7583e-01, time/batch = 0.1828s	
1898/2700 (epoch 35.148), train_loss = 1.42001931, grad/param norm = 4.4664e-01, time/batch = 0.1815s	
1899/2700 (epoch 35.167), train_loss = 1.52872511, grad/param norm = 5.2750e-01, time/batch = 0.1817s	
1900/2700 (epoch 35.185), train_loss = 1.42703824, grad/param norm = 4.6044e-01, time/batch = 0.1782s	
1901/2700 (epoch 35.204), train_loss = 1.51589436, grad/param norm = 5.3177e-01, time/batch = 0.1713s	
1902/2700 (epoch 35.222), train_loss = 1.42017137, grad/param norm = 4.9853e-01, time/batch = 0.1601s	
1903/2700 (epoch 35.241), train_loss = 1.36526108, grad/param norm = 4.5720e-01, time/batch = 0.1640s	
1904/2700 (epoch 35.259), train_loss = 1.43716797, grad/param norm = 5.3184e-01, time/batch = 0.1616s	
1905/2700 (epoch 35.278), train_loss = 1.52657913, grad/param norm = 5.3210e-01, time/batch = 0.1367s	
1906/2700 (epoch 35.296), train_loss = 1.47617143, grad/param norm = 4.6256e-01, time/batch = 0.1566s	
1907/2700 (epoch 35.315), train_loss = 1.46472048, grad/param norm = 4.7928e-01, time/batch = 0.1619s	
1908/2700 (epoch 35.333), train_loss = 1.48328900, grad/param norm = 4.9956e-01, time/batch = 0.1654s	
1909/2700 (epoch 35.352), train_loss = 1.46660787, grad/param norm = 4.8446e-01, time/batch = 0.1682s	
1910/2700 (epoch 35.370), train_loss = 1.48758514, grad/param norm = 5.3076e-01, time/batch = 0.1702s	
1911/2700 (epoch 35.389), train_loss = 1.45474092, grad/param norm = 5.2883e-01, time/batch = 0.1625s	
1912/2700 (epoch 35.407), train_loss = 1.50161191, grad/param norm = 5.2601e-01, time/batch = 0.1362s	
1913/2700 (epoch 35.426), train_loss = 1.50781652, grad/param norm = 4.9185e-01, time/batch = 0.1487s	
1914/2700 (epoch 35.444), train_loss = 1.45119049, grad/param norm = 4.7552e-01, time/batch = 0.1484s	
1915/2700 (epoch 35.463), train_loss = 1.49360393, grad/param norm = 4.6570e-01, time/batch = 0.1281s	
1916/2700 (epoch 35.481), train_loss = 1.50210166, grad/param norm = 4.9050e-01, time/batch = 0.1820s	
1917/2700 (epoch 35.500), train_loss = 1.44137902, grad/param norm = 5.3592e-01, time/batch = 0.1804s	
1918/2700 (epoch 35.519), train_loss = 1.48388777, grad/param norm = 4.8988e-01, time/batch = 0.1804s	
1919/2700 (epoch 35.537), train_loss = 1.50254684, grad/param norm = 4.7641e-01, time/batch = 0.1794s	
1920/2700 (epoch 35.556), train_loss = 1.41333748, grad/param norm = 4.8022e-01, time/batch = 0.1821s	
1921/2700 (epoch 35.574), train_loss = 1.42077825, grad/param norm = 5.3356e-01, time/batch = 0.1555s	
1922/2700 (epoch 35.593), train_loss = 1.43274226, grad/param norm = 4.9675e-01, time/batch = 0.1445s	
1923/2700 (epoch 35.611), train_loss = 1.38981987, grad/param norm = 4.5752e-01, time/batch = 0.1679s	
1924/2700 (epoch 35.630), train_loss = 1.40981089, grad/param norm = 4.5404e-01, time/batch = 0.1669s	
1925/2700 (epoch 35.648), train_loss = 1.44338068, grad/param norm = 4.7051e-01, time/batch = 0.1610s	
1926/2700 (epoch 35.667), train_loss = 1.41921553, grad/param norm = 5.1350e-01, time/batch = 0.1569s	
1927/2700 (epoch 35.685), train_loss = 1.46872737, grad/param norm = 5.2321e-01, time/batch = 0.1599s	
1928/2700 (epoch 35.704), train_loss = 1.49400437, grad/param norm = 5.2075e-01, time/batch = 0.1468s	
1929/2700 (epoch 35.722), train_loss = 1.45380385, grad/param norm = 4.6305e-01, time/batch = 0.1470s	
1930/2700 (epoch 35.741), train_loss = 1.44881953, grad/param norm = 4.7125e-01, time/batch = 0.1561s	
1931/2700 (epoch 35.759), train_loss = 1.46450588, grad/param norm = 5.0769e-01, time/batch = 0.1599s	
1932/2700 (epoch 35.778), train_loss = 1.49518062, grad/param norm = 5.1354e-01, time/batch = 0.1595s	
1933/2700 (epoch 35.796), train_loss = 1.45474113, grad/param norm = 4.7889e-01, time/batch = 0.1652s	
1934/2700 (epoch 35.815), train_loss = 1.48808322, grad/param norm = 4.9657e-01, time/batch = 0.1622s	
1935/2700 (epoch 35.833), train_loss = 1.44873751, grad/param norm = 5.1001e-01, time/batch = 0.1671s	
1936/2700 (epoch 35.852), train_loss = 1.43444995, grad/param norm = 4.8662e-01, time/batch = 0.1522s	
1937/2700 (epoch 35.870), train_loss = 1.45410828, grad/param norm = 4.7062e-01, time/batch = 0.1830s	
1938/2700 (epoch 35.889), train_loss = 1.46063594, grad/param norm = 4.8491e-01, time/batch = 0.1845s	
1939/2700 (epoch 35.907), train_loss = 1.55648192, grad/param norm = 5.2087e-01, time/batch = 0.1851s	
1940/2700 (epoch 35.926), train_loss = 1.47955329, grad/param norm = 4.7012e-01, time/batch = 0.1831s	
1941/2700 (epoch 35.944), train_loss = 1.46244629, grad/param norm = 4.9432e-01, time/batch = 0.1738s	
1942/2700 (epoch 35.963), train_loss = 1.48472529, grad/param norm = 5.0384e-01, time/batch = 0.1758s	
1943/2700 (epoch 35.981), train_loss = 1.46151581, grad/param norm = 4.9260e-01, time/batch = 0.1612s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
1944/2700 (epoch 36.000), train_loss = 1.54568991, grad/param norm = 5.3786e-01, time/batch = 0.1434s	
1945/2700 (epoch 36.019), train_loss = 1.50919459, grad/param norm = 5.0607e-01, time/batch = 0.1739s	
1946/2700 (epoch 36.037), train_loss = 1.51581892, grad/param norm = 5.0335e-01, time/batch = 0.1653s	
1947/2700 (epoch 36.056), train_loss = 1.45119537, grad/param norm = 4.7847e-01, time/batch = 0.1650s	
1948/2700 (epoch 36.074), train_loss = 1.46204706, grad/param norm = 5.1310e-01, time/batch = 0.1660s	
1949/2700 (epoch 36.093), train_loss = 1.43720776, grad/param norm = 5.0272e-01, time/batch = 0.1573s	
1950/2700 (epoch 36.111), train_loss = 1.40711776, grad/param norm = 4.7669e-01, time/batch = 0.1616s	
1951/2700 (epoch 36.130), train_loss = 1.46278729, grad/param norm = 4.7690e-01, time/batch = 0.1759s	
1952/2700 (epoch 36.148), train_loss = 1.41223778, grad/param norm = 4.4991e-01, time/batch = 0.1715s	
1953/2700 (epoch 36.167), train_loss = 1.52092123, grad/param norm = 5.2465e-01, time/batch = 0.1676s	
1954/2700 (epoch 36.185), train_loss = 1.41828994, grad/param norm = 4.5381e-01, time/batch = 0.1509s	
1955/2700 (epoch 36.204), train_loss = 1.50789274, grad/param norm = 5.2728e-01, time/batch = 0.1678s	
1956/2700 (epoch 36.222), train_loss = 1.41188731, grad/param norm = 4.9682e-01, time/batch = 0.1627s	
1957/2700 (epoch 36.241), train_loss = 1.35877132, grad/param norm = 4.6351e-01, time/batch = 0.1476s	
1958/2700 (epoch 36.259), train_loss = 1.42988080, grad/param norm = 5.3753e-01, time/batch = 0.1841s	
1959/2700 (epoch 36.278), train_loss = 1.51824611, grad/param norm = 5.2928e-01, time/batch = 0.1838s	
1960/2700 (epoch 36.296), train_loss = 1.46818082, grad/param norm = 4.6368e-01, time/batch = 0.1818s	
1961/2700 (epoch 36.315), train_loss = 1.45642019, grad/param norm = 4.8055e-01, time/batch = 0.1646s	
1962/2700 (epoch 36.333), train_loss = 1.47570539, grad/param norm = 5.0226e-01, time/batch = 0.1545s	
1963/2700 (epoch 36.352), train_loss = 1.45889055, grad/param norm = 4.8602e-01, time/batch = 0.1616s	
1964/2700 (epoch 36.370), train_loss = 1.47950179, grad/param norm = 5.3837e-01, time/batch = 0.1541s	
1965/2700 (epoch 36.389), train_loss = 1.44610480, grad/param norm = 5.2201e-01, time/batch = 0.1786s	
1966/2700 (epoch 36.407), train_loss = 1.49304828, grad/param norm = 5.1801e-01, time/batch = 0.1832s	
1967/2700 (epoch 36.426), train_loss = 1.49947011, grad/param norm = 4.9188e-01, time/batch = 0.1722s	
1968/2700 (epoch 36.444), train_loss = 1.44430500, grad/param norm = 4.7717e-01, time/batch = 0.1830s	
1969/2700 (epoch 36.463), train_loss = 1.48533810, grad/param norm = 4.6740e-01, time/batch = 0.1739s	
1970/2700 (epoch 36.481), train_loss = 1.49396392, grad/param norm = 4.9147e-01, time/batch = 0.1711s	
1971/2700 (epoch 36.500), train_loss = 1.43264139, grad/param norm = 5.3390e-01, time/batch = 0.1850s	
1972/2700 (epoch 36.519), train_loss = 1.47636078, grad/param norm = 4.8934e-01, time/batch = 0.1832s	
1973/2700 (epoch 36.537), train_loss = 1.49433156, grad/param norm = 4.7944e-01, time/batch = 0.1751s	
1974/2700 (epoch 36.556), train_loss = 1.40544449, grad/param norm = 4.8036e-01, time/batch = 0.1798s	
1975/2700 (epoch 36.574), train_loss = 1.41248641, grad/param norm = 5.3371e-01, time/batch = 0.1818s	
1976/2700 (epoch 36.593), train_loss = 1.42429542, grad/param norm = 4.9580e-01, time/batch = 0.1734s	
1977/2700 (epoch 36.611), train_loss = 1.38304490, grad/param norm = 4.6236e-01, time/batch = 0.1590s	
1978/2700 (epoch 36.630), train_loss = 1.40165648, grad/param norm = 4.5662e-01, time/batch = 0.1683s	
1979/2700 (epoch 36.648), train_loss = 1.43538006, grad/param norm = 4.7407e-01, time/batch = 0.1498s	
1980/2700 (epoch 36.667), train_loss = 1.41156207, grad/param norm = 5.1632e-01, time/batch = 0.1620s	
1981/2700 (epoch 36.685), train_loss = 1.46116334, grad/param norm = 5.2439e-01, time/batch = 0.1775s	
1982/2700 (epoch 36.704), train_loss = 1.48649596, grad/param norm = 5.2258e-01, time/batch = 0.1773s	
1983/2700 (epoch 36.722), train_loss = 1.44678408, grad/param norm = 4.6970e-01, time/batch = 0.1740s	
1984/2700 (epoch 36.741), train_loss = 1.44071533, grad/param norm = 4.7365e-01, time/batch = 0.1810s	
1985/2700 (epoch 36.759), train_loss = 1.45662552, grad/param norm = 5.1071e-01, time/batch = 0.1781s	
1986/2700 (epoch 36.778), train_loss = 1.48670470, grad/param norm = 5.1310e-01, time/batch = 0.1714s	
1987/2700 (epoch 36.796), train_loss = 1.44606545, grad/param norm = 4.7934e-01, time/batch = 0.1640s	
1988/2700 (epoch 36.815), train_loss = 1.48024403, grad/param norm = 5.0268e-01, time/batch = 0.1388s	
1989/2700 (epoch 36.833), train_loss = 1.44092369, grad/param norm = 5.1084e-01, time/batch = 0.1823s	
1990/2700 (epoch 36.852), train_loss = 1.42627849, grad/param norm = 4.8648e-01, time/batch = 0.1818s	
1991/2700 (epoch 36.870), train_loss = 1.44609251, grad/param norm = 4.7250e-01, time/batch = 0.1769s	
1992/2700 (epoch 36.889), train_loss = 1.45303355, grad/param norm = 4.9106e-01, time/batch = 0.1715s	
1993/2700 (epoch 36.907), train_loss = 1.54702157, grad/param norm = 5.2205e-01, time/batch = 0.1589s	
1994/2700 (epoch 36.926), train_loss = 1.47124923, grad/param norm = 4.6976e-01, time/batch = 0.1851s	
1995/2700 (epoch 36.944), train_loss = 1.45486569, grad/param norm = 4.9904e-01, time/batch = 0.1838s	
1996/2700 (epoch 36.963), train_loss = 1.47547370, grad/param norm = 5.0220e-01, time/batch = 0.1841s	
1997/2700 (epoch 36.981), train_loss = 1.45301427, grad/param norm = 4.9656e-01, time/batch = 0.1746s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
1998/2700 (epoch 37.000), train_loss = 1.53709622, grad/param norm = 5.4008e-01, time/batch = 0.1356s	
1999/2700 (epoch 37.019), train_loss = 1.50140439, grad/param norm = 5.0665e-01, time/batch = 0.1581s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch37.04_1.7361.t7	
2000/2700 (epoch 37.037), train_loss = 1.50729669, grad/param norm = 5.0329e-01, time/batch = 0.1490s	
2001/2700 (epoch 37.056), train_loss = 1.55803073, grad/param norm = 4.8949e-01, time/batch = 0.1462s	
2002/2700 (epoch 37.074), train_loss = 1.45484153, grad/param norm = 4.9739e-01, time/batch = 0.1439s	
2003/2700 (epoch 37.093), train_loss = 1.42879379, grad/param norm = 4.8224e-01, time/batch = 0.1492s	
2004/2700 (epoch 37.111), train_loss = 1.39980676, grad/param norm = 4.8649e-01, time/batch = 0.1593s	
2005/2700 (epoch 37.130), train_loss = 1.45542385, grad/param norm = 4.7952e-01, time/batch = 0.1548s	
2006/2700 (epoch 37.148), train_loss = 1.40496440, grad/param norm = 4.5349e-01, time/batch = 0.1425s	
2007/2700 (epoch 37.167), train_loss = 1.51470745, grad/param norm = 5.3724e-01, time/batch = 0.1640s	
2008/2700 (epoch 37.185), train_loss = 1.41055799, grad/param norm = 4.5827e-01, time/batch = 0.1661s	
2009/2700 (epoch 37.204), train_loss = 1.50103078, grad/param norm = 5.2941e-01, time/batch = 0.1638s	
2010/2700 (epoch 37.222), train_loss = 1.40468756, grad/param norm = 4.9842e-01, time/batch = 0.1461s	
2011/2700 (epoch 37.241), train_loss = 1.35231825, grad/param norm = 4.6769e-01, time/batch = 0.1828s	
2012/2700 (epoch 37.259), train_loss = 1.42272944, grad/param norm = 5.3573e-01, time/batch = 0.1843s	
2013/2700 (epoch 37.278), train_loss = 1.51033545, grad/param norm = 5.2497e-01, time/batch = 0.1821s	
2014/2700 (epoch 37.296), train_loss = 1.46038090, grad/param norm = 4.6500e-01, time/batch = 0.1799s	
2015/2700 (epoch 37.315), train_loss = 1.44838054, grad/param norm = 4.8355e-01, time/batch = 0.1823s	
2016/2700 (epoch 37.333), train_loss = 1.46858866, grad/param norm = 5.0509e-01, time/batch = 0.1742s	
2017/2700 (epoch 37.352), train_loss = 1.45134971, grad/param norm = 4.8707e-01, time/batch = 0.1671s	
2018/2700 (epoch 37.370), train_loss = 1.47193609, grad/param norm = 5.4227e-01, time/batch = 0.1563s	
2019/2700 (epoch 37.389), train_loss = 1.43755083, grad/param norm = 5.1676e-01, time/batch = 0.1432s	
2020/2700 (epoch 37.407), train_loss = 1.48466832, grad/param norm = 5.1170e-01, time/batch = 0.1563s	
2021/2700 (epoch 37.426), train_loss = 1.49150286, grad/param norm = 4.9190e-01, time/batch = 0.1805s	
2022/2700 (epoch 37.444), train_loss = 1.43756007, grad/param norm = 4.7746e-01, time/batch = 0.1802s	
2023/2700 (epoch 37.463), train_loss = 1.47734214, grad/param norm = 4.6811e-01, time/batch = 0.1711s	
2024/2700 (epoch 37.481), train_loss = 1.48617218, grad/param norm = 4.9065e-01, time/batch = 0.1647s	
2025/2700 (epoch 37.500), train_loss = 1.42418778, grad/param norm = 5.3166e-01, time/batch = 0.1558s	
2026/2700 (epoch 37.519), train_loss = 1.46930122, grad/param norm = 4.9024e-01, time/batch = 0.1483s	
2027/2700 (epoch 37.537), train_loss = 1.48611009, grad/param norm = 4.8199e-01, time/batch = 0.1249s	
2028/2700 (epoch 37.556), train_loss = 1.39784017, grad/param norm = 4.8105e-01, time/batch = 0.1688s	
2029/2700 (epoch 37.574), train_loss = 1.40478951, grad/param norm = 5.3444e-01, time/batch = 0.1607s	
2030/2700 (epoch 37.593), train_loss = 1.41614873, grad/param norm = 4.9667e-01, time/batch = 0.1806s	
2031/2700 (epoch 37.611), train_loss = 1.37641848, grad/param norm = 4.6587e-01, time/batch = 0.1685s	
2032/2700 (epoch 37.630), train_loss = 1.39385236, grad/param norm = 4.5938e-01, time/batch = 0.1656s	
2033/2700 (epoch 37.648), train_loss = 1.42747527, grad/param norm = 4.7579e-01, time/batch = 0.1592s	
2034/2700 (epoch 37.667), train_loss = 1.40426820, grad/param norm = 5.1878e-01, time/batch = 0.1688s	
2035/2700 (epoch 37.685), train_loss = 1.45384935, grad/param norm = 5.2666e-01, time/batch = 0.1721s	
2036/2700 (epoch 37.704), train_loss = 1.47921136, grad/param norm = 5.2481e-01, time/batch = 0.1691s	
2037/2700 (epoch 37.722), train_loss = 1.43960360, grad/param norm = 4.7623e-01, time/batch = 0.1652s	
2038/2700 (epoch 37.741), train_loss = 1.43299071, grad/param norm = 4.7624e-01, time/batch = 0.1577s	
2039/2700 (epoch 37.759), train_loss = 1.44885409, grad/param norm = 5.1185e-01, time/batch = 0.1373s	
2040/2700 (epoch 37.778), train_loss = 1.47833737, grad/param norm = 5.1195e-01, time/batch = 0.1595s	
2041/2700 (epoch 37.796), train_loss = 1.43782655, grad/param norm = 4.8163e-01, time/batch = 0.1609s	
2042/2700 (epoch 37.815), train_loss = 1.47264952, grad/param norm = 5.0845e-01, time/batch = 0.1493s	
2043/2700 (epoch 37.833), train_loss = 1.43320330, grad/param norm = 5.1120e-01, time/batch = 0.1256s	
2044/2700 (epoch 37.852), train_loss = 1.41839858, grad/param norm = 4.8756e-01, time/batch = 0.1422s	
2045/2700 (epoch 37.870), train_loss = 1.43843459, grad/param norm = 4.7543e-01, time/batch = 0.1478s	
2046/2700 (epoch 37.889), train_loss = 1.44556442, grad/param norm = 4.9431e-01, time/batch = 0.1567s	
2047/2700 (epoch 37.907), train_loss = 1.53783348, grad/param norm = 5.2047e-01, time/batch = 0.1570s	
2048/2700 (epoch 37.926), train_loss = 1.46321623, grad/param norm = 4.6896e-01, time/batch = 0.1540s	
2049/2700 (epoch 37.944), train_loss = 1.44757426, grad/param norm = 5.0308e-01, time/batch = 0.1580s	
2050/2700 (epoch 37.963), train_loss = 1.46668498, grad/param norm = 5.0082e-01, time/batch = 0.1811s	
2051/2700 (epoch 37.981), train_loss = 1.44504326, grad/param norm = 4.9962e-01, time/batch = 0.1635s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2052/2700 (epoch 38.000), train_loss = 1.52883853, grad/param norm = 5.4107e-01, time/batch = 0.1553s	
2053/2700 (epoch 38.019), train_loss = 1.49335067, grad/param norm = 5.0971e-01, time/batch = 0.1473s	
2054/2700 (epoch 38.037), train_loss = 1.49906302, grad/param norm = 5.1621e-01, time/batch = 0.1692s	
2055/2700 (epoch 38.056), train_loss = 1.43827902, grad/param norm = 4.8368e-01, time/batch = 0.1696s	
2056/2700 (epoch 38.074), train_loss = 1.44840457, grad/param norm = 5.1547e-01, time/batch = 0.1690s	
2057/2700 (epoch 38.093), train_loss = 1.42156986, grad/param norm = 5.0177e-01, time/batch = 0.1691s	
2058/2700 (epoch 38.111), train_loss = 1.39155729, grad/param norm = 4.7760e-01, time/batch = 0.1677s	
2059/2700 (epoch 38.130), train_loss = 1.44709111, grad/param norm = 4.8291e-01, time/batch = 0.1376s	
2060/2700 (epoch 38.148), train_loss = 1.39732778, grad/param norm = 4.5863e-01, time/batch = 0.1585s	
2061/2700 (epoch 38.167), train_loss = 1.50644674, grad/param norm = 5.2325e-01, time/batch = 0.1647s	
2062/2700 (epoch 38.185), train_loss = 1.40242984, grad/param norm = 4.4928e-01, time/batch = 0.1520s	
2063/2700 (epoch 38.204), train_loss = 1.49310877, grad/param norm = 5.2231e-01, time/batch = 0.1285s	
2064/2700 (epoch 38.222), train_loss = 1.39681559, grad/param norm = 4.9742e-01, time/batch = 0.1423s	
2065/2700 (epoch 38.241), train_loss = 1.34652386, grad/param norm = 4.7628e-01, time/batch = 0.1444s	
2066/2700 (epoch 38.259), train_loss = 1.41570572, grad/param norm = 5.4061e-01, time/batch = 0.1509s	
2067/2700 (epoch 38.278), train_loss = 1.50242503, grad/param norm = 5.2210e-01, time/batch = 0.1574s	
2068/2700 (epoch 38.296), train_loss = 1.45286753, grad/param norm = 4.6646e-01, time/batch = 0.1636s	
2069/2700 (epoch 38.315), train_loss = 1.44067192, grad/param norm = 4.8512e-01, time/batch = 0.1432s	
2070/2700 (epoch 38.333), train_loss = 1.46128342, grad/param norm = 5.0487e-01, time/batch = 0.1783s	
2071/2700 (epoch 38.352), train_loss = 1.44457470, grad/param norm = 4.8888e-01, time/batch = 0.1716s	
2072/2700 (epoch 38.370), train_loss = 1.46436229, grad/param norm = 5.4985e-01, time/batch = 0.1699s	
2073/2700 (epoch 38.389), train_loss = 1.42928245, grad/param norm = 5.1027e-01, time/batch = 0.1599s	
2074/2700 (epoch 38.407), train_loss = 1.47675361, grad/param norm = 5.0658e-01, time/batch = 0.1819s	
2075/2700 (epoch 38.426), train_loss = 1.48362556, grad/param norm = 4.9398e-01, time/batch = 0.1824s	
2076/2700 (epoch 38.444), train_loss = 1.43116985, grad/param norm = 4.7815e-01, time/batch = 0.1837s	
2077/2700 (epoch 38.463), train_loss = 1.46973568, grad/param norm = 4.7078e-01, time/batch = 0.1818s	
2078/2700 (epoch 38.481), train_loss = 1.47846690, grad/param norm = 4.9153e-01, time/batch = 0.1701s	
2079/2700 (epoch 38.500), train_loss = 1.41627680, grad/param norm = 5.3236e-01, time/batch = 0.1685s	
2080/2700 (epoch 38.519), train_loss = 1.46222066, grad/param norm = 4.8976e-01, time/batch = 0.1559s	
2081/2700 (epoch 38.537), train_loss = 1.47880809, grad/param norm = 4.8566e-01, time/batch = 0.1836s	
2082/2700 (epoch 38.556), train_loss = 1.39040031, grad/param norm = 4.8093e-01, time/batch = 0.1795s	
2083/2700 (epoch 38.574), train_loss = 1.39717974, grad/param norm = 5.3514e-01, time/batch = 0.1830s	
2084/2700 (epoch 38.593), train_loss = 1.40863147, grad/param norm = 4.9678e-01, time/batch = 0.1838s	
2085/2700 (epoch 38.611), train_loss = 1.37020979, grad/param norm = 4.6999e-01, time/batch = 0.1834s	
2086/2700 (epoch 38.630), train_loss = 1.38631287, grad/param norm = 4.6271e-01, time/batch = 0.1825s	
2087/2700 (epoch 38.648), train_loss = 1.41998609, grad/param norm = 4.7825e-01, time/batch = 0.1790s	
2088/2700 (epoch 38.667), train_loss = 1.39717101, grad/param norm = 5.2111e-01, time/batch = 0.1527s	
2089/2700 (epoch 38.685), train_loss = 1.44712947, grad/param norm = 5.2843e-01, time/batch = 0.1671s	
2090/2700 (epoch 38.704), train_loss = 1.47216624, grad/param norm = 5.2733e-01, time/batch = 0.1587s	
2091/2700 (epoch 38.722), train_loss = 1.43302668, grad/param norm = 4.8180e-01, time/batch = 0.1719s	
2092/2700 (epoch 38.741), train_loss = 1.42563429, grad/param norm = 4.7947e-01, time/batch = 0.1748s	
2093/2700 (epoch 38.759), train_loss = 1.44145990, grad/param norm = 5.1476e-01, time/batch = 0.1690s	
2094/2700 (epoch 38.778), train_loss = 1.47059464, grad/param norm = 5.1358e-01, time/batch = 0.1654s	
2095/2700 (epoch 38.796), train_loss = 1.42983241, grad/param norm = 4.8353e-01, time/batch = 0.1642s	
2096/2700 (epoch 38.815), train_loss = 1.46544333, grad/param norm = 5.1322e-01, time/batch = 0.1666s	
2097/2700 (epoch 38.833), train_loss = 1.42579919, grad/param norm = 5.1017e-01, time/batch = 0.1660s	
2098/2700 (epoch 38.852), train_loss = 1.41080743, grad/param norm = 4.8769e-01, time/batch = 0.1454s	
2099/2700 (epoch 38.870), train_loss = 1.43102867, grad/param norm = 4.7733e-01, time/batch = 0.1616s	
2100/2700 (epoch 38.889), train_loss = 1.43863642, grad/param norm = 5.0012e-01, time/batch = 0.1458s	
2101/2700 (epoch 38.907), train_loss = 1.52924912, grad/param norm = 5.2141e-01, time/batch = 0.1610s	
2102/2700 (epoch 38.926), train_loss = 1.45557256, grad/param norm = 4.7009e-01, time/batch = 0.1673s	
2103/2700 (epoch 38.944), train_loss = 1.44055465, grad/param norm = 5.0756e-01, time/batch = 0.1652s	
2104/2700 (epoch 38.963), train_loss = 1.45831913, grad/param norm = 4.9946e-01, time/batch = 0.1639s	
2105/2700 (epoch 38.981), train_loss = 1.43713234, grad/param norm = 5.0308e-01, time/batch = 0.1656s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2106/2700 (epoch 39.000), train_loss = 1.52078633, grad/param norm = 5.4226e-01, time/batch = 0.1686s	
2107/2700 (epoch 39.019), train_loss = 1.48624317, grad/param norm = 5.1096e-01, time/batch = 0.1685s	
2108/2700 (epoch 39.037), train_loss = 1.49109197, grad/param norm = 5.1216e-01, time/batch = 0.1606s	
2109/2700 (epoch 39.056), train_loss = 1.43079865, grad/param norm = 4.7992e-01, time/batch = 0.1825s	
2110/2700 (epoch 39.074), train_loss = 1.44184010, grad/param norm = 5.1041e-01, time/batch = 0.1705s	
2111/2700 (epoch 39.093), train_loss = 1.41394086, grad/param norm = 4.9061e-01, time/batch = 0.1467s	
2112/2700 (epoch 39.111), train_loss = 1.38468169, grad/param norm = 4.8779e-01, time/batch = 0.1725s	
2113/2700 (epoch 39.130), train_loss = 1.43967207, grad/param norm = 4.8625e-01, time/batch = 0.1700s	
2114/2700 (epoch 39.148), train_loss = 1.39031578, grad/param norm = 4.5958e-01, time/batch = 0.1647s	
2115/2700 (epoch 39.167), train_loss = 1.49980733, grad/param norm = 5.3376e-01, time/batch = 0.1630s	
2116/2700 (epoch 39.185), train_loss = 1.39539299, grad/param norm = 4.5162e-01, time/batch = 0.1533s	
2117/2700 (epoch 39.204), train_loss = 1.48615247, grad/param norm = 5.2020e-01, time/batch = 0.1537s	
2118/2700 (epoch 39.222), train_loss = 1.38963988, grad/param norm = 5.0034e-01, time/batch = 0.1481s	
2119/2700 (epoch 39.241), train_loss = 1.34054470, grad/param norm = 4.7939e-01, time/batch = 0.1527s	
2120/2700 (epoch 39.259), train_loss = 1.40870602, grad/param norm = 5.3552e-01, time/batch = 0.1606s	
2121/2700 (epoch 39.278), train_loss = 1.49494321, grad/param norm = 5.1792e-01, time/batch = 0.1239s	
2122/2700 (epoch 39.296), train_loss = 1.44557397, grad/param norm = 4.6770e-01, time/batch = 0.1837s	
2123/2700 (epoch 39.315), train_loss = 1.43325509, grad/param norm = 4.8775e-01, time/batch = 0.1847s	
2124/2700 (epoch 39.333), train_loss = 1.45433255, grad/param norm = 5.0637e-01, time/batch = 0.1818s	
2125/2700 (epoch 39.352), train_loss = 1.43788265, grad/param norm = 4.9100e-01, time/batch = 0.1828s	
2126/2700 (epoch 39.370), train_loss = 1.45709434, grad/param norm = 5.5136e-01, time/batch = 0.1810s	
2127/2700 (epoch 39.389), train_loss = 1.42109099, grad/param norm = 5.0612e-01, time/batch = 0.1732s	
2128/2700 (epoch 39.407), train_loss = 1.46900790, grad/param norm = 5.0361e-01, time/batch = 0.1830s	
2129/2700 (epoch 39.426), train_loss = 1.47600520, grad/param norm = 4.9525e-01, time/batch = 0.1812s	
2130/2700 (epoch 39.444), train_loss = 1.42493095, grad/param norm = 4.7783e-01, time/batch = 0.1829s	
2131/2700 (epoch 39.463), train_loss = 1.46249617, grad/param norm = 4.7307e-01, time/batch = 0.1533s	
2132/2700 (epoch 39.481), train_loss = 1.47105893, grad/param norm = 4.9255e-01, time/batch = 0.1740s	
2133/2700 (epoch 39.500), train_loss = 1.40858252, grad/param norm = 5.3229e-01, time/batch = 0.1599s	
2134/2700 (epoch 39.519), train_loss = 1.45546242, grad/param norm = 4.9058e-01, time/batch = 0.1514s	
2135/2700 (epoch 39.537), train_loss = 1.47174677, grad/param norm = 4.9029e-01, time/batch = 0.1483s	
2136/2700 (epoch 39.556), train_loss = 1.38323951, grad/param norm = 4.8086e-01, time/batch = 0.1565s	
2137/2700 (epoch 39.574), train_loss = 1.38994306, grad/param norm = 5.3581e-01, time/batch = 0.1560s	
2138/2700 (epoch 39.593), train_loss = 1.40136794, grad/param norm = 4.9850e-01, time/batch = 0.1675s	
2139/2700 (epoch 39.611), train_loss = 1.36419118, grad/param norm = 4.7315e-01, time/batch = 0.1747s	
2140/2700 (epoch 39.630), train_loss = 1.37915890, grad/param norm = 4.6636e-01, time/batch = 0.1809s	
2141/2700 (epoch 39.648), train_loss = 1.41263466, grad/param norm = 4.7917e-01, time/batch = 0.1800s	
2142/2700 (epoch 39.667), train_loss = 1.39034406, grad/param norm = 5.2360e-01, time/batch = 0.1501s	
2143/2700 (epoch 39.685), train_loss = 1.44066362, grad/param norm = 5.3124e-01, time/batch = 0.1822s	
2144/2700 (epoch 39.704), train_loss = 1.46531668, grad/param norm = 5.3009e-01, time/batch = 0.1821s	
2145/2700 (epoch 39.722), train_loss = 1.42652916, grad/param norm = 4.8696e-01, time/batch = 0.1788s	
2146/2700 (epoch 39.741), train_loss = 1.41855739, grad/param norm = 4.8263e-01, time/batch = 0.1704s	
2147/2700 (epoch 39.759), train_loss = 1.43418873, grad/param norm = 5.1625e-01, time/batch = 0.1575s	
2148/2700 (epoch 39.778), train_loss = 1.46296305, grad/param norm = 5.1504e-01, time/batch = 0.1849s	
2149/2700 (epoch 39.796), train_loss = 1.42218550, grad/param norm = 4.8685e-01, time/batch = 0.1830s	
2150/2700 (epoch 39.815), train_loss = 1.45843915, grad/param norm = 5.1743e-01, time/batch = 0.1781s	
2151/2700 (epoch 39.833), train_loss = 1.41850691, grad/param norm = 5.0861e-01, time/batch = 0.1691s	
2152/2700 (epoch 39.852), train_loss = 1.40340423, grad/param norm = 4.8864e-01, time/batch = 0.1513s	
2153/2700 (epoch 39.870), train_loss = 1.42387609, grad/param norm = 4.7961e-01, time/batch = 0.1695s	
2154/2700 (epoch 39.889), train_loss = 1.43191409, grad/param norm = 5.0267e-01, time/batch = 0.1715s	
2155/2700 (epoch 39.907), train_loss = 1.52090521, grad/param norm = 5.1956e-01, time/batch = 0.1734s	
2156/2700 (epoch 39.926), train_loss = 1.44814978, grad/param norm = 4.7094e-01, time/batch = 0.1704s	
2157/2700 (epoch 39.944), train_loss = 1.43372889, grad/param norm = 5.1178e-01, time/batch = 0.1556s	
2158/2700 (epoch 39.963), train_loss = 1.45039627, grad/param norm = 4.9845e-01, time/batch = 0.1522s	
2159/2700 (epoch 39.981), train_loss = 1.42955982, grad/param norm = 5.0590e-01, time/batch = 0.1577s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2160/2700 (epoch 40.000), train_loss = 1.51303336, grad/param norm = 5.4301e-01, time/batch = 0.1611s	
2161/2700 (epoch 40.019), train_loss = 1.47867635, grad/param norm = 5.1445e-01, time/batch = 0.1838s	
2162/2700 (epoch 40.037), train_loss = 1.48349203, grad/param norm = 5.2518e-01, time/batch = 0.1842s	
2163/2700 (epoch 40.056), train_loss = 1.42374017, grad/param norm = 4.8393e-01, time/batch = 0.1581s	
2164/2700 (epoch 40.074), train_loss = 1.43478144, grad/param norm = 5.1279e-01, time/batch = 0.1655s	
2165/2700 (epoch 40.093), train_loss = 1.40753365, grad/param norm = 4.9846e-01, time/batch = 0.1660s	
2166/2700 (epoch 40.111), train_loss = 1.37748751, grad/param norm = 4.8373e-01, time/batch = 0.1610s	
2167/2700 (epoch 40.130), train_loss = 1.43249475, grad/param norm = 4.9030e-01, time/batch = 0.1615s	
2168/2700 (epoch 40.148), train_loss = 1.38349277, grad/param norm = 4.6529e-01, time/batch = 0.1679s	
2169/2700 (epoch 40.167), train_loss = 1.49289752, grad/param norm = 5.3166e-01, time/batch = 0.1621s	
2170/2700 (epoch 40.185), train_loss = 1.38835135, grad/param norm = 4.5177e-01, time/batch = 0.1794s	
2171/2700 (epoch 40.204), train_loss = 1.47931600, grad/param norm = 5.2096e-01, time/batch = 0.1666s	
2172/2700 (epoch 40.222), train_loss = 1.38286918, grad/param norm = 5.0322e-01, time/batch = 0.1722s	
2173/2700 (epoch 40.241), train_loss = 1.33486381, grad/param norm = 4.8447e-01, time/batch = 0.1576s	
2174/2700 (epoch 40.259), train_loss = 1.40189612, grad/param norm = 5.3316e-01, time/batch = 0.1751s	
2175/2700 (epoch 40.278), train_loss = 1.48778381, grad/param norm = 5.1541e-01, time/batch = 0.1672s	
2176/2700 (epoch 40.296), train_loss = 1.43854717, grad/param norm = 4.6920e-01, time/batch = 0.1571s	
2177/2700 (epoch 40.315), train_loss = 1.42596904, grad/param norm = 4.9061e-01, time/batch = 0.1825s	
2178/2700 (epoch 40.333), train_loss = 1.44756883, grad/param norm = 5.0619e-01, time/batch = 0.1741s	
2179/2700 (epoch 40.352), train_loss = 1.43142185, grad/param norm = 4.9302e-01, time/batch = 0.1812s	
2180/2700 (epoch 40.370), train_loss = 1.45003580, grad/param norm = 5.5558e-01, time/batch = 0.1797s	
2181/2700 (epoch 40.389), train_loss = 1.41315572, grad/param norm = 5.0179e-01, time/batch = 0.1656s	
2182/2700 (epoch 40.407), train_loss = 1.46147738, grad/param norm = 5.0061e-01, time/batch = 0.1659s	
2183/2700 (epoch 40.426), train_loss = 1.46872351, grad/param norm = 4.9844e-01, time/batch = 0.1603s	
2184/2700 (epoch 40.444), train_loss = 1.41898309, grad/param norm = 4.7831e-01, time/batch = 0.1584s	
2185/2700 (epoch 40.463), train_loss = 1.45560084, grad/param norm = 4.7601e-01, time/batch = 0.1536s	
2186/2700 (epoch 40.481), train_loss = 1.46391913, grad/param norm = 4.9378e-01, time/batch = 0.1371s	
2187/2700 (epoch 40.500), train_loss = 1.40126903, grad/param norm = 5.3222e-01, time/batch = 0.1526s	
2188/2700 (epoch 40.519), train_loss = 1.44886321, grad/param norm = 4.9056e-01, time/batch = 0.1402s	
2189/2700 (epoch 40.537), train_loss = 1.46487794, grad/param norm = 4.9402e-01, time/batch = 0.1534s	
2190/2700 (epoch 40.556), train_loss = 1.37633212, grad/param norm = 4.8036e-01, time/batch = 0.1593s	
2191/2700 (epoch 40.574), train_loss = 1.38295519, grad/param norm = 5.3661e-01, time/batch = 0.1602s	
2192/2700 (epoch 40.593), train_loss = 1.39459123, grad/param norm = 5.0021e-01, time/batch = 0.1686s	
2193/2700 (epoch 40.611), train_loss = 1.35831628, grad/param norm = 4.7509e-01, time/batch = 0.1683s	
2194/2700 (epoch 40.630), train_loss = 1.37232101, grad/param norm = 4.7098e-01, time/batch = 0.1699s	
2195/2700 (epoch 40.648), train_loss = 1.40544916, grad/param norm = 4.7955e-01, time/batch = 0.1554s	
2196/2700 (epoch 40.667), train_loss = 1.38387149, grad/param norm = 5.2529e-01, time/batch = 0.1346s	
2197/2700 (epoch 40.685), train_loss = 1.43445001, grad/param norm = 5.3351e-01, time/batch = 0.1263s	
2198/2700 (epoch 40.704), train_loss = 1.45868488, grad/param norm = 5.3270e-01, time/batch = 0.1209s	
2199/2700 (epoch 40.722), train_loss = 1.42012894, grad/param norm = 4.9196e-01, time/batch = 0.1809s	
2200/2700 (epoch 40.741), train_loss = 1.41181708, grad/param norm = 4.8637e-01, time/batch = 0.1805s	
2201/2700 (epoch 40.759), train_loss = 1.42721575, grad/param norm = 5.1807e-01, time/batch = 0.1715s	
2202/2700 (epoch 40.778), train_loss = 1.45571108, grad/param norm = 5.1733e-01, time/batch = 0.1719s	
2203/2700 (epoch 40.796), train_loss = 1.41483043, grad/param norm = 4.8930e-01, time/batch = 0.1762s	
2204/2700 (epoch 40.815), train_loss = 1.45168725, grad/param norm = 5.2107e-01, time/batch = 0.1787s	
2205/2700 (epoch 40.833), train_loss = 1.41152124, grad/param norm = 5.0734e-01, time/batch = 0.1785s	
2206/2700 (epoch 40.852), train_loss = 1.39628294, grad/param norm = 4.8952e-01, time/batch = 0.1793s	
2207/2700 (epoch 40.870), train_loss = 1.41702558, grad/param norm = 4.8239e-01, time/batch = 0.1686s	
2208/2700 (epoch 40.889), train_loss = 1.42539887, grad/param norm = 5.0531e-01, time/batch = 0.1456s	
2209/2700 (epoch 40.907), train_loss = 1.51303030, grad/param norm = 5.1850e-01, time/batch = 0.1639s	
2210/2700 (epoch 40.926), train_loss = 1.44111558, grad/param norm = 4.7267e-01, time/batch = 0.1586s	
2211/2700 (epoch 40.944), train_loss = 1.42716239, grad/param norm = 5.1537e-01, time/batch = 0.1763s	
2212/2700 (epoch 40.963), train_loss = 1.44283597, grad/param norm = 4.9767e-01, time/batch = 0.1788s	
2213/2700 (epoch 40.981), train_loss = 1.42230281, grad/param norm = 5.0835e-01, time/batch = 0.1835s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2214/2700 (epoch 41.000), train_loss = 1.50560492, grad/param norm = 5.4365e-01, time/batch = 0.1832s	
2215/2700 (epoch 41.019), train_loss = 1.47221271, grad/param norm = 5.1705e-01, time/batch = 0.1843s	
2216/2700 (epoch 41.037), train_loss = 1.47603509, grad/param norm = 5.1774e-01, time/batch = 0.1838s	
2217/2700 (epoch 41.056), train_loss = 1.41697597, grad/param norm = 4.8165e-01, time/batch = 0.1741s	
2218/2700 (epoch 41.074), train_loss = 1.42876156, grad/param norm = 5.1054e-01, time/batch = 0.1478s	
2219/2700 (epoch 41.093), train_loss = 1.40068566, grad/param norm = 4.9191e-01, time/batch = 0.1663s	
2220/2700 (epoch 41.111), train_loss = 1.37104914, grad/param norm = 4.9239e-01, time/batch = 0.1688s	
2221/2700 (epoch 41.130), train_loss = 1.42559431, grad/param norm = 4.9416e-01, time/batch = 0.1866s	
2222/2700 (epoch 41.148), train_loss = 1.37693746, grad/param norm = 4.6697e-01, time/batch = 0.1703s	
2223/2700 (epoch 41.167), train_loss = 1.48657106, grad/param norm = 5.3960e-01, time/batch = 0.1582s	
2224/2700 (epoch 41.185), train_loss = 1.38198467, grad/param norm = 4.5388e-01, time/batch = 0.1542s	
2225/2700 (epoch 41.204), train_loss = 1.47274573, grad/param norm = 5.1944e-01, time/batch = 0.1559s	
2226/2700 (epoch 41.222), train_loss = 1.37639036, grad/param norm = 5.0688e-01, time/batch = 0.1521s	
2227/2700 (epoch 41.241), train_loss = 1.32930845, grad/param norm = 4.8789e-01, time/batch = 0.1486s	
2228/2700 (epoch 41.259), train_loss = 1.39539470, grad/param norm = 5.2888e-01, time/batch = 0.1208s	
2229/2700 (epoch 41.278), train_loss = 1.48107821, grad/param norm = 5.1383e-01, time/batch = 0.1781s	
2230/2700 (epoch 41.296), train_loss = 1.43172627, grad/param norm = 4.7079e-01, time/batch = 0.1793s	
2231/2700 (epoch 41.315), train_loss = 1.41895498, grad/param norm = 4.9279e-01, time/batch = 0.1839s	
2232/2700 (epoch 41.333), train_loss = 1.44100402, grad/param norm = 5.0612e-01, time/batch = 0.1827s	
2233/2700 (epoch 41.352), train_loss = 1.42510371, grad/param norm = 4.9491e-01, time/batch = 0.1807s	
2234/2700 (epoch 41.370), train_loss = 1.44330852, grad/param norm = 5.5566e-01, time/batch = 0.1788s	
2235/2700 (epoch 41.389), train_loss = 1.40544696, grad/param norm = 5.0014e-01, time/batch = 0.1814s	
2236/2700 (epoch 41.407), train_loss = 1.45424399, grad/param norm = 4.9911e-01, time/batch = 0.1802s	
2237/2700 (epoch 41.426), train_loss = 1.46157111, grad/param norm = 5.0008e-01, time/batch = 0.1638s	
2238/2700 (epoch 41.444), train_loss = 1.41316273, grad/param norm = 4.7810e-01, time/batch = 0.1414s	
2239/2700 (epoch 41.463), train_loss = 1.44899913, grad/param norm = 4.7896e-01, time/batch = 0.1267s	
2240/2700 (epoch 41.481), train_loss = 1.45697237, grad/param norm = 4.9497e-01, time/batch = 0.1161s	
2241/2700 (epoch 41.500), train_loss = 1.39415415, grad/param norm = 5.3249e-01, time/batch = 0.1513s	
2242/2700 (epoch 41.519), train_loss = 1.44251390, grad/param norm = 4.9123e-01, time/batch = 0.1479s	
2243/2700 (epoch 41.537), train_loss = 1.45831256, grad/param norm = 4.9762e-01, time/batch = 0.1405s	
2244/2700 (epoch 41.556), train_loss = 1.36968135, grad/param norm = 4.8057e-01, time/batch = 0.1355s	
2245/2700 (epoch 41.574), train_loss = 1.37630453, grad/param norm = 5.3762e-01, time/batch = 0.1376s	
2246/2700 (epoch 41.593), train_loss = 1.38797885, grad/param norm = 5.0247e-01, time/batch = 0.1380s	
2247/2700 (epoch 41.611), train_loss = 1.35267528, grad/param norm = 4.7689e-01, time/batch = 0.1309s	
2248/2700 (epoch 41.630), train_loss = 1.36579941, grad/param norm = 4.7564e-01, time/batch = 0.0984s	
2249/2700 (epoch 41.648), train_loss = 1.39849614, grad/param norm = 4.7941e-01, time/batch = 0.1252s	
2250/2700 (epoch 41.667), train_loss = 1.37758600, grad/param norm = 5.2753e-01, time/batch = 0.1249s	
2251/2700 (epoch 41.685), train_loss = 1.42852893, grad/param norm = 5.3678e-01, time/batch = 0.1488s	
2252/2700 (epoch 41.704), train_loss = 1.45222231, grad/param norm = 5.3551e-01, time/batch = 0.1510s	
2253/2700 (epoch 41.722), train_loss = 1.41390656, grad/param norm = 4.9632e-01, time/batch = 0.1394s	
2254/2700 (epoch 41.741), train_loss = 1.40531881, grad/param norm = 4.9001e-01, time/batch = 0.1332s	
2255/2700 (epoch 41.759), train_loss = 1.42040316, grad/param norm = 5.1892e-01, time/batch = 0.1354s	
2256/2700 (epoch 41.778), train_loss = 1.44863352, grad/param norm = 5.2008e-01, time/batch = 0.1277s	
2257/2700 (epoch 41.796), train_loss = 1.40781140, grad/param norm = 4.9273e-01, time/batch = 0.1462s	
2258/2700 (epoch 41.815), train_loss = 1.44509436, grad/param norm = 5.2397e-01, time/batch = 0.1274s	
2259/2700 (epoch 41.833), train_loss = 1.40469223, grad/param norm = 5.0571e-01, time/batch = 0.1362s	
2260/2700 (epoch 41.852), train_loss = 1.38936109, grad/param norm = 4.9084e-01, time/batch = 0.1378s	
2261/2700 (epoch 41.870), train_loss = 1.41039238, grad/param norm = 4.8479e-01, time/batch = 0.1373s	
2262/2700 (epoch 41.889), train_loss = 1.41914667, grad/param norm = 5.0670e-01, time/batch = 0.1355s	
2263/2700 (epoch 41.907), train_loss = 1.50545998, grad/param norm = 5.1683e-01, time/batch = 0.1357s	
2264/2700 (epoch 41.926), train_loss = 1.43427870, grad/param norm = 4.7471e-01, time/batch = 0.1360s	
2265/2700 (epoch 41.944), train_loss = 1.42075844, grad/param norm = 5.1885e-01, time/batch = 0.1313s	
2266/2700 (epoch 41.963), train_loss = 1.43567058, grad/param norm = 4.9720e-01, time/batch = 0.1364s	
2267/2700 (epoch 41.981), train_loss = 1.41536439, grad/param norm = 5.1065e-01, time/batch = 0.1376s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2268/2700 (epoch 42.000), train_loss = 1.49845755, grad/param norm = 5.4384e-01, time/batch = 0.1229s	
2269/2700 (epoch 42.019), train_loss = 1.46506512, grad/param norm = 5.2060e-01, time/batch = 0.1485s	
2270/2700 (epoch 42.037), train_loss = 1.46894757, grad/param norm = 5.2975e-01, time/batch = 0.1493s	
2271/2700 (epoch 42.056), train_loss = 1.41040632, grad/param norm = 4.8494e-01, time/batch = 0.1407s	
2272/2700 (epoch 42.074), train_loss = 1.42193981, grad/param norm = 5.1267e-01, time/batch = 0.1442s	
2273/2700 (epoch 42.093), train_loss = 1.39494091, grad/param norm = 5.0158e-01, time/batch = 0.1476s	
2274/2700 (epoch 42.111), train_loss = 1.36435081, grad/param norm = 4.8654e-01, time/batch = 0.1445s	
2275/2700 (epoch 42.130), train_loss = 1.41897526, grad/param norm = 4.9967e-01, time/batch = 0.1477s	
2276/2700 (epoch 42.148), train_loss = 1.37061201, grad/param norm = 4.7286e-01, time/batch = 0.1482s	
2277/2700 (epoch 42.167), train_loss = 1.48010090, grad/param norm = 5.3857e-01, time/batch = 0.1492s	
2278/2700 (epoch 42.185), train_loss = 1.37565442, grad/param norm = 4.5658e-01, time/batch = 0.1313s	
2279/2700 (epoch 42.204), train_loss = 1.46637574, grad/param norm = 5.2101e-01, time/batch = 0.1169s	
2280/2700 (epoch 42.222), train_loss = 1.37023595, grad/param norm = 5.1096e-01, time/batch = 0.1179s	
2281/2700 (epoch 42.241), train_loss = 1.32397680, grad/param norm = 4.9210e-01, time/batch = 0.1459s	
2282/2700 (epoch 42.259), train_loss = 1.38893637, grad/param norm = 5.2524e-01, time/batch = 0.1357s	
2283/2700 (epoch 42.278), train_loss = 1.47462632, grad/param norm = 5.1306e-01, time/batch = 0.1232s	
2284/2700 (epoch 42.296), train_loss = 1.42518883, grad/param norm = 4.7257e-01, time/batch = 0.1446s	
2285/2700 (epoch 42.315), train_loss = 1.41207515, grad/param norm = 4.9585e-01, time/batch = 0.1412s	
2286/2700 (epoch 42.333), train_loss = 1.43459767, grad/param norm = 5.0553e-01, time/batch = 0.1218s	
2287/2700 (epoch 42.352), train_loss = 1.41903781, grad/param norm = 4.9744e-01, time/batch = 0.1164s	
2288/2700 (epoch 42.370), train_loss = 1.43673470, grad/param norm = 5.5796e-01, time/batch = 0.1159s	
2289/2700 (epoch 42.389), train_loss = 1.39803142, grad/param norm = 4.9724e-01, time/batch = 0.0973s	
2290/2700 (epoch 42.407), train_loss = 1.44729804, grad/param norm = 4.9796e-01, time/batch = 0.1321s	
2291/2700 (epoch 42.426), train_loss = 1.45479318, grad/param norm = 5.0447e-01, time/batch = 0.1498s	
2292/2700 (epoch 42.444), train_loss = 1.40762317, grad/param norm = 4.7875e-01, time/batch = 0.1255s	
2293/2700 (epoch 42.463), train_loss = 1.44272456, grad/param norm = 4.8237e-01, time/batch = 0.1521s	
2294/2700 (epoch 42.481), train_loss = 1.45027951, grad/param norm = 4.9607e-01, time/batch = 0.1509s	
2295/2700 (epoch 42.500), train_loss = 1.38740254, grad/param norm = 5.3263e-01, time/batch = 0.1400s	
2296/2700 (epoch 42.519), train_loss = 1.43627586, grad/param norm = 4.9115e-01, time/batch = 0.1372s	
2297/2700 (epoch 42.537), train_loss = 1.45192485, grad/param norm = 5.0062e-01, time/batch = 0.1370s	
2298/2700 (epoch 42.556), train_loss = 1.36326545, grad/param norm = 4.8040e-01, time/batch = 0.1379s	
2299/2700 (epoch 42.574), train_loss = 1.36986300, grad/param norm = 5.3850e-01, time/batch = 0.1292s	
2300/2700 (epoch 42.593), train_loss = 1.38183567, grad/param norm = 5.0445e-01, time/batch = 0.1372s	
2301/2700 (epoch 42.611), train_loss = 1.34716955, grad/param norm = 4.7769e-01, time/batch = 0.1333s	
2302/2700 (epoch 42.630), train_loss = 1.35954384, grad/param norm = 4.8126e-01, time/batch = 0.1379s	
2303/2700 (epoch 42.648), train_loss = 1.39172044, grad/param norm = 4.7885e-01, time/batch = 0.1336s	
2304/2700 (epoch 42.667), train_loss = 1.37164461, grad/param norm = 5.2922e-01, time/batch = 0.1325s	
2305/2700 (epoch 42.685), train_loss = 1.42279031, grad/param norm = 5.3926e-01, time/batch = 0.1324s	
2306/2700 (epoch 42.704), train_loss = 1.44595740, grad/param norm = 5.3780e-01, time/batch = 0.1304s	
2307/2700 (epoch 42.722), train_loss = 1.40780529, grad/param norm = 5.0057e-01, time/batch = 0.1308s	
2308/2700 (epoch 42.741), train_loss = 1.39912742, grad/param norm = 4.9414e-01, time/batch = 0.1276s	
2309/2700 (epoch 42.759), train_loss = 1.41388923, grad/param norm = 5.2041e-01, time/batch = 0.1214s	
2310/2700 (epoch 42.778), train_loss = 1.44191863, grad/param norm = 5.2316e-01, time/batch = 0.1397s	
2311/2700 (epoch 42.796), train_loss = 1.40103938, grad/param norm = 4.9456e-01, time/batch = 0.1302s	
2312/2700 (epoch 42.815), train_loss = 1.43874578, grad/param norm = 5.2687e-01, time/batch = 0.1245s	
2313/2700 (epoch 42.833), train_loss = 1.39822090, grad/param norm = 5.0479e-01, time/batch = 0.1244s	
2314/2700 (epoch 42.852), train_loss = 1.38270655, grad/param norm = 4.9185e-01, time/batch = 0.1284s	
2315/2700 (epoch 42.870), train_loss = 1.40402274, grad/param norm = 4.8773e-01, time/batch = 0.1277s	
2316/2700 (epoch 42.889), train_loss = 1.41309577, grad/param norm = 5.0842e-01, time/batch = 0.1070s	
2317/2700 (epoch 42.907), train_loss = 1.49828013, grad/param norm = 5.1595e-01, time/batch = 0.1277s	
2318/2700 (epoch 42.926), train_loss = 1.42780961, grad/param norm = 4.7743e-01, time/batch = 0.1321s	
2319/2700 (epoch 42.944), train_loss = 1.41461970, grad/param norm = 5.2216e-01, time/batch = 0.1244s	
2320/2700 (epoch 42.963), train_loss = 1.42881538, grad/param norm = 4.9716e-01, time/batch = 0.1377s	
2321/2700 (epoch 42.981), train_loss = 1.40870238, grad/param norm = 5.1255e-01, time/batch = 0.1322s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
2322/2700 (epoch 43.000), train_loss = 1.49162443, grad/param norm = 5.4422e-01, time/batch = 0.1248s	
2323/2700 (epoch 43.019), train_loss = 1.45925850, grad/param norm = 5.2393e-01, time/batch = 0.1296s	
2324/2700 (epoch 43.037), train_loss = 1.46194847, grad/param norm = 5.2051e-01, time/batch = 0.1303s	
2325/2700 (epoch 43.056), train_loss = 1.40415513, grad/param norm = 4.8578e-01, time/batch = 0.1338s	
2326/2700 (epoch 43.074), train_loss = 1.41642737, grad/param norm = 5.1297e-01, time/batch = 0.1376s	
2327/2700 (epoch 43.093), train_loss = 1.38868545, grad/param norm = 4.9682e-01, time/batch = 0.1369s	
2328/2700 (epoch 43.111), train_loss = 1.35834777, grad/param norm = 4.9498e-01, time/batch = 0.1354s	
2329/2700 (epoch 43.130), train_loss = 1.41251818, grad/param norm = 5.0291e-01, time/batch = 0.1287s	
2330/2700 (epoch 43.148), train_loss = 1.36453166, grad/param norm = 4.7403e-01, time/batch = 0.1372s	
2331/2700 (epoch 43.167), train_loss = 1.47412812, grad/param norm = 5.4703e-01, time/batch = 0.1343s	
2332/2700 (epoch 43.185), train_loss = 1.36990976, grad/param norm = 4.5896e-01, time/batch = 0.1263s	
2333/2700 (epoch 43.204), train_loss = 1.46017661, grad/param norm = 5.1968e-01, time/batch = 0.1303s	
2334/2700 (epoch 43.222), train_loss = 1.36428335, grad/param norm = 5.1525e-01, time/batch = 0.1341s	
2335/2700 (epoch 43.241), train_loss = 1.31877533, grad/param norm = 4.9480e-01, time/batch = 0.1338s	
2336/2700 (epoch 43.259), train_loss = 1.38286970, grad/param norm = 5.2095e-01, time/batch = 0.1361s	
2337/2700 (epoch 43.278), train_loss = 1.46862246, grad/param norm = 5.1344e-01, time/batch = 0.1382s	
2338/2700 (epoch 43.296), train_loss = 1.41884155, grad/param norm = 4.7440e-01, time/batch = 0.1375s	
2339/2700 (epoch 43.315), train_loss = 1.40546237, grad/param norm = 4.9771e-01, time/batch = 0.1293s	
2340/2700 (epoch 43.333), train_loss = 1.42840295, grad/param norm = 5.0558e-01, time/batch = 0.1393s	
2341/2700 (epoch 43.352), train_loss = 1.41299453, grad/param norm = 4.9935e-01, time/batch = 0.1321s	
2342/2700 (epoch 43.370), train_loss = 1.43048749, grad/param norm = 5.5618e-01, time/batch = 0.1313s	
2343/2700 (epoch 43.389), train_loss = 1.39088499, grad/param norm = 4.9721e-01, time/batch = 0.1288s	
2344/2700 (epoch 43.407), train_loss = 1.44062679, grad/param norm = 4.9764e-01, time/batch = 0.1295s	
2345/2700 (epoch 43.426), train_loss = 1.44810577, grad/param norm = 5.0652e-01, time/batch = 0.1363s	
2346/2700 (epoch 43.444), train_loss = 1.40219134, grad/param norm = 4.7892e-01, time/batch = 0.1342s	
2347/2700 (epoch 43.463), train_loss = 1.43669562, grad/param norm = 4.8567e-01, time/batch = 0.1394s	
2348/2700 (epoch 43.481), train_loss = 1.44375297, grad/param norm = 4.9726e-01, time/batch = 0.1390s	
2349/2700 (epoch 43.500), train_loss = 1.38077327, grad/param norm = 5.3281e-01, time/batch = 0.1396s	
2350/2700 (epoch 43.519), train_loss = 1.43027189, grad/param norm = 4.9181e-01, time/batch = 0.1364s	
2351/2700 (epoch 43.537), train_loss = 1.44581048, grad/param norm = 5.0375e-01, time/batch = 0.1315s	
2352/2700 (epoch 43.556), train_loss = 1.35711883, grad/param norm = 4.8132e-01, time/batch = 0.1473s	
2353/2700 (epoch 43.574), train_loss = 1.36374188, grad/param norm = 5.3958e-01, time/batch = 0.1409s	
2354/2700 (epoch 43.593), train_loss = 1.37578678, grad/param norm = 5.0693e-01, time/batch = 0.1317s	
2355/2700 (epoch 43.611), train_loss = 1.34188650, grad/param norm = 4.7875e-01, time/batch = 0.1312s	
2356/2700 (epoch 43.630), train_loss = 1.35356433, grad/param norm = 4.8669e-01, time/batch = 0.1278s	
2357/2700 (epoch 43.648), train_loss = 1.38520041, grad/param norm = 4.7831e-01, time/batch = 0.1260s	
2358/2700 (epoch 43.667), train_loss = 1.36585353, grad/param norm = 5.3166e-01, time/batch = 0.1280s	
2359/2700 (epoch 43.685), train_loss = 1.41732916, grad/param norm = 5.4265e-01, time/batch = 0.1349s	
2360/2700 (epoch 43.704), train_loss = 1.43984317, grad/param norm = 5.4025e-01, time/batch = 0.1142s	
2361/2700 (epoch 43.722), train_loss = 1.40191170, grad/param norm = 5.0433e-01, time/batch = 0.1438s	
2362/2700 (epoch 43.741), train_loss = 1.39311340, grad/param norm = 4.9787e-01, time/batch = 0.1263s	
2363/2700 (epoch 43.759), train_loss = 1.40752596, grad/param norm = 5.2091e-01, time/batch = 0.1252s	
2364/2700 (epoch 43.778), train_loss = 1.43537102, grad/param norm = 5.2685e-01, time/batch = 0.1351s	
2365/2700 (epoch 43.796), train_loss = 1.39459377, grad/param norm = 4.9762e-01, time/batch = 0.1387s	
2366/2700 (epoch 43.815), train_loss = 1.43251913, grad/param norm = 5.2906e-01, time/batch = 0.1421s	
2367/2700 (epoch 43.833), train_loss = 1.39192314, grad/param norm = 5.0376e-01, time/batch = 0.1479s	
2368/2700 (epoch 43.852), train_loss = 1.37623735, grad/param norm = 4.9325e-01, time/batch = 0.1482s	
2369/2700 (epoch 43.870), train_loss = 1.39783340, grad/param norm = 4.9020e-01, time/batch = 0.1463s	
2370/2700 (epoch 43.889), train_loss = 1.40729170, grad/param norm = 5.0943e-01, time/batch = 0.1401s	
2371/2700 (epoch 43.907), train_loss = 1.49136235, grad/param norm = 5.1477e-01, time/batch = 0.1449s	
2372/2700 (epoch 43.926), train_loss = 1.42149321, grad/param norm = 4.8042e-01, time/batch = 0.1486s	
2373/2700 (epoch 43.944), train_loss = 1.40864110, grad/param norm = 5.2549e-01, time/batch = 0.1404s	
2374/2700 (epoch 43.963), train_loss = 1.42229146, grad/param norm = 4.9735e-01, time/batch = 0.1336s	
2375/2700 (epoch 43.981), train_loss = 1.40233433, grad/param norm = 5.1451e-01, time/batch = 0.1318s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
2376/2700 (epoch 44.000), train_loss = 1.48506548, grad/param norm = 5.4409e-01, time/batch = 0.1311s	
2377/2700 (epoch 44.019), train_loss = 1.45246971, grad/param norm = 5.2543e-01, time/batch = 0.1195s	
2378/2700 (epoch 44.037), train_loss = 1.45526200, grad/param norm = 5.2910e-01, time/batch = 0.1045s	
2379/2700 (epoch 44.056), train_loss = 1.39798308, grad/param norm = 4.8813e-01, time/batch = 0.1221s	
2380/2700 (epoch 44.074), train_loss = 1.40990895, grad/param norm = 5.1441e-01, time/batch = 0.1320s	
2381/2700 (epoch 44.093), train_loss = 1.38341372, grad/param norm = 5.0649e-01, time/batch = 0.1156s	
2382/2700 (epoch 44.111), train_loss = 1.35214316, grad/param norm = 4.8956e-01, time/batch = 0.1405s	
2383/2700 (epoch 44.130), train_loss = 1.40636502, grad/param norm = 5.0906e-01, time/batch = 0.1269s	
2384/2700 (epoch 44.148), train_loss = 1.35869833, grad/param norm = 4.7922e-01, time/batch = 0.1341s	
2385/2700 (epoch 44.167), train_loss = 1.46807900, grad/param norm = 5.4759e-01, time/batch = 0.1377s	
2386/2700 (epoch 44.185), train_loss = 1.36420404, grad/param norm = 4.6325e-01, time/batch = 0.1465s	
2387/2700 (epoch 44.204), train_loss = 1.45421137, grad/param norm = 5.2137e-01, time/batch = 0.1499s	
2388/2700 (epoch 44.222), train_loss = 1.35859425, grad/param norm = 5.1987e-01, time/batch = 0.1482s	
2389/2700 (epoch 44.241), train_loss = 1.31377549, grad/param norm = 4.9815e-01, time/batch = 0.1490s	
2390/2700 (epoch 44.259), train_loss = 1.37682521, grad/param norm = 5.1730e-01, time/batch = 0.1505s	
2391/2700 (epoch 44.278), train_loss = 1.46281056, grad/param norm = 5.1444e-01, time/batch = 0.1273s	
2392/2700 (epoch 44.296), train_loss = 1.41279248, grad/param norm = 4.7647e-01, time/batch = 0.1513s	
2393/2700 (epoch 44.315), train_loss = 1.39899850, grad/param norm = 5.0073e-01, time/batch = 0.1495s	
2394/2700 (epoch 44.333), train_loss = 1.42232952, grad/param norm = 5.0522e-01, time/batch = 0.1457s	
2395/2700 (epoch 44.352), train_loss = 1.40721387, grad/param norm = 5.0209e-01, time/batch = 0.1444s	
2396/2700 (epoch 44.370), train_loss = 1.42437017, grad/param norm = 5.5657e-01, time/batch = 0.1390s	
2397/2700 (epoch 44.389), train_loss = 1.38404916, grad/param norm = 4.9584e-01, time/batch = 0.1368s	
2398/2700 (epoch 44.407), train_loss = 1.43427078, grad/param norm = 4.9818e-01, time/batch = 0.1330s	
2399/2700 (epoch 44.426), train_loss = 1.44178267, grad/param norm = 5.1115e-01, time/batch = 0.1321s	
2400/2700 (epoch 44.444), train_loss = 1.39700476, grad/param norm = 4.7970e-01, time/batch = 0.1370s	
2401/2700 (epoch 44.463), train_loss = 1.43097693, grad/param norm = 4.8933e-01, time/batch = 0.1498s	
2402/2700 (epoch 44.481), train_loss = 1.43747123, grad/param norm = 4.9824e-01, time/batch = 0.1400s	
2403/2700 (epoch 44.500), train_loss = 1.37449099, grad/param norm = 5.3295e-01, time/batch = 0.1341s	
2404/2700 (epoch 44.519), train_loss = 1.42438734, grad/param norm = 4.9204e-01, time/batch = 0.1294s	
2405/2700 (epoch 44.537), train_loss = 1.43985463, grad/param norm = 5.0656e-01, time/batch = 0.1288s	
2406/2700 (epoch 44.556), train_loss = 1.35119672, grad/param norm = 4.8186e-01, time/batch = 0.1114s	
2407/2700 (epoch 44.574), train_loss = 1.35781292, grad/param norm = 5.4046e-01, time/batch = 0.1179s	
2408/2700 (epoch 44.593), train_loss = 1.37017735, grad/param norm = 5.0886e-01, time/batch = 0.1215s	
2409/2700 (epoch 44.611), train_loss = 1.33672706, grad/param norm = 4.7904e-01, time/batch = 0.1239s	
2410/2700 (epoch 44.630), train_loss = 1.34781140, grad/param norm = 4.9295e-01, time/batch = 0.1235s	
2411/2700 (epoch 44.648), train_loss = 1.37886363, grad/param norm = 4.7755e-01, time/batch = 0.1455s	
2412/2700 (epoch 44.667), train_loss = 1.36039102, grad/param norm = 5.3376e-01, time/batch = 0.1482s	
2413/2700 (epoch 44.685), train_loss = 1.41199608, grad/param norm = 5.4516e-01, time/batch = 0.1477s	
2414/2700 (epoch 44.704), train_loss = 1.43392890, grad/param norm = 5.4211e-01, time/batch = 0.1469s	
2415/2700 (epoch 44.722), train_loss = 1.39616126, grad/param norm = 5.0806e-01, time/batch = 0.1401s	
2416/2700 (epoch 44.741), train_loss = 1.38736867, grad/param norm = 5.0191e-01, time/batch = 0.1516s	
2417/2700 (epoch 44.759), train_loss = 1.40143959, grad/param norm = 5.2220e-01, time/batch = 0.1477s	
2418/2700 (epoch 44.778), train_loss = 1.42914107, grad/param norm = 5.3024e-01, time/batch = 0.1524s	
2419/2700 (epoch 44.796), train_loss = 1.38836339, grad/param norm = 4.9891e-01, time/batch = 0.1421s	
2420/2700 (epoch 44.815), train_loss = 1.42655068, grad/param norm = 5.3187e-01, time/batch = 0.1339s	
2421/2700 (epoch 44.833), train_loss = 1.38599487, grad/param norm = 5.0361e-01, time/batch = 0.1134s	
2422/2700 (epoch 44.852), train_loss = 1.37000553, grad/param norm = 4.9431e-01, time/batch = 0.1463s	
2423/2700 (epoch 44.870), train_loss = 1.39187182, grad/param norm = 4.9317e-01, time/batch = 0.1459s	
2424/2700 (epoch 44.889), train_loss = 1.40168035, grad/param norm = 5.1085e-01, time/batch = 0.1435s	
2425/2700 (epoch 44.907), train_loss = 1.48476136, grad/param norm = 5.1423e-01, time/batch = 0.1324s	
2426/2700 (epoch 44.926), train_loss = 1.41551875, grad/param norm = 4.8405e-01, time/batch = 0.1323s	
2427/2700 (epoch 44.944), train_loss = 1.40292538, grad/param norm = 5.2883e-01, time/batch = 0.1331s	
2428/2700 (epoch 44.963), train_loss = 1.41602887, grad/param norm = 4.9806e-01, time/batch = 0.1368s	
2429/2700 (epoch 44.981), train_loss = 1.39621210, grad/param norm = 5.1614e-01, time/batch = 0.1360s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
2430/2700 (epoch 45.000), train_loss = 1.47880385, grad/param norm = 5.4434e-01, time/batch = 0.1378s	
2431/2700 (epoch 45.019), train_loss = 1.44712412, grad/param norm = 5.3025e-01, time/batch = 0.1239s	
2432/2700 (epoch 45.037), train_loss = 1.44875650, grad/param norm = 5.2179e-01, time/batch = 0.1205s	
2433/2700 (epoch 45.056), train_loss = 1.39224200, grad/param norm = 4.9213e-01, time/batch = 0.1197s	
2434/2700 (epoch 45.074), train_loss = 1.40476986, grad/param norm = 5.1685e-01, time/batch = 0.1118s	
2435/2700 (epoch 45.093), train_loss = 1.37772062, grad/param norm = 5.0408e-01, time/batch = 0.1191s	
2436/2700 (epoch 45.111), train_loss = 1.34646889, grad/param norm = 4.9600e-01, time/batch = 0.1271s	
2437/2700 (epoch 45.130), train_loss = 1.40033310, grad/param norm = 5.1211e-01, time/batch = 0.1366s	
2438/2700 (epoch 45.148), train_loss = 1.35308892, grad/param norm = 4.8106e-01, time/batch = 0.1398s	
2439/2700 (epoch 45.167), train_loss = 1.46238889, grad/param norm = 5.5519e-01, time/batch = 0.1453s	
2440/2700 (epoch 45.185), train_loss = 1.35893452, grad/param norm = 4.6596e-01, time/batch = 0.1455s	
2441/2700 (epoch 45.204), train_loss = 1.44835462, grad/param norm = 5.2063e-01, time/batch = 0.1267s	
2442/2700 (epoch 45.222), train_loss = 1.35307705, grad/param norm = 5.2415e-01, time/batch = 0.0937s	
2443/2700 (epoch 45.241), train_loss = 1.30889870, grad/param norm = 5.0035e-01, time/batch = 0.1119s	
2444/2700 (epoch 45.259), train_loss = 1.37116438, grad/param norm = 5.1381e-01, time/batch = 0.1292s	
2445/2700 (epoch 45.278), train_loss = 1.45737932, grad/param norm = 5.1611e-01, time/batch = 0.1312s	
2446/2700 (epoch 45.296), train_loss = 1.40690935, grad/param norm = 4.7864e-01, time/batch = 0.1342s	
2447/2700 (epoch 45.315), train_loss = 1.39278515, grad/param norm = 5.0241e-01, time/batch = 0.1372s	
2448/2700 (epoch 45.333), train_loss = 1.41648667, grad/param norm = 5.0590e-01, time/batch = 0.1310s	
2449/2700 (epoch 45.352), train_loss = 1.40138639, grad/param norm = 5.0381e-01, time/batch = 0.1191s	
2450/2700 (epoch 45.370), train_loss = 1.41856495, grad/param norm = 5.5401e-01, time/batch = 0.1187s	
2451/2700 (epoch 45.389), train_loss = 1.37749490, grad/param norm = 4.9694e-01, time/batch = 0.1368s	
2452/2700 (epoch 45.407), train_loss = 1.42815054, grad/param norm = 4.9887e-01, time/batch = 0.1304s	
2453/2700 (epoch 45.426), train_loss = 1.43553781, grad/param norm = 5.1343e-01, time/batch = 0.1052s	
2454/2700 (epoch 45.444), train_loss = 1.39192720, grad/param norm = 4.8030e-01, time/batch = 0.1491s	
2455/2700 (epoch 45.463), train_loss = 1.42546506, grad/param norm = 4.9286e-01, time/batch = 0.1502s	
2456/2700 (epoch 45.481), train_loss = 1.43132817, grad/param norm = 4.9932e-01, time/batch = 0.1481s	
2457/2700 (epoch 45.500), train_loss = 1.36830880, grad/param norm = 5.3317e-01, time/batch = 0.1479s	
2458/2700 (epoch 45.519), train_loss = 1.41870435, grad/param norm = 4.9280e-01, time/batch = 0.1499s	
2459/2700 (epoch 45.537), train_loss = 1.43412543, grad/param norm = 5.0957e-01, time/batch = 0.1416s	
2460/2700 (epoch 45.556), train_loss = 1.34553520, grad/param norm = 4.8347e-01, time/batch = 0.1333s	
2461/2700 (epoch 45.574), train_loss = 1.35217583, grad/param norm = 5.4155e-01, time/batch = 0.1240s	
2462/2700 (epoch 45.593), train_loss = 1.36465247, grad/param norm = 5.1119e-01, time/batch = 0.1165s	
2463/2700 (epoch 45.611), train_loss = 1.33176152, grad/param norm = 4.7973e-01, time/batch = 0.1103s	
2464/2700 (epoch 45.630), train_loss = 1.34228567, grad/param norm = 4.9882e-01, time/batch = 0.1387s	
2465/2700 (epoch 45.648), train_loss = 1.37277754, grad/param norm = 4.7705e-01, time/batch = 0.1376s	
2466/2700 (epoch 45.667), train_loss = 1.35505578, grad/param norm = 5.3652e-01, time/batch = 0.1378s	
2467/2700 (epoch 45.685), train_loss = 1.40690871, grad/param norm = 5.4835e-01, time/batch = 0.1375s	
2468/2700 (epoch 45.704), train_loss = 1.42816088, grad/param norm = 5.4406e-01, time/batch = 0.1384s	
2469/2700 (epoch 45.722), train_loss = 1.39063014, grad/param norm = 5.1156e-01, time/batch = 0.1405s	
2470/2700 (epoch 45.741), train_loss = 1.38175970, grad/param norm = 5.0537e-01, time/batch = 0.1396s	
2471/2700 (epoch 45.759), train_loss = 1.39549537, grad/param norm = 5.2259e-01, time/batch = 0.1337s	
2472/2700 (epoch 45.778), train_loss = 1.42307876, grad/param norm = 5.3433e-01, time/batch = 0.1273s	
2473/2700 (epoch 45.796), train_loss = 1.38243582, grad/param norm = 5.0151e-01, time/batch = 0.1144s	
2474/2700 (epoch 45.815), train_loss = 1.42069154, grad/param norm = 5.3395e-01, time/batch = 0.1427s	
2475/2700 (epoch 45.833), train_loss = 1.38025394, grad/param norm = 5.0353e-01, time/batch = 0.1404s	
2476/2700 (epoch 45.852), train_loss = 1.36394305, grad/param norm = 4.9561e-01, time/batch = 0.1396s	
2477/2700 (epoch 45.870), train_loss = 1.38606781, grad/param norm = 4.9578e-01, time/batch = 0.1375s	
2478/2700 (epoch 45.889), train_loss = 1.39628531, grad/param norm = 5.1215e-01, time/batch = 0.1392s	
2479/2700 (epoch 45.907), train_loss = 1.47840563, grad/param norm = 5.1362e-01, time/batch = 0.1398s	
2480/2700 (epoch 45.926), train_loss = 1.40966952, grad/param norm = 4.8795e-01, time/batch = 0.1414s	
2481/2700 (epoch 45.944), train_loss = 1.39737309, grad/param norm = 5.3199e-01, time/batch = 0.1316s	
2482/2700 (epoch 45.963), train_loss = 1.41002731, grad/param norm = 4.9893e-01, time/batch = 0.1263s	
2483/2700 (epoch 45.981), train_loss = 1.39035284, grad/param norm = 5.1795e-01, time/batch = 0.0872s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
2484/2700 (epoch 46.000), train_loss = 1.47280308, grad/param norm = 5.4415e-01, time/batch = 0.1215s	
2485/2700 (epoch 46.019), train_loss = 1.44091351, grad/param norm = 5.3400e-01, time/batch = 0.1120s	
2486/2700 (epoch 46.037), train_loss = 1.44255294, grad/param norm = 5.2928e-01, time/batch = 0.1037s	
2487/2700 (epoch 46.056), train_loss = 1.38656022, grad/param norm = 4.9403e-01, time/batch = 0.1013s	
2488/2700 (epoch 46.074), train_loss = 1.39849683, grad/param norm = 5.1853e-01, time/batch = 0.1257s	
2489/2700 (epoch 46.093), train_loss = 1.37300646, grad/param norm = 5.1438e-01, time/batch = 0.1305s	
2490/2700 (epoch 46.111), train_loss = 1.34079760, grad/param norm = 4.9166e-01, time/batch = 0.1347s	
2491/2700 (epoch 46.130), train_loss = 1.39466039, grad/param norm = 5.1841e-01, time/batch = 0.1400s	
2492/2700 (epoch 46.148), train_loss = 1.34768343, grad/param norm = 4.8526e-01, time/batch = 0.1418s	
2493/2700 (epoch 46.167), train_loss = 1.45673470, grad/param norm = 5.5687e-01, time/batch = 0.1435s	
2494/2700 (epoch 46.185), train_loss = 1.35370481, grad/param norm = 4.7120e-01, time/batch = 0.1172s	
2495/2700 (epoch 46.204), train_loss = 1.44274373, grad/param norm = 5.2237e-01, time/batch = 0.1406s	
2496/2700 (epoch 46.222), train_loss = 1.34777545, grad/param norm = 5.2880e-01, time/batch = 0.1351s	
2497/2700 (epoch 46.241), train_loss = 1.30419297, grad/param norm = 5.0306e-01, time/batch = 0.1319s	
2498/2700 (epoch 46.259), train_loss = 1.36549087, grad/param norm = 5.1086e-01, time/batch = 0.1339s	
2499/2700 (epoch 46.278), train_loss = 1.45206147, grad/param norm = 5.1803e-01, time/batch = 0.1304s	
2500/2700 (epoch 46.296), train_loss = 1.40136054, grad/param norm = 4.8114e-01, time/batch = 0.1293s	
2501/2700 (epoch 46.315), train_loss = 1.38668325, grad/param norm = 5.0512e-01, time/batch = 0.1478s	
2502/2700 (epoch 46.333), train_loss = 1.41070770, grad/param norm = 5.0573e-01, time/batch = 0.1508s	
2503/2700 (epoch 46.352), train_loss = 1.39586558, grad/param norm = 5.0656e-01, time/batch = 0.1414s	
2504/2700 (epoch 46.370), train_loss = 1.41284823, grad/param norm = 5.5376e-01, time/batch = 0.1486s	
2505/2700 (epoch 46.389), train_loss = 1.37124368, grad/param norm = 4.9683e-01, time/batch = 0.1440s	
2506/2700 (epoch 46.407), train_loss = 1.42234966, grad/param norm = 5.0072e-01, time/batch = 0.1366s	
2507/2700 (epoch 46.426), train_loss = 1.42963139, grad/param norm = 5.1769e-01, time/batch = 0.1367s	
2508/2700 (epoch 46.444), train_loss = 1.38706112, grad/param norm = 4.8139e-01, time/batch = 0.1378s	
2509/2700 (epoch 46.463), train_loss = 1.42022349, grad/param norm = 4.9672e-01, time/batch = 0.1401s	
2510/2700 (epoch 46.481), train_loss = 1.42543501, grad/param norm = 5.0030e-01, time/batch = 0.1396s	
2511/2700 (epoch 46.500), train_loss = 1.36250277, grad/param norm = 5.3386e-01, time/batch = 0.1417s	
2512/2700 (epoch 46.519), train_loss = 1.41314547, grad/param norm = 4.9340e-01, time/batch = 0.1473s	
2513/2700 (epoch 46.537), train_loss = 1.42852998, grad/param norm = 5.1231e-01, time/batch = 0.1303s	
2514/2700 (epoch 46.556), train_loss = 1.34006440, grad/param norm = 4.8464e-01, time/batch = 0.1224s	
2515/2700 (epoch 46.574), train_loss = 1.34670827, grad/param norm = 5.4236e-01, time/batch = 0.1217s	
2516/2700 (epoch 46.593), train_loss = 1.35953726, grad/param norm = 5.1266e-01, time/batch = 0.1261s	
2517/2700 (epoch 46.611), train_loss = 1.32691830, grad/param norm = 4.7997e-01, time/batch = 0.1312s	
2518/2700 (epoch 46.630), train_loss = 1.33693197, grad/param norm = 5.0522e-01, time/batch = 0.1383s	
2519/2700 (epoch 46.648), train_loss = 1.36686715, grad/param norm = 4.7637e-01, time/batch = 0.1369s	
2520/2700 (epoch 46.667), train_loss = 1.35001652, grad/param norm = 5.3903e-01, time/batch = 0.1306s	
2521/2700 (epoch 46.685), train_loss = 1.40187180, grad/param norm = 5.5051e-01, time/batch = 0.1467s	
2522/2700 (epoch 46.704), train_loss = 1.42262033, grad/param norm = 5.4540e-01, time/batch = 0.1466s	
2523/2700 (epoch 46.722), train_loss = 1.38523491, grad/param norm = 5.1502e-01, time/batch = 0.1368s	
2524/2700 (epoch 46.741), train_loss = 1.37640316, grad/param norm = 5.0912e-01, time/batch = 0.1103s	
2525/2700 (epoch 46.759), train_loss = 1.38980328, grad/param norm = 5.2386e-01, time/batch = 0.1211s	
2526/2700 (epoch 46.778), train_loss = 1.41728318, grad/param norm = 5.3758e-01, time/batch = 0.1290s	
2527/2700 (epoch 46.796), train_loss = 1.37670070, grad/param norm = 5.0245e-01, time/batch = 0.1396s	
2528/2700 (epoch 46.815), train_loss = 1.41508672, grad/param norm = 5.3707e-01, time/batch = 0.1405s	
2529/2700 (epoch 46.833), train_loss = 1.37485930, grad/param norm = 5.0422e-01, time/batch = 0.1307s	
2530/2700 (epoch 46.852), train_loss = 1.35808519, grad/param norm = 4.9657e-01, time/batch = 0.1373s	
2531/2700 (epoch 46.870), train_loss = 1.38047305, grad/param norm = 4.9885e-01, time/batch = 0.1484s	
2532/2700 (epoch 46.889), train_loss = 1.39107360, grad/param norm = 5.1372e-01, time/batch = 0.1331s	
2533/2700 (epoch 46.907), train_loss = 1.47229946, grad/param norm = 5.1344e-01, time/batch = 0.1328s	
2534/2700 (epoch 46.926), train_loss = 1.40414574, grad/param norm = 4.9250e-01, time/batch = 0.1261s	
2535/2700 (epoch 46.944), train_loss = 1.39206664, grad/param norm = 5.3519e-01, time/batch = 0.1379s	
2536/2700 (epoch 46.963), train_loss = 1.40424028, grad/param norm = 5.0041e-01, time/batch = 0.1354s	
2537/2700 (epoch 46.981), train_loss = 1.38469495, grad/param norm = 5.1947e-01, time/batch = 0.1303s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
2538/2700 (epoch 47.000), train_loss = 1.46704545, grad/param norm = 5.4463e-01, time/batch = 0.0997s	
2539/2700 (epoch 47.019), train_loss = 1.43621742, grad/param norm = 5.3768e-01, time/batch = 0.1257s	
2540/2700 (epoch 47.037), train_loss = 1.43650286, grad/param norm = 5.2262e-01, time/batch = 0.1340s	
2541/2700 (epoch 47.056), train_loss = 1.38122439, grad/param norm = 4.9994e-01, time/batch = 0.1323s	
2542/2700 (epoch 47.074), train_loss = 1.39388920, grad/param norm = 5.2231e-01, time/batch = 0.1244s	
2543/2700 (epoch 47.093), train_loss = 1.36764840, grad/param norm = 5.1221e-01, time/batch = 0.1302s	
2544/2700 (epoch 47.111), train_loss = 1.33545295, grad/param norm = 4.9776e-01, time/batch = 0.1325s	
2545/2700 (epoch 47.130), train_loss = 1.38901211, grad/param norm = 5.2121e-01, time/batch = 0.1115s	
2546/2700 (epoch 47.148), train_loss = 1.34256576, grad/param norm = 4.8784e-01, time/batch = 0.1506s	
2547/2700 (epoch 47.167), train_loss = 1.45132978, grad/param norm = 5.6392e-01, time/batch = 0.1477s	
2548/2700 (epoch 47.185), train_loss = 1.34883643, grad/param norm = 4.7389e-01, time/batch = 0.1524s	
2549/2700 (epoch 47.204), train_loss = 1.43720597, grad/param norm = 5.2214e-01, time/batch = 0.1457s	
2550/2700 (epoch 47.222), train_loss = 1.34262731, grad/param norm = 5.3254e-01, time/batch = 0.1328s	
2551/2700 (epoch 47.241), train_loss = 1.29961570, grad/param norm = 5.0486e-01, time/batch = 0.1414s	
2552/2700 (epoch 47.259), train_loss = 1.36023879, grad/param norm = 5.0840e-01, time/batch = 0.1484s	
2553/2700 (epoch 47.278), train_loss = 1.44708549, grad/param norm = 5.2028e-01, time/batch = 0.1323s	
2554/2700 (epoch 47.296), train_loss = 1.39590892, grad/param norm = 4.8377e-01, time/batch = 0.1294s	
2555/2700 (epoch 47.315), train_loss = 1.38087798, grad/param norm = 5.0637e-01, time/batch = 0.1160s	
2556/2700 (epoch 47.333), train_loss = 1.40524350, grad/param norm = 5.0737e-01, time/batch = 0.1159s	
2557/2700 (epoch 47.352), train_loss = 1.39021071, grad/param norm = 5.0769e-01, time/batch = 0.1182s	
2558/2700 (epoch 47.370), train_loss = 1.40746121, grad/param norm = 5.5081e-01, time/batch = 0.1140s	
2559/2700 (epoch 47.389), train_loss = 1.36524988, grad/param norm = 4.9910e-01, time/batch = 0.1203s	
2560/2700 (epoch 47.407), train_loss = 1.41671530, grad/param norm = 5.0221e-01, time/batch = 0.1267s	
2561/2700 (epoch 47.426), train_loss = 1.42376305, grad/param norm = 5.1931e-01, time/batch = 0.1420s	
2562/2700 (epoch 47.444), train_loss = 1.38229249, grad/param norm = 4.8250e-01, time/batch = 0.1374s	
2563/2700 (epoch 47.463), train_loss = 1.41514963, grad/param norm = 5.0029e-01, time/batch = 0.1295s	
2564/2700 (epoch 47.481), train_loss = 1.41962301, grad/param norm = 5.0130e-01, time/batch = 0.1320s	
2565/2700 (epoch 47.500), train_loss = 1.35673603, grad/param norm = 5.3441e-01, time/batch = 0.1009s	
2566/2700 (epoch 47.519), train_loss = 1.40777909, grad/param norm = 4.9442e-01, time/batch = 0.0853s	
2567/2700 (epoch 47.537), train_loss = 1.42314050, grad/param norm = 5.1526e-01, time/batch = 0.1129s	
2568/2700 (epoch 47.556), train_loss = 1.33486878, grad/param norm = 4.8686e-01, time/batch = 0.1060s	
2569/2700 (epoch 47.574), train_loss = 1.34151190, grad/param norm = 5.4348e-01, time/batch = 0.1060s	
2570/2700 (epoch 47.593), train_loss = 1.35447569, grad/param norm = 5.1473e-01, time/batch = 0.1047s	
2571/2700 (epoch 47.611), train_loss = 1.32224902, grad/param norm = 4.8074e-01, time/batch = 0.1203s	
2572/2700 (epoch 47.630), train_loss = 1.33179197, grad/param norm = 5.1087e-01, time/batch = 0.1115s	
2573/2700 (epoch 47.648), train_loss = 1.36120689, grad/param norm = 4.7607e-01, time/batch = 0.1070s	
2574/2700 (epoch 47.667), train_loss = 1.34506322, grad/param norm = 5.4204e-01, time/batch = 0.1094s	
2575/2700 (epoch 47.685), train_loss = 1.39709719, grad/param norm = 5.5342e-01, time/batch = 0.1141s	
2576/2700 (epoch 47.704), train_loss = 1.41720784, grad/param norm = 5.4704e-01, time/batch = 0.1007s	
2577/2700 (epoch 47.722), train_loss = 1.38008845, grad/param norm = 5.1850e-01, time/batch = 0.1211s	
2578/2700 (epoch 47.741), train_loss = 1.37112744, grad/param norm = 5.1204e-01, time/batch = 0.1094s	
2579/2700 (epoch 47.759), train_loss = 1.38423599, grad/param norm = 5.2416e-01, time/batch = 0.1097s	
2580/2700 (epoch 47.778), train_loss = 1.41163410, grad/param norm = 5.4182e-01, time/batch = 0.1184s	
2581/2700 (epoch 47.796), train_loss = 1.37124297, grad/param norm = 5.0485e-01, time/batch = 0.1069s	
2582/2700 (epoch 47.815), train_loss = 1.40958263, grad/param norm = 5.3918e-01, time/batch = 0.1134s	
2583/2700 (epoch 47.833), train_loss = 1.36962971, grad/param norm = 5.0507e-01, time/batch = 0.1224s	
2584/2700 (epoch 47.852), train_loss = 1.35238543, grad/param norm = 4.9768e-01, time/batch = 0.1299s	
2585/2700 (epoch 47.870), train_loss = 1.37500318, grad/param norm = 5.0155e-01, time/batch = 0.1295s	
2586/2700 (epoch 47.889), train_loss = 1.38603766, grad/param norm = 5.1551e-01, time/batch = 0.1293s	
2587/2700 (epoch 47.907), train_loss = 1.46642539, grad/param norm = 5.1323e-01, time/batch = 0.1121s	
2588/2700 (epoch 47.926), train_loss = 1.39869517, grad/param norm = 4.9713e-01, time/batch = 0.1208s	
2589/2700 (epoch 47.944), train_loss = 1.38691650, grad/param norm = 5.3790e-01, time/batch = 0.1000s	
2590/2700 (epoch 47.963), train_loss = 1.39866597, grad/param norm = 5.0196e-01, time/batch = 0.1021s	
2591/2700 (epoch 47.981), train_loss = 1.37929099, grad/param norm = 5.2124e-01, time/batch = 0.1347s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
2592/2700 (epoch 48.000), train_loss = 1.46153977, grad/param norm = 5.4459e-01, time/batch = 0.1245s	
2593/2700 (epoch 48.019), train_loss = 1.43012234, grad/param norm = 5.3533e-01, time/batch = 0.1178s	
2594/2700 (epoch 48.037), train_loss = 1.43063992, grad/param norm = 5.2531e-01, time/batch = 0.1254s	
2595/2700 (epoch 48.056), train_loss = 1.37585146, grad/param norm = 5.0168e-01, time/batch = 0.1314s	
2596/2700 (epoch 48.074), train_loss = 1.38812024, grad/param norm = 5.2404e-01, time/batch = 0.1368s	
2597/2700 (epoch 48.093), train_loss = 1.36311690, grad/param norm = 5.2091e-01, time/batch = 0.1264s	
2598/2700 (epoch 48.111), train_loss = 1.33015020, grad/param norm = 4.9519e-01, time/batch = 0.1393s	
2599/2700 (epoch 48.130), train_loss = 1.38368155, grad/param norm = 5.2708e-01, time/batch = 0.1198s	
2600/2700 (epoch 48.148), train_loss = 1.33761820, grad/param norm = 4.9128e-01, time/batch = 0.1491s	
2601/2700 (epoch 48.167), train_loss = 1.44603951, grad/param norm = 5.6624e-01, time/batch = 0.1389s	
2602/2700 (epoch 48.185), train_loss = 1.34404475, grad/param norm = 4.7918e-01, time/batch = 0.1275s	
2603/2700 (epoch 48.204), train_loss = 1.43192611, grad/param norm = 5.2412e-01, time/batch = 0.1324s	
2604/2700 (epoch 48.222), train_loss = 1.33765014, grad/param norm = 5.3664e-01, time/batch = 0.1371s	
2605/2700 (epoch 48.241), train_loss = 1.29520586, grad/param norm = 5.0706e-01, time/batch = 0.1418s	
2606/2700 (epoch 48.259), train_loss = 1.35499643, grad/param norm = 5.0628e-01, time/batch = 0.1328s	
2607/2700 (epoch 48.278), train_loss = 1.44218475, grad/param norm = 5.2254e-01, time/batch = 0.1324s	
2608/2700 (epoch 48.296), train_loss = 1.39075631, grad/param norm = 4.8668e-01, time/batch = 0.1334s	
2609/2700 (epoch 48.315), train_loss = 1.37521902, grad/param norm = 5.0854e-01, time/batch = 0.1328s	
2610/2700 (epoch 48.333), train_loss = 1.39984705, grad/param norm = 5.0799e-01, time/batch = 0.1000s	
2611/2700 (epoch 48.352), train_loss = 1.38486488, grad/param norm = 5.0979e-01, time/batch = 0.1418s	
2612/2700 (epoch 48.370), train_loss = 1.40217832, grad/param norm = 5.4995e-01, time/batch = 0.1261s	
2613/2700 (epoch 48.389), train_loss = 1.35951882, grad/param norm = 5.0045e-01, time/batch = 0.1286s	
2614/2700 (epoch 48.407), train_loss = 1.41134622, grad/param norm = 5.0480e-01, time/batch = 0.1347s	
2615/2700 (epoch 48.426), train_loss = 1.41819042, grad/param norm = 5.2227e-01, time/batch = 0.1199s	
2616/2700 (epoch 48.444), train_loss = 1.37770554, grad/param norm = 4.8406e-01, time/batch = 0.1328s	
2617/2700 (epoch 48.463), train_loss = 1.41032675, grad/param norm = 5.0406e-01, time/batch = 0.1233s	
2618/2700 (epoch 48.481), train_loss = 1.41407312, grad/param norm = 5.0236e-01, time/batch = 0.1188s	
2619/2700 (epoch 48.500), train_loss = 1.35131406, grad/param norm = 5.3558e-01, time/batch = 0.1163s	
2620/2700 (epoch 48.519), train_loss = 1.40257140, grad/param norm = 4.9546e-01, time/batch = 0.1266s	
2621/2700 (epoch 48.537), train_loss = 1.41790339, grad/param norm = 5.1791e-01, time/batch = 0.1170s	
2622/2700 (epoch 48.556), train_loss = 1.32985391, grad/param norm = 4.8870e-01, time/batch = 0.1337s	
2623/2700 (epoch 48.574), train_loss = 1.33646636, grad/param norm = 5.4434e-01, time/batch = 0.1273s	
2624/2700 (epoch 48.593), train_loss = 1.34978158, grad/param norm = 5.1602e-01, time/batch = 0.1226s	
2625/2700 (epoch 48.611), train_loss = 1.31770379, grad/param norm = 4.8144e-01, time/batch = 0.1446s	
2626/2700 (epoch 48.630), train_loss = 1.32681949, grad/param norm = 5.1675e-01, time/batch = 0.1335s	
2627/2700 (epoch 48.648), train_loss = 1.35572921, grad/param norm = 4.7573e-01, time/batch = 0.1205s	
2628/2700 (epoch 48.667), train_loss = 1.34037417, grad/param norm = 5.4473e-01, time/batch = 0.1210s	
2629/2700 (epoch 48.685), train_loss = 1.39237221, grad/param norm = 5.5541e-01, time/batch = 0.1194s	
2630/2700 (epoch 48.704), train_loss = 1.41201701, grad/param norm = 5.4843e-01, time/batch = 0.1263s	
2631/2700 (epoch 48.722), train_loss = 1.37511048, grad/param norm = 5.2195e-01, time/batch = 0.1444s	
2632/2700 (epoch 48.741), train_loss = 1.36606538, grad/param norm = 5.1518e-01, time/batch = 0.1190s	
2633/2700 (epoch 48.759), train_loss = 1.37888601, grad/param norm = 5.2537e-01, time/batch = 0.1084s	
2634/2700 (epoch 48.778), train_loss = 1.40619319, grad/param norm = 5.4498e-01, time/batch = 0.1321s	
2635/2700 (epoch 48.796), train_loss = 1.36595751, grad/param norm = 5.0583e-01, time/batch = 0.1347s	
2636/2700 (epoch 48.815), train_loss = 1.40433710, grad/param norm = 5.4239e-01, time/batch = 0.1383s	
2637/2700 (epoch 48.833), train_loss = 1.36469749, grad/param norm = 5.0647e-01, time/batch = 0.1403s	
2638/2700 (epoch 48.852), train_loss = 1.34686430, grad/param norm = 4.9855e-01, time/batch = 0.1244s	
2639/2700 (epoch 48.870), train_loss = 1.36971457, grad/param norm = 5.0454e-01, time/batch = 0.1233s	
2640/2700 (epoch 48.889), train_loss = 1.38116068, grad/param norm = 5.1731e-01, time/batch = 0.1279s	
2641/2700 (epoch 48.907), train_loss = 1.46075973, grad/param norm = 5.1317e-01, time/batch = 0.1461s	
2642/2700 (epoch 48.926), train_loss = 1.39354177, grad/param norm = 5.0234e-01, time/batch = 0.1176s	
2643/2700 (epoch 48.944), train_loss = 1.38199520, grad/param norm = 5.4069e-01, time/batch = 0.1420s	
2644/2700 (epoch 48.963), train_loss = 1.39327888, grad/param norm = 5.0407e-01, time/batch = 0.1387s	
2645/2700 (epoch 48.981), train_loss = 1.37408249, grad/param norm = 5.2266e-01, time/batch = 0.1366s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
2646/2700 (epoch 49.000), train_loss = 1.45626597, grad/param norm = 5.4526e-01, time/batch = 0.1407s	
2647/2700 (epoch 49.019), train_loss = 1.42542251, grad/param norm = 5.4353e-01, time/batch = 0.1382s	
2648/2700 (epoch 49.037), train_loss = 1.42512415, grad/param norm = 5.2335e-01, time/batch = 0.1192s	
2649/2700 (epoch 49.056), train_loss = 1.37102436, grad/param norm = 5.0787e-01, time/batch = 0.1090s	
2650/2700 (epoch 49.074), train_loss = 1.38368970, grad/param norm = 5.2856e-01, time/batch = 0.1153s	
2651/2700 (epoch 49.093), train_loss = 1.35824924, grad/param norm = 5.2108e-01, time/batch = 0.1178s	
2652/2700 (epoch 49.111), train_loss = 1.32513099, grad/param norm = 4.9906e-01, time/batch = 0.0960s	
2653/2700 (epoch 49.130), train_loss = 1.37850053, grad/param norm = 5.3091e-01, time/batch = 0.1142s	
2654/2700 (epoch 49.148), train_loss = 1.33289397, grad/param norm = 4.9472e-01, time/batch = 0.1065s	
2655/2700 (epoch 49.167), train_loss = 1.44089452, grad/param norm = 5.7150e-01, time/batch = 0.1028s	
2656/2700 (epoch 49.185), train_loss = 1.33947549, grad/param norm = 4.8229e-01, time/batch = 0.1062s	
2657/2700 (epoch 49.204), train_loss = 1.42668815, grad/param norm = 5.2474e-01, time/batch = 0.1124s	
2658/2700 (epoch 49.222), train_loss = 1.33283651, grad/param norm = 5.3973e-01, time/batch = 0.1166s	
2659/2700 (epoch 49.241), train_loss = 1.29091762, grad/param norm = 5.0862e-01, time/batch = 0.1158s	
2660/2700 (epoch 49.259), train_loss = 1.35002855, grad/param norm = 5.0464e-01, time/batch = 0.1183s	
2661/2700 (epoch 49.278), train_loss = 1.43756735, grad/param norm = 5.2473e-01, time/batch = 0.1255s	
2662/2700 (epoch 49.296), train_loss = 1.38573278, grad/param norm = 4.9005e-01, time/batch = 0.1189s	
2663/2700 (epoch 49.315), train_loss = 1.36978694, grad/param norm = 5.0940e-01, time/batch = 0.1096s	
2664/2700 (epoch 49.333), train_loss = 1.39470462, grad/param norm = 5.0994e-01, time/batch = 0.1056s	
2665/2700 (epoch 49.352), train_loss = 1.37945545, grad/param norm = 5.1065e-01, time/batch = 0.1000s	
2666/2700 (epoch 49.370), train_loss = 1.39715287, grad/param norm = 5.4807e-01, time/batch = 0.1047s	
2667/2700 (epoch 49.389), train_loss = 1.35402235, grad/param norm = 5.0311e-01, time/batch = 0.1091s	
2668/2700 (epoch 49.407), train_loss = 1.40612725, grad/param norm = 5.0674e-01, time/batch = 0.1150s	
2669/2700 (epoch 49.426), train_loss = 1.41268940, grad/param norm = 5.2348e-01, time/batch = 0.1177s	
2670/2700 (epoch 49.444), train_loss = 1.37324193, grad/param norm = 4.8579e-01, time/batch = 0.1174s	
2671/2700 (epoch 49.463), train_loss = 1.40564514, grad/param norm = 5.0757e-01, time/batch = 0.1259s	
2672/2700 (epoch 49.481), train_loss = 1.40860678, grad/param norm = 5.0341e-01, time/batch = 0.1178s	
2673/2700 (epoch 49.500), train_loss = 1.34598943, grad/param norm = 5.3675e-01, time/batch = 0.1157s	
2674/2700 (epoch 49.519), train_loss = 1.39752905, grad/param norm = 4.9676e-01, time/batch = 0.1107s	
2675/2700 (epoch 49.537), train_loss = 1.41283478, grad/param norm = 5.2050e-01, time/batch = 0.1083s	
2676/2700 (epoch 49.556), train_loss = 1.32505597, grad/param norm = 4.9121e-01, time/batch = 0.1010s	
2677/2700 (epoch 49.574), train_loss = 1.33162974, grad/param norm = 5.4536e-01, time/batch = 0.1069s	
2678/2700 (epoch 49.593), train_loss = 1.34517055, grad/param norm = 5.1763e-01, time/batch = 0.1123s	
2679/2700 (epoch 49.611), train_loss = 1.31330293, grad/param norm = 4.8247e-01, time/batch = 0.1176s	
2680/2700 (epoch 49.630), train_loss = 1.32201662, grad/param norm = 5.2192e-01, time/batch = 0.1193s	
2681/2700 (epoch 49.648), train_loss = 1.35047272, grad/param norm = 4.7573e-01, time/batch = 0.1198s	
2682/2700 (epoch 49.667), train_loss = 1.33578539, grad/param norm = 5.4769e-01, time/batch = 0.1178s	
2683/2700 (epoch 49.685), train_loss = 1.38782488, grad/param norm = 5.5770e-01, time/batch = 0.1181s	
2684/2700 (epoch 49.704), train_loss = 1.40697039, grad/param norm = 5.4995e-01, time/batch = 0.1173s	
2685/2700 (epoch 49.722), train_loss = 1.37033919, grad/param norm = 5.2548e-01, time/batch = 0.1138s	
2686/2700 (epoch 49.741), train_loss = 1.36110708, grad/param norm = 5.1769e-01, time/batch = 0.1035s	
2687/2700 (epoch 49.759), train_loss = 1.37365430, grad/param norm = 5.2593e-01, time/batch = 0.1029s	
2688/2700 (epoch 49.778), train_loss = 1.40089571, grad/param norm = 5.4887e-01, time/batch = 0.1067s	
2689/2700 (epoch 49.796), train_loss = 1.36089557, grad/param norm = 5.0777e-01, time/batch = 0.1096s	
2690/2700 (epoch 49.815), train_loss = 1.39921016, grad/param norm = 5.4489e-01, time/batch = 0.1169s	
2691/2700 (epoch 49.833), train_loss = 1.35994278, grad/param norm = 5.0803e-01, time/batch = 0.1179s	
2692/2700 (epoch 49.852), train_loss = 1.34149732, grad/param norm = 4.9937e-01, time/batch = 0.1178s	
2693/2700 (epoch 49.870), train_loss = 1.36455647, grad/param norm = 5.0734e-01, time/batch = 0.1185s	
2694/2700 (epoch 49.889), train_loss = 1.37642898, grad/param norm = 5.1935e-01, time/batch = 0.1177s	
2695/2700 (epoch 49.907), train_loss = 1.45530382, grad/param norm = 5.1305e-01, time/batch = 0.1172s	
2696/2700 (epoch 49.926), train_loss = 1.38846158, grad/param norm = 5.0744e-01, time/batch = 0.1152s	
2697/2700 (epoch 49.944), train_loss = 1.37721329, grad/param norm = 5.4284e-01, time/batch = 0.0910s	
2698/2700 (epoch 49.963), train_loss = 1.38806590, grad/param norm = 5.0633e-01, time/batch = 0.1126s	
2699/2700 (epoch 49.981), train_loss = 1.36908396, grad/param norm = 5.2440e-01, time/batch = 0.1154s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch50.00_1.7463.t7	
2700/2700 (epoch 50.000), train_loss = 1.45120783, grad/param norm = 5.4576e-01, time/batch = 0.1180s	
