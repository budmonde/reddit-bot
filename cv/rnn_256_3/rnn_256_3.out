using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 54, val: 3, test: 0	
vocab size: 91	
creating an rnn with 3 layers	
number of parameters in the model: 375899	
cloning rnn	
cloning criterion	
1/2700 (epoch 0.019), train_loss = 4.55992363, grad/param norm = 2.1392e+00, time/batch = 0.2226s	
2/2700 (epoch 0.037), train_loss = 4.09023944, grad/param norm = 6.1456e+00, time/batch = 0.0610s	
3/2700 (epoch 0.056), train_loss = 3.76582830, grad/param norm = 6.0924e+00, time/batch = 0.0602s	
4/2700 (epoch 0.074), train_loss = 4.08432559, grad/param norm = 4.7007e+00, time/batch = 0.0594s	
5/2700 (epoch 0.093), train_loss = 4.65190527, grad/param norm = 8.7386e+00, time/batch = 0.0571s	
6/2700 (epoch 0.111), train_loss = 6.11479930, grad/param norm = 1.4940e+01, time/batch = 0.0569s	
7/2700 (epoch 0.130), train_loss = 3.41997496, grad/param norm = 2.6971e+00, time/batch = 0.0544s	
8/2700 (epoch 0.148), train_loss = 4.30226946, grad/param norm = 1.1879e+01, time/batch = 0.0546s	
9/2700 (epoch 0.167), train_loss = 3.39642835, grad/param norm = 3.4542e+00, time/batch = 0.0549s	
10/2700 (epoch 0.185), train_loss = 3.48160231, grad/param norm = 3.8180e+00, time/batch = 0.0528s	
11/2700 (epoch 0.204), train_loss = 3.36971330, grad/param norm = 4.7296e+00, time/batch = 0.0529s	
12/2700 (epoch 0.222), train_loss = 3.25977437, grad/param norm = 2.3851e+00, time/batch = 0.0514s	
13/2700 (epoch 0.241), train_loss = 3.20228326, grad/param norm = 1.2825e+00, time/batch = 0.0511s	
14/2700 (epoch 0.259), train_loss = 3.22659900, grad/param norm = 1.0384e+00, time/batch = 0.0512s	
15/2700 (epoch 0.278), train_loss = 3.30190671, grad/param norm = 1.2298e+00, time/batch = 0.0512s	
16/2700 (epoch 0.296), train_loss = 3.30927593, grad/param norm = 1.3936e+00, time/batch = 0.0522s	
17/2700 (epoch 0.315), train_loss = 3.28289713, grad/param norm = 1.3332e+00, time/batch = 0.0515s	
18/2700 (epoch 0.333), train_loss = 3.36650566, grad/param norm = 1.2137e+00, time/batch = 0.0513s	
19/2700 (epoch 0.352), train_loss = 3.36217477, grad/param norm = 1.2854e+00, time/batch = 0.0512s	
20/2700 (epoch 0.370), train_loss = 3.30763472, grad/param norm = 1.2808e+00, time/batch = 0.0512s	
21/2700 (epoch 0.389), train_loss = 3.27123311, grad/param norm = 1.2170e+00, time/batch = 0.0512s	
22/2700 (epoch 0.407), train_loss = 3.28859209, grad/param norm = 9.7396e-01, time/batch = 0.0511s	
23/2700 (epoch 0.426), train_loss = 3.29437390, grad/param norm = 1.0748e+00, time/batch = 0.0519s	
24/2700 (epoch 0.444), train_loss = 3.22111097, grad/param norm = 1.0082e+00, time/batch = 0.0514s	
25/2700 (epoch 0.463), train_loss = 3.26395413, grad/param norm = 1.0334e+00, time/batch = 0.0514s	
26/2700 (epoch 0.481), train_loss = 3.33826102, grad/param norm = 1.0191e+00, time/batch = 0.0512s	
27/2700 (epoch 0.500), train_loss = 3.38121602, grad/param norm = 1.2176e+00, time/batch = 0.0514s	
28/2700 (epoch 0.519), train_loss = 3.34170693, grad/param norm = 1.2517e+00, time/batch = 0.0513s	
29/2700 (epoch 0.537), train_loss = 3.34825446, grad/param norm = 1.4077e+00, time/batch = 0.0512s	
30/2700 (epoch 0.556), train_loss = 3.29826410, grad/param norm = 1.3403e+00, time/batch = 0.0519s	
31/2700 (epoch 0.574), train_loss = 3.24215415, grad/param norm = 1.1289e+00, time/batch = 0.0521s	
32/2700 (epoch 0.593), train_loss = 3.24362446, grad/param norm = 1.4088e+00, time/batch = 0.0511s	
33/2700 (epoch 0.611), train_loss = 3.19020230, grad/param norm = 1.4263e+00, time/batch = 0.0509s	
34/2700 (epoch 0.630), train_loss = 3.23424202, grad/param norm = 1.7774e+00, time/batch = 0.0511s	
35/2700 (epoch 0.648), train_loss = 3.31400619, grad/param norm = 2.3835e+00, time/batch = 0.0511s	
36/2700 (epoch 0.667), train_loss = 3.26804624, grad/param norm = 2.5530e+00, time/batch = 0.0512s	
37/2700 (epoch 0.685), train_loss = 3.24613920, grad/param norm = 2.1551e+00, time/batch = 0.0521s	
38/2700 (epoch 0.704), train_loss = 3.22649016, grad/param norm = 2.2560e+00, time/batch = 0.0512s	
39/2700 (epoch 0.722), train_loss = 3.21562082, grad/param norm = 1.9641e+00, time/batch = 0.0513s	
40/2700 (epoch 0.741), train_loss = 3.34702511, grad/param norm = 1.7139e+00, time/batch = 0.0512s	
41/2700 (epoch 0.759), train_loss = 3.29550614, grad/param norm = 1.8551e+00, time/batch = 0.0520s	
42/2700 (epoch 0.778), train_loss = 3.29480901, grad/param norm = 2.1341e+00, time/batch = 0.0509s	
43/2700 (epoch 0.796), train_loss = 3.28779643, grad/param norm = 1.9926e+00, time/batch = 0.0517s	
44/2700 (epoch 0.815), train_loss = 3.22505926, grad/param norm = 1.8531e+00, time/batch = 0.0515s	
45/2700 (epoch 0.833), train_loss = 3.26724790, grad/param norm = 1.8078e+00, time/batch = 0.0512s	
46/2700 (epoch 0.852), train_loss = 3.25243834, grad/param norm = 1.6851e+00, time/batch = 0.0514s	
47/2700 (epoch 0.870), train_loss = 3.24617883, grad/param norm = 1.5513e+00, time/batch = 0.0513s	
48/2700 (epoch 0.889), train_loss = 3.27109873, grad/param norm = 1.4603e+00, time/batch = 0.0514s	
49/2700 (epoch 0.907), train_loss = 3.32219040, grad/param norm = 1.6665e+00, time/batch = 0.0513s	
50/2700 (epoch 0.926), train_loss = 3.29028823, grad/param norm = 1.9781e+00, time/batch = 0.0517s	
51/2700 (epoch 0.944), train_loss = 3.30186058, grad/param norm = 1.7146e+00, time/batch = 0.0525s	
52/2700 (epoch 0.963), train_loss = 3.36580091, grad/param norm = 1.4874e+00, time/batch = 0.0514s	
53/2700 (epoch 0.981), train_loss = 3.41984584, grad/param norm = 1.4353e+00, time/batch = 0.0513s	
54/2700 (epoch 1.000), train_loss = 3.32556765, grad/param norm = 1.4410e+00, time/batch = 0.0513s	
55/2700 (epoch 1.019), train_loss = 3.25868231, grad/param norm = 1.5732e+00, time/batch = 0.0513s	
56/2700 (epoch 1.037), train_loss = 3.28264672, grad/param norm = 1.6131e+00, time/batch = 0.0513s	
57/2700 (epoch 1.056), train_loss = 3.27747795, grad/param norm = 1.2133e+00, time/batch = 0.0521s	
58/2700 (epoch 1.074), train_loss = 3.30242100, grad/param norm = 1.0830e+00, time/batch = 0.0516s	
59/2700 (epoch 1.093), train_loss = 3.31677566, grad/param norm = 1.3103e+00, time/batch = 0.0513s	
60/2700 (epoch 1.111), train_loss = 3.29351108, grad/param norm = 1.4822e+00, time/batch = 0.0512s	
61/2700 (epoch 1.130), train_loss = 3.31408938, grad/param norm = 1.5243e+00, time/batch = 0.0520s	
62/2700 (epoch 1.148), train_loss = 3.27352187, grad/param norm = 2.0188e+00, time/batch = 0.0509s	
63/2700 (epoch 1.167), train_loss = 3.31326118, grad/param norm = 2.2244e+00, time/batch = 0.0515s	
64/2700 (epoch 1.185), train_loss = 3.28045484, grad/param norm = 2.0437e+00, time/batch = 0.0520s	
65/2700 (epoch 1.204), train_loss = 3.21219513, grad/param norm = 2.1478e+00, time/batch = 0.0514s	
66/2700 (epoch 1.222), train_loss = 3.19030804, grad/param norm = 2.4599e+00, time/batch = 0.0513s	
67/2700 (epoch 1.241), train_loss = 3.20279497, grad/param norm = 2.1001e+00, time/batch = 0.0513s	
68/2700 (epoch 1.259), train_loss = 3.23890446, grad/param norm = 2.0112e+00, time/batch = 0.0512s	
69/2700 (epoch 1.278), train_loss = 3.32521655, grad/param norm = 2.2785e+00, time/batch = 0.0514s	
70/2700 (epoch 1.296), train_loss = 3.31681478, grad/param norm = 1.9812e+00, time/batch = 0.0520s	
71/2700 (epoch 1.315), train_loss = 3.28819943, grad/param norm = 1.5266e+00, time/batch = 0.0526s	
72/2700 (epoch 1.333), train_loss = 3.35446784, grad/param norm = 1.1765e+00, time/batch = 0.0512s	
73/2700 (epoch 1.352), train_loss = 3.36233963, grad/param norm = 1.2978e+00, time/batch = 0.0512s	
74/2700 (epoch 1.370), train_loss = 3.31434102, grad/param norm = 1.4324e+00, time/batch = 0.0511s	
75/2700 (epoch 1.389), train_loss = 3.27359252, grad/param norm = 1.3766e+00, time/batch = 0.0511s	
76/2700 (epoch 1.407), train_loss = 3.29757410, grad/param norm = 1.3112e+00, time/batch = 0.0513s	
77/2700 (epoch 1.426), train_loss = 3.29962261, grad/param norm = 1.3320e+00, time/batch = 0.0522s	
78/2700 (epoch 1.444), train_loss = 3.22643756, grad/param norm = 1.5308e+00, time/batch = 0.0514s	
79/2700 (epoch 1.463), train_loss = 3.27967414, grad/param norm = 1.9990e+00, time/batch = 0.0513s	
80/2700 (epoch 1.481), train_loss = 3.36719316, grad/param norm = 2.1380e+00, time/batch = 0.0513s	
81/2700 (epoch 1.500), train_loss = 3.40630233, grad/param norm = 2.3755e+00, time/batch = 0.0527s	
82/2700 (epoch 1.519), train_loss = 3.36747681, grad/param norm = 2.4043e+00, time/batch = 0.0513s	
83/2700 (epoch 1.537), train_loss = 3.36678911, grad/param norm = 2.0410e+00, time/batch = 0.0522s	
84/2700 (epoch 1.556), train_loss = 3.30070278, grad/param norm = 1.5883e+00, time/batch = 0.0542s	
85/2700 (epoch 1.574), train_loss = 3.24182735, grad/param norm = 1.2499e+00, time/batch = 0.0542s	
86/2700 (epoch 1.593), train_loss = 3.25103292, grad/param norm = 1.5611e+00, time/batch = 0.0567s	
87/2700 (epoch 1.611), train_loss = 3.19555432, grad/param norm = 1.4613e+00, time/batch = 0.0569s	
88/2700 (epoch 1.630), train_loss = 3.23602820, grad/param norm = 1.5962e+00, time/batch = 0.0554s	
89/2700 (epoch 1.648), train_loss = 3.31554136, grad/param norm = 1.7256e+00, time/batch = 0.0572s	
90/2700 (epoch 1.667), train_loss = 3.25299686, grad/param norm = 1.7835e+00, time/batch = 0.0557s	
91/2700 (epoch 1.685), train_loss = 3.24265240, grad/param norm = 1.6229e+00, time/batch = 0.0577s	
92/2700 (epoch 1.704), train_loss = 3.21925412, grad/param norm = 1.8084e+00, time/batch = 0.0555s	
93/2700 (epoch 1.722), train_loss = 3.21159307, grad/param norm = 1.6568e+00, time/batch = 0.0570s	
94/2700 (epoch 1.741), train_loss = 3.33597208, grad/param norm = 1.4963e+00, time/batch = 0.0543s	
95/2700 (epoch 1.759), train_loss = 3.29296930, grad/param norm = 1.8336e+00, time/batch = 0.0516s	
96/2700 (epoch 1.778), train_loss = 3.29803754, grad/param norm = 2.3711e+00, time/batch = 0.0548s	
97/2700 (epoch 1.796), train_loss = 3.30254676, grad/param norm = 2.3220e+00, time/batch = 0.0536s	
98/2700 (epoch 1.815), train_loss = 3.23282545, grad/param norm = 2.0803e+00, time/batch = 0.0520s	
99/2700 (epoch 1.833), train_loss = 3.27437668, grad/param norm = 2.0835e+00, time/batch = 0.0542s	
100/2700 (epoch 1.852), train_loss = 3.26337484, grad/param norm = 2.1254e+00, time/batch = 0.0580s	
101/2700 (epoch 1.870), train_loss = 3.25604584, grad/param norm = 1.7727e+00, time/batch = 0.0557s	
102/2700 (epoch 1.889), train_loss = 3.27279082, grad/param norm = 1.5290e+00, time/batch = 0.0549s	
103/2700 (epoch 1.907), train_loss = 3.32282560, grad/param norm = 1.6299e+00, time/batch = 0.0551s	
104/2700 (epoch 1.926), train_loss = 3.28733380, grad/param norm = 1.9020e+00, time/batch = 0.0546s	
105/2700 (epoch 1.944), train_loss = 3.30059000, grad/param norm = 1.6462e+00, time/batch = 0.0558s	
106/2700 (epoch 1.963), train_loss = 3.36428010, grad/param norm = 1.4313e+00, time/batch = 0.0562s	
107/2700 (epoch 1.981), train_loss = 3.41987598, grad/param norm = 1.4257e+00, time/batch = 0.0548s	
108/2700 (epoch 2.000), train_loss = 3.32989015, grad/param norm = 1.4412e+00, time/batch = 0.0542s	
109/2700 (epoch 2.019), train_loss = 3.26121658, grad/param norm = 1.5678e+00, time/batch = 0.0537s	
110/2700 (epoch 2.037), train_loss = 3.28701962, grad/param norm = 1.6114e+00, time/batch = 0.0535s	
111/2700 (epoch 2.056), train_loss = 3.27851922, grad/param norm = 1.1935e+00, time/batch = 0.0529s	
112/2700 (epoch 2.074), train_loss = 3.30475320, grad/param norm = 1.0918e+00, time/batch = 0.0521s	
113/2700 (epoch 2.093), train_loss = 3.31882886, grad/param norm = 1.3185e+00, time/batch = 0.0523s	
114/2700 (epoch 2.111), train_loss = 3.29419901, grad/param norm = 1.4220e+00, time/batch = 0.0526s	
115/2700 (epoch 2.130), train_loss = 3.31385065, grad/param norm = 1.3643e+00, time/batch = 0.0533s	
116/2700 (epoch 2.148), train_loss = 3.27042516, grad/param norm = 1.6972e+00, time/batch = 0.0526s	
117/2700 (epoch 2.167), train_loss = 3.29971762, grad/param norm = 1.8750e+00, time/batch = 0.0528s	
118/2700 (epoch 2.185), train_loss = 3.27355797, grad/param norm = 1.5785e+00, time/batch = 0.0524s	
119/2700 (epoch 2.204), train_loss = 3.20144734, grad/param norm = 1.5105e+00, time/batch = 0.0523s	
120/2700 (epoch 2.222), train_loss = 3.17437162, grad/param norm = 1.8755e+00, time/batch = 0.0522s	
121/2700 (epoch 2.241), train_loss = 3.19910894, grad/param norm = 1.8325e+00, time/batch = 0.0552s	
122/2700 (epoch 2.259), train_loss = 3.23819789, grad/param norm = 1.9751e+00, time/batch = 0.0582s	
123/2700 (epoch 2.278), train_loss = 3.32879088, grad/param norm = 2.9561e+00, time/batch = 0.0575s	
124/2700 (epoch 2.296), train_loss = 3.34516407, grad/param norm = 2.7730e+00, time/batch = 0.0622s	
125/2700 (epoch 2.315), train_loss = 3.29904654, grad/param norm = 1.7898e+00, time/batch = 0.0701s	
126/2700 (epoch 2.333), train_loss = 3.35558205, grad/param norm = 1.2869e+00, time/batch = 0.0972s	
127/2700 (epoch 2.352), train_loss = 3.36468347, grad/param norm = 1.3907e+00, time/batch = 0.0994s	
128/2700 (epoch 2.370), train_loss = 3.32025899, grad/param norm = 1.6144e+00, time/batch = 0.0890s	
129/2700 (epoch 2.389), train_loss = 3.27834003, grad/param norm = 1.5640e+00, time/batch = 0.0842s	
130/2700 (epoch 2.407), train_loss = 3.30233260, grad/param norm = 1.4531e+00, time/batch = 0.0942s	
131/2700 (epoch 2.426), train_loss = 3.30074156, grad/param norm = 1.3794e+00, time/batch = 0.1032s	
132/2700 (epoch 2.444), train_loss = 3.22479938, grad/param norm = 1.4473e+00, time/batch = 0.0919s	
133/2700 (epoch 2.463), train_loss = 3.27506010, grad/param norm = 1.7765e+00, time/batch = 0.0854s	
134/2700 (epoch 2.481), train_loss = 3.36339452, grad/param norm = 1.9686e+00, time/batch = 0.0902s	
135/2700 (epoch 2.500), train_loss = 3.40638940, grad/param norm = 2.2238e+00, time/batch = 0.0977s	
136/2700 (epoch 2.519), train_loss = 3.36351143, grad/param norm = 2.2691e+00, time/batch = 0.0821s	
137/2700 (epoch 2.537), train_loss = 3.36606599, grad/param norm = 2.0372e+00, time/batch = 0.1038s	
138/2700 (epoch 2.556), train_loss = 3.30135912, grad/param norm = 1.6329e+00, time/batch = 0.0943s	
139/2700 (epoch 2.574), train_loss = 3.24128155, grad/param norm = 1.2634e+00, time/batch = 0.0848s	
140/2700 (epoch 2.593), train_loss = 3.25135166, grad/param norm = 1.5468e+00, time/batch = 0.0895s	
141/2700 (epoch 2.611), train_loss = 3.19417172, grad/param norm = 1.4195e+00, time/batch = 0.1129s	
142/2700 (epoch 2.630), train_loss = 3.23457183, grad/param norm = 1.5718e+00, time/batch = 0.1122s	
143/2700 (epoch 2.648), train_loss = 3.31484439, grad/param norm = 1.7273e+00, time/batch = 0.1084s	
144/2700 (epoch 2.667), train_loss = 3.25446810, grad/param norm = 1.8153e+00, time/batch = 0.1006s	
145/2700 (epoch 2.685), train_loss = 3.24393907, grad/param norm = 1.6925e+00, time/batch = 0.0919s	
146/2700 (epoch 2.704), train_loss = 3.22208355, grad/param norm = 1.8921e+00, time/batch = 0.0839s	
147/2700 (epoch 2.722), train_loss = 3.21470796, grad/param norm = 1.7510e+00, time/batch = 0.0617s	
148/2700 (epoch 2.741), train_loss = 3.34006694, grad/param norm = 1.6106e+00, time/batch = 0.1033s	
149/2700 (epoch 2.759), train_loss = 3.29655943, grad/param norm = 1.9172e+00, time/batch = 0.0972s	
150/2700 (epoch 2.778), train_loss = 3.29687827, grad/param norm = 2.3385e+00, time/batch = 0.0865s	
151/2700 (epoch 2.796), train_loss = 3.30079713, grad/param norm = 2.3151e+00, time/batch = 0.1119s	
152/2700 (epoch 2.815), train_loss = 3.23345418, grad/param norm = 2.0757e+00, time/batch = 0.1112s	
153/2700 (epoch 2.833), train_loss = 3.27455741, grad/param norm = 2.0746e+00, time/batch = 0.1123s	
154/2700 (epoch 2.852), train_loss = 3.26297189, grad/param norm = 2.1225e+00, time/batch = 0.1117s	
155/2700 (epoch 2.870), train_loss = 3.25581227, grad/param norm = 1.7713e+00, time/batch = 0.1109s	
156/2700 (epoch 2.889), train_loss = 3.27258447, grad/param norm = 1.5179e+00, time/batch = 0.1124s	
157/2700 (epoch 2.907), train_loss = 3.32218241, grad/param norm = 1.6129e+00, time/batch = 0.1039s	
158/2700 (epoch 2.926), train_loss = 3.28589902, grad/param norm = 1.8813e+00, time/batch = 0.0677s	
159/2700 (epoch 2.944), train_loss = 3.30004996, grad/param norm = 1.6369e+00, time/batch = 0.1111s	
160/2700 (epoch 2.963), train_loss = 3.36399281, grad/param norm = 1.4439e+00, time/batch = 0.1123s	
161/2700 (epoch 2.981), train_loss = 3.42126736, grad/param norm = 1.4469e+00, time/batch = 0.1024s	
162/2700 (epoch 3.000), train_loss = 3.33096019, grad/param norm = 1.4629e+00, time/batch = 0.1095s	
163/2700 (epoch 3.019), train_loss = 3.26268815, grad/param norm = 1.5723e+00, time/batch = 0.1123s	
164/2700 (epoch 3.037), train_loss = 3.28733271, grad/param norm = 1.6247e+00, time/batch = 0.1110s	
165/2700 (epoch 3.056), train_loss = 3.27878990, grad/param norm = 1.2268e+00, time/batch = 0.1113s	
166/2700 (epoch 3.074), train_loss = 3.30498057, grad/param norm = 1.1010e+00, time/batch = 0.1123s	
167/2700 (epoch 3.093), train_loss = 3.31898141, grad/param norm = 1.3205e+00, time/batch = 0.1111s	
168/2700 (epoch 3.111), train_loss = 3.29405869, grad/param norm = 1.4230e+00, time/batch = 0.1012s	
169/2700 (epoch 3.130), train_loss = 3.31349115, grad/param norm = 1.3544e+00, time/batch = 0.0927s	
170/2700 (epoch 3.148), train_loss = 3.26916369, grad/param norm = 1.6936e+00, time/batch = 0.0855s	
171/2700 (epoch 3.167), train_loss = 3.29985359, grad/param norm = 1.8882e+00, time/batch = 0.1125s	
172/2700 (epoch 3.185), train_loss = 3.27452865, grad/param norm = 1.6722e+00, time/batch = 0.1111s	
173/2700 (epoch 3.204), train_loss = 3.20487782, grad/param norm = 1.7089e+00, time/batch = 0.1119s	
174/2700 (epoch 3.222), train_loss = 3.18051144, grad/param norm = 2.1729e+00, time/batch = 0.1113s	
175/2700 (epoch 3.241), train_loss = 3.20502349, grad/param norm = 2.2127e+00, time/batch = 0.1114s	
176/2700 (epoch 3.259), train_loss = 3.24408985, grad/param norm = 2.1962e+00, time/batch = 0.1078s	
177/2700 (epoch 3.278), train_loss = 3.32376173, grad/param norm = 2.6963e+00, time/batch = 0.0995s	
178/2700 (epoch 3.296), train_loss = 3.33573553, grad/param norm = 2.5471e+00, time/batch = 0.0900s	
179/2700 (epoch 3.315), train_loss = 3.29849376, grad/param norm = 1.7366e+00, time/batch = 0.0545s	
180/2700 (epoch 3.333), train_loss = 3.35579965, grad/param norm = 1.2325e+00, time/batch = 0.1032s	
181/2700 (epoch 3.352), train_loss = 3.36483783, grad/param norm = 1.3577e+00, time/batch = 0.1125s	
182/2700 (epoch 3.370), train_loss = 3.31985145, grad/param norm = 1.5403e+00, time/batch = 0.1126s	
183/2700 (epoch 3.389), train_loss = 3.27628891, grad/param norm = 1.4677e+00, time/batch = 0.1132s	
184/2700 (epoch 3.407), train_loss = 3.30118108, grad/param norm = 1.3655e+00, time/batch = 0.1136s	
185/2700 (epoch 3.426), train_loss = 3.29985305, grad/param norm = 1.3079e+00, time/batch = 0.1125s	
186/2700 (epoch 3.444), train_loss = 3.22349082, grad/param norm = 1.3687e+00, time/batch = 0.1133s	
187/2700 (epoch 3.463), train_loss = 3.27377570, grad/param norm = 1.7025e+00, time/batch = 0.1126s	
188/2700 (epoch 3.481), train_loss = 3.36154182, grad/param norm = 1.9052e+00, time/batch = 0.1124s	
189/2700 (epoch 3.500), train_loss = 3.40579320, grad/param norm = 2.2208e+00, time/batch = 0.1011s	
190/2700 (epoch 3.519), train_loss = 3.36465683, grad/param norm = 2.3129e+00, time/batch = 0.0980s	
191/2700 (epoch 3.537), train_loss = 3.36785630, grad/param norm = 2.0801e+00, time/batch = 0.1131s	
192/2700 (epoch 3.556), train_loss = 3.30215779, grad/param norm = 1.6719e+00, time/batch = 0.1139s	
193/2700 (epoch 3.574), train_loss = 3.24221050, grad/param norm = 1.3034e+00, time/batch = 0.1124s	
194/2700 (epoch 3.593), train_loss = 3.25197032, grad/param norm = 1.5802e+00, time/batch = 0.1125s	
195/2700 (epoch 3.611), train_loss = 3.19455495, grad/param norm = 1.4502e+00, time/batch = 0.1133s	
196/2700 (epoch 3.630), train_loss = 3.23515978, grad/param norm = 1.6067e+00, time/batch = 0.1123s	
197/2700 (epoch 3.648), train_loss = 3.31556758, grad/param norm = 1.7535e+00, time/batch = 0.1122s	
198/2700 (epoch 3.667), train_loss = 3.25411188, grad/param norm = 1.8228e+00, time/batch = 0.1113s	
199/2700 (epoch 3.685), train_loss = 3.24357594, grad/param norm = 1.6897e+00, time/batch = 0.1037s	
200/2700 (epoch 3.704), train_loss = 3.22165756, grad/param norm = 1.8947e+00, time/batch = 0.0919s	
201/2700 (epoch 3.722), train_loss = 3.21467473, grad/param norm = 1.7520e+00, time/batch = 0.1131s	
202/2700 (epoch 3.741), train_loss = 3.34001328, grad/param norm = 1.6024e+00, time/batch = 0.1118s	
203/2700 (epoch 3.759), train_loss = 3.29630928, grad/param norm = 1.9100e+00, time/batch = 0.1111s	
204/2700 (epoch 3.778), train_loss = 3.29651639, grad/param norm = 2.3375e+00, time/batch = 0.1105s	
205/2700 (epoch 3.796), train_loss = 3.30031220, grad/param norm = 2.2918e+00, time/batch = 0.1128s	
206/2700 (epoch 3.815), train_loss = 3.23262469, grad/param norm = 2.0440e+00, time/batch = 0.1108s	
207/2700 (epoch 3.833), train_loss = 3.27415827, grad/param norm = 2.0617e+00, time/batch = 0.1113s	
208/2700 (epoch 3.852), train_loss = 3.26263075, grad/param norm = 2.1280e+00, time/batch = 0.1123s	
209/2700 (epoch 3.870), train_loss = 3.25582249, grad/param norm = 1.7790e+00, time/batch = 0.1069s	
210/2700 (epoch 3.889), train_loss = 3.27278031, grad/param norm = 1.5317e+00, time/batch = 0.0731s	
211/2700 (epoch 3.907), train_loss = 3.32211951, grad/param norm = 1.6370e+00, time/batch = 0.0953s	
212/2700 (epoch 3.926), train_loss = 3.28554265, grad/param norm = 1.8908e+00, time/batch = 0.1025s	
213/2700 (epoch 3.944), train_loss = 3.29928620, grad/param norm = 1.6173e+00, time/batch = 0.1097s	
214/2700 (epoch 3.963), train_loss = 3.36245147, grad/param norm = 1.4111e+00, time/batch = 0.1114s	
215/2700 (epoch 3.981), train_loss = 3.42100681, grad/param norm = 1.4293e+00, time/batch = 0.1133s	
216/2700 (epoch 4.000), train_loss = 3.33039154, grad/param norm = 1.4616e+00, time/batch = 0.1108s	
217/2700 (epoch 4.019), train_loss = 3.26188087, grad/param norm = 1.5576e+00, time/batch = 0.1115s	
218/2700 (epoch 4.037), train_loss = 3.28715559, grad/param norm = 1.6310e+00, time/batch = 0.1120s	
219/2700 (epoch 4.056), train_loss = 3.27960625, grad/param norm = 1.2480e+00, time/batch = 0.1112s	
220/2700 (epoch 4.074), train_loss = 3.30555954, grad/param norm = 1.1156e+00, time/batch = 0.1041s	
221/2700 (epoch 4.093), train_loss = 3.31921870, grad/param norm = 1.3178e+00, time/batch = 0.1131s	
222/2700 (epoch 4.111), train_loss = 3.29428976, grad/param norm = 1.4328e+00, time/batch = 0.1109s	
223/2700 (epoch 4.130), train_loss = 3.31473507, grad/param norm = 1.3794e+00, time/batch = 0.1113s	
224/2700 (epoch 4.148), train_loss = 3.26939647, grad/param norm = 1.6762e+00, time/batch = 0.1118s	
225/2700 (epoch 4.167), train_loss = 3.29842258, grad/param norm = 1.8435e+00, time/batch = 0.1117s	
226/2700 (epoch 4.185), train_loss = 3.27328983, grad/param norm = 1.5889e+00, time/batch = 0.1317s	
227/2700 (epoch 4.204), train_loss = 3.20337571, grad/param norm = 1.5597e+00, time/batch = 0.1364s	
228/2700 (epoch 4.222), train_loss = 3.17641403, grad/param norm = 1.9197e+00, time/batch = 0.1347s	
229/2700 (epoch 4.241), train_loss = 3.19976859, grad/param norm = 1.8107e+00, time/batch = 0.1235s	
230/2700 (epoch 4.259), train_loss = 3.23527747, grad/param norm = 1.8639e+00, time/batch = 0.1070s	
231/2700 (epoch 4.278), train_loss = 3.32312303, grad/param norm = 2.7788e+00, time/batch = 0.1083s	
232/2700 (epoch 4.296), train_loss = 3.33675494, grad/param norm = 2.5577e+00, time/batch = 0.1167s	
233/2700 (epoch 4.315), train_loss = 3.29577570, grad/param norm = 1.8309e+00, time/batch = 0.1166s	
234/2700 (epoch 4.333), train_loss = 3.36075516, grad/param norm = 1.4953e+00, time/batch = 0.1155s	
235/2700 (epoch 4.352), train_loss = 3.37026810, grad/param norm = 1.5728e+00, time/batch = 0.1177s	
236/2700 (epoch 4.370), train_loss = 3.32396031, grad/param norm = 1.7499e+00, time/batch = 0.1171s	
237/2700 (epoch 4.389), train_loss = 3.28085023, grad/param norm = 1.6700e+00, time/batch = 0.1171s	
238/2700 (epoch 4.407), train_loss = 3.30435213, grad/param norm = 1.5486e+00, time/batch = 0.1168s	
239/2700 (epoch 4.426), train_loss = 3.30207270, grad/param norm = 1.4516e+00, time/batch = 0.1163s	
240/2700 (epoch 4.444), train_loss = 3.22587680, grad/param norm = 1.5107e+00, time/batch = 0.0936s	
241/2700 (epoch 4.463), train_loss = 3.27579953, grad/param norm = 1.8023e+00, time/batch = 0.1143s	
242/2700 (epoch 4.481), train_loss = 3.36302325, grad/param norm = 1.9520e+00, time/batch = 0.1122s	
243/2700 (epoch 4.500), train_loss = 3.40535902, grad/param norm = 2.1632e+00, time/batch = 0.1118s	
244/2700 (epoch 4.519), train_loss = 3.36180829, grad/param norm = 2.2089e+00, time/batch = 0.1101s	
245/2700 (epoch 4.537), train_loss = 3.36556756, grad/param norm = 2.0002e+00, time/batch = 0.1111s	
246/2700 (epoch 4.556), train_loss = 3.30097206, grad/param norm = 1.6051e+00, time/batch = 0.1094s	
247/2700 (epoch 4.574), train_loss = 3.24106492, grad/param norm = 1.2415e+00, time/batch = 0.1102s	
248/2700 (epoch 4.593), train_loss = 3.25091113, grad/param norm = 1.5222e+00, time/batch = 0.1122s	
249/2700 (epoch 4.611), train_loss = 3.19327015, grad/param norm = 1.3898e+00, time/batch = 0.1107s	
250/2700 (epoch 4.630), train_loss = 3.23393763, grad/param norm = 1.5444e+00, time/batch = 0.0951s	
251/2700 (epoch 4.648), train_loss = 3.31412070, grad/param norm = 1.7010e+00, time/batch = 0.1141s	
252/2700 (epoch 4.667), train_loss = 3.25345711, grad/param norm = 1.7853e+00, time/batch = 0.1142s	
253/2700 (epoch 4.685), train_loss = 3.24314356, grad/param norm = 1.6728e+00, time/batch = 0.1161s	
254/2700 (epoch 4.704), train_loss = 3.22188671, grad/param norm = 1.8881e+00, time/batch = 0.1251s	
255/2700 (epoch 4.722), train_loss = 3.21500762, grad/param norm = 1.7560e+00, time/batch = 0.1454s	
256/2700 (epoch 4.741), train_loss = 3.34041967, grad/param norm = 1.6199e+00, time/batch = 0.1537s	
257/2700 (epoch 4.759), train_loss = 3.29707903, grad/param norm = 1.9369e+00, time/batch = 0.1508s	
258/2700 (epoch 4.778), train_loss = 3.29746579, grad/param norm = 2.3702e+00, time/batch = 0.1550s	
259/2700 (epoch 4.796), train_loss = 3.30156426, grad/param norm = 2.3310e+00, time/batch = 0.1574s	
260/2700 (epoch 4.815), train_loss = 3.23348372, grad/param norm = 2.0724e+00, time/batch = 0.1471s	
261/2700 (epoch 4.833), train_loss = 3.27449956, grad/param norm = 2.0649e+00, time/batch = 0.1823s	
262/2700 (epoch 4.852), train_loss = 3.26277269, grad/param norm = 2.1130e+00, time/batch = 0.1821s	
263/2700 (epoch 4.870), train_loss = 3.25578432, grad/param norm = 1.7596e+00, time/batch = 0.1806s	
264/2700 (epoch 4.889), train_loss = 3.27242375, grad/param norm = 1.5097e+00, time/batch = 0.1678s	
265/2700 (epoch 4.907), train_loss = 3.32134811, grad/param norm = 1.6110e+00, time/batch = 0.1817s	
266/2700 (epoch 4.926), train_loss = 3.28514210, grad/param norm = 1.8762e+00, time/batch = 0.1802s	
267/2700 (epoch 4.944), train_loss = 3.29977262, grad/param norm = 1.6270e+00, time/batch = 0.1810s	
268/2700 (epoch 4.963), train_loss = 3.36356286, grad/param norm = 1.4330e+00, time/batch = 0.1795s	
269/2700 (epoch 4.981), train_loss = 3.42141175, grad/param norm = 1.4424e+00, time/batch = 0.1808s	
270/2700 (epoch 5.000), train_loss = 3.33022710, grad/param norm = 1.4490e+00, time/batch = 0.1707s	
271/2700 (epoch 5.019), train_loss = 3.26204181, grad/param norm = 1.5616e+00, time/batch = 0.1735s	
272/2700 (epoch 5.037), train_loss = 3.28755212, grad/param norm = 1.6173e+00, time/batch = 0.1742s	
273/2700 (epoch 5.056), train_loss = 3.27857500, grad/param norm = 1.2057e+00, time/batch = 0.1761s	
274/2700 (epoch 5.074), train_loss = 3.30471919, grad/param norm = 1.0898e+00, time/batch = 0.1603s	
275/2700 (epoch 5.093), train_loss = 3.31902969, grad/param norm = 1.3109e+00, time/batch = 0.1773s	
276/2700 (epoch 5.111), train_loss = 3.29400529, grad/param norm = 1.4143e+00, time/batch = 0.1668s	
277/2700 (epoch 5.130), train_loss = 3.31369233, grad/param norm = 1.3495e+00, time/batch = 0.1714s	
278/2700 (epoch 5.148), train_loss = 3.26916052, grad/param norm = 1.6596e+00, time/batch = 0.1709s	
279/2700 (epoch 5.167), train_loss = 3.29813186, grad/param norm = 1.8416e+00, time/batch = 0.1730s	
280/2700 (epoch 5.185), train_loss = 3.27330365, grad/param norm = 1.5874e+00, time/batch = 0.1643s	
281/2700 (epoch 5.204), train_loss = 3.20283053, grad/param norm = 1.5580e+00, time/batch = 0.1701s	
282/2700 (epoch 5.222), train_loss = 3.17611212, grad/param norm = 1.9503e+00, time/batch = 0.1690s	
283/2700 (epoch 5.241), train_loss = 3.20103168, grad/param norm = 1.9165e+00, time/batch = 0.1700s	
284/2700 (epoch 5.259), train_loss = 3.23874876, grad/param norm = 1.9965e+00, time/batch = 0.1599s	
285/2700 (epoch 5.278), train_loss = 3.32489185, grad/param norm = 2.8481e+00, time/batch = 0.1702s	
286/2700 (epoch 5.296), train_loss = 3.33930849, grad/param norm = 2.6170e+00, time/batch = 0.1765s	
287/2700 (epoch 5.315), train_loss = 3.29824695, grad/param norm = 1.7953e+00, time/batch = 0.1767s	
288/2700 (epoch 5.333), train_loss = 3.35798223, grad/param norm = 1.3571e+00, time/batch = 0.1752s	
289/2700 (epoch 5.352), train_loss = 3.36710559, grad/param norm = 1.4616e+00, time/batch = 0.1734s	
290/2700 (epoch 5.370), train_loss = 3.32207433, grad/param norm = 1.6548e+00, time/batch = 0.1657s	
291/2700 (epoch 5.389), train_loss = 3.27878769, grad/param norm = 1.5793e+00, time/batch = 0.1675s	
292/2700 (epoch 5.407), train_loss = 3.30296476, grad/param norm = 1.4696e+00, time/batch = 0.1712s	
293/2700 (epoch 5.426), train_loss = 3.30108130, grad/param norm = 1.3877e+00, time/batch = 0.1726s	
294/2700 (epoch 5.444), train_loss = 3.22485644, grad/param norm = 1.4459e+00, time/batch = 0.1579s	
295/2700 (epoch 5.463), train_loss = 3.27507125, grad/param norm = 1.7527e+00, time/batch = 0.1747s	
296/2700 (epoch 5.481), train_loss = 3.36252620, grad/param norm = 1.9282e+00, time/batch = 0.1823s	
297/2700 (epoch 5.500), train_loss = 3.40569673, grad/param norm = 2.1795e+00, time/batch = 0.1894s	
298/2700 (epoch 5.519), train_loss = 3.36273102, grad/param norm = 2.2384e+00, time/batch = 0.1970s	
299/2700 (epoch 5.537), train_loss = 3.36647018, grad/param norm = 2.0299e+00, time/batch = 0.1909s	
300/2700 (epoch 5.556), train_loss = 3.30154961, grad/param norm = 1.6337e+00, time/batch = 0.1809s	
301/2700 (epoch 5.574), train_loss = 3.24140637, grad/param norm = 1.2644e+00, time/batch = 0.1780s	
302/2700 (epoch 5.593), train_loss = 3.25113134, grad/param norm = 1.5376e+00, time/batch = 0.1724s	
303/2700 (epoch 5.611), train_loss = 3.19353597, grad/param norm = 1.4039e+00, time/batch = 0.1636s	
304/2700 (epoch 5.630), train_loss = 3.23431194, grad/param norm = 1.5646e+00, time/batch = 0.1472s	
305/2700 (epoch 5.648), train_loss = 3.31475163, grad/param norm = 1.7205e+00, time/batch = 0.1746s	
306/2700 (epoch 5.667), train_loss = 3.25391840, grad/param norm = 1.8007e+00, time/batch = 0.1619s	
307/2700 (epoch 5.685), train_loss = 3.24356442, grad/param norm = 1.6834e+00, time/batch = 0.1553s	
308/2700 (epoch 5.704), train_loss = 3.22231657, grad/param norm = 1.8960e+00, time/batch = 0.1677s	
309/2700 (epoch 5.722), train_loss = 3.21521578, grad/param norm = 1.7582e+00, time/batch = 0.1702s	
310/2700 (epoch 5.741), train_loss = 3.34053344, grad/param norm = 1.6179e+00, time/batch = 0.1741s	
311/2700 (epoch 5.759), train_loss = 3.29713566, grad/param norm = 1.9276e+00, time/batch = 0.1464s	
312/2700 (epoch 5.778), train_loss = 3.29699794, grad/param norm = 2.3486e+00, time/batch = 0.1865s	
313/2700 (epoch 5.796), train_loss = 3.30087443, grad/param norm = 2.3080e+00, time/batch = 0.1856s	
314/2700 (epoch 5.815), train_loss = 3.23311084, grad/param norm = 2.0554e+00, time/batch = 0.1766s	
315/2700 (epoch 5.833), train_loss = 3.27411660, grad/param norm = 2.0512e+00, time/batch = 0.1883s	
316/2700 (epoch 5.852), train_loss = 3.26249402, grad/param norm = 2.1015e+00, time/batch = 0.1886s	
317/2700 (epoch 5.870), train_loss = 3.25579726, grad/param norm = 1.7589e+00, time/batch = 0.2052s	
318/2700 (epoch 5.889), train_loss = 3.27253588, grad/param norm = 1.5128e+00, time/batch = 0.2508s	
319/2700 (epoch 5.907), train_loss = 3.32142210, grad/param norm = 1.6137e+00, time/batch = 0.2513s	
320/2700 (epoch 5.926), train_loss = 3.28524772, grad/param norm = 1.8773e+00, time/batch = 0.2534s	
321/2700 (epoch 5.944), train_loss = 3.29983594, grad/param norm = 1.6266e+00, time/batch = 0.2447s	
322/2700 (epoch 5.963), train_loss = 3.36359071, grad/param norm = 1.4326e+00, time/batch = 0.2514s	
323/2700 (epoch 5.981), train_loss = 3.42146051, grad/param norm = 1.4409e+00, time/batch = 0.2519s	
324/2700 (epoch 6.000), train_loss = 3.33022092, grad/param norm = 1.4479e+00, time/batch = 0.2441s	
325/2700 (epoch 6.019), train_loss = 3.26208807, grad/param norm = 1.5608e+00, time/batch = 0.2520s	
326/2700 (epoch 6.037), train_loss = 3.28756274, grad/param norm = 1.6165e+00, time/batch = 0.2393s	
327/2700 (epoch 6.056), train_loss = 3.27861322, grad/param norm = 1.2051e+00, time/batch = 0.2262s	
328/2700 (epoch 6.074), train_loss = 3.30471301, grad/param norm = 1.0873e+00, time/batch = 0.2018s	
329/2700 (epoch 6.093), train_loss = 3.31901816, grad/param norm = 1.3069e+00, time/batch = 0.2515s	
330/2700 (epoch 6.111), train_loss = 3.29397348, grad/param norm = 1.4119e+00, time/batch = 0.2518s	
331/2700 (epoch 6.130), train_loss = 3.31371685, grad/param norm = 1.3484e+00, time/batch = 0.2417s	
332/2700 (epoch 6.148), train_loss = 3.26917786, grad/param norm = 1.6617e+00, time/batch = 0.2405s	
333/2700 (epoch 6.167), train_loss = 3.29834252, grad/param norm = 1.8440e+00, time/batch = 0.2306s	
334/2700 (epoch 6.185), train_loss = 3.27351546, grad/param norm = 1.6012e+00, time/batch = 0.2199s	
335/2700 (epoch 6.204), train_loss = 3.20335075, grad/param norm = 1.5871e+00, time/batch = 0.2265s	
336/2700 (epoch 6.222), train_loss = 3.17708225, grad/param norm = 1.9991e+00, time/batch = 0.2319s	
337/2700 (epoch 6.241), train_loss = 3.20224793, grad/param norm = 1.9963e+00, time/batch = 0.2357s	
338/2700 (epoch 6.259), train_loss = 3.24038689, grad/param norm = 2.0573e+00, time/batch = 0.2371s	
339/2700 (epoch 6.278), train_loss = 3.32420699, grad/param norm = 2.8054e+00, time/batch = 0.2071s	
340/2700 (epoch 6.296), train_loss = 3.33789694, grad/param norm = 2.5809e+00, time/batch = 0.2354s	
341/2700 (epoch 6.315), train_loss = 3.29853059, grad/param norm = 1.7762e+00, time/batch = 0.2238s	
342/2700 (epoch 6.333), train_loss = 3.35745753, grad/param norm = 1.3207e+00, time/batch = 0.2343s	
343/2700 (epoch 6.352), train_loss = 3.36652805, grad/param norm = 1.4313e+00, time/batch = 0.2528s	
344/2700 (epoch 6.370), train_loss = 3.32154587, grad/param norm = 1.6199e+00, time/batch = 0.2438s	
345/2700 (epoch 6.389), train_loss = 3.27807062, grad/param norm = 1.5437e+00, time/batch = 0.2480s	
346/2700 (epoch 6.407), train_loss = 3.30247602, grad/param norm = 1.4375e+00, time/batch = 0.2414s	
347/2700 (epoch 6.426), train_loss = 3.30074485, grad/param norm = 1.3620e+00, time/batch = 0.2377s	
348/2700 (epoch 6.444), train_loss = 3.22441835, grad/param norm = 1.4174e+00, time/batch = 0.2369s	
349/2700 (epoch 6.463), train_loss = 3.27461488, grad/param norm = 1.7262e+00, time/batch = 0.2287s	
350/2700 (epoch 6.481), train_loss = 3.36210732, grad/param norm = 1.9104e+00, time/batch = 0.1973s	
351/2700 (epoch 6.500), train_loss = 3.40573746, grad/param norm = 2.1788e+00, time/batch = 0.2462s	
352/2700 (epoch 6.519), train_loss = 3.36312627, grad/param norm = 2.2468e+00, time/batch = 0.2249s	
353/2700 (epoch 6.537), train_loss = 3.36685768, grad/param norm = 2.0390e+00, time/batch = 0.2165s	
354/2700 (epoch 6.556), train_loss = 3.30181480, grad/param norm = 1.6427e+00, time/batch = 0.2229s	
355/2700 (epoch 6.574), train_loss = 3.24157465, grad/param norm = 1.2723e+00, time/batch = 0.2179s	
356/2700 (epoch 6.593), train_loss = 3.25128824, grad/param norm = 1.5437e+00, time/batch = 0.2308s	
357/2700 (epoch 6.611), train_loss = 3.19370452, grad/param norm = 1.4104e+00, time/batch = 0.2228s	
358/2700 (epoch 6.630), train_loss = 3.23450259, grad/param norm = 1.5719e+00, time/batch = 0.2118s	
359/2700 (epoch 6.648), train_loss = 3.31502313, grad/param norm = 1.7264e+00, time/batch = 0.2021s	
360/2700 (epoch 6.667), train_loss = 3.25406406, grad/param norm = 1.8039e+00, time/batch = 0.2052s	
361/2700 (epoch 6.685), train_loss = 3.24365581, grad/param norm = 1.6836e+00, time/batch = 0.2330s	
362/2700 (epoch 6.704), train_loss = 3.22237288, grad/param norm = 1.8946e+00, time/batch = 0.2135s	
363/2700 (epoch 6.722), train_loss = 3.21529141, grad/param norm = 1.7557e+00, time/batch = 0.1888s	
364/2700 (epoch 6.741), train_loss = 3.34051447, grad/param norm = 1.6132e+00, time/batch = 0.2013s	
365/2700 (epoch 6.759), train_loss = 3.29709256, grad/param norm = 1.9199e+00, time/batch = 0.2111s	
366/2700 (epoch 6.778), train_loss = 3.29680710, grad/param norm = 2.3360e+00, time/batch = 0.2240s	
367/2700 (epoch 6.796), train_loss = 3.30059200, grad/param norm = 2.2941e+00, time/batch = 0.2286s	
368/2700 (epoch 6.815), train_loss = 3.23295262, grad/param norm = 2.0444e+00, time/batch = 0.2319s	
369/2700 (epoch 6.833), train_loss = 3.27398038, grad/param norm = 2.0415e+00, time/batch = 0.2345s	
370/2700 (epoch 6.852), train_loss = 3.26238472, grad/param norm = 2.0928e+00, time/batch = 0.2354s	
371/2700 (epoch 6.870), train_loss = 3.25579232, grad/param norm = 1.7548e+00, time/batch = 0.2409s	
372/2700 (epoch 6.889), train_loss = 3.27256759, grad/param norm = 1.5108e+00, time/batch = 0.2437s	
373/2700 (epoch 6.907), train_loss = 3.32145868, grad/param norm = 1.6126e+00, time/batch = 0.2303s	
374/2700 (epoch 6.926), train_loss = 3.28526627, grad/param norm = 1.8746e+00, time/batch = 0.2217s	
375/2700 (epoch 6.944), train_loss = 3.29983956, grad/param norm = 1.6239e+00, time/batch = 0.1662s	
376/2700 (epoch 6.963), train_loss = 3.36361226, grad/param norm = 1.4307e+00, time/batch = 0.2048s	
377/2700 (epoch 6.981), train_loss = 3.42149076, grad/param norm = 1.4384e+00, time/batch = 0.2198s	
378/2700 (epoch 7.000), train_loss = 3.33022878, grad/param norm = 1.4454e+00, time/batch = 0.2308s	
379/2700 (epoch 7.019), train_loss = 3.26211258, grad/param norm = 1.5581e+00, time/batch = 0.2344s	
380/2700 (epoch 7.037), train_loss = 3.28758477, grad/param norm = 1.6138e+00, time/batch = 0.2410s	
381/2700 (epoch 7.056), train_loss = 3.27862507, grad/param norm = 1.2030e+00, time/batch = 0.2171s	
382/2700 (epoch 7.074), train_loss = 3.30470458, grad/param norm = 1.0844e+00, time/batch = 0.2185s	
383/2700 (epoch 7.093), train_loss = 3.31901384, grad/param norm = 1.3033e+00, time/batch = 0.2149s	
384/2700 (epoch 7.111), train_loss = 3.29396622, grad/param norm = 1.4086e+00, time/batch = 0.1929s	
385/2700 (epoch 7.130), train_loss = 3.31372191, grad/param norm = 1.3456e+00, time/batch = 0.2133s	
386/2700 (epoch 7.148), train_loss = 3.26917714, grad/param norm = 1.6591e+00, time/batch = 0.2380s	
387/2700 (epoch 7.167), train_loss = 3.29841424, grad/param norm = 1.8413e+00, time/batch = 0.2502s	
388/2700 (epoch 7.185), train_loss = 3.27359804, grad/param norm = 1.6031e+00, time/batch = 0.2524s	
389/2700 (epoch 7.204), train_loss = 3.20353614, grad/param norm = 1.5942e+00, time/batch = 0.2503s	
390/2700 (epoch 7.222), train_loss = 3.17741537, grad/param norm = 2.0110e+00, time/batch = 0.2420s	
391/2700 (epoch 7.241), train_loss = 3.20260353, grad/param norm = 2.0155e+00, time/batch = 0.2525s	
392/2700 (epoch 7.259), train_loss = 3.24079473, grad/param norm = 2.0679e+00, time/batch = 0.2492s	
393/2700 (epoch 7.278), train_loss = 3.32390673, grad/param norm = 2.7820e+00, time/batch = 0.2464s	
394/2700 (epoch 7.296), train_loss = 3.33742846, grad/param norm = 2.5636e+00, time/batch = 0.2491s	
395/2700 (epoch 7.315), train_loss = 3.29864063, grad/param norm = 1.7682e+00, time/batch = 0.2303s	
396/2700 (epoch 7.333), train_loss = 3.35733248, grad/param norm = 1.3089e+00, time/batch = 0.2149s	
397/2700 (epoch 7.352), train_loss = 3.36638548, grad/param norm = 1.4207e+00, time/batch = 0.1874s	
398/2700 (epoch 7.370), train_loss = 3.32141131, grad/param norm = 1.6075e+00, time/batch = 0.2040s	
399/2700 (epoch 7.389), train_loss = 3.27788337, grad/param norm = 1.5313e+00, time/batch = 0.2262s	
400/2700 (epoch 7.407), train_loss = 3.30234757, grad/param norm = 1.4264e+00, time/batch = 0.2419s	
401/2700 (epoch 7.426), train_loss = 3.30066503, grad/param norm = 1.3528e+00, time/batch = 0.2270s	
402/2700 (epoch 7.444), train_loss = 3.22431087, grad/param norm = 1.4074e+00, time/batch = 0.2306s	
403/2700 (epoch 7.463), train_loss = 3.27449556, grad/param norm = 1.7159e+00, time/batch = 0.2389s	
404/2700 (epoch 7.481), train_loss = 3.36200368, grad/param norm = 1.9018e+00, time/batch = 0.2320s	
405/2700 (epoch 7.500), train_loss = 3.40574775, grad/param norm = 2.1739e+00, time/batch = 0.2228s	
406/2700 (epoch 7.519), train_loss = 3.36323238, grad/param norm = 2.2441e+00, time/batch = 0.2240s	
407/2700 (epoch 7.537), train_loss = 3.36695650, grad/param norm = 2.0367e+00, time/batch = 0.2153s	
408/2700 (epoch 7.556), train_loss = 3.30188165, grad/param norm = 1.6413e+00, time/batch = 0.2357s	
409/2700 (epoch 7.574), train_loss = 3.24162127, grad/param norm = 1.2715e+00, time/batch = 0.2522s	
410/2700 (epoch 7.593), train_loss = 3.25133368, grad/param norm = 1.5419e+00, time/batch = 0.2509s	
411/2700 (epoch 7.611), train_loss = 3.19375204, grad/param norm = 1.4090e+00, time/batch = 0.2400s	
412/2700 (epoch 7.630), train_loss = 3.23455413, grad/param norm = 1.5703e+00, time/batch = 0.2530s	
413/2700 (epoch 7.648), train_loss = 3.31509090, grad/param norm = 1.7240e+00, time/batch = 0.2503s	
414/2700 (epoch 7.667), train_loss = 3.25409341, grad/param norm = 1.8005e+00, time/batch = 0.2525s	
415/2700 (epoch 7.685), train_loss = 3.24366723, grad/param norm = 1.6795e+00, time/batch = 0.2346s	
416/2700 (epoch 7.704), train_loss = 3.22237574, grad/param norm = 1.8897e+00, time/batch = 0.2319s	
417/2700 (epoch 7.722), train_loss = 3.21530680, grad/param norm = 1.7508e+00, time/batch = 0.2226s	
418/2700 (epoch 7.741), train_loss = 3.34049652, grad/param norm = 1.6079e+00, time/batch = 0.1982s	
419/2700 (epoch 7.759), train_loss = 3.29706858, grad/param norm = 1.9131e+00, time/batch = 0.1750s	
420/2700 (epoch 7.778), train_loss = 3.29676232, grad/param norm = 2.3271e+00, time/batch = 0.1846s	
421/2700 (epoch 7.796), train_loss = 3.30052192, grad/param norm = 2.2850e+00, time/batch = 0.1878s	
422/2700 (epoch 7.815), train_loss = 3.23291641, grad/param norm = 2.0367e+00, time/batch = 0.2066s	
423/2700 (epoch 7.833), train_loss = 3.27395134, grad/param norm = 2.0342e+00, time/batch = 0.2188s	
424/2700 (epoch 7.852), train_loss = 3.26236351, grad/param norm = 2.0855e+00, time/batch = 0.2268s	
425/2700 (epoch 7.870), train_loss = 3.25579226, grad/param norm = 1.7495e+00, time/batch = 0.2341s	
426/2700 (epoch 7.889), train_loss = 3.27257949, grad/param norm = 1.5065e+00, time/batch = 0.2126s	
427/2700 (epoch 7.907), train_loss = 3.32147190, grad/param norm = 1.6081e+00, time/batch = 0.2258s	
428/2700 (epoch 7.926), train_loss = 3.28528337, grad/param norm = 1.8692e+00, time/batch = 0.2130s	
429/2700 (epoch 7.944), train_loss = 3.29984940, grad/param norm = 1.6192e+00, time/batch = 0.2314s	
430/2700 (epoch 7.963), train_loss = 3.36362068, grad/param norm = 1.4267e+00, time/batch = 0.2430s	
431/2700 (epoch 7.981), train_loss = 3.42149821, grad/param norm = 1.4342e+00, time/batch = 0.2299s	
432/2700 (epoch 8.000), train_loss = 3.33028533, grad/param norm = 1.4406e+00, time/batch = 0.2499s	
433/2700 (epoch 8.019), train_loss = 3.26210200, grad/param norm = 1.5523e+00, time/batch = 0.2515s	
434/2700 (epoch 8.037), train_loss = 3.28758377, grad/param norm = 1.6065e+00, time/batch = 0.2527s	
435/2700 (epoch 8.056), train_loss = 3.27859486, grad/param norm = 1.1972e+00, time/batch = 0.2514s	
436/2700 (epoch 8.074), train_loss = 3.30466739, grad/param norm = 1.0784e+00, time/batch = 0.2422s	
437/2700 (epoch 8.093), train_loss = 3.31899059, grad/param norm = 1.2962e+00, time/batch = 0.2147s	
438/2700 (epoch 8.111), train_loss = 3.29394316, grad/param norm = 1.4023e+00, time/batch = 0.2109s	
439/2700 (epoch 8.130), train_loss = 3.31375220, grad/param norm = 1.3411e+00, time/batch = 0.2081s	
440/2700 (epoch 8.148), train_loss = 3.26921334, grad/param norm = 1.6564e+00, time/batch = 0.2269s	
441/2700 (epoch 8.167), train_loss = 3.29859348, grad/param norm = 1.8379e+00, time/batch = 0.2171s	
442/2700 (epoch 8.185), train_loss = 3.27375731, grad/param norm = 1.6081e+00, time/batch = 0.2402s	
443/2700 (epoch 8.204), train_loss = 3.20392486, grad/param norm = 1.6113e+00, time/batch = 0.2535s	
444/2700 (epoch 8.222), train_loss = 3.17815976, grad/param norm = 2.0384e+00, time/batch = 0.2530s	
445/2700 (epoch 8.241), train_loss = 3.20333033, grad/param norm = 2.0553e+00, time/batch = 0.2534s	
446/2700 (epoch 8.259), train_loss = 3.24158758, grad/param norm = 2.0880e+00, time/batch = 0.2454s	
447/2700 (epoch 8.278), train_loss = 3.32330589, grad/param norm = 2.7337e+00, time/batch = 0.2451s	
448/2700 (epoch 8.296), train_loss = 3.33658062, grad/param norm = 2.5322e+00, time/batch = 0.2488s	
449/2700 (epoch 8.315), train_loss = 3.29888302, grad/param norm = 1.7532e+00, time/batch = 0.2256s	
450/2700 (epoch 8.333), train_loss = 3.35706139, grad/param norm = 1.2852e+00, time/batch = 0.2161s	
451/2700 (epoch 8.352), train_loss = 3.36607098, grad/param norm = 1.3995e+00, time/batch = 0.2234s	
452/2700 (epoch 8.370), train_loss = 3.32109947, grad/param norm = 1.5831e+00, time/batch = 0.2214s	
453/2700 (epoch 8.389), train_loss = 3.27746185, grad/param norm = 1.5065e+00, time/batch = 0.2334s	
454/2700 (epoch 8.407), train_loss = 3.30204799, grad/param norm = 1.4041e+00, time/batch = 0.2501s	
455/2700 (epoch 8.426), train_loss = 3.30049153, grad/param norm = 1.3352e+00, time/batch = 0.2537s	
456/2700 (epoch 8.444), train_loss = 3.22409260, grad/param norm = 1.3884e+00, time/batch = 0.2469s	
457/2700 (epoch 8.463), train_loss = 3.27424949, grad/param norm = 1.6970e+00, time/batch = 0.2427s	
458/2700 (epoch 8.481), train_loss = 3.36180474, grad/param norm = 1.8866e+00, time/batch = 0.2369s	
459/2700 (epoch 8.500), train_loss = 3.40577368, grad/param norm = 2.1670e+00, time/batch = 0.2295s	
460/2700 (epoch 8.519), train_loss = 3.36346223, grad/param norm = 2.2418e+00, time/batch = 0.2317s	
461/2700 (epoch 8.537), train_loss = 3.36716298, grad/param norm = 2.0349e+00, time/batch = 0.2544s	
462/2700 (epoch 8.556), train_loss = 3.30202815, grad/param norm = 1.6407e+00, time/batch = 0.2527s	
463/2700 (epoch 8.574), train_loss = 3.24172443, grad/param norm = 1.2718e+00, time/batch = 0.2485s	
464/2700 (epoch 8.593), train_loss = 3.25143847, grad/param norm = 1.5407e+00, time/batch = 0.2337s	
465/2700 (epoch 8.611), train_loss = 3.19386645, grad/param norm = 1.4086e+00, time/batch = 0.2203s	
466/2700 (epoch 8.630), train_loss = 3.23466675, grad/param norm = 1.5692e+00, time/batch = 0.2164s	
467/2700 (epoch 8.648), train_loss = 3.31522479, grad/param norm = 1.7212e+00, time/batch = 0.2278s	
468/2700 (epoch 8.667), train_loss = 3.25415133, grad/param norm = 1.7958e+00, time/batch = 0.2160s	
469/2700 (epoch 8.685), train_loss = 3.24368401, grad/param norm = 1.6733e+00, time/batch = 0.2319s	
470/2700 (epoch 8.704), train_loss = 3.22236834, grad/param norm = 1.8820e+00, time/batch = 0.2264s	
471/2700 (epoch 8.722), train_loss = 3.21532143, grad/param norm = 1.7429e+00, time/batch = 0.2314s	
472/2700 (epoch 8.741), train_loss = 3.34044765, grad/param norm = 1.5990e+00, time/batch = 0.2387s	
473/2700 (epoch 8.759), train_loss = 3.29699438, grad/param norm = 1.9023e+00, time/batch = 0.2406s	
474/2700 (epoch 8.778), train_loss = 3.29667311, grad/param norm = 2.3140e+00, time/batch = 0.2304s	
475/2700 (epoch 8.796), train_loss = 3.30040583, grad/param norm = 2.2714e+00, time/batch = 0.2220s	
476/2700 (epoch 8.815), train_loss = 3.23284058, grad/param norm = 2.0252e+00, time/batch = 0.2189s	
477/2700 (epoch 8.833), train_loss = 3.27389388, grad/param norm = 2.0235e+00, time/batch = 0.2169s	
478/2700 (epoch 8.852), train_loss = 3.26231526, grad/param norm = 2.0752e+00, time/batch = 0.2125s	
479/2700 (epoch 8.870), train_loss = 3.25579272, grad/param norm = 1.7425e+00, time/batch = 0.2260s	
480/2700 (epoch 8.889), train_loss = 3.27259801, grad/param norm = 1.5014e+00, time/batch = 0.2259s	
481/2700 (epoch 8.907), train_loss = 3.32149164, grad/param norm = 1.6029e+00, time/batch = 0.2420s	
482/2700 (epoch 8.926), train_loss = 3.28530176, grad/param norm = 1.8625e+00, time/batch = 0.2533s	
483/2700 (epoch 8.944), train_loss = 3.29986057, grad/param norm = 1.6132e+00, time/batch = 0.2533s	
484/2700 (epoch 8.963), train_loss = 3.36363128, grad/param norm = 1.4214e+00, time/batch = 0.2551s	
485/2700 (epoch 8.981), train_loss = 3.42151462, grad/param norm = 1.4287e+00, time/batch = 0.2465s	
486/2700 (epoch 9.000), train_loss = 3.33023952, grad/param norm = 1.4357e+00, time/batch = 0.2305s	
487/2700 (epoch 9.019), train_loss = 3.26213691, grad/param norm = 1.5478e+00, time/batch = 0.2215s	
488/2700 (epoch 9.037), train_loss = 3.28760318, grad/param norm = 1.6032e+00, time/batch = 0.2139s	
489/2700 (epoch 9.056), train_loss = 3.27863687, grad/param norm = 1.1950e+00, time/batch = 0.2066s	
490/2700 (epoch 9.074), train_loss = 3.30470040, grad/param norm = 1.0764e+00, time/batch = 0.2175s	
491/2700 (epoch 9.093), train_loss = 3.31900836, grad/param norm = 1.2934e+00, time/batch = 0.2280s	
492/2700 (epoch 9.111), train_loss = 3.29395566, grad/param norm = 1.3984e+00, time/batch = 0.2161s	
493/2700 (epoch 9.130), train_loss = 3.31373060, grad/param norm = 1.3365e+00, time/batch = 0.2315s	
494/2700 (epoch 9.148), train_loss = 3.26919363, grad/param norm = 1.6492e+00, time/batch = 0.2354s	
495/2700 (epoch 9.167), train_loss = 3.29850569, grad/param norm = 1.8305e+00, time/batch = 0.2172s	
496/2700 (epoch 9.185), train_loss = 3.27368780, grad/param norm = 1.5980e+00, time/batch = 0.2086s	
497/2700 (epoch 9.204), train_loss = 3.20373288, grad/param norm = 1.5951e+00, time/batch = 0.1940s	
498/2700 (epoch 9.222), train_loss = 3.17778845, grad/param norm = 2.0152e+00, time/batch = 0.2062s	
499/2700 (epoch 9.241), train_loss = 3.20297770, grad/param norm = 2.0266e+00, time/batch = 0.2118s	
500/2700 (epoch 9.259), train_loss = 3.24121231, grad/param norm = 2.0690e+00, time/batch = 0.2308s	
501/2700 (epoch 9.278), train_loss = 3.32359016, grad/param norm = 2.7445e+00, time/batch = 0.2432s	
502/2700 (epoch 9.296), train_loss = 3.33696220, grad/param norm = 2.5346e+00, time/batch = 0.2466s	
503/2700 (epoch 9.315), train_loss = 3.29874758, grad/param norm = 1.7516e+00, time/batch = 0.2312s	
504/2700 (epoch 9.333), train_loss = 3.35718767, grad/param norm = 1.2903e+00, time/batch = 0.2433s	
505/2700 (epoch 9.352), train_loss = 3.36622187, grad/param norm = 1.4029e+00, time/batch = 0.2454s	
506/2700 (epoch 9.370), train_loss = 3.32125634, grad/param norm = 1.5873e+00, time/batch = 0.2329s	
507/2700 (epoch 9.389), train_loss = 3.27767677, grad/param norm = 1.5113e+00, time/batch = 0.1889s	
508/2700 (epoch 9.407), train_loss = 3.30220171, grad/param norm = 1.4081e+00, time/batch = 0.2024s	
509/2700 (epoch 9.426), train_loss = 3.30057580, grad/param norm = 1.3371e+00, time/batch = 0.2106s	
510/2700 (epoch 9.444), train_loss = 3.22419480, grad/param norm = 1.3906e+00, time/batch = 0.2131s	
511/2700 (epoch 9.463), train_loss = 3.27436358, grad/param norm = 1.6976e+00, time/batch = 0.2211s	
512/2700 (epoch 9.481), train_loss = 3.36188942, grad/param norm = 1.8846e+00, time/batch = 0.2387s	
513/2700 (epoch 9.500), train_loss = 3.40575838, grad/param norm = 2.1598e+00, time/batch = 0.2425s	
514/2700 (epoch 9.519), train_loss = 3.36334991, grad/param norm = 2.2321e+00, time/batch = 0.2324s	
515/2700 (epoch 9.537), train_loss = 3.36706254, grad/param norm = 2.0259e+00, time/batch = 0.2359s	
516/2700 (epoch 9.556), train_loss = 3.30195745, grad/param norm = 1.6331e+00, time/batch = 0.2225s	
517/2700 (epoch 9.574), train_loss = 3.24167562, grad/param norm = 1.2655e+00, time/batch = 0.2104s	
518/2700 (epoch 9.593), train_loss = 3.25138703, grad/param norm = 1.5338e+00, time/batch = 0.2358s	
519/2700 (epoch 9.611), train_loss = 3.19380947, grad/param norm = 1.4020e+00, time/batch = 0.2518s	
520/2700 (epoch 9.630), train_loss = 3.23461143, grad/param norm = 1.5621e+00, time/batch = 0.2470s	
521/2700 (epoch 9.648), train_loss = 3.31516315, grad/param norm = 1.7143e+00, time/batch = 0.2423s	
522/2700 (epoch 9.667), train_loss = 3.25412939, grad/param norm = 1.7895e+00, time/batch = 0.2548s	
523/2700 (epoch 9.685), train_loss = 3.24368341, grad/param norm = 1.6684e+00, time/batch = 0.2535s	
524/2700 (epoch 9.704), train_loss = 3.22237721, grad/param norm = 1.8766e+00, time/batch = 0.2540s	
525/2700 (epoch 9.722), train_loss = 3.21531747, grad/param norm = 1.7384e+00, time/batch = 0.2434s	
526/2700 (epoch 9.741), train_loss = 3.34047912, grad/param norm = 1.5958e+00, time/batch = 0.2426s	
527/2700 (epoch 9.759), train_loss = 3.29703988, grad/param norm = 1.8985e+00, time/batch = 0.2141s	
528/2700 (epoch 9.778), train_loss = 3.29671065, grad/param norm = 2.3091e+00, time/batch = 0.2246s	
529/2700 (epoch 9.796), train_loss = 3.30045627, grad/param norm = 2.2669e+00, time/batch = 0.2368s	
530/2700 (epoch 9.815), train_loss = 3.23287433, grad/param norm = 2.0209e+00, time/batch = 0.2539s	
531/2700 (epoch 9.833), train_loss = 3.27391861, grad/param norm = 2.0188e+00, time/batch = 0.2288s	
532/2700 (epoch 9.852), train_loss = 3.26233569, grad/param norm = 2.0701e+00, time/batch = 0.2442s	
533/2700 (epoch 9.870), train_loss = 3.25579216, grad/param norm = 1.7375e+00, time/batch = 0.2408s	
534/2700 (epoch 9.889), train_loss = 3.27258656, grad/param norm = 1.4967e+00, time/batch = 0.2337s	
535/2700 (epoch 9.907), train_loss = 3.32148075, grad/param norm = 1.5978e+00, time/batch = 0.2296s	
536/2700 (epoch 9.926), train_loss = 3.28529005, grad/param norm = 1.8569e+00, time/batch = 0.2249s	
537/2700 (epoch 9.944), train_loss = 3.29985159, grad/param norm = 1.6084e+00, time/batch = 0.2080s	
538/2700 (epoch 9.963), train_loss = 3.36362354, grad/param norm = 1.4171e+00, time/batch = 0.1972s	
539/2700 (epoch 9.981), train_loss = 3.42150566, grad/param norm = 1.4246e+00, time/batch = 0.2101s	
decayed learning rate by a factor 0.97 to 0.00194	
540/2700 (epoch 10.000), train_loss = 3.33023695, grad/param norm = 1.4316e+00, time/batch = 0.2264s	
541/2700 (epoch 10.019), train_loss = 3.26212845, grad/param norm = 1.5433e+00, time/batch = 0.2094s	
542/2700 (epoch 10.037), train_loss = 3.28430571, grad/param norm = 1.5270e+00, time/batch = 0.2474s	
543/2700 (epoch 10.056), train_loss = 3.27538626, grad/param norm = 1.1037e+00, time/batch = 0.2416s	
544/2700 (epoch 10.074), train_loss = 3.30280297, grad/param norm = 1.0173e+00, time/batch = 0.2376s	
545/2700 (epoch 10.093), train_loss = 3.31613892, grad/param norm = 1.2339e+00, time/batch = 0.2389s	
546/2700 (epoch 10.111), train_loss = 3.28989800, grad/param norm = 1.2987e+00, time/batch = 0.2348s	
547/2700 (epoch 10.130), train_loss = 3.30909436, grad/param norm = 1.2168e+00, time/batch = 0.2262s	
548/2700 (epoch 10.148), train_loss = 3.26534350, grad/param norm = 1.5085e+00, time/batch = 0.1976s	
549/2700 (epoch 10.167), train_loss = 3.29238601, grad/param norm = 1.7154e+00, time/batch = 0.2150s	
550/2700 (epoch 10.185), train_loss = 3.26824741, grad/param norm = 1.4059e+00, time/batch = 0.2029s	
551/2700 (epoch 10.204), train_loss = 3.19614246, grad/param norm = 1.3366e+00, time/batch = 0.2150s	
552/2700 (epoch 10.222), train_loss = 3.17056218, grad/param norm = 1.6114e+00, time/batch = 0.2072s	
553/2700 (epoch 10.241), train_loss = 3.19133388, grad/param norm = 1.2909e+00, time/batch = 0.2214s	
554/2700 (epoch 10.259), train_loss = 3.22243417, grad/param norm = 9.7204e-01, time/batch = 0.2348s	
555/2700 (epoch 10.278), train_loss = 3.29704717, grad/param norm = 1.2194e+00, time/batch = 0.2370s	
556/2700 (epoch 10.296), train_loss = 3.30468784, grad/param norm = 1.4014e+00, time/batch = 0.2410s	
557/2700 (epoch 10.315), train_loss = 3.28468904, grad/param norm = 1.4478e+00, time/batch = 0.2458s	
558/2700 (epoch 10.333), train_loss = 3.36253228, grad/param norm = 1.5969e+00, time/batch = 0.2394s	
559/2700 (epoch 10.352), train_loss = 3.38506348, grad/param norm = 2.2650e+00, time/batch = 0.2263s	
560/2700 (epoch 10.370), train_loss = 3.35363236, grad/param norm = 2.7245e+00, time/batch = 0.2141s	
561/2700 (epoch 10.389), train_loss = 3.30254199, grad/param norm = 2.6602e+00, time/batch = 0.2175s	
562/2700 (epoch 10.407), train_loss = 3.32611261, grad/param norm = 2.3646e+00, time/batch = 0.2117s	
563/2700 (epoch 10.426), train_loss = 3.30698256, grad/param norm = 1.7516e+00, time/batch = 0.2320s	
564/2700 (epoch 10.444), train_loss = 3.23008576, grad/param norm = 1.7047e+00, time/batch = 0.2493s	
565/2700 (epoch 10.463), train_loss = 3.27406594, grad/param norm = 1.7345e+00, time/batch = 0.2562s	
566/2700 (epoch 10.481), train_loss = 3.35613630, grad/param norm = 1.7316e+00, time/batch = 0.2565s	
567/2700 (epoch 10.500), train_loss = 3.39862659, grad/param norm = 1.8380e+00, time/batch = 0.2551s	
568/2700 (epoch 10.519), train_loss = 3.35173853, grad/param norm = 1.8297e+00, time/batch = 0.2523s	
569/2700 (epoch 10.537), train_loss = 3.35667835, grad/param norm = 1.7257e+00, time/batch = 0.2452s	
570/2700 (epoch 10.556), train_loss = 3.29577280, grad/param norm = 1.4023e+00, time/batch = 0.2324s	
571/2700 (epoch 10.574), train_loss = 3.23962728, grad/param norm = 1.1092e+00, time/batch = 0.2527s	
572/2700 (epoch 10.593), train_loss = 3.24895656, grad/param norm = 1.3930e+00, time/batch = 0.2437s	
573/2700 (epoch 10.611), train_loss = 3.19016578, grad/param norm = 1.2404e+00, time/batch = 0.2462s	
574/2700 (epoch 10.630), train_loss = 3.23012586, grad/param norm = 1.3418e+00, time/batch = 0.2303s	
575/2700 (epoch 10.648), train_loss = 3.30856278, grad/param norm = 1.5024e+00, time/batch = 0.2134s	
576/2700 (epoch 10.667), train_loss = 3.24916114, grad/param norm = 1.5940e+00, time/batch = 0.2237s	
577/2700 (epoch 10.685), train_loss = 3.23855629, grad/param norm = 1.5021e+00, time/batch = 0.2357s	
578/2700 (epoch 10.704), train_loss = 3.21693786, grad/param norm = 1.7159e+00, time/batch = 0.2278s	
579/2700 (epoch 10.722), train_loss = 3.20880869, grad/param norm = 1.5686e+00, time/batch = 0.2307s	
580/2700 (epoch 10.741), train_loss = 3.33604156, grad/param norm = 1.4622e+00, time/batch = 0.2245s	
581/2700 (epoch 10.759), train_loss = 3.29212539, grad/param norm = 1.8066e+00, time/batch = 0.2551s	
582/2700 (epoch 10.778), train_loss = 3.29735833, grad/param norm = 2.3451e+00, time/batch = 0.2580s	
583/2700 (epoch 10.796), train_loss = 3.30337049, grad/param norm = 2.3600e+00, time/batch = 0.2284s	
584/2700 (epoch 10.815), train_loss = 3.23418903, grad/param norm = 2.0947e+00, time/batch = 0.2313s	
585/2700 (epoch 10.833), train_loss = 3.27406679, grad/param norm = 2.0815e+00, time/batch = 0.2365s	
586/2700 (epoch 10.852), train_loss = 3.26265407, grad/param norm = 2.1121e+00, time/batch = 0.2413s	
587/2700 (epoch 10.870), train_loss = 3.25406665, grad/param norm = 1.7254e+00, time/batch = 0.2324s	
588/2700 (epoch 10.889), train_loss = 3.27124302, grad/param norm = 1.4614e+00, time/batch = 0.2145s	
589/2700 (epoch 10.907), train_loss = 3.32002829, grad/param norm = 1.5437e+00, time/batch = 0.2167s	
590/2700 (epoch 10.926), train_loss = 3.28312222, grad/param norm = 1.7932e+00, time/batch = 0.2312s	
591/2700 (epoch 10.944), train_loss = 3.29725849, grad/param norm = 1.5479e+00, time/batch = 0.2145s	
592/2700 (epoch 10.963), train_loss = 3.36175025, grad/param norm = 1.3601e+00, time/batch = 0.2529s	
593/2700 (epoch 10.981), train_loss = 3.41979470, grad/param norm = 1.3784e+00, time/batch = 0.2466s	
decayed learning rate by a factor 0.97 to 0.0018818	
594/2700 (epoch 11.000), train_loss = 3.32829172, grad/param norm = 1.3802e+00, time/batch = 0.2540s	
595/2700 (epoch 11.019), train_loss = 3.26055075, grad/param norm = 1.4881e+00, time/batch = 0.2542s	
596/2700 (epoch 11.037), train_loss = 3.28229126, grad/param norm = 1.4623e+00, time/batch = 0.2542s	
597/2700 (epoch 11.056), train_loss = 3.27392193, grad/param norm = 1.0550e+00, time/batch = 0.2545s	
598/2700 (epoch 11.074), train_loss = 3.30226052, grad/param norm = 1.0117e+00, time/batch = 0.2418s	
599/2700 (epoch 11.093), train_loss = 3.31514114, grad/param norm = 1.2332e+00, time/batch = 0.2212s	
600/2700 (epoch 11.111), train_loss = 3.28867424, grad/param norm = 1.2767e+00, time/batch = 0.2065s	
601/2700 (epoch 11.130), train_loss = 3.30743735, grad/param norm = 1.1899e+00, time/batch = 0.2344s	
602/2700 (epoch 11.148), train_loss = 3.26407401, grad/param norm = 1.4610e+00, time/batch = 0.2016s	
603/2700 (epoch 11.167), train_loss = 3.28966834, grad/param norm = 1.6913e+00, time/batch = 0.2490s	
604/2700 (epoch 11.185), train_loss = 3.26669985, grad/param norm = 1.3659e+00, time/batch = 0.2465s	
605/2700 (epoch 11.204), train_loss = 3.19474566, grad/param norm = 1.3829e+00, time/batch = 0.2392s	
606/2700 (epoch 11.222), train_loss = 3.17352358, grad/param norm = 1.6955e+00, time/batch = 0.2405s	
607/2700 (epoch 11.241), train_loss = 3.19922269, grad/param norm = 1.8605e+00, time/batch = 0.2322s	
608/2700 (epoch 11.259), train_loss = 3.24852054, grad/param norm = 2.6404e+00, time/batch = 0.2304s	
609/2700 (epoch 11.278), train_loss = 3.32974655, grad/param norm = 2.5500e+00, time/batch = 0.2200s	
610/2700 (epoch 11.296), train_loss = 3.31537688, grad/param norm = 2.1982e+00, time/batch = 0.2052s	
611/2700 (epoch 11.315), train_loss = 3.28779320, grad/param norm = 1.9335e+00, time/batch = 0.2107s	
612/2700 (epoch 11.333), train_loss = 3.36267301, grad/param norm = 1.6188e+00, time/batch = 0.1965s	
613/2700 (epoch 11.352), train_loss = 3.37427399, grad/param norm = 1.6423e+00, time/batch = 0.2000s	
614/2700 (epoch 11.370), train_loss = 3.32192143, grad/param norm = 1.4455e+00, time/batch = 0.2429s	
615/2700 (epoch 11.389), train_loss = 3.27123824, grad/param norm = 1.1840e+00, time/batch = 0.2524s	
616/2700 (epoch 11.407), train_loss = 3.29322328, grad/param norm = 1.0428e+00, time/batch = 0.2484s	
617/2700 (epoch 11.426), train_loss = 3.29623636, grad/param norm = 1.0701e+00, time/batch = 0.2456s	
618/2700 (epoch 11.444), train_loss = 3.21732666, grad/param norm = 1.0312e+00, time/batch = 0.2346s	
619/2700 (epoch 11.463), train_loss = 3.26470058, grad/param norm = 1.1087e+00, time/batch = 0.1971s	
620/2700 (epoch 11.481), train_loss = 3.33889420, grad/param norm = 9.0843e-01, time/batch = 0.2008s	
621/2700 (epoch 11.500), train_loss = 3.38156154, grad/param norm = 1.0284e+00, time/batch = 0.1878s	
622/2700 (epoch 11.519), train_loss = 3.33830445, grad/param norm = 1.2509e+00, time/batch = 0.2135s	
623/2700 (epoch 11.537), train_loss = 3.35075459, grad/param norm = 1.5234e+00, time/batch = 0.2324s	
624/2700 (epoch 11.556), train_loss = 3.29536924, grad/param norm = 1.4995e+00, time/batch = 0.2211s	
625/2700 (epoch 11.574), train_loss = 3.24319654, grad/param norm = 1.4299e+00, time/batch = 0.2154s	
626/2700 (epoch 11.593), train_loss = 3.25609090, grad/param norm = 1.8132e+00, time/batch = 0.2105s	
627/2700 (epoch 11.611), train_loss = 3.20211312, grad/param norm = 1.8611e+00, time/batch = 0.2059s	
628/2700 (epoch 11.630), train_loss = 3.24546607, grad/param norm = 2.1119e+00, time/batch = 0.2107s	
629/2700 (epoch 11.648), train_loss = 3.32832995, grad/param norm = 2.2743e+00, time/batch = 0.2153s	
630/2700 (epoch 11.667), train_loss = 3.26573519, grad/param norm = 2.3500e+00, time/batch = 0.2445s	
631/2700 (epoch 11.685), train_loss = 3.25088383, grad/param norm = 1.9390e+00, time/batch = 0.2298s	
632/2700 (epoch 11.704), train_loss = 3.22190464, grad/param norm = 1.9130e+00, time/batch = 0.2496s	
633/2700 (epoch 11.722), train_loss = 3.20876206, grad/param norm = 1.5983e+00, time/batch = 0.2544s	
634/2700 (epoch 11.741), train_loss = 3.33241131, grad/param norm = 1.3366e+00, time/batch = 0.2560s	
635/2700 (epoch 11.759), train_loss = 3.28475379, grad/param norm = 1.5712e+00, time/batch = 0.2376s	
636/2700 (epoch 11.778), train_loss = 3.28491107, grad/param norm = 1.9361e+00, time/batch = 0.2352s	
637/2700 (epoch 11.796), train_loss = 3.28643840, grad/param norm = 1.8938e+00, time/batch = 0.2180s	
638/2700 (epoch 11.815), train_loss = 3.22465125, grad/param norm = 1.6815e+00, time/batch = 0.2232s	
639/2700 (epoch 11.833), train_loss = 3.26321834, grad/param norm = 1.6706e+00, time/batch = 0.2310s	
640/2700 (epoch 11.852), train_loss = 3.25065360, grad/param norm = 1.7215e+00, time/batch = 0.2517s	
641/2700 (epoch 11.870), train_loss = 3.24823051, grad/param norm = 1.5782e+00, time/batch = 0.2342s	
642/2700 (epoch 11.889), train_loss = 3.27068248, grad/param norm = 1.4371e+00, time/batch = 0.2517s	
643/2700 (epoch 11.907), train_loss = 3.32063768, grad/param norm = 1.6041e+00, time/batch = 0.2524s	
644/2700 (epoch 11.926), train_loss = 3.28394146, grad/param norm = 1.8558e+00, time/batch = 0.2531s	
645/2700 (epoch 11.944), train_loss = 3.29677280, grad/param norm = 1.6000e+00, time/batch = 0.2462s	
646/2700 (epoch 11.963), train_loss = 3.36206424, grad/param norm = 1.4255e+00, time/batch = 0.2467s	
647/2700 (epoch 11.981), train_loss = 3.42036341, grad/param norm = 1.4165e+00, time/batch = 0.2390s	
decayed learning rate by a factor 0.97 to 0.001825346	
648/2700 (epoch 12.000), train_loss = 3.32739515, grad/param norm = 1.4237e+00, time/batch = 0.2157s	
649/2700 (epoch 12.019), train_loss = 3.26145143, grad/param norm = 1.5475e+00, time/batch = 0.1919s	
650/2700 (epoch 12.037), train_loss = 3.28226535, grad/param norm = 1.5331e+00, time/batch = 0.1928s	
651/2700 (epoch 12.056), train_loss = 3.27380054, grad/param norm = 1.0959e+00, time/batch = 0.2016s	
652/2700 (epoch 12.074), train_loss = 3.30114984, grad/param norm = 9.7381e-01, time/batch = 0.2128s	
653/2700 (epoch 12.093), train_loss = 3.31378271, grad/param norm = 1.1835e+00, time/batch = 0.2306s	
654/2700 (epoch 12.111), train_loss = 3.28708945, grad/param norm = 1.2626e+00, time/batch = 0.2389s	
655/2700 (epoch 12.130), train_loss = 3.30677049, grad/param norm = 1.1991e+00, time/batch = 0.2403s	
656/2700 (epoch 12.148), train_loss = 3.26330645, grad/param norm = 1.5165e+00, time/batch = 0.2252s	
657/2700 (epoch 12.167), train_loss = 3.28997656, grad/param norm = 1.7017e+00, time/batch = 0.2280s	
658/2700 (epoch 12.185), train_loss = 3.26591660, grad/param norm = 1.4718e+00, time/batch = 0.2239s	
659/2700 (epoch 12.204), train_loss = 3.19588414, grad/param norm = 1.4942e+00, time/batch = 0.2135s	
660/2700 (epoch 12.222), train_loss = 3.17315396, grad/param norm = 1.9293e+00, time/batch = 0.1834s	
661/2700 (epoch 12.241), train_loss = 3.19568422, grad/param norm = 1.8353e+00, time/batch = 0.2074s	
662/2700 (epoch 12.259), train_loss = 3.23280353, grad/param norm = 1.8109e+00, time/batch = 0.2234s	
663/2700 (epoch 12.278), train_loss = 3.31657400, grad/param norm = 2.3863e+00, time/batch = 0.2427s	
664/2700 (epoch 12.296), train_loss = 3.32449330, grad/param norm = 2.2821e+00, time/batch = 0.2471s	
665/2700 (epoch 12.315), train_loss = 3.28988309, grad/param norm = 1.6021e+00, time/batch = 0.2492s	
666/2700 (epoch 12.333), train_loss = 3.35224759, grad/param norm = 1.1650e+00, time/batch = 0.2477s	
667/2700 (epoch 12.352), train_loss = 3.36206218, grad/param norm = 1.2989e+00, time/batch = 0.2223s	
668/2700 (epoch 12.370), train_loss = 3.31560356, grad/param norm = 1.4860e+00, time/batch = 0.2365s	
669/2700 (epoch 12.389), train_loss = 3.27404634, grad/param norm = 1.4040e+00, time/batch = 0.2127s	
670/2700 (epoch 12.407), train_loss = 3.29662626, grad/param norm = 1.2692e+00, time/batch = 0.2071s	
671/2700 (epoch 12.426), train_loss = 3.29563951, grad/param norm = 1.1968e+00, time/batch = 0.2052s	
672/2700 (epoch 12.444), train_loss = 3.21927133, grad/param norm = 1.2418e+00, time/batch = 0.2217s	
673/2700 (epoch 12.463), train_loss = 3.26820458, grad/param norm = 1.5325e+00, time/batch = 0.2500s	
674/2700 (epoch 12.481), train_loss = 3.35351200, grad/param norm = 1.7181e+00, time/batch = 0.2540s	
675/2700 (epoch 12.500), train_loss = 3.39947173, grad/param norm = 2.0155e+00, time/batch = 0.2533s	
676/2700 (epoch 12.519), train_loss = 3.35619305, grad/param norm = 2.0698e+00, time/batch = 0.2542s	
677/2700 (epoch 12.537), train_loss = 3.35942045, grad/param norm = 1.8881e+00, time/batch = 0.2503s	
678/2700 (epoch 12.556), train_loss = 3.29471308, grad/param norm = 1.5182e+00, time/batch = 0.2542s	
679/2700 (epoch 12.574), train_loss = 3.23948965, grad/param norm = 1.1836e+00, time/batch = 0.2479s	
680/2700 (epoch 12.593), train_loss = 3.24830815, grad/param norm = 1.4382e+00, time/batch = 0.2187s	
681/2700 (epoch 12.611), train_loss = 3.18967116, grad/param norm = 1.2871e+00, time/batch = 0.2494s	
682/2700 (epoch 12.630), train_loss = 3.23031282, grad/param norm = 1.4143e+00, time/batch = 0.2515s	
683/2700 (epoch 12.648), train_loss = 3.30871349, grad/param norm = 1.5545e+00, time/batch = 0.2371s	
684/2700 (epoch 12.667), train_loss = 3.24660071, grad/param norm = 1.6096e+00, time/batch = 0.2202s	
685/2700 (epoch 12.685), train_loss = 3.23655159, grad/param norm = 1.4899e+00, time/batch = 0.2232s	
686/2700 (epoch 12.704), train_loss = 3.21399021, grad/param norm = 1.6871e+00, time/batch = 0.2434s	
687/2700 (epoch 12.722), train_loss = 3.20464391, grad/param norm = 1.5142e+00, time/batch = 0.2409s	
688/2700 (epoch 12.741), train_loss = 3.33179484, grad/param norm = 1.3656e+00, time/batch = 0.2552s	
689/2700 (epoch 12.759), train_loss = 3.28665276, grad/param norm = 1.6798e+00, time/batch = 0.2550s	
690/2700 (epoch 12.778), train_loss = 3.28954301, grad/param norm = 2.1460e+00, time/batch = 0.2428s	
691/2700 (epoch 12.796), train_loss = 3.29261908, grad/param norm = 2.1434e+00, time/batch = 0.2585s	
692/2700 (epoch 12.815), train_loss = 3.22735483, grad/param norm = 1.8982e+00, time/batch = 0.2572s	
693/2700 (epoch 12.833), train_loss = 3.26601662, grad/param norm = 1.8871e+00, time/batch = 0.2528s	
694/2700 (epoch 12.852), train_loss = 3.25473847, grad/param norm = 1.9248e+00, time/batch = 0.2538s	
695/2700 (epoch 12.870), train_loss = 3.24870376, grad/param norm = 1.6325e+00, time/batch = 0.2525s	
696/2700 (epoch 12.889), train_loss = 3.26931610, grad/param norm = 1.4071e+00, time/batch = 0.2526s	
697/2700 (epoch 12.907), train_loss = 3.31858485, grad/param norm = 1.5115e+00, time/batch = 0.2432s	
698/2700 (epoch 12.926), train_loss = 3.28060497, grad/param norm = 1.7425e+00, time/batch = 0.2346s	
699/2700 (epoch 12.944), train_loss = 3.29327576, grad/param norm = 1.4913e+00, time/batch = 0.2163s	
700/2700 (epoch 12.963), train_loss = 3.35920785, grad/param norm = 1.3139e+00, time/batch = 0.2041s	
701/2700 (epoch 12.981), train_loss = 3.41751513, grad/param norm = 1.3307e+00, time/batch = 0.1996s	
decayed learning rate by a factor 0.97 to 0.00177058562	
702/2700 (epoch 13.000), train_loss = 3.32510712, grad/param norm = 1.3306e+00, time/batch = 0.2488s	
703/2700 (epoch 13.019), train_loss = 3.25894271, grad/param norm = 1.4447e+00, time/batch = 0.2432s	
704/2700 (epoch 13.037), train_loss = 3.27957950, grad/param norm = 1.4126e+00, time/batch = 0.2385s	
705/2700 (epoch 13.056), train_loss = 3.27186226, grad/param norm = 1.0064e+00, time/batch = 0.2329s	
706/2700 (epoch 13.074), train_loss = 3.30079335, grad/param norm = 9.7630e-01, time/batch = 0.2143s	
707/2700 (epoch 13.093), train_loss = 3.31286030, grad/param norm = 1.1950e+00, time/batch = 0.2064s	
708/2700 (epoch 13.111), train_loss = 3.28583084, grad/param norm = 1.2250e+00, time/batch = 0.1918s	
709/2700 (epoch 13.130), train_loss = 3.30448460, grad/param norm = 1.1330e+00, time/batch = 0.2264s	
710/2700 (epoch 13.148), train_loss = 3.26143385, grad/param norm = 1.3987e+00, time/batch = 0.2370s	
711/2700 (epoch 13.167), train_loss = 3.28559536, grad/param norm = 1.6201e+00, time/batch = 0.2222s	
712/2700 (epoch 13.185), train_loss = 3.26276713, grad/param norm = 1.2826e+00, time/batch = 0.2182s	
713/2700 (epoch 13.204), train_loss = 3.19121942, grad/param norm = 1.2911e+00, time/batch = 0.2291s	
714/2700 (epoch 13.222), train_loss = 3.16980223, grad/param norm = 1.5967e+00, time/batch = 0.2254s	
715/2700 (epoch 13.241), train_loss = 3.19442911, grad/param norm = 1.7130e+00, time/batch = 0.2280s	
716/2700 (epoch 13.259), train_loss = 3.24123145, grad/param norm = 2.4102e+00, time/batch = 0.2228s	
717/2700 (epoch 13.278), train_loss = 3.32254738, grad/param norm = 2.4021e+00, time/batch = 0.2091s	
718/2700 (epoch 13.296), train_loss = 3.31322154, grad/param norm = 2.1892e+00, time/batch = 0.1925s	
719/2700 (epoch 13.315), train_loss = 3.28644257, grad/param norm = 1.9296e+00, time/batch = 0.1943s	
720/2700 (epoch 13.333), train_loss = 3.36086737, grad/param norm = 1.5929e+00, time/batch = 0.2093s	
721/2700 (epoch 13.352), train_loss = 3.37154225, grad/param norm = 1.5863e+00, time/batch = 0.1962s	
722/2700 (epoch 13.370), train_loss = 3.31677056, grad/param norm = 1.3733e+00, time/batch = 0.2301s	
723/2700 (epoch 13.389), train_loss = 3.26830659, grad/param norm = 1.1134e+00, time/batch = 0.2187s	
724/2700 (epoch 13.407), train_loss = 3.29043633, grad/param norm = 9.7657e-01, time/batch = 0.2320s	
725/2700 (epoch 13.426), train_loss = 3.29353875, grad/param norm = 1.0063e+00, time/batch = 0.2186s	
726/2700 (epoch 13.444), train_loss = 3.21521745, grad/param norm = 9.5777e-01, time/batch = 0.2191s	
727/2700 (epoch 13.463), train_loss = 3.26217120, grad/param norm = 1.0413e+00, time/batch = 0.2276s	
728/2700 (epoch 13.481), train_loss = 3.33658966, grad/param norm = 8.6164e-01, time/batch = 0.2468s	
729/2700 (epoch 13.500), train_loss = 3.38040001, grad/param norm = 1.0410e+00, time/batch = 0.2417s	
730/2700 (epoch 13.519), train_loss = 3.33740968, grad/param norm = 1.2650e+00, time/batch = 0.2527s	
731/2700 (epoch 13.537), train_loss = 3.34867819, grad/param norm = 1.5157e+00, time/batch = 0.2348s	
732/2700 (epoch 13.556), train_loss = 3.29133956, grad/param norm = 1.4486e+00, time/batch = 0.2515s	
733/2700 (epoch 13.574), train_loss = 3.24095093, grad/param norm = 1.3644e+00, time/batch = 0.2541s	
734/2700 (epoch 13.593), train_loss = 3.25356498, grad/param norm = 1.7479e+00, time/batch = 0.2453s	
735/2700 (epoch 13.611), train_loss = 3.19909633, grad/param norm = 1.7878e+00, time/batch = 0.2530s	
736/2700 (epoch 13.630), train_loss = 3.24361962, grad/param norm = 2.0549e+00, time/batch = 0.2463s	
737/2700 (epoch 13.648), train_loss = 3.32457423, grad/param norm = 2.1677e+00, time/batch = 0.2303s	
738/2700 (epoch 13.667), train_loss = 3.25655252, grad/param norm = 2.1034e+00, time/batch = 0.2104s	
739/2700 (epoch 13.685), train_loss = 3.24169001, grad/param norm = 1.7303e+00, time/batch = 0.2210s	
740/2700 (epoch 13.704), train_loss = 3.21515908, grad/param norm = 1.7796e+00, time/batch = 0.2193s	
741/2700 (epoch 13.722), train_loss = 3.20318826, grad/param norm = 1.4847e+00, time/batch = 0.2106s	
742/2700 (epoch 13.741), train_loss = 3.32805637, grad/param norm = 1.2320e+00, time/batch = 0.2304s	
743/2700 (epoch 13.759), train_loss = 3.28040665, grad/param norm = 1.4792e+00, time/batch = 0.2352s	
744/2700 (epoch 13.778), train_loss = 3.28059660, grad/param norm = 1.8391e+00, time/batch = 0.2423s	
745/2700 (epoch 13.796), train_loss = 3.28078696, grad/param norm = 1.8061e+00, time/batch = 0.2392s	
746/2700 (epoch 13.815), train_loss = 3.22095871, grad/param norm = 1.6020e+00, time/batch = 0.2524s	
747/2700 (epoch 13.833), train_loss = 3.25899546, grad/param norm = 1.5899e+00, time/batch = 0.2415s	
748/2700 (epoch 13.852), train_loss = 3.24668881, grad/param norm = 1.6430e+00, time/batch = 0.2246s	
749/2700 (epoch 13.870), train_loss = 3.24397511, grad/param norm = 1.5056e+00, time/batch = 0.2166s	
750/2700 (epoch 13.889), train_loss = 3.26839159, grad/param norm = 1.3739e+00, time/batch = 0.2198s	
751/2700 (epoch 13.907), train_loss = 3.31878272, grad/param norm = 1.5477e+00, time/batch = 0.2218s	
752/2700 (epoch 13.926), train_loss = 3.28084767, grad/param norm = 1.7829e+00, time/batch = 0.2218s	
753/2700 (epoch 13.944), train_loss = 3.29262819, grad/param norm = 1.5283e+00, time/batch = 0.2305s	
754/2700 (epoch 13.963), train_loss = 3.35934710, grad/param norm = 1.3616e+00, time/batch = 0.2261s	
755/2700 (epoch 13.981), train_loss = 3.41771885, grad/param norm = 1.3581e+00, time/batch = 0.2239s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
756/2700 (epoch 14.000), train_loss = 3.32421008, grad/param norm = 1.3605e+00, time/batch = 0.2115s	
757/2700 (epoch 14.019), train_loss = 3.25943514, grad/param norm = 1.4863e+00, time/batch = 0.2061s	
758/2700 (epoch 14.037), train_loss = 3.27924377, grad/param norm = 1.4602e+00, time/batch = 0.1887s	
759/2700 (epoch 14.056), train_loss = 3.27150877, grad/param norm = 1.0290e+00, time/batch = 0.1919s	
760/2700 (epoch 14.074), train_loss = 3.29980918, grad/param norm = 9.3854e-01, time/batch = 0.2066s	
761/2700 (epoch 14.093), train_loss = 3.31159272, grad/param norm = 1.1497e+00, time/batch = 0.1941s	
762/2700 (epoch 14.111), train_loss = 3.28441870, grad/param norm = 1.2045e+00, time/batch = 0.2369s	
763/2700 (epoch 14.130), train_loss = 3.30365263, grad/param norm = 1.1279e+00, time/batch = 0.2545s	
764/2700 (epoch 14.148), train_loss = 3.26059918, grad/param norm = 1.4245e+00, time/batch = 0.2540s	
765/2700 (epoch 14.167), train_loss = 3.28484772, grad/param norm = 1.6012e+00, time/batch = 0.2529s	
766/2700 (epoch 14.185), train_loss = 3.26132672, grad/param norm = 1.3191e+00, time/batch = 0.2567s	
767/2700 (epoch 14.204), train_loss = 3.19088964, grad/param norm = 1.2992e+00, time/batch = 0.2493s	
768/2700 (epoch 14.222), train_loss = 3.16774774, grad/param norm = 1.7059e+00, time/batch = 0.2280s	
769/2700 (epoch 14.241), train_loss = 3.19031098, grad/param norm = 1.5779e+00, time/batch = 0.2163s	
770/2700 (epoch 14.259), train_loss = 3.22674920, grad/param norm = 1.5944e+00, time/batch = 0.2307s	
771/2700 (epoch 14.278), train_loss = 3.31179097, grad/param norm = 2.3394e+00, time/batch = 0.2072s	
772/2700 (epoch 14.296), train_loss = 3.32215550, grad/param norm = 2.2753e+00, time/batch = 0.2292s	
773/2700 (epoch 14.315), train_loss = 3.28636452, grad/param norm = 1.5921e+00, time/batch = 0.2448s	
774/2700 (epoch 14.333), train_loss = 3.35029967, grad/param norm = 1.1705e+00, time/batch = 0.2375s	
775/2700 (epoch 14.352), train_loss = 3.36029853, grad/param norm = 1.2870e+00, time/batch = 0.2367s	
776/2700 (epoch 14.370), train_loss = 3.31323679, grad/param norm = 1.4952e+00, time/batch = 0.2297s	
777/2700 (epoch 14.389), train_loss = 3.27343010, grad/param norm = 1.4131e+00, time/batch = 0.2303s	
778/2700 (epoch 14.407), train_loss = 3.29436210, grad/param norm = 1.2488e+00, time/batch = 0.2334s	
779/2700 (epoch 14.426), train_loss = 3.29341170, grad/param norm = 1.1565e+00, time/batch = 0.2089s	
780/2700 (epoch 14.444), train_loss = 3.21762416, grad/param norm = 1.2058e+00, time/batch = 0.2053s	
781/2700 (epoch 14.463), train_loss = 3.26600220, grad/param norm = 1.4773e+00, time/batch = 0.1999s	
782/2700 (epoch 14.481), train_loss = 3.34967688, grad/param norm = 1.6354e+00, time/batch = 0.2024s	
783/2700 (epoch 14.500), train_loss = 3.39566686, grad/param norm = 1.9063e+00, time/batch = 0.2405s	
784/2700 (epoch 14.519), train_loss = 3.35101621, grad/param norm = 1.9308e+00, time/batch = 0.2397s	
785/2700 (epoch 14.537), train_loss = 3.35415585, grad/param norm = 1.7723e+00, time/batch = 0.2344s	
786/2700 (epoch 14.556), train_loss = 3.29001873, grad/param norm = 1.4218e+00, time/batch = 0.2299s	
787/2700 (epoch 14.574), train_loss = 3.23793017, grad/param norm = 1.1142e+00, time/batch = 0.2261s	
788/2700 (epoch 14.593), train_loss = 3.24610760, grad/param norm = 1.3656e+00, time/batch = 0.2282s	
789/2700 (epoch 14.611), train_loss = 3.18699296, grad/param norm = 1.2050e+00, time/batch = 0.2312s	
790/2700 (epoch 14.630), train_loss = 3.22770281, grad/param norm = 1.3168e+00, time/batch = 0.1973s	
791/2700 (epoch 14.648), train_loss = 3.30505286, grad/param norm = 1.4523e+00, time/batch = 0.2080s	
792/2700 (epoch 14.667), train_loss = 3.24211136, grad/param norm = 1.4923e+00, time/batch = 0.2025s	
793/2700 (epoch 14.685), train_loss = 3.23251752, grad/param norm = 1.3783e+00, time/batch = 0.1929s	
794/2700 (epoch 14.704), train_loss = 3.20925288, grad/param norm = 1.5721e+00, time/batch = 0.2181s	
795/2700 (epoch 14.722), train_loss = 3.19905231, grad/param norm = 1.3826e+00, time/batch = 0.2212s	
796/2700 (epoch 14.741), train_loss = 3.32723945, grad/param norm = 1.2440e+00, time/batch = 0.2273s	
797/2700 (epoch 14.759), train_loss = 3.28171247, grad/param norm = 1.5665e+00, time/batch = 0.2349s	
798/2700 (epoch 14.778), train_loss = 3.28501610, grad/param norm = 2.0384e+00, time/batch = 0.2448s	
799/2700 (epoch 14.796), train_loss = 3.28759101, grad/param norm = 2.0732e+00, time/batch = 0.2503s	
800/2700 (epoch 14.815), train_loss = 3.22442014, grad/param norm = 1.8423e+00, time/batch = 0.2515s	
801/2700 (epoch 14.833), train_loss = 3.26208922, grad/param norm = 1.8322e+00, time/batch = 0.1990s	
802/2700 (epoch 14.852), train_loss = 3.25073979, grad/param norm = 1.8569e+00, time/batch = 0.2024s	
803/2700 (epoch 14.870), train_loss = 3.24444850, grad/param norm = 1.5748e+00, time/batch = 0.1984s	
804/2700 (epoch 14.889), train_loss = 3.26738228, grad/param norm = 1.3595e+00, time/batch = 0.2453s	
805/2700 (epoch 14.907), train_loss = 3.31699282, grad/param norm = 1.4639e+00, time/batch = 0.2533s	
806/2700 (epoch 14.926), train_loss = 3.27776096, grad/param norm = 1.6715e+00, time/batch = 0.2532s	
807/2700 (epoch 14.944), train_loss = 3.28927828, grad/param norm = 1.4186e+00, time/batch = 0.2533s	
808/2700 (epoch 14.963), train_loss = 3.35664616, grad/param norm = 1.2526e+00, time/batch = 0.2489s	
809/2700 (epoch 14.981), train_loss = 3.41529848, grad/param norm = 1.2779e+00, time/batch = 0.2437s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
810/2700 (epoch 15.000), train_loss = 3.32214044, grad/param norm = 1.2752e+00, time/batch = 0.2356s	
811/2700 (epoch 15.019), train_loss = 3.25710143, grad/param norm = 1.3877e+00, time/batch = 0.2378s	
812/2700 (epoch 15.037), train_loss = 3.27672292, grad/param norm = 1.3429e+00, time/batch = 0.2512s	
813/2700 (epoch 15.056), train_loss = 3.26985956, grad/param norm = 9.5283e-01, time/batch = 0.2390s	
814/2700 (epoch 15.074), train_loss = 3.29972157, grad/param norm = 9.6735e-01, time/batch = 0.2259s	
815/2700 (epoch 15.093), train_loss = 3.31101225, grad/param norm = 1.1831e+00, time/batch = 0.2031s	
816/2700 (epoch 15.111), train_loss = 3.28345843, grad/param norm = 1.1905e+00, time/batch = 0.1958s	
817/2700 (epoch 15.130), train_loss = 3.30182171, grad/param norm = 1.0954e+00, time/batch = 0.2182s	
818/2700 (epoch 15.148), train_loss = 3.25935550, grad/param norm = 1.3473e+00, time/batch = 0.2384s	
819/2700 (epoch 15.167), train_loss = 3.28190404, grad/param norm = 1.5834e+00, time/batch = 0.2498s	
820/2700 (epoch 15.185), train_loss = 3.26008900, grad/param norm = 1.2574e+00, time/batch = 0.2521s	
821/2700 (epoch 15.204), train_loss = 3.18971947, grad/param norm = 1.3368e+00, time/batch = 0.2390s	
822/2700 (epoch 15.222), train_loss = 3.17062978, grad/param norm = 1.7057e+00, time/batch = 0.2266s	
823/2700 (epoch 15.241), train_loss = 3.19727911, grad/param norm = 1.9171e+00, time/batch = 0.2305s	
824/2700 (epoch 15.259), train_loss = 3.24010698, grad/param norm = 2.4627e+00, time/batch = 0.2140s	
825/2700 (epoch 15.278), train_loss = 3.31446981, grad/param norm = 2.2137e+00, time/batch = 0.2148s	
826/2700 (epoch 15.296), train_loss = 3.30570494, grad/param norm = 1.8825e+00, time/batch = 0.2312s	
827/2700 (epoch 15.315), train_loss = 3.27912007, grad/param norm = 1.6642e+00, time/batch = 0.2478s	
828/2700 (epoch 15.333), train_loss = 3.35672982, grad/param norm = 1.4386e+00, time/batch = 0.2532s	
829/2700 (epoch 15.352), train_loss = 3.36644304, grad/param norm = 1.4393e+00, time/batch = 0.2532s	
830/2700 (epoch 15.370), train_loss = 3.31086395, grad/param norm = 1.2607e+00, time/batch = 0.2526s	
831/2700 (epoch 15.389), train_loss = 3.26540973, grad/param norm = 1.0339e+00, time/batch = 0.2567s	
832/2700 (epoch 15.407), train_loss = 3.28807775, grad/param norm = 9.1951e-01, time/batch = 0.2523s	
833/2700 (epoch 15.426), train_loss = 3.29135275, grad/param norm = 9.5648e-01, time/batch = 0.2397s	
834/2700 (epoch 15.444), train_loss = 3.21417767, grad/param norm = 9.3357e-01, time/batch = 0.2477s	
835/2700 (epoch 15.463), train_loss = 3.26093695, grad/param norm = 1.0295e+00, time/batch = 0.2405s	
836/2700 (epoch 15.481), train_loss = 3.33504641, grad/param norm = 8.5846e-01, time/batch = 0.2248s	
837/2700 (epoch 15.500), train_loss = 3.37958868, grad/param norm = 1.0838e+00, time/batch = 0.2116s	
838/2700 (epoch 15.519), train_loss = 3.33652989, grad/param norm = 1.2982e+00, time/batch = 0.2224s	
839/2700 (epoch 15.537), train_loss = 3.34671424, grad/param norm = 1.5227e+00, time/batch = 0.2314s	
840/2700 (epoch 15.556), train_loss = 3.28821414, grad/param norm = 1.4244e+00, time/batch = 0.2279s	
841/2700 (epoch 15.574), train_loss = 3.24003479, grad/param norm = 1.3208e+00, time/batch = 0.2409s	
842/2700 (epoch 15.593), train_loss = 3.25165594, grad/param norm = 1.6882e+00, time/batch = 0.2437s	
843/2700 (epoch 15.611), train_loss = 3.19598513, grad/param norm = 1.6712e+00, time/batch = 0.2279s	
844/2700 (epoch 15.630), train_loss = 3.23840735, grad/param norm = 1.8763e+00, time/batch = 0.2207s	
845/2700 (epoch 15.648), train_loss = 3.31725527, grad/param norm = 1.9762e+00, time/batch = 0.2149s	
846/2700 (epoch 15.667), train_loss = 3.24884668, grad/param norm = 1.8993e+00, time/batch = 0.2366s	
847/2700 (epoch 15.685), train_loss = 3.23554738, grad/param norm = 1.5684e+00, time/batch = 0.2216s	
848/2700 (epoch 15.704), train_loss = 3.20939031, grad/param norm = 1.6513e+00, time/batch = 0.2045s	
849/2700 (epoch 15.722), train_loss = 3.19828712, grad/param norm = 1.3770e+00, time/batch = 0.2130s	
850/2700 (epoch 15.741), train_loss = 3.32438282, grad/param norm = 1.1433e+00, time/batch = 0.2295s	
851/2700 (epoch 15.759), train_loss = 3.27682662, grad/param norm = 1.4054e+00, time/batch = 0.2324s	
852/2700 (epoch 15.778), train_loss = 3.27694443, grad/param norm = 1.7574e+00, time/batch = 0.2484s	
853/2700 (epoch 15.796), train_loss = 3.27609159, grad/param norm = 1.7396e+00, time/batch = 0.2508s	
854/2700 (epoch 15.815), train_loss = 3.21805780, grad/param norm = 1.5490e+00, time/batch = 0.2306s	
855/2700 (epoch 15.833), train_loss = 3.25581621, grad/param norm = 1.5398e+00, time/batch = 0.2186s	
856/2700 (epoch 15.852), train_loss = 3.24373804, grad/param norm = 1.5934e+00, time/batch = 0.2106s	
857/2700 (epoch 15.870), train_loss = 3.24034476, grad/param norm = 1.4512e+00, time/batch = 0.2065s	
858/2700 (epoch 15.889), train_loss = 3.26635872, grad/param norm = 1.3226e+00, time/batch = 0.1842s	
859/2700 (epoch 15.907), train_loss = 3.31714511, grad/param norm = 1.4964e+00, time/batch = 0.1827s	
860/2700 (epoch 15.926), train_loss = 3.27793573, grad/param norm = 1.7097e+00, time/batch = 0.1966s	
861/2700 (epoch 15.944), train_loss = 3.28875124, grad/param norm = 1.4551e+00, time/batch = 0.1986s	
862/2700 (epoch 15.963), train_loss = 3.35686316, grad/param norm = 1.2969e+00, time/batch = 0.2226s	
863/2700 (epoch 15.981), train_loss = 3.41542787, grad/param norm = 1.3024e+00, time/batch = 0.2358s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
864/2700 (epoch 16.000), train_loss = 3.32133165, grad/param norm = 1.2995e+00, time/batch = 0.2353s	
865/2700 (epoch 16.019), train_loss = 3.25754404, grad/param norm = 1.4242e+00, time/batch = 0.2536s	
866/2700 (epoch 16.037), train_loss = 3.27638561, grad/param norm = 1.3835e+00, time/batch = 0.2376s	
867/2700 (epoch 16.056), train_loss = 3.26943501, grad/param norm = 9.6334e-01, time/batch = 0.2321s	
868/2700 (epoch 16.074), train_loss = 3.29867903, grad/param norm = 9.1550e-01, time/batch = 0.2154s	
869/2700 (epoch 16.093), train_loss = 3.30964971, grad/param norm = 1.1257e+00, time/batch = 0.2233s	
870/2700 (epoch 16.111), train_loss = 3.28199220, grad/param norm = 1.1531e+00, time/batch = 0.2415s	
871/2700 (epoch 16.130), train_loss = 3.30076379, grad/param norm = 1.0641e+00, time/batch = 0.2327s	
872/2700 (epoch 16.148), train_loss = 3.25821966, grad/param norm = 1.3360e+00, time/batch = 0.2448s	
873/2700 (epoch 16.167), train_loss = 3.28022025, grad/param norm = 1.5138e+00, time/batch = 0.2520s	
874/2700 (epoch 16.185), train_loss = 3.25743019, grad/param norm = 1.1727e+00, time/batch = 0.2486s	
875/2700 (epoch 16.204), train_loss = 3.18655589, grad/param norm = 1.1132e+00, time/batch = 0.2524s	
876/2700 (epoch 16.222), train_loss = 3.16298661, grad/param norm = 1.4276e+00, time/batch = 0.2551s	
877/2700 (epoch 16.241), train_loss = 3.18319877, grad/param norm = 1.1179e+00, time/batch = 0.2184s	
878/2700 (epoch 16.259), train_loss = 3.21535854, grad/param norm = 8.6832e-01, time/batch = 0.2137s	
879/2700 (epoch 16.278), train_loss = 3.29328303, grad/param norm = 1.3309e+00, time/batch = 0.2002s	
880/2700 (epoch 16.296), train_loss = 3.30464424, grad/param norm = 1.7100e+00, time/batch = 0.2102s	
881/2700 (epoch 16.315), train_loss = 3.28716740, grad/param norm = 1.8663e+00, time/batch = 0.2074s	
882/2700 (epoch 16.333), train_loss = 3.36135291, grad/param norm = 1.7818e+00, time/batch = 0.2265s	
883/2700 (epoch 16.352), train_loss = 3.36826713, grad/param norm = 1.8760e+00, time/batch = 0.2497s	
884/2700 (epoch 16.370), train_loss = 3.32233831, grad/param norm = 2.0718e+00, time/batch = 0.2445s	
885/2700 (epoch 16.389), train_loss = 3.28002010, grad/param norm = 1.8281e+00, time/batch = 0.2532s	
886/2700 (epoch 16.407), train_loss = 3.29748035, grad/param norm = 1.5555e+00, time/batch = 0.2567s	
887/2700 (epoch 16.426), train_loss = 3.29378966, grad/param norm = 1.2852e+00, time/batch = 0.2447s	
888/2700 (epoch 16.444), train_loss = 3.21856626, grad/param norm = 1.2996e+00, time/batch = 0.2486s	
889/2700 (epoch 16.463), train_loss = 3.26478988, grad/param norm = 1.4190e+00, time/batch = 0.2263s	
890/2700 (epoch 16.481), train_loss = 3.34460051, grad/param norm = 1.4407e+00, time/batch = 0.2177s	
891/2700 (epoch 16.500), train_loss = 3.38894909, grad/param norm = 1.6081e+00, time/batch = 0.2253s	
892/2700 (epoch 16.519), train_loss = 3.34192516, grad/param norm = 1.5929e+00, time/batch = 0.2218s	
893/2700 (epoch 16.537), train_loss = 3.34654358, grad/param norm = 1.5270e+00, time/batch = 0.2388s	
894/2700 (epoch 16.556), train_loss = 3.28458318, grad/param norm = 1.2305e+00, time/batch = 0.2426s	
895/2700 (epoch 16.574), train_loss = 3.23596063, grad/param norm = 9.9223e-01, time/batch = 0.2460s	
896/2700 (epoch 16.593), train_loss = 3.24362854, grad/param norm = 1.2603e+00, time/batch = 0.2404s	
897/2700 (epoch 16.611), train_loss = 3.18407516, grad/param norm = 1.0963e+00, time/batch = 0.2344s	
898/2700 (epoch 16.630), train_loss = 3.22463397, grad/param norm = 1.1758e+00, time/batch = 0.2231s	
899/2700 (epoch 16.648), train_loss = 3.30049852, grad/param norm = 1.2976e+00, time/batch = 0.2099s	
900/2700 (epoch 16.667), train_loss = 3.23694861, grad/param norm = 1.3221e+00, time/batch = 0.1903s	
901/2700 (epoch 16.685), train_loss = 3.22797821, grad/param norm = 1.2293e+00, time/batch = 0.2555s	
902/2700 (epoch 16.704), train_loss = 3.20418557, grad/param norm = 1.4303e+00, time/batch = 0.2490s	
903/2700 (epoch 16.722), train_loss = 3.19379131, grad/param norm = 1.2291e+00, time/batch = 0.2267s	
904/2700 (epoch 16.741), train_loss = 3.32299242, grad/param norm = 1.1172e+00, time/batch = 0.2029s	
905/2700 (epoch 16.759), train_loss = 3.27702969, grad/param norm = 1.4492e+00, time/batch = 0.1972s	
906/2700 (epoch 16.778), train_loss = 3.28109166, grad/param norm = 1.9403e+00, time/batch = 0.2010s	
907/2700 (epoch 16.796), train_loss = 3.28437932, grad/param norm = 2.0491e+00, time/batch = 0.2135s	
908/2700 (epoch 16.815), train_loss = 3.22323461, grad/param norm = 1.8504e+00, time/batch = 0.2078s	
909/2700 (epoch 16.833), train_loss = 3.26016360, grad/param norm = 1.8532e+00, time/batch = 0.2235s	
910/2700 (epoch 16.852), train_loss = 3.24884659, grad/param norm = 1.8551e+00, time/batch = 0.2192s	
911/2700 (epoch 16.870), train_loss = 3.24092599, grad/param norm = 1.5355e+00, time/batch = 0.2466s	
912/2700 (epoch 16.889), train_loss = 3.26548422, grad/param norm = 1.3124e+00, time/batch = 0.2518s	
913/2700 (epoch 16.907), train_loss = 3.31540147, grad/param norm = 1.4073e+00, time/batch = 0.2485s	
914/2700 (epoch 16.926), train_loss = 3.27492991, grad/param norm = 1.5911e+00, time/batch = 0.2301s	
915/2700 (epoch 16.944), train_loss = 3.28553014, grad/param norm = 1.3418e+00, time/batch = 0.2038s	
916/2700 (epoch 16.963), train_loss = 3.35435459, grad/param norm = 1.1913e+00, time/batch = 0.2048s	
917/2700 (epoch 16.981), train_loss = 3.41350390, grad/param norm = 1.2324e+00, time/batch = 0.2153s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
918/2700 (epoch 17.000), train_loss = 3.31955320, grad/param norm = 1.2249e+00, time/batch = 0.2124s	
919/2700 (epoch 17.019), train_loss = 3.25530020, grad/param norm = 1.3295e+00, time/batch = 0.2209s	
920/2700 (epoch 17.037), train_loss = 3.27396711, grad/param norm = 1.2686e+00, time/batch = 0.2188s	
921/2700 (epoch 17.056), train_loss = 3.26808934, grad/param norm = 9.0648e-01, time/batch = 0.2412s	
922/2700 (epoch 17.074), train_loss = 3.29893864, grad/param norm = 9.8028e-01, time/batch = 0.2536s	
923/2700 (epoch 17.093), train_loss = 3.30950634, grad/param norm = 1.1873e+00, time/batch = 0.2533s	
924/2700 (epoch 17.111), train_loss = 3.28136221, grad/param norm = 1.1683e+00, time/batch = 0.2419s	
925/2700 (epoch 17.130), train_loss = 3.29940412, grad/param norm = 1.0691e+00, time/batch = 0.2148s	
926/2700 (epoch 17.148), train_loss = 3.25754533, grad/param norm = 1.3062e+00, time/batch = 0.1976s	
927/2700 (epoch 17.167), train_loss = 3.27876649, grad/param norm = 1.5598e+00, time/batch = 0.1880s	
928/2700 (epoch 17.185), train_loss = 3.25782626, grad/param norm = 1.2493e+00, time/batch = 0.1856s	
929/2700 (epoch 17.204), train_loss = 3.18849226, grad/param norm = 1.3664e+00, time/batch = 0.1928s	
930/2700 (epoch 17.222), train_loss = 3.17004200, grad/param norm = 1.7308e+00, time/batch = 0.2318s	
931/2700 (epoch 17.241), train_loss = 3.19514536, grad/param norm = 1.8827e+00, time/batch = 0.2294s	
932/2700 (epoch 17.259), train_loss = 3.23311828, grad/param norm = 2.1965e+00, time/batch = 0.2157s	
933/2700 (epoch 17.278), train_loss = 3.30528908, grad/param norm = 1.9544e+00, time/batch = 0.2282s	
934/2700 (epoch 17.296), train_loss = 3.30209620, grad/param norm = 1.7651e+00, time/batch = 0.2127s	
935/2700 (epoch 17.315), train_loss = 3.27637724, grad/param norm = 1.5826e+00, time/batch = 0.1865s	
936/2700 (epoch 17.333), train_loss = 3.35425931, grad/param norm = 1.3811e+00, time/batch = 0.2215s	
937/2700 (epoch 17.352), train_loss = 3.36308745, grad/param norm = 1.3701e+00, time/batch = 0.2367s	
938/2700 (epoch 17.370), train_loss = 3.30679660, grad/param norm = 1.1949e+00, time/batch = 0.2507s	
939/2700 (epoch 17.389), train_loss = 3.26319661, grad/param norm = 9.7429e-01, time/batch = 0.2457s	
940/2700 (epoch 17.407), train_loss = 3.28601790, grad/param norm = 8.7154e-01, time/batch = 0.2407s	
941/2700 (epoch 17.426), train_loss = 3.28946420, grad/param norm = 9.1812e-01, time/batch = 0.2375s	
942/2700 (epoch 17.444), train_loss = 3.21309422, grad/param norm = 8.9859e-01, time/batch = 0.2412s	
943/2700 (epoch 17.463), train_loss = 3.25939667, grad/param norm = 9.9928e-01, time/batch = 0.2268s	
944/2700 (epoch 17.481), train_loss = 3.33345447, grad/param norm = 8.3385e-01, time/batch = 0.2312s	
945/2700 (epoch 17.500), train_loss = 3.37863174, grad/param norm = 1.0906e+00, time/batch = 0.2065s	
946/2700 (epoch 17.519), train_loss = 3.33554095, grad/param norm = 1.2972e+00, time/batch = 0.1983s	
947/2700 (epoch 17.537), train_loss = 3.34470585, grad/param norm = 1.4989e+00, time/batch = 0.1981s	
948/2700 (epoch 17.556), train_loss = 3.28485523, grad/param norm = 1.3712e+00, time/batch = 0.2240s	
949/2700 (epoch 17.574), train_loss = 3.23876938, grad/param norm = 1.2625e+00, time/batch = 0.2409s	
950/2700 (epoch 17.593), train_loss = 3.24941916, grad/param norm = 1.6187e+00, time/batch = 0.2402s	
951/2700 (epoch 17.611), train_loss = 3.19269897, grad/param norm = 1.5704e+00, time/batch = 0.2425s	
952/2700 (epoch 17.630), train_loss = 3.23448946, grad/param norm = 1.7419e+00, time/batch = 0.2511s	
953/2700 (epoch 17.648), train_loss = 3.31172762, grad/param norm = 1.8316e+00, time/batch = 0.2532s	
954/2700 (epoch 17.667), train_loss = 3.24327629, grad/param norm = 1.7555e+00, time/batch = 0.2399s	
955/2700 (epoch 17.685), train_loss = 3.23116045, grad/param norm = 1.4492e+00, time/batch = 0.2296s	
956/2700 (epoch 17.704), train_loss = 3.20503939, grad/param norm = 1.5488e+00, time/batch = 0.2205s	
957/2700 (epoch 17.722), train_loss = 3.19430651, grad/param norm = 1.2818e+00, time/batch = 0.2179s	
958/2700 (epoch 17.741), train_loss = 3.32130352, grad/param norm = 1.0643e+00, time/batch = 0.2358s	
959/2700 (epoch 17.759), train_loss = 3.27365901, grad/param norm = 1.3340e+00, time/batch = 0.2515s	
960/2700 (epoch 17.778), train_loss = 3.27325638, grad/param norm = 1.6639e+00, time/batch = 0.2440s	
961/2700 (epoch 17.796), train_loss = 3.27146671, grad/param norm = 1.6650e+00, time/batch = 0.2401s	
962/2700 (epoch 17.815), train_loss = 3.21536477, grad/param norm = 1.4902e+00, time/batch = 0.2508s	
963/2700 (epoch 17.833), train_loss = 3.25284399, grad/param norm = 1.4819e+00, time/batch = 0.2517s	
964/2700 (epoch 17.852), train_loss = 3.24079508, grad/param norm = 1.5336e+00, time/batch = 0.2559s	
965/2700 (epoch 17.870), train_loss = 3.23683743, grad/param norm = 1.3900e+00, time/batch = 0.2392s	
966/2700 (epoch 17.889), train_loss = 3.26442400, grad/param norm = 1.2700e+00, time/batch = 0.2503s	
967/2700 (epoch 17.907), train_loss = 3.31571124, grad/param norm = 1.4495e+00, time/batch = 0.2306s	
968/2700 (epoch 17.926), train_loss = 3.27522376, grad/param norm = 1.6394e+00, time/batch = 0.2127s	
969/2700 (epoch 17.944), train_loss = 3.28519749, grad/param norm = 1.3875e+00, time/batch = 0.2206s	
970/2700 (epoch 17.963), train_loss = 3.35475625, grad/param norm = 1.2415e+00, time/batch = 0.2277s	
971/2700 (epoch 17.981), train_loss = 3.41358093, grad/param norm = 1.2556e+00, time/batch = 0.2154s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
972/2700 (epoch 18.000), train_loss = 3.31877193, grad/param norm = 1.2482e+00, time/batch = 0.2244s	
973/2700 (epoch 18.019), train_loss = 3.25587915, grad/param norm = 1.3706e+00, time/batch = 0.2289s	
974/2700 (epoch 18.037), train_loss = 3.27381963, grad/param norm = 1.3157e+00, time/batch = 0.2348s	
975/2700 (epoch 18.056), train_loss = 3.26766766, grad/param norm = 9.0884e-01, time/batch = 0.2368s	
976/2700 (epoch 18.074), train_loss = 3.29770591, grad/param norm = 9.0251e-01, time/batch = 0.2175s	
977/2700 (epoch 18.093), train_loss = 3.30793233, grad/param norm = 1.1084e+00, time/batch = 0.2121s	
978/2700 (epoch 18.111), train_loss = 3.27983289, grad/param norm = 1.1122e+00, time/batch = 0.1978s	
979/2700 (epoch 18.130), train_loss = 3.29824090, grad/param norm = 1.0167e+00, time/batch = 0.1976s	
980/2700 (epoch 18.148), train_loss = 3.25628763, grad/param norm = 1.2688e+00, time/batch = 0.2161s	
981/2700 (epoch 18.167), train_loss = 3.27652128, grad/param norm = 1.4558e+00, time/batch = 0.2042s	
982/2700 (epoch 18.185), train_loss = 3.25466815, grad/param norm = 1.0899e+00, time/batch = 0.2297s	
983/2700 (epoch 18.204), train_loss = 3.18418069, grad/param norm = 1.0577e+00, time/batch = 0.2256s	
984/2700 (epoch 18.222), train_loss = 3.16175666, grad/param norm = 1.3428e+00, time/batch = 0.2220s	
985/2700 (epoch 18.241), train_loss = 3.18201128, grad/param norm = 1.1765e+00, time/batch = 0.2197s	
986/2700 (epoch 18.259), train_loss = 3.21938711, grad/param norm = 1.3812e+00, time/batch = 0.2080s	
987/2700 (epoch 18.278), train_loss = 3.29918951, grad/param norm = 1.7397e+00, time/batch = 0.2278s	
988/2700 (epoch 18.296), train_loss = 3.31201227, grad/param norm = 2.3237e+00, time/batch = 0.2023s	
989/2700 (epoch 18.315), train_loss = 3.29228251, grad/param norm = 2.1874e+00, time/batch = 0.1956s	
990/2700 (epoch 18.333), train_loss = 3.35907055, grad/param norm = 1.6835e+00, time/batch = 0.2145s	
991/2700 (epoch 18.352), train_loss = 3.36671366, grad/param norm = 1.5654e+00, time/batch = 0.2118s	
992/2700 (epoch 18.370), train_loss = 3.30729401, grad/param norm = 1.2575e+00, time/batch = 0.2246s	
993/2700 (epoch 18.389), train_loss = 3.26209775, grad/param norm = 9.6122e-01, time/batch = 0.2553s	
994/2700 (epoch 18.407), train_loss = 3.28476778, grad/param norm = 8.4176e-01, time/batch = 0.2533s	
995/2700 (epoch 18.426), train_loss = 3.28827538, grad/param norm = 8.9640e-01, time/batch = 0.2524s	
996/2700 (epoch 18.444), train_loss = 3.21130886, grad/param norm = 8.0192e-01, time/batch = 0.2473s	
997/2700 (epoch 18.463), train_loss = 3.25689090, grad/param norm = 8.9362e-01, time/batch = 0.2524s	
998/2700 (epoch 18.481), train_loss = 3.33228332, grad/param norm = 7.7385e-01, time/batch = 0.2480s	
999/2700 (epoch 18.500), train_loss = 3.37882293, grad/param norm = 1.0658e+00, time/batch = 0.2239s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch18.52_9.6651.t7	
1000/2700 (epoch 18.519), train_loss = 3.33596647, grad/param norm = 1.2606e+00, time/batch = 0.2157s	
1001/2700 (epoch 18.537), train_loss = 9.57343187, grad/param norm = 7.9405e+00, time/batch = 0.2400s	
1002/2700 (epoch 18.556), train_loss = 7.04000790, grad/param norm = 7.6937e+00, time/batch = 0.2477s	
1003/2700 (epoch 18.574), train_loss = 5.29648546, grad/param norm = 6.7233e+00, time/batch = 0.2563s	
1004/2700 (epoch 18.593), train_loss = 3.59221391, grad/param norm = 4.5821e+00, time/batch = 0.2357s	
1005/2700 (epoch 18.611), train_loss = 5.33591559, grad/param norm = 3.1450e+00, time/batch = 0.2304s	
1006/2700 (epoch 18.630), train_loss = 4.71718470, grad/param norm = 1.4501e+00, time/batch = 0.2250s	
1007/2700 (epoch 18.648), train_loss = 4.57221245, grad/param norm = 1.5538e+00, time/batch = 0.1891s	
1008/2700 (epoch 18.667), train_loss = 4.48366239, grad/param norm = 1.0051e+00, time/batch = 0.2018s	
1009/2700 (epoch 18.685), train_loss = 4.43619968, grad/param norm = 1.1561e+00, time/batch = 0.2215s	
1010/2700 (epoch 18.704), train_loss = 4.37827391, grad/param norm = 1.5439e+00, time/batch = 0.2186s	
1011/2700 (epoch 18.722), train_loss = 4.40484220, grad/param norm = 1.3905e+00, time/batch = 0.2365s	
1012/2700 (epoch 18.741), train_loss = 4.44385276, grad/param norm = 2.3129e+00, time/batch = 0.2408s	
1013/2700 (epoch 18.759), train_loss = 4.18671032, grad/param norm = 3.2617e+00, time/batch = 0.2401s	
1014/2700 (epoch 18.778), train_loss = 5.46555516, grad/param norm = 5.0756e+00, time/batch = 0.2251s	
1015/2700 (epoch 18.796), train_loss = 4.61369811, grad/param norm = 2.9257e+00, time/batch = 0.2431s	
1016/2700 (epoch 18.815), train_loss = 4.40575633, grad/param norm = 2.1231e+00, time/batch = 0.2344s	
1017/2700 (epoch 18.833), train_loss = 3.90221166, grad/param norm = 2.7096e+00, time/batch = 0.2279s	
1018/2700 (epoch 18.852), train_loss = 3.52267753, grad/param norm = 2.0267e+00, time/batch = 0.2125s	
1019/2700 (epoch 18.870), train_loss = 3.32405166, grad/param norm = 1.0760e+00, time/batch = 0.2021s	
1020/2700 (epoch 18.889), train_loss = 3.31482776, grad/param norm = 1.0711e+00, time/batch = 0.1910s	
1021/2700 (epoch 18.907), train_loss = 3.34326963, grad/param norm = 1.1975e+00, time/batch = 0.1808s	
1022/2700 (epoch 18.926), train_loss = 3.29772258, grad/param norm = 1.2203e+00, time/batch = 0.1768s	
1023/2700 (epoch 18.944), train_loss = 3.31642851, grad/param norm = 1.1598e+00, time/batch = 0.2040s	
1024/2700 (epoch 18.963), train_loss = 3.37048169, grad/param norm = 1.0978e+00, time/batch = 0.2085s	
1025/2700 (epoch 18.981), train_loss = 3.41338817, grad/param norm = 9.0950e-01, time/batch = 0.2410s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1026/2700 (epoch 19.000), train_loss = 3.32369630, grad/param norm = 8.5121e-01, time/batch = 0.2506s	
1027/2700 (epoch 19.019), train_loss = 3.24776613, grad/param norm = 8.9344e-01, time/batch = 0.2526s	
1028/2700 (epoch 19.037), train_loss = 3.27855578, grad/param norm = 8.7120e-01, time/batch = 0.2465s	
1029/2700 (epoch 19.056), train_loss = 3.29233789, grad/param norm = 7.9890e-01, time/batch = 0.2283s	
1030/2700 (epoch 19.074), train_loss = 3.31365008, grad/param norm = 9.0232e-01, time/batch = 0.2164s	
1031/2700 (epoch 19.093), train_loss = 3.31233049, grad/param norm = 9.6880e-01, time/batch = 0.1947s	
1032/2700 (epoch 19.111), train_loss = 3.29691385, grad/param norm = 9.9395e-01, time/batch = 0.2234s	
1033/2700 (epoch 19.130), train_loss = 3.30298858, grad/param norm = 9.1088e-01, time/batch = 0.2412s	
1034/2700 (epoch 19.148), train_loss = 3.26468777, grad/param norm = 9.9424e-01, time/batch = 0.2433s	
1035/2700 (epoch 19.167), train_loss = 3.28114408, grad/param norm = 1.2143e+00, time/batch = 0.2505s	
1036/2700 (epoch 19.185), train_loss = 3.26243308, grad/param norm = 9.0546e-01, time/batch = 0.2458s	
1037/2700 (epoch 19.204), train_loss = 3.19474008, grad/param norm = 9.1434e-01, time/batch = 0.2414s	
1038/2700 (epoch 19.222), train_loss = 3.17035837, grad/param norm = 1.0487e+00, time/batch = 0.2373s	
1039/2700 (epoch 19.241), train_loss = 3.18249728, grad/param norm = 7.9597e-01, time/batch = 0.2269s	
1040/2700 (epoch 19.259), train_loss = 3.21564255, grad/param norm = 7.9924e-01, time/batch = 0.2052s	
1041/2700 (epoch 19.278), train_loss = 3.29360451, grad/param norm = 8.4924e-01, time/batch = 0.2558s	
1042/2700 (epoch 19.296), train_loss = 3.29547249, grad/param norm = 9.2763e-01, time/batch = 0.2252s	
1043/2700 (epoch 19.315), train_loss = 3.27296909, grad/param norm = 8.8002e-01, time/batch = 0.2219s	
1044/2700 (epoch 19.333), train_loss = 3.35073053, grad/param norm = 7.9979e-01, time/batch = 0.1965s	
1045/2700 (epoch 19.352), train_loss = 3.34892266, grad/param norm = 8.7472e-01, time/batch = 0.1972s	
1046/2700 (epoch 19.370), train_loss = 3.30019334, grad/param norm = 8.1751e-01, time/batch = 0.2148s	
1047/2700 (epoch 19.389), train_loss = 3.26312983, grad/param norm = 6.7011e-01, time/batch = 0.2395s	
1048/2700 (epoch 19.407), train_loss = 3.28966082, grad/param norm = 6.6509e-01, time/batch = 0.2527s	
1049/2700 (epoch 19.426), train_loss = 3.28985031, grad/param norm = 7.1318e-01, time/batch = 0.2543s	
1050/2700 (epoch 19.444), train_loss = 3.22190360, grad/param norm = 6.9592e-01, time/batch = 0.2462s	
1051/2700 (epoch 19.463), train_loss = 3.25857634, grad/param norm = 7.0015e-01, time/batch = 0.2390s	
1052/2700 (epoch 19.481), train_loss = 3.33760247, grad/param norm = 6.3385e-01, time/batch = 0.2387s	
1053/2700 (epoch 19.500), train_loss = 3.37900861, grad/param norm = 8.1255e-01, time/batch = 0.2533s	
1054/2700 (epoch 19.519), train_loss = 3.33855869, grad/param norm = 8.6288e-01, time/batch = 0.2456s	
1055/2700 (epoch 19.537), train_loss = 3.34412858, grad/param norm = 9.3157e-01, time/batch = 0.2519s	
1056/2700 (epoch 19.556), train_loss = 3.27522692, grad/param norm = 7.4885e-01, time/batch = 0.2357s	
1057/2700 (epoch 19.574), train_loss = 3.24596737, grad/param norm = 8.8280e-01, time/batch = 0.2220s	
1058/2700 (epoch 19.593), train_loss = 3.24863569, grad/param norm = 1.0229e+00, time/batch = 0.2211s	
1059/2700 (epoch 19.611), train_loss = 3.18242807, grad/param norm = 8.8261e-01, time/batch = 0.2369s	
1060/2700 (epoch 19.630), train_loss = 3.22772950, grad/param norm = 1.0150e+00, time/batch = 0.2515s	
1061/2700 (epoch 19.648), train_loss = 3.29746683, grad/param norm = 1.2326e+00, time/batch = 0.2327s	
1062/2700 (epoch 19.667), train_loss = 3.25212831, grad/param norm = 1.6944e+00, time/batch = 0.2422s	
1063/2700 (epoch 19.685), train_loss = 3.24797544, grad/param norm = 1.7793e+00, time/batch = 0.2440s	
1064/2700 (epoch 19.704), train_loss = 3.21425102, grad/param norm = 1.5527e+00, time/batch = 0.2362s	
1065/2700 (epoch 19.722), train_loss = 3.20010629, grad/param norm = 1.3357e+00, time/batch = 0.2333s	
1066/2700 (epoch 19.741), train_loss = 3.31862880, grad/param norm = 1.1543e+00, time/batch = 0.2284s	
1067/2700 (epoch 19.759), train_loss = 3.26814482, grad/param norm = 9.6262e-01, time/batch = 0.2290s	
1068/2700 (epoch 19.778), train_loss = 3.27774113, grad/param norm = 1.1315e+00, time/batch = 0.2137s	
1069/2700 (epoch 19.796), train_loss = 3.25971489, grad/param norm = 1.0474e+00, time/batch = 0.2085s	
1070/2700 (epoch 19.815), train_loss = 3.20555396, grad/param norm = 8.0529e-01, time/batch = 0.2178s	
1071/2700 (epoch 19.833), train_loss = 3.23935629, grad/param norm = 7.3836e-01, time/batch = 0.2043s	
1072/2700 (epoch 19.852), train_loss = 3.23287868, grad/param norm = 7.4356e-01, time/batch = 0.2127s	
1073/2700 (epoch 19.870), train_loss = 3.22389342, grad/param norm = 6.1090e-01, time/batch = 0.2450s	
1074/2700 (epoch 19.889), train_loss = 3.25585938, grad/param norm = 6.4145e-01, time/batch = 0.2497s	
1075/2700 (epoch 19.907), train_loss = 3.30907849, grad/param norm = 8.6336e-01, time/batch = 0.2383s	
1076/2700 (epoch 19.926), train_loss = 3.26302833, grad/param norm = 8.7657e-01, time/batch = 0.2310s	
1077/2700 (epoch 19.944), train_loss = 3.26511271, grad/param norm = 8.1219e-01, time/batch = 0.2262s	
1078/2700 (epoch 19.963), train_loss = 3.35222976, grad/param norm = 8.0307e-01, time/batch = 0.2034s	
1079/2700 (epoch 19.981), train_loss = 3.41120827, grad/param norm = 8.1556e-01, time/batch = 0.1970s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1080/2700 (epoch 20.000), train_loss = 3.30881868, grad/param norm = 7.8959e-01, time/batch = 0.2113s	
1081/2700 (epoch 20.019), train_loss = 3.24091762, grad/param norm = 9.0518e-01, time/batch = 0.2330s	
1082/2700 (epoch 20.037), train_loss = 3.26426886, grad/param norm = 9.0791e-01, time/batch = 0.2390s	
1083/2700 (epoch 20.056), train_loss = 3.26472258, grad/param norm = 7.5513e-01, time/batch = 0.2402s	
1084/2700 (epoch 20.074), train_loss = 3.30036800, grad/param norm = 9.1424e-01, time/batch = 0.2402s	
1085/2700 (epoch 20.093), train_loss = 3.30348463, grad/param norm = 9.0646e-01, time/batch = 0.2246s	
1086/2700 (epoch 20.111), train_loss = 3.27627994, grad/param norm = 7.9932e-01, time/batch = 0.2216s	
1087/2700 (epoch 20.130), train_loss = 3.28983004, grad/param norm = 7.6352e-01, time/batch = 0.2169s	
1088/2700 (epoch 20.148), train_loss = 3.25385698, grad/param norm = 8.3744e-01, time/batch = 0.1950s	
1089/2700 (epoch 20.167), train_loss = 3.26292813, grad/param norm = 9.3967e-01, time/batch = 0.1762s	
1090/2700 (epoch 20.185), train_loss = 3.24699311, grad/param norm = 6.9997e-01, time/batch = 0.1903s	
1091/2700 (epoch 20.204), train_loss = 3.18626423, grad/param norm = 7.7758e-01, time/batch = 0.1832s	
1092/2700 (epoch 20.222), train_loss = 3.15672954, grad/param norm = 9.4178e-01, time/batch = 0.2046s	
1093/2700 (epoch 20.241), train_loss = 3.17833726, grad/param norm = 7.2784e-01, time/batch = 0.2214s	
1094/2700 (epoch 20.259), train_loss = 3.20791583, grad/param norm = 5.5698e-01, time/batch = 0.2055s	
1095/2700 (epoch 20.278), train_loss = 3.28092922, grad/param norm = 6.9784e-01, time/batch = 0.2189s	
1096/2700 (epoch 20.296), train_loss = 3.28864679, grad/param norm = 8.0385e-01, time/batch = 0.2323s	
1097/2700 (epoch 20.315), train_loss = 3.26748381, grad/param norm = 8.3409e-01, time/batch = 0.2142s	
1098/2700 (epoch 20.333), train_loss = 3.34346529, grad/param norm = 8.0343e-01, time/batch = 0.2244s	
1099/2700 (epoch 20.352), train_loss = 3.35145112, grad/param norm = 9.3391e-01, time/batch = 0.2377s	
1100/2700 (epoch 20.370), train_loss = 3.30082448, grad/param norm = 9.5830e-01, time/batch = 0.2520s	
1101/2700 (epoch 20.389), train_loss = 3.26285174, grad/param norm = 7.9326e-01, time/batch = 0.2346s	
1102/2700 (epoch 20.407), train_loss = 3.28237716, grad/param norm = 7.4772e-01, time/batch = 0.2528s	
1103/2700 (epoch 20.426), train_loss = 3.28590487, grad/param norm = 7.9005e-01, time/batch = 0.2522s	
1104/2700 (epoch 20.444), train_loss = 3.22117802, grad/param norm = 9.5758e-01, time/batch = 0.2483s	
1105/2700 (epoch 20.463), train_loss = 3.26205528, grad/param norm = 1.4203e+00, time/batch = 0.2161s	
1106/2700 (epoch 20.481), train_loss = 3.33515752, grad/param norm = 1.0247e+00, time/batch = 0.2193s	
1107/2700 (epoch 20.500), train_loss = 3.38680767, grad/param norm = 1.1168e+00, time/batch = 0.2076s	
1108/2700 (epoch 20.519), train_loss = 3.33840196, grad/param norm = 1.0362e+00, time/batch = 0.1969s	
1109/2700 (epoch 20.537), train_loss = 3.34070846, grad/param norm = 1.0776e+00, time/batch = 0.2121s	
1110/2700 (epoch 20.556), train_loss = 3.27460310, grad/param norm = 8.7588e-01, time/batch = 0.2386s	
1111/2700 (epoch 20.574), train_loss = 3.23992292, grad/param norm = 9.5084e-01, time/batch = 0.2288s	
1112/2700 (epoch 20.593), train_loss = 3.24634291, grad/param norm = 1.1136e+00, time/batch = 0.2402s	
1113/2700 (epoch 20.611), train_loss = 3.18132646, grad/param norm = 9.4911e-01, time/batch = 0.2437s	
1114/2700 (epoch 20.630), train_loss = 3.22247493, grad/param norm = 8.5897e-01, time/batch = 0.2476s	
1115/2700 (epoch 20.648), train_loss = 3.29437657, grad/param norm = 9.0814e-01, time/batch = 0.2434s	
1116/2700 (epoch 20.667), train_loss = 3.22646327, grad/param norm = 8.8652e-01, time/batch = 0.2452s	
1117/2700 (epoch 20.685), train_loss = 3.22196216, grad/param norm = 9.3122e-01, time/batch = 0.2289s	
1118/2700 (epoch 20.704), train_loss = 3.19497627, grad/param norm = 1.0333e+00, time/batch = 0.2167s	
1119/2700 (epoch 20.722), train_loss = 3.17961491, grad/param norm = 9.0859e-01, time/batch = 0.2275s	
1120/2700 (epoch 20.741), train_loss = 3.31842540, grad/param norm = 1.0562e+00, time/batch = 0.2371s	
1121/2700 (epoch 20.759), train_loss = 3.26290124, grad/param norm = 9.4591e-01, time/batch = 0.2332s	
1122/2700 (epoch 20.778), train_loss = 3.25847399, grad/param norm = 8.4844e-01, time/batch = 0.2455s	
1123/2700 (epoch 20.796), train_loss = 3.24718099, grad/param norm = 7.5853e-01, time/batch = 0.2551s	
1124/2700 (epoch 20.815), train_loss = 3.20174208, grad/param norm = 7.2614e-01, time/batch = 0.2541s	
1125/2700 (epoch 20.833), train_loss = 3.23525807, grad/param norm = 7.3237e-01, time/batch = 0.2449s	
1126/2700 (epoch 20.852), train_loss = 3.22931694, grad/param norm = 7.2610e-01, time/batch = 0.2393s	
1127/2700 (epoch 20.870), train_loss = 3.22316958, grad/param norm = 6.5140e-01, time/batch = 0.2253s	
1128/2700 (epoch 20.889), train_loss = 3.25477956, grad/param norm = 7.2407e-01, time/batch = 0.2069s	
1129/2700 (epoch 20.907), train_loss = 3.31310002, grad/param norm = 9.9931e-01, time/batch = 0.1965s	
1130/2700 (epoch 20.926), train_loss = 3.26404751, grad/param norm = 1.0014e+00, time/batch = 0.2099s	
1131/2700 (epoch 20.944), train_loss = 3.26591466, grad/param norm = 8.5972e-01, time/batch = 0.2051s	
1132/2700 (epoch 20.963), train_loss = 3.35247208, grad/param norm = 8.7022e-01, time/batch = 0.2250s	
1133/2700 (epoch 20.981), train_loss = 3.40936440, grad/param norm = 8.7740e-01, time/batch = 0.2440s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1134/2700 (epoch 21.000), train_loss = 3.30946894, grad/param norm = 8.9553e-01, time/batch = 0.2527s	
1135/2700 (epoch 21.019), train_loss = 3.24899050, grad/param norm = 1.0357e+00, time/batch = 0.2439s	
1136/2700 (epoch 21.037), train_loss = 3.26412932, grad/param norm = 9.6559e-01, time/batch = 0.2460s	
1137/2700 (epoch 21.056), train_loss = 3.26257248, grad/param norm = 6.5768e-01, time/batch = 0.2546s	
1138/2700 (epoch 21.074), train_loss = 3.29570671, grad/param norm = 6.9435e-01, time/batch = 0.2464s	
1139/2700 (epoch 21.093), train_loss = 3.30092474, grad/param norm = 7.8613e-01, time/batch = 0.2426s	
1140/2700 (epoch 21.111), train_loss = 3.27398757, grad/param norm = 7.7787e-01, time/batch = 0.2274s	
1141/2700 (epoch 21.130), train_loss = 3.28930650, grad/param norm = 7.8068e-01, time/batch = 0.2512s	
1142/2700 (epoch 21.148), train_loss = 3.25384308, grad/param norm = 8.5949e-01, time/batch = 0.2513s	
1143/2700 (epoch 21.167), train_loss = 3.26129474, grad/param norm = 9.2869e-01, time/batch = 0.2379s	
1144/2700 (epoch 21.185), train_loss = 3.24535288, grad/param norm = 6.6495e-01, time/batch = 0.2265s	
1145/2700 (epoch 21.204), train_loss = 3.18334523, grad/param norm = 7.1428e-01, time/batch = 0.2081s	
1146/2700 (epoch 21.222), train_loss = 3.15390344, grad/param norm = 9.1603e-01, time/batch = 0.2090s	
1147/2700 (epoch 21.241), train_loss = 3.17527738, grad/param norm = 7.1557e-01, time/batch = 0.2326s	
1148/2700 (epoch 21.259), train_loss = 3.20730086, grad/param norm = 5.7609e-01, time/batch = 0.2292s	
1149/2700 (epoch 21.278), train_loss = 3.28135002, grad/param norm = 8.2608e-01, time/batch = 0.2149s	
1150/2700 (epoch 21.296), train_loss = 3.28985857, grad/param norm = 9.7282e-01, time/batch = 0.2186s	
1151/2700 (epoch 21.315), train_loss = 3.26763227, grad/param norm = 9.8698e-01, time/batch = 0.2539s	
1152/2700 (epoch 21.333), train_loss = 3.34363743, grad/param norm = 9.4640e-01, time/batch = 0.2547s	
1153/2700 (epoch 21.352), train_loss = 3.35137511, grad/param norm = 1.1086e+00, time/batch = 0.2534s	
1154/2700 (epoch 21.370), train_loss = 3.30448700, grad/param norm = 1.2926e+00, time/batch = 0.2507s	
1155/2700 (epoch 21.389), train_loss = 3.26731402, grad/param norm = 1.1004e+00, time/batch = 0.2351s	
1156/2700 (epoch 21.407), train_loss = 3.28440245, grad/param norm = 9.4135e-01, time/batch = 0.2244s	
1157/2700 (epoch 21.426), train_loss = 3.28498202, grad/param norm = 7.9605e-01, time/batch = 0.2036s	
1158/2700 (epoch 21.444), train_loss = 3.21719381, grad/param norm = 8.7534e-01, time/batch = 0.2146s	
1159/2700 (epoch 21.463), train_loss = 3.25271904, grad/param norm = 8.3896e-01, time/batch = 0.2273s	
1160/2700 (epoch 21.481), train_loss = 3.33207239, grad/param norm = 8.4511e-01, time/batch = 0.2162s	
1161/2700 (epoch 21.500), train_loss = 3.37934520, grad/param norm = 1.0079e+00, time/batch = 0.2460s	
1162/2700 (epoch 21.519), train_loss = 3.33028207, grad/param norm = 9.2990e-01, time/batch = 0.2445s	
1163/2700 (epoch 21.537), train_loss = 3.33471730, grad/param norm = 9.0746e-01, time/batch = 0.2318s	
1164/2700 (epoch 21.556), train_loss = 3.27316042, grad/param norm = 7.3516e-01, time/batch = 0.2262s	
1165/2700 (epoch 21.574), train_loss = 3.23552281, grad/param norm = 7.1737e-01, time/batch = 0.2137s	
1166/2700 (epoch 21.593), train_loss = 3.23818065, grad/param norm = 8.7002e-01, time/batch = 0.2020s	
1167/2700 (epoch 21.611), train_loss = 3.17593756, grad/param norm = 6.7009e-01, time/batch = 0.1999s	
1168/2700 (epoch 21.630), train_loss = 3.21891067, grad/param norm = 7.4278e-01, time/batch = 0.1872s	
1169/2700 (epoch 21.648), train_loss = 3.29042981, grad/param norm = 7.8429e-01, time/batch = 0.1896s	
1170/2700 (epoch 21.667), train_loss = 3.22364853, grad/param norm = 7.4081e-01, time/batch = 0.1906s	
1171/2700 (epoch 21.685), train_loss = 3.21742678, grad/param norm = 7.3502e-01, time/batch = 0.1866s	
1172/2700 (epoch 21.704), train_loss = 3.19039513, grad/param norm = 8.6011e-01, time/batch = 0.2058s	
1173/2700 (epoch 21.722), train_loss = 3.17884716, grad/param norm = 7.8144e-01, time/batch = 0.2053s	
1174/2700 (epoch 21.741), train_loss = 3.31644923, grad/param norm = 1.0215e+00, time/batch = 0.2036s	
1175/2700 (epoch 21.759), train_loss = 3.26397890, grad/param norm = 1.0408e+00, time/batch = 0.2018s	
1176/2700 (epoch 21.778), train_loss = 3.25883702, grad/param norm = 9.3674e-01, time/batch = 0.2169s	
1177/2700 (epoch 21.796), train_loss = 3.25034878, grad/param norm = 8.9328e-01, time/batch = 0.2400s	
1178/2700 (epoch 21.815), train_loss = 3.20262985, grad/param norm = 7.6835e-01, time/batch = 0.2533s	
1179/2700 (epoch 21.833), train_loss = 3.23414467, grad/param norm = 7.1144e-01, time/batch = 0.2527s	
1180/2700 (epoch 21.852), train_loss = 3.22691353, grad/param norm = 6.6706e-01, time/batch = 0.2420s	
1181/2700 (epoch 21.870), train_loss = 3.22128165, grad/param norm = 5.9383e-01, time/batch = 0.2416s	
1182/2700 (epoch 21.889), train_loss = 3.25395545, grad/param norm = 6.4696e-01, time/batch = 0.2283s	
1183/2700 (epoch 21.907), train_loss = 3.31097942, grad/param norm = 9.2796e-01, time/batch = 0.2428s	
1184/2700 (epoch 21.926), train_loss = 3.26198447, grad/param norm = 9.6067e-01, time/batch = 0.2335s	
1185/2700 (epoch 21.944), train_loss = 3.26676567, grad/param norm = 8.8900e-01, time/batch = 0.2224s	
1186/2700 (epoch 21.963), train_loss = 3.35357634, grad/param norm = 9.2105e-01, time/batch = 0.2085s	
1187/2700 (epoch 21.981), train_loss = 3.40938309, grad/param norm = 9.1928e-01, time/batch = 0.2307s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1188/2700 (epoch 22.000), train_loss = 3.30904487, grad/param norm = 9.6744e-01, time/batch = 0.2454s	
1189/2700 (epoch 22.019), train_loss = 3.25184504, grad/param norm = 1.1141e+00, time/batch = 0.2509s	
1190/2700 (epoch 22.037), train_loss = 3.26513077, grad/param norm = 1.0548e+00, time/batch = 0.2547s	
1191/2700 (epoch 22.056), train_loss = 3.26204769, grad/param norm = 6.9751e-01, time/batch = 0.2416s	
1192/2700 (epoch 22.074), train_loss = 3.29574377, grad/param norm = 6.8953e-01, time/batch = 0.2504s	
1193/2700 (epoch 22.093), train_loss = 3.30057863, grad/param norm = 7.8051e-01, time/batch = 0.2322s	
1194/2700 (epoch 22.111), train_loss = 3.27355042, grad/param norm = 7.9328e-01, time/batch = 0.2366s	
1195/2700 (epoch 22.130), train_loss = 3.28910142, grad/param norm = 8.2090e-01, time/batch = 0.2247s	
1196/2700 (epoch 22.148), train_loss = 3.25371001, grad/param norm = 8.8984e-01, time/batch = 0.1999s	
1197/2700 (epoch 22.167), train_loss = 3.26035664, grad/param norm = 9.3133e-01, time/batch = 0.1872s	
1198/2700 (epoch 22.185), train_loss = 3.24568212, grad/param norm = 7.2101e-01, time/batch = 0.2122s	
1199/2700 (epoch 22.204), train_loss = 3.18289138, grad/param norm = 7.6674e-01, time/batch = 0.2314s	
1200/2700 (epoch 22.222), train_loss = 3.15420554, grad/param norm = 9.9174e-01, time/batch = 0.2455s	
1201/2700 (epoch 22.241), train_loss = 3.17616231, grad/param norm = 8.2651e-01, time/batch = 0.2224s	
1202/2700 (epoch 22.259), train_loss = 3.20929444, grad/param norm = 7.7645e-01, time/batch = 0.2528s	
1203/2700 (epoch 22.278), train_loss = 3.28436585, grad/param norm = 1.0835e+00, time/batch = 0.2547s	
1204/2700 (epoch 22.296), train_loss = 3.28965266, grad/param norm = 1.0189e+00, time/batch = 0.2434s	
1205/2700 (epoch 22.315), train_loss = 3.26469141, grad/param norm = 8.3881e-01, time/batch = 0.2508s	
1206/2700 (epoch 22.333), train_loss = 3.33953040, grad/param norm = 7.1302e-01, time/batch = 0.2399s	
1207/2700 (epoch 22.352), train_loss = 3.34703585, grad/param norm = 8.2067e-01, time/batch = 0.2343s	
1208/2700 (epoch 22.370), train_loss = 3.29831858, grad/param norm = 9.8601e-01, time/batch = 0.2148s	
1209/2700 (epoch 22.389), train_loss = 3.26276654, grad/param norm = 8.5051e-01, time/batch = 0.2202s	
1210/2700 (epoch 22.407), train_loss = 3.28122123, grad/param norm = 7.6625e-01, time/batch = 0.2328s	
1211/2700 (epoch 22.426), train_loss = 3.28324753, grad/param norm = 7.2913e-01, time/batch = 0.2219s	
1212/2700 (epoch 22.444), train_loss = 3.21828733, grad/param norm = 9.1125e-01, time/batch = 0.2504s	
1213/2700 (epoch 22.463), train_loss = 3.25303662, grad/param norm = 9.4835e-01, time/batch = 0.2511s	
1214/2700 (epoch 22.481), train_loss = 3.33410967, grad/param norm = 9.6551e-01, time/batch = 0.2523s	
1215/2700 (epoch 22.500), train_loss = 3.38175309, grad/param norm = 1.1384e+00, time/batch = 0.2476s	
1216/2700 (epoch 22.519), train_loss = 3.33243563, grad/param norm = 1.0567e+00, time/batch = 0.2503s	
1217/2700 (epoch 22.537), train_loss = 3.33734270, grad/param norm = 9.5891e-01, time/batch = 0.2346s	
1218/2700 (epoch 22.556), train_loss = 3.27317598, grad/param norm = 7.2835e-01, time/batch = 0.2305s	
1219/2700 (epoch 22.574), train_loss = 3.23465446, grad/param norm = 7.0323e-01, time/batch = 0.2039s	
1220/2700 (epoch 22.593), train_loss = 3.23744296, grad/param norm = 8.5803e-01, time/batch = 0.1815s	
1221/2700 (epoch 22.611), train_loss = 3.17534614, grad/param norm = 6.5083e-01, time/batch = 0.2069s	
1222/2700 (epoch 22.630), train_loss = 3.21791553, grad/param norm = 7.1806e-01, time/batch = 0.1937s	
1223/2700 (epoch 22.648), train_loss = 3.29121018, grad/param norm = 7.8827e-01, time/batch = 0.2151s	
1224/2700 (epoch 22.667), train_loss = 3.22286816, grad/param norm = 7.3534e-01, time/batch = 0.2253s	
1225/2700 (epoch 22.685), train_loss = 3.21684524, grad/param norm = 7.3102e-01, time/batch = 0.2222s	
1226/2700 (epoch 22.704), train_loss = 3.19106346, grad/param norm = 8.6439e-01, time/batch = 0.2200s	
1227/2700 (epoch 22.722), train_loss = 3.17785167, grad/param norm = 7.7546e-01, time/batch = 0.2076s	
1228/2700 (epoch 22.741), train_loss = 3.31607712, grad/param norm = 1.0196e+00, time/batch = 0.2191s	
1229/2700 (epoch 22.759), train_loss = 3.26311070, grad/param norm = 1.0079e+00, time/batch = 0.2216s	
1230/2700 (epoch 22.778), train_loss = 3.25747910, grad/param norm = 8.9865e-01, time/batch = 0.2327s	
1231/2700 (epoch 22.796), train_loss = 3.24888073, grad/param norm = 8.4619e-01, time/batch = 0.2257s	
1232/2700 (epoch 22.815), train_loss = 3.20099540, grad/param norm = 7.2143e-01, time/batch = 0.2313s	
1233/2700 (epoch 22.833), train_loss = 3.23354080, grad/param norm = 6.8534e-01, time/batch = 0.2433s	
1234/2700 (epoch 22.852), train_loss = 3.22609002, grad/param norm = 6.5887e-01, time/batch = 0.2356s	
1235/2700 (epoch 22.870), train_loss = 3.22041633, grad/param norm = 5.7850e-01, time/batch = 0.2319s	
1236/2700 (epoch 22.889), train_loss = 3.25357167, grad/param norm = 6.2845e-01, time/batch = 0.2304s	
1237/2700 (epoch 22.907), train_loss = 3.30960188, grad/param norm = 8.9908e-01, time/batch = 0.2157s	
1238/2700 (epoch 22.926), train_loss = 3.26053702, grad/param norm = 9.2141e-01, time/batch = 0.2084s	
1239/2700 (epoch 22.944), train_loss = 3.26600753, grad/param norm = 8.4381e-01, time/batch = 0.1986s	
1240/2700 (epoch 22.963), train_loss = 3.35255857, grad/param norm = 8.6670e-01, time/batch = 0.2193s	
1241/2700 (epoch 22.981), train_loss = 3.40787038, grad/param norm = 8.5354e-01, time/batch = 0.2162s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1242/2700 (epoch 23.000), train_loss = 3.30714372, grad/param norm = 8.9287e-01, time/batch = 0.2372s	
1243/2700 (epoch 23.019), train_loss = 3.25080387, grad/param norm = 1.0458e+00, time/batch = 0.2476s	
1244/2700 (epoch 23.037), train_loss = 3.26403466, grad/param norm = 9.9761e-01, time/batch = 0.2530s	
1245/2700 (epoch 23.056), train_loss = 3.26165619, grad/param norm = 6.7938e-01, time/batch = 0.2536s	
1246/2700 (epoch 23.074), train_loss = 3.29464907, grad/param norm = 6.6626e-01, time/batch = 0.2540s	
1247/2700 (epoch 23.093), train_loss = 3.29965447, grad/param norm = 7.3969e-01, time/batch = 0.2473s	
1248/2700 (epoch 23.111), train_loss = 3.27223232, grad/param norm = 7.5522e-01, time/batch = 0.2507s	
1249/2700 (epoch 23.130), train_loss = 3.28834454, grad/param norm = 8.2435e-01, time/batch = 0.2215s	
1250/2700 (epoch 23.148), train_loss = 3.25411609, grad/param norm = 9.3576e-01, time/batch = 0.2186s	
1251/2700 (epoch 23.167), train_loss = 3.26042791, grad/param norm = 9.8267e-01, time/batch = 0.2220s	
1252/2700 (epoch 23.185), train_loss = 3.24627242, grad/param norm = 8.0598e-01, time/batch = 0.2224s	
1253/2700 (epoch 23.204), train_loss = 3.18469207, grad/param norm = 8.7486e-01, time/batch = 0.2255s	
1254/2700 (epoch 23.222), train_loss = 3.15547016, grad/param norm = 1.0827e+00, time/batch = 0.2401s	
1255/2700 (epoch 23.241), train_loss = 3.17555458, grad/param norm = 8.4288e-01, time/batch = 0.2402s	
1256/2700 (epoch 23.259), train_loss = 3.20850819, grad/param norm = 7.4866e-01, time/batch = 0.2337s	
1257/2700 (epoch 23.278), train_loss = 3.28257524, grad/param norm = 9.5610e-01, time/batch = 0.2222s	
1258/2700 (epoch 23.296), train_loss = 3.28710661, grad/param norm = 8.7369e-01, time/batch = 0.2227s	
1259/2700 (epoch 23.315), train_loss = 3.26290911, grad/param norm = 7.4690e-01, time/batch = 0.2228s	
1260/2700 (epoch 23.333), train_loss = 3.33883462, grad/param norm = 6.5121e-01, time/batch = 0.2157s	
1261/2700 (epoch 23.352), train_loss = 3.34650304, grad/param norm = 7.6911e-01, time/batch = 0.2208s	
1262/2700 (epoch 23.370), train_loss = 3.29700922, grad/param norm = 9.4135e-01, time/batch = 0.2074s	
1263/2700 (epoch 23.389), train_loss = 3.26117889, grad/param norm = 7.7792e-01, time/batch = 0.2014s	
1264/2700 (epoch 23.407), train_loss = 3.28013086, grad/param norm = 7.2577e-01, time/batch = 0.2068s	
1265/2700 (epoch 23.426), train_loss = 3.28409523, grad/param norm = 7.4761e-01, time/batch = 0.2328s	
1266/2700 (epoch 23.444), train_loss = 3.21715173, grad/param norm = 8.8461e-01, time/batch = 0.2380s	
1267/2700 (epoch 23.463), train_loss = 3.25303427, grad/param norm = 8.9464e-01, time/batch = 0.2357s	
1268/2700 (epoch 23.481), train_loss = 3.33220102, grad/param norm = 9.2325e-01, time/batch = 0.2228s	
1269/2700 (epoch 23.500), train_loss = 3.38013130, grad/param norm = 1.0835e+00, time/batch = 0.2248s	
1270/2700 (epoch 23.519), train_loss = 3.33273457, grad/param norm = 1.0104e+00, time/batch = 0.2057s	
1271/2700 (epoch 23.537), train_loss = 3.34336659, grad/param norm = 9.2144e-01, time/batch = 0.2534s	
1272/2700 (epoch 23.556), train_loss = 3.27209961, grad/param norm = 7.0968e-01, time/batch = 0.2528s	
1273/2700 (epoch 23.574), train_loss = 3.24054759, grad/param norm = 7.9618e-01, time/batch = 0.2511s	
1274/2700 (epoch 23.593), train_loss = 3.24033497, grad/param norm = 8.9639e-01, time/batch = 0.2474s	
1275/2700 (epoch 23.611), train_loss = 3.17713232, grad/param norm = 6.8733e-01, time/batch = 0.2352s	
1276/2700 (epoch 23.630), train_loss = 3.21848441, grad/param norm = 7.3641e-01, time/batch = 0.2222s	
1277/2700 (epoch 23.648), train_loss = 3.29299563, grad/param norm = 7.9759e-01, time/batch = 0.2007s	
1278/2700 (epoch 23.667), train_loss = 3.22162515, grad/param norm = 7.1684e-01, time/batch = 0.2073s	
1279/2700 (epoch 23.685), train_loss = 3.21569123, grad/param norm = 6.9848e-01, time/batch = 0.2187s	
1280/2700 (epoch 23.704), train_loss = 3.18975984, grad/param norm = 8.0564e-01, time/batch = 0.2240s	
1281/2700 (epoch 23.722), train_loss = 3.17652528, grad/param norm = 6.7769e-01, time/batch = 0.2205s	
1282/2700 (epoch 23.741), train_loss = 3.31348586, grad/param norm = 8.4315e-01, time/batch = 0.2298s	
1283/2700 (epoch 23.759), train_loss = 3.26129345, grad/param norm = 9.0289e-01, time/batch = 0.2351s	
1284/2700 (epoch 23.778), train_loss = 3.25638685, grad/param norm = 8.5975e-01, time/batch = 0.2329s	
1285/2700 (epoch 23.796), train_loss = 3.24848728, grad/param norm = 8.2286e-01, time/batch = 0.2114s	
1286/2700 (epoch 23.815), train_loss = 3.20240211, grad/param norm = 7.1853e-01, time/batch = 0.2391s	
1287/2700 (epoch 23.833), train_loss = 3.23314138, grad/param norm = 6.9403e-01, time/batch = 0.2245s	
1288/2700 (epoch 23.852), train_loss = 3.22547984, grad/param norm = 6.3219e-01, time/batch = 0.2161s	
1289/2700 (epoch 23.870), train_loss = 3.21974339, grad/param norm = 5.6200e-01, time/batch = 0.2309s	
1290/2700 (epoch 23.889), train_loss = 3.25258707, grad/param norm = 6.1121e-01, time/batch = 0.2457s	
1291/2700 (epoch 23.907), train_loss = 3.31170219, grad/param norm = 9.1834e-01, time/batch = 0.2305s	
1292/2700 (epoch 23.926), train_loss = 3.26156044, grad/param norm = 9.6027e-01, time/batch = 0.2350s	
1293/2700 (epoch 23.944), train_loss = 3.26648311, grad/param norm = 8.7387e-01, time/batch = 0.2540s	
1294/2700 (epoch 23.963), train_loss = 3.35194988, grad/param norm = 8.8191e-01, time/batch = 0.2539s	
1295/2700 (epoch 23.981), train_loss = 3.40942687, grad/param norm = 8.9154e-01, time/batch = 0.2507s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1296/2700 (epoch 24.000), train_loss = 3.30799047, grad/param norm = 9.3701e-01, time/batch = 0.2554s	
1297/2700 (epoch 24.019), train_loss = 3.25100102, grad/param norm = 1.0611e+00, time/batch = 0.2352s	
1298/2700 (epoch 24.037), train_loss = 3.26234443, grad/param norm = 9.6057e-01, time/batch = 0.2196s	
1299/2700 (epoch 24.056), train_loss = 3.26030940, grad/param norm = 5.9866e-01, time/batch = 0.1998s	
1300/2700 (epoch 24.074), train_loss = 3.29431796, grad/param norm = 6.3970e-01, time/batch = 0.2030s	
1301/2700 (epoch 24.093), train_loss = 3.29958758, grad/param norm = 7.6265e-01, time/batch = 0.2070s	
1302/2700 (epoch 24.111), train_loss = 3.27198566, grad/param norm = 7.2782e-01, time/batch = 0.2173s	
1303/2700 (epoch 24.130), train_loss = 3.28601494, grad/param norm = 7.2168e-01, time/batch = 0.1981s	
1304/2700 (epoch 24.148), train_loss = 3.25273929, grad/param norm = 8.3761e-01, time/batch = 0.2116s	
1305/2700 (epoch 24.167), train_loss = 3.25937539, grad/param norm = 9.1677e-01, time/batch = 0.2111s	
1306/2700 (epoch 24.185), train_loss = 3.24504186, grad/param norm = 7.5595e-01, time/batch = 0.1787s	
1307/2700 (epoch 24.204), train_loss = 3.18368688, grad/param norm = 8.1464e-01, time/batch = 0.1865s	
1308/2700 (epoch 24.222), train_loss = 3.15547766, grad/param norm = 1.0451e+00, time/batch = 0.2034s	
1309/2700 (epoch 24.241), train_loss = 3.17459752, grad/param norm = 7.9272e-01, time/batch = 0.2239s	
1310/2700 (epoch 24.259), train_loss = 3.20732115, grad/param norm = 6.8926e-01, time/batch = 0.2321s	
1311/2700 (epoch 24.278), train_loss = 3.28295657, grad/param norm = 8.8844e-01, time/batch = 0.2191s	
1312/2700 (epoch 24.296), train_loss = 3.28548169, grad/param norm = 8.2840e-01, time/batch = 0.2433s	
1313/2700 (epoch 24.315), train_loss = 3.26341034, grad/param norm = 7.0693e-01, time/batch = 0.2392s	
1314/2700 (epoch 24.333), train_loss = 3.33739838, grad/param norm = 6.0577e-01, time/batch = 0.2388s	
1315/2700 (epoch 24.352), train_loss = 3.34502752, grad/param norm = 7.4495e-01, time/batch = 0.2474s	
1316/2700 (epoch 24.370), train_loss = 3.29574972, grad/param norm = 8.7454e-01, time/batch = 0.2459s	
1317/2700 (epoch 24.389), train_loss = 3.25995624, grad/param norm = 6.9932e-01, time/batch = 0.2098s	
1318/2700 (epoch 24.407), train_loss = 3.27901085, grad/param norm = 6.7091e-01, time/batch = 0.1883s	
1319/2700 (epoch 24.426), train_loss = 3.28178923, grad/param norm = 6.8502e-01, time/batch = 0.2059s	
1320/2700 (epoch 24.444), train_loss = 3.21851826, grad/param norm = 8.8549e-01, time/batch = 0.2268s	
1321/2700 (epoch 24.463), train_loss = 3.25224122, grad/param norm = 8.6596e-01, time/batch = 0.2116s	
1322/2700 (epoch 24.481), train_loss = 3.33439417, grad/param norm = 9.6344e-01, time/batch = 0.2354s	
1323/2700 (epoch 24.500), train_loss = 3.37956462, grad/param norm = 1.1296e+00, time/batch = 0.2439s	
1324/2700 (epoch 24.519), train_loss = 3.33725782, grad/param norm = 1.1185e+00, time/batch = 0.2396s	
1325/2700 (epoch 24.537), train_loss = 3.34721843, grad/param norm = 1.4963e+00, time/batch = 0.2320s	
1326/2700 (epoch 24.556), train_loss = 3.29666860, grad/param norm = 1.6003e+00, time/batch = 0.2292s	
1327/2700 (epoch 24.574), train_loss = 3.24814394, grad/param norm = 1.0292e+00, time/batch = 0.2094s	
1328/2700 (epoch 24.593), train_loss = 6.08041296, grad/param norm = 4.5884e+00, time/batch = 0.2237s	
1329/2700 (epoch 24.611), train_loss = 5.55677899, grad/param norm = 1.2233e+01, time/batch = 0.2358s	
1330/2700 (epoch 24.630), train_loss = 5.36413033, grad/param norm = 3.5278e+00, time/batch = 0.2494s	
1331/2700 (epoch 24.648), train_loss = 4.76475304, grad/param norm = 2.2728e+00, time/batch = 0.2258s	
1332/2700 (epoch 24.667), train_loss = 4.39435729, grad/param norm = 3.2067e+00, time/batch = 0.2506s	
1333/2700 (epoch 24.685), train_loss = 4.30128181, grad/param norm = 3.0767e+00, time/batch = 0.2501s	
1334/2700 (epoch 24.704), train_loss = 3.54075173, grad/param norm = 2.4984e+00, time/batch = 0.2515s	
1335/2700 (epoch 24.722), train_loss = 3.30750566, grad/param norm = 1.1940e+00, time/batch = 0.2531s	
1336/2700 (epoch 24.741), train_loss = 3.34862786, grad/param norm = 6.7500e-01, time/batch = 0.2443s	
1337/2700 (epoch 24.759), train_loss = 3.30298216, grad/param norm = 7.6918e-01, time/batch = 0.2375s	
1338/2700 (epoch 24.778), train_loss = 3.29057735, grad/param norm = 6.5619e-01, time/batch = 0.2213s	
1339/2700 (epoch 24.796), train_loss = 3.26494828, grad/param norm = 6.2248e-01, time/batch = 0.2123s	
1340/2700 (epoch 24.815), train_loss = 3.21560987, grad/param norm = 5.7746e-01, time/batch = 0.2061s	
1341/2700 (epoch 24.833), train_loss = 3.24560051, grad/param norm = 5.6809e-01, time/batch = 0.2150s	
1342/2700 (epoch 24.852), train_loss = 3.24299099, grad/param norm = 5.7974e-01, time/batch = 0.2173s	
1343/2700 (epoch 24.870), train_loss = 3.23127493, grad/param norm = 4.7602e-01, time/batch = 0.2308s	
1344/2700 (epoch 24.889), train_loss = 3.26477077, grad/param norm = 5.9084e-01, time/batch = 0.2296s	
1345/2700 (epoch 24.907), train_loss = 3.30895344, grad/param norm = 6.7243e-01, time/batch = 0.2240s	
1346/2700 (epoch 24.926), train_loss = 3.26601696, grad/param norm = 6.7253e-01, time/batch = 0.2115s	
1347/2700 (epoch 24.944), train_loss = 3.27112825, grad/param norm = 5.9358e-01, time/batch = 0.2023s	
1348/2700 (epoch 24.963), train_loss = 3.34440500, grad/param norm = 5.8448e-01, time/batch = 0.1821s	
1349/2700 (epoch 24.981), train_loss = 3.41036427, grad/param norm = 6.5609e-01, time/batch = 0.2064s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1350/2700 (epoch 25.000), train_loss = 3.31516067, grad/param norm = 6.8333e-01, time/batch = 0.2038s	
1351/2700 (epoch 25.019), train_loss = 3.22992858, grad/param norm = 7.1486e-01, time/batch = 0.2389s	
1352/2700 (epoch 25.037), train_loss = 3.25951977, grad/param norm = 6.3385e-01, time/batch = 0.2264s	
1353/2700 (epoch 25.056), train_loss = 3.27134420, grad/param norm = 6.2882e-01, time/batch = 0.2092s	
1354/2700 (epoch 25.074), train_loss = 3.29671498, grad/param norm = 6.9657e-01, time/batch = 0.2215s	
1355/2700 (epoch 25.093), train_loss = 3.30087596, grad/param norm = 6.7964e-01, time/batch = 0.2333s	
1356/2700 (epoch 25.111), train_loss = 3.27554780, grad/param norm = 7.6052e-01, time/batch = 0.2394s	
1357/2700 (epoch 25.130), train_loss = 3.28800931, grad/param norm = 7.5226e-01, time/batch = 0.2353s	
1358/2700 (epoch 25.148), train_loss = 3.25371267, grad/param norm = 7.1768e-01, time/batch = 0.2163s	
1359/2700 (epoch 25.167), train_loss = 3.26079053, grad/param norm = 8.8277e-01, time/batch = 0.2260s	
1360/2700 (epoch 25.185), train_loss = 3.24420688, grad/param norm = 6.3176e-01, time/batch = 0.2044s	
1361/2700 (epoch 25.204), train_loss = 3.17722984, grad/param norm = 6.3910e-01, time/batch = 0.2495s	
1362/2700 (epoch 25.222), train_loss = 3.15582923, grad/param norm = 8.6849e-01, time/batch = 0.2559s	
1363/2700 (epoch 25.241), train_loss = 3.17374003, grad/param norm = 6.7932e-01, time/batch = 0.2325s	
1364/2700 (epoch 25.259), train_loss = 3.20589246, grad/param norm = 6.7124e-01, time/batch = 0.2175s	
1365/2700 (epoch 25.278), train_loss = 3.27664844, grad/param norm = 7.3075e-01, time/batch = 0.2232s	
1366/2700 (epoch 25.296), train_loss = 3.28444461, grad/param norm = 7.5458e-01, time/batch = 0.2391s	
1367/2700 (epoch 25.315), train_loss = 3.25704991, grad/param norm = 7.3051e-01, time/batch = 0.2419s	
1368/2700 (epoch 25.333), train_loss = 3.34147636, grad/param norm = 8.0733e-01, time/batch = 0.2359s	
1369/2700 (epoch 25.352), train_loss = 3.34340812, grad/param norm = 8.8673e-01, time/batch = 0.1981s	
1370/2700 (epoch 25.370), train_loss = 3.30438690, grad/param norm = 1.1914e+00, time/batch = 0.2402s	
1371/2700 (epoch 25.389), train_loss = 3.25681284, grad/param norm = 6.7317e-01, time/batch = 0.2341s	
1372/2700 (epoch 25.407), train_loss = 3.27876907, grad/param norm = 7.0849e-01, time/batch = 0.2415s	
1373/2700 (epoch 25.426), train_loss = 3.28643137, grad/param norm = 8.0531e-01, time/batch = 0.2348s	
1374/2700 (epoch 25.444), train_loss = 3.20911115, grad/param norm = 7.2735e-01, time/batch = 0.2264s	
1375/2700 (epoch 25.463), train_loss = 3.24939556, grad/param norm = 9.3479e-01, time/batch = 0.2141s	
1376/2700 (epoch 25.481), train_loss = 3.32986447, grad/param norm = 1.1120e+00, time/batch = 0.2094s	
1377/2700 (epoch 25.500), train_loss = 3.37616761, grad/param norm = 1.1510e+00, time/batch = 0.2200s	
1378/2700 (epoch 25.519), train_loss = 3.32826528, grad/param norm = 8.5315e-01, time/batch = 0.2310s	
1379/2700 (epoch 25.537), train_loss = 3.32276516, grad/param norm = 7.8862e-01, time/batch = 0.2205s	
1380/2700 (epoch 25.556), train_loss = 3.25757778, grad/param norm = 7.2692e-01, time/batch = 0.2262s	
1381/2700 (epoch 25.574), train_loss = 3.24489037, grad/param norm = 9.9650e-01, time/batch = 0.2501s	
1382/2700 (epoch 25.593), train_loss = 3.23155890, grad/param norm = 1.1628e+00, time/batch = 0.2573s	
1383/2700 (epoch 25.611), train_loss = 3.17790868, grad/param norm = 1.0931e+00, time/batch = 0.2552s	
1384/2700 (epoch 25.630), train_loss = 3.23764822, grad/param norm = 1.5577e+00, time/batch = 0.2560s	
1385/2700 (epoch 25.648), train_loss = 3.29894587, grad/param norm = 1.3757e+00, time/batch = 0.2565s	
1386/2700 (epoch 25.667), train_loss = 3.21097692, grad/param norm = 8.0437e-01, time/batch = 0.2546s	
1387/2700 (epoch 25.685), train_loss = 3.20830847, grad/param norm = 7.2419e-01, time/batch = 0.2553s	
1388/2700 (epoch 25.704), train_loss = 3.17776186, grad/param norm = 8.4614e-01, time/batch = 0.2556s	
1389/2700 (epoch 25.722), train_loss = 3.16736052, grad/param norm = 7.3130e-01, time/batch = 0.2508s	
1390/2700 (epoch 25.741), train_loss = 3.29777345, grad/param norm = 8.5883e-01, time/batch = 0.2483s	
1391/2700 (epoch 25.759), train_loss = 3.26749301, grad/param norm = 9.8463e-01, time/batch = 0.2495s	
1392/2700 (epoch 25.778), train_loss = 3.24779523, grad/param norm = 9.8426e-01, time/batch = 0.2418s	
1393/2700 (epoch 25.796), train_loss = 3.23722241, grad/param norm = 9.8218e-01, time/batch = 0.2310s	
1394/2700 (epoch 25.815), train_loss = 3.18865705, grad/param norm = 8.7516e-01, time/batch = 0.2245s	
1395/2700 (epoch 25.833), train_loss = 3.24310239, grad/param norm = 1.0688e+00, time/batch = 0.2241s	
1396/2700 (epoch 25.852), train_loss = 3.21262311, grad/param norm = 9.3577e-01, time/batch = 0.2251s	
1397/2700 (epoch 25.870), train_loss = 3.21763581, grad/param norm = 8.2152e-01, time/batch = 0.2529s	
1398/2700 (epoch 25.889), train_loss = 3.24563173, grad/param norm = 7.6118e-01, time/batch = 0.2518s	
1399/2700 (epoch 25.907), train_loss = 3.29303720, grad/param norm = 8.3615e-01, time/batch = 0.2453s	
1400/2700 (epoch 25.926), train_loss = 3.22522996, grad/param norm = 9.3478e-01, time/batch = 0.2545s	
1401/2700 (epoch 25.944), train_loss = 3.22717361, grad/param norm = 8.3140e-01, time/batch = 0.2277s	
1402/2700 (epoch 25.963), train_loss = 3.37624126, grad/param norm = 1.4912e+00, time/batch = 0.2494s	
1403/2700 (epoch 25.981), train_loss = 3.42554875, grad/param norm = 1.9416e+00, time/batch = 0.2306s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1404/2700 (epoch 26.000), train_loss = 3.31558110, grad/param norm = 1.3800e+00, time/batch = 0.2236s	
1405/2700 (epoch 26.019), train_loss = 3.25539179, grad/param norm = 1.0679e+00, time/batch = 0.2227s	
1406/2700 (epoch 26.037), train_loss = 3.25770626, grad/param norm = 8.7231e-01, time/batch = 0.2302s	
1407/2700 (epoch 26.056), train_loss = 3.24873289, grad/param norm = 6.7319e-01, time/batch = 0.2388s	
1408/2700 (epoch 26.074), train_loss = 3.27160448, grad/param norm = 8.4236e-01, time/batch = 0.2457s	
1409/2700 (epoch 26.093), train_loss = 3.29234390, grad/param norm = 1.0454e+00, time/batch = 0.2486s	
1410/2700 (epoch 26.111), train_loss = 3.25215160, grad/param norm = 9.1558e-01, time/batch = 0.2518s	
1411/2700 (epoch 26.130), train_loss = 3.29367715, grad/param norm = 1.3271e+00, time/batch = 0.2367s	
1412/2700 (epoch 26.148), train_loss = 3.24426993, grad/param norm = 1.3864e+00, time/batch = 0.2526s	
1413/2700 (epoch 26.167), train_loss = 3.24399284, grad/param norm = 1.2385e+00, time/batch = 0.2143s	
1414/2700 (epoch 26.185), train_loss = 3.22755519, grad/param norm = 1.0118e+00, time/batch = 0.2141s	
1415/2700 (epoch 26.204), train_loss = 3.16979867, grad/param norm = 1.0540e+00, time/batch = 0.1999s	
1416/2700 (epoch 26.222), train_loss = 3.13724648, grad/param norm = 1.1136e+00, time/batch = 0.2552s	
1417/2700 (epoch 26.241), train_loss = 3.17553789, grad/param norm = 9.6339e-01, time/batch = 0.2542s	
1418/2700 (epoch 26.259), train_loss = 3.18465088, grad/param norm = 9.6252e-01, time/batch = 0.2477s	
1419/2700 (epoch 26.278), train_loss = 3.26248490, grad/param norm = 1.1643e+00, time/batch = 0.2400s	
1420/2700 (epoch 26.296), train_loss = 3.25749877, grad/param norm = 1.0931e+00, time/batch = 0.2112s	
1421/2700 (epoch 26.315), train_loss = 3.22272222, grad/param norm = 8.1257e-01, time/batch = 0.2324s	
1422/2700 (epoch 26.333), train_loss = 3.30694280, grad/param norm = 8.7864e-01, time/batch = 0.2485s	
1423/2700 (epoch 26.352), train_loss = 3.29600799, grad/param norm = 9.7882e-01, time/batch = 0.2503s	
1424/2700 (epoch 26.370), train_loss = 3.26453399, grad/param norm = 1.4952e+00, time/batch = 0.2317s	
1425/2700 (epoch 26.389), train_loss = 3.29535075, grad/param norm = 1.2105e+00, time/batch = 0.2146s	
1426/2700 (epoch 26.407), train_loss = 3.27616230, grad/param norm = 1.0493e+00, time/batch = 0.2126s	
1427/2700 (epoch 26.426), train_loss = 3.26053300, grad/param norm = 7.7627e-01, time/batch = 0.2522s	
1428/2700 (epoch 26.444), train_loss = 3.17557807, grad/param norm = 7.2234e-01, time/batch = 0.2524s	
1429/2700 (epoch 26.463), train_loss = 3.23248398, grad/param norm = 1.5701e+00, time/batch = 0.2532s	
1430/2700 (epoch 26.481), train_loss = 3.29726808, grad/param norm = 8.2300e-01, time/batch = 0.2504s	
1431/2700 (epoch 26.500), train_loss = 3.33399269, grad/param norm = 1.1829e+00, time/batch = 0.2467s	
1432/2700 (epoch 26.519), train_loss = 3.29550867, grad/param norm = 1.3344e+00, time/batch = 0.2515s	
1433/2700 (epoch 26.537), train_loss = 3.30750542, grad/param norm = 1.4059e+00, time/batch = 0.2531s	
1434/2700 (epoch 26.556), train_loss = 3.24922965, grad/param norm = 1.2186e+00, time/batch = 0.2526s	
1435/2700 (epoch 26.574), train_loss = 3.18979566, grad/param norm = 1.0401e+00, time/batch = 0.2517s	
1436/2700 (epoch 26.593), train_loss = 3.19078244, grad/param norm = 1.4343e+00, time/batch = 0.2481s	
1437/2700 (epoch 26.611), train_loss = 3.18618005, grad/param norm = 1.2573e+00, time/batch = 0.2111s	
1438/2700 (epoch 26.630), train_loss = 3.14349859, grad/param norm = 9.9359e-01, time/batch = 0.2395s	
1439/2700 (epoch 26.648), train_loss = 3.20208657, grad/param norm = 1.1958e+00, time/batch = 0.2544s	
1440/2700 (epoch 26.667), train_loss = 3.17529368, grad/param norm = 1.3992e+00, time/batch = 0.2496s	
1441/2700 (epoch 26.685), train_loss = 3.21346922, grad/param norm = 1.8625e+00, time/batch = 0.2324s	
1442/2700 (epoch 26.704), train_loss = 3.17336198, grad/param norm = 2.3264e+00, time/batch = 0.2566s	
1443/2700 (epoch 26.722), train_loss = 3.18660578, grad/param norm = 2.4374e+00, time/batch = 0.2523s	
1444/2700 (epoch 26.741), train_loss = 3.32915369, grad/param norm = 1.7391e+00, time/batch = 0.2499s	
1445/2700 (epoch 26.759), train_loss = 3.19192954, grad/param norm = 8.6494e-01, time/batch = 0.2496s	
1446/2700 (epoch 26.778), train_loss = 3.16559181, grad/param norm = 8.5896e-01, time/batch = 0.2481s	
1447/2700 (epoch 26.796), train_loss = 3.14060154, grad/param norm = 1.0721e+00, time/batch = 0.2330s	
1448/2700 (epoch 26.815), train_loss = 3.06373086, grad/param norm = 2.1986e+00, time/batch = 0.2192s	
1449/2700 (epoch 26.833), train_loss = 3.13002474, grad/param norm = 1.6183e+00, time/batch = 0.1910s	
1450/2700 (epoch 26.852), train_loss = 3.29955497, grad/param norm = 1.5155e+00, time/batch = 0.2017s	
1451/2700 (epoch 26.870), train_loss = 3.13339054, grad/param norm = 9.9371e-01, time/batch = 0.1816s	
1452/2700 (epoch 26.889), train_loss = 3.13232330, grad/param norm = 9.9644e-01, time/batch = 0.2228s	
1453/2700 (epoch 26.907), train_loss = 3.18951609, grad/param norm = 1.0661e+00, time/batch = 0.2270s	
1454/2700 (epoch 26.926), train_loss = 3.15934410, grad/param norm = 1.4399e+00, time/batch = 0.2243s	
1455/2700 (epoch 26.944), train_loss = 3.21908250, grad/param norm = 1.5556e+00, time/batch = 0.2277s	
1456/2700 (epoch 26.963), train_loss = 3.25408584, grad/param norm = 1.4069e+00, time/batch = 0.2287s	
1457/2700 (epoch 26.981), train_loss = 3.31847347, grad/param norm = 1.3709e+00, time/batch = 0.2300s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1458/2700 (epoch 27.000), train_loss = 3.21430632, grad/param norm = 1.4221e+00, time/batch = 0.2282s	
1459/2700 (epoch 27.019), train_loss = 3.14333620, grad/param norm = 1.6152e+00, time/batch = 0.2045s	
1460/2700 (epoch 27.037), train_loss = 3.15220673, grad/param norm = 1.2928e+00, time/batch = 0.1980s	
1461/2700 (epoch 27.056), train_loss = 3.12164320, grad/param norm = 1.1570e+00, time/batch = 0.1948s	
1462/2700 (epoch 27.074), train_loss = 3.16769233, grad/param norm = 1.3301e+00, time/batch = 0.1859s	
1463/2700 (epoch 27.093), train_loss = 3.20014987, grad/param norm = 1.6414e+00, time/batch = 0.2263s	
1464/2700 (epoch 27.111), train_loss = 3.16319171, grad/param norm = 1.5158e+00, time/batch = 0.2285s	
1465/2700 (epoch 27.130), train_loss = 3.16217972, grad/param norm = 1.6776e+00, time/batch = 0.2337s	
1466/2700 (epoch 27.148), train_loss = 3.22137960, grad/param norm = 2.8422e+00, time/batch = 0.2369s	
1467/2700 (epoch 27.167), train_loss = 3.17607061, grad/param norm = 2.1429e+00, time/batch = 0.2431s	
1468/2700 (epoch 27.185), train_loss = 3.07080555, grad/param norm = 8.7140e-01, time/batch = 0.2444s	
1469/2700 (epoch 27.204), train_loss = 3.00394500, grad/param norm = 9.8134e-01, time/batch = 0.2456s	
1470/2700 (epoch 27.222), train_loss = 2.98027585, grad/param norm = 1.4206e+00, time/batch = 0.2213s	
1471/2700 (epoch 27.241), train_loss = 3.07121174, grad/param norm = 2.1303e+00, time/batch = 0.2136s	
1472/2700 (epoch 27.259), train_loss = 3.16701743, grad/param norm = 2.0841e+00, time/batch = 0.1810s	
1473/2700 (epoch 27.278), train_loss = 3.13672486, grad/param norm = 1.2119e+00, time/batch = 0.2266s	
1474/2700 (epoch 27.296), train_loss = 3.08688358, grad/param norm = 8.1635e-01, time/batch = 0.2427s	
1475/2700 (epoch 27.315), train_loss = 3.08331363, grad/param norm = 8.6316e-01, time/batch = 0.2521s	
1476/2700 (epoch 27.333), train_loss = 3.14075071, grad/param norm = 7.9541e-01, time/batch = 0.2519s	
1477/2700 (epoch 27.352), train_loss = 3.15982000, grad/param norm = 9.2207e-01, time/batch = 0.2526s	
1478/2700 (epoch 27.370), train_loss = 3.07029321, grad/param norm = 9.3223e-01, time/batch = 0.2517s	
1479/2700 (epoch 27.389), train_loss = 3.04628945, grad/param norm = 9.8513e-01, time/batch = 0.2538s	
1480/2700 (epoch 27.407), train_loss = 3.08753489, grad/param norm = 1.2369e+00, time/batch = 0.2554s	
1481/2700 (epoch 27.426), train_loss = 3.11006747, grad/param norm = 1.4184e+00, time/batch = 0.2561s	
1482/2700 (epoch 27.444), train_loss = 3.02118433, grad/param norm = 1.7712e+00, time/batch = 0.2375s	
1483/2700 (epoch 27.463), train_loss = 3.14340570, grad/param norm = 2.2159e+00, time/batch = 0.2512s	
1484/2700 (epoch 27.481), train_loss = 3.19489750, grad/param norm = 1.7522e+00, time/batch = 0.2441s	
1485/2700 (epoch 27.500), train_loss = 3.20144338, grad/param norm = 1.5335e+00, time/batch = 0.2262s	
1486/2700 (epoch 27.519), train_loss = 3.13473978, grad/param norm = 1.4292e+00, time/batch = 0.2145s	
1487/2700 (epoch 27.537), train_loss = 3.13297026, grad/param norm = 1.6354e+00, time/batch = 0.2270s	
1488/2700 (epoch 27.556), train_loss = 3.10611215, grad/param norm = 1.8338e+00, time/batch = 0.2409s	
1489/2700 (epoch 27.574), train_loss = 3.09789025, grad/param norm = 2.3095e+00, time/batch = 0.2445s	
1490/2700 (epoch 27.593), train_loss = 3.10512623, grad/param norm = 2.1139e+00, time/batch = 0.2413s	
1491/2700 (epoch 27.611), train_loss = 2.95503324, grad/param norm = 8.2098e-01, time/batch = 0.2372s	
1492/2700 (epoch 27.630), train_loss = 2.97523478, grad/param norm = 7.6592e-01, time/batch = 0.2491s	
1493/2700 (epoch 27.648), train_loss = 3.03414953, grad/param norm = 7.8905e-01, time/batch = 0.2378s	
1494/2700 (epoch 27.667), train_loss = 2.95894552, grad/param norm = 6.2721e-01, time/batch = 0.2312s	
1495/2700 (epoch 27.685), train_loss = 2.98039119, grad/param norm = 6.5867e-01, time/batch = 0.2275s	
1496/2700 (epoch 27.704), train_loss = 2.94570555, grad/param norm = 8.2018e-01, time/batch = 0.2334s	
1497/2700 (epoch 27.722), train_loss = 2.92816070, grad/param norm = 6.4477e-01, time/batch = 0.2275s	
1498/2700 (epoch 27.741), train_loss = 3.09724255, grad/param norm = 8.1512e-01, time/batch = 0.2116s	
1499/2700 (epoch 27.759), train_loss = 3.04300396, grad/param norm = 1.0572e+00, time/batch = 0.2105s	
1500/2700 (epoch 27.778), train_loss = 3.04658188, grad/param norm = 1.2881e+00, time/batch = 0.2278s	
1501/2700 (epoch 27.796), train_loss = 3.02121685, grad/param norm = 1.2988e+00, time/batch = 0.2197s	
1502/2700 (epoch 27.815), train_loss = 2.96747799, grad/param norm = 1.3082e+00, time/batch = 0.2184s	
1503/2700 (epoch 27.833), train_loss = 2.98603735, grad/param norm = 1.1823e+00, time/batch = 0.2456s	
1504/2700 (epoch 27.852), train_loss = 2.98188976, grad/param norm = 9.3494e-01, time/batch = 0.2487s	
1505/2700 (epoch 27.870), train_loss = 2.94802758, grad/param norm = 8.1411e-01, time/batch = 0.2471s	
1506/2700 (epoch 27.889), train_loss = 2.99675800, grad/param norm = 1.0141e+00, time/batch = 0.2489s	
1507/2700 (epoch 27.907), train_loss = 3.08865776, grad/param norm = 1.4876e+00, time/batch = 0.2334s	
1508/2700 (epoch 27.926), train_loss = 3.06355063, grad/param norm = 2.0965e+00, time/batch = 0.2161s	
1509/2700 (epoch 27.944), train_loss = 3.14068098, grad/param norm = 2.3807e+00, time/batch = 0.1963s	
1510/2700 (epoch 27.963), train_loss = 3.22103928, grad/param norm = 2.5535e+00, time/batch = 0.2081s	
1511/2700 (epoch 27.981), train_loss = 3.28092411, grad/param norm = 2.7802e+00, time/batch = 0.2236s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1512/2700 (epoch 28.000), train_loss = 3.21652903, grad/param norm = 2.2818e+00, time/batch = 0.2374s	
1513/2700 (epoch 28.019), train_loss = 3.01379681, grad/param norm = 1.2386e+00, time/batch = 0.2114s	
1514/2700 (epoch 28.037), train_loss = 3.01254485, grad/param norm = 7.2822e-01, time/batch = 0.2099s	
1515/2700 (epoch 28.056), train_loss = 2.97400205, grad/param norm = 6.3080e-01, time/batch = 0.2057s	
1516/2700 (epoch 28.074), train_loss = 3.01209959, grad/param norm = 8.0129e-01, time/batch = 0.2045s	
1517/2700 (epoch 28.093), train_loss = 3.02394873, grad/param norm = 8.0295e-01, time/batch = 0.1962s	
1518/2700 (epoch 28.111), train_loss = 2.99163849, grad/param norm = 7.6448e-01, time/batch = 0.1872s	
1519/2700 (epoch 28.130), train_loss = 3.01392159, grad/param norm = 8.3101e-01, time/batch = 0.2126s	
1520/2700 (epoch 28.148), train_loss = 2.94591310, grad/param norm = 9.2504e-01, time/batch = 0.2422s	
1521/2700 (epoch 28.167), train_loss = 2.95296003, grad/param norm = 1.0361e+00, time/batch = 0.2299s	
1522/2700 (epoch 28.185), train_loss = 2.93000186, grad/param norm = 9.8601e-01, time/batch = 0.2294s	
1523/2700 (epoch 28.204), train_loss = 2.87365080, grad/param norm = 1.1630e+00, time/batch = 0.2328s	
1524/2700 (epoch 28.222), train_loss = 2.87945109, grad/param norm = 1.6655e+00, time/batch = 0.2336s	
1525/2700 (epoch 28.241), train_loss = 2.92692805, grad/param norm = 2.0567e+00, time/batch = 0.2415s	
1526/2700 (epoch 28.259), train_loss = 2.96443870, grad/param norm = 1.9970e+00, time/batch = 0.2212s	
1527/2700 (epoch 28.278), train_loss = 2.99941639, grad/param norm = 1.3021e+00, time/batch = 0.2198s	
1528/2700 (epoch 28.296), train_loss = 2.92779772, grad/param norm = 8.3723e-01, time/batch = 0.2337s	
1529/2700 (epoch 28.315), train_loss = 2.93917690, grad/param norm = 6.3721e-01, time/batch = 0.2492s	
1530/2700 (epoch 28.333), train_loss = 2.99295714, grad/param norm = 1.0448e+00, time/batch = 0.2536s	
1531/2700 (epoch 28.352), train_loss = 3.10359252, grad/param norm = 1.9248e+00, time/batch = 0.2385s	
1532/2700 (epoch 28.370), train_loss = 3.02488782, grad/param norm = 1.9772e+00, time/batch = 0.2472s	
1533/2700 (epoch 28.389), train_loss = 2.99095788, grad/param norm = 2.0254e+00, time/batch = 0.2461s	
1534/2700 (epoch 28.407), train_loss = 3.01005766, grad/param norm = 1.8838e+00, time/batch = 0.2471s	
1535/2700 (epoch 28.426), train_loss = 2.97501390, grad/param norm = 1.0076e+00, time/batch = 0.2240s	
1536/2700 (epoch 28.444), train_loss = 2.81432889, grad/param norm = 7.0400e-01, time/batch = 0.2221s	
1537/2700 (epoch 28.463), train_loss = 2.88872438, grad/param norm = 7.6224e-01, time/batch = 0.2082s	
1538/2700 (epoch 28.481), train_loss = 2.95929798, grad/param norm = 1.0687e+00, time/batch = 0.1919s	
1539/2700 (epoch 28.500), train_loss = 3.04752756, grad/param norm = 1.7774e+00, time/batch = 0.2050s	
1540/2700 (epoch 28.519), train_loss = 3.06490022, grad/param norm = 2.5462e+00, time/batch = 0.2242s	
1541/2700 (epoch 28.537), train_loss = 3.00034050, grad/param norm = 1.8072e+00, time/batch = 0.2204s	
1542/2700 (epoch 28.556), train_loss = 2.90980253, grad/param norm = 1.3398e+00, time/batch = 0.2366s	
1543/2700 (epoch 28.574), train_loss = 2.92785726, grad/param norm = 1.4514e+00, time/batch = 0.2334s	
1544/2700 (epoch 28.593), train_loss = 2.84795148, grad/param norm = 1.1283e+00, time/batch = 0.2437s	
1545/2700 (epoch 28.611), train_loss = 2.74306797, grad/param norm = 7.0296e-01, time/batch = 0.2431s	
1546/2700 (epoch 28.630), train_loss = 2.78098218, grad/param norm = 7.1783e-01, time/batch = 0.2513s	
1547/2700 (epoch 28.648), train_loss = 2.82838352, grad/param norm = 7.8191e-01, time/batch = 0.2384s	
1548/2700 (epoch 28.667), train_loss = 2.77387063, grad/param norm = 9.3076e-01, time/batch = 0.2241s	
1549/2700 (epoch 28.685), train_loss = 2.83686080, grad/param norm = 1.2909e+00, time/batch = 0.2161s	
1550/2700 (epoch 28.704), train_loss = 2.82434481, grad/param norm = 1.7505e+00, time/batch = 0.2305s	
1551/2700 (epoch 28.722), train_loss = 2.82206576, grad/param norm = 1.6948e+00, time/batch = 0.2259s	
1552/2700 (epoch 28.741), train_loss = 2.96181156, grad/param norm = 1.6177e+00, time/batch = 0.2440s	
1553/2700 (epoch 28.759), train_loss = 2.90262420, grad/param norm = 1.3562e+00, time/batch = 0.2442s	
1554/2700 (epoch 28.778), train_loss = 2.83426855, grad/param norm = 9.3371e-01, time/batch = 0.2460s	
1555/2700 (epoch 28.796), train_loss = 2.83555482, grad/param norm = 1.0746e+00, time/batch = 0.2366s	
1556/2700 (epoch 28.815), train_loss = 2.76426753, grad/param norm = 9.1705e-01, time/batch = 0.2429s	
1557/2700 (epoch 28.833), train_loss = 2.78018661, grad/param norm = 1.1707e+00, time/batch = 0.2337s	
1558/2700 (epoch 28.852), train_loss = 2.82307542, grad/param norm = 1.3208e+00, time/batch = 0.2338s	
1559/2700 (epoch 28.870), train_loss = 2.77460154, grad/param norm = 1.2919e+00, time/batch = 0.2166s	
1560/2700 (epoch 28.889), train_loss = 2.85410679, grad/param norm = 9.5520e+00, time/batch = 0.1859s	
1561/2700 (epoch 28.907), train_loss = 2.99845044, grad/param norm = 1.9716e+00, time/batch = 0.2379s	
1562/2700 (epoch 28.926), train_loss = 2.83213131, grad/param norm = 1.1724e+00, time/batch = 0.2152s	
1563/2700 (epoch 28.944), train_loss = 2.82235336, grad/param norm = 8.9056e-01, time/batch = 0.2144s	
1564/2700 (epoch 28.963), train_loss = 2.90766724, grad/param norm = 1.6650e+00, time/batch = 0.2195s	
1565/2700 (epoch 28.981), train_loss = 3.10140983, grad/param norm = 1.8991e+00, time/batch = 0.2289s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
1566/2700 (epoch 29.000), train_loss = 2.88734112, grad/param norm = 9.6071e-01, time/batch = 0.2054s	
1567/2700 (epoch 29.019), train_loss = 2.77317035, grad/param norm = 1.2108e+00, time/batch = 0.2346s	
1568/2700 (epoch 29.037), train_loss = 2.82726772, grad/param norm = 1.1715e+00, time/batch = 0.2288s	
1569/2700 (epoch 29.056), train_loss = 2.78671876, grad/param norm = 1.1834e+00, time/batch = 0.2272s	
1570/2700 (epoch 29.074), train_loss = 2.79391419, grad/param norm = 1.0257e+00, time/batch = 0.2170s	
1571/2700 (epoch 29.093), train_loss = 2.80796984, grad/param norm = 9.1703e-01, time/batch = 0.2425s	
1572/2700 (epoch 29.111), train_loss = 2.77609863, grad/param norm = 8.3528e-01, time/batch = 0.2385s	
1573/2700 (epoch 29.130), train_loss = 2.79861517, grad/param norm = 8.4084e-01, time/batch = 0.2204s	
1574/2700 (epoch 29.148), train_loss = 2.74333037, grad/param norm = 1.1110e+00, time/batch = 0.2060s	
1575/2700 (epoch 29.167), train_loss = 2.77272764, grad/param norm = 1.1990e+00, time/batch = 0.2210s	
1576/2700 (epoch 29.185), train_loss = 2.72107627, grad/param norm = 1.0685e+00, time/batch = 0.2173s	
1577/2700 (epoch 29.204), train_loss = 2.65690607, grad/param norm = 9.3177e-01, time/batch = 0.2320s	
1578/2700 (epoch 29.222), train_loss = 2.65763189, grad/param norm = 1.5468e+00, time/batch = 0.2236s	
1579/2700 (epoch 29.241), train_loss = 2.70219313, grad/param norm = 1.6804e+00, time/batch = 0.2125s	
1580/2700 (epoch 29.259), train_loss = 2.70031010, grad/param norm = 1.4629e+00, time/batch = 0.2134s	
1581/2700 (epoch 29.278), train_loss = 2.76273930, grad/param norm = 1.3869e+00, time/batch = 0.2538s	
1582/2700 (epoch 29.296), train_loss = 2.71261324, grad/param norm = 9.5185e-01, time/batch = 0.2553s	
1583/2700 (epoch 29.315), train_loss = 2.75407744, grad/param norm = 9.8587e-01, time/batch = 0.2506s	
1584/2700 (epoch 29.333), train_loss = 2.75000156, grad/param norm = 1.0404e+00, time/batch = 0.2449s	
1585/2700 (epoch 29.352), train_loss = 2.82654246, grad/param norm = 1.3257e+00, time/batch = 0.2283s	
1586/2700 (epoch 29.370), train_loss = 2.83312312, grad/param norm = 1.6268e+00, time/batch = 0.2184s	
1587/2700 (epoch 29.389), train_loss = 2.72571133, grad/param norm = 1.1086e+00, time/batch = 0.2022s	
1588/2700 (epoch 29.407), train_loss = 2.72016496, grad/param norm = 8.5560e-01, time/batch = 0.2104s	
1589/2700 (epoch 29.426), train_loss = 2.74089272, grad/param norm = 8.7631e-01, time/batch = 0.2151s	
1590/2700 (epoch 29.444), train_loss = 2.61417840, grad/param norm = 8.0965e-01, time/batch = 0.2087s	
1591/2700 (epoch 29.463), train_loss = 2.70405144, grad/param norm = 9.6550e-01, time/batch = 0.2352s	
1592/2700 (epoch 29.481), train_loss = 2.77167806, grad/param norm = 1.1739e+00, time/batch = 0.2268s	
1593/2700 (epoch 29.500), train_loss = 2.77920374, grad/param norm = 1.1279e+00, time/batch = 0.2255s	
1594/2700 (epoch 29.519), train_loss = 2.70166153, grad/param norm = 8.6991e-01, time/batch = 0.2101s	
1595/2700 (epoch 29.537), train_loss = 2.70036641, grad/param norm = 9.7623e-01, time/batch = 0.1942s	
1596/2700 (epoch 29.556), train_loss = 2.69195999, grad/param norm = 1.0291e+00, time/batch = 0.2003s	
1597/2700 (epoch 29.574), train_loss = 2.68074758, grad/param norm = 1.0959e+00, time/batch = 0.1995s	
1598/2700 (epoch 29.593), train_loss = 2.66899233, grad/param norm = 1.0470e+00, time/batch = 0.2234s	
1599/2700 (epoch 29.611), train_loss = 2.57341869, grad/param norm = 7.6285e-01, time/batch = 0.2250s	
1600/2700 (epoch 29.630), train_loss = 2.61541816, grad/param norm = 8.4717e-01, time/batch = 0.2288s	
1601/2700 (epoch 29.648), train_loss = 2.66377737, grad/param norm = 1.2507e+00, time/batch = 0.2460s	
1602/2700 (epoch 29.667), train_loss = 2.66318987, grad/param norm = 1.8502e+00, time/batch = 0.2523s	
1603/2700 (epoch 29.685), train_loss = 2.69356923, grad/param norm = 1.3210e+00, time/batch = 0.2544s	
1604/2700 (epoch 29.704), train_loss = 2.65436351, grad/param norm = 1.3000e+00, time/batch = 0.2342s	
1605/2700 (epoch 29.722), train_loss = 2.62960862, grad/param norm = 1.2433e+00, time/batch = 0.2253s	
1606/2700 (epoch 29.741), train_loss = 2.80892892, grad/param norm = 1.2849e+00, time/batch = 0.2126s	
1607/2700 (epoch 29.759), train_loss = 2.72330049, grad/param norm = 1.4269e+00, time/batch = 0.1889s	
1608/2700 (epoch 29.778), train_loss = 2.71552096, grad/param norm = 1.7447e+00, time/batch = 0.1871s	
1609/2700 (epoch 29.796), train_loss = 2.69440387, grad/param norm = 1.9614e+00, time/batch = 0.1987s	
1610/2700 (epoch 29.815), train_loss = 2.64883300, grad/param norm = 1.5239e+00, time/batch = 0.2071s	
1611/2700 (epoch 29.833), train_loss = 2.61970379, grad/param norm = 1.2996e+00, time/batch = 0.2220s	
1612/2700 (epoch 29.852), train_loss = 2.67401820, grad/param norm = 1.3361e+00, time/batch = 0.1938s	
1613/2700 (epoch 29.870), train_loss = 2.60366292, grad/param norm = 9.4257e-01, time/batch = 0.2100s	
1614/2700 (epoch 29.889), train_loss = 2.61896936, grad/param norm = 9.9465e-01, time/batch = 0.1844s	
1615/2700 (epoch 29.907), train_loss = 2.72813425, grad/param norm = 1.0879e+00, time/batch = 0.2068s	
1616/2700 (epoch 29.926), train_loss = 2.69129764, grad/param norm = 1.5962e+00, time/batch = 0.2145s	
1617/2700 (epoch 29.944), train_loss = 2.78813404, grad/param norm = 1.3402e+00, time/batch = 0.2343s	
1618/2700 (epoch 29.963), train_loss = 2.73127002, grad/param norm = 8.5228e-01, time/batch = 0.2367s	
1619/2700 (epoch 29.981), train_loss = 2.70507368, grad/param norm = 9.0590e-01, time/batch = 0.2511s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
1620/2700 (epoch 30.000), train_loss = 2.69915825, grad/param norm = 9.8340e-01, time/batch = 0.2506s	
1621/2700 (epoch 30.019), train_loss = 2.64136565, grad/param norm = 1.0413e+00, time/batch = 0.2334s	
1622/2700 (epoch 30.037), train_loss = 2.66766798, grad/param norm = 9.8770e-01, time/batch = 0.2335s	
1623/2700 (epoch 30.056), train_loss = 2.63096405, grad/param norm = 1.2203e+00, time/batch = 0.2276s	
1624/2700 (epoch 30.074), train_loss = 2.65284212, grad/param norm = 1.4215e+00, time/batch = 0.2305s	
1625/2700 (epoch 30.093), train_loss = 2.68123336, grad/param norm = 1.3956e+00, time/batch = 0.2266s	
1626/2700 (epoch 30.111), train_loss = 2.63707812, grad/param norm = 1.1928e+00, time/batch = 0.2107s	
1627/2700 (epoch 30.130), train_loss = 2.63532117, grad/param norm = 9.5321e-01, time/batch = 0.2003s	
1628/2700 (epoch 30.148), train_loss = 2.57386003, grad/param norm = 9.0871e-01, time/batch = 0.2150s	
1629/2700 (epoch 30.167), train_loss = 2.59800161, grad/param norm = 9.0385e-01, time/batch = 0.2195s	
1630/2700 (epoch 30.185), train_loss = 2.55409256, grad/param norm = 7.8096e-01, time/batch = 0.2520s	
1631/2700 (epoch 30.204), train_loss = 2.53101790, grad/param norm = 9.4485e-01, time/batch = 0.2372s	
1632/2700 (epoch 30.222), train_loss = 2.53179343, grad/param norm = 1.2347e+00, time/batch = 0.2424s	
1633/2700 (epoch 30.241), train_loss = 2.53105539, grad/param norm = 1.0390e+00, time/batch = 0.2457s	
1634/2700 (epoch 30.259), train_loss = 2.52475483, grad/param norm = 6.7568e-01, time/batch = 0.2344s	
1635/2700 (epoch 30.278), train_loss = 2.58235648, grad/param norm = 6.6746e-01, time/batch = 0.2320s	
1636/2700 (epoch 30.296), train_loss = 2.54819131, grad/param norm = 6.6892e-01, time/batch = 0.2172s	
1637/2700 (epoch 30.315), train_loss = 2.60512350, grad/param norm = 7.6689e-01, time/batch = 0.2210s	
1638/2700 (epoch 30.333), train_loss = 2.61218383, grad/param norm = 1.0514e+00, time/batch = 0.2378s	
1639/2700 (epoch 30.352), train_loss = 2.68444376, grad/param norm = 1.5657e+00, time/batch = 0.2452s	
1640/2700 (epoch 30.370), train_loss = 2.68508197, grad/param norm = 1.8588e+00, time/batch = 0.2527s	
1641/2700 (epoch 30.389), train_loss = 2.57335595, grad/param norm = 1.2007e+00, time/batch = 0.2452s	
1642/2700 (epoch 30.407), train_loss = 2.57084911, grad/param norm = 1.0910e+00, time/batch = 0.2538s	
1643/2700 (epoch 30.426), train_loss = 2.61578809, grad/param norm = 1.0517e+00, time/batch = 0.2528s	
1644/2700 (epoch 30.444), train_loss = 2.49210064, grad/param norm = 8.7778e-01, time/batch = 0.2500s	
1645/2700 (epoch 30.463), train_loss = 2.56172810, grad/param norm = 9.8382e-01, time/batch = 0.2438s	
1646/2700 (epoch 30.481), train_loss = 2.62416696, grad/param norm = 1.2139e+00, time/batch = 0.2359s	
1647/2700 (epoch 30.500), train_loss = 2.66635934, grad/param norm = 1.5556e+00, time/batch = 0.2188s	
1648/2700 (epoch 30.519), train_loss = 2.61040937, grad/param norm = 1.6379e+00, time/batch = 0.2206s	
1649/2700 (epoch 30.537), train_loss = 2.58858732, grad/param norm = 1.1262e+00, time/batch = 0.2414s	
1650/2700 (epoch 30.556), train_loss = 2.52913684, grad/param norm = 8.3235e-01, time/batch = 0.2238s	
1651/2700 (epoch 30.574), train_loss = 2.50930234, grad/param norm = 9.2507e-01, time/batch = 0.2266s	
1652/2700 (epoch 30.593), train_loss = 2.50329944, grad/param norm = 9.6050e-01, time/batch = 0.2397s	
1653/2700 (epoch 30.611), train_loss = 2.43539704, grad/param norm = 9.3866e-01, time/batch = 0.2359s	
1654/2700 (epoch 30.630), train_loss = 2.47595757, grad/param norm = 9.0026e-01, time/batch = 0.2193s	
1655/2700 (epoch 30.648), train_loss = 2.50785738, grad/param norm = 8.3452e-01, time/batch = 0.2299s	
1656/2700 (epoch 30.667), train_loss = 2.44152756, grad/param norm = 8.7772e-01, time/batch = 0.2261s	
1657/2700 (epoch 30.685), train_loss = 2.50593623, grad/param norm = 1.1165e+00, time/batch = 0.2192s	
1658/2700 (epoch 30.704), train_loss = 2.49841967, grad/param norm = 1.1755e+00, time/batch = 0.2122s	
1659/2700 (epoch 30.722), train_loss = 2.48050644, grad/param norm = 1.1443e+00, time/batch = 0.2006s	
1660/2700 (epoch 30.741), train_loss = 2.63868407, grad/param norm = 1.2951e+00, time/batch = 0.1958s	
1661/2700 (epoch 30.759), train_loss = 2.56796645, grad/param norm = 1.3466e+00, time/batch = 0.2215s	
1662/2700 (epoch 30.778), train_loss = 2.54230573, grad/param norm = 1.2633e+00, time/batch = 0.2304s	
1663/2700 (epoch 30.796), train_loss = 2.50943226, grad/param norm = 1.0336e+00, time/batch = 0.2409s	
1664/2700 (epoch 30.815), train_loss = 2.50434152, grad/param norm = 9.9398e-01, time/batch = 0.2408s	
1665/2700 (epoch 30.833), train_loss = 2.48547951, grad/param norm = 1.2612e+00, time/batch = 0.2193s	
1666/2700 (epoch 30.852), train_loss = 2.57085233, grad/param norm = 1.4808e+00, time/batch = 0.2452s	
1667/2700 (epoch 30.870), train_loss = 2.50614730, grad/param norm = 1.3940e+00, time/batch = 0.2394s	
1668/2700 (epoch 30.889), train_loss = 2.51049612, grad/param norm = 1.1272e+00, time/batch = 0.2211s	
1669/2700 (epoch 30.907), train_loss = 2.57829723, grad/param norm = 8.2950e-01, time/batch = 0.2020s	
1670/2700 (epoch 30.926), train_loss = 2.51443788, grad/param norm = 9.6384e-01, time/batch = 0.1969s	
1671/2700 (epoch 30.944), train_loss = 2.53114819, grad/param norm = 9.0880e-01, time/batch = 0.1926s	
1672/2700 (epoch 30.963), train_loss = 2.56458987, grad/param norm = 7.2092e-01, time/batch = 0.2207s	
1673/2700 (epoch 30.981), train_loss = 2.54351775, grad/param norm = 8.2183e-01, time/batch = 0.2389s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
1674/2700 (epoch 31.000), train_loss = 2.55910522, grad/param norm = 8.1827e-01, time/batch = 0.2440s	
1675/2700 (epoch 31.019), train_loss = 2.50975863, grad/param norm = 9.4509e-01, time/batch = 0.2443s	
1676/2700 (epoch 31.037), train_loss = 2.54073921, grad/param norm = 9.7814e-01, time/batch = 0.2509s	
1677/2700 (epoch 31.056), train_loss = 2.49859885, grad/param norm = 9.1166e-01, time/batch = 0.2520s	
1678/2700 (epoch 31.074), train_loss = 2.50176862, grad/param norm = 1.0173e+00, time/batch = 0.2488s	
1679/2700 (epoch 31.093), train_loss = 2.52619528, grad/param norm = 1.0059e+00, time/batch = 0.2258s	
1680/2700 (epoch 31.111), train_loss = 2.49245859, grad/param norm = 9.6174e-01, time/batch = 0.2184s	
1681/2700 (epoch 31.130), train_loss = 2.50549722, grad/param norm = 7.8964e-01, time/batch = 0.2178s	
1682/2700 (epoch 31.148), train_loss = 2.44513196, grad/param norm = 7.4504e-01, time/batch = 0.2078s	
1683/2700 (epoch 31.167), train_loss = 2.46761653, grad/param norm = 8.2063e-01, time/batch = 0.2195s	
1684/2700 (epoch 31.185), train_loss = 2.42636552, grad/param norm = 9.4310e-01, time/batch = 0.2370s	
1685/2700 (epoch 31.204), train_loss = 2.42645836, grad/param norm = 1.2021e+00, time/batch = 0.2441s	
1686/2700 (epoch 31.222), train_loss = 2.41139414, grad/param norm = 1.5305e+00, time/batch = 0.2538s	
1687/2700 (epoch 31.241), train_loss = 2.38916738, grad/param norm = 1.3522e+00, time/batch = 0.2467s	
1688/2700 (epoch 31.259), train_loss = 2.40174023, grad/param norm = 1.3074e+00, time/batch = 0.2433s	
1689/2700 (epoch 31.278), train_loss = 2.49534304, grad/param norm = 1.2175e+00, time/batch = 0.2265s	
1690/2700 (epoch 31.296), train_loss = 2.44817123, grad/param norm = 1.0255e+00, time/batch = 0.2188s	
1691/2700 (epoch 31.315), train_loss = 2.51468758, grad/param norm = 1.0405e+00, time/batch = 0.2449s	
1692/2700 (epoch 31.333), train_loss = 2.48223650, grad/param norm = 8.2376e-01, time/batch = 0.2299s	
1693/2700 (epoch 31.352), train_loss = 2.51347773, grad/param norm = 7.9058e-01, time/batch = 0.2189s	
1694/2700 (epoch 31.370), train_loss = 2.46096121, grad/param norm = 7.9499e-01, time/batch = 0.2064s	
1695/2700 (epoch 31.389), train_loss = 2.42222863, grad/param norm = 7.0017e-01, time/batch = 0.1845s	
1696/2700 (epoch 31.407), train_loss = 2.42155664, grad/param norm = 6.6046e-01, time/batch = 0.2164s	
1697/2700 (epoch 31.426), train_loss = 2.45405114, grad/param norm = 7.6565e-01, time/batch = 0.2356s	
1698/2700 (epoch 31.444), train_loss = 2.35504608, grad/param norm = 7.3439e-01, time/batch = 0.2535s	
1699/2700 (epoch 31.463), train_loss = 2.42668283, grad/param norm = 7.4645e-01, time/batch = 0.2511s	
1700/2700 (epoch 31.481), train_loss = 2.47874121, grad/param norm = 8.4463e-01, time/batch = 0.2444s	
1701/2700 (epoch 31.500), train_loss = 2.49702281, grad/param norm = 8.5592e-01, time/batch = 0.2389s	
1702/2700 (epoch 31.519), train_loss = 2.44731558, grad/param norm = 9.8403e-01, time/batch = 0.2343s	
1703/2700 (epoch 31.537), train_loss = 2.48691309, grad/param norm = 1.1596e+00, time/batch = 0.2521s	
1704/2700 (epoch 31.556), train_loss = 2.44307763, grad/param norm = 8.8717e-01, time/batch = 0.2511s	
1705/2700 (epoch 31.574), train_loss = 2.37275092, grad/param norm = 7.1343e-01, time/batch = 0.2397s	
1706/2700 (epoch 31.593), train_loss = 2.36138052, grad/param norm = 6.9346e-01, time/batch = 0.2298s	
1707/2700 (epoch 31.611), train_loss = 2.29460749, grad/param norm = 7.1327e-01, time/batch = 0.2146s	
1708/2700 (epoch 31.630), train_loss = 2.36167373, grad/param norm = 1.0943e+00, time/batch = 0.2298s	
1709/2700 (epoch 31.648), train_loss = 2.42354314, grad/param norm = 1.4398e+00, time/batch = 0.2463s	
1710/2700 (epoch 31.667), train_loss = 2.37578610, grad/param norm = 1.4693e+00, time/batch = 0.2532s	
1711/2700 (epoch 31.685), train_loss = 2.41691764, grad/param norm = 1.3376e+00, time/batch = 0.2325s	
1712/2700 (epoch 31.704), train_loss = 2.38174099, grad/param norm = 1.1477e+00, time/batch = 0.2433s	
1713/2700 (epoch 31.722), train_loss = 2.33634585, grad/param norm = 8.4470e-01, time/batch = 0.2407s	
1714/2700 (epoch 31.741), train_loss = 2.48939247, grad/param norm = 7.4765e-01, time/batch = 0.2354s	
1715/2700 (epoch 31.759), train_loss = 2.43428884, grad/param norm = 8.8401e-01, time/batch = 0.2278s	
1716/2700 (epoch 31.778), train_loss = 2.45426711, grad/param norm = 1.2253e+00, time/batch = 0.2269s	
1717/2700 (epoch 31.796), train_loss = 2.43867518, grad/param norm = 1.2047e+00, time/batch = 0.2167s	
1718/2700 (epoch 31.815), train_loss = 2.40259708, grad/param norm = 9.2621e-01, time/batch = 0.2051s	
1719/2700 (epoch 31.833), train_loss = 2.34545397, grad/param norm = 7.8280e-01, time/batch = 0.2120s	
1720/2700 (epoch 31.852), train_loss = 2.38359244, grad/param norm = 6.4124e-01, time/batch = 0.2355s	
1721/2700 (epoch 31.870), train_loss = 2.34907577, grad/param norm = 6.0762e-01, time/batch = 0.2233s	
1722/2700 (epoch 31.889), train_loss = 2.35083630, grad/param norm = 6.6833e-01, time/batch = 0.2343s	
1723/2700 (epoch 31.907), train_loss = 2.47188444, grad/param norm = 8.3021e-01, time/batch = 0.2417s	
1724/2700 (epoch 31.926), train_loss = 2.41985884, grad/param norm = 9.1577e-01, time/batch = 0.2525s	
1725/2700 (epoch 31.944), train_loss = 2.40276711, grad/param norm = 7.0028e-01, time/batch = 0.2428s	
1726/2700 (epoch 31.963), train_loss = 2.44897041, grad/param norm = 7.5170e-01, time/batch = 0.2157s	
1727/2700 (epoch 31.981), train_loss = 2.41829498, grad/param norm = 8.8966e-01, time/batch = 0.1926s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
1728/2700 (epoch 32.000), train_loss = 2.43244387, grad/param norm = 8.7558e-01, time/batch = 0.2065s	
1729/2700 (epoch 32.019), train_loss = 2.40898054, grad/param norm = 1.0403e+00, time/batch = 0.2204s	
1730/2700 (epoch 32.037), train_loss = 2.44013644, grad/param norm = 1.2705e+00, time/batch = 0.2233s	
1731/2700 (epoch 32.056), train_loss = 2.40835556, grad/param norm = 1.2614e+00, time/batch = 0.2444s	
1732/2700 (epoch 32.074), train_loss = 2.39784749, grad/param norm = 1.2080e+00, time/batch = 0.2518s	
1733/2700 (epoch 32.093), train_loss = 2.41203184, grad/param norm = 9.7453e-01, time/batch = 0.2405s	
1734/2700 (epoch 32.111), train_loss = 2.37566370, grad/param norm = 8.0125e-01, time/batch = 0.2404s	
1735/2700 (epoch 32.130), train_loss = 2.39685545, grad/param norm = 7.0897e-01, time/batch = 0.2379s	
1736/2700 (epoch 32.148), train_loss = 2.34625564, grad/param norm = 7.8570e-01, time/batch = 0.2231s	
1737/2700 (epoch 32.167), train_loss = 2.37952757, grad/param norm = 9.1026e-01, time/batch = 0.2088s	
1738/2700 (epoch 32.185), train_loss = 2.32181746, grad/param norm = 9.3256e-01, time/batch = 0.1878s	
1739/2700 (epoch 32.204), train_loss = 2.32696664, grad/param norm = 9.9952e-01, time/batch = 0.1867s	
1740/2700 (epoch 32.222), train_loss = 2.30388651, grad/param norm = 1.2338e+00, time/batch = 0.2075s	
1741/2700 (epoch 32.241), train_loss = 2.26858000, grad/param norm = 9.0841e-01, time/batch = 0.2113s	
1742/2700 (epoch 32.259), train_loss = 2.27835932, grad/param norm = 6.8074e-01, time/batch = 0.2293s	
1743/2700 (epoch 32.278), train_loss = 2.36912596, grad/param norm = 7.1563e-01, time/batch = 0.2337s	
1744/2700 (epoch 32.296), train_loss = 2.34467252, grad/param norm = 6.4200e-01, time/batch = 0.2071s	
1745/2700 (epoch 32.315), train_loss = 2.37710594, grad/param norm = 6.9292e-01, time/batch = 0.2111s	
1746/2700 (epoch 32.333), train_loss = 2.37367488, grad/param norm = 8.1785e-01, time/batch = 0.1907s	
1747/2700 (epoch 32.352), train_loss = 2.42875300, grad/param norm = 9.7399e-01, time/batch = 0.2157s	
1748/2700 (epoch 32.370), train_loss = 2.37766437, grad/param norm = 9.4209e-01, time/batch = 0.2338s	
1749/2700 (epoch 32.389), train_loss = 2.33799352, grad/param norm = 8.3768e-01, time/batch = 0.2497s	
1750/2700 (epoch 32.407), train_loss = 2.33314179, grad/param norm = 7.3817e-01, time/batch = 0.2517s	
1751/2700 (epoch 32.426), train_loss = 2.35273917, grad/param norm = 6.7865e-01, time/batch = 0.2420s	
1752/2700 (epoch 32.444), train_loss = 2.26471250, grad/param norm = 8.1714e-01, time/batch = 0.2531s	
1753/2700 (epoch 32.463), train_loss = 2.33840462, grad/param norm = 1.1012e+00, time/batch = 0.2541s	
1754/2700 (epoch 32.481), train_loss = 2.40561447, grad/param norm = 1.2471e+00, time/batch = 0.2502s	
1755/2700 (epoch 32.500), train_loss = 2.40521395, grad/param norm = 1.2953e+00, time/batch = 0.2191s	
1756/2700 (epoch 32.519), train_loss = 2.36756504, grad/param norm = 1.1923e+00, time/batch = 0.2065s	
1757/2700 (epoch 32.537), train_loss = 2.34718578, grad/param norm = 8.4349e-01, time/batch = 0.2016s	
1758/2700 (epoch 32.556), train_loss = 2.29783632, grad/param norm = 5.7330e-01, time/batch = 0.2016s	
1759/2700 (epoch 32.574), train_loss = 2.27081760, grad/param norm = 5.8823e-01, time/batch = 0.2268s	
1760/2700 (epoch 32.593), train_loss = 2.26627683, grad/param norm = 6.1089e-01, time/batch = 0.2485s	
1761/2700 (epoch 32.611), train_loss = 2.19561000, grad/param norm = 6.0887e-01, time/batch = 0.2296s	
1762/2700 (epoch 32.630), train_loss = 2.25471553, grad/param norm = 6.7587e-01, time/batch = 0.2490s	
1763/2700 (epoch 32.648), train_loss = 2.28637836, grad/param norm = 6.8040e-01, time/batch = 0.2537s	
1764/2700 (epoch 32.667), train_loss = 2.23330300, grad/param norm = 7.0968e-01, time/batch = 0.2527s	
1765/2700 (epoch 32.685), train_loss = 2.28437719, grad/param norm = 8.6689e-01, time/batch = 0.2483s	
1766/2700 (epoch 32.704), train_loss = 2.29527413, grad/param norm = 9.6890e-01, time/batch = 0.2412s	
1767/2700 (epoch 32.722), train_loss = 2.27494138, grad/param norm = 1.0216e+00, time/batch = 0.2274s	
1768/2700 (epoch 32.741), train_loss = 2.41936842, grad/param norm = 1.1870e+00, time/batch = 0.2169s	
1769/2700 (epoch 32.759), train_loss = 2.37085912, grad/param norm = 1.2371e+00, time/batch = 0.2238s	
1770/2700 (epoch 32.778), train_loss = 2.36911005, grad/param norm = 1.1334e+00, time/batch = 0.2389s	
1771/2700 (epoch 32.796), train_loss = 2.31514628, grad/param norm = 9.7582e-01, time/batch = 0.2316s	
1772/2700 (epoch 32.815), train_loss = 2.31195915, grad/param norm = 7.7066e-01, time/batch = 0.2478s	
1773/2700 (epoch 32.833), train_loss = 2.25901595, grad/param norm = 7.3221e-01, time/batch = 0.2522s	
1774/2700 (epoch 32.852), train_loss = 2.29220215, grad/param norm = 6.0756e-01, time/batch = 0.2527s	
1775/2700 (epoch 32.870), train_loss = 2.26360856, grad/param norm = 5.5045e-01, time/batch = 0.2456s	
1776/2700 (epoch 32.889), train_loss = 2.25659454, grad/param norm = 5.3284e-01, time/batch = 0.2326s	
1777/2700 (epoch 32.907), train_loss = 2.36834291, grad/param norm = 6.3943e-01, time/batch = 0.2273s	
1778/2700 (epoch 32.926), train_loss = 2.31638587, grad/param norm = 7.7967e-01, time/batch = 0.2153s	
1779/2700 (epoch 32.944), train_loss = 2.32339660, grad/param norm = 7.6507e-01, time/batch = 0.2028s	
1780/2700 (epoch 32.963), train_loss = 2.38937285, grad/param norm = 9.3563e-01, time/batch = 0.1994s	
1781/2700 (epoch 32.981), train_loss = 2.39988812, grad/param norm = 1.2515e+00, time/batch = 0.1981s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
1782/2700 (epoch 33.000), train_loss = 2.42325200, grad/param norm = 1.3510e+00, time/batch = 0.2229s	
1783/2700 (epoch 33.019), train_loss = 2.34426841, grad/param norm = 8.8406e-01, time/batch = 0.2459s	
1784/2700 (epoch 33.037), train_loss = 2.33103504, grad/param norm = 7.8851e-01, time/batch = 0.2496s	
1785/2700 (epoch 33.056), train_loss = 2.30049863, grad/param norm = 9.5446e-01, time/batch = 0.2486s	
1786/2700 (epoch 33.074), train_loss = 2.29084068, grad/param norm = 1.1026e+00, time/batch = 0.2376s	
1787/2700 (epoch 33.093), train_loss = 2.32232529, grad/param norm = 1.0150e+00, time/batch = 0.2225s	
1788/2700 (epoch 33.111), train_loss = 2.28494537, grad/param norm = 9.4065e-01, time/batch = 0.2319s	
1789/2700 (epoch 33.130), train_loss = 2.30090546, grad/param norm = 7.3685e-01, time/batch = 0.2069s	
1790/2700 (epoch 33.148), train_loss = 2.24307589, grad/param norm = 7.1915e-01, time/batch = 0.1994s	
1791/2700 (epoch 33.167), train_loss = 2.27733959, grad/param norm = 7.1914e-01, time/batch = 0.1894s	
1792/2700 (epoch 33.185), train_loss = 2.22074918, grad/param norm = 6.9414e-01, time/batch = 0.2086s	
1793/2700 (epoch 33.204), train_loss = 2.22316292, grad/param norm = 8.5882e-01, time/batch = 0.2272s	
1794/2700 (epoch 33.222), train_loss = 2.17706292, grad/param norm = 9.2805e-01, time/batch = 0.2323s	
1795/2700 (epoch 33.241), train_loss = 2.15027447, grad/param norm = 9.0105e-01, time/batch = 0.2336s	
1796/2700 (epoch 33.259), train_loss = 2.18449904, grad/param norm = 7.5539e-01, time/batch = 0.2317s	
1797/2700 (epoch 33.278), train_loss = 2.28133396, grad/param norm = 7.2980e-01, time/batch = 0.2070s	
1798/2700 (epoch 33.296), train_loss = 2.26549745, grad/param norm = 7.6351e-01, time/batch = 0.2298s	
1799/2700 (epoch 33.315), train_loss = 2.30412062, grad/param norm = 8.0476e-01, time/batch = 0.2299s	
1800/2700 (epoch 33.333), train_loss = 2.28173318, grad/param norm = 7.0938e-01, time/batch = 0.2039s	
1801/2700 (epoch 33.352), train_loss = 2.29664581, grad/param norm = 6.6755e-01, time/batch = 0.1959s	
1802/2700 (epoch 33.370), train_loss = 2.27891366, grad/param norm = 7.5348e-01, time/batch = 0.2199s	
1803/2700 (epoch 33.389), train_loss = 2.24801050, grad/param norm = 7.9213e-01, time/batch = 0.2389s	
1804/2700 (epoch 33.407), train_loss = 2.25458008, grad/param norm = 7.3862e-01, time/batch = 0.2515s	
1805/2700 (epoch 33.426), train_loss = 2.27559411, grad/param norm = 7.5333e-01, time/batch = 0.2531s	
1806/2700 (epoch 33.444), train_loss = 2.17852500, grad/param norm = 5.8177e-01, time/batch = 0.2542s	
1807/2700 (epoch 33.463), train_loss = 2.23098433, grad/param norm = 4.7931e-01, time/batch = 0.2403s	
1808/2700 (epoch 33.481), train_loss = 2.28079523, grad/param norm = 5.2685e-01, time/batch = 0.2527s	
1809/2700 (epoch 33.500), train_loss = 2.26571567, grad/param norm = 6.2013e-01, time/batch = 0.2533s	
1810/2700 (epoch 33.519), train_loss = 2.24593883, grad/param norm = 7.4585e-01, time/batch = 0.2517s	
1811/2700 (epoch 33.537), train_loss = 2.26948378, grad/param norm = 8.8220e-01, time/batch = 0.2524s	
1812/2700 (epoch 33.556), train_loss = 2.24949639, grad/param norm = 8.2547e-01, time/batch = 0.2515s	
1813/2700 (epoch 33.574), train_loss = 2.20814617, grad/param norm = 7.9966e-01, time/batch = 0.2485s	
1814/2700 (epoch 33.593), train_loss = 2.20984791, grad/param norm = 9.3569e-01, time/batch = 0.2350s	
1815/2700 (epoch 33.611), train_loss = 2.14258987, grad/param norm = 1.1098e+00, time/batch = 0.2211s	
1816/2700 (epoch 33.630), train_loss = 2.22765970, grad/param norm = 1.2577e+00, time/batch = 0.2195s	
1817/2700 (epoch 33.648), train_loss = 2.26272149, grad/param norm = 1.2523e+00, time/batch = 0.2135s	
1818/2700 (epoch 33.667), train_loss = 2.21030383, grad/param norm = 1.1156e+00, time/batch = 0.2436s	
1819/2700 (epoch 33.685), train_loss = 2.22027148, grad/param norm = 9.9932e-01, time/batch = 0.2381s	
1820/2700 (epoch 33.704), train_loss = 2.21743500, grad/param norm = 8.1974e-01, time/batch = 0.2349s	
1821/2700 (epoch 33.722), train_loss = 2.17749190, grad/param norm = 7.3037e-01, time/batch = 0.2393s	
1822/2700 (epoch 33.741), train_loss = 2.29558640, grad/param norm = 6.6009e-01, time/batch = 0.2540s	
1823/2700 (epoch 33.759), train_loss = 2.26392261, grad/param norm = 7.1985e-01, time/batch = 0.2548s	
1824/2700 (epoch 33.778), train_loss = 2.27226073, grad/param norm = 7.6778e-01, time/batch = 0.2519s	
1825/2700 (epoch 33.796), train_loss = 2.22834384, grad/param norm = 7.3886e-01, time/batch = 0.2542s	
1826/2700 (epoch 33.815), train_loss = 2.23815823, grad/param norm = 6.9238e-01, time/batch = 0.2396s	
1827/2700 (epoch 33.833), train_loss = 2.18513608, grad/param norm = 6.8728e-01, time/batch = 0.2169s	
1828/2700 (epoch 33.852), train_loss = 2.21393644, grad/param norm = 6.2415e-01, time/batch = 0.1969s	
1829/2700 (epoch 33.870), train_loss = 2.19004939, grad/param norm = 6.0300e-01, time/batch = 0.1998s	
1830/2700 (epoch 33.889), train_loss = 2.18792168, grad/param norm = 6.6893e-01, time/batch = 0.2233s	
1831/2700 (epoch 33.907), train_loss = 2.31276510, grad/param norm = 8.4255e-01, time/batch = 0.2167s	
1832/2700 (epoch 33.926), train_loss = 2.26488816, grad/param norm = 1.0090e+00, time/batch = 0.2180s	
1833/2700 (epoch 33.944), train_loss = 2.26693767, grad/param norm = 1.0131e+00, time/batch = 0.2338s	
1834/2700 (epoch 33.963), train_loss = 2.29359504, grad/param norm = 9.4409e-01, time/batch = 0.2346s	
1835/2700 (epoch 33.981), train_loss = 2.26622635, grad/param norm = 8.6762e-01, time/batch = 0.2362s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
1836/2700 (epoch 34.000), train_loss = 2.26987611, grad/param norm = 9.0661e-01, time/batch = 0.2225s	
1837/2700 (epoch 34.019), train_loss = 2.24073992, grad/param norm = 8.4468e-01, time/batch = 0.2059s	
1838/2700 (epoch 34.037), train_loss = 2.24379248, grad/param norm = 6.8897e-01, time/batch = 0.1865s	
1839/2700 (epoch 34.056), train_loss = 2.21390511, grad/param norm = 6.7000e-01, time/batch = 0.2181s	
1840/2700 (epoch 34.074), train_loss = 2.18381225, grad/param norm = 6.4459e-01, time/batch = 0.2242s	
1841/2700 (epoch 34.093), train_loss = 2.22150223, grad/param norm = 6.9770e-01, time/batch = 0.2415s	
1842/2700 (epoch 34.111), train_loss = 2.18235314, grad/param norm = 7.6798e-01, time/batch = 0.2499s	
1843/2700 (epoch 34.130), train_loss = 2.22147885, grad/param norm = 7.2520e-01, time/batch = 0.2420s	
1844/2700 (epoch 34.148), train_loss = 2.16973191, grad/param norm = 6.9131e-01, time/batch = 0.2487s	
1845/2700 (epoch 34.167), train_loss = 2.20860496, grad/param norm = 7.1264e-01, time/batch = 0.2444s	
1846/2700 (epoch 34.185), train_loss = 2.14454456, grad/param norm = 7.0012e-01, time/batch = 0.2332s	
1847/2700 (epoch 34.204), train_loss = 2.14801987, grad/param norm = 5.4167e-01, time/batch = 0.2188s	
1848/2700 (epoch 34.222), train_loss = 2.08678112, grad/param norm = 6.0877e-01, time/batch = 0.1819s	
1849/2700 (epoch 34.241), train_loss = 2.06641361, grad/param norm = 6.5919e-01, time/batch = 0.1693s	
1850/2700 (epoch 34.259), train_loss = 2.13296556, grad/param norm = 8.2642e-01, time/batch = 0.2218s	
1851/2700 (epoch 34.278), train_loss = 2.23869273, grad/param norm = 9.1538e-01, time/batch = 0.2172s	
1852/2700 (epoch 34.296), train_loss = 2.20528423, grad/param norm = 7.6523e-01, time/batch = 0.2338s	
1853/2700 (epoch 34.315), train_loss = 2.22866874, grad/param norm = 7.2990e-01, time/batch = 0.2352s	
1854/2700 (epoch 34.333), train_loss = 2.21369996, grad/param norm = 7.2756e-01, time/batch = 0.2216s	
1855/2700 (epoch 34.352), train_loss = 2.24370452, grad/param norm = 7.7798e-01, time/batch = 0.2288s	
1856/2700 (epoch 34.370), train_loss = 2.22568852, grad/param norm = 8.9055e-01, time/batch = 0.2196s	
1857/2700 (epoch 34.389), train_loss = 2.19278620, grad/param norm = 8.4218e-01, time/batch = 0.2124s	
1858/2700 (epoch 34.407), train_loss = 2.18284983, grad/param norm = 7.2474e-01, time/batch = 0.1840s	
1859/2700 (epoch 34.426), train_loss = 2.21458694, grad/param norm = 6.8890e-01, time/batch = 0.2221s	
1860/2700 (epoch 34.444), train_loss = 2.11885992, grad/param norm = 7.1035e-01, time/batch = 0.2464s	
1861/2700 (epoch 34.463), train_loss = 2.17521108, grad/param norm = 8.0576e-01, time/batch = 0.2284s	
1862/2700 (epoch 34.481), train_loss = 2.23631355, grad/param norm = 9.4492e-01, time/batch = 0.2333s	
1863/2700 (epoch 34.500), train_loss = 2.21081953, grad/param norm = 1.0112e+00, time/batch = 0.2291s	
1864/2700 (epoch 34.519), train_loss = 2.18750884, grad/param norm = 9.6798e-01, time/batch = 0.2273s	
1865/2700 (epoch 34.537), train_loss = 2.18909119, grad/param norm = 7.7919e-01, time/batch = 0.2164s	
1866/2700 (epoch 34.556), train_loss = 2.14816849, grad/param norm = 6.8541e-01, time/batch = 0.2015s	
1867/2700 (epoch 34.574), train_loss = 2.14363051, grad/param norm = 7.9126e-01, time/batch = 0.1907s	
1868/2700 (epoch 34.593), train_loss = 2.15329628, grad/param norm = 9.1898e-01, time/batch = 0.2004s	
1869/2700 (epoch 34.611), train_loss = 2.07918826, grad/param norm = 8.7495e-01, time/batch = 0.2294s	
1870/2700 (epoch 34.630), train_loss = 2.12204370, grad/param norm = 8.2053e-01, time/batch = 0.2418s	
1871/2700 (epoch 34.648), train_loss = 2.13234134, grad/param norm = 6.5689e-01, time/batch = 0.2389s	
1872/2700 (epoch 34.667), train_loss = 2.08352096, grad/param norm = 5.2479e-01, time/batch = 0.2533s	
1873/2700 (epoch 34.685), train_loss = 2.10669260, grad/param norm = 5.1410e-01, time/batch = 0.2544s	
1874/2700 (epoch 34.704), train_loss = 2.11998711, grad/param norm = 5.7548e-01, time/batch = 0.2532s	
1875/2700 (epoch 34.722), train_loss = 2.08863536, grad/param norm = 5.1870e-01, time/batch = 0.2527s	
1876/2700 (epoch 34.741), train_loss = 2.19956819, grad/param norm = 5.2172e-01, time/batch = 0.2419s	
1877/2700 (epoch 34.759), train_loss = 2.18610347, grad/param norm = 6.4587e-01, time/batch = 0.2323s	
1878/2700 (epoch 34.778), train_loss = 2.19761058, grad/param norm = 7.8704e-01, time/batch = 0.2120s	
1879/2700 (epoch 34.796), train_loss = 2.15876897, grad/param norm = 8.1207e-01, time/batch = 0.2210s	
1880/2700 (epoch 34.815), train_loss = 2.17888512, grad/param norm = 9.4364e-01, time/batch = 0.2269s	
1881/2700 (epoch 34.833), train_loss = 2.15082701, grad/param norm = 1.0210e+00, time/batch = 0.2280s	
1882/2700 (epoch 34.852), train_loss = 2.15641487, grad/param norm = 9.1196e-01, time/batch = 0.2423s	
1883/2700 (epoch 34.870), train_loss = 2.14939053, grad/param norm = 9.7406e-01, time/batch = 0.2512s	
1884/2700 (epoch 34.889), train_loss = 2.15136548, grad/param norm = 1.0121e+00, time/batch = 0.2503s	
1885/2700 (epoch 34.907), train_loss = 2.26724465, grad/param norm = 1.0022e+00, time/batch = 0.2529s	
1886/2700 (epoch 34.926), train_loss = 2.19179843, grad/param norm = 8.7918e-01, time/batch = 0.2463s	
1887/2700 (epoch 34.944), train_loss = 2.17853191, grad/param norm = 6.9258e-01, time/batch = 0.2333s	
1888/2700 (epoch 34.963), train_loss = 2.19719479, grad/param norm = 5.5958e-01, time/batch = 0.2207s	
1889/2700 (epoch 34.981), train_loss = 2.17337348, grad/param norm = 6.3441e-01, time/batch = 0.2048s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
1890/2700 (epoch 35.000), train_loss = 2.20190711, grad/param norm = 6.9792e-01, time/batch = 0.1895s	
1891/2700 (epoch 35.019), train_loss = 2.19311426, grad/param norm = 8.6679e-01, time/batch = 0.1796s	
1892/2700 (epoch 35.037), train_loss = 2.19893751, grad/param norm = 8.5225e-01, time/batch = 0.2227s	
1893/2700 (epoch 35.056), train_loss = 2.14737306, grad/param norm = 7.9789e-01, time/batch = 0.2381s	
1894/2700 (epoch 35.074), train_loss = 2.11582523, grad/param norm = 7.8500e-01, time/batch = 0.2527s	
1895/2700 (epoch 35.093), train_loss = 2.15592164, grad/param norm = 7.6893e-01, time/batch = 0.2516s	
1896/2700 (epoch 35.111), train_loss = 2.11439705, grad/param norm = 7.4228e-01, time/batch = 0.2519s	
1897/2700 (epoch 35.130), train_loss = 2.14531737, grad/param norm = 6.2038e-01, time/batch = 0.2530s	
1898/2700 (epoch 35.148), train_loss = 2.09685437, grad/param norm = 6.4203e-01, time/batch = 0.2431s	
1899/2700 (epoch 35.167), train_loss = 2.14667290, grad/param norm = 6.9997e-01, time/batch = 0.2224s	
1900/2700 (epoch 35.185), train_loss = 2.08001943, grad/param norm = 6.5709e-01, time/batch = 0.2150s	
1901/2700 (epoch 35.204), train_loss = 2.09678930, grad/param norm = 5.7357e-01, time/batch = 0.2437s	
1902/2700 (epoch 35.222), train_loss = 2.03234011, grad/param norm = 6.4465e-01, time/batch = 0.2523s	
1903/2700 (epoch 35.241), train_loss = 1.99770894, grad/param norm = 6.2771e-01, time/batch = 0.2464s	
1904/2700 (epoch 35.259), train_loss = 2.04383957, grad/param norm = 6.2801e-01, time/batch = 0.2278s	
1905/2700 (epoch 35.278), train_loss = 2.13265132, grad/param norm = 6.0266e-01, time/batch = 0.2142s	
1906/2700 (epoch 35.296), train_loss = 2.11189682, grad/param norm = 5.2176e-01, time/batch = 0.2280s	
1907/2700 (epoch 35.315), train_loss = 2.13625718, grad/param norm = 5.7046e-01, time/batch = 0.2435s	
1908/2700 (epoch 35.333), train_loss = 2.12392757, grad/param norm = 6.1220e-01, time/batch = 0.2499s	
1909/2700 (epoch 35.352), train_loss = 2.15782012, grad/param norm = 7.0579e-01, time/batch = 0.2183s	
1910/2700 (epoch 35.370), train_loss = 2.16495701, grad/param norm = 9.0348e-01, time/batch = 0.2270s	
1911/2700 (epoch 35.389), train_loss = 2.13021005, grad/param norm = 9.6292e-01, time/batch = 0.2489s	
1912/2700 (epoch 35.407), train_loss = 2.13409632, grad/param norm = 9.1204e-01, time/batch = 0.2421s	
1913/2700 (epoch 35.426), train_loss = 2.15363699, grad/param norm = 8.5390e-01, time/batch = 0.2352s	
1914/2700 (epoch 35.444), train_loss = 2.04741640, grad/param norm = 5.8824e-01, time/batch = 0.2213s	
1915/2700 (epoch 35.463), train_loss = 2.09770592, grad/param norm = 4.6516e-01, time/batch = 0.2089s	
1916/2700 (epoch 35.481), train_loss = 2.15392602, grad/param norm = 5.6115e-01, time/batch = 0.1992s	
1917/2700 (epoch 35.500), train_loss = 2.11613573, grad/param norm = 5.7236e-01, time/batch = 0.2034s	
1918/2700 (epoch 35.519), train_loss = 2.09805310, grad/param norm = 6.1492e-01, time/batch = 0.2058s	
1919/2700 (epoch 35.537), train_loss = 2.12171606, grad/param norm = 6.7434e-01, time/batch = 0.2105s	
1920/2700 (epoch 35.556), train_loss = 2.08575437, grad/param norm = 6.5217e-01, time/batch = 0.2100s	
1921/2700 (epoch 35.574), train_loss = 2.08696067, grad/param norm = 8.4554e-01, time/batch = 0.2386s	
1922/2700 (epoch 35.593), train_loss = 2.09902318, grad/param norm = 9.9538e-01, time/batch = 0.2108s	
1923/2700 (epoch 35.611), train_loss = 2.00953303, grad/param norm = 1.0007e+00, time/batch = 0.2512s	
1924/2700 (epoch 35.630), train_loss = 2.07664766, grad/param norm = 1.0139e+00, time/batch = 0.2510s	
1925/2700 (epoch 35.648), train_loss = 2.10097721, grad/param norm = 9.8071e-01, time/batch = 0.2400s	
1926/2700 (epoch 35.667), train_loss = 2.05854372, grad/param norm = 9.0340e-01, time/batch = 0.2238s	
1927/2700 (epoch 35.685), train_loss = 2.07446637, grad/param norm = 8.5763e-01, time/batch = 0.2144s	
1928/2700 (epoch 35.704), train_loss = 2.07660490, grad/param norm = 7.5713e-01, time/batch = 0.2299s	
1929/2700 (epoch 35.722), train_loss = 2.03692155, grad/param norm = 6.6530e-01, time/batch = 0.2210s	
1930/2700 (epoch 35.741), train_loss = 2.13387000, grad/param norm = 6.2965e-01, time/batch = 0.2241s	
1931/2700 (epoch 35.759), train_loss = 2.11973587, grad/param norm = 6.5743e-01, time/batch = 0.2285s	
1932/2700 (epoch 35.778), train_loss = 2.12674353, grad/param norm = 6.2316e-01, time/batch = 0.2470s	
1933/2700 (epoch 35.796), train_loss = 2.08290591, grad/param norm = 6.5670e-01, time/batch = 0.2499s	
1934/2700 (epoch 35.815), train_loss = 2.10804394, grad/param norm = 6.5508e-01, time/batch = 0.2418s	
1935/2700 (epoch 35.833), train_loss = 2.06573674, grad/param norm = 6.4322e-01, time/batch = 0.2410s	
1936/2700 (epoch 35.852), train_loss = 2.08104426, grad/param norm = 5.7349e-01, time/batch = 0.2332s	
1937/2700 (epoch 35.870), train_loss = 2.05988801, grad/param norm = 5.6156e-01, time/batch = 0.2112s	
1938/2700 (epoch 35.889), train_loss = 2.06945713, grad/param norm = 5.8210e-01, time/batch = 0.1975s	
1939/2700 (epoch 35.907), train_loss = 2.18385129, grad/param norm = 7.2444e-01, time/batch = 0.1791s	
1940/2700 (epoch 35.926), train_loss = 2.11795473, grad/param norm = 8.1995e-01, time/batch = 0.2003s	
1941/2700 (epoch 35.944), train_loss = 2.11088261, grad/param norm = 7.6990e-01, time/batch = 0.2097s	
1942/2700 (epoch 35.963), train_loss = 2.14652779, grad/param norm = 7.5716e-01, time/batch = 0.2000s	
1943/2700 (epoch 35.981), train_loss = 2.12519957, grad/param norm = 8.3424e-01, time/batch = 0.2037s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
1944/2700 (epoch 36.000), train_loss = 2.14366487, grad/param norm = 7.1245e-01, time/batch = 0.2308s	
1945/2700 (epoch 36.019), train_loss = 2.11971784, grad/param norm = 7.6747e-01, time/batch = 0.2215s	
1946/2700 (epoch 36.037), train_loss = 2.13186182, grad/param norm = 7.8867e-01, time/batch = 0.2126s	
1947/2700 (epoch 36.056), train_loss = 2.08955179, grad/param norm = 8.7560e-01, time/batch = 0.1906s	
1948/2700 (epoch 36.074), train_loss = 2.06623958, grad/param norm = 8.6295e-01, time/batch = 0.2024s	
1949/2700 (epoch 36.093), train_loss = 2.09991283, grad/param norm = 7.8198e-01, time/batch = 0.2175s	
1950/2700 (epoch 36.111), train_loss = 2.04525519, grad/param norm = 6.8506e-01, time/batch = 0.2491s	
1951/2700 (epoch 36.130), train_loss = 2.07137884, grad/param norm = 5.4928e-01, time/batch = 0.2296s	
1952/2700 (epoch 36.148), train_loss = 2.02766744, grad/param norm = 6.2241e-01, time/batch = 0.2293s	
1953/2700 (epoch 36.167), train_loss = 2.08949319, grad/param norm = 7.2741e-01, time/batch = 0.2160s	
1954/2700 (epoch 36.185), train_loss = 2.02354866, grad/param norm = 7.2505e-01, time/batch = 0.2107s	
1955/2700 (epoch 36.204), train_loss = 2.04827675, grad/param norm = 6.3832e-01, time/batch = 0.2006s	
1956/2700 (epoch 36.222), train_loss = 1.98586373, grad/param norm = 7.4305e-01, time/batch = 0.1958s	
1957/2700 (epoch 36.241), train_loss = 1.94106439, grad/param norm = 6.2526e-01, time/batch = 0.1987s	
1958/2700 (epoch 36.259), train_loss = 1.97894074, grad/param norm = 5.6000e-01, time/batch = 0.2198s	
1959/2700 (epoch 36.278), train_loss = 2.06723804, grad/param norm = 5.6209e-01, time/batch = 0.2448s	
1960/2700 (epoch 36.296), train_loss = 2.05098903, grad/param norm = 4.7013e-01, time/batch = 0.2527s	
1961/2700 (epoch 36.315), train_loss = 2.07647215, grad/param norm = 5.1299e-01, time/batch = 0.2341s	
1962/2700 (epoch 36.333), train_loss = 2.06443997, grad/param norm = 5.7655e-01, time/batch = 0.2443s	
1963/2700 (epoch 36.352), train_loss = 2.10455387, grad/param norm = 7.1612e-01, time/batch = 0.2505s	
1964/2700 (epoch 36.370), train_loss = 2.11621007, grad/param norm = 8.3070e-01, time/batch = 0.2346s	
1965/2700 (epoch 36.389), train_loss = 2.06505983, grad/param norm = 7.8271e-01, time/batch = 0.2333s	
1966/2700 (epoch 36.407), train_loss = 2.05915851, grad/param norm = 6.4674e-01, time/batch = 0.2174s	
1967/2700 (epoch 36.426), train_loss = 2.08523522, grad/param norm = 6.3466e-01, time/batch = 0.2215s	
1968/2700 (epoch 36.444), train_loss = 1.98355203, grad/param norm = 4.7824e-01, time/batch = 0.2345s	
1969/2700 (epoch 36.463), train_loss = 2.04281370, grad/param norm = 4.5456e-01, time/batch = 0.2423s	
1970/2700 (epoch 36.481), train_loss = 2.09307083, grad/param norm = 5.6576e-01, time/batch = 0.2500s	
1971/2700 (epoch 36.500), train_loss = 2.05842973, grad/param norm = 6.2433e-01, time/batch = 0.2428s	
1972/2700 (epoch 36.519), train_loss = 2.04584628, grad/param norm = 7.3604e-01, time/batch = 0.2508s	
1973/2700 (epoch 36.537), train_loss = 2.07176271, grad/param norm = 7.8156e-01, time/batch = 0.2515s	
1974/2700 (epoch 36.556), train_loss = 2.02440715, grad/param norm = 8.3078e-01, time/batch = 0.2509s	
1975/2700 (epoch 36.574), train_loss = 2.03764853, grad/param norm = 8.9700e-01, time/batch = 0.2202s	
1976/2700 (epoch 36.593), train_loss = 2.04003056, grad/param norm = 9.4443e-01, time/batch = 0.2219s	
1977/2700 (epoch 36.611), train_loss = 1.95347809, grad/param norm = 9.0102e-01, time/batch = 0.2041s	
1978/2700 (epoch 36.630), train_loss = 2.01554200, grad/param norm = 9.8741e-01, time/batch = 0.1915s	
1979/2700 (epoch 36.648), train_loss = 2.03003294, grad/param norm = 7.9129e-01, time/batch = 0.2071s	
1980/2700 (epoch 36.667), train_loss = 1.97946739, grad/param norm = 6.1212e-01, time/batch = 0.2346s	
1981/2700 (epoch 36.685), train_loss = 1.99763830, grad/param norm = 5.6439e-01, time/batch = 0.2258s	
1982/2700 (epoch 36.704), train_loss = 2.00980443, grad/param norm = 5.8499e-01, time/batch = 0.2378s	
1983/2700 (epoch 36.722), train_loss = 1.96787767, grad/param norm = 5.2102e-01, time/batch = 0.2431s	
1984/2700 (epoch 36.741), train_loss = 2.06117662, grad/param norm = 5.1393e-01, time/batch = 0.2458s	
1985/2700 (epoch 36.759), train_loss = 2.06874979, grad/param norm = 6.6768e-01, time/batch = 0.2434s	
1986/2700 (epoch 36.778), train_loss = 2.08804064, grad/param norm = 8.2039e-01, time/batch = 0.2455s	
1987/2700 (epoch 36.796), train_loss = 2.04053947, grad/param norm = 8.0607e-01, time/batch = 0.2367s	
1988/2700 (epoch 36.815), train_loss = 2.05562460, grad/param norm = 7.8116e-01, time/batch = 0.2258s	
1989/2700 (epoch 36.833), train_loss = 2.02093377, grad/param norm = 7.9253e-01, time/batch = 0.2139s	
1990/2700 (epoch 36.852), train_loss = 2.03627265, grad/param norm = 7.8420e-01, time/batch = 0.2110s	
1991/2700 (epoch 36.870), train_loss = 2.03185302, grad/param norm = 8.1177e-01, time/batch = 0.2235s	
1992/2700 (epoch 36.889), train_loss = 2.03285163, grad/param norm = 7.7147e-01, time/batch = 0.2356s	
1993/2700 (epoch 36.907), train_loss = 2.14982867, grad/param norm = 8.0035e-01, time/batch = 0.2480s	
1994/2700 (epoch 36.926), train_loss = 2.07028690, grad/param norm = 8.5986e-01, time/batch = 0.2423s	
1995/2700 (epoch 36.944), train_loss = 2.06021508, grad/param norm = 7.2462e-01, time/batch = 0.2372s	
1996/2700 (epoch 36.963), train_loss = 2.07613328, grad/param norm = 5.9259e-01, time/batch = 0.2340s	
1997/2700 (epoch 36.981), train_loss = 2.05771549, grad/param norm = 5.8594e-01, time/batch = 0.2282s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
1998/2700 (epoch 37.000), train_loss = 2.07845611, grad/param norm = 6.1681e-01, time/batch = 0.2322s	
1999/2700 (epoch 37.019), train_loss = 2.06306675, grad/param norm = 6.3342e-01, time/batch = 0.2113s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch37.04_2.0186.t7	
2000/2700 (epoch 37.037), train_loss = 2.06765103, grad/param norm = 5.7970e-01, time/batch = 0.1659s	
2001/2700 (epoch 37.056), train_loss = 2.06981510, grad/param norm = 6.1864e-01, time/batch = 0.2177s	
2002/2700 (epoch 37.074), train_loss = 1.98845434, grad/param norm = 6.1253e-01, time/batch = 0.2273s	
2003/2700 (epoch 37.093), train_loss = 2.02121849, grad/param norm = 6.0142e-01, time/batch = 0.2243s	
2004/2700 (epoch 37.111), train_loss = 1.97721404, grad/param norm = 6.2725e-01, time/batch = 0.2358s	
2005/2700 (epoch 37.130), train_loss = 2.01868974, grad/param norm = 5.6495e-01, time/batch = 0.2392s	
2006/2700 (epoch 37.148), train_loss = 1.97384246, grad/param norm = 6.2428e-01, time/batch = 0.2061s	
2007/2700 (epoch 37.167), train_loss = 2.03917392, grad/param norm = 6.8054e-01, time/batch = 0.2026s	
2008/2700 (epoch 37.185), train_loss = 1.96678738, grad/param norm = 6.8087e-01, time/batch = 0.2326s	
2009/2700 (epoch 37.204), train_loss = 1.99019283, grad/param norm = 5.5830e-01, time/batch = 0.2482s	
2010/2700 (epoch 37.222), train_loss = 1.92329968, grad/param norm = 5.4198e-01, time/batch = 0.2525s	
2011/2700 (epoch 37.241), train_loss = 1.88060223, grad/param norm = 5.2392e-01, time/batch = 0.2418s	
2012/2700 (epoch 37.259), train_loss = 1.93085772, grad/param norm = 6.7446e-01, time/batch = 0.2522s	
2013/2700 (epoch 37.278), train_loss = 2.03337639, grad/param norm = 7.9480e-01, time/batch = 0.2482s	
2014/2700 (epoch 37.296), train_loss = 2.03995309, grad/param norm = 8.1570e-01, time/batch = 0.2353s	
2015/2700 (epoch 37.315), train_loss = 2.04815318, grad/param norm = 7.6900e-01, time/batch = 0.2304s	
2016/2700 (epoch 37.333), train_loss = 2.00622816, grad/param norm = 6.0725e-01, time/batch = 0.2177s	
2017/2700 (epoch 37.352), train_loss = 2.03106677, grad/param norm = 5.3253e-01, time/batch = 0.2032s	
2018/2700 (epoch 37.370), train_loss = 2.03625937, grad/param norm = 5.9629e-01, time/batch = 0.2005s	
2019/2700 (epoch 37.389), train_loss = 2.00190281, grad/param norm = 6.6338e-01, time/batch = 0.2152s	
2020/2700 (epoch 37.407), train_loss = 2.00950613, grad/param norm = 6.7526e-01, time/batch = 0.2239s	
2021/2700 (epoch 37.426), train_loss = 2.04338153, grad/param norm = 6.7510e-01, time/batch = 0.2199s	
2022/2700 (epoch 37.444), train_loss = 1.94902522, grad/param norm = 7.9476e-01, time/batch = 0.2385s	
2023/2700 (epoch 37.463), train_loss = 2.03218225, grad/param norm = 9.5892e-01, time/batch = 0.2502s	
2024/2700 (epoch 37.481), train_loss = 2.06753948, grad/param norm = 9.0340e-01, time/batch = 0.2449s	
2025/2700 (epoch 37.500), train_loss = 2.01521477, grad/param norm = 7.5814e-01, time/batch = 0.2550s	
2026/2700 (epoch 37.519), train_loss = 1.99259565, grad/param norm = 6.5663e-01, time/batch = 0.2549s	
2027/2700 (epoch 37.537), train_loss = 2.00934927, grad/param norm = 5.9117e-01, time/batch = 0.2464s	
2028/2700 (epoch 37.556), train_loss = 1.95989325, grad/param norm = 5.7478e-01, time/batch = 0.2242s	
2029/2700 (epoch 37.574), train_loss = 1.96879338, grad/param norm = 6.2885e-01, time/batch = 0.2167s	
2030/2700 (epoch 37.593), train_loss = 1.96862711, grad/param norm = 7.0971e-01, time/batch = 0.1921s	
2031/2700 (epoch 37.611), train_loss = 1.88536775, grad/param norm = 6.9902e-01, time/batch = 0.2313s	
2032/2700 (epoch 37.630), train_loss = 1.94277182, grad/param norm = 7.1390e-01, time/batch = 0.2121s	
2033/2700 (epoch 37.648), train_loss = 1.96233079, grad/param norm = 6.0154e-01, time/batch = 0.2244s	
2034/2700 (epoch 37.667), train_loss = 1.92614546, grad/param norm = 5.5803e-01, time/batch = 0.2282s	
2035/2700 (epoch 37.685), train_loss = 1.95503937, grad/param norm = 6.7592e-01, time/batch = 0.2317s	
2036/2700 (epoch 37.704), train_loss = 1.97394219, grad/param norm = 7.4009e-01, time/batch = 0.2335s	
2037/2700 (epoch 37.722), train_loss = 1.93959543, grad/param norm = 7.3043e-01, time/batch = 0.2232s	
2038/2700 (epoch 37.741), train_loss = 2.01953278, grad/param norm = 7.3908e-01, time/batch = 0.1894s	
2039/2700 (epoch 37.759), train_loss = 2.01492041, grad/param norm = 7.8036e-01, time/batch = 0.1982s	
2040/2700 (epoch 37.778), train_loss = 2.03430132, grad/param norm = 7.0930e-01, time/batch = 0.1926s	
2041/2700 (epoch 37.796), train_loss = 1.97942700, grad/param norm = 6.4850e-01, time/batch = 0.1775s	
2042/2700 (epoch 37.815), train_loss = 2.00441211, grad/param norm = 5.9399e-01, time/batch = 0.1922s	
2043/2700 (epoch 37.833), train_loss = 1.96470137, grad/param norm = 6.1432e-01, time/batch = 0.2183s	
2044/2700 (epoch 37.852), train_loss = 1.97814113, grad/param norm = 6.3693e-01, time/batch = 0.2351s	
2045/2700 (epoch 37.870), train_loss = 1.96647999, grad/param norm = 6.2054e-01, time/batch = 0.2393s	
2046/2700 (epoch 37.889), train_loss = 1.98205652, grad/param norm = 6.1944e-01, time/batch = 0.2496s	
2047/2700 (epoch 37.907), train_loss = 2.08854257, grad/param norm = 6.4351e-01, time/batch = 0.2520s	
2048/2700 (epoch 37.926), train_loss = 2.01047595, grad/param norm = 6.6645e-01, time/batch = 0.2432s	
2049/2700 (epoch 37.944), train_loss = 1.99834759, grad/param norm = 6.5672e-01, time/batch = 0.2505s	
2050/2700 (epoch 37.963), train_loss = 2.03017136, grad/param norm = 6.0433e-01, time/batch = 0.2214s	
2051/2700 (epoch 37.981), train_loss = 2.01539669, grad/param norm = 6.2063e-01, time/batch = 0.2508s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2052/2700 (epoch 38.000), train_loss = 2.03477947, grad/param norm = 5.8252e-01, time/batch = 0.2334s	
2053/2700 (epoch 38.019), train_loss = 2.02100899, grad/param norm = 6.5051e-01, time/batch = 0.2212s	
2054/2700 (epoch 38.037), train_loss = 2.02406060, grad/param norm = 5.7412e-01, time/batch = 0.2197s	
2055/2700 (epoch 38.056), train_loss = 1.96272144, grad/param norm = 5.7154e-01, time/batch = 0.2245s	
2056/2700 (epoch 38.074), train_loss = 1.93669492, grad/param norm = 5.6589e-01, time/batch = 0.2382s	
2057/2700 (epoch 38.093), train_loss = 1.96926442, grad/param norm = 6.1249e-01, time/batch = 0.2412s	
2058/2700 (epoch 38.111), train_loss = 1.92581477, grad/param norm = 6.0328e-01, time/batch = 0.2302s	
2059/2700 (epoch 38.130), train_loss = 1.95827693, grad/param norm = 4.8257e-01, time/batch = 0.2281s	
2060/2700 (epoch 38.148), train_loss = 1.91398685, grad/param norm = 5.7374e-01, time/batch = 0.2255s	
2061/2700 (epoch 38.167), train_loss = 1.97934837, grad/param norm = 6.0629e-01, time/batch = 0.2543s	
2062/2700 (epoch 38.185), train_loss = 1.91887846, grad/param norm = 6.9022e-01, time/batch = 0.2430s	
2063/2700 (epoch 38.204), train_loss = 1.97222319, grad/param norm = 9.3795e-01, time/batch = 0.2320s	
2064/2700 (epoch 38.222), train_loss = 1.91679865, grad/param norm = 9.4478e-01, time/batch = 0.2113s	
2065/2700 (epoch 38.241), train_loss = 1.85106700, grad/param norm = 8.1291e-01, time/batch = 0.1907s	
2066/2700 (epoch 38.259), train_loss = 1.88575564, grad/param norm = 6.3454e-01, time/batch = 0.2008s	
2067/2700 (epoch 38.278), train_loss = 1.97342772, grad/param norm = 5.8458e-01, time/batch = 0.2455s	
2068/2700 (epoch 38.296), train_loss = 1.96506911, grad/param norm = 5.7132e-01, time/batch = 0.2429s	
2069/2700 (epoch 38.315), train_loss = 1.98494587, grad/param norm = 6.0287e-01, time/batch = 0.2521s	
2070/2700 (epoch 38.333), train_loss = 1.95674889, grad/param norm = 5.7170e-01, time/batch = 0.2529s	
2071/2700 (epoch 38.352), train_loss = 1.99121354, grad/param norm = 6.0777e-01, time/batch = 0.2342s	
2072/2700 (epoch 38.370), train_loss = 2.00296097, grad/param norm = 7.0203e-01, time/batch = 0.2486s	
2073/2700 (epoch 38.389), train_loss = 1.96636488, grad/param norm = 7.1074e-01, time/batch = 0.2503s	
2074/2700 (epoch 38.407), train_loss = 1.95949905, grad/param norm = 6.1880e-01, time/batch = 0.2496s	
2075/2700 (epoch 38.426), train_loss = 1.99272229, grad/param norm = 6.1915e-01, time/batch = 0.2484s	
2076/2700 (epoch 38.444), train_loss = 1.89393883, grad/param norm = 5.1925e-01, time/batch = 0.2211s	
2077/2700 (epoch 38.463), train_loss = 1.95683028, grad/param norm = 4.8506e-01, time/batch = 0.2150s	
2078/2700 (epoch 38.481), train_loss = 1.99644152, grad/param norm = 5.4045e-01, time/batch = 0.2229s	
2079/2700 (epoch 38.500), train_loss = 1.95059539, grad/param norm = 5.2855e-01, time/batch = 0.2360s	
2080/2700 (epoch 38.519), train_loss = 1.94332630, grad/param norm = 5.7793e-01, time/batch = 0.2488s	
2081/2700 (epoch 38.537), train_loss = 1.97039174, grad/param norm = 6.0941e-01, time/batch = 0.2395s	
2082/2700 (epoch 38.556), train_loss = 1.91368120, grad/param norm = 5.2701e-01, time/batch = 0.2446s	
2083/2700 (epoch 38.574), train_loss = 1.92061068, grad/param norm = 6.0071e-01, time/batch = 0.2545s	
2084/2700 (epoch 38.593), train_loss = 1.92560351, grad/param norm = 7.7042e-01, time/batch = 0.2577s	
2085/2700 (epoch 38.611), train_loss = 1.84377574, grad/param norm = 8.3003e-01, time/batch = 0.2546s	
2086/2700 (epoch 38.630), train_loss = 1.90984625, grad/param norm = 8.8866e-01, time/batch = 0.2491s	
2087/2700 (epoch 38.648), train_loss = 1.93328893, grad/param norm = 8.1772e-01, time/batch = 0.2385s	
2088/2700 (epoch 38.667), train_loss = 1.90379192, grad/param norm = 8.2030e-01, time/batch = 0.2304s	
2089/2700 (epoch 38.685), train_loss = 1.92968094, grad/param norm = 8.7165e-01, time/batch = 0.2143s	
2090/2700 (epoch 38.704), train_loss = 1.93281388, grad/param norm = 7.7063e-01, time/batch = 0.1973s	
2091/2700 (epoch 38.722), train_loss = 1.88729829, grad/param norm = 6.2038e-01, time/batch = 0.2227s	
2092/2700 (epoch 38.741), train_loss = 1.95734555, grad/param norm = 5.5352e-01, time/batch = 0.2122s	
2093/2700 (epoch 38.759), train_loss = 1.95166037, grad/param norm = 5.4906e-01, time/batch = 0.2050s	
2094/2700 (epoch 38.778), train_loss = 1.97446483, grad/param norm = 4.9233e-01, time/batch = 0.2384s	
2095/2700 (epoch 38.796), train_loss = 1.92188865, grad/param norm = 5.1044e-01, time/batch = 0.2328s	
2096/2700 (epoch 38.815), train_loss = 1.95249225, grad/param norm = 4.9804e-01, time/batch = 0.2304s	
2097/2700 (epoch 38.833), train_loss = 1.91367607, grad/param norm = 5.2889e-01, time/batch = 0.2141s	
2098/2700 (epoch 38.852), train_loss = 1.92275329, grad/param norm = 5.0390e-01, time/batch = 0.2370s	
2099/2700 (epoch 38.870), train_loss = 1.91159911, grad/param norm = 4.7632e-01, time/batch = 0.2189s	
2100/2700 (epoch 38.889), train_loss = 1.92874526, grad/param norm = 4.9028e-01, time/batch = 0.2040s	
2101/2700 (epoch 38.907), train_loss = 2.03853737, grad/param norm = 5.9715e-01, time/batch = 0.2217s	
2102/2700 (epoch 38.926), train_loss = 1.96221868, grad/param norm = 6.4018e-01, time/batch = 0.2186s	
2103/2700 (epoch 38.944), train_loss = 1.94550060, grad/param norm = 6.2429e-01, time/batch = 0.2298s	
2104/2700 (epoch 38.963), train_loss = 1.98745749, grad/param norm = 6.6896e-01, time/batch = 0.2334s	
2105/2700 (epoch 38.981), train_loss = 1.98529457, grad/param norm = 9.4802e-01, time/batch = 0.2524s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2106/2700 (epoch 39.000), train_loss = 2.02326806, grad/param norm = 7.5993e-01, time/batch = 0.2527s	
2107/2700 (epoch 39.019), train_loss = 1.98855250, grad/param norm = 7.1753e-01, time/batch = 0.2541s	
2108/2700 (epoch 39.037), train_loss = 1.99014496, grad/param norm = 6.4240e-01, time/batch = 0.2446s	
2109/2700 (epoch 39.056), train_loss = 1.93233714, grad/param norm = 7.4118e-01, time/batch = 0.2344s	
2110/2700 (epoch 39.074), train_loss = 1.92514977, grad/param norm = 7.6650e-01, time/batch = 0.2113s	
2111/2700 (epoch 39.093), train_loss = 1.93902339, grad/param norm = 7.1024e-01, time/batch = 0.2536s	
2112/2700 (epoch 39.111), train_loss = 1.88682001, grad/param norm = 6.0139e-01, time/batch = 0.2490s	
2113/2700 (epoch 39.130), train_loss = 1.91585265, grad/param norm = 4.7528e-01, time/batch = 0.2369s	
2114/2700 (epoch 39.148), train_loss = 1.86699913, grad/param norm = 5.4585e-01, time/batch = 0.2208s	
2115/2700 (epoch 39.167), train_loss = 1.93524960, grad/param norm = 6.1572e-01, time/batch = 0.2040s	
2116/2700 (epoch 39.185), train_loss = 1.87396006, grad/param norm = 6.6797e-01, time/batch = 0.2498s	
2117/2700 (epoch 39.204), train_loss = 1.90756487, grad/param norm = 5.8447e-01, time/batch = 0.2467s	
2118/2700 (epoch 39.222), train_loss = 1.84903558, grad/param norm = 6.3269e-01, time/batch = 0.2142s	
2119/2700 (epoch 39.241), train_loss = 1.78985814, grad/param norm = 5.1537e-01, time/batch = 0.2426s	
2120/2700 (epoch 39.259), train_loss = 1.83327198, grad/param norm = 5.5308e-01, time/batch = 0.2354s	
2121/2700 (epoch 39.278), train_loss = 1.92974734, grad/param norm = 6.1301e-01, time/batch = 0.2370s	
2122/2700 (epoch 39.296), train_loss = 1.92117392, grad/param norm = 5.8894e-01, time/batch = 0.2410s	
2123/2700 (epoch 39.315), train_loss = 1.93876836, grad/param norm = 6.0004e-01, time/batch = 0.2320s	
2124/2700 (epoch 39.333), train_loss = 1.90095708, grad/param norm = 5.1697e-01, time/batch = 0.2221s	
2125/2700 (epoch 39.352), train_loss = 1.93685922, grad/param norm = 5.3914e-01, time/batch = 0.2184s	
2126/2700 (epoch 39.370), train_loss = 1.95331201, grad/param norm = 6.5432e-01, time/batch = 0.2254s	
2127/2700 (epoch 39.389), train_loss = 1.92815436, grad/param norm = 7.1205e-01, time/batch = 0.2520s	
2128/2700 (epoch 39.407), train_loss = 1.92563089, grad/param norm = 6.6055e-01, time/batch = 0.2432s	
2129/2700 (epoch 39.426), train_loss = 1.96276619, grad/param norm = 6.4390e-01, time/batch = 0.2322s	
2130/2700 (epoch 39.444), train_loss = 1.85888697, grad/param norm = 6.5662e-01, time/batch = 0.2304s	
2131/2700 (epoch 39.463), train_loss = 1.92654332, grad/param norm = 6.6985e-01, time/batch = 0.2536s	
2132/2700 (epoch 39.481), train_loss = 1.95465903, grad/param norm = 6.6062e-01, time/batch = 0.2528s	
2133/2700 (epoch 39.500), train_loss = 1.91045924, grad/param norm = 6.2524e-01, time/batch = 0.2533s	
2134/2700 (epoch 39.519), train_loss = 1.90313448, grad/param norm = 6.1873e-01, time/batch = 0.2532s	
2135/2700 (epoch 39.537), train_loss = 1.93249728, grad/param norm = 6.1143e-01, time/batch = 0.2550s	
2136/2700 (epoch 39.556), train_loss = 1.87084327, grad/param norm = 5.7323e-01, time/batch = 0.2541s	
2137/2700 (epoch 39.574), train_loss = 1.87962131, grad/param norm = 5.9070e-01, time/batch = 0.2225s	
2138/2700 (epoch 39.593), train_loss = 1.87518102, grad/param norm = 6.8190e-01, time/batch = 0.2110s	
2139/2700 (epoch 39.611), train_loss = 1.80449550, grad/param norm = 7.1624e-01, time/batch = 0.2118s	
2140/2700 (epoch 39.630), train_loss = 1.86742661, grad/param norm = 8.0439e-01, time/batch = 0.2146s	
2141/2700 (epoch 39.648), train_loss = 1.88888784, grad/param norm = 6.5755e-01, time/batch = 0.2366s	
2142/2700 (epoch 39.667), train_loss = 1.84575791, grad/param norm = 5.2402e-01, time/batch = 0.2451s	
2143/2700 (epoch 39.685), train_loss = 1.86238546, grad/param norm = 5.2820e-01, time/batch = 0.2386s	
2144/2700 (epoch 39.704), train_loss = 1.87920965, grad/param norm = 5.5037e-01, time/batch = 0.2346s	
2145/2700 (epoch 39.722), train_loss = 1.84167238, grad/param norm = 4.8159e-01, time/batch = 0.2286s	
2146/2700 (epoch 39.741), train_loss = 1.90588830, grad/param norm = 4.8562e-01, time/batch = 0.2217s	
2147/2700 (epoch 39.759), train_loss = 1.91141771, grad/param norm = 5.5785e-01, time/batch = 0.2208s	
2148/2700 (epoch 39.778), train_loss = 1.94309206, grad/param norm = 5.4731e-01, time/batch = 0.2061s	
2149/2700 (epoch 39.796), train_loss = 1.88832776, grad/param norm = 5.5638e-01, time/batch = 0.1707s	
2150/2700 (epoch 39.815), train_loss = 1.91458173, grad/param norm = 5.1391e-01, time/batch = 0.2000s	
2151/2700 (epoch 39.833), train_loss = 1.87102811, grad/param norm = 5.1648e-01, time/batch = 0.2096s	
2152/2700 (epoch 39.852), train_loss = 1.88004286, grad/param norm = 5.0584e-01, time/batch = 0.2220s	
2153/2700 (epoch 39.870), train_loss = 1.87353923, grad/param norm = 5.2325e-01, time/batch = 0.2347s	
2154/2700 (epoch 39.889), train_loss = 1.89475259, grad/param norm = 5.4920e-01, time/batch = 0.2323s	
2155/2700 (epoch 39.907), train_loss = 2.00201898, grad/param norm = 6.3980e-01, time/batch = 0.2311s	
2156/2700 (epoch 39.926), train_loss = 1.92169600, grad/param norm = 6.8077e-01, time/batch = 0.2304s	
2157/2700 (epoch 39.944), train_loss = 1.90573755, grad/param norm = 6.9602e-01, time/batch = 0.2244s	
2158/2700 (epoch 39.963), train_loss = 1.95037966, grad/param norm = 7.3910e-01, time/batch = 0.2220s	
2159/2700 (epoch 39.981), train_loss = 1.94239396, grad/param norm = 8.0444e-01, time/batch = 0.1968s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2160/2700 (epoch 40.000), train_loss = 1.96573358, grad/param norm = 6.7497e-01, time/batch = 0.1869s	
2161/2700 (epoch 40.019), train_loss = 1.94640147, grad/param norm = 7.0024e-01, time/batch = 0.2020s	
2162/2700 (epoch 40.037), train_loss = 1.95966359, grad/param norm = 7.4672e-01, time/batch = 0.1983s	
2163/2700 (epoch 40.056), train_loss = 1.89621648, grad/param norm = 8.4028e-01, time/batch = 0.2185s	
2164/2700 (epoch 40.074), train_loss = 1.87875406, grad/param norm = 7.0817e-01, time/batch = 0.2384s	
2165/2700 (epoch 40.093), train_loss = 1.88684765, grad/param norm = 6.1915e-01, time/batch = 0.2522s	
2166/2700 (epoch 40.111), train_loss = 1.83707587, grad/param norm = 5.5741e-01, time/batch = 0.2531s	
2167/2700 (epoch 40.130), train_loss = 1.87579581, grad/param norm = 5.0718e-01, time/batch = 0.2522s	
2168/2700 (epoch 40.148), train_loss = 1.82554378, grad/param norm = 5.6896e-01, time/batch = 0.2549s	
2169/2700 (epoch 40.167), train_loss = 1.89739956, grad/param norm = 6.2624e-01, time/batch = 0.2420s	
2170/2700 (epoch 40.185), train_loss = 1.83358408, grad/param norm = 6.4392e-01, time/batch = 0.2233s	
2171/2700 (epoch 40.204), train_loss = 1.86511804, grad/param norm = 5.0952e-01, time/batch = 0.2530s	
2172/2700 (epoch 40.222), train_loss = 1.80787869, grad/param norm = 5.4095e-01, time/batch = 0.2533s	
2173/2700 (epoch 40.241), train_loss = 1.74689857, grad/param norm = 4.6773e-01, time/batch = 0.2411s	
2174/2700 (epoch 40.259), train_loss = 1.79360384, grad/param norm = 5.0925e-01, time/batch = 0.2247s	
2175/2700 (epoch 40.278), train_loss = 1.89180459, grad/param norm = 5.7898e-01, time/batch = 0.2181s	
2176/2700 (epoch 40.296), train_loss = 1.88690709, grad/param norm = 5.9354e-01, time/batch = 0.2310s	
2177/2700 (epoch 40.315), train_loss = 1.90319503, grad/param norm = 6.2227e-01, time/batch = 0.2450s	
2178/2700 (epoch 40.333), train_loss = 1.86033009, grad/param norm = 5.0682e-01, time/batch = 0.2531s	
2179/2700 (epoch 40.352), train_loss = 1.88905672, grad/param norm = 4.3617e-01, time/batch = 0.2510s	
2180/2700 (epoch 40.370), train_loss = 1.89411773, grad/param norm = 4.6050e-01, time/batch = 0.2307s	
2181/2700 (epoch 40.389), train_loss = 1.86982601, grad/param norm = 5.2409e-01, time/batch = 0.2383s	
2182/2700 (epoch 40.407), train_loss = 1.87555721, grad/param norm = 5.3539e-01, time/batch = 0.2455s	
2183/2700 (epoch 40.426), train_loss = 1.91598023, grad/param norm = 6.1716e-01, time/batch = 0.2411s	
2184/2700 (epoch 40.444), train_loss = 1.82053475, grad/param norm = 5.7384e-01, time/batch = 0.2221s	
2185/2700 (epoch 40.463), train_loss = 1.88738989, grad/param norm = 5.6434e-01, time/batch = 0.2021s	
2186/2700 (epoch 40.481), train_loss = 1.91217092, grad/param norm = 5.1432e-01, time/batch = 0.2144s	
2187/2700 (epoch 40.500), train_loss = 1.87126735, grad/param norm = 5.4084e-01, time/batch = 0.2235s	
2188/2700 (epoch 40.519), train_loss = 1.87529740, grad/param norm = 7.0490e-01, time/batch = 0.2292s	
2189/2700 (epoch 40.537), train_loss = 1.91595123, grad/param norm = 7.8937e-01, time/batch = 0.2297s	
2190/2700 (epoch 40.556), train_loss = 1.85742888, grad/param norm = 7.6116e-01, time/batch = 0.2391s	
2191/2700 (epoch 40.574), train_loss = 1.86611987, grad/param norm = 8.4639e-01, time/batch = 0.2011s	
2192/2700 (epoch 40.593), train_loss = 1.86181980, grad/param norm = 9.0918e-01, time/batch = 0.2436s	
2193/2700 (epoch 40.611), train_loss = 1.76451883, grad/param norm = 7.5080e-01, time/batch = 0.2355s	
2194/2700 (epoch 40.630), train_loss = 1.80577613, grad/param norm = 5.9784e-01, time/batch = 0.2152s	
2195/2700 (epoch 40.648), train_loss = 1.83159015, grad/param norm = 5.1304e-01, time/batch = 0.2246s	
2196/2700 (epoch 40.667), train_loss = 1.79857834, grad/param norm = 4.4043e-01, time/batch = 0.2404s	
2197/2700 (epoch 40.685), train_loss = 1.81948830, grad/param norm = 4.8101e-01, time/batch = 0.2534s	
2198/2700 (epoch 40.704), train_loss = 1.83805167, grad/param norm = 4.9447e-01, time/batch = 0.2537s	
2199/2700 (epoch 40.722), train_loss = 1.80334610, grad/param norm = 4.3759e-01, time/batch = 0.2508s	
2200/2700 (epoch 40.741), train_loss = 1.86443537, grad/param norm = 4.3801e-01, time/batch = 0.2543s	
2201/2700 (epoch 40.759), train_loss = 1.87055313, grad/param norm = 4.9839e-01, time/batch = 0.2350s	
2202/2700 (epoch 40.778), train_loss = 1.90414182, grad/param norm = 5.1888e-01, time/batch = 0.2357s	
2203/2700 (epoch 40.796), train_loss = 1.85398226, grad/param norm = 5.6669e-01, time/batch = 0.2482s	
2204/2700 (epoch 40.815), train_loss = 1.88061351, grad/param norm = 5.4962e-01, time/batch = 0.2330s	
2205/2700 (epoch 40.833), train_loss = 1.83709669, grad/param norm = 5.5223e-01, time/batch = 0.2218s	
2206/2700 (epoch 40.852), train_loss = 1.84282137, grad/param norm = 5.3444e-01, time/batch = 0.2014s	
2207/2700 (epoch 40.870), train_loss = 1.83971000, grad/param norm = 5.6545e-01, time/batch = 0.1966s	
2208/2700 (epoch 40.889), train_loss = 1.86592677, grad/param norm = 7.1613e-01, time/batch = 0.2153s	
2209/2700 (epoch 40.907), train_loss = 1.99569061, grad/param norm = 9.3814e-01, time/batch = 0.2228s	
2210/2700 (epoch 40.926), train_loss = 1.92329293, grad/param norm = 1.0558e+00, time/batch = 0.2399s	
2211/2700 (epoch 40.944), train_loss = 1.90948538, grad/param norm = 8.9934e-01, time/batch = 0.2263s	
2212/2700 (epoch 40.963), train_loss = 1.92364526, grad/param norm = 7.3753e-01, time/batch = 0.2301s	
2213/2700 (epoch 40.981), train_loss = 1.89932082, grad/param norm = 6.5165e-01, time/batch = 0.2090s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2214/2700 (epoch 41.000), train_loss = 1.92250271, grad/param norm = 6.4856e-01, time/batch = 0.2150s	
2215/2700 (epoch 41.019), train_loss = 1.90813020, grad/param norm = 6.2686e-01, time/batch = 0.2296s	
2216/2700 (epoch 41.037), train_loss = 1.91407943, grad/param norm = 5.4998e-01, time/batch = 0.2106s	
2217/2700 (epoch 41.056), train_loss = 1.83315691, grad/param norm = 5.5219e-01, time/batch = 0.1894s	
2218/2700 (epoch 41.074), train_loss = 1.82004545, grad/param norm = 4.7807e-01, time/batch = 0.2031s	
2219/2700 (epoch 41.093), train_loss = 1.84000749, grad/param norm = 5.0835e-01, time/batch = 0.2264s	
2220/2700 (epoch 41.111), train_loss = 1.79509845, grad/param norm = 5.0554e-01, time/batch = 0.2307s	
2221/2700 (epoch 41.130), train_loss = 1.84065410, grad/param norm = 4.8713e-01, time/batch = 0.2302s	
2222/2700 (epoch 41.148), train_loss = 1.79047987, grad/param norm = 5.6929e-01, time/batch = 0.2408s	
2223/2700 (epoch 41.167), train_loss = 1.86056525, grad/param norm = 5.4537e-01, time/batch = 0.2423s	
2224/2700 (epoch 41.185), train_loss = 1.79088041, grad/param norm = 4.8116e-01, time/batch = 0.2392s	
2225/2700 (epoch 41.204), train_loss = 1.82765697, grad/param norm = 4.6690e-01, time/batch = 0.2337s	
2226/2700 (epoch 41.222), train_loss = 1.77383844, grad/param norm = 5.0304e-01, time/batch = 0.2291s	
2227/2700 (epoch 41.241), train_loss = 1.70775466, grad/param norm = 4.5363e-01, time/batch = 0.2151s	
2228/2700 (epoch 41.259), train_loss = 1.75815745, grad/param norm = 4.8740e-01, time/batch = 0.2108s	
2229/2700 (epoch 41.278), train_loss = 1.85671322, grad/param norm = 5.7381e-01, time/batch = 0.2264s	
2230/2700 (epoch 41.296), train_loss = 1.85239187, grad/param norm = 6.1879e-01, time/batch = 0.2234s	
2231/2700 (epoch 41.315), train_loss = 1.87029454, grad/param norm = 6.4747e-01, time/batch = 0.2259s	
2232/2700 (epoch 41.333), train_loss = 1.82547370, grad/param norm = 5.0761e-01, time/batch = 0.2365s	
2233/2700 (epoch 41.352), train_loss = 1.85198194, grad/param norm = 4.4365e-01, time/batch = 0.2417s	
2234/2700 (epoch 41.370), train_loss = 1.85714665, grad/param norm = 4.7627e-01, time/batch = 0.2375s	
2235/2700 (epoch 41.389), train_loss = 1.83584295, grad/param norm = 5.2442e-01, time/batch = 0.2209s	
2236/2700 (epoch 41.407), train_loss = 1.83848349, grad/param norm = 4.8202e-01, time/batch = 0.2037s	
2237/2700 (epoch 41.426), train_loss = 1.87730455, grad/param norm = 5.3748e-01, time/batch = 0.2284s	
2238/2700 (epoch 41.444), train_loss = 1.77815576, grad/param norm = 4.9507e-01, time/batch = 0.2168s	
2239/2700 (epoch 41.463), train_loss = 1.84823659, grad/param norm = 4.9469e-01, time/batch = 0.1977s	
2240/2700 (epoch 41.481), train_loss = 1.87227139, grad/param norm = 4.8565e-01, time/batch = 0.2019s	
2241/2700 (epoch 41.500), train_loss = 1.82989058, grad/param norm = 5.1817e-01, time/batch = 0.2088s	
2242/2700 (epoch 41.519), train_loss = 1.84687022, grad/param norm = 6.4726e-01, time/batch = 0.2195s	
2243/2700 (epoch 41.537), train_loss = 1.88814595, grad/param norm = 8.4552e-01, time/batch = 0.2288s	
2244/2700 (epoch 41.556), train_loss = 1.83172958, grad/param norm = 7.2749e-01, time/batch = 0.2290s	
2245/2700 (epoch 41.574), train_loss = 1.82941305, grad/param norm = 7.3070e-01, time/batch = 0.2328s	
2246/2700 (epoch 41.593), train_loss = 1.81482814, grad/param norm = 7.4589e-01, time/batch = 0.2207s	
2247/2700 (epoch 41.611), train_loss = 1.72188327, grad/param norm = 6.3808e-01, time/batch = 0.2048s	
2248/2700 (epoch 41.630), train_loss = 1.76476738, grad/param norm = 5.7895e-01, time/batch = 0.1812s	
2249/2700 (epoch 41.648), train_loss = 1.79608014, grad/param norm = 5.3213e-01, time/batch = 0.1912s	
2250/2700 (epoch 41.667), train_loss = 1.77117512, grad/param norm = 5.9499e-01, time/batch = 0.2013s	
2251/2700 (epoch 41.685), train_loss = 1.80637660, grad/param norm = 7.7053e-01, time/batch = 0.2210s	
2252/2700 (epoch 41.704), train_loss = 1.82559756, grad/param norm = 7.5177e-01, time/batch = 0.2308s	
2253/2700 (epoch 41.722), train_loss = 1.78921972, grad/param norm = 6.8740e-01, time/batch = 0.2269s	
2254/2700 (epoch 41.741), train_loss = 1.84458860, grad/param norm = 6.7078e-01, time/batch = 0.2323s	
2255/2700 (epoch 41.759), train_loss = 1.83875302, grad/param norm = 6.1577e-01, time/batch = 0.2370s	
2256/2700 (epoch 41.778), train_loss = 1.87030011, grad/param norm = 5.3040e-01, time/batch = 0.2433s	
2257/2700 (epoch 41.796), train_loss = 1.81246017, grad/param norm = 5.1437e-01, time/batch = 0.2325s	
2258/2700 (epoch 41.815), train_loss = 1.84373914, grad/param norm = 4.7181e-01, time/batch = 0.2224s	
2259/2700 (epoch 41.833), train_loss = 1.80090918, grad/param norm = 5.2517e-01, time/batch = 0.2179s	
2260/2700 (epoch 41.852), train_loss = 1.80943001, grad/param norm = 5.1474e-01, time/batch = 0.2317s	
2261/2700 (epoch 41.870), train_loss = 1.80305662, grad/param norm = 4.6877e-01, time/batch = 0.2300s	
2262/2700 (epoch 41.889), train_loss = 1.82055316, grad/param norm = 4.6662e-01, time/batch = 0.2456s	
2263/2700 (epoch 41.907), train_loss = 1.93169852, grad/param norm = 5.2931e-01, time/batch = 0.2544s	
2264/2700 (epoch 41.926), train_loss = 1.84726289, grad/param norm = 6.0033e-01, time/batch = 0.2510s	
2265/2700 (epoch 41.944), train_loss = 1.83199217, grad/param norm = 5.5632e-01, time/batch = 0.2522s	
2266/2700 (epoch 41.963), train_loss = 1.86940978, grad/param norm = 5.8343e-01, time/batch = 0.2541s	
2267/2700 (epoch 41.981), train_loss = 1.86372125, grad/param norm = 6.4349e-01, time/batch = 0.2514s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2268/2700 (epoch 42.000), train_loss = 1.88880098, grad/param norm = 6.8683e-01, time/batch = 0.2280s	
2269/2700 (epoch 42.019), train_loss = 1.87737855, grad/param norm = 7.0446e-01, time/batch = 0.2203s	
2270/2700 (epoch 42.037), train_loss = 1.88043966, grad/param norm = 5.8805e-01, time/batch = 0.1989s	
2271/2700 (epoch 42.056), train_loss = 1.79773916, grad/param norm = 5.5320e-01, time/batch = 0.2560s	
2272/2700 (epoch 42.074), train_loss = 1.79473443, grad/param norm = 5.3188e-01, time/batch = 0.2520s	
2273/2700 (epoch 42.093), train_loss = 1.81032167, grad/param norm = 5.6585e-01, time/batch = 0.2352s	
2274/2700 (epoch 42.111), train_loss = 1.76329224, grad/param norm = 5.6295e-01, time/batch = 0.2168s	
2275/2700 (epoch 42.130), train_loss = 1.81611092, grad/param norm = 6.1631e-01, time/batch = 0.2147s	
2276/2700 (epoch 42.148), train_loss = 1.76618206, grad/param norm = 7.1007e-01, time/batch = 0.2230s	
2277/2700 (epoch 42.167), train_loss = 1.83855422, grad/param norm = 6.9452e-01, time/batch = 0.2323s	
2278/2700 (epoch 42.185), train_loss = 1.76516526, grad/param norm = 5.9794e-01, time/batch = 0.2135s	
2279/2700 (epoch 42.204), train_loss = 1.79739987, grad/param norm = 4.8431e-01, time/batch = 0.2407s	
2280/2700 (epoch 42.222), train_loss = 1.74883224, grad/param norm = 5.8314e-01, time/batch = 0.2490s	
2281/2700 (epoch 42.241), train_loss = 1.68063206, grad/param norm = 4.9395e-01, time/batch = 0.2129s	
2282/2700 (epoch 42.259), train_loss = 1.72437001, grad/param norm = 4.5383e-01, time/batch = 0.2187s	
2283/2700 (epoch 42.278), train_loss = 1.81963550, grad/param norm = 4.9841e-01, time/batch = 0.2156s	
2284/2700 (epoch 42.296), train_loss = 1.80915161, grad/param norm = 4.9781e-01, time/batch = 0.2304s	
2285/2700 (epoch 42.315), train_loss = 1.82561235, grad/param norm = 4.9703e-01, time/batch = 0.2158s	
2286/2700 (epoch 42.333), train_loss = 1.79045947, grad/param norm = 4.6522e-01, time/batch = 0.2279s	
2287/2700 (epoch 42.352), train_loss = 1.83234115, grad/param norm = 5.9628e-01, time/batch = 0.2381s	
2288/2700 (epoch 42.370), train_loss = 1.85579558, grad/param norm = 7.6592e-01, time/batch = 0.2398s	
2289/2700 (epoch 42.389), train_loss = 1.84186504, grad/param norm = 7.9279e-01, time/batch = 0.2477s	
2290/2700 (epoch 42.407), train_loss = 1.82598311, grad/param norm = 6.2545e-01, time/batch = 0.2283s	
2291/2700 (epoch 42.426), train_loss = 1.84906503, grad/param norm = 5.4777e-01, time/batch = 0.2389s	
2292/2700 (epoch 42.444), train_loss = 1.74263626, grad/param norm = 4.3422e-01, time/batch = 0.2416s	
2293/2700 (epoch 42.463), train_loss = 1.81447913, grad/param norm = 4.7508e-01, time/batch = 0.2341s	
2294/2700 (epoch 42.481), train_loss = 1.84101901, grad/param norm = 5.1141e-01, time/batch = 0.2308s	
2295/2700 (epoch 42.500), train_loss = 1.79179619, grad/param norm = 4.9074e-01, time/batch = 0.2120s	
2296/2700 (epoch 42.519), train_loss = 1.80195231, grad/param norm = 5.5121e-01, time/batch = 0.1979s	
2297/2700 (epoch 42.537), train_loss = 1.83165468, grad/param norm = 6.0430e-01, time/batch = 0.2132s	
2298/2700 (epoch 42.556), train_loss = 1.76488989, grad/param norm = 6.0843e-01, time/batch = 0.2299s	
2299/2700 (epoch 42.574), train_loss = 1.77755937, grad/param norm = 6.0762e-01, time/batch = 0.2260s	
2300/2700 (epoch 42.593), train_loss = 1.76654384, grad/param norm = 6.0645e-01, time/batch = 0.2526s	
2301/2700 (epoch 42.611), train_loss = 1.68481351, grad/param norm = 5.2232e-01, time/batch = 0.2262s	
2302/2700 (epoch 42.630), train_loss = 1.73967351, grad/param norm = 5.8435e-01, time/batch = 0.2438s	
2303/2700 (epoch 42.648), train_loss = 1.77301410, grad/param norm = 6.2429e-01, time/batch = 0.2427s	
2304/2700 (epoch 42.667), train_loss = 1.73808642, grad/param norm = 5.3497e-01, time/batch = 0.2481s	
2305/2700 (epoch 42.685), train_loss = 1.76162762, grad/param norm = 5.5985e-01, time/batch = 0.2313s	
2306/2700 (epoch 42.704), train_loss = 1.78907962, grad/param norm = 6.5766e-01, time/batch = 0.2178s	
2307/2700 (epoch 42.722), train_loss = 1.75805776, grad/param norm = 6.4891e-01, time/batch = 0.2206s	
2308/2700 (epoch 42.741), train_loss = 1.80604065, grad/param norm = 6.1569e-01, time/batch = 0.2360s	
2309/2700 (epoch 42.759), train_loss = 1.82189348, grad/param norm = 7.1818e-01, time/batch = 0.2442s	
2310/2700 (epoch 42.778), train_loss = 1.86471581, grad/param norm = 7.8722e-01, time/batch = 0.2516s	
2311/2700 (epoch 42.796), train_loss = 1.81067997, grad/param norm = 7.5267e-01, time/batch = 0.2404s	
2312/2700 (epoch 42.815), train_loss = 1.82450587, grad/param norm = 6.6393e-01, time/batch = 0.2469s	
2313/2700 (epoch 42.833), train_loss = 1.77773118, grad/param norm = 6.5736e-01, time/batch = 0.2476s	
2314/2700 (epoch 42.852), train_loss = 1.78222691, grad/param norm = 6.2562e-01, time/batch = 0.2541s	
2315/2700 (epoch 42.870), train_loss = 1.77791290, grad/param norm = 5.6163e-01, time/batch = 0.2553s	
2316/2700 (epoch 42.889), train_loss = 1.79549287, grad/param norm = 5.5958e-01, time/batch = 0.2543s	
2317/2700 (epoch 42.907), train_loss = 1.90650900, grad/param norm = 6.3351e-01, time/batch = 0.2504s	
2318/2700 (epoch 42.926), train_loss = 1.81826091, grad/param norm = 6.6925e-01, time/batch = 0.2342s	
2319/2700 (epoch 42.944), train_loss = 1.80409215, grad/param norm = 6.1232e-01, time/batch = 0.2195s	
2320/2700 (epoch 42.963), train_loss = 1.83899179, grad/param norm = 5.9635e-01, time/batch = 0.2041s	
2321/2700 (epoch 42.981), train_loss = 1.82169693, grad/param norm = 5.7204e-01, time/batch = 0.2127s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
2322/2700 (epoch 43.000), train_loss = 1.84787771, grad/param norm = 5.6667e-01, time/batch = 0.2213s	
2323/2700 (epoch 43.019), train_loss = 1.83760771, grad/param norm = 5.7317e-01, time/batch = 0.2196s	
2324/2700 (epoch 43.037), train_loss = 1.84365544, grad/param norm = 4.9561e-01, time/batch = 0.2268s	
2325/2700 (epoch 43.056), train_loss = 1.76398345, grad/param norm = 5.5878e-01, time/batch = 0.2222s	
2326/2700 (epoch 43.074), train_loss = 1.76167621, grad/param norm = 5.0694e-01, time/batch = 0.2209s	
2327/2700 (epoch 43.093), train_loss = 1.77269389, grad/param norm = 5.1203e-01, time/batch = 0.2118s	
2328/2700 (epoch 43.111), train_loss = 1.72818555, grad/param norm = 5.0053e-01, time/batch = 0.1969s	
2329/2700 (epoch 43.130), train_loss = 1.77852501, grad/param norm = 4.8961e-01, time/batch = 0.1964s	
2330/2700 (epoch 43.148), train_loss = 1.72348860, grad/param norm = 5.5273e-01, time/batch = 0.1944s	
2331/2700 (epoch 43.167), train_loss = 1.79343259, grad/param norm = 4.9857e-01, time/batch = 0.2234s	
2332/2700 (epoch 43.185), train_loss = 1.72642590, grad/param norm = 4.5735e-01, time/batch = 0.2338s	
2333/2700 (epoch 43.204), train_loss = 1.76831291, grad/param norm = 5.3003e-01, time/batch = 0.2360s	
2334/2700 (epoch 43.222), train_loss = 1.71978505, grad/param norm = 6.0910e-01, time/batch = 0.2082s	
2335/2700 (epoch 43.241), train_loss = 1.65093782, grad/param norm = 5.5645e-01, time/batch = 0.2529s	
2336/2700 (epoch 43.259), train_loss = 1.69762318, grad/param norm = 4.7334e-01, time/batch = 0.2527s	
2337/2700 (epoch 43.278), train_loss = 1.79061715, grad/param norm = 4.8627e-01, time/batch = 0.2468s	
2338/2700 (epoch 43.296), train_loss = 1.78012940, grad/param norm = 4.9885e-01, time/batch = 0.2299s	
2339/2700 (epoch 43.315), train_loss = 1.79522980, grad/param norm = 4.9580e-01, time/batch = 0.2127s	
2340/2700 (epoch 43.333), train_loss = 1.75586204, grad/param norm = 4.6038e-01, time/batch = 0.2074s	
2341/2700 (epoch 43.352), train_loss = 1.79201291, grad/param norm = 6.0294e-01, time/batch = 0.1952s	
2342/2700 (epoch 43.370), train_loss = 1.81607798, grad/param norm = 7.1000e-01, time/batch = 0.2091s	
2343/2700 (epoch 43.389), train_loss = 1.79409086, grad/param norm = 7.2900e-01, time/batch = 0.2220s	
2344/2700 (epoch 43.407), train_loss = 1.79301001, grad/param norm = 6.3276e-01, time/batch = 0.2293s	
2345/2700 (epoch 43.426), train_loss = 1.82044804, grad/param norm = 5.6247e-01, time/batch = 0.2239s	
2346/2700 (epoch 43.444), train_loss = 1.71213651, grad/param norm = 4.3067e-01, time/batch = 0.2339s	
2347/2700 (epoch 43.463), train_loss = 1.78838181, grad/param norm = 4.8329e-01, time/batch = 0.2219s	
2348/2700 (epoch 43.481), train_loss = 1.80741138, grad/param norm = 4.7389e-01, time/batch = 0.2147s	
2349/2700 (epoch 43.500), train_loss = 1.75626752, grad/param norm = 4.3089e-01, time/batch = 0.2277s	
2350/2700 (epoch 43.519), train_loss = 1.76883532, grad/param norm = 4.7147e-01, time/batch = 0.2435s	
2351/2700 (epoch 43.537), train_loss = 1.79781846, grad/param norm = 5.5137e-01, time/batch = 0.2271s	
2352/2700 (epoch 43.556), train_loss = 1.73075396, grad/param norm = 5.3769e-01, time/batch = 0.2473s	
2353/2700 (epoch 43.574), train_loss = 1.75033660, grad/param norm = 6.1866e-01, time/batch = 0.2543s	
2354/2700 (epoch 43.593), train_loss = 1.74623445, grad/param norm = 7.0915e-01, time/batch = 0.2497s	
2355/2700 (epoch 43.611), train_loss = 1.66545408, grad/param norm = 6.5885e-01, time/batch = 0.2558s	
2356/2700 (epoch 43.630), train_loss = 1.71384805, grad/param norm = 6.3767e-01, time/batch = 0.2437s	
2357/2700 (epoch 43.648), train_loss = 1.73840010, grad/param norm = 5.1883e-01, time/batch = 0.2451s	
2358/2700 (epoch 43.667), train_loss = 1.70361113, grad/param norm = 4.5117e-01, time/batch = 0.2273s	
2359/2700 (epoch 43.685), train_loss = 1.73392555, grad/param norm = 5.8410e-01, time/batch = 0.2191s	
2360/2700 (epoch 43.704), train_loss = 1.75844382, grad/param norm = 6.1181e-01, time/batch = 0.2246s	
2361/2700 (epoch 43.722), train_loss = 1.73069323, grad/param norm = 6.1757e-01, time/batch = 0.2152s	
2362/2700 (epoch 43.741), train_loss = 1.77840613, grad/param norm = 6.6050e-01, time/batch = 0.2162s	
2363/2700 (epoch 43.759), train_loss = 1.78295405, grad/param norm = 6.6426e-01, time/batch = 0.2223s	
2364/2700 (epoch 43.778), train_loss = 1.81749850, grad/param norm = 5.9387e-01, time/batch = 0.2236s	
2365/2700 (epoch 43.796), train_loss = 1.75833698, grad/param norm = 5.6433e-01, time/batch = 0.2254s	
2366/2700 (epoch 43.815), train_loss = 1.78668645, grad/param norm = 5.0507e-01, time/batch = 0.2246s	
2367/2700 (epoch 43.833), train_loss = 1.74240021, grad/param norm = 5.6871e-01, time/batch = 0.2201s	
2368/2700 (epoch 43.852), train_loss = 1.75356253, grad/param norm = 6.0381e-01, time/batch = 0.2218s	
2369/2700 (epoch 43.870), train_loss = 1.75311624, grad/param norm = 6.1097e-01, time/batch = 0.2081s	
2370/2700 (epoch 43.889), train_loss = 1.77464669, grad/param norm = 5.7639e-01, time/batch = 0.1954s	
2371/2700 (epoch 43.907), train_loss = 1.87066617, grad/param norm = 5.3358e-01, time/batch = 0.2117s	
2372/2700 (epoch 43.926), train_loss = 1.77909432, grad/param norm = 4.8999e-01, time/batch = 0.2038s	
2373/2700 (epoch 43.944), train_loss = 1.76337788, grad/param norm = 4.9246e-01, time/batch = 0.2272s	
2374/2700 (epoch 43.963), train_loss = 1.80470190, grad/param norm = 5.4262e-01, time/batch = 0.2354s	
2375/2700 (epoch 43.981), train_loss = 1.78974167, grad/param norm = 5.8071e-01, time/batch = 0.2183s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
2376/2700 (epoch 44.000), train_loss = 1.82571763, grad/param norm = 5.5489e-01, time/batch = 0.2508s	
2377/2700 (epoch 44.019), train_loss = 1.81117688, grad/param norm = 5.8362e-01, time/batch = 0.2540s	
2378/2700 (epoch 44.037), train_loss = 1.81985262, grad/param norm = 5.5441e-01, time/batch = 0.2307s	
2379/2700 (epoch 44.056), train_loss = 1.74207021, grad/param norm = 6.7838e-01, time/batch = 0.2308s	
2380/2700 (epoch 44.074), train_loss = 1.74621422, grad/param norm = 6.3094e-01, time/batch = 0.2057s	
2381/2700 (epoch 44.093), train_loss = 1.75241523, grad/param norm = 6.0740e-01, time/batch = 0.2123s	
2382/2700 (epoch 44.111), train_loss = 1.70378620, grad/param norm = 5.4492e-01, time/batch = 0.1935s	
2383/2700 (epoch 44.130), train_loss = 1.75127901, grad/param norm = 4.8867e-01, time/batch = 0.1833s	
2384/2700 (epoch 44.148), train_loss = 1.69690026, grad/param norm = 5.3983e-01, time/batch = 0.2048s	
2385/2700 (epoch 44.167), train_loss = 1.76545918, grad/param norm = 5.2756e-01, time/batch = 0.2222s	
2386/2700 (epoch 44.185), train_loss = 1.70808348, grad/param norm = 6.4514e-01, time/batch = 0.2467s	
2387/2700 (epoch 44.204), train_loss = 1.76021585, grad/param norm = 7.7280e-01, time/batch = 0.2466s	
2388/2700 (epoch 44.222), train_loss = 1.70409161, grad/param norm = 7.0787e-01, time/batch = 0.2505s	
2389/2700 (epoch 44.241), train_loss = 1.62674294, grad/param norm = 5.7963e-01, time/batch = 0.2417s	
2390/2700 (epoch 44.259), train_loss = 1.66861325, grad/param norm = 4.6717e-01, time/batch = 0.2362s	
2391/2700 (epoch 44.278), train_loss = 1.76160794, grad/param norm = 4.6959e-01, time/batch = 0.2211s	
2392/2700 (epoch 44.296), train_loss = 1.74728393, grad/param norm = 4.6340e-01, time/batch = 0.2222s	
2393/2700 (epoch 44.315), train_loss = 1.76130077, grad/param norm = 4.5693e-01, time/batch = 0.1964s	
2394/2700 (epoch 44.333), train_loss = 1.72930226, grad/param norm = 4.6710e-01, time/batch = 0.2269s	
2395/2700 (epoch 44.352), train_loss = 1.76472825, grad/param norm = 5.7332e-01, time/batch = 0.2284s	
2396/2700 (epoch 44.370), train_loss = 1.77913687, grad/param norm = 6.3213e-01, time/batch = 0.2428s	
2397/2700 (epoch 44.389), train_loss = 1.75644711, grad/param norm = 6.1510e-01, time/batch = 0.2288s	
2398/2700 (epoch 44.407), train_loss = 1.75934336, grad/param norm = 5.1882e-01, time/batch = 0.2290s	
2399/2700 (epoch 44.426), train_loss = 1.79273496, grad/param norm = 5.1251e-01, time/batch = 0.2340s	
2400/2700 (epoch 44.444), train_loss = 1.68597241, grad/param norm = 4.5418e-01, time/batch = 0.2300s	
2401/2700 (epoch 44.463), train_loss = 1.76193873, grad/param norm = 5.1293e-01, time/batch = 0.2391s	
2402/2700 (epoch 44.481), train_loss = 1.77763019, grad/param norm = 5.1273e-01, time/batch = 0.2345s	
2403/2700 (epoch 44.500), train_loss = 1.73279971, grad/param norm = 4.9455e-01, time/batch = 0.2157s	
2404/2700 (epoch 44.519), train_loss = 1.74820214, grad/param norm = 5.3475e-01, time/batch = 0.1845s	
2405/2700 (epoch 44.537), train_loss = 1.77362811, grad/param norm = 5.7832e-01, time/batch = 0.2077s	
2406/2700 (epoch 44.556), train_loss = 1.70134713, grad/param norm = 5.6600e-01, time/batch = 0.2305s	
2407/2700 (epoch 44.574), train_loss = 1.71703506, grad/param norm = 5.7120e-01, time/batch = 0.2453s	
2408/2700 (epoch 44.593), train_loss = 1.70767158, grad/param norm = 5.8586e-01, time/batch = 0.2514s	
2409/2700 (epoch 44.611), train_loss = 1.62403010, grad/param norm = 5.0633e-01, time/batch = 0.2453s	
2410/2700 (epoch 44.630), train_loss = 1.67890208, grad/param norm = 5.5418e-01, time/batch = 0.2459s	
2411/2700 (epoch 44.648), train_loss = 1.71240502, grad/param norm = 5.5306e-01, time/batch = 0.2451s	
2412/2700 (epoch 44.667), train_loss = 1.67817566, grad/param norm = 4.9496e-01, time/batch = 0.2507s	
2413/2700 (epoch 44.685), train_loss = 1.70792945, grad/param norm = 5.6084e-01, time/batch = 0.2513s	
2414/2700 (epoch 44.704), train_loss = 1.73132471, grad/param norm = 5.6292e-01, time/batch = 0.2462s	
2415/2700 (epoch 44.722), train_loss = 1.69320665, grad/param norm = 4.8650e-01, time/batch = 0.2457s	
2416/2700 (epoch 44.741), train_loss = 1.73040229, grad/param norm = 4.3610e-01, time/batch = 0.2356s	
2417/2700 (epoch 44.759), train_loss = 1.73916330, grad/param norm = 4.8144e-01, time/batch = 0.2190s	
2418/2700 (epoch 44.778), train_loss = 1.78725729, grad/param norm = 5.8219e-01, time/batch = 0.2214s	
2419/2700 (epoch 44.796), train_loss = 1.74065526, grad/param norm = 6.9007e-01, time/batch = 0.2358s	
2420/2700 (epoch 44.815), train_loss = 1.78054756, grad/param norm = 8.1520e-01, time/batch = 0.2514s	
2421/2700 (epoch 44.833), train_loss = 1.74240533, grad/param norm = 8.3722e-01, time/batch = 0.2377s	
2422/2700 (epoch 44.852), train_loss = 1.73143568, grad/param norm = 6.7835e-01, time/batch = 0.2446s	
2423/2700 (epoch 44.870), train_loss = 1.72396334, grad/param norm = 5.7368e-01, time/batch = 0.2554s	
2424/2700 (epoch 44.889), train_loss = 1.74609051, grad/param norm = 5.8223e-01, time/batch = 0.2537s	
2425/2700 (epoch 44.907), train_loss = 1.85581640, grad/param norm = 6.6236e-01, time/batch = 0.2284s	
2426/2700 (epoch 44.926), train_loss = 1.76164911, grad/param norm = 6.4851e-01, time/batch = 0.2266s	
2427/2700 (epoch 44.944), train_loss = 1.74483793, grad/param norm = 6.0515e-01, time/batch = 0.2265s	
2428/2700 (epoch 44.963), train_loss = 1.78500638, grad/param norm = 6.4874e-01, time/batch = 0.2134s	
2429/2700 (epoch 44.981), train_loss = 1.76547540, grad/param norm = 6.3064e-01, time/batch = 0.2054s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
2430/2700 (epoch 45.000), train_loss = 1.79874763, grad/param norm = 5.8346e-01, time/batch = 0.2215s	
2431/2700 (epoch 45.019), train_loss = 1.77981891, grad/param norm = 5.5842e-01, time/batch = 0.2177s	
2432/2700 (epoch 45.037), train_loss = 1.78518797, grad/param norm = 4.8529e-01, time/batch = 0.2416s	
2433/2700 (epoch 45.056), train_loss = 1.70592243, grad/param norm = 5.4855e-01, time/batch = 0.2383s	
2434/2700 (epoch 45.074), train_loss = 1.71139950, grad/param norm = 5.0558e-01, time/batch = 0.2492s	
2435/2700 (epoch 45.093), train_loss = 1.72029917, grad/param norm = 5.4057e-01, time/batch = 0.2430s	
2436/2700 (epoch 45.111), train_loss = 1.67488994, grad/param norm = 5.3697e-01, time/batch = 0.2247s	
2437/2700 (epoch 45.130), train_loss = 1.72686814, grad/param norm = 5.6707e-01, time/batch = 0.2137s	
2438/2700 (epoch 45.148), train_loss = 1.66867699, grad/param norm = 5.6967e-01, time/batch = 0.1940s	
2439/2700 (epoch 45.167), train_loss = 1.73763667, grad/param norm = 5.0468e-01, time/batch = 0.1961s	
2440/2700 (epoch 45.185), train_loss = 1.67448906, grad/param norm = 4.8829e-01, time/batch = 0.2100s	
2441/2700 (epoch 45.204), train_loss = 1.71085815, grad/param norm = 4.5469e-01, time/batch = 0.2157s	
2442/2700 (epoch 45.222), train_loss = 1.66314091, grad/param norm = 5.0192e-01, time/batch = 0.2350s	
2443/2700 (epoch 45.241), train_loss = 1.59423938, grad/param norm = 4.5247e-01, time/batch = 0.2281s	
2444/2700 (epoch 45.259), train_loss = 1.64600204, grad/param norm = 5.1926e-01, time/batch = 0.2129s	
2445/2700 (epoch 45.278), train_loss = 1.74653999, grad/param norm = 6.2065e-01, time/batch = 0.2185s	
2446/2700 (epoch 45.296), train_loss = 1.73749367, grad/param norm = 6.5867e-01, time/batch = 0.1526s	
2447/2700 (epoch 45.315), train_loss = 1.74827093, grad/param norm = 6.2526e-01, time/batch = 0.2225s	
2448/2700 (epoch 45.333), train_loss = 1.70279796, grad/param norm = 5.0323e-01, time/batch = 0.2186s	
2449/2700 (epoch 45.352), train_loss = 1.73352813, grad/param norm = 5.1877e-01, time/batch = 0.2360s	
2450/2700 (epoch 45.370), train_loss = 1.74582246, grad/param norm = 5.9434e-01, time/batch = 0.2519s	
2451/2700 (epoch 45.389), train_loss = 1.72956109, grad/param norm = 6.0578e-01, time/batch = 0.2390s	
2452/2700 (epoch 45.407), train_loss = 1.74370135, grad/param norm = 5.7556e-01, time/batch = 0.2494s	
2453/2700 (epoch 45.426), train_loss = 1.77714973, grad/param norm = 5.7089e-01, time/batch = 0.2530s	
2454/2700 (epoch 45.444), train_loss = 1.67487605, grad/param norm = 6.1533e-01, time/batch = 0.2537s	
2455/2700 (epoch 45.463), train_loss = 1.75291942, grad/param norm = 6.7716e-01, time/batch = 0.2430s	
2456/2700 (epoch 45.481), train_loss = 1.75497761, grad/param norm = 5.7113e-01, time/batch = 0.2415s	
2457/2700 (epoch 45.500), train_loss = 1.70665255, grad/param norm = 4.8851e-01, time/batch = 0.2376s	
2458/2700 (epoch 45.519), train_loss = 1.71762845, grad/param norm = 4.7594e-01, time/batch = 0.2238s	
2459/2700 (epoch 45.537), train_loss = 1.74280647, grad/param norm = 5.1671e-01, time/batch = 0.2047s	
2460/2700 (epoch 45.556), train_loss = 1.67290267, grad/param norm = 5.3113e-01, time/batch = 0.2007s	
2461/2700 (epoch 45.574), train_loss = 1.69237759, grad/param norm = 5.3491e-01, time/batch = 0.2112s	
2462/2700 (epoch 45.593), train_loss = 1.68019655, grad/param norm = 5.6456e-01, time/batch = 0.2194s	
2463/2700 (epoch 45.611), train_loss = 1.60340935, grad/param norm = 5.5707e-01, time/batch = 0.2289s	
2464/2700 (epoch 45.630), train_loss = 1.65575892, grad/param norm = 5.6786e-01, time/batch = 0.2290s	
2465/2700 (epoch 45.648), train_loss = 1.68763407, grad/param norm = 5.5225e-01, time/batch = 0.2365s	
2466/2700 (epoch 45.667), train_loss = 1.65587208, grad/param norm = 5.5917e-01, time/batch = 0.2248s	
2467/2700 (epoch 45.685), train_loss = 1.68996668, grad/param norm = 6.7961e-01, time/batch = 0.1969s	
2468/2700 (epoch 45.704), train_loss = 1.71065368, grad/param norm = 6.2310e-01, time/batch = 0.2170s	
2469/2700 (epoch 45.722), train_loss = 1.67509634, grad/param norm = 5.5718e-01, time/batch = 0.2035s	
2470/2700 (epoch 45.741), train_loss = 1.71129919, grad/param norm = 5.5402e-01, time/batch = 0.2210s	
2471/2700 (epoch 45.759), train_loss = 1.71327621, grad/param norm = 5.3659e-01, time/batch = 0.2298s	
2472/2700 (epoch 45.778), train_loss = 1.75500282, grad/param norm = 4.9655e-01, time/batch = 0.2427s	
2473/2700 (epoch 45.796), train_loss = 1.69777711, grad/param norm = 5.1903e-01, time/batch = 0.2508s	
2474/2700 (epoch 45.815), train_loss = 1.73175016, grad/param norm = 4.7581e-01, time/batch = 0.2490s	
2475/2700 (epoch 45.833), train_loss = 1.68150923, grad/param norm = 4.8803e-01, time/batch = 0.2458s	
2476/2700 (epoch 45.852), train_loss = 1.68663848, grad/param norm = 4.9138e-01, time/batch = 0.2480s	
2477/2700 (epoch 45.870), train_loss = 1.69035824, grad/param norm = 5.2021e-01, time/batch = 0.2191s	
2478/2700 (epoch 45.889), train_loss = 1.71532516, grad/param norm = 5.0425e-01, time/batch = 0.2036s	
2479/2700 (epoch 45.907), train_loss = 1.81478077, grad/param norm = 5.0018e-01, time/batch = 0.1802s	
2480/2700 (epoch 45.926), train_loss = 1.72451509, grad/param norm = 4.9053e-01, time/batch = 0.1802s	
2481/2700 (epoch 45.944), train_loss = 1.71276174, grad/param norm = 5.6532e-01, time/batch = 0.1768s	
2482/2700 (epoch 45.963), train_loss = 1.75879673, grad/param norm = 6.3021e-01, time/batch = 0.1985s	
2483/2700 (epoch 45.981), train_loss = 1.73524696, grad/param norm = 6.0464e-01, time/batch = 0.2109s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
2484/2700 (epoch 46.000), train_loss = 1.77258621, grad/param norm = 5.4570e-01, time/batch = 0.2189s	
2485/2700 (epoch 46.019), train_loss = 1.75607392, grad/param norm = 5.4946e-01, time/batch = 0.2276s	
2486/2700 (epoch 46.037), train_loss = 1.76200928, grad/param norm = 5.3198e-01, time/batch = 0.2335s	
2487/2700 (epoch 46.056), train_loss = 1.68920359, grad/param norm = 6.7052e-01, time/batch = 0.2316s	
2488/2700 (epoch 46.074), train_loss = 1.69696504, grad/param norm = 6.1316e-01, time/batch = 0.2430s	
2489/2700 (epoch 46.093), train_loss = 1.69517031, grad/param norm = 5.6004e-01, time/batch = 0.2217s	
2490/2700 (epoch 46.111), train_loss = 1.64600612, grad/param norm = 4.8399e-01, time/batch = 0.2230s	
2491/2700 (epoch 46.130), train_loss = 1.69618435, grad/param norm = 4.6871e-01, time/batch = 0.2055s	
2492/2700 (epoch 46.148), train_loss = 1.63846803, grad/param norm = 4.9274e-01, time/batch = 0.2220s	
2493/2700 (epoch 46.167), train_loss = 1.70995208, grad/param norm = 4.7215e-01, time/batch = 0.2427s	
2494/2700 (epoch 46.185), train_loss = 1.65001064, grad/param norm = 4.9973e-01, time/batch = 0.2454s	
2495/2700 (epoch 46.204), train_loss = 1.69180076, grad/param norm = 5.4858e-01, time/batch = 0.2468s	
2496/2700 (epoch 46.222), train_loss = 1.64523373, grad/param norm = 5.9580e-01, time/batch = 0.2421s	
2497/2700 (epoch 46.241), train_loss = 1.57551776, grad/param norm = 5.5354e-01, time/batch = 0.2334s	
2498/2700 (epoch 46.259), train_loss = 1.61986633, grad/param norm = 4.9242e-01, time/batch = 0.2365s	
2499/2700 (epoch 46.278), train_loss = 1.71315573, grad/param norm = 4.8902e-01, time/batch = 0.2106s	
2500/2700 (epoch 46.296), train_loss = 1.69726150, grad/param norm = 4.7529e-01, time/batch = 0.2145s	
2501/2700 (epoch 46.315), train_loss = 1.70686330, grad/param norm = 4.5667e-01, time/batch = 0.2239s	
2502/2700 (epoch 46.333), train_loss = 1.67792504, grad/param norm = 5.0929e-01, time/batch = 0.2172s	
2503/2700 (epoch 46.352), train_loss = 1.72158267, grad/param norm = 7.3814e-01, time/batch = 0.2247s	
2504/2700 (epoch 46.370), train_loss = 1.74396620, grad/param norm = 7.9577e-01, time/batch = 0.2412s	
2505/2700 (epoch 46.389), train_loss = 1.71583689, grad/param norm = 7.1707e-01, time/batch = 0.2540s	
2506/2700 (epoch 46.407), train_loss = 1.71748423, grad/param norm = 5.6346e-01, time/batch = 0.2537s	
2507/2700 (epoch 46.426), train_loss = 1.74693175, grad/param norm = 5.2055e-01, time/batch = 0.2499s	
2508/2700 (epoch 46.444), train_loss = 1.63653026, grad/param norm = 4.2955e-01, time/batch = 0.2539s	
2509/2700 (epoch 46.463), train_loss = 1.71371453, grad/param norm = 4.7675e-01, time/batch = 0.2455s	
2510/2700 (epoch 46.481), train_loss = 1.72232721, grad/param norm = 4.7932e-01, time/batch = 0.2541s	
2511/2700 (epoch 46.500), train_loss = 1.67735979, grad/param norm = 4.5548e-01, time/batch = 0.2118s	
2512/2700 (epoch 46.519), train_loss = 1.69796315, grad/param norm = 4.9044e-01, time/batch = 0.2134s	
2513/2700 (epoch 46.537), train_loss = 1.71693146, grad/param norm = 5.2701e-01, time/batch = 0.1993s	
2514/2700 (epoch 46.556), train_loss = 1.64582754, grad/param norm = 5.0171e-01, time/batch = 0.2521s	
2515/2700 (epoch 46.574), train_loss = 1.67030203, grad/param norm = 5.7481e-01, time/batch = 0.2507s	
2516/2700 (epoch 46.593), train_loss = 1.66055520, grad/param norm = 6.3198e-01, time/batch = 0.2507s	
2517/2700 (epoch 46.611), train_loss = 1.57501806, grad/param norm = 5.7270e-01, time/batch = 0.2446s	
2518/2700 (epoch 46.630), train_loss = 1.62464486, grad/param norm = 5.3139e-01, time/batch = 0.2530s	
2519/2700 (epoch 46.648), train_loss = 1.66134283, grad/param norm = 5.3711e-01, time/batch = 0.2438s	
2520/2700 (epoch 46.667), train_loss = 1.63557905, grad/param norm = 5.8797e-01, time/batch = 0.2113s	
2521/2700 (epoch 46.685), train_loss = 1.67050721, grad/param norm = 6.7612e-01, time/batch = 0.2535s	
2522/2700 (epoch 46.704), train_loss = 1.68680520, grad/param norm = 5.8016e-01, time/batch = 0.2505s	
2523/2700 (epoch 46.722), train_loss = 1.64770478, grad/param norm = 4.9157e-01, time/batch = 0.2338s	
2524/2700 (epoch 46.741), train_loss = 1.67931408, grad/param norm = 4.8158e-01, time/batch = 0.2056s	
2525/2700 (epoch 46.759), train_loss = 1.68429109, grad/param norm = 4.8213e-01, time/batch = 0.2509s	
2526/2700 (epoch 46.778), train_loss = 1.72797050, grad/param norm = 4.6906e-01, time/batch = 0.2469s	
2527/2700 (epoch 46.796), train_loss = 1.67154647, grad/param norm = 4.8910e-01, time/batch = 0.2367s	
2528/2700 (epoch 46.815), train_loss = 1.70612258, grad/param norm = 4.6356e-01, time/batch = 0.2385s	
2529/2700 (epoch 46.833), train_loss = 1.65801937, grad/param norm = 4.9382e-01, time/batch = 0.2350s	
2530/2700 (epoch 46.852), train_loss = 1.66081899, grad/param norm = 4.7467e-01, time/batch = 0.2090s	
2531/2700 (epoch 46.870), train_loss = 1.66364436, grad/param norm = 4.4229e-01, time/batch = 0.2488s	
2532/2700 (epoch 46.889), train_loss = 1.68779314, grad/param norm = 4.7593e-01, time/batch = 0.2512s	
2533/2700 (epoch 46.907), train_loss = 1.80011404, grad/param norm = 6.0792e-01, time/batch = 0.2517s	
2534/2700 (epoch 46.926), train_loss = 1.71316602, grad/param norm = 6.7491e-01, time/batch = 0.2505s	
2535/2700 (epoch 46.944), train_loss = 1.69731781, grad/param norm = 6.6375e-01, time/batch = 0.2199s	
2536/2700 (epoch 46.963), train_loss = 1.73601890, grad/param norm = 7.0154e-01, time/batch = 0.2227s	
2537/2700 (epoch 46.981), train_loss = 1.71670761, grad/param norm = 6.5982e-01, time/batch = 0.2239s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
2538/2700 (epoch 47.000), train_loss = 1.74752319, grad/param norm = 6.3662e-01, time/batch = 0.2483s	
2539/2700 (epoch 47.019), train_loss = 1.73727179, grad/param norm = 6.1767e-01, time/batch = 0.2522s	
2540/2700 (epoch 47.037), train_loss = 1.73718853, grad/param norm = 5.4490e-01, time/batch = 0.2441s	
2541/2700 (epoch 47.056), train_loss = 1.66258144, grad/param norm = 5.8458e-01, time/batch = 0.2466s	
2542/2700 (epoch 47.074), train_loss = 1.67195230, grad/param norm = 5.5349e-01, time/batch = 0.2520s	
2543/2700 (epoch 47.093), train_loss = 1.67387539, grad/param norm = 5.7811e-01, time/batch = 0.2531s	
2544/2700 (epoch 47.111), train_loss = 1.62880809, grad/param norm = 5.8890e-01, time/batch = 0.2544s	
2545/2700 (epoch 47.130), train_loss = 1.68518691, grad/param norm = 6.3515e-01, time/batch = 0.2452s	
2546/2700 (epoch 47.148), train_loss = 1.62029810, grad/param norm = 5.6743e-01, time/batch = 0.2324s	
2547/2700 (epoch 47.167), train_loss = 1.68761793, grad/param norm = 4.8495e-01, time/batch = 0.2123s	
2548/2700 (epoch 47.185), train_loss = 1.62528066, grad/param norm = 4.8455e-01, time/batch = 0.2210s	
2549/2700 (epoch 47.204), train_loss = 1.66452368, grad/param norm = 4.6919e-01, time/batch = 0.2386s	
2550/2700 (epoch 47.222), train_loss = 1.61609671, grad/param norm = 5.0792e-01, time/batch = 0.2526s	
2551/2700 (epoch 47.241), train_loss = 1.54768191, grad/param norm = 4.5964e-01, time/batch = 0.2340s	
2552/2700 (epoch 47.259), train_loss = 1.59553557, grad/param norm = 4.8204e-01, time/batch = 0.2453s	
2553/2700 (epoch 47.278), train_loss = 1.69303151, grad/param norm = 5.4862e-01, time/batch = 0.2450s	
2554/2700 (epoch 47.296), train_loss = 1.68013201, grad/param norm = 5.6230e-01, time/batch = 0.2426s	
2555/2700 (epoch 47.315), train_loss = 1.68560873, grad/param norm = 5.2280e-01, time/batch = 0.2385s	
2556/2700 (epoch 47.333), train_loss = 1.64916829, grad/param norm = 4.3766e-01, time/batch = 0.2231s	
2557/2700 (epoch 47.352), train_loss = 1.67966631, grad/param norm = 4.7109e-01, time/batch = 0.2097s	
2558/2700 (epoch 47.370), train_loss = 1.68947730, grad/param norm = 5.4069e-01, time/batch = 0.2004s	
2559/2700 (epoch 47.389), train_loss = 1.67104064, grad/param norm = 5.4607e-01, time/batch = 0.1887s	
2560/2700 (epoch 47.407), train_loss = 1.69302749, grad/param norm = 5.2371e-01, time/batch = 0.2102s	
2561/2700 (epoch 47.426), train_loss = 1.72824800, grad/param norm = 5.3337e-01, time/batch = 0.2015s	
2562/2700 (epoch 47.444), train_loss = 1.62805354, grad/param norm = 6.0777e-01, time/batch = 0.2330s	
2563/2700 (epoch 47.463), train_loss = 1.71024962, grad/param norm = 6.9261e-01, time/batch = 0.2327s	
2564/2700 (epoch 47.481), train_loss = 1.70376420, grad/param norm = 5.7988e-01, time/batch = 0.2297s	
2565/2700 (epoch 47.500), train_loss = 1.65672695, grad/param norm = 4.8207e-01, time/batch = 0.2286s	
2566/2700 (epoch 47.519), train_loss = 1.67274169, grad/param norm = 4.6564e-01, time/batch = 0.2241s	
2567/2700 (epoch 47.537), train_loss = 1.69541421, grad/param norm = 5.2415e-01, time/batch = 0.2224s	
2568/2700 (epoch 47.556), train_loss = 1.62483419, grad/param norm = 5.4682e-01, time/batch = 0.1988s	
2569/2700 (epoch 47.574), train_loss = 1.64773398, grad/param norm = 5.5115e-01, time/batch = 0.2075s	
2570/2700 (epoch 47.593), train_loss = 1.63711742, grad/param norm = 5.7273e-01, time/batch = 0.2151s	
2571/2700 (epoch 47.611), train_loss = 1.55839793, grad/param norm = 5.7965e-01, time/batch = 0.2257s	
2572/2700 (epoch 47.630), train_loss = 1.61009371, grad/param norm = 5.7664e-01, time/batch = 0.2140s	
2573/2700 (epoch 47.648), train_loss = 1.63754528, grad/param norm = 5.0944e-01, time/batch = 0.2265s	
2574/2700 (epoch 47.667), train_loss = 1.60229900, grad/param norm = 4.5351e-01, time/batch = 0.2329s	
2575/2700 (epoch 47.685), train_loss = 1.63675706, grad/param norm = 5.4785e-01, time/batch = 0.2359s	
2576/2700 (epoch 47.704), train_loss = 1.65992912, grad/param norm = 5.2238e-01, time/batch = 0.2420s	
2577/2700 (epoch 47.722), train_loss = 1.62639781, grad/param norm = 4.6998e-01, time/batch = 0.2442s	
2578/2700 (epoch 47.741), train_loss = 1.65296774, grad/param norm = 4.7193e-01, time/batch = 0.2388s	
2579/2700 (epoch 47.759), train_loss = 1.66083081, grad/param norm = 4.8927e-01, time/batch = 0.2268s	
2580/2700 (epoch 47.778), train_loss = 1.70525028, grad/param norm = 4.8423e-01, time/batch = 0.2149s	
2581/2700 (epoch 47.796), train_loss = 1.64866729, grad/param norm = 5.0171e-01, time/batch = 0.2105s	
2582/2700 (epoch 47.815), train_loss = 1.68268831, grad/param norm = 4.6191e-01, time/batch = 0.2055s	
2583/2700 (epoch 47.833), train_loss = 1.63183117, grad/param norm = 4.5918e-01, time/batch = 0.2304s	
2584/2700 (epoch 47.852), train_loss = 1.63306823, grad/param norm = 4.4550e-01, time/batch = 0.2469s	
2585/2700 (epoch 47.870), train_loss = 1.63842298, grad/param norm = 4.3992e-01, time/batch = 0.2520s	
2586/2700 (epoch 47.889), train_loss = 1.66514649, grad/param norm = 4.7008e-01, time/batch = 0.2548s	
2587/2700 (epoch 47.907), train_loss = 1.77349165, grad/param norm = 5.7435e-01, time/batch = 0.2559s	
2588/2700 (epoch 47.926), train_loss = 1.68992443, grad/param norm = 6.6310e-01, time/batch = 0.2518s	
2589/2700 (epoch 47.944), train_loss = 1.68338244, grad/param norm = 7.3327e-01, time/batch = 0.2496s	
2590/2700 (epoch 47.963), train_loss = 1.72258894, grad/param norm = 7.6203e-01, time/batch = 0.2284s	
2591/2700 (epoch 47.981), train_loss = 1.68935680, grad/param norm = 6.2616e-01, time/batch = 0.2540s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
2592/2700 (epoch 48.000), train_loss = 1.72286837, grad/param norm = 5.8286e-01, time/batch = 0.2416s	
2593/2700 (epoch 48.019), train_loss = 1.71281067, grad/param norm = 5.6375e-01, time/batch = 0.2453s	
2594/2700 (epoch 48.037), train_loss = 1.70934497, grad/param norm = 4.9148e-01, time/batch = 0.2295s	
2595/2700 (epoch 48.056), train_loss = 1.63493268, grad/param norm = 5.4719e-01, time/batch = 0.2132s	
2596/2700 (epoch 48.074), train_loss = 1.64432461, grad/param norm = 5.0227e-01, time/batch = 0.2245s	
2597/2700 (epoch 48.093), train_loss = 1.64309757, grad/param norm = 5.1576e-01, time/batch = 0.2354s	
2598/2700 (epoch 48.111), train_loss = 1.60047735, grad/param norm = 5.1868e-01, time/batch = 0.2311s	
2599/2700 (epoch 48.130), train_loss = 1.66067819, grad/param norm = 5.8978e-01, time/batch = 0.2367s	
2600/2700 (epoch 48.148), train_loss = 1.59816442, grad/param norm = 5.6926e-01, time/batch = 0.2272s	
2601/2700 (epoch 48.167), train_loss = 1.66628020, grad/param norm = 5.0259e-01, time/batch = 0.2519s	
2602/2700 (epoch 48.185), train_loss = 1.60437079, grad/param norm = 4.9876e-01, time/batch = 0.2503s	
2603/2700 (epoch 48.204), train_loss = 1.64489650, grad/param norm = 4.8502e-01, time/batch = 0.2344s	
2604/2700 (epoch 48.222), train_loss = 1.59672056, grad/param norm = 5.4117e-01, time/batch = 0.2288s	
2605/2700 (epoch 48.241), train_loss = 1.52768440, grad/param norm = 4.5972e-01, time/batch = 0.2284s	
2606/2700 (epoch 48.259), train_loss = 1.57131787, grad/param norm = 4.5554e-01, time/batch = 0.2331s	
2607/2700 (epoch 48.278), train_loss = 1.66841686, grad/param norm = 5.2459e-01, time/batch = 0.2281s	
2608/2700 (epoch 48.296), train_loss = 1.65498053, grad/param norm = 5.4478e-01, time/batch = 0.2132s	
2609/2700 (epoch 48.315), train_loss = 1.66101963, grad/param norm = 5.1845e-01, time/batch = 0.2130s	
2610/2700 (epoch 48.333), train_loss = 1.62870238, grad/param norm = 4.5337e-01, time/batch = 0.2271s	
2611/2700 (epoch 48.352), train_loss = 1.65951237, grad/param norm = 5.0101e-01, time/batch = 0.2049s	
2612/2700 (epoch 48.370), train_loss = 1.66738098, grad/param norm = 5.6911e-01, time/batch = 0.2520s	
2613/2700 (epoch 48.389), train_loss = 1.64885025, grad/param norm = 5.5246e-01, time/batch = 0.2448s	
2614/2700 (epoch 48.407), train_loss = 1.66903217, grad/param norm = 4.8810e-01, time/batch = 0.2536s	
2615/2700 (epoch 48.426), train_loss = 1.70084055, grad/param norm = 4.7663e-01, time/batch = 0.2536s	
2616/2700 (epoch 48.444), train_loss = 1.59729717, grad/param norm = 5.2756e-01, time/batch = 0.2538s	
2617/2700 (epoch 48.463), train_loss = 1.68460946, grad/param norm = 6.6298e-01, time/batch = 0.2500s	
2618/2700 (epoch 48.481), train_loss = 1.68152487, grad/param norm = 6.2132e-01, time/batch = 0.2344s	
2619/2700 (epoch 48.500), train_loss = 1.63558474, grad/param norm = 5.1394e-01, time/batch = 0.2172s	
2620/2700 (epoch 48.519), train_loss = 1.65495100, grad/param norm = 5.0060e-01, time/batch = 0.2046s	
2621/2700 (epoch 48.537), train_loss = 1.67287131, grad/param norm = 5.4773e-01, time/batch = 0.2190s	
2622/2700 (epoch 48.556), train_loss = 1.60085975, grad/param norm = 5.7908e-01, time/batch = 0.2072s	
2623/2700 (epoch 48.574), train_loss = 1.62646312, grad/param norm = 5.6804e-01, time/batch = 0.2455s	
2624/2700 (epoch 48.593), train_loss = 1.61217324, grad/param norm = 5.2445e-01, time/batch = 0.2456s	
2625/2700 (epoch 48.611), train_loss = 1.52428130, grad/param norm = 4.4131e-01, time/batch = 0.2435s	
2626/2700 (epoch 48.630), train_loss = 1.57663278, grad/param norm = 4.7722e-01, time/batch = 0.2420s	
2627/2700 (epoch 48.648), train_loss = 1.61982971, grad/param norm = 5.5203e-01, time/batch = 0.2277s	
2628/2700 (epoch 48.667), train_loss = 1.58917626, grad/param norm = 5.5568e-01, time/batch = 0.2075s	
2629/2700 (epoch 48.685), train_loss = 1.62570083, grad/param norm = 6.0895e-01, time/batch = 0.1818s	
2630/2700 (epoch 48.704), train_loss = 1.64252029, grad/param norm = 5.2913e-01, time/batch = 0.1883s	
2631/2700 (epoch 48.722), train_loss = 1.60335302, grad/param norm = 4.4288e-01, time/batch = 0.1929s	
2632/2700 (epoch 48.741), train_loss = 1.62661717, grad/param norm = 4.3431e-01, time/batch = 0.2139s	
2633/2700 (epoch 48.759), train_loss = 1.63516125, grad/param norm = 4.6766e-01, time/batch = 0.2066s	
2634/2700 (epoch 48.778), train_loss = 1.68413697, grad/param norm = 5.1918e-01, time/batch = 0.2144s	
2635/2700 (epoch 48.796), train_loss = 1.63061986, grad/param norm = 5.7090e-01, time/batch = 0.2298s	
2636/2700 (epoch 48.815), train_loss = 1.67290788, grad/param norm = 6.6242e-01, time/batch = 0.2266s	
2637/2700 (epoch 48.833), train_loss = 1.63208957, grad/param norm = 7.1975e-01, time/batch = 0.2177s	
2638/2700 (epoch 48.852), train_loss = 1.62386199, grad/param norm = 6.2431e-01, time/batch = 0.1960s	
2639/2700 (epoch 48.870), train_loss = 1.62524976, grad/param norm = 5.6220e-01, time/batch = 0.2005s	
2640/2700 (epoch 48.889), train_loss = 1.65269977, grad/param norm = 6.1270e-01, time/batch = 0.2306s	
2641/2700 (epoch 48.907), train_loss = 1.76366551, grad/param norm = 6.8290e-01, time/batch = 0.2183s	
2642/2700 (epoch 48.926), train_loss = 1.66579341, grad/param norm = 6.2489e-01, time/batch = 0.2228s	
2643/2700 (epoch 48.944), train_loss = 1.64950906, grad/param norm = 5.9320e-01, time/batch = 0.2270s	
2644/2700 (epoch 48.963), train_loss = 1.68409470, grad/param norm = 5.8988e-01, time/batch = 0.2111s	
2645/2700 (epoch 48.981), train_loss = 1.65279228, grad/param norm = 5.0238e-01, time/batch = 0.2053s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
2646/2700 (epoch 49.000), train_loss = 1.69506417, grad/param norm = 5.0247e-01, time/batch = 0.1978s	
2647/2700 (epoch 49.019), train_loss = 1.68803987, grad/param norm = 5.2280e-01, time/batch = 0.1906s	
2648/2700 (epoch 49.037), train_loss = 1.68736190, grad/param norm = 4.8736e-01, time/batch = 0.1966s	
2649/2700 (epoch 49.056), train_loss = 1.61454227, grad/param norm = 5.7428e-01, time/batch = 0.2079s	
2650/2700 (epoch 49.074), train_loss = 1.62405984, grad/param norm = 4.9750e-01, time/batch = 0.2521s	
2651/2700 (epoch 49.093), train_loss = 1.61819469, grad/param norm = 4.9044e-01, time/batch = 0.2311s	
2652/2700 (epoch 49.111), train_loss = 1.57750100, grad/param norm = 4.8937e-01, time/batch = 0.2461s	
2653/2700 (epoch 49.130), train_loss = 1.64035133, grad/param norm = 5.6349e-01, time/batch = 0.2522s	
2654/2700 (epoch 49.148), train_loss = 1.57487503, grad/param norm = 5.3059e-01, time/batch = 0.2523s	
2655/2700 (epoch 49.167), train_loss = 1.64130837, grad/param norm = 4.6366e-01, time/batch = 0.2359s	
2656/2700 (epoch 49.185), train_loss = 1.58226573, grad/param norm = 4.8922e-01, time/batch = 0.2336s	
2657/2700 (epoch 49.204), train_loss = 1.63007332, grad/param norm = 5.7600e-01, time/batch = 0.2181s	
2658/2700 (epoch 49.222), train_loss = 1.58018940, grad/param norm = 6.0508e-01, time/batch = 0.2220s	
2659/2700 (epoch 49.241), train_loss = 1.51157684, grad/param norm = 5.3037e-01, time/batch = 0.2313s	
2660/2700 (epoch 49.259), train_loss = 1.54987103, grad/param norm = 4.5266e-01, time/batch = 0.2514s	
2661/2700 (epoch 49.278), train_loss = 1.64248682, grad/param norm = 4.6169e-01, time/batch = 0.2364s	
2662/2700 (epoch 49.296), train_loss = 1.62690868, grad/param norm = 4.6329e-01, time/batch = 0.2513s	
2663/2700 (epoch 49.315), train_loss = 1.63511496, grad/param norm = 4.7194e-01, time/batch = 0.2531s	
2664/2700 (epoch 49.333), train_loss = 1.61788097, grad/param norm = 5.6780e-01, time/batch = 0.2522s	
2665/2700 (epoch 49.352), train_loss = 1.65696530, grad/param norm = 7.2142e-01, time/batch = 0.2452s	
2666/2700 (epoch 49.370), train_loss = 1.66094095, grad/param norm = 6.9475e-01, time/batch = 0.2323s	
2667/2700 (epoch 49.389), train_loss = 1.63245361, grad/param norm = 6.0253e-01, time/batch = 0.2273s	
2668/2700 (epoch 49.407), train_loss = 1.65188517, grad/param norm = 5.0728e-01, time/batch = 0.2049s	
2669/2700 (epoch 49.426), train_loss = 1.68351141, grad/param norm = 5.1182e-01, time/batch = 0.1859s	
2670/2700 (epoch 49.444), train_loss = 1.57082104, grad/param norm = 4.3402e-01, time/batch = 0.2008s	
2671/2700 (epoch 49.463), train_loss = 1.65223033, grad/param norm = 4.8450e-01, time/batch = 0.2120s	
2672/2700 (epoch 49.481), train_loss = 1.64924947, grad/param norm = 4.9005e-01, time/batch = 0.2257s	
2673/2700 (epoch 49.500), train_loss = 1.60787436, grad/param norm = 4.7958e-01, time/batch = 0.2266s	
2674/2700 (epoch 49.519), train_loss = 1.63552089, grad/param norm = 5.1027e-01, time/batch = 0.2276s	
2675/2700 (epoch 49.537), train_loss = 1.64885220, grad/param norm = 5.5075e-01, time/batch = 0.2363s	
2676/2700 (epoch 49.556), train_loss = 1.57723885, grad/param norm = 5.3474e-01, time/batch = 0.2254s	
2677/2700 (epoch 49.574), train_loss = 1.60963978, grad/param norm = 6.2203e-01, time/batch = 0.2313s	
2678/2700 (epoch 49.593), train_loss = 1.60058263, grad/param norm = 6.5112e-01, time/batch = 0.2162s	
2679/2700 (epoch 49.611), train_loss = 1.51480414, grad/param norm = 5.8812e-01, time/batch = 0.2060s	
2680/2700 (epoch 49.630), train_loss = 1.55839503, grad/param norm = 5.2367e-01, time/batch = 0.1854s	
2681/2700 (epoch 49.648), train_loss = 1.59290868, grad/param norm = 4.7913e-01, time/batch = 0.2146s	
2682/2700 (epoch 49.667), train_loss = 1.56185809, grad/param norm = 4.8395e-01, time/batch = 0.2282s	
2683/2700 (epoch 49.685), train_loss = 1.60044824, grad/param norm = 5.7171e-01, time/batch = 0.2460s	
2684/2700 (epoch 49.704), train_loss = 1.62011679, grad/param norm = 5.0125e-01, time/batch = 0.2483s	
2685/2700 (epoch 49.722), train_loss = 1.58579953, grad/param norm = 4.4776e-01, time/batch = 0.2467s	
2686/2700 (epoch 49.741), train_loss = 1.60554474, grad/param norm = 4.7151e-01, time/batch = 0.2409s	
2687/2700 (epoch 49.759), train_loss = 1.61614225, grad/param norm = 5.1785e-01, time/batch = 0.2185s	
2688/2700 (epoch 49.778), train_loss = 1.66368855, grad/param norm = 5.2667e-01, time/batch = 0.2434s	
2689/2700 (epoch 49.796), train_loss = 1.60711086, grad/param norm = 5.1907e-01, time/batch = 0.2169s	
2690/2700 (epoch 49.815), train_loss = 1.64151884, grad/param norm = 4.9164e-01, time/batch = 0.2115s	
2691/2700 (epoch 49.833), train_loss = 1.59266685, grad/param norm = 4.8852e-01, time/batch = 0.2056s	
2692/2700 (epoch 49.852), train_loss = 1.58988373, grad/param norm = 4.7395e-01, time/batch = 0.2248s	
2693/2700 (epoch 49.870), train_loss = 1.59814356, grad/param norm = 4.7053e-01, time/batch = 0.2414s	
2694/2700 (epoch 49.889), train_loss = 1.62533023, grad/param norm = 5.1779e-01, time/batch = 0.2533s	
2695/2700 (epoch 49.907), train_loss = 1.73596071, grad/param norm = 6.0842e-01, time/batch = 0.2531s	
2696/2700 (epoch 49.926), train_loss = 1.64771819, grad/param norm = 6.2833e-01, time/batch = 0.2537s	
2697/2700 (epoch 49.944), train_loss = 1.63379765, grad/param norm = 6.3272e-01, time/batch = 0.2505s	
2698/2700 (epoch 49.963), train_loss = 1.66564157, grad/param norm = 6.1324e-01, time/batch = 0.2537s	
2699/2700 (epoch 49.981), train_loss = 1.63079232, grad/param norm = 5.1102e-01, time/batch = 0.2487s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch50.00_1.7805.t7	
2700/2700 (epoch 50.000), train_loss = 1.67640307, grad/param norm = 5.1014e-01, time/batch = 0.2185s	
