using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 54, val: 3, test: 0	
vocab size: 91	
creating an rnn with 2 layers	
number of parameters in the model: 244315	
cloning rnn	
cloning criterion	
1/2700 (epoch 0.019), train_loss = 4.49782258, grad/param norm = 2.0960e+00, time/batch = 0.5582s	
2/2700 (epoch 0.037), train_loss = 3.84283971, grad/param norm = 7.7386e+00, time/batch = 0.1769s	
3/2700 (epoch 0.056), train_loss = 3.51132143, grad/param norm = 4.6042e+00, time/batch = 0.1552s	
4/2700 (epoch 0.074), train_loss = 4.02794941, grad/param norm = 6.5790e+00, time/batch = 0.1537s	
5/2700 (epoch 0.093), train_loss = 3.95559658, grad/param norm = 1.6601e+01, time/batch = 0.1766s	
6/2700 (epoch 0.111), train_loss = 3.41534772, grad/param norm = 3.2839e+00, time/batch = 0.1754s	
7/2700 (epoch 0.130), train_loss = 3.40952842, grad/param norm = 3.6182e+00, time/batch = 0.1740s	
8/2700 (epoch 0.148), train_loss = 3.40967199, grad/param norm = 4.2717e+00, time/batch = 0.1675s	
9/2700 (epoch 0.167), train_loss = 3.41652665, grad/param norm = 4.4169e+00, time/batch = 0.1604s	
10/2700 (epoch 0.185), train_loss = 3.34391989, grad/param norm = 3.0299e+00, time/batch = 0.1615s	
11/2700 (epoch 0.204), train_loss = 3.22266188, grad/param norm = 2.2434e+00, time/batch = 0.1740s	
12/2700 (epoch 0.222), train_loss = 3.16626287, grad/param norm = 1.5025e+00, time/batch = 0.1760s	
13/2700 (epoch 0.241), train_loss = 3.19106381, grad/param norm = 1.6464e+00, time/batch = 0.1984s	
14/2700 (epoch 0.259), train_loss = 3.22938373, grad/param norm = 1.9473e+00, time/batch = 0.1631s	
15/2700 (epoch 0.278), train_loss = 3.30118066, grad/param norm = 2.0965e+00, time/batch = 0.1649s	
16/2700 (epoch 0.296), train_loss = 3.31323092, grad/param norm = 2.4395e+00, time/batch = 0.1718s	
17/2700 (epoch 0.315), train_loss = 3.29246546, grad/param norm = 2.6285e+00, time/batch = 0.1788s	
18/2700 (epoch 0.333), train_loss = 3.37197232, grad/param norm = 2.2796e+00, time/batch = 0.1734s	
19/2700 (epoch 0.352), train_loss = 3.37277465, grad/param norm = 2.0343e+00, time/batch = 0.1627s	
20/2700 (epoch 0.370), train_loss = 3.31947835, grad/param norm = 1.8371e+00, time/batch = 0.1569s	
21/2700 (epoch 0.389), train_loss = 3.27089381, grad/param norm = 1.7592e+00, time/batch = 0.1520s	
22/2700 (epoch 0.407), train_loss = 3.30403040, grad/param norm = 2.0373e+00, time/batch = 0.1720s	
23/2700 (epoch 0.426), train_loss = 3.31856053, grad/param norm = 2.2775e+00, time/batch = 0.1584s	
24/2700 (epoch 0.444), train_loss = 3.21922830, grad/param norm = 1.9419e+00, time/batch = 0.1756s	
25/2700 (epoch 0.463), train_loss = 3.27751014, grad/param norm = 2.1272e+00, time/batch = 0.1713s	
26/2700 (epoch 0.481), train_loss = 3.36022056, grad/param norm = 2.2113e+00, time/batch = 0.1663s	
27/2700 (epoch 0.500), train_loss = 3.40462469, grad/param norm = 2.2319e+00, time/batch = 0.1595s	
28/2700 (epoch 0.519), train_loss = 3.35265240, grad/param norm = 1.7751e+00, time/batch = 0.1561s	
29/2700 (epoch 0.537), train_loss = 3.33475013, grad/param norm = 1.5328e+00, time/batch = 0.1566s	
30/2700 (epoch 0.556), train_loss = 3.28202467, grad/param norm = 1.3378e+00, time/batch = 0.1520s	
31/2700 (epoch 0.574), train_loss = 3.24042052, grad/param norm = 1.5425e+00, time/batch = 0.1745s	
32/2700 (epoch 0.593), train_loss = 3.25682157, grad/param norm = 1.9236e+00, time/batch = 0.1652s	
33/2700 (epoch 0.611), train_loss = 3.18572044, grad/param norm = 1.6112e+00, time/batch = 0.1485s	
34/2700 (epoch 0.630), train_loss = 3.22147277, grad/param norm = 1.6595e+00, time/batch = 0.1256s	
35/2700 (epoch 0.648), train_loss = 3.31027036, grad/param norm = 2.0802e+00, time/batch = 0.1543s	
36/2700 (epoch 0.667), train_loss = 3.24729212, grad/param norm = 2.4283e+00, time/batch = 0.1611s	
37/2700 (epoch 0.685), train_loss = 3.25922244, grad/param norm = 2.9600e+00, time/batch = 0.1613s	
38/2700 (epoch 0.704), train_loss = 3.24277154, grad/param norm = 3.4985e+00, time/batch = 0.1619s	
39/2700 (epoch 0.722), train_loss = 3.23465168, grad/param norm = 3.2933e+00, time/batch = 0.1634s	
40/2700 (epoch 0.741), train_loss = 3.34808615, grad/param norm = 3.0232e+00, time/batch = 0.1569s	
41/2700 (epoch 0.759), train_loss = 3.29362421, grad/param norm = 2.5049e+00, time/batch = 0.1749s	
42/2700 (epoch 0.778), train_loss = 3.27777605, grad/param norm = 2.4381e+00, time/batch = 0.1602s	
43/2700 (epoch 0.796), train_loss = 3.26076087, grad/param norm = 1.8176e+00, time/batch = 0.1739s	
44/2700 (epoch 0.815), train_loss = 3.20522642, grad/param norm = 1.4440e+00, time/batch = 0.1464s	
45/2700 (epoch 0.833), train_loss = 3.23728867, grad/param norm = 1.5559e+00, time/batch = 0.1701s	
46/2700 (epoch 0.852), train_loss = 3.22779236, grad/param norm = 1.6145e+00, time/batch = 0.1613s	
47/2700 (epoch 0.870), train_loss = 3.22103382, grad/param norm = 1.4778e+00, time/batch = 0.1559s	
48/2700 (epoch 0.889), train_loss = 3.24478317, grad/param norm = 1.3808e+00, time/batch = 0.1550s	
49/2700 (epoch 0.907), train_loss = 3.29803374, grad/param norm = 2.0690e+00, time/batch = 0.1623s	
50/2700 (epoch 0.926), train_loss = 3.30611313, grad/param norm = 3.2346e+00, time/batch = 0.1715s	
51/2700 (epoch 0.944), train_loss = 3.30302990, grad/param norm = 3.2945e+00, time/batch = 0.1548s	
52/2700 (epoch 0.963), train_loss = 3.34199807, grad/param norm = 2.2350e+00, time/batch = 0.1668s	
53/2700 (epoch 0.981), train_loss = 3.36024324, grad/param norm = 1.9603e+00, time/batch = 0.1601s	
54/2700 (epoch 1.000), train_loss = 3.27786367, grad/param norm = 2.1493e+00, time/batch = 0.1648s	
55/2700 (epoch 1.019), train_loss = 3.18755322, grad/param norm = 2.2459e+00, time/batch = 0.1719s	
56/2700 (epoch 1.037), train_loss = 3.23630582, grad/param norm = 2.7044e+00, time/batch = 0.1721s	
57/2700 (epoch 1.056), train_loss = 3.20326497, grad/param norm = 3.3349e+00, time/batch = 0.1793s	
58/2700 (epoch 1.074), train_loss = 3.38581817, grad/param norm = 4.3064e+00, time/batch = 0.1775s	
59/2700 (epoch 1.093), train_loss = 3.43135610, grad/param norm = 4.3811e+00, time/batch = 0.1790s	
60/2700 (epoch 1.111), train_loss = 3.23131957, grad/param norm = 2.8714e+00, time/batch = 0.1719s	
61/2700 (epoch 1.130), train_loss = 3.16734624, grad/param norm = 1.6012e+00, time/batch = 0.1805s	
62/2700 (epoch 1.148), train_loss = 3.03455037, grad/param norm = 1.2778e+00, time/batch = 0.1801s	
63/2700 (epoch 1.167), train_loss = 3.04665613, grad/param norm = 1.6668e+00, time/batch = 0.1693s	
64/2700 (epoch 1.185), train_loss = 3.03586334, grad/param norm = 2.0826e+00, time/batch = 0.1501s	
65/2700 (epoch 1.204), train_loss = 2.98182445, grad/param norm = 2.1187e+00, time/batch = 0.1565s	
66/2700 (epoch 1.222), train_loss = 2.91603201, grad/param norm = 2.1243e+00, time/batch = 0.1494s	
67/2700 (epoch 1.241), train_loss = 2.92381053, grad/param norm = 1.9469e+00, time/batch = 0.1553s	
68/2700 (epoch 1.259), train_loss = 2.94782537, grad/param norm = 2.3918e+00, time/batch = 0.1617s	
69/2700 (epoch 1.278), train_loss = 2.97812265, grad/param norm = 1.3520e+00, time/batch = 0.1606s	
70/2700 (epoch 1.296), train_loss = 2.98053502, grad/param norm = 2.3007e+00, time/batch = 0.1656s	
71/2700 (epoch 1.315), train_loss = 3.02313120, grad/param norm = 2.9059e+00, time/batch = 0.1700s	
72/2700 (epoch 1.333), train_loss = 3.05472224, grad/param norm = 3.0601e+00, time/batch = 0.1642s	
73/2700 (epoch 1.352), train_loss = 3.06193936, grad/param norm = 2.6946e+00, time/batch = 0.1520s	
74/2700 (epoch 1.370), train_loss = 2.93588260, grad/param norm = 2.0626e+00, time/batch = 0.1621s	
75/2700 (epoch 1.389), train_loss = 2.86540010, grad/param norm = 1.6661e+00, time/batch = 0.1532s	
76/2700 (epoch 1.407), train_loss = 2.85429092, grad/param norm = 1.6314e+00, time/batch = 0.1730s	
77/2700 (epoch 1.426), train_loss = 2.91728790, grad/param norm = 2.5485e+00, time/batch = 0.1625s	
78/2700 (epoch 1.444), train_loss = 2.87294573, grad/param norm = 2.8200e+00, time/batch = 0.1604s	
79/2700 (epoch 1.463), train_loss = 2.92948596, grad/param norm = 3.0585e+00, time/batch = 0.1651s	
80/2700 (epoch 1.481), train_loss = 2.97647759, grad/param norm = 2.4841e+00, time/batch = 0.1636s	
81/2700 (epoch 1.500), train_loss = 2.97308817, grad/param norm = 2.2509e+00, time/batch = 0.1506s	
82/2700 (epoch 1.519), train_loss = 2.85940941, grad/param norm = 1.5689e+00, time/batch = 0.1585s	
83/2700 (epoch 1.537), train_loss = 2.82458254, grad/param norm = 1.3759e+00, time/batch = 0.1605s	
84/2700 (epoch 1.556), train_loss = 2.80722999, grad/param norm = 1.5995e+00, time/batch = 0.1759s	
85/2700 (epoch 1.574), train_loss = 2.77226986, grad/param norm = 2.1776e+00, time/batch = 0.1408s	
86/2700 (epoch 1.593), train_loss = 2.76255036, grad/param norm = 2.2233e+00, time/batch = 0.1531s	
87/2700 (epoch 1.611), train_loss = 2.66550333, grad/param norm = 2.0289e+00, time/batch = 0.1557s	
88/2700 (epoch 1.630), train_loss = 2.70533934, grad/param norm = 1.8749e+00, time/batch = 0.1477s	
89/2700 (epoch 1.648), train_loss = 2.73564456, grad/param norm = 1.4006e+00, time/batch = 0.1567s	
90/2700 (epoch 1.667), train_loss = 2.64011557, grad/param norm = 1.3660e+00, time/batch = 0.1771s	
91/2700 (epoch 1.685), train_loss = 2.68527020, grad/param norm = 1.8137e+00, time/batch = 0.1646s	
92/2700 (epoch 1.704), train_loss = 2.68413667, grad/param norm = 2.3089e+00, time/batch = 0.1661s	
93/2700 (epoch 1.722), train_loss = 2.66505963, grad/param norm = 2.1227e+00, time/batch = 0.1729s	
94/2700 (epoch 1.741), train_loss = 2.81939597, grad/param norm = 2.1558e+00, time/batch = 0.1773s	
95/2700 (epoch 1.759), train_loss = 2.73231730, grad/param norm = 1.9107e+00, time/batch = 0.1763s	
96/2700 (epoch 1.778), train_loss = 2.68839701, grad/param norm = 1.4634e+00, time/batch = 0.1416s	
97/2700 (epoch 1.796), train_loss = 2.64767458, grad/param norm = 1.2197e+00, time/batch = 0.1602s	
98/2700 (epoch 1.815), train_loss = 2.60715287, grad/param norm = 1.1679e+00, time/batch = 0.1635s	
99/2700 (epoch 1.833), train_loss = 2.63529573, grad/param norm = 1.5318e+00, time/batch = 0.1612s	
100/2700 (epoch 1.852), train_loss = 2.68546261, grad/param norm = 1.8574e+00, time/batch = 0.1620s	
101/2700 (epoch 1.870), train_loss = 2.66000656, grad/param norm = 1.2788e+00, time/batch = 0.1599s	
102/2700 (epoch 1.889), train_loss = 2.59463209, grad/param norm = 9.4017e-01, time/batch = 0.1539s	
103/2700 (epoch 1.907), train_loss = 2.69831400, grad/param norm = 9.7021e-01, time/batch = 0.1588s	
104/2700 (epoch 1.926), train_loss = 2.62549974, grad/param norm = 1.3252e+00, time/batch = 0.1571s	
105/2700 (epoch 1.944), train_loss = 2.66641947, grad/param norm = 1.6627e+00, time/batch = 0.1601s	
106/2700 (epoch 1.963), train_loss = 2.71715940, grad/param norm = 1.6374e+00, time/batch = 0.1557s	
107/2700 (epoch 1.981), train_loss = 2.70586071, grad/param norm = 1.8903e+00, time/batch = 0.1557s	
108/2700 (epoch 2.000), train_loss = 2.69691029, grad/param norm = 2.2072e+00, time/batch = 0.1799s	
109/2700 (epoch 2.019), train_loss = 2.78562159, grad/param norm = 5.5944e+00, time/batch = 0.1802s	
110/2700 (epoch 2.037), train_loss = 2.72931496, grad/param norm = 1.4219e+00, time/batch = 0.1785s	
111/2700 (epoch 2.056), train_loss = 2.65776812, grad/param norm = 1.6672e+00, time/batch = 0.1801s	
112/2700 (epoch 2.074), train_loss = 2.74881859, grad/param norm = 2.6544e+00, time/batch = 0.1742s	
113/2700 (epoch 2.093), train_loss = 2.74399286, grad/param norm = 2.4716e+00, time/batch = 0.1777s	
114/2700 (epoch 2.111), train_loss = 2.65111076, grad/param norm = 1.7228e+00, time/batch = 0.1773s	
115/2700 (epoch 2.130), train_loss = 2.64435633, grad/param norm = 1.3873e+00, time/batch = 0.1763s	
116/2700 (epoch 2.148), train_loss = 2.57423821, grad/param norm = 1.8459e+00, time/batch = 0.1676s	
117/2700 (epoch 2.167), train_loss = 2.61980550, grad/param norm = 1.7210e+00, time/batch = 0.1737s	
118/2700 (epoch 2.185), train_loss = 2.53278419, grad/param norm = 1.1612e+00, time/batch = 0.1457s	
119/2700 (epoch 2.204), train_loss = 2.49356847, grad/param norm = 1.0416e+00, time/batch = 0.1779s	
120/2700 (epoch 2.222), train_loss = 2.43575853, grad/param norm = 1.1641e+00, time/batch = 0.1791s	
121/2700 (epoch 2.241), train_loss = 2.44176867, grad/param norm = 1.0757e+00, time/batch = 0.1554s	
122/2700 (epoch 2.259), train_loss = 2.46237020, grad/param norm = 1.1719e+00, time/batch = 0.1583s	
123/2700 (epoch 2.278), train_loss = 2.56209245, grad/param norm = 1.3401e+00, time/batch = 0.1771s	
124/2700 (epoch 2.296), train_loss = 2.56185927, grad/param norm = 3.2655e+00, time/batch = 0.1758s	
125/2700 (epoch 2.315), train_loss = 2.58149822, grad/param norm = 1.2010e+00, time/batch = 0.1748s	
126/2700 (epoch 2.333), train_loss = 2.56325181, grad/param norm = 1.0819e+00, time/batch = 0.1677s	
127/2700 (epoch 2.352), train_loss = 2.61489877, grad/param norm = 1.4248e+00, time/batch = 0.1453s	
128/2700 (epoch 2.370), train_loss = 2.58705703, grad/param norm = 2.0637e+00, time/batch = 0.1429s	
129/2700 (epoch 2.389), train_loss = 2.58594994, grad/param norm = 2.2720e+00, time/batch = 0.1377s	
130/2700 (epoch 2.407), train_loss = 2.55044365, grad/param norm = 1.9703e+00, time/batch = 0.1336s	
131/2700 (epoch 2.426), train_loss = 2.60071399, grad/param norm = 1.5150e+00, time/batch = 0.1513s	
132/2700 (epoch 2.444), train_loss = 2.46968081, grad/param norm = 1.3782e+00, time/batch = 0.1470s	
133/2700 (epoch 2.463), train_loss = 2.52962562, grad/param norm = 1.2866e+00, time/batch = 0.1402s	
134/2700 (epoch 2.481), train_loss = 2.54976081, grad/param norm = 1.0389e+00, time/batch = 0.1310s	
135/2700 (epoch 2.500), train_loss = 2.56398225, grad/param norm = 9.5480e-01, time/batch = 0.1415s	
136/2700 (epoch 2.519), train_loss = 2.51071054, grad/param norm = 2.3859e+00, time/batch = 0.1555s	
137/2700 (epoch 2.537), train_loss = 2.53663294, grad/param norm = 1.1023e+00, time/batch = 0.1435s	
138/2700 (epoch 2.556), train_loss = 2.51572930, grad/param norm = 1.3416e+00, time/batch = 0.1759s	
139/2700 (epoch 2.574), train_loss = 2.48256788, grad/param norm = 1.7353e+00, time/batch = 0.1630s	
140/2700 (epoch 2.593), train_loss = 2.47179874, grad/param norm = 1.8723e+00, time/batch = 0.1708s	
141/2700 (epoch 2.611), train_loss = 2.40118873, grad/param norm = 1.6827e+00, time/batch = 0.1678s	
142/2700 (epoch 2.630), train_loss = 2.43480112, grad/param norm = 1.4296e+00, time/batch = 0.1768s	
143/2700 (epoch 2.648), train_loss = 2.43928895, grad/param norm = 9.4565e-01, time/batch = 0.1777s	
144/2700 (epoch 2.667), train_loss = 2.35109164, grad/param norm = 8.3584e-01, time/batch = 0.1797s	
145/2700 (epoch 2.685), train_loss = 2.39538463, grad/param norm = 9.1485e-01, time/batch = 0.1763s	
146/2700 (epoch 2.704), train_loss = 2.39882723, grad/param norm = 1.1041e+00, time/batch = 0.1770s	
147/2700 (epoch 2.722), train_loss = 2.39027286, grad/param norm = 9.9683e-01, time/batch = 0.1665s	
148/2700 (epoch 2.741), train_loss = 2.54261212, grad/param norm = 1.0815e+00, time/batch = 0.1768s	
149/2700 (epoch 2.759), train_loss = 2.51000027, grad/param norm = 1.4449e+00, time/batch = 0.1684s	
150/2700 (epoch 2.778), train_loss = 2.50530910, grad/param norm = 1.7142e+00, time/batch = 0.1388s	
151/2700 (epoch 2.796), train_loss = 2.51997779, grad/param norm = 1.9413e+00, time/batch = 0.1693s	
152/2700 (epoch 2.815), train_loss = 2.47865690, grad/param norm = 1.9059e+00, time/batch = 0.1783s	
153/2700 (epoch 2.833), train_loss = 2.43704121, grad/param norm = 1.9287e+00, time/batch = 0.1784s	
154/2700 (epoch 2.852), train_loss = 2.53233154, grad/param norm = 2.1433e+00, time/batch = 0.1776s	
155/2700 (epoch 2.870), train_loss = 2.51588729, grad/param norm = 1.1599e+00, time/batch = 0.1792s	
156/2700 (epoch 2.889), train_loss = 2.49034405, grad/param norm = 1.0296e+00, time/batch = 0.1752s	
157/2700 (epoch 2.907), train_loss = 2.58734113, grad/param norm = 1.0044e+00, time/batch = 0.1714s	
158/2700 (epoch 2.926), train_loss = 2.50743954, grad/param norm = 1.0645e+00, time/batch = 0.1564s	
159/2700 (epoch 2.944), train_loss = 2.53067614, grad/param norm = 1.0440e+00, time/batch = 0.1516s	
160/2700 (epoch 2.963), train_loss = 2.54782857, grad/param norm = 9.3506e-01, time/batch = 0.1391s	
161/2700 (epoch 2.981), train_loss = 2.52009944, grad/param norm = 1.0369e+00, time/batch = 0.1693s	
162/2700 (epoch 3.000), train_loss = 2.52462813, grad/param norm = 1.8248e+00, time/batch = 0.1693s	
163/2700 (epoch 3.019), train_loss = 2.49768227, grad/param norm = 1.3554e+00, time/batch = 0.1716s	
164/2700 (epoch 3.037), train_loss = 2.45354430, grad/param norm = 1.0302e+00, time/batch = 0.1748s	
165/2700 (epoch 3.056), train_loss = 2.40454906, grad/param norm = 1.0685e+00, time/batch = 0.1762s	
166/2700 (epoch 3.074), train_loss = 2.41250700, grad/param norm = 1.2298e+00, time/batch = 0.1778s	
167/2700 (epoch 3.093), train_loss = 2.44862604, grad/param norm = 1.3381e+00, time/batch = 0.1652s	
168/2700 (epoch 3.111), train_loss = 2.38337372, grad/param norm = 1.2188e+00, time/batch = 0.1812s	
169/2700 (epoch 3.130), train_loss = 2.39437532, grad/param norm = 1.1272e+00, time/batch = 0.1808s	
170/2700 (epoch 3.148), train_loss = 2.35592315, grad/param norm = 1.5054e+00, time/batch = 0.1827s	
171/2700 (epoch 3.167), train_loss = 2.42691570, grad/param norm = 1.4543e+00, time/batch = 0.1730s	
172/2700 (epoch 3.185), train_loss = 2.34441663, grad/param norm = 1.1855e+00, time/batch = 0.1770s	
173/2700 (epoch 3.204), train_loss = 2.33585916, grad/param norm = 1.2503e+00, time/batch = 0.1755s	
174/2700 (epoch 3.222), train_loss = 2.27955547, grad/param norm = 1.2407e+00, time/batch = 0.1768s	
175/2700 (epoch 3.241), train_loss = 2.25497620, grad/param norm = 1.3351e+00, time/batch = 0.1721s	
176/2700 (epoch 3.259), train_loss = 2.29675559, grad/param norm = 1.2496e+00, time/batch = 0.1664s	
177/2700 (epoch 3.278), train_loss = 2.38723624, grad/param norm = 1.1560e+00, time/batch = 0.1469s	
178/2700 (epoch 3.296), train_loss = 2.37249516, grad/param norm = 1.1629e+00, time/batch = 0.1602s	
179/2700 (epoch 3.315), train_loss = 2.38513520, grad/param norm = 1.1485e+00, time/batch = 0.1692s	
180/2700 (epoch 3.333), train_loss = 2.37048800, grad/param norm = 1.1264e+00, time/batch = 0.1636s	
181/2700 (epoch 3.352), train_loss = 2.39164209, grad/param norm = 1.1143e+00, time/batch = 0.1453s	
182/2700 (epoch 3.370), train_loss = 2.39195296, grad/param norm = 1.9280e+00, time/batch = 0.1785s	
183/2700 (epoch 3.389), train_loss = 2.37179928, grad/param norm = 1.0510e+00, time/batch = 0.1767s	
184/2700 (epoch 3.407), train_loss = 2.34773077, grad/param norm = 1.0065e+00, time/batch = 0.1753s	
185/2700 (epoch 3.426), train_loss = 2.38670563, grad/param norm = 1.0173e+00, time/batch = 0.1775s	
186/2700 (epoch 3.444), train_loss = 2.28060836, grad/param norm = 1.1927e+00, time/batch = 0.1766s	
187/2700 (epoch 3.463), train_loss = 2.38121214, grad/param norm = 1.5640e+00, time/batch = 0.1764s	
188/2700 (epoch 3.481), train_loss = 2.43050123, grad/param norm = 1.6441e+00, time/batch = 0.1529s	
189/2700 (epoch 3.500), train_loss = 2.44307294, grad/param norm = 1.7177e+00, time/batch = 0.1783s	
190/2700 (epoch 3.519), train_loss = 2.39182104, grad/param norm = 1.6719e+00, time/batch = 0.1706s	
191/2700 (epoch 3.537), train_loss = 2.37317793, grad/param norm = 1.1270e+00, time/batch = 0.1557s	
192/2700 (epoch 3.556), train_loss = 2.31920703, grad/param norm = 9.9699e-01, time/batch = 0.1474s	
193/2700 (epoch 3.574), train_loss = 2.28909018, grad/param norm = 9.5288e-01, time/batch = 0.1424s	
194/2700 (epoch 3.593), train_loss = 2.27114629, grad/param norm = 1.0320e+00, time/batch = 0.1571s	
195/2700 (epoch 3.611), train_loss = 2.19121206, grad/param norm = 9.3920e-01, time/batch = 0.1684s	
196/2700 (epoch 3.630), train_loss = 2.24331929, grad/param norm = 9.3940e-01, time/batch = 0.1723s	
197/2700 (epoch 3.648), train_loss = 2.28310941, grad/param norm = 8.7319e-01, time/batch = 0.1700s	
198/2700 (epoch 3.667), train_loss = 2.22388236, grad/param norm = 9.3924e-01, time/batch = 0.1676s	
199/2700 (epoch 3.685), train_loss = 2.28049509, grad/param norm = 9.7102e-01, time/batch = 0.1798s	
200/2700 (epoch 3.704), train_loss = 2.28505316, grad/param norm = 1.0770e+00, time/batch = 0.1755s	
201/2700 (epoch 3.722), train_loss = 2.26708298, grad/param norm = 1.1882e+00, time/batch = 0.1592s	
202/2700 (epoch 3.741), train_loss = 2.41009475, grad/param norm = 1.3362e+00, time/batch = 0.1539s	
203/2700 (epoch 3.759), train_loss = 2.37330059, grad/param norm = 1.3007e+00, time/batch = 0.1783s	
204/2700 (epoch 3.778), train_loss = 2.34509182, grad/param norm = 1.1656e+00, time/batch = 0.1753s	
205/2700 (epoch 3.796), train_loss = 2.28561598, grad/param norm = 1.0564e+00, time/batch = 0.1776s	
206/2700 (epoch 3.815), train_loss = 2.28727552, grad/param norm = 8.7066e-01, time/batch = 0.1785s	
207/2700 (epoch 3.833), train_loss = 2.26363550, grad/param norm = 1.1671e+00, time/batch = 0.1793s	
208/2700 (epoch 3.852), train_loss = 2.31252631, grad/param norm = 1.1533e+00, time/batch = 0.1697s	
209/2700 (epoch 3.870), train_loss = 2.26711313, grad/param norm = 1.1795e+00, time/batch = 0.1765s	
210/2700 (epoch 3.889), train_loss = 2.28097323, grad/param norm = 1.0975e+00, time/batch = 0.1683s	
211/2700 (epoch 3.907), train_loss = 2.38151587, grad/param norm = 1.0190e+00, time/batch = 0.1778s	
212/2700 (epoch 3.926), train_loss = 2.31755663, grad/param norm = 1.1134e+00, time/batch = 0.1648s	
213/2700 (epoch 3.944), train_loss = 2.31226744, grad/param norm = 1.0171e+00, time/batch = 0.1566s	
214/2700 (epoch 3.963), train_loss = 2.33894311, grad/param norm = 8.7600e-01, time/batch = 0.1553s	
215/2700 (epoch 3.981), train_loss = 2.32298327, grad/param norm = 8.9976e-01, time/batch = 0.1479s	
216/2700 (epoch 4.000), train_loss = 2.38617993, grad/param norm = 2.3034e+00, time/batch = 0.1517s	
217/2700 (epoch 4.019), train_loss = 2.30772006, grad/param norm = 8.6707e-01, time/batch = 0.1649s	
218/2700 (epoch 4.037), train_loss = 2.30274227, grad/param norm = 9.0238e-01, time/batch = 0.1666s	
219/2700 (epoch 4.056), train_loss = 2.26520037, grad/param norm = 9.0529e-01, time/batch = 0.1683s	
220/2700 (epoch 4.074), train_loss = 2.25088934, grad/param norm = 9.5572e-01, time/batch = 0.1519s	
221/2700 (epoch 4.093), train_loss = 2.29162725, grad/param norm = 9.8435e-01, time/batch = 0.1721s	
222/2700 (epoch 4.111), train_loss = 2.21952979, grad/param norm = 8.9932e-01, time/batch = 0.1777s	
223/2700 (epoch 4.130), train_loss = 2.24521817, grad/param norm = 8.2808e-01, time/batch = 0.1702s	
224/2700 (epoch 4.148), train_loss = 2.20671227, grad/param norm = 9.3453e-01, time/batch = 0.1807s	
225/2700 (epoch 4.167), train_loss = 2.26389724, grad/param norm = 1.0187e+00, time/batch = 0.1800s	
226/2700 (epoch 4.185), train_loss = 2.20348305, grad/param norm = 8.5674e-01, time/batch = 0.1801s	
227/2700 (epoch 4.204), train_loss = 2.18905311, grad/param norm = 7.4438e-01, time/batch = 0.1775s	
228/2700 (epoch 4.222), train_loss = 2.14087970, grad/param norm = 8.6064e-01, time/batch = 0.1730s	
229/2700 (epoch 4.241), train_loss = 2.11004019, grad/param norm = 9.6769e-01, time/batch = 0.1731s	
230/2700 (epoch 4.259), train_loss = 2.16571599, grad/param norm = 9.6158e-01, time/batch = 0.1793s	
231/2700 (epoch 4.278), train_loss = 2.26006603, grad/param norm = 9.9437e-01, time/batch = 0.1787s	
232/2700 (epoch 4.296), train_loss = 2.23876790, grad/param norm = 1.2849e+00, time/batch = 0.1804s	
233/2700 (epoch 4.315), train_loss = 2.29116368, grad/param norm = 1.3979e+00, time/batch = 0.1685s	
234/2700 (epoch 4.333), train_loss = 2.31937880, grad/param norm = 1.5652e+00, time/batch = 0.1641s	
235/2700 (epoch 4.352), train_loss = 2.30440496, grad/param norm = 1.3370e+00, time/batch = 0.1557s	
236/2700 (epoch 4.370), train_loss = 2.30741032, grad/param norm = 1.3501e+00, time/batch = 0.1625s	
237/2700 (epoch 4.389), train_loss = 2.23287566, grad/param norm = 1.1219e+00, time/batch = 0.1695s	
238/2700 (epoch 4.407), train_loss = 2.21203276, grad/param norm = 9.2215e-01, time/batch = 0.1669s	
239/2700 (epoch 4.426), train_loss = 2.24036751, grad/param norm = 7.1066e-01, time/batch = 0.1458s	
240/2700 (epoch 4.444), train_loss = 2.13643621, grad/param norm = 7.4960e-01, time/batch = 0.1611s	
241/2700 (epoch 4.463), train_loss = 2.20880059, grad/param norm = 8.2772e-01, time/batch = 0.1660s	
242/2700 (epoch 4.481), train_loss = 2.23901320, grad/param norm = 8.9907e-01, time/batch = 0.1708s	
243/2700 (epoch 4.500), train_loss = 2.25831135, grad/param norm = 9.3400e-01, time/batch = 0.1686s	
244/2700 (epoch 4.519), train_loss = 2.21623132, grad/param norm = 1.0553e+00, time/batch = 0.1481s	
245/2700 (epoch 4.537), train_loss = 2.26281120, grad/param norm = 1.0859e+00, time/batch = 0.1601s	
246/2700 (epoch 4.556), train_loss = 2.21055595, grad/param norm = 8.4729e-01, time/batch = 0.1548s	
247/2700 (epoch 4.574), train_loss = 2.16156313, grad/param norm = 7.6274e-01, time/batch = 0.1394s	
248/2700 (epoch 4.593), train_loss = 2.16141119, grad/param norm = 8.3924e-01, time/batch = 0.1267s	
249/2700 (epoch 4.611), train_loss = 2.06252651, grad/param norm = 9.0204e-01, time/batch = 0.1114s	
250/2700 (epoch 4.630), train_loss = 2.13957520, grad/param norm = 9.4086e-01, time/batch = 0.1704s	
251/2700 (epoch 4.648), train_loss = 2.18258641, grad/param norm = 1.0231e+00, time/batch = 0.1599s	
252/2700 (epoch 4.667), train_loss = 2.14587966, grad/param norm = 1.1579e+00, time/batch = 0.1682s	
253/2700 (epoch 4.685), train_loss = 2.18570464, grad/param norm = 1.1562e+00, time/batch = 0.1725s	
254/2700 (epoch 4.704), train_loss = 2.20811405, grad/param norm = 1.2653e+00, time/batch = 0.1785s	
255/2700 (epoch 4.722), train_loss = 2.16935600, grad/param norm = 1.2037e+00, time/batch = 0.1692s	
256/2700 (epoch 4.741), train_loss = 2.25594234, grad/param norm = 1.1200e+00, time/batch = 0.1681s	
257/2700 (epoch 4.759), train_loss = 2.22660566, grad/param norm = 1.0278e+00, time/batch = 0.1623s	
258/2700 (epoch 4.778), train_loss = 2.21611386, grad/param norm = 9.2862e-01, time/batch = 0.1633s	
259/2700 (epoch 4.796), train_loss = 2.17079231, grad/param norm = 8.8314e-01, time/batch = 0.1447s	
260/2700 (epoch 4.815), train_loss = 2.18110421, grad/param norm = 7.5715e-01, time/batch = 0.1664s	
261/2700 (epoch 4.833), train_loss = 2.13278704, grad/param norm = 7.2477e-01, time/batch = 0.1669s	
262/2700 (epoch 4.852), train_loss = 2.15895334, grad/param norm = 7.1674e-01, time/batch = 0.1650s	
263/2700 (epoch 4.870), train_loss = 2.12715125, grad/param norm = 7.2646e-01, time/batch = 0.1636s	
264/2700 (epoch 4.889), train_loss = 2.15066685, grad/param norm = 8.2207e-01, time/batch = 0.1593s	
265/2700 (epoch 4.907), train_loss = 2.26456841, grad/param norm = 8.3956e-01, time/batch = 0.1636s	
266/2700 (epoch 4.926), train_loss = 2.20782747, grad/param norm = 8.8819e-01, time/batch = 0.1326s	
267/2700 (epoch 4.944), train_loss = 2.19519293, grad/param norm = 8.1426e-01, time/batch = 0.1766s	
268/2700 (epoch 4.963), train_loss = 2.21056629, grad/param norm = 8.3643e-01, time/batch = 0.1812s	
269/2700 (epoch 4.981), train_loss = 2.18896953, grad/param norm = 7.3465e-01, time/batch = 0.1648s	
270/2700 (epoch 5.000), train_loss = 2.21134530, grad/param norm = 9.6916e-01, time/batch = 0.1593s	
271/2700 (epoch 5.019), train_loss = 2.18787498, grad/param norm = 1.0279e+00, time/batch = 0.1793s	
272/2700 (epoch 5.037), train_loss = 2.19539222, grad/param norm = 9.6865e-01, time/batch = 0.1792s	
273/2700 (epoch 5.056), train_loss = 2.12356666, grad/param norm = 7.3899e-01, time/batch = 0.1798s	
274/2700 (epoch 5.074), train_loss = 2.09697016, grad/param norm = 7.0922e-01, time/batch = 0.1804s	
275/2700 (epoch 5.093), train_loss = 2.16043501, grad/param norm = 8.2911e-01, time/batch = 0.1822s	
276/2700 (epoch 5.111), train_loss = 2.10400683, grad/param norm = 9.5285e-01, time/batch = 0.1680s	
277/2700 (epoch 5.130), train_loss = 2.15114808, grad/param norm = 9.5665e-01, time/batch = 0.1701s	
278/2700 (epoch 5.148), train_loss = 2.10968004, grad/param norm = 1.1061e+00, time/batch = 0.1592s	
279/2700 (epoch 5.167), train_loss = 2.17095532, grad/param norm = 9.5480e-01, time/batch = 0.1542s	
280/2700 (epoch 5.185), train_loss = 2.08945912, grad/param norm = 8.6823e-01, time/batch = 0.1461s	
281/2700 (epoch 5.204), train_loss = 2.10656211, grad/param norm = 8.1067e-01, time/batch = 0.1723s	
282/2700 (epoch 5.222), train_loss = 2.05771948, grad/param norm = 9.7235e-01, time/batch = 0.1649s	
283/2700 (epoch 5.241), train_loss = 2.01540287, grad/param norm = 8.7441e-01, time/batch = 0.1604s	
284/2700 (epoch 5.259), train_loss = 2.03686044, grad/param norm = 7.7392e-01, time/batch = 0.1571s	
285/2700 (epoch 5.278), train_loss = 2.13533708, grad/param norm = 7.9523e-01, time/batch = 0.1610s	
286/2700 (epoch 5.296), train_loss = 2.10125553, grad/param norm = 7.2832e-01, time/batch = 0.1647s	
287/2700 (epoch 5.315), train_loss = 2.12587969, grad/param norm = 7.1437e-01, time/batch = 0.1494s	
288/2700 (epoch 5.333), train_loss = 2.10872819, grad/param norm = 6.4763e-01, time/batch = 0.1575s	
289/2700 (epoch 5.352), train_loss = 2.10887234, grad/param norm = 6.4410e-01, time/batch = 0.1601s	
290/2700 (epoch 5.370), train_loss = 2.14606645, grad/param norm = 7.5793e-01, time/batch = 0.1357s	
291/2700 (epoch 5.389), train_loss = 2.10839422, grad/param norm = 9.0839e-01, time/batch = 0.1714s	
292/2700 (epoch 5.407), train_loss = 2.13377734, grad/param norm = 1.1850e+00, time/batch = 0.1739s	
293/2700 (epoch 5.426), train_loss = 2.16798645, grad/param norm = 7.7864e-01, time/batch = 0.1776s	
294/2700 (epoch 5.444), train_loss = 2.05587694, grad/param norm = 7.5711e-01, time/batch = 0.1791s	
295/2700 (epoch 5.463), train_loss = 2.12642923, grad/param norm = 8.1563e-01, time/batch = 0.1735s	
296/2700 (epoch 5.481), train_loss = 2.14189069, grad/param norm = 7.7307e-01, time/batch = 0.1693s	
297/2700 (epoch 5.500), train_loss = 2.14256639, grad/param norm = 7.4634e-01, time/batch = 0.1591s	
298/2700 (epoch 5.519), train_loss = 2.09396260, grad/param norm = 7.4121e-01, time/batch = 0.1325s	
299/2700 (epoch 5.537), train_loss = 2.12984857, grad/param norm = 7.8113e-01, time/batch = 0.1805s	
300/2700 (epoch 5.556), train_loss = 2.08987278, grad/param norm = 7.7382e-01, time/batch = 0.1744s	
301/2700 (epoch 5.574), train_loss = 2.06641591, grad/param norm = 7.5429e-01, time/batch = 0.1696s	
302/2700 (epoch 5.593), train_loss = 2.07877620, grad/param norm = 8.2054e-01, time/batch = 0.1682s	
303/2700 (epoch 5.611), train_loss = 1.96040013, grad/param norm = 7.3706e-01, time/batch = 0.1633s	
304/2700 (epoch 5.630), train_loss = 2.01890999, grad/param norm = 7.9221e-01, time/batch = 0.1629s	
305/2700 (epoch 5.648), train_loss = 2.07126145, grad/param norm = 8.1876e-01, time/batch = 0.1628s	
306/2700 (epoch 5.667), train_loss = 2.01975708, grad/param norm = 7.6228e-01, time/batch = 0.1568s	
307/2700 (epoch 5.685), train_loss = 2.05838467, grad/param norm = 8.4507e-01, time/batch = 0.1715s	
308/2700 (epoch 5.704), train_loss = 2.09093682, grad/param norm = 9.9478e-01, time/batch = 0.1417s	
309/2700 (epoch 5.722), train_loss = 2.06027787, grad/param norm = 1.1696e+00, time/batch = 0.1564s	
310/2700 (epoch 5.741), train_loss = 2.17591701, grad/param norm = 1.2708e+00, time/batch = 0.1472s	
311/2700 (epoch 5.759), train_loss = 2.14863449, grad/param norm = 1.0835e+00, time/batch = 0.1466s	
312/2700 (epoch 5.778), train_loss = 2.10969996, grad/param norm = 7.6727e-01, time/batch = 0.1432s	
313/2700 (epoch 5.796), train_loss = 2.05879288, grad/param norm = 7.2949e-01, time/batch = 0.1474s	
314/2700 (epoch 5.815), train_loss = 2.08789700, grad/param norm = 7.2381e-01, time/batch = 0.1447s	
315/2700 (epoch 5.833), train_loss = 2.05602869, grad/param norm = 8.2432e-01, time/batch = 0.1547s	
316/2700 (epoch 5.852), train_loss = 2.09343868, grad/param norm = 8.2875e-01, time/batch = 0.1501s	
317/2700 (epoch 5.870), train_loss = 2.05426102, grad/param norm = 7.2781e-01, time/batch = 0.1562s	
318/2700 (epoch 5.889), train_loss = 2.05852461, grad/param norm = 6.8549e-01, time/batch = 0.1537s	
319/2700 (epoch 5.907), train_loss = 2.15740263, grad/param norm = 6.4677e-01, time/batch = 0.1466s	
320/2700 (epoch 5.926), train_loss = 2.09702232, grad/param norm = 6.8770e-01, time/batch = 0.1641s	
321/2700 (epoch 5.944), train_loss = 2.08596836, grad/param norm = 6.4531e-01, time/batch = 0.1703s	
322/2700 (epoch 5.963), train_loss = 2.10292962, grad/param norm = 6.7201e-01, time/batch = 0.1799s	
323/2700 (epoch 5.981), train_loss = 2.08971834, grad/param norm = 6.3348e-01, time/batch = 0.1805s	
324/2700 (epoch 6.000), train_loss = 2.12054435, grad/param norm = 8.2423e-01, time/batch = 0.1802s	
325/2700 (epoch 6.019), train_loss = 2.10769983, grad/param norm = 8.4561e-01, time/batch = 0.1792s	
326/2700 (epoch 6.037), train_loss = 2.09617950, grad/param norm = 7.7000e-01, time/batch = 0.1798s	
327/2700 (epoch 6.056), train_loss = 2.05321760, grad/param norm = 9.5110e-01, time/batch = 0.1716s	
328/2700 (epoch 6.074), train_loss = 2.03615021, grad/param norm = 9.7646e-01, time/batch = 0.1788s	
329/2700 (epoch 6.093), train_loss = 2.06073106, grad/param norm = 8.6356e-01, time/batch = 0.1649s	
330/2700 (epoch 6.111), train_loss = 2.01030681, grad/param norm = 9.4061e-01, time/batch = 0.1789s	
331/2700 (epoch 6.130), train_loss = 2.05668789, grad/param norm = 8.6678e-01, time/batch = 0.1579s	
332/2700 (epoch 6.148), train_loss = 2.01022392, grad/param norm = 8.1166e-01, time/batch = 0.1801s	
333/2700 (epoch 6.167), train_loss = 2.07196903, grad/param norm = 8.3994e-01, time/batch = 0.1792s	
334/2700 (epoch 6.185), train_loss = 1.99562124, grad/param norm = 7.3944e-01, time/batch = 0.1772s	
335/2700 (epoch 6.204), train_loss = 2.01584484, grad/param norm = 7.3776e-01, time/batch = 0.1788s	
336/2700 (epoch 6.222), train_loss = 1.97480696, grad/param norm = 8.0710e-01, time/batch = 0.1773s	
337/2700 (epoch 6.241), train_loss = 1.89741039, grad/param norm = 7.6685e-01, time/batch = 0.1733s	
338/2700 (epoch 6.259), train_loss = 1.95042886, grad/param norm = 6.7910e-01, time/batch = 0.1786s	
339/2700 (epoch 6.278), train_loss = 2.04608266, grad/param norm = 7.1675e-01, time/batch = 0.1805s	
340/2700 (epoch 6.296), train_loss = 2.02389516, grad/param norm = 6.4326e-01, time/batch = 0.1500s	
341/2700 (epoch 6.315), train_loss = 2.02445433, grad/param norm = 5.5410e-01, time/batch = 0.1444s	
342/2700 (epoch 6.333), train_loss = 2.02214182, grad/param norm = 5.6626e-01, time/batch = 0.1561s	
343/2700 (epoch 6.352), train_loss = 2.02268601, grad/param norm = 6.6084e-01, time/batch = 0.1532s	
344/2700 (epoch 6.370), train_loss = 2.06457893, grad/param norm = 7.2881e-01, time/batch = 0.1555s	
345/2700 (epoch 6.389), train_loss = 2.01808987, grad/param norm = 7.4208e-01, time/batch = 0.1489s	
346/2700 (epoch 6.407), train_loss = 2.02486008, grad/param norm = 7.2179e-01, time/batch = 0.1528s	
347/2700 (epoch 6.426), train_loss = 2.07309359, grad/param norm = 7.8771e-01, time/batch = 0.1434s	
348/2700 (epoch 6.444), train_loss = 1.98323641, grad/param norm = 8.8156e-01, time/batch = 0.1644s	
349/2700 (epoch 6.463), train_loss = 2.05804059, grad/param norm = 8.8335e-01, time/batch = 0.1652s	
350/2700 (epoch 6.481), train_loss = 2.05726546, grad/param norm = 7.2968e-01, time/batch = 0.1645s	
351/2700 (epoch 6.500), train_loss = 2.06205688, grad/param norm = 8.3227e-01, time/batch = 0.1738s	
352/2700 (epoch 6.519), train_loss = 2.04972653, grad/param norm = 8.1673e-01, time/batch = 0.1468s	
353/2700 (epoch 6.537), train_loss = 2.06961432, grad/param norm = 7.8662e-01, time/batch = 0.1453s	
354/2700 (epoch 6.556), train_loss = 1.99691803, grad/param norm = 6.7164e-01, time/batch = 0.1393s	
355/2700 (epoch 6.574), train_loss = 1.97809233, grad/param norm = 7.1079e-01, time/batch = 0.1371s	
356/2700 (epoch 6.593), train_loss = 1.98481064, grad/param norm = 7.6256e-01, time/batch = 0.1419s	
357/2700 (epoch 6.611), train_loss = 1.87701060, grad/param norm = 8.1591e-01, time/batch = 0.1393s	
358/2700 (epoch 6.630), train_loss = 1.94343072, grad/param norm = 7.6410e-01, time/batch = 0.1627s	
359/2700 (epoch 6.648), train_loss = 1.98471601, grad/param norm = 7.6833e-01, time/batch = 0.1689s	
360/2700 (epoch 6.667), train_loss = 1.94970870, grad/param norm = 7.9756e-01, time/batch = 0.1709s	
361/2700 (epoch 6.685), train_loss = 1.98484172, grad/param norm = 8.8302e-01, time/batch = 0.1380s	
362/2700 (epoch 6.704), train_loss = 2.01062880, grad/param norm = 8.6126e-01, time/batch = 0.1416s	
363/2700 (epoch 6.722), train_loss = 1.94639866, grad/param norm = 7.7461e-01, time/batch = 0.1777s	
364/2700 (epoch 6.741), train_loss = 2.03706260, grad/param norm = 7.3073e-01, time/batch = 0.1799s	
365/2700 (epoch 6.759), train_loss = 2.02198039, grad/param norm = 6.7874e-01, time/batch = 0.1778s	
366/2700 (epoch 6.778), train_loss = 2.02635429, grad/param norm = 6.3831e-01, time/batch = 0.1693s	
367/2700 (epoch 6.796), train_loss = 2.00275798, grad/param norm = 7.6812e-01, time/batch = 0.1674s	
368/2700 (epoch 6.815), train_loss = 2.03258439, grad/param norm = 8.0273e-01, time/batch = 0.1583s	
369/2700 (epoch 6.833), train_loss = 1.97258859, grad/param norm = 7.4066e-01, time/batch = 0.1549s	
370/2700 (epoch 6.852), train_loss = 1.99381972, grad/param norm = 6.6122e-01, time/batch = 0.1650s	
371/2700 (epoch 6.870), train_loss = 1.96149192, grad/param norm = 5.8480e-01, time/batch = 0.1583s	
372/2700 (epoch 6.889), train_loss = 1.97194707, grad/param norm = 5.8844e-01, time/batch = 0.1482s	
373/2700 (epoch 6.907), train_loss = 2.07756521, grad/param norm = 6.0167e-01, time/batch = 0.1773s	
374/2700 (epoch 6.926), train_loss = 2.01176199, grad/param norm = 6.5665e-01, time/batch = 0.1723s	
375/2700 (epoch 6.944), train_loss = 2.00507187, grad/param norm = 6.6243e-01, time/batch = 0.1695s	
376/2700 (epoch 6.963), train_loss = 2.02985610, grad/param norm = 7.9652e-01, time/batch = 0.1646s	
377/2700 (epoch 6.981), train_loss = 2.02363029, grad/param norm = 7.6362e-01, time/batch = 0.1490s	
378/2700 (epoch 7.000), train_loss = 2.03436786, grad/param norm = 6.9825e-01, time/batch = 0.1478s	
379/2700 (epoch 7.019), train_loss = 2.01279024, grad/param norm = 6.9494e-01, time/batch = 0.1287s	
380/2700 (epoch 7.037), train_loss = 2.00796016, grad/param norm = 5.9734e-01, time/batch = 0.1439s	
381/2700 (epoch 7.056), train_loss = 1.94455804, grad/param norm = 5.4533e-01, time/batch = 0.1798s	
382/2700 (epoch 7.074), train_loss = 1.91868463, grad/param norm = 5.8721e-01, time/batch = 0.1742s	
383/2700 (epoch 7.093), train_loss = 1.95343055, grad/param norm = 5.8329e-01, time/batch = 0.1499s	
384/2700 (epoch 7.111), train_loss = 1.91331437, grad/param norm = 7.6531e-01, time/batch = 0.1522s	
385/2700 (epoch 7.130), train_loss = 1.97971530, grad/param norm = 8.8795e-01, time/batch = 0.1484s	
386/2700 (epoch 7.148), train_loss = 1.96857236, grad/param norm = 1.0667e+00, time/batch = 0.1460s	
387/2700 (epoch 7.167), train_loss = 2.03583556, grad/param norm = 9.7660e-01, time/batch = 0.1428s	
388/2700 (epoch 7.185), train_loss = 1.95270362, grad/param norm = 8.6410e-01, time/batch = 0.1487s	
389/2700 (epoch 7.204), train_loss = 1.94610016, grad/param norm = 6.5994e-01, time/batch = 0.1432s	
390/2700 (epoch 7.222), train_loss = 1.90143159, grad/param norm = 7.3849e-01, time/batch = 0.1565s	
391/2700 (epoch 7.241), train_loss = 1.82020738, grad/param norm = 6.1789e-01, time/batch = 0.1627s	
392/2700 (epoch 7.259), train_loss = 1.86644897, grad/param norm = 5.7032e-01, time/batch = 0.1638s	
393/2700 (epoch 7.278), train_loss = 1.95764336, grad/param norm = 6.1073e-01, time/batch = 0.1360s	
394/2700 (epoch 7.296), train_loss = 1.93543597, grad/param norm = 5.8543e-01, time/batch = 0.1522s	
395/2700 (epoch 7.315), train_loss = 1.95256935, grad/param norm = 5.8287e-01, time/batch = 0.1517s	
396/2700 (epoch 7.333), train_loss = 1.96945284, grad/param norm = 5.8451e-01, time/batch = 0.1493s	
397/2700 (epoch 7.352), train_loss = 1.96746240, grad/param norm = 6.5755e-01, time/batch = 0.1581s	
398/2700 (epoch 7.370), train_loss = 2.01390096, grad/param norm = 7.7659e-01, time/batch = 0.1624s	
399/2700 (epoch 7.389), train_loss = 1.97888561, grad/param norm = 8.0047e-01, time/batch = 0.1603s	
400/2700 (epoch 7.407), train_loss = 1.97033231, grad/param norm = 6.5185e-01, time/batch = 0.1681s	
401/2700 (epoch 7.426), train_loss = 2.00435325, grad/param norm = 6.8255e-01, time/batch = 0.1554s	
402/2700 (epoch 7.444), train_loss = 1.89655022, grad/param norm = 6.4604e-01, time/batch = 0.1651s	
403/2700 (epoch 7.463), train_loss = 1.96712566, grad/param norm = 6.4597e-01, time/batch = 0.1607s	
404/2700 (epoch 7.481), train_loss = 1.97215019, grad/param norm = 6.6991e-01, time/batch = 0.1676s	
405/2700 (epoch 7.500), train_loss = 1.96713887, grad/param norm = 6.8270e-01, time/batch = 0.1795s	
406/2700 (epoch 7.519), train_loss = 1.94061004, grad/param norm = 6.2510e-01, time/batch = 0.1767s	
407/2700 (epoch 7.537), train_loss = 1.98099381, grad/param norm = 6.9692e-01, time/batch = 0.1777s	
408/2700 (epoch 7.556), train_loss = 1.93021631, grad/param norm = 7.5527e-01, time/batch = 0.1620s	
409/2700 (epoch 7.574), train_loss = 1.91936913, grad/param norm = 7.1239e-01, time/batch = 0.1620s	
410/2700 (epoch 7.593), train_loss = 1.91476880, grad/param norm = 6.7146e-01, time/batch = 0.1528s	
411/2700 (epoch 7.611), train_loss = 1.80069526, grad/param norm = 5.7926e-01, time/batch = 0.1745s	
412/2700 (epoch 7.630), train_loss = 1.85535311, grad/param norm = 6.2177e-01, time/batch = 0.1660s	
413/2700 (epoch 7.648), train_loss = 1.90039984, grad/param norm = 6.0964e-01, time/batch = 0.1505s	
414/2700 (epoch 7.667), train_loss = 1.86015957, grad/param norm = 5.4104e-01, time/batch = 0.1583s	
415/2700 (epoch 7.685), train_loss = 1.88766996, grad/param norm = 6.0025e-01, time/batch = 0.1472s	
416/2700 (epoch 7.704), train_loss = 1.93154560, grad/param norm = 7.4788e-01, time/batch = 0.1718s	
417/2700 (epoch 7.722), train_loss = 1.89231577, grad/param norm = 6.9284e-01, time/batch = 0.1731s	
418/2700 (epoch 7.741), train_loss = 1.97426191, grad/param norm = 7.1048e-01, time/batch = 0.1662s	
419/2700 (epoch 7.759), train_loss = 1.99982387, grad/param norm = 8.4032e-01, time/batch = 0.1685s	
420/2700 (epoch 7.778), train_loss = 2.02024740, grad/param norm = 9.3322e-01, time/batch = 0.1580s	
421/2700 (epoch 7.796), train_loss = 1.96625297, grad/param norm = 8.5296e-01, time/batch = 0.1805s	
422/2700 (epoch 7.815), train_loss = 1.95615068, grad/param norm = 7.7785e-01, time/batch = 0.1796s	
423/2700 (epoch 7.833), train_loss = 1.90282085, grad/param norm = 7.9867e-01, time/batch = 0.1701s	
424/2700 (epoch 7.852), train_loss = 1.93673029, grad/param norm = 6.9591e-01, time/batch = 0.1790s	
425/2700 (epoch 7.870), train_loss = 1.89268549, grad/param norm = 5.8386e-01, time/batch = 0.1636s	
426/2700 (epoch 7.889), train_loss = 1.90448446, grad/param norm = 5.7743e-01, time/batch = 0.1560s	
427/2700 (epoch 7.907), train_loss = 2.00728079, grad/param norm = 5.8058e-01, time/batch = 0.1464s	
428/2700 (epoch 7.926), train_loss = 1.93989474, grad/param norm = 6.0804e-01, time/batch = 0.1279s	
429/2700 (epoch 7.944), train_loss = 1.93776721, grad/param norm = 5.8610e-01, time/batch = 0.1476s	
430/2700 (epoch 7.963), train_loss = 1.94306817, grad/param norm = 6.1064e-01, time/batch = 0.1570s	
431/2700 (epoch 7.981), train_loss = 1.92898021, grad/param norm = 5.7863e-01, time/batch = 0.1639s	
432/2700 (epoch 8.000), train_loss = 1.95853238, grad/param norm = 5.4640e-01, time/batch = 0.1694s	
433/2700 (epoch 8.019), train_loss = 1.93119269, grad/param norm = 5.4585e-01, time/batch = 0.1741s	
434/2700 (epoch 8.037), train_loss = 1.94033994, grad/param norm = 4.8577e-01, time/batch = 0.1514s	
435/2700 (epoch 8.056), train_loss = 1.87650628, grad/param norm = 5.3529e-01, time/batch = 0.1634s	
436/2700 (epoch 8.074), train_loss = 1.85228909, grad/param norm = 5.8227e-01, time/batch = 0.1547s	
437/2700 (epoch 8.093), train_loss = 1.88774678, grad/param norm = 5.8018e-01, time/batch = 0.1664s	
438/2700 (epoch 8.111), train_loss = 1.85918547, grad/param norm = 6.6513e-01, time/batch = 0.1532s	
439/2700 (epoch 8.130), train_loss = 1.91472683, grad/param norm = 7.4317e-01, time/batch = 0.1541s	
440/2700 (epoch 8.148), train_loss = 1.87901307, grad/param norm = 7.1274e-01, time/batch = 0.1548s	
441/2700 (epoch 8.167), train_loss = 1.93648000, grad/param norm = 6.6537e-01, time/batch = 0.1442s	
442/2700 (epoch 8.185), train_loss = 1.84023309, grad/param norm = 5.9402e-01, time/batch = 0.1596s	
443/2700 (epoch 8.204), train_loss = 1.88213774, grad/param norm = 6.3791e-01, time/batch = 0.1653s	
444/2700 (epoch 8.222), train_loss = 1.85417512, grad/param norm = 6.9809e-01, time/batch = 0.1554s	
445/2700 (epoch 8.241), train_loss = 1.76771666, grad/param norm = 7.2889e-01, time/batch = 0.1790s	
446/2700 (epoch 8.259), train_loss = 1.83672944, grad/param norm = 8.1015e-01, time/batch = 0.1780s	
447/2700 (epoch 8.278), train_loss = 1.91836574, grad/param norm = 6.9944e-01, time/batch = 0.1680s	
448/2700 (epoch 8.296), train_loss = 1.89280072, grad/param norm = 6.4848e-01, time/batch = 0.1745s	
449/2700 (epoch 8.315), train_loss = 1.90551612, grad/param norm = 6.7882e-01, time/batch = 0.1744s	
450/2700 (epoch 8.333), train_loss = 1.91194710, grad/param norm = 6.4189e-01, time/batch = 0.1698s	
451/2700 (epoch 8.352), train_loss = 1.88533199, grad/param norm = 6.2608e-01, time/batch = 0.1762s	
452/2700 (epoch 8.370), train_loss = 1.92518397, grad/param norm = 6.5791e-01, time/batch = 0.1736s	
453/2700 (epoch 8.389), train_loss = 1.88073646, grad/param norm = 6.4957e-01, time/batch = 0.1764s	
454/2700 (epoch 8.407), train_loss = 1.89544442, grad/param norm = 5.7960e-01, time/batch = 0.1665s	
455/2700 (epoch 8.426), train_loss = 1.92675525, grad/param norm = 5.3357e-01, time/batch = 0.1775s	
456/2700 (epoch 8.444), train_loss = 1.83090819, grad/param norm = 5.2346e-01, time/batch = 0.1774s	
457/2700 (epoch 8.463), train_loss = 1.90296158, grad/param norm = 5.6144e-01, time/batch = 0.1719s	
458/2700 (epoch 8.481), train_loss = 1.91233082, grad/param norm = 5.8867e-01, time/batch = 0.1346s	
459/2700 (epoch 8.500), train_loss = 1.91472856, grad/param norm = 6.6476e-01, time/batch = 0.1758s	
460/2700 (epoch 8.519), train_loss = 1.90993239, grad/param norm = 8.1696e-01, time/batch = 0.1794s	
461/2700 (epoch 8.537), train_loss = 1.95325818, grad/param norm = 7.5412e-01, time/batch = 0.1749s	
462/2700 (epoch 8.556), train_loss = 1.88962962, grad/param norm = 8.0224e-01, time/batch = 0.1784s	
463/2700 (epoch 8.574), train_loss = 1.86583899, grad/param norm = 6.9026e-01, time/batch = 0.1763s	
464/2700 (epoch 8.593), train_loss = 1.85614345, grad/param norm = 6.1229e-01, time/batch = 0.1671s	
465/2700 (epoch 8.611), train_loss = 1.74062393, grad/param norm = 5.1629e-01, time/batch = 0.1559s	
466/2700 (epoch 8.630), train_loss = 1.79679449, grad/param norm = 5.4466e-01, time/batch = 0.1531s	
467/2700 (epoch 8.648), train_loss = 1.84537484, grad/param norm = 5.9012e-01, time/batch = 0.1512s	
468/2700 (epoch 8.667), train_loss = 1.81832340, grad/param norm = 6.3043e-01, time/batch = 0.1358s	
469/2700 (epoch 8.685), train_loss = 1.86183676, grad/param norm = 8.4471e-01, time/batch = 0.1454s	
470/2700 (epoch 8.704), train_loss = 1.89612628, grad/param norm = 8.4136e-01, time/batch = 0.1434s	
471/2700 (epoch 8.722), train_loss = 1.84606603, grad/param norm = 8.0164e-01, time/batch = 0.1490s	
472/2700 (epoch 8.741), train_loss = 1.91640879, grad/param norm = 8.0324e-01, time/batch = 0.1506s	
473/2700 (epoch 8.759), train_loss = 1.90716922, grad/param norm = 6.9578e-01, time/batch = 0.1471s	
474/2700 (epoch 8.778), train_loss = 1.90577542, grad/param norm = 5.8719e-01, time/batch = 0.1350s	
475/2700 (epoch 8.796), train_loss = 1.85102567, grad/param norm = 5.9892e-01, time/batch = 0.1406s	
476/2700 (epoch 8.815), train_loss = 1.89064083, grad/param norm = 6.0673e-01, time/batch = 0.1736s	
477/2700 (epoch 8.833), train_loss = 1.84705223, grad/param norm = 6.6507e-01, time/batch = 0.1787s	
478/2700 (epoch 8.852), train_loss = 1.87175144, grad/param norm = 6.2216e-01, time/batch = 0.1749s	
479/2700 (epoch 8.870), train_loss = 1.84167121, grad/param norm = 5.6146e-01, time/batch = 0.1694s	
480/2700 (epoch 8.889), train_loss = 1.85317216, grad/param norm = 5.3680e-01, time/batch = 0.1788s	
481/2700 (epoch 8.907), train_loss = 1.95717966, grad/param norm = 5.3336e-01, time/batch = 0.1697s	
482/2700 (epoch 8.926), train_loss = 1.89403116, grad/param norm = 5.9523e-01, time/batch = 0.1711s	
483/2700 (epoch 8.944), train_loss = 1.88436523, grad/param norm = 6.3092e-01, time/batch = 0.1696s	
484/2700 (epoch 8.963), train_loss = 1.90932778, grad/param norm = 6.3392e-01, time/batch = 0.1724s	
485/2700 (epoch 8.981), train_loss = 1.89462729, grad/param norm = 6.7042e-01, time/batch = 0.1551s	
486/2700 (epoch 9.000), train_loss = 1.92344564, grad/param norm = 5.5912e-01, time/batch = 0.1638s	
487/2700 (epoch 9.019), train_loss = 1.87858608, grad/param norm = 5.8207e-01, time/batch = 0.1673s	
488/2700 (epoch 9.037), train_loss = 1.89489136, grad/param norm = 5.6140e-01, time/batch = 0.1540s	
489/2700 (epoch 9.056), train_loss = 1.82950462, grad/param norm = 6.1861e-01, time/batch = 0.1541s	
490/2700 (epoch 9.074), train_loss = 1.79637880, grad/param norm = 5.9589e-01, time/batch = 0.1581s	
491/2700 (epoch 9.093), train_loss = 1.82124635, grad/param norm = 5.3995e-01, time/batch = 0.1818s	
492/2700 (epoch 9.111), train_loss = 1.78020612, grad/param norm = 5.1603e-01, time/batch = 0.1800s	
493/2700 (epoch 9.130), train_loss = 1.82190092, grad/param norm = 5.0282e-01, time/batch = 0.1799s	
494/2700 (epoch 9.148), train_loss = 1.78865827, grad/param norm = 5.3687e-01, time/batch = 0.1795s	
495/2700 (epoch 9.167), train_loss = 1.86744725, grad/param norm = 5.9352e-01, time/batch = 0.1705s	
496/2700 (epoch 9.185), train_loss = 1.78270074, grad/param norm = 5.5116e-01, time/batch = 0.1741s	
497/2700 (epoch 9.204), train_loss = 1.82448094, grad/param norm = 6.1160e-01, time/batch = 0.1787s	
498/2700 (epoch 9.222), train_loss = 1.80470965, grad/param norm = 7.2729e-01, time/batch = 0.1809s	
499/2700 (epoch 9.241), train_loss = 1.72032044, grad/param norm = 7.2003e-01, time/batch = 0.1721s	
500/2700 (epoch 9.259), train_loss = 1.78611838, grad/param norm = 6.1414e-01, time/batch = 0.1618s	
501/2700 (epoch 9.278), train_loss = 1.86104175, grad/param norm = 6.4421e-01, time/batch = 0.1788s	
502/2700 (epoch 9.296), train_loss = 1.85079346, grad/param norm = 6.3139e-01, time/batch = 0.1758s	
503/2700 (epoch 9.315), train_loss = 1.83476141, grad/param norm = 5.2455e-01, time/batch = 0.1581s	
504/2700 (epoch 9.333), train_loss = 1.83644247, grad/param norm = 5.8425e-01, time/batch = 0.1476s	
505/2700 (epoch 9.352), train_loss = 1.84908796, grad/param norm = 6.2229e-01, time/batch = 0.1633s	
506/2700 (epoch 9.370), train_loss = 1.88495120, grad/param norm = 6.8383e-01, time/batch = 0.1710s	
507/2700 (epoch 9.389), train_loss = 1.83719161, grad/param norm = 6.0644e-01, time/batch = 0.1720s	
508/2700 (epoch 9.407), train_loss = 1.82684792, grad/param norm = 4.9768e-01, time/batch = 0.1739s	
509/2700 (epoch 9.426), train_loss = 1.86464857, grad/param norm = 4.8609e-01, time/batch = 0.1773s	
510/2700 (epoch 9.444), train_loss = 1.77338191, grad/param norm = 4.9872e-01, time/batch = 0.1801s	
511/2700 (epoch 9.463), train_loss = 1.84880944, grad/param norm = 5.4079e-01, time/batch = 0.1534s	
512/2700 (epoch 9.481), train_loss = 1.86513784, grad/param norm = 6.4383e-01, time/batch = 0.1805s	
513/2700 (epoch 9.500), train_loss = 1.84767057, grad/param norm = 5.9875e-01, time/batch = 0.1793s	
514/2700 (epoch 9.519), train_loss = 1.82098482, grad/param norm = 5.0155e-01, time/batch = 0.1802s	
515/2700 (epoch 9.537), train_loss = 1.85641909, grad/param norm = 5.3562e-01, time/batch = 0.1724s	
516/2700 (epoch 9.556), train_loss = 1.78456402, grad/param norm = 5.8007e-01, time/batch = 0.1737s	
517/2700 (epoch 9.574), train_loss = 1.79348429, grad/param norm = 6.1753e-01, time/batch = 0.1642s	
518/2700 (epoch 9.593), train_loss = 1.80708452, grad/param norm = 6.5544e-01, time/batch = 0.1694s	
519/2700 (epoch 9.611), train_loss = 1.70947891, grad/param norm = 6.0066e-01, time/batch = 0.1579s	
520/2700 (epoch 9.630), train_loss = 1.75697941, grad/param norm = 6.8324e-01, time/batch = 0.1494s	
521/2700 (epoch 9.648), train_loss = 1.80396926, grad/param norm = 6.4775e-01, time/batch = 0.1755s	
522/2700 (epoch 9.667), train_loss = 1.76201358, grad/param norm = 5.4495e-01, time/batch = 0.1626s	
523/2700 (epoch 9.685), train_loss = 1.79239893, grad/param norm = 6.0543e-01, time/batch = 0.1549s	
524/2700 (epoch 9.704), train_loss = 1.82995229, grad/param norm = 6.6295e-01, time/batch = 0.1608s	
525/2700 (epoch 9.722), train_loss = 1.78047258, grad/param norm = 5.9362e-01, time/batch = 0.1650s	
526/2700 (epoch 9.741), train_loss = 1.83892375, grad/param norm = 5.7724e-01, time/batch = 0.1524s	
527/2700 (epoch 9.759), train_loss = 1.86551718, grad/param norm = 7.2573e-01, time/batch = 0.1517s	
528/2700 (epoch 9.778), train_loss = 1.90441701, grad/param norm = 8.3617e-01, time/batch = 0.1571s	
529/2700 (epoch 9.796), train_loss = 1.84589851, grad/param norm = 8.2739e-01, time/batch = 0.1610s	
530/2700 (epoch 9.815), train_loss = 1.87527352, grad/param norm = 8.1906e-01, time/batch = 0.1577s	
531/2700 (epoch 9.833), train_loss = 1.80985208, grad/param norm = 7.1786e-01, time/batch = 0.1717s	
532/2700 (epoch 9.852), train_loss = 1.82857145, grad/param norm = 5.9508e-01, time/batch = 0.1647s	
533/2700 (epoch 9.870), train_loss = 1.79691612, grad/param norm = 4.9632e-01, time/batch = 0.1748s	
534/2700 (epoch 9.889), train_loss = 1.79265684, grad/param norm = 4.7053e-01, time/batch = 0.1783s	
535/2700 (epoch 9.907), train_loss = 1.90134832, grad/param norm = 4.8376e-01, time/batch = 0.1773s	
536/2700 (epoch 9.926), train_loss = 1.83523729, grad/param norm = 5.1972e-01, time/batch = 0.1605s	
537/2700 (epoch 9.944), train_loss = 1.81891781, grad/param norm = 5.1555e-01, time/batch = 0.1615s	
538/2700 (epoch 9.963), train_loss = 1.83834197, grad/param norm = 5.6483e-01, time/batch = 0.1547s	
539/2700 (epoch 9.981), train_loss = 1.82358929, grad/param norm = 5.4930e-01, time/batch = 0.1447s	
decayed learning rate by a factor 0.97 to 0.00194	
540/2700 (epoch 10.000), train_loss = 1.86906846, grad/param norm = 5.8110e-01, time/batch = 0.1438s	
541/2700 (epoch 10.019), train_loss = 1.83809723, grad/param norm = 5.8043e-01, time/batch = 0.1799s	
542/2700 (epoch 10.037), train_loss = 1.85220822, grad/param norm = 5.3653e-01, time/batch = 0.1788s	
543/2700 (epoch 10.056), train_loss = 1.78304955, grad/param norm = 5.6444e-01, time/batch = 0.1686s	
544/2700 (epoch 10.074), train_loss = 1.74922465, grad/param norm = 5.2895e-01, time/batch = 0.1653s	
545/2700 (epoch 10.093), train_loss = 1.76399753, grad/param norm = 4.7901e-01, time/batch = 0.1540s	
546/2700 (epoch 10.111), train_loss = 1.72428589, grad/param norm = 4.9099e-01, time/batch = 0.1587s	
547/2700 (epoch 10.130), train_loss = 1.77049287, grad/param norm = 4.6868e-01, time/batch = 0.1479s	
548/2700 (epoch 10.148), train_loss = 1.73846596, grad/param norm = 5.0356e-01, time/batch = 0.1558s	
549/2700 (epoch 10.167), train_loss = 1.81595453, grad/param norm = 5.3804e-01, time/batch = 0.1582s	
550/2700 (epoch 10.185), train_loss = 1.72504539, grad/param norm = 4.8306e-01, time/batch = 0.1559s	
551/2700 (epoch 10.204), train_loss = 1.76430651, grad/param norm = 4.9762e-01, time/batch = 0.1609s	
552/2700 (epoch 10.222), train_loss = 1.73999221, grad/param norm = 6.0931e-01, time/batch = 0.1504s	
553/2700 (epoch 10.241), train_loss = 1.65143194, grad/param norm = 5.6140e-01, time/batch = 0.1348s	
554/2700 (epoch 10.259), train_loss = 1.71117729, grad/param norm = 4.9430e-01, time/batch = 0.1593s	
555/2700 (epoch 10.278), train_loss = 1.78669821, grad/param norm = 5.3196e-01, time/batch = 0.1644s	
556/2700 (epoch 10.296), train_loss = 1.77782472, grad/param norm = 5.3004e-01, time/batch = 0.1620s	
557/2700 (epoch 10.315), train_loss = 1.77483288, grad/param norm = 4.9863e-01, time/batch = 0.1722s	
558/2700 (epoch 10.333), train_loss = 1.78816429, grad/param norm = 5.3971e-01, time/batch = 0.1793s	
559/2700 (epoch 10.352), train_loss = 1.79270269, grad/param norm = 6.2048e-01, time/batch = 0.1774s	
560/2700 (epoch 10.370), train_loss = 1.82572005, grad/param norm = 6.7230e-01, time/batch = 0.1760s	
561/2700 (epoch 10.389), train_loss = 1.79090529, grad/param norm = 6.4705e-01, time/batch = 0.1753s	
562/2700 (epoch 10.407), train_loss = 1.80699702, grad/param norm = 6.6204e-01, time/batch = 0.1742s	
563/2700 (epoch 10.426), train_loss = 1.86105559, grad/param norm = 7.2298e-01, time/batch = 0.1706s	
564/2700 (epoch 10.444), train_loss = 1.73874632, grad/param norm = 6.1060e-01, time/batch = 0.1441s	
565/2700 (epoch 10.463), train_loss = 1.80747843, grad/param norm = 5.3456e-01, time/batch = 0.1452s	
566/2700 (epoch 10.481), train_loss = 1.80552475, grad/param norm = 5.2021e-01, time/batch = 0.1374s	
567/2700 (epoch 10.500), train_loss = 1.78524841, grad/param norm = 5.2331e-01, time/batch = 0.1550s	
568/2700 (epoch 10.519), train_loss = 1.79076531, grad/param norm = 5.4978e-01, time/batch = 0.1741s	
569/2700 (epoch 10.537), train_loss = 1.82912252, grad/param norm = 6.2146e-01, time/batch = 0.1647s	
570/2700 (epoch 10.556), train_loss = 1.74055140, grad/param norm = 5.7668e-01, time/batch = 0.1585s	
571/2700 (epoch 10.574), train_loss = 1.73621351, grad/param norm = 6.0123e-01, time/batch = 0.1719s	
572/2700 (epoch 10.593), train_loss = 1.75339674, grad/param norm = 6.4724e-01, time/batch = 0.1780s	
573/2700 (epoch 10.611), train_loss = 1.67362782, grad/param norm = 7.1810e-01, time/batch = 0.1797s	
574/2700 (epoch 10.630), train_loss = 1.72842346, grad/param norm = 6.4904e-01, time/batch = 0.1715s	
575/2700 (epoch 10.648), train_loss = 1.75174570, grad/param norm = 6.1981e-01, time/batch = 0.1813s	
576/2700 (epoch 10.667), train_loss = 1.72653500, grad/param norm = 6.1774e-01, time/batch = 0.1726s	
577/2700 (epoch 10.685), train_loss = 1.75155608, grad/param norm = 6.5232e-01, time/batch = 0.1711s	
578/2700 (epoch 10.704), train_loss = 1.76967505, grad/param norm = 5.9641e-01, time/batch = 0.1633s	
579/2700 (epoch 10.722), train_loss = 1.71746787, grad/param norm = 5.2380e-01, time/batch = 0.1595s	
580/2700 (epoch 10.741), train_loss = 1.78010018, grad/param norm = 5.2415e-01, time/batch = 0.1572s	
581/2700 (epoch 10.759), train_loss = 1.78163663, grad/param norm = 5.2280e-01, time/batch = 0.1745s	
582/2700 (epoch 10.778), train_loss = 1.80063804, grad/param norm = 4.7851e-01, time/batch = 0.1717s	
583/2700 (epoch 10.796), train_loss = 1.74180056, grad/param norm = 5.1873e-01, time/batch = 0.1649s	
584/2700 (epoch 10.815), train_loss = 1.79373195, grad/param norm = 5.4711e-01, time/batch = 0.1548s	
585/2700 (epoch 10.833), train_loss = 1.74255186, grad/param norm = 5.7721e-01, time/batch = 0.1454s	
586/2700 (epoch 10.852), train_loss = 1.75895597, grad/param norm = 5.5274e-01, time/batch = 0.1385s	
587/2700 (epoch 10.870), train_loss = 1.75570961, grad/param norm = 5.7543e-01, time/batch = 0.1335s	
588/2700 (epoch 10.889), train_loss = 1.76968636, grad/param norm = 5.8312e-01, time/batch = 0.1592s	
589/2700 (epoch 10.907), train_loss = 1.87914289, grad/param norm = 5.8942e-01, time/batch = 0.1637s	
590/2700 (epoch 10.926), train_loss = 1.80497014, grad/param norm = 5.9487e-01, time/batch = 0.1725s	
591/2700 (epoch 10.944), train_loss = 1.77828096, grad/param norm = 5.4474e-01, time/batch = 0.1604s	
592/2700 (epoch 10.963), train_loss = 1.78890041, grad/param norm = 5.2324e-01, time/batch = 0.1665s	
593/2700 (epoch 10.981), train_loss = 1.77233540, grad/param norm = 5.6976e-01, time/batch = 0.1690s	
decayed learning rate by a factor 0.97 to 0.0018818	
594/2700 (epoch 11.000), train_loss = 1.82840046, grad/param norm = 4.9646e-01, time/batch = 0.1659s	
595/2700 (epoch 11.019), train_loss = 1.78224791, grad/param norm = 5.2166e-01, time/batch = 0.1488s	
596/2700 (epoch 11.037), train_loss = 1.80776424, grad/param norm = 5.2421e-01, time/batch = 0.1575s	
597/2700 (epoch 11.056), train_loss = 1.72990022, grad/param norm = 5.2130e-01, time/batch = 0.1630s	
598/2700 (epoch 11.074), train_loss = 1.69643550, grad/param norm = 4.6790e-01, time/batch = 0.1687s	
599/2700 (epoch 11.093), train_loss = 1.71308050, grad/param norm = 4.4520e-01, time/batch = 0.1624s	
600/2700 (epoch 11.111), train_loss = 1.68047839, grad/param norm = 4.9482e-01, time/batch = 0.1540s	
601/2700 (epoch 11.130), train_loss = 1.73829374, grad/param norm = 5.1835e-01, time/batch = 0.1600s	
602/2700 (epoch 11.148), train_loss = 1.70681720, grad/param norm = 5.6198e-01, time/batch = 0.1487s	
603/2700 (epoch 11.167), train_loss = 1.78904298, grad/param norm = 6.0679e-01, time/batch = 0.1483s	
604/2700 (epoch 11.185), train_loss = 1.69686611, grad/param norm = 5.3095e-01, time/batch = 0.1540s	
605/2700 (epoch 11.204), train_loss = 1.72361050, grad/param norm = 4.8541e-01, time/batch = 0.1605s	
606/2700 (epoch 11.222), train_loss = 1.68326071, grad/param norm = 5.0970e-01, time/batch = 0.1337s	
607/2700 (epoch 11.241), train_loss = 1.59376951, grad/param norm = 4.5594e-01, time/batch = 0.1676s	
608/2700 (epoch 11.259), train_loss = 1.65985925, grad/param norm = 4.5272e-01, time/batch = 0.1449s	
609/2700 (epoch 11.278), train_loss = 1.73741626, grad/param norm = 5.2069e-01, time/batch = 0.1664s	
610/2700 (epoch 11.296), train_loss = 1.73359690, grad/param norm = 5.1916e-01, time/batch = 0.1565s	
611/2700 (epoch 11.315), train_loss = 1.72496625, grad/param norm = 4.6879e-01, time/batch = 0.1591s	
612/2700 (epoch 11.333), train_loss = 1.73086112, grad/param norm = 4.8299e-01, time/batch = 0.1468s	
613/2700 (epoch 11.352), train_loss = 1.73029605, grad/param norm = 5.1046e-01, time/batch = 0.1442s	
614/2700 (epoch 11.370), train_loss = 1.76164435, grad/param norm = 5.7776e-01, time/batch = 0.1527s	
615/2700 (epoch 11.389), train_loss = 1.72565274, grad/param norm = 5.6235e-01, time/batch = 0.1616s	
616/2700 (epoch 11.407), train_loss = 1.74113327, grad/param norm = 5.3328e-01, time/batch = 0.1600s	
617/2700 (epoch 11.426), train_loss = 1.78758246, grad/param norm = 5.6762e-01, time/batch = 0.1664s	
618/2700 (epoch 11.444), train_loss = 1.70983563, grad/param norm = 6.2693e-01, time/batch = 0.1579s	
619/2700 (epoch 11.463), train_loss = 1.80042636, grad/param norm = 7.6139e-01, time/batch = 0.1624s	
620/2700 (epoch 11.481), train_loss = 1.78685784, grad/param norm = 6.7539e-01, time/batch = 0.1517s	
621/2700 (epoch 11.500), train_loss = 1.73697741, grad/param norm = 5.1389e-01, time/batch = 0.1807s	
622/2700 (epoch 11.519), train_loss = 1.73744531, grad/param norm = 4.8204e-01, time/batch = 0.1773s	
623/2700 (epoch 11.537), train_loss = 1.76621089, grad/param norm = 5.4980e-01, time/batch = 0.1763s	
624/2700 (epoch 11.556), train_loss = 1.70723798, grad/param norm = 6.2537e-01, time/batch = 0.1691s	
625/2700 (epoch 11.574), train_loss = 1.70721188, grad/param norm = 5.9000e-01, time/batch = 0.1551s	
626/2700 (epoch 11.593), train_loss = 1.71605605, grad/param norm = 5.5597e-01, time/batch = 0.1574s	
627/2700 (epoch 11.611), train_loss = 1.60734288, grad/param norm = 4.8213e-01, time/batch = 0.1667s	
628/2700 (epoch 11.630), train_loss = 1.64565663, grad/param norm = 4.7200e-01, time/batch = 0.1578s	
629/2700 (epoch 11.648), train_loss = 1.68992176, grad/param norm = 5.2749e-01, time/batch = 0.1610s	
630/2700 (epoch 11.667), train_loss = 1.66579671, grad/param norm = 5.0433e-01, time/batch = 0.1608s	
631/2700 (epoch 11.685), train_loss = 1.69298250, grad/param norm = 5.4032e-01, time/batch = 0.1785s	
632/2700 (epoch 11.704), train_loss = 1.72174470, grad/param norm = 5.1811e-01, time/batch = 0.1769s	
633/2700 (epoch 11.722), train_loss = 1.67112117, grad/param norm = 4.4647e-01, time/batch = 0.1731s	
634/2700 (epoch 11.741), train_loss = 1.72863182, grad/param norm = 4.5223e-01, time/batch = 0.1709s	
635/2700 (epoch 11.759), train_loss = 1.73321219, grad/param norm = 4.9997e-01, time/batch = 0.1593s	
636/2700 (epoch 11.778), train_loss = 1.76320192, grad/param norm = 5.3077e-01, time/batch = 0.1771s	
637/2700 (epoch 11.796), train_loss = 1.70704652, grad/param norm = 5.5798e-01, time/batch = 0.1783s	
638/2700 (epoch 11.815), train_loss = 1.75221393, grad/param norm = 5.5025e-01, time/batch = 0.1666s	
639/2700 (epoch 11.833), train_loss = 1.70166397, grad/param norm = 6.0020e-01, time/batch = 0.1424s	
640/2700 (epoch 11.852), train_loss = 1.71897221, grad/param norm = 5.4540e-01, time/batch = 0.1646s	
641/2700 (epoch 11.870), train_loss = 1.70989668, grad/param norm = 5.7460e-01, time/batch = 0.1663s	
642/2700 (epoch 11.889), train_loss = 1.71292374, grad/param norm = 5.0407e-01, time/batch = 0.1623s	
643/2700 (epoch 11.907), train_loss = 1.81244591, grad/param norm = 4.7052e-01, time/batch = 0.1655s	
644/2700 (epoch 11.926), train_loss = 1.74750728, grad/param norm = 5.2992e-01, time/batch = 0.1464s	
645/2700 (epoch 11.944), train_loss = 1.72964386, grad/param norm = 5.2093e-01, time/batch = 0.1381s	
646/2700 (epoch 11.963), train_loss = 1.74223429, grad/param norm = 5.1230e-01, time/batch = 0.1636s	
647/2700 (epoch 11.981), train_loss = 1.72203514, grad/param norm = 5.3856e-01, time/batch = 0.1722s	
decayed learning rate by a factor 0.97 to 0.001825346	
648/2700 (epoch 12.000), train_loss = 1.78352948, grad/param norm = 5.2013e-01, time/batch = 0.1714s	
649/2700 (epoch 12.019), train_loss = 1.74642207, grad/param norm = 5.4976e-01, time/batch = 0.1491s	
650/2700 (epoch 12.037), train_loss = 1.76956875, grad/param norm = 5.3686e-01, time/batch = 0.1637s	
651/2700 (epoch 12.056), train_loss = 1.69189102, grad/param norm = 5.4040e-01, time/batch = 0.1786s	
652/2700 (epoch 12.074), train_loss = 1.67169840, grad/param norm = 5.1269e-01, time/batch = 0.1821s	
653/2700 (epoch 12.093), train_loss = 1.68270572, grad/param norm = 4.9643e-01, time/batch = 0.1809s	
654/2700 (epoch 12.111), train_loss = 1.64534904, grad/param norm = 5.4160e-01, time/batch = 0.1807s	
655/2700 (epoch 12.130), train_loss = 1.70153103, grad/param norm = 5.2754e-01, time/batch = 0.1798s	
656/2700 (epoch 12.148), train_loss = 1.66486673, grad/param norm = 5.2243e-01, time/batch = 0.1794s	
657/2700 (epoch 12.167), train_loss = 1.73162111, grad/param norm = 5.0110e-01, time/batch = 0.1784s	
658/2700 (epoch 12.185), train_loss = 1.64583584, grad/param norm = 4.6718e-01, time/batch = 0.1784s	
659/2700 (epoch 12.204), train_loss = 1.67767725, grad/param norm = 4.2632e-01, time/batch = 0.1611s	
660/2700 (epoch 12.222), train_loss = 1.64555695, grad/param norm = 4.8729e-01, time/batch = 0.1691s	
661/2700 (epoch 12.241), train_loss = 1.56573240, grad/param norm = 5.1693e-01, time/batch = 0.1782s	
662/2700 (epoch 12.259), train_loss = 1.64011306, grad/param norm = 5.3051e-01, time/batch = 0.1777s	
663/2700 (epoch 12.278), train_loss = 1.70732772, grad/param norm = 5.3248e-01, time/batch = 0.1812s	
664/2700 (epoch 12.296), train_loss = 1.69535857, grad/param norm = 5.1399e-01, time/batch = 0.1725s	
665/2700 (epoch 12.315), train_loss = 1.69450922, grad/param norm = 4.9758e-01, time/batch = 0.1761s	
666/2700 (epoch 12.333), train_loss = 1.69123467, grad/param norm = 5.2293e-01, time/batch = 0.1768s	
667/2700 (epoch 12.352), train_loss = 1.69820825, grad/param norm = 5.4577e-01, time/batch = 0.1787s	
668/2700 (epoch 12.370), train_loss = 1.72227238, grad/param norm = 5.6463e-01, time/batch = 0.1791s	
669/2700 (epoch 12.389), train_loss = 1.68813971, grad/param norm = 5.4585e-01, time/batch = 0.1615s	
670/2700 (epoch 12.407), train_loss = 1.70207944, grad/param norm = 4.9281e-01, time/batch = 0.1410s	
671/2700 (epoch 12.426), train_loss = 1.74169126, grad/param norm = 4.9091e-01, time/batch = 0.1703s	
672/2700 (epoch 12.444), train_loss = 1.64842645, grad/param norm = 4.6797e-01, time/batch = 0.1596s	
673/2700 (epoch 12.463), train_loss = 1.72620559, grad/param norm = 5.0705e-01, time/batch = 0.1595s	
674/2700 (epoch 12.481), train_loss = 1.71376023, grad/param norm = 5.1109e-01, time/batch = 0.1586s	
675/2700 (epoch 12.500), train_loss = 1.67721702, grad/param norm = 4.4156e-01, time/batch = 0.1716s	
676/2700 (epoch 12.519), train_loss = 1.69142805, grad/param norm = 3.9170e-01, time/batch = 0.1641s	
677/2700 (epoch 12.537), train_loss = 1.70666228, grad/param norm = 4.5443e-01, time/batch = 0.1672s	
678/2700 (epoch 12.556), train_loss = 1.62800026, grad/param norm = 4.6821e-01, time/batch = 0.1696s	
679/2700 (epoch 12.574), train_loss = 1.64052295, grad/param norm = 5.0719e-01, time/batch = 0.1773s	
680/2700 (epoch 12.593), train_loss = 1.66442924, grad/param norm = 5.3745e-01, time/batch = 0.1504s	
681/2700 (epoch 12.611), train_loss = 1.58066914, grad/param norm = 5.3663e-01, time/batch = 0.1824s	
682/2700 (epoch 12.630), train_loss = 1.61756026, grad/param norm = 5.4075e-01, time/batch = 0.1809s	
683/2700 (epoch 12.648), train_loss = 1.65009873, grad/param norm = 4.9732e-01, time/batch = 0.1736s	
684/2700 (epoch 12.667), train_loss = 1.62681139, grad/param norm = 4.8628e-01, time/batch = 0.1801s	
685/2700 (epoch 12.685), train_loss = 1.66725596, grad/param norm = 5.6718e-01, time/batch = 0.1790s	
686/2700 (epoch 12.704), train_loss = 1.69941459, grad/param norm = 6.1022e-01, time/batch = 0.1787s	
687/2700 (epoch 12.722), train_loss = 1.65901423, grad/param norm = 5.8820e-01, time/batch = 0.1782s	
688/2700 (epoch 12.741), train_loss = 1.70593038, grad/param norm = 6.1137e-01, time/batch = 0.1803s	
689/2700 (epoch 12.759), train_loss = 1.70855592, grad/param norm = 6.2095e-01, time/batch = 0.1796s	
690/2700 (epoch 12.778), train_loss = 1.73623893, grad/param norm = 5.7513e-01, time/batch = 0.1560s	
691/2700 (epoch 12.796), train_loss = 1.66221765, grad/param norm = 5.6405e-01, time/batch = 0.1705s	
692/2700 (epoch 12.815), train_loss = 1.71785949, grad/param norm = 5.2120e-01, time/batch = 0.1686s	
693/2700 (epoch 12.833), train_loss = 1.66033123, grad/param norm = 5.4041e-01, time/batch = 0.1560s	
694/2700 (epoch 12.852), train_loss = 1.67889639, grad/param norm = 5.3548e-01, time/batch = 0.1668s	
695/2700 (epoch 12.870), train_loss = 1.67156128, grad/param norm = 4.9204e-01, time/batch = 0.1508s	
696/2700 (epoch 12.889), train_loss = 1.66291183, grad/param norm = 4.3953e-01, time/batch = 0.1367s	
697/2700 (epoch 12.907), train_loss = 1.76683898, grad/param norm = 4.4604e-01, time/batch = 0.1456s	
698/2700 (epoch 12.926), train_loss = 1.69989723, grad/param norm = 4.7256e-01, time/batch = 0.1577s	
699/2700 (epoch 12.944), train_loss = 1.68018276, grad/param norm = 4.6094e-01, time/batch = 0.1685s	
700/2700 (epoch 12.963), train_loss = 1.69978878, grad/param norm = 4.9988e-01, time/batch = 0.1675s	
701/2700 (epoch 12.981), train_loss = 1.68250274, grad/param norm = 5.2174e-01, time/batch = 0.1529s	
decayed learning rate by a factor 0.97 to 0.00177058562	
702/2700 (epoch 13.000), train_loss = 1.77797383, grad/param norm = 6.5037e-01, time/batch = 0.1807s	
703/2700 (epoch 13.019), train_loss = 1.73593582, grad/param norm = 5.6177e-01, time/batch = 0.1784s	
704/2700 (epoch 13.037), train_loss = 1.73166800, grad/param norm = 4.8162e-01, time/batch = 0.1805s	
705/2700 (epoch 13.056), train_loss = 1.64619997, grad/param norm = 4.5873e-01, time/batch = 0.1785s	
706/2700 (epoch 13.074), train_loss = 1.62768592, grad/param norm = 4.4857e-01, time/batch = 0.1785s	
707/2700 (epoch 13.093), train_loss = 1.63320903, grad/param norm = 4.5039e-01, time/batch = 0.1778s	
708/2700 (epoch 13.111), train_loss = 1.60000825, grad/param norm = 4.9834e-01, time/batch = 0.1803s	
709/2700 (epoch 13.130), train_loss = 1.66429614, grad/param norm = 4.9612e-01, time/batch = 0.1751s	
710/2700 (epoch 13.148), train_loss = 1.62215861, grad/param norm = 4.7033e-01, time/batch = 0.1654s	
711/2700 (epoch 13.167), train_loss = 1.69688142, grad/param norm = 5.0364e-01, time/batch = 0.1667s	
712/2700 (epoch 13.185), train_loss = 1.61317403, grad/param norm = 4.7693e-01, time/batch = 0.1757s	
713/2700 (epoch 13.204), train_loss = 1.64709984, grad/param norm = 4.7610e-01, time/batch = 0.1803s	
714/2700 (epoch 13.222), train_loss = 1.61518754, grad/param norm = 5.4722e-01, time/batch = 0.1810s	
715/2700 (epoch 13.241), train_loss = 1.53372520, grad/param norm = 5.4628e-01, time/batch = 0.1804s	
716/2700 (epoch 13.259), train_loss = 1.59459750, grad/param norm = 4.8173e-01, time/batch = 0.1803s	
717/2700 (epoch 13.278), train_loss = 1.66219921, grad/param norm = 5.0426e-01, time/batch = 0.1784s	
718/2700 (epoch 13.296), train_loss = 1.65594420, grad/param norm = 5.1473e-01, time/batch = 0.1765s	
719/2700 (epoch 13.315), train_loss = 1.65155679, grad/param norm = 5.1254e-01, time/batch = 0.1748s	
720/2700 (epoch 13.333), train_loss = 1.66389520, grad/param norm = 5.1781e-01, time/batch = 0.1582s	
721/2700 (epoch 13.352), train_loss = 1.66466704, grad/param norm = 5.3555e-01, time/batch = 0.1718s	
722/2700 (epoch 13.370), train_loss = 1.69332859, grad/param norm = 5.8439e-01, time/batch = 0.1393s	
723/2700 (epoch 13.389), train_loss = 1.65876453, grad/param norm = 6.8331e-01, time/batch = 0.1569s	
724/2700 (epoch 13.407), train_loss = 1.68556409, grad/param norm = 5.6317e-01, time/batch = 0.1646s	
725/2700 (epoch 13.426), train_loss = 1.72200994, grad/param norm = 5.6485e-01, time/batch = 0.1713s	
726/2700 (epoch 13.444), train_loss = 1.62274978, grad/param norm = 4.9478e-01, time/batch = 0.1749s	
727/2700 (epoch 13.463), train_loss = 1.68324675, grad/param norm = 4.5933e-01, time/batch = 0.1776s	
728/2700 (epoch 13.481), train_loss = 1.67169173, grad/param norm = 4.5527e-01, time/batch = 0.1779s	
729/2700 (epoch 13.500), train_loss = 1.64305939, grad/param norm = 4.7119e-01, time/batch = 0.1793s	
730/2700 (epoch 13.519), train_loss = 1.66967729, grad/param norm = 5.0015e-01, time/batch = 0.1808s	
731/2700 (epoch 13.537), train_loss = 1.68540018, grad/param norm = 5.4683e-01, time/batch = 0.1555s	
732/2700 (epoch 13.556), train_loss = 1.59683222, grad/param norm = 4.9698e-01, time/batch = 0.1311s	
733/2700 (epoch 13.574), train_loss = 1.60236619, grad/param norm = 5.0034e-01, time/batch = 0.1611s	
734/2700 (epoch 13.593), train_loss = 1.62462748, grad/param norm = 5.3955e-01, time/batch = 0.1606s	
735/2700 (epoch 13.611), train_loss = 1.54615516, grad/param norm = 5.6437e-01, time/batch = 0.1516s	
736/2700 (epoch 13.630), train_loss = 1.57978406, grad/param norm = 5.1658e-01, time/batch = 0.1389s	
737/2700 (epoch 13.648), train_loss = 1.60945268, grad/param norm = 4.9901e-01, time/batch = 0.1433s	
738/2700 (epoch 13.667), train_loss = 1.58956511, grad/param norm = 4.7728e-01, time/batch = 0.1560s	
739/2700 (epoch 13.685), train_loss = 1.61653870, grad/param norm = 5.0474e-01, time/batch = 0.1624s	
740/2700 (epoch 13.704), train_loss = 1.64402307, grad/param norm = 4.8589e-01, time/batch = 0.1601s	
741/2700 (epoch 13.722), train_loss = 1.59925421, grad/param norm = 4.2216e-01, time/batch = 0.1424s	
742/2700 (epoch 13.741), train_loss = 1.64080133, grad/param norm = 4.3080e-01, time/batch = 0.1519s	
743/2700 (epoch 13.759), train_loss = 1.64870738, grad/param norm = 4.6041e-01, time/batch = 0.1500s	
744/2700 (epoch 13.778), train_loss = 1.68581984, grad/param norm = 4.9482e-01, time/batch = 0.1584s	
745/2700 (epoch 13.796), train_loss = 1.62650965, grad/param norm = 5.2144e-01, time/batch = 0.1486s	
746/2700 (epoch 13.815), train_loss = 1.69194436, grad/param norm = 5.7991e-01, time/batch = 0.1395s	
747/2700 (epoch 13.833), train_loss = 1.64220384, grad/param norm = 5.7476e-01, time/batch = 0.1457s	
748/2700 (epoch 13.852), train_loss = 1.64236900, grad/param norm = 5.2182e-01, time/batch = 0.1552s	
749/2700 (epoch 13.870), train_loss = 1.63474524, grad/param norm = 4.5668e-01, time/batch = 0.1658s	
750/2700 (epoch 13.889), train_loss = 1.62617328, grad/param norm = 4.9395e-01, time/batch = 0.1671s	
751/2700 (epoch 13.907), train_loss = 1.74553112, grad/param norm = 5.6381e-01, time/batch = 0.1517s	
752/2700 (epoch 13.926), train_loss = 1.67832737, grad/param norm = 5.6933e-01, time/batch = 0.1663s	
753/2700 (epoch 13.944), train_loss = 1.66367827, grad/param norm = 5.4322e-01, time/batch = 0.1629s	
754/2700 (epoch 13.963), train_loss = 1.67029808, grad/param norm = 5.7467e-01, time/batch = 0.1566s	
755/2700 (epoch 13.981), train_loss = 1.64425788, grad/param norm = 5.4780e-01, time/batch = 0.1727s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
756/2700 (epoch 14.000), train_loss = 1.71303560, grad/param norm = 4.8810e-01, time/batch = 0.1724s	
757/2700 (epoch 14.019), train_loss = 1.67789494, grad/param norm = 4.9234e-01, time/batch = 0.1702s	
758/2700 (epoch 14.037), train_loss = 1.69733325, grad/param norm = 4.9546e-01, time/batch = 0.1632s	
759/2700 (epoch 14.056), train_loss = 1.60981055, grad/param norm = 4.8247e-01, time/batch = 0.1656s	
760/2700 (epoch 14.074), train_loss = 1.59236007, grad/param norm = 4.5368e-01, time/batch = 0.1578s	
761/2700 (epoch 14.093), train_loss = 1.59842732, grad/param norm = 4.5752e-01, time/batch = 0.1608s	
762/2700 (epoch 14.111), train_loss = 1.56455499, grad/param norm = 5.0277e-01, time/batch = 0.1748s	
763/2700 (epoch 14.130), train_loss = 1.62803410, grad/param norm = 4.8228e-01, time/batch = 0.1642s	
764/2700 (epoch 14.148), train_loss = 1.58748418, grad/param norm = 4.6536e-01, time/batch = 0.1595s	
765/2700 (epoch 14.167), train_loss = 1.65478896, grad/param norm = 4.7531e-01, time/batch = 0.1427s	
766/2700 (epoch 14.185), train_loss = 1.57510414, grad/param norm = 4.5371e-01, time/batch = 0.1792s	
767/2700 (epoch 14.204), train_loss = 1.61807273, grad/param norm = 4.9417e-01, time/batch = 0.1803s	
768/2700 (epoch 14.222), train_loss = 1.58267420, grad/param norm = 5.3952e-01, time/batch = 0.1803s	
769/2700 (epoch 14.241), train_loss = 1.50364934, grad/param norm = 5.4114e-01, time/batch = 0.1826s	
770/2700 (epoch 14.259), train_loss = 1.56213929, grad/param norm = 4.7403e-01, time/batch = 0.1810s	
771/2700 (epoch 14.278), train_loss = 1.62162263, grad/param norm = 4.6079e-01, time/batch = 0.1719s	
772/2700 (epoch 14.296), train_loss = 1.61076319, grad/param norm = 4.6711e-01, time/batch = 0.1566s	
773/2700 (epoch 14.315), train_loss = 1.60865627, grad/param norm = 4.5279e-01, time/batch = 0.1550s	
774/2700 (epoch 14.333), train_loss = 1.61842467, grad/param norm = 4.8892e-01, time/batch = 0.1445s	
775/2700 (epoch 14.352), train_loss = 1.62282815, grad/param norm = 4.9537e-01, time/batch = 0.1690s	
776/2700 (epoch 14.370), train_loss = 1.63594049, grad/param norm = 5.0419e-01, time/batch = 0.1536s	
777/2700 (epoch 14.389), train_loss = 1.59878185, grad/param norm = 4.8254e-01, time/batch = 0.1479s	
778/2700 (epoch 14.407), train_loss = 1.63748091, grad/param norm = 4.8927e-01, time/batch = 0.1489s	
779/2700 (epoch 14.426), train_loss = 1.67505743, grad/param norm = 4.6698e-01, time/batch = 0.1531s	
780/2700 (epoch 14.444), train_loss = 1.59176254, grad/param norm = 4.7081e-01, time/batch = 0.1654s	
781/2700 (epoch 14.463), train_loss = 1.66269773, grad/param norm = 5.4610e-01, time/batch = 0.1587s	
782/2700 (epoch 14.481), train_loss = 1.64433391, grad/param norm = 5.3568e-01, time/batch = 0.1693s	
783/2700 (epoch 14.500), train_loss = 1.60331982, grad/param norm = 4.7337e-01, time/batch = 0.1734s	
784/2700 (epoch 14.519), train_loss = 1.62835433, grad/param norm = 4.2021e-01, time/batch = 0.1621s	
785/2700 (epoch 14.537), train_loss = 1.63247204, grad/param norm = 4.5423e-01, time/batch = 0.1745s	
786/2700 (epoch 14.556), train_loss = 1.55672762, grad/param norm = 4.8641e-01, time/batch = 0.1638s	
787/2700 (epoch 14.574), train_loss = 1.57233670, grad/param norm = 5.3174e-01, time/batch = 0.1778s	
788/2700 (epoch 14.593), train_loss = 1.60442136, grad/param norm = 5.3772e-01, time/batch = 0.1710s	
789/2700 (epoch 14.611), train_loss = 1.50585088, grad/param norm = 4.6351e-01, time/batch = 0.1661s	
790/2700 (epoch 14.630), train_loss = 1.53950138, grad/param norm = 5.1765e-01, time/batch = 0.1560s	
791/2700 (epoch 14.648), train_loss = 1.59226078, grad/param norm = 5.8316e-01, time/batch = 0.1810s	
792/2700 (epoch 14.667), train_loss = 1.56773951, grad/param norm = 5.3896e-01, time/batch = 0.1786s	
793/2700 (epoch 14.685), train_loss = 1.59885435, grad/param norm = 5.6530e-01, time/batch = 0.1783s	
794/2700 (epoch 14.704), train_loss = 1.63726170, grad/param norm = 6.4201e-01, time/batch = 0.1678s	
795/2700 (epoch 14.722), train_loss = 1.59599026, grad/param norm = 5.4943e-01, time/batch = 0.1753s	
796/2700 (epoch 14.741), train_loss = 1.61873007, grad/param norm = 4.8913e-01, time/batch = 0.1692s	
797/2700 (epoch 14.759), train_loss = 1.61952914, grad/param norm = 5.0611e-01, time/batch = 0.1435s	
798/2700 (epoch 14.778), train_loss = 1.65842870, grad/param norm = 5.6669e-01, time/batch = 0.1791s	
799/2700 (epoch 14.796), train_loss = 1.59438537, grad/param norm = 5.1148e-01, time/batch = 0.1776s	
800/2700 (epoch 14.815), train_loss = 1.63763627, grad/param norm = 4.7397e-01, time/batch = 0.1666s	
801/2700 (epoch 14.833), train_loss = 1.58527904, grad/param norm = 4.7738e-01, time/batch = 0.1740s	
802/2700 (epoch 14.852), train_loss = 1.59894711, grad/param norm = 4.8667e-01, time/batch = 0.1678s	
803/2700 (epoch 14.870), train_loss = 1.60527626, grad/param norm = 4.6777e-01, time/batch = 0.1632s	
804/2700 (epoch 14.889), train_loss = 1.58990885, grad/param norm = 4.4354e-01, time/batch = 0.1587s	
805/2700 (epoch 14.907), train_loss = 1.69761181, grad/param norm = 4.5755e-01, time/batch = 0.1484s	
806/2700 (epoch 14.926), train_loss = 1.62894608, grad/param norm = 4.8473e-01, time/batch = 0.1621s	
807/2700 (epoch 14.944), train_loss = 1.61559243, grad/param norm = 4.7067e-01, time/batch = 0.1440s	
808/2700 (epoch 14.963), train_loss = 1.62102554, grad/param norm = 4.7406e-01, time/batch = 0.1438s	
809/2700 (epoch 14.981), train_loss = 1.59393044, grad/param norm = 4.8614e-01, time/batch = 0.1441s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
810/2700 (epoch 15.000), train_loss = 1.67752944, grad/param norm = 4.6979e-01, time/batch = 0.1387s	
811/2700 (epoch 15.019), train_loss = 1.64409978, grad/param norm = 4.7775e-01, time/batch = 0.1342s	
812/2700 (epoch 15.037), train_loss = 1.66006785, grad/param norm = 4.6496e-01, time/batch = 0.1462s	
813/2700 (epoch 15.056), train_loss = 1.57014904, grad/param norm = 4.5586e-01, time/batch = 0.1600s	
814/2700 (epoch 15.074), train_loss = 1.55870331, grad/param norm = 4.3969e-01, time/batch = 0.1715s	
815/2700 (epoch 15.093), train_loss = 1.56322813, grad/param norm = 4.4870e-01, time/batch = 0.1666s	
816/2700 (epoch 15.111), train_loss = 1.53034371, grad/param norm = 4.6897e-01, time/batch = 0.1765s	
817/2700 (epoch 15.130), train_loss = 1.59562271, grad/param norm = 4.6080e-01, time/batch = 0.1773s	
818/2700 (epoch 15.148), train_loss = 1.55573110, grad/param norm = 4.4319e-01, time/batch = 0.1667s	
819/2700 (epoch 15.167), train_loss = 1.61612508, grad/param norm = 4.5151e-01, time/batch = 0.1793s	
820/2700 (epoch 15.185), train_loss = 1.54374966, grad/param norm = 4.4118e-01, time/batch = 0.1767s	
821/2700 (epoch 15.204), train_loss = 1.59282680, grad/param norm = 5.1824e-01, time/batch = 0.1825s	
822/2700 (epoch 15.222), train_loss = 1.55564431, grad/param norm = 5.3097e-01, time/batch = 0.1787s	
823/2700 (epoch 15.241), train_loss = 1.47734341, grad/param norm = 5.4386e-01, time/batch = 0.1797s	
824/2700 (epoch 15.259), train_loss = 1.54240708, grad/param norm = 5.4459e-01, time/batch = 0.1779s	
825/2700 (epoch 15.278), train_loss = 1.60429687, grad/param norm = 5.1977e-01, time/batch = 0.1681s	
826/2700 (epoch 15.296), train_loss = 1.58019467, grad/param norm = 4.6811e-01, time/batch = 0.1782s	
827/2700 (epoch 15.315), train_loss = 1.57069790, grad/param norm = 4.3074e-01, time/batch = 0.1774s	
828/2700 (epoch 15.333), train_loss = 1.57912331, grad/param norm = 4.4384e-01, time/batch = 0.1744s	
829/2700 (epoch 15.352), train_loss = 1.58125850, grad/param norm = 4.7285e-01, time/batch = 0.1438s	
830/2700 (epoch 15.370), train_loss = 1.60767513, grad/param norm = 5.2636e-01, time/batch = 0.1605s	
831/2700 (epoch 15.389), train_loss = 1.56304162, grad/param norm = 5.0102e-01, time/batch = 0.1775s	
832/2700 (epoch 15.407), train_loss = 1.60487835, grad/param norm = 5.1294e-01, time/batch = 0.1749s	
833/2700 (epoch 15.426), train_loss = 1.65327167, grad/param norm = 5.2672e-01, time/batch = 0.1677s	
834/2700 (epoch 15.444), train_loss = 1.56924210, grad/param norm = 4.9399e-01, time/batch = 0.1608s	
835/2700 (epoch 15.463), train_loss = 1.62193140, grad/param norm = 4.8503e-01, time/batch = 0.1519s	
836/2700 (epoch 15.481), train_loss = 1.59911015, grad/param norm = 4.4845e-01, time/batch = 0.1493s	
837/2700 (epoch 15.500), train_loss = 1.56566724, grad/param norm = 4.3200e-01, time/batch = 0.1577s	
838/2700 (epoch 15.519), train_loss = 1.60523185, grad/param norm = 4.4646e-01, time/batch = 0.1584s	
839/2700 (epoch 15.537), train_loss = 1.61037204, grad/param norm = 5.1145e-01, time/batch = 0.1409s	
840/2700 (epoch 15.556), train_loss = 1.52757746, grad/param norm = 5.0447e-01, time/batch = 0.1576s	
841/2700 (epoch 15.574), train_loss = 1.54720440, grad/param norm = 5.5801e-01, time/batch = 0.1792s	
842/2700 (epoch 15.593), train_loss = 1.58040439, grad/param norm = 5.7912e-01, time/batch = 0.1771s	
843/2700 (epoch 15.611), train_loss = 1.49294120, grad/param norm = 5.4724e-01, time/batch = 0.1752s	
844/2700 (epoch 15.630), train_loss = 1.50867072, grad/param norm = 5.0090e-01, time/batch = 0.1707s	
845/2700 (epoch 15.648), train_loss = 1.54971509, grad/param norm = 4.7254e-01, time/batch = 0.1639s	
846/2700 (epoch 15.667), train_loss = 1.52318608, grad/param norm = 4.7167e-01, time/batch = 0.1667s	
847/2700 (epoch 15.685), train_loss = 1.56922059, grad/param norm = 5.3050e-01, time/batch = 0.1706s	
848/2700 (epoch 15.704), train_loss = 1.59220576, grad/param norm = 5.1490e-01, time/batch = 0.1716s	
849/2700 (epoch 15.722), train_loss = 1.54691747, grad/param norm = 4.4555e-01, time/batch = 0.1457s	
850/2700 (epoch 15.741), train_loss = 1.57767944, grad/param norm = 4.6298e-01, time/batch = 0.1167s	
851/2700 (epoch 15.759), train_loss = 1.57641675, grad/param norm = 4.7947e-01, time/batch = 0.1775s	
852/2700 (epoch 15.778), train_loss = 1.61568861, grad/param norm = 4.4909e-01, time/batch = 0.1782s	
853/2700 (epoch 15.796), train_loss = 1.55137964, grad/param norm = 4.8830e-01, time/batch = 0.1785s	
854/2700 (epoch 15.815), train_loss = 1.61362602, grad/param norm = 4.8143e-01, time/batch = 0.1794s	
855/2700 (epoch 15.833), train_loss = 1.55620777, grad/param norm = 4.8778e-01, time/batch = 0.1724s	
856/2700 (epoch 15.852), train_loss = 1.57099091, grad/param norm = 5.0770e-01, time/batch = 0.1671s	
857/2700 (epoch 15.870), train_loss = 1.57608831, grad/param norm = 4.8645e-01, time/batch = 0.1636s	
858/2700 (epoch 15.889), train_loss = 1.56146684, grad/param norm = 4.4277e-01, time/batch = 0.1560s	
859/2700 (epoch 15.907), train_loss = 1.66287001, grad/param norm = 4.4645e-01, time/batch = 0.1587s	
860/2700 (epoch 15.926), train_loss = 1.60286729, grad/param norm = 4.9420e-01, time/batch = 0.1578s	
861/2700 (epoch 15.944), train_loss = 1.58399540, grad/param norm = 4.9634e-01, time/batch = 0.1796s	
862/2700 (epoch 15.963), train_loss = 1.59655158, grad/param norm = 4.9497e-01, time/batch = 0.1746s	
863/2700 (epoch 15.981), train_loss = 1.56951731, grad/param norm = 5.2636e-01, time/batch = 0.1741s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
864/2700 (epoch 16.000), train_loss = 1.66565788, grad/param norm = 5.2364e-01, time/batch = 0.1701s	
865/2700 (epoch 16.019), train_loss = 1.62403382, grad/param norm = 5.2423e-01, time/batch = 0.1617s	
866/2700 (epoch 16.037), train_loss = 1.63138734, grad/param norm = 4.9128e-01, time/batch = 0.1606s	
867/2700 (epoch 16.056), train_loss = 1.54178793, grad/param norm = 4.8785e-01, time/batch = 0.1486s	
868/2700 (epoch 16.074), train_loss = 1.53116069, grad/param norm = 4.3878e-01, time/batch = 0.1268s	
869/2700 (epoch 16.093), train_loss = 1.52916671, grad/param norm = 4.1917e-01, time/batch = 0.1374s	
870/2700 (epoch 16.111), train_loss = 1.49054096, grad/param norm = 4.3534e-01, time/batch = 0.1482s	
871/2700 (epoch 16.130), train_loss = 1.56082122, grad/param norm = 4.3509e-01, time/batch = 0.1455s	
872/2700 (epoch 16.148), train_loss = 1.52395712, grad/param norm = 4.5485e-01, time/batch = 0.1759s	
873/2700 (epoch 16.167), train_loss = 1.58796920, grad/param norm = 4.7486e-01, time/batch = 0.1766s	
874/2700 (epoch 16.185), train_loss = 1.52201593, grad/param norm = 4.7617e-01, time/batch = 0.1744s	
875/2700 (epoch 16.204), train_loss = 1.55821325, grad/param norm = 4.7512e-01, time/batch = 0.1721s	
876/2700 (epoch 16.222), train_loss = 1.52418372, grad/param norm = 4.9473e-01, time/batch = 0.1514s	
877/2700 (epoch 16.241), train_loss = 1.44267658, grad/param norm = 4.8322e-01, time/batch = 0.1787s	
878/2700 (epoch 16.259), train_loss = 1.50690644, grad/param norm = 4.5791e-01, time/batch = 0.1721s	
879/2700 (epoch 16.278), train_loss = 1.56258042, grad/param norm = 4.6164e-01, time/batch = 0.1741s	
880/2700 (epoch 16.296), train_loss = 1.54749429, grad/param norm = 4.5377e-01, time/batch = 0.1685s	
881/2700 (epoch 16.315), train_loss = 1.54142602, grad/param norm = 4.3908e-01, time/batch = 0.1647s	
882/2700 (epoch 16.333), train_loss = 1.54861577, grad/param norm = 4.5164e-01, time/batch = 0.1493s	
883/2700 (epoch 16.352), train_loss = 1.54526077, grad/param norm = 4.6254e-01, time/batch = 0.1501s	
884/2700 (epoch 16.370), train_loss = 1.56745600, grad/param norm = 4.9238e-01, time/batch = 0.1618s	
885/2700 (epoch 16.389), train_loss = 1.52484807, grad/param norm = 4.7383e-01, time/batch = 0.1673s	
886/2700 (epoch 16.407), train_loss = 1.57555765, grad/param norm = 5.1901e-01, time/batch = 0.1645s	
887/2700 (epoch 16.426), train_loss = 1.62318127, grad/param norm = 4.8965e-01, time/batch = 0.1787s	
888/2700 (epoch 16.444), train_loss = 1.54313976, grad/param norm = 5.0602e-01, time/batch = 0.1689s	
889/2700 (epoch 16.463), train_loss = 1.60490093, grad/param norm = 5.5621e-01, time/batch = 0.1787s	
890/2700 (epoch 16.481), train_loss = 1.58309194, grad/param norm = 5.2817e-01, time/batch = 0.1780s	
891/2700 (epoch 16.500), train_loss = 1.54341351, grad/param norm = 5.1308e-01, time/batch = 0.1672s	
892/2700 (epoch 16.519), train_loss = 1.58192095, grad/param norm = 4.8132e-01, time/batch = 0.1585s	
893/2700 (epoch 16.537), train_loss = 1.57671527, grad/param norm = 5.0123e-01, time/batch = 0.1725s	
894/2700 (epoch 16.556), train_loss = 1.49496098, grad/param norm = 4.7584e-01, time/batch = 0.1680s	
895/2700 (epoch 16.574), train_loss = 1.50619216, grad/param norm = 4.9276e-01, time/batch = 0.1656s	
896/2700 (epoch 16.593), train_loss = 1.54013510, grad/param norm = 5.0336e-01, time/batch = 0.1596s	
897/2700 (epoch 16.611), train_loss = 1.45045537, grad/param norm = 4.5706e-01, time/batch = 0.1774s	
898/2700 (epoch 16.630), train_loss = 1.47312370, grad/param norm = 4.7594e-01, time/batch = 0.1624s	
899/2700 (epoch 16.648), train_loss = 1.52360471, grad/param norm = 5.1199e-01, time/batch = 0.1791s	
900/2700 (epoch 16.667), train_loss = 1.49384090, grad/param norm = 4.8338e-01, time/batch = 0.1702s	
901/2700 (epoch 16.685), train_loss = 1.53748274, grad/param norm = 5.1612e-01, time/batch = 0.1700s	
902/2700 (epoch 16.704), train_loss = 1.57338747, grad/param norm = 5.8003e-01, time/batch = 0.1679s	
903/2700 (epoch 16.722), train_loss = 1.52655739, grad/param norm = 4.9646e-01, time/batch = 0.1571s	
904/2700 (epoch 16.741), train_loss = 1.55142032, grad/param norm = 4.8012e-01, time/batch = 0.1505s	
905/2700 (epoch 16.759), train_loss = 1.55377260, grad/param norm = 5.0067e-01, time/batch = 0.1613s	
906/2700 (epoch 16.778), train_loss = 1.59533004, grad/param norm = 5.1744e-01, time/batch = 0.1758s	
907/2700 (epoch 16.796), train_loss = 1.52752820, grad/param norm = 5.1088e-01, time/batch = 0.1506s	
908/2700 (epoch 16.815), train_loss = 1.58574846, grad/param norm = 5.2198e-01, time/batch = 0.1496s	
909/2700 (epoch 16.833), train_loss = 1.53755506, grad/param norm = 5.0369e-01, time/batch = 0.1570s	
910/2700 (epoch 16.852), train_loss = 1.53618764, grad/param norm = 4.9081e-01, time/batch = 0.1624s	
911/2700 (epoch 16.870), train_loss = 1.54827919, grad/param norm = 4.4223e-01, time/batch = 0.1579s	
912/2700 (epoch 16.889), train_loss = 1.52453018, grad/param norm = 4.2854e-01, time/batch = 0.1580s	
913/2700 (epoch 16.907), train_loss = 1.62980404, grad/param norm = 4.7165e-01, time/batch = 0.1486s	
914/2700 (epoch 16.926), train_loss = 1.56434936, grad/param norm = 4.8277e-01, time/batch = 0.1562s	
915/2700 (epoch 16.944), train_loss = 1.54879251, grad/param norm = 4.6315e-01, time/batch = 0.1535s	
916/2700 (epoch 16.963), train_loss = 1.56161232, grad/param norm = 4.9038e-01, time/batch = 0.1520s	
917/2700 (epoch 16.981), train_loss = 1.53024935, grad/param norm = 5.1818e-01, time/batch = 0.1499s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
918/2700 (epoch 17.000), train_loss = 1.64753602, grad/param norm = 5.8219e-01, time/batch = 0.1514s	
919/2700 (epoch 17.019), train_loss = 1.60268073, grad/param norm = 4.9484e-01, time/batch = 0.1651s	
920/2700 (epoch 17.037), train_loss = 1.60009330, grad/param norm = 4.6119e-01, time/batch = 0.1761s	
921/2700 (epoch 17.056), train_loss = 1.51026036, grad/param norm = 4.5966e-01, time/batch = 0.1673s	
922/2700 (epoch 17.074), train_loss = 1.50284707, grad/param norm = 4.4187e-01, time/batch = 0.1739s	
923/2700 (epoch 17.093), train_loss = 1.49897306, grad/param norm = 4.3416e-01, time/batch = 0.1771s	
924/2700 (epoch 17.111), train_loss = 1.46792677, grad/param norm = 4.6517e-01, time/batch = 0.1733s	
925/2700 (epoch 17.130), train_loss = 1.54332830, grad/param norm = 4.7652e-01, time/batch = 0.1798s	
926/2700 (epoch 17.148), train_loss = 1.49869951, grad/param norm = 4.7119e-01, time/batch = 0.1821s	
927/2700 (epoch 17.167), train_loss = 1.55834047, grad/param norm = 4.5222e-01, time/batch = 0.1703s	
928/2700 (epoch 17.185), train_loss = 1.48495785, grad/param norm = 4.2163e-01, time/batch = 0.1749s	
929/2700 (epoch 17.204), train_loss = 1.52245521, grad/param norm = 4.3558e-01, time/batch = 0.1679s	
930/2700 (epoch 17.222), train_loss = 1.48926676, grad/param norm = 4.4494e-01, time/batch = 0.1670s	
931/2700 (epoch 17.241), train_loss = 1.41519335, grad/param norm = 4.6009e-01, time/batch = 0.1690s	
932/2700 (epoch 17.259), train_loss = 1.48329801, grad/param norm = 5.0363e-01, time/batch = 0.1683s	
933/2700 (epoch 17.278), train_loss = 1.53990506, grad/param norm = 4.8530e-01, time/batch = 0.1633s	
934/2700 (epoch 17.296), train_loss = 1.51682291, grad/param norm = 4.5310e-01, time/batch = 0.1630s	
935/2700 (epoch 17.315), train_loss = 1.50912721, grad/param norm = 4.3954e-01, time/batch = 0.1359s	
936/2700 (epoch 17.333), train_loss = 1.52309594, grad/param norm = 4.6732e-01, time/batch = 0.1271s	
937/2700 (epoch 17.352), train_loss = 1.52949388, grad/param norm = 5.1622e-01, time/batch = 0.0941s	
938/2700 (epoch 17.370), train_loss = 1.54809500, grad/param norm = 5.2481e-01, time/batch = 0.1338s	
939/2700 (epoch 17.389), train_loss = 1.49677004, grad/param norm = 4.8363e-01, time/batch = 0.1628s	
940/2700 (epoch 17.407), train_loss = 1.54313920, grad/param norm = 4.5902e-01, time/batch = 0.1682s	
941/2700 (epoch 17.426), train_loss = 1.58404922, grad/param norm = 4.4255e-01, time/batch = 0.1681s	
942/2700 (epoch 17.444), train_loss = 1.50024480, grad/param norm = 4.2891e-01, time/batch = 0.1603s	
943/2700 (epoch 17.463), train_loss = 1.55443868, grad/param norm = 4.3418e-01, time/batch = 0.1578s	
944/2700 (epoch 17.481), train_loss = 1.53686181, grad/param norm = 4.5497e-01, time/batch = 0.1655s	
945/2700 (epoch 17.500), train_loss = 1.50747411, grad/param norm = 4.8593e-01, time/batch = 0.1703s	
946/2700 (epoch 17.519), train_loss = 1.55825246, grad/param norm = 5.0400e-01, time/batch = 0.1719s	
947/2700 (epoch 17.537), train_loss = 1.55600168, grad/param norm = 5.3498e-01, time/batch = 0.1641s	
948/2700 (epoch 17.556), train_loss = 1.46642535, grad/param norm = 4.8491e-01, time/batch = 0.1592s	
949/2700 (epoch 17.574), train_loss = 1.47942519, grad/param norm = 5.0886e-01, time/batch = 0.1501s	
950/2700 (epoch 17.593), train_loss = 1.51660169, grad/param norm = 5.3940e-01, time/batch = 0.1688s	
951/2700 (epoch 17.611), train_loss = 1.43685247, grad/param norm = 5.4319e-01, time/batch = 0.1589s	
952/2700 (epoch 17.630), train_loss = 1.44975770, grad/param norm = 4.8556e-01, time/batch = 0.1516s	
953/2700 (epoch 17.648), train_loss = 1.49487718, grad/param norm = 4.8802e-01, time/batch = 0.1462s	
954/2700 (epoch 17.667), train_loss = 1.46161137, grad/param norm = 4.7159e-01, time/batch = 0.1478s	
955/2700 (epoch 17.685), train_loss = 1.50898085, grad/param norm = 5.0904e-01, time/batch = 0.1597s	
956/2700 (epoch 17.704), train_loss = 1.53380563, grad/param norm = 4.9244e-01, time/batch = 0.1670s	
957/2700 (epoch 17.722), train_loss = 1.49114886, grad/param norm = 4.4749e-01, time/batch = 0.1589s	
958/2700 (epoch 17.741), train_loss = 1.52493245, grad/param norm = 5.0107e-01, time/batch = 0.1739s	
959/2700 (epoch 17.759), train_loss = 1.51445956, grad/param norm = 4.8707e-01, time/batch = 0.1592s	
960/2700 (epoch 17.778), train_loss = 1.56250866, grad/param norm = 4.7396e-01, time/batch = 0.1473s	
961/2700 (epoch 17.796), train_loss = 1.50978553, grad/param norm = 5.7049e-01, time/batch = 0.1791s	
962/2700 (epoch 17.815), train_loss = 1.56769982, grad/param norm = 5.1767e-01, time/batch = 0.1789s	
963/2700 (epoch 17.833), train_loss = 1.49784548, grad/param norm = 4.7034e-01, time/batch = 0.1773s	
964/2700 (epoch 17.852), train_loss = 1.50387080, grad/param norm = 4.8311e-01, time/batch = 0.1800s	
965/2700 (epoch 17.870), train_loss = 1.51901637, grad/param norm = 4.5189e-01, time/batch = 0.1759s	
966/2700 (epoch 17.889), train_loss = 1.49880886, grad/param norm = 4.2297e-01, time/batch = 0.1736s	
967/2700 (epoch 17.907), train_loss = 1.59471008, grad/param norm = 4.4556e-01, time/batch = 0.1803s	
968/2700 (epoch 17.926), train_loss = 1.53239408, grad/param norm = 4.6432e-01, time/batch = 0.1797s	
969/2700 (epoch 17.944), train_loss = 1.51695781, grad/param norm = 4.5549e-01, time/batch = 0.1716s	
970/2700 (epoch 17.963), train_loss = 1.52838358, grad/param norm = 4.5426e-01, time/batch = 0.1477s	
971/2700 (epoch 17.981), train_loss = 1.49030080, grad/param norm = 4.7731e-01, time/batch = 0.1579s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
972/2700 (epoch 18.000), train_loss = 1.60041322, grad/param norm = 4.9111e-01, time/batch = 0.1565s	
973/2700 (epoch 18.019), train_loss = 1.57064423, grad/param norm = 5.0640e-01, time/batch = 0.1577s	
974/2700 (epoch 18.037), train_loss = 1.57517390, grad/param norm = 4.8697e-01, time/batch = 0.1552s	
975/2700 (epoch 18.056), train_loss = 1.48541960, grad/param norm = 4.7800e-01, time/batch = 0.1600s	
976/2700 (epoch 18.074), train_loss = 1.47826401, grad/param norm = 4.4586e-01, time/batch = 0.1539s	
977/2700 (epoch 18.093), train_loss = 1.47893915, grad/param norm = 4.7166e-01, time/batch = 0.1623s	
978/2700 (epoch 18.111), train_loss = 1.44359565, grad/param norm = 4.7567e-01, time/batch = 0.1632s	
979/2700 (epoch 18.130), train_loss = 1.51759987, grad/param norm = 4.7944e-01, time/batch = 0.1652s	
980/2700 (epoch 18.148), train_loss = 1.47596703, grad/param norm = 4.6675e-01, time/batch = 0.1533s	
981/2700 (epoch 18.167), train_loss = 1.52904494, grad/param norm = 4.4918e-01, time/batch = 0.1632s	
982/2700 (epoch 18.185), train_loss = 1.45695818, grad/param norm = 4.2221e-01, time/batch = 0.1573s	
983/2700 (epoch 18.204), train_loss = 1.50583650, grad/param norm = 4.7361e-01, time/batch = 0.1537s	
984/2700 (epoch 18.222), train_loss = 1.46945905, grad/param norm = 4.8269e-01, time/batch = 0.1580s	
985/2700 (epoch 18.241), train_loss = 1.39199567, grad/param norm = 4.6045e-01, time/batch = 0.1570s	
986/2700 (epoch 18.259), train_loss = 1.44697644, grad/param norm = 4.3864e-01, time/batch = 0.1419s	
987/2700 (epoch 18.278), train_loss = 1.50432322, grad/param norm = 4.3993e-01, time/batch = 0.1445s	
988/2700 (epoch 18.296), train_loss = 1.48477046, grad/param norm = 4.3851e-01, time/batch = 0.1619s	
989/2700 (epoch 18.315), train_loss = 1.48438663, grad/param norm = 5.3585e-01, time/batch = 0.1705s	
990/2700 (epoch 18.333), train_loss = 1.50563998, grad/param norm = 4.8421e-01, time/batch = 0.1641s	
991/2700 (epoch 18.352), train_loss = 1.48786047, grad/param norm = 4.7172e-01, time/batch = 0.1578s	
992/2700 (epoch 18.370), train_loss = 1.51149141, grad/param norm = 5.0400e-01, time/batch = 0.1809s	
993/2700 (epoch 18.389), train_loss = 1.46399148, grad/param norm = 4.8228e-01, time/batch = 0.1800s	
994/2700 (epoch 18.407), train_loss = 1.51731832, grad/param norm = 4.7791e-01, time/batch = 0.1797s	
995/2700 (epoch 18.426), train_loss = 1.57732085, grad/param norm = 5.4468e-01, time/batch = 0.1764s	
996/2700 (epoch 18.444), train_loss = 1.49929316, grad/param norm = 5.5735e-01, time/batch = 0.1799s	
997/2700 (epoch 18.463), train_loss = 1.53935405, grad/param norm = 4.9789e-01, time/batch = 0.1792s	
998/2700 (epoch 18.481), train_loss = 1.51972763, grad/param norm = 4.6159e-01, time/batch = 0.1781s	
999/2700 (epoch 18.500), train_loss = 1.47479149, grad/param norm = 4.5492e-01, time/batch = 0.1764s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch18.52_1.7687.t7	
1000/2700 (epoch 18.519), train_loss = 1.52372340, grad/param norm = 4.4817e-01, time/batch = 0.1666s	
1001/2700 (epoch 18.537), train_loss = 1.61365703, grad/param norm = 4.6987e-01, time/batch = 0.1784s	
1002/2700 (epoch 18.556), train_loss = 1.44162622, grad/param norm = 4.8479e-01, time/batch = 0.1654s	
1003/2700 (epoch 18.574), train_loss = 1.45829337, grad/param norm = 4.9714e-01, time/batch = 0.1787s	
1004/2700 (epoch 18.593), train_loss = 1.49989539, grad/param norm = 5.2714e-01, time/batch = 0.1758s	
1005/2700 (epoch 18.611), train_loss = 1.40798723, grad/param norm = 4.7965e-01, time/batch = 0.1715s	
1006/2700 (epoch 18.630), train_loss = 1.41725093, grad/param norm = 4.5508e-01, time/batch = 0.1660s	
1007/2700 (epoch 18.648), train_loss = 1.46671953, grad/param norm = 4.7812e-01, time/batch = 0.1623s	
1008/2700 (epoch 18.667), train_loss = 1.43515317, grad/param norm = 4.6427e-01, time/batch = 0.1490s	
1009/2700 (epoch 18.685), train_loss = 1.48343688, grad/param norm = 5.1217e-01, time/batch = 0.1790s	
1010/2700 (epoch 18.704), train_loss = 1.52106903, grad/param norm = 5.6897e-01, time/batch = 0.1576s	
1011/2700 (epoch 18.722), train_loss = 1.47238884, grad/param norm = 4.8864e-01, time/batch = 0.1405s	
1012/2700 (epoch 18.741), train_loss = 1.49130336, grad/param norm = 4.7074e-01, time/batch = 0.1426s	
1013/2700 (epoch 18.759), train_loss = 1.48272477, grad/param norm = 4.6986e-01, time/batch = 0.1682s	
1014/2700 (epoch 18.778), train_loss = 1.53571310, grad/param norm = 5.4248e-01, time/batch = 0.1696s	
1015/2700 (epoch 18.796), train_loss = 1.47773566, grad/param norm = 5.0029e-01, time/batch = 0.1728s	
1016/2700 (epoch 18.815), train_loss = 1.52244334, grad/param norm = 4.6822e-01, time/batch = 0.1688s	
1017/2700 (epoch 18.833), train_loss = 1.47646916, grad/param norm = 4.9201e-01, time/batch = 0.1643s	
1018/2700 (epoch 18.852), train_loss = 1.48144713, grad/param norm = 5.1665e-01, time/batch = 0.1573s	
1019/2700 (epoch 18.870), train_loss = 1.50109616, grad/param norm = 4.6902e-01, time/batch = 0.1527s	
1020/2700 (epoch 18.889), train_loss = 1.47071965, grad/param norm = 4.4271e-01, time/batch = 0.1502s	
1021/2700 (epoch 18.907), train_loss = 1.57426660, grad/param norm = 4.9170e-01, time/batch = 0.1784s	
1022/2700 (epoch 18.926), train_loss = 1.50951190, grad/param norm = 5.0506e-01, time/batch = 0.1793s	
1023/2700 (epoch 18.944), train_loss = 1.49328058, grad/param norm = 4.7860e-01, time/batch = 0.1801s	
1024/2700 (epoch 18.963), train_loss = 1.50500220, grad/param norm = 4.8665e-01, time/batch = 0.1825s	
1025/2700 (epoch 18.981), train_loss = 1.46591970, grad/param norm = 5.0458e-01, time/batch = 0.1817s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1026/2700 (epoch 19.000), train_loss = 1.58671940, grad/param norm = 5.5278e-01, time/batch = 0.1820s	
1027/2700 (epoch 19.019), train_loss = 1.55295459, grad/param norm = 4.9608e-01, time/batch = 0.1815s	
1028/2700 (epoch 19.037), train_loss = 1.54245844, grad/param norm = 4.6854e-01, time/batch = 0.1709s	
1029/2700 (epoch 19.056), train_loss = 1.45327214, grad/param norm = 4.5649e-01, time/batch = 0.1787s	
1030/2700 (epoch 19.074), train_loss = 1.44857232, grad/param norm = 4.5459e-01, time/batch = 0.1754s	
1031/2700 (epoch 19.093), train_loss = 1.44995889, grad/param norm = 4.6935e-01, time/batch = 0.1581s	
1032/2700 (epoch 19.111), train_loss = 1.42191139, grad/param norm = 4.9060e-01, time/batch = 0.1720s	
1033/2700 (epoch 19.130), train_loss = 1.49792542, grad/param norm = 4.9225e-01, time/batch = 0.1675s	
1034/2700 (epoch 19.148), train_loss = 1.44811885, grad/param norm = 4.6260e-01, time/batch = 0.1727s	
1035/2700 (epoch 19.167), train_loss = 1.50393658, grad/param norm = 4.6298e-01, time/batch = 0.1659s	
1036/2700 (epoch 19.185), train_loss = 1.44011372, grad/param norm = 4.7807e-01, time/batch = 0.1590s	
1037/2700 (epoch 19.204), train_loss = 1.47696429, grad/param norm = 4.7254e-01, time/batch = 0.1493s	
1038/2700 (epoch 19.222), train_loss = 1.43956275, grad/param norm = 4.6340e-01, time/batch = 0.1474s	
1039/2700 (epoch 19.241), train_loss = 1.36340798, grad/param norm = 4.4726e-01, time/batch = 0.1432s	
1040/2700 (epoch 19.259), train_loss = 1.42227460, grad/param norm = 4.4842e-01, time/batch = 0.1509s	
1041/2700 (epoch 19.278), train_loss = 1.48218070, grad/param norm = 4.7109e-01, time/batch = 0.1414s	
1042/2700 (epoch 19.296), train_loss = 1.46404005, grad/param norm = 4.6608e-01, time/batch = 0.1763s	
1043/2700 (epoch 19.315), train_loss = 1.44844698, grad/param norm = 4.5710e-01, time/batch = 0.1761s	
1044/2700 (epoch 19.333), train_loss = 1.46432683, grad/param norm = 4.5557e-01, time/batch = 0.1783s	
1045/2700 (epoch 19.352), train_loss = 1.45678997, grad/param norm = 4.7334e-01, time/batch = 0.1789s	
1046/2700 (epoch 19.370), train_loss = 1.48445971, grad/param norm = 5.2087e-01, time/batch = 0.1808s	
1047/2700 (epoch 19.389), train_loss = 1.45178430, grad/param norm = 5.2276e-01, time/batch = 0.1796s	
1048/2700 (epoch 19.407), train_loss = 1.50718591, grad/param norm = 6.0121e-01, time/batch = 0.1729s	
1049/2700 (epoch 19.426), train_loss = 1.54798760, grad/param norm = 4.9937e-01, time/batch = 0.1632s	
1050/2700 (epoch 19.444), train_loss = 1.45453326, grad/param norm = 4.4246e-01, time/batch = 0.1535s	
1051/2700 (epoch 19.463), train_loss = 1.50414878, grad/param norm = 4.6397e-01, time/batch = 0.1745s	
1052/2700 (epoch 19.481), train_loss = 1.48899858, grad/param norm = 4.7549e-01, time/batch = 0.1665s	
1053/2700 (epoch 19.500), train_loss = 1.44921894, grad/param norm = 4.7779e-01, time/batch = 0.1563s	
1054/2700 (epoch 19.519), train_loss = 1.49493996, grad/param norm = 4.7043e-01, time/batch = 0.1651s	
1055/2700 (epoch 19.537), train_loss = 1.49902278, grad/param norm = 5.0078e-01, time/batch = 0.1672s	
1056/2700 (epoch 19.556), train_loss = 1.41162798, grad/param norm = 4.8833e-01, time/batch = 0.1741s	
1057/2700 (epoch 19.574), train_loss = 1.42741177, grad/param norm = 5.0735e-01, time/batch = 0.1776s	
1058/2700 (epoch 19.593), train_loss = 1.46997065, grad/param norm = 5.2583e-01, time/batch = 0.1739s	
1059/2700 (epoch 19.611), train_loss = 1.37974366, grad/param norm = 4.6270e-01, time/batch = 0.1647s	
1060/2700 (epoch 19.630), train_loss = 1.39732142, grad/param norm = 4.8821e-01, time/batch = 0.1481s	
1061/2700 (epoch 19.648), train_loss = 1.44455748, grad/param norm = 5.0019e-01, time/batch = 0.1643s	
1062/2700 (epoch 19.667), train_loss = 1.40834217, grad/param norm = 4.7588e-01, time/batch = 0.1479s	
1063/2700 (epoch 19.685), train_loss = 1.46325432, grad/param norm = 5.1443e-01, time/batch = 0.1742s	
1064/2700 (epoch 19.704), train_loss = 1.49684754, grad/param norm = 5.5037e-01, time/batch = 0.1828s	
1065/2700 (epoch 19.722), train_loss = 1.44411188, grad/param norm = 4.5145e-01, time/batch = 0.1820s	
1066/2700 (epoch 19.741), train_loss = 1.45759784, grad/param norm = 4.4104e-01, time/batch = 0.1804s	
1067/2700 (epoch 19.759), train_loss = 1.45112439, grad/param norm = 4.5963e-01, time/batch = 0.1814s	
1068/2700 (epoch 19.778), train_loss = 1.50330327, grad/param norm = 4.7069e-01, time/batch = 0.1662s	
1069/2700 (epoch 19.796), train_loss = 1.43963836, grad/param norm = 4.6048e-01, time/batch = 0.1504s	
1070/2700 (epoch 19.815), train_loss = 1.49570194, grad/param norm = 4.5592e-01, time/batch = 0.1531s	
1071/2700 (epoch 19.833), train_loss = 1.44949637, grad/param norm = 4.9975e-01, time/batch = 0.1803s	
1072/2700 (epoch 19.852), train_loss = 1.45705112, grad/param norm = 5.4725e-01, time/batch = 0.1763s	
1073/2700 (epoch 19.870), train_loss = 1.48095995, grad/param norm = 4.9463e-01, time/batch = 0.1547s	
1074/2700 (epoch 19.889), train_loss = 1.44403771, grad/param norm = 4.3331e-01, time/batch = 0.1623s	
1075/2700 (epoch 19.907), train_loss = 1.54150832, grad/param norm = 4.6733e-01, time/batch = 0.1700s	
1076/2700 (epoch 19.926), train_loss = 1.47746160, grad/param norm = 4.8799e-01, time/batch = 0.1753s	
1077/2700 (epoch 19.944), train_loss = 1.46427097, grad/param norm = 4.9286e-01, time/batch = 0.1791s	
1078/2700 (epoch 19.963), train_loss = 1.48080710, grad/param norm = 4.8851e-01, time/batch = 0.1760s	
1079/2700 (epoch 19.981), train_loss = 1.44035397, grad/param norm = 5.2667e-01, time/batch = 0.1465s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1080/2700 (epoch 20.000), train_loss = 1.55333361, grad/param norm = 5.1560e-01, time/batch = 0.1649s	
1081/2700 (epoch 20.019), train_loss = 1.52444392, grad/param norm = 5.0911e-01, time/batch = 0.1644s	
1082/2700 (epoch 20.037), train_loss = 1.51914416, grad/param norm = 4.8924e-01, time/batch = 0.1622s	
1083/2700 (epoch 20.056), train_loss = 1.43102779, grad/param norm = 4.7895e-01, time/batch = 0.1461s	
1084/2700 (epoch 20.074), train_loss = 1.42275054, grad/param norm = 4.4538e-01, time/batch = 0.1714s	
1085/2700 (epoch 20.093), train_loss = 1.42268738, grad/param norm = 4.5607e-01, time/batch = 0.1677s	
1086/2700 (epoch 20.111), train_loss = 1.38898501, grad/param norm = 4.4602e-01, time/batch = 0.1589s	
1087/2700 (epoch 20.130), train_loss = 1.46248036, grad/param norm = 4.5236e-01, time/batch = 0.1503s	
1088/2700 (epoch 20.148), train_loss = 1.42313093, grad/param norm = 4.4326e-01, time/batch = 0.1436s	
1089/2700 (epoch 20.167), train_loss = 1.47838278, grad/param norm = 4.8213e-01, time/batch = 0.1269s	
1090/2700 (epoch 20.185), train_loss = 1.41979056, grad/param norm = 4.8409e-01, time/batch = 0.1642s	
1091/2700 (epoch 20.204), train_loss = 1.46228911, grad/param norm = 5.0125e-01, time/batch = 0.1587s	
1092/2700 (epoch 20.222), train_loss = 1.41587756, grad/param norm = 4.7248e-01, time/batch = 0.1708s	
1093/2700 (epoch 20.241), train_loss = 1.34467124, grad/param norm = 4.5705e-01, time/batch = 0.1719s	
1094/2700 (epoch 20.259), train_loss = 1.39893800, grad/param norm = 4.5936e-01, time/batch = 0.1589s	
1095/2700 (epoch 20.278), train_loss = 1.45815521, grad/param norm = 4.7042e-01, time/batch = 0.1710s	
1096/2700 (epoch 20.296), train_loss = 1.43475524, grad/param norm = 4.5312e-01, time/batch = 0.1749s	
1097/2700 (epoch 20.315), train_loss = 1.42155054, grad/param norm = 4.5767e-01, time/batch = 0.1767s	
1098/2700 (epoch 20.333), train_loss = 1.44244888, grad/param norm = 5.0113e-01, time/batch = 0.1663s	
1099/2700 (epoch 20.352), train_loss = 1.44245355, grad/param norm = 5.3690e-01, time/batch = 0.1544s	
1100/2700 (epoch 20.370), train_loss = 1.45534716, grad/param norm = 5.1031e-01, time/batch = 0.1598s	
1101/2700 (epoch 20.389), train_loss = 1.41161664, grad/param norm = 4.6546e-01, time/batch = 0.1809s	
1102/2700 (epoch 20.407), train_loss = 1.46467006, grad/param norm = 4.6163e-01, time/batch = 0.1794s	
1103/2700 (epoch 20.426), train_loss = 1.51499942, grad/param norm = 4.8468e-01, time/batch = 0.1780s	
1104/2700 (epoch 20.444), train_loss = 1.43264662, grad/param norm = 4.6440e-01, time/batch = 0.1797s	
1105/2700 (epoch 20.463), train_loss = 1.47460140, grad/param norm = 4.5488e-01, time/batch = 0.1506s	
1106/2700 (epoch 20.481), train_loss = 1.45879296, grad/param norm = 4.6773e-01, time/batch = 0.1763s	
1107/2700 (epoch 20.500), train_loss = 1.42721114, grad/param norm = 4.8270e-01, time/batch = 0.1792s	
1108/2700 (epoch 20.519), train_loss = 1.47939965, grad/param norm = 4.8219e-01, time/batch = 0.1789s	
1109/2700 (epoch 20.537), train_loss = 1.47193013, grad/param norm = 4.9364e-01, time/batch = 0.1684s	
1110/2700 (epoch 20.556), train_loss = 1.38009116, grad/param norm = 4.6129e-01, time/batch = 0.1764s	
1111/2700 (epoch 20.574), train_loss = 1.40277221, grad/param norm = 5.0677e-01, time/batch = 0.1557s	
1112/2700 (epoch 20.593), train_loss = 1.44889725, grad/param norm = 5.3759e-01, time/batch = 0.1667s	
1113/2700 (epoch 20.611), train_loss = 1.36255869, grad/param norm = 4.9810e-01, time/batch = 0.1702s	
1114/2700 (epoch 20.630), train_loss = 1.36987488, grad/param norm = 4.5683e-01, time/batch = 0.1751s	
1115/2700 (epoch 20.648), train_loss = 1.41908149, grad/param norm = 4.6596e-01, time/batch = 0.1714s	
1116/2700 (epoch 20.667), train_loss = 1.38251561, grad/param norm = 4.7385e-01, time/batch = 0.1799s	
1117/2700 (epoch 20.685), train_loss = 1.43738728, grad/param norm = 5.1497e-01, time/batch = 0.1790s	
1118/2700 (epoch 20.704), train_loss = 1.46767941, grad/param norm = 5.1566e-01, time/batch = 0.1807s	
1119/2700 (epoch 20.722), train_loss = 1.42268430, grad/param norm = 4.7535e-01, time/batch = 0.1698s	
1120/2700 (epoch 20.741), train_loss = 1.44219412, grad/param norm = 5.0247e-01, time/batch = 0.1643s	
1121/2700 (epoch 20.759), train_loss = 1.42502905, grad/param norm = 4.6893e-01, time/batch = 0.1803s	
1122/2700 (epoch 20.778), train_loss = 1.47567968, grad/param norm = 4.6032e-01, time/batch = 0.1789s	
1123/2700 (epoch 20.796), train_loss = 1.41870269, grad/param norm = 5.2957e-01, time/batch = 0.1783s	
1124/2700 (epoch 20.815), train_loss = 1.48491115, grad/param norm = 5.3445e-01, time/batch = 0.1767s	
1125/2700 (epoch 20.833), train_loss = 1.43346716, grad/param norm = 5.0354e-01, time/batch = 0.1752s	
1126/2700 (epoch 20.852), train_loss = 1.42856483, grad/param norm = 5.0661e-01, time/batch = 0.1504s	
1127/2700 (epoch 20.870), train_loss = 1.44983613, grad/param norm = 4.4126e-01, time/batch = 0.1474s	
1128/2700 (epoch 20.889), train_loss = 1.42600573, grad/param norm = 4.7532e-01, time/batch = 0.1655s	
1129/2700 (epoch 20.907), train_loss = 1.52776331, grad/param norm = 5.4563e-01, time/batch = 0.1720s	
1130/2700 (epoch 20.926), train_loss = 1.46334568, grad/param norm = 5.3147e-01, time/batch = 0.1522s	
1131/2700 (epoch 20.944), train_loss = 1.44120027, grad/param norm = 4.8296e-01, time/batch = 0.1613s	
1132/2700 (epoch 20.963), train_loss = 1.45241421, grad/param norm = 4.8676e-01, time/batch = 0.1683s	
1133/2700 (epoch 20.981), train_loss = 1.40783507, grad/param norm = 4.8795e-01, time/batch = 0.1726s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1134/2700 (epoch 21.000), train_loss = 1.52927348, grad/param norm = 5.4305e-01, time/batch = 0.1716s	
1135/2700 (epoch 21.019), train_loss = 1.50535392, grad/param norm = 5.0187e-01, time/batch = 0.1609s	
1136/2700 (epoch 21.037), train_loss = 1.49425037, grad/param norm = 4.8858e-01, time/batch = 0.1363s	
1137/2700 (epoch 21.056), train_loss = 1.40452906, grad/param norm = 4.7637e-01, time/batch = 0.1327s	
1138/2700 (epoch 21.074), train_loss = 1.39786641, grad/param norm = 4.6146e-01, time/batch = 0.1410s	
1139/2700 (epoch 21.093), train_loss = 1.39865434, grad/param norm = 4.6648e-01, time/batch = 0.1443s	
1140/2700 (epoch 21.111), train_loss = 1.37075309, grad/param norm = 4.7406e-01, time/batch = 0.1437s	
1141/2700 (epoch 21.130), train_loss = 1.44207528, grad/param norm = 4.7427e-01, time/batch = 0.1753s	
1142/2700 (epoch 21.148), train_loss = 1.39874560, grad/param norm = 4.5628e-01, time/batch = 0.1695s	
1143/2700 (epoch 21.167), train_loss = 1.45342471, grad/param norm = 4.6858e-01, time/batch = 0.1630s	
1144/2700 (epoch 21.185), train_loss = 1.39191029, grad/param norm = 4.7348e-01, time/batch = 0.1592s	
1145/2700 (epoch 21.204), train_loss = 1.42986967, grad/param norm = 4.7092e-01, time/batch = 0.1644s	
1146/2700 (epoch 21.222), train_loss = 1.39177384, grad/param norm = 4.7168e-01, time/batch = 0.1686s	
1147/2700 (epoch 21.241), train_loss = 1.32233526, grad/param norm = 4.6836e-01, time/batch = 0.1484s	
1148/2700 (epoch 21.259), train_loss = 1.37550633, grad/param norm = 4.6487e-01, time/batch = 0.1828s	
1149/2700 (epoch 21.278), train_loss = 1.43316237, grad/param norm = 4.7168e-01, time/batch = 0.1818s	
1150/2700 (epoch 21.296), train_loss = 1.41012087, grad/param norm = 4.5493e-01, time/batch = 0.1738s	
1151/2700 (epoch 21.315), train_loss = 1.38917032, grad/param norm = 4.4665e-01, time/batch = 0.1695s	
1152/2700 (epoch 21.333), train_loss = 1.41288835, grad/param norm = 4.6688e-01, time/batch = 0.1676s	
1153/2700 (epoch 21.352), train_loss = 1.40967138, grad/param norm = 4.8597e-01, time/batch = 0.1674s	
1154/2700 (epoch 21.370), train_loss = 1.43178606, grad/param norm = 5.2781e-01, time/batch = 0.1640s	
1155/2700 (epoch 21.389), train_loss = 1.39750423, grad/param norm = 5.2262e-01, time/batch = 0.1623s	
1156/2700 (epoch 21.407), train_loss = 1.45280606, grad/param norm = 5.4847e-01, time/batch = 0.1636s	
1157/2700 (epoch 21.426), train_loss = 1.49276667, grad/param norm = 4.8850e-01, time/batch = 0.1556s	
1158/2700 (epoch 21.444), train_loss = 1.40861637, grad/param norm = 4.6490e-01, time/batch = 0.1621s	
1159/2700 (epoch 21.463), train_loss = 1.45118820, grad/param norm = 4.7189e-01, time/batch = 0.1554s	
1160/2700 (epoch 21.481), train_loss = 1.43227364, grad/param norm = 4.5721e-01, time/batch = 0.1584s	
1161/2700 (epoch 21.500), train_loss = 1.39753834, grad/param norm = 4.6179e-01, time/batch = 0.1566s	
1162/2700 (epoch 21.519), train_loss = 1.44912165, grad/param norm = 4.7168e-01, time/batch = 0.1566s	
1163/2700 (epoch 21.537), train_loss = 1.45010813, grad/param norm = 5.0110e-01, time/batch = 0.1583s	
1164/2700 (epoch 21.556), train_loss = 1.36742542, grad/param norm = 5.1689e-01, time/batch = 0.1610s	
1165/2700 (epoch 21.574), train_loss = 1.37951577, grad/param norm = 5.2117e-01, time/batch = 0.1597s	
1166/2700 (epoch 21.593), train_loss = 1.42405245, grad/param norm = 5.2876e-01, time/batch = 0.1515s	
1167/2700 (epoch 21.611), train_loss = 1.33556946, grad/param norm = 4.6477e-01, time/batch = 0.1461s	
1168/2700 (epoch 21.630), train_loss = 1.35162491, grad/param norm = 4.7912e-01, time/batch = 0.1578s	
1169/2700 (epoch 21.648), train_loss = 1.39759392, grad/param norm = 4.8789e-01, time/batch = 0.1477s	
1170/2700 (epoch 21.667), train_loss = 1.35813720, grad/param norm = 4.8468e-01, time/batch = 0.1487s	
1171/2700 (epoch 21.685), train_loss = 1.41897390, grad/param norm = 5.2887e-01, time/batch = 0.1324s	
1172/2700 (epoch 21.704), train_loss = 1.45588713, grad/param norm = 5.7349e-01, time/batch = 0.1576s	
1173/2700 (epoch 21.722), train_loss = 1.40470201, grad/param norm = 4.8792e-01, time/batch = 0.1643s	
1174/2700 (epoch 21.741), train_loss = 1.41286387, grad/param norm = 4.7605e-01, time/batch = 0.1677s	
1175/2700 (epoch 21.759), train_loss = 1.40574378, grad/param norm = 5.0607e-01, time/batch = 0.1743s	
1176/2700 (epoch 21.778), train_loss = 1.46457642, grad/param norm = 5.2211e-01, time/batch = 0.1780s	
1177/2700 (epoch 21.796), train_loss = 1.38686330, grad/param norm = 4.6707e-01, time/batch = 0.1704s	
1178/2700 (epoch 21.815), train_loss = 1.44536512, grad/param norm = 4.7115e-01, time/batch = 0.1771s	
1179/2700 (epoch 21.833), train_loss = 1.40921182, grad/param norm = 5.2334e-01, time/batch = 0.1648s	
1180/2700 (epoch 21.852), train_loss = 1.41099332, grad/param norm = 5.4479e-01, time/batch = 0.1778s	
1181/2700 (epoch 21.870), train_loss = 1.43626617, grad/param norm = 4.7706e-01, time/batch = 0.1681s	
1182/2700 (epoch 21.889), train_loss = 1.39961022, grad/param norm = 4.8074e-01, time/batch = 0.1659s	
1183/2700 (epoch 21.907), train_loss = 1.50013594, grad/param norm = 5.2968e-01, time/batch = 0.1593s	
1184/2700 (epoch 21.926), train_loss = 1.42637937, grad/param norm = 5.0222e-01, time/batch = 0.1510s	
1185/2700 (epoch 21.944), train_loss = 1.41530542, grad/param norm = 4.7733e-01, time/batch = 0.1505s	
1186/2700 (epoch 21.963), train_loss = 1.42480678, grad/param norm = 4.7173e-01, time/batch = 0.1476s	
1187/2700 (epoch 21.981), train_loss = 1.38058136, grad/param norm = 4.9164e-01, time/batch = 0.1382s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1188/2700 (epoch 22.000), train_loss = 1.49768241, grad/param norm = 4.9743e-01, time/batch = 0.1595s	
1189/2700 (epoch 22.019), train_loss = 1.48335776, grad/param norm = 5.3073e-01, time/batch = 0.1568s	
1190/2700 (epoch 22.037), train_loss = 1.47530678, grad/param norm = 5.1857e-01, time/batch = 0.1374s	
1191/2700 (epoch 22.056), train_loss = 1.38708570, grad/param norm = 4.9528e-01, time/batch = 0.1653s	
1192/2700 (epoch 22.074), train_loss = 1.37483489, grad/param norm = 4.6879e-01, time/batch = 0.1603s	
1193/2700 (epoch 22.093), train_loss = 1.37909896, grad/param norm = 4.9216e-01, time/batch = 0.1804s	
1194/2700 (epoch 22.111), train_loss = 1.35058281, grad/param norm = 4.8006e-01, time/batch = 0.1745s	
1195/2700 (epoch 22.130), train_loss = 1.41815467, grad/param norm = 4.7890e-01, time/batch = 0.1681s	
1196/2700 (epoch 22.148), train_loss = 1.38245206, grad/param norm = 4.6242e-01, time/batch = 0.1664s	
1197/2700 (epoch 22.167), train_loss = 1.43343632, grad/param norm = 5.1243e-01, time/batch = 0.1588s	
1198/2700 (epoch 22.185), train_loss = 1.37845026, grad/param norm = 5.0714e-01, time/batch = 0.1802s	
1199/2700 (epoch 22.204), train_loss = 1.41809781, grad/param norm = 5.0719e-01, time/batch = 0.1766s	
1200/2700 (epoch 22.222), train_loss = 1.36925686, grad/param norm = 4.7907e-01, time/batch = 0.1697s	
1201/2700 (epoch 22.241), train_loss = 1.30059731, grad/param norm = 4.5708e-01, time/batch = 0.1659s	
1202/2700 (epoch 22.259), train_loss = 1.35060635, grad/param norm = 4.6471e-01, time/batch = 0.1548s	
1203/2700 (epoch 22.278), train_loss = 1.41361971, grad/param norm = 4.9573e-01, time/batch = 0.1803s	
1204/2700 (epoch 22.296), train_loss = 1.38831097, grad/param norm = 4.7099e-01, time/batch = 0.1796s	
1205/2700 (epoch 22.315), train_loss = 1.36438788, grad/param norm = 4.9692e-01, time/batch = 0.1785s	
1206/2700 (epoch 22.333), train_loss = 1.39043129, grad/param norm = 4.6270e-01, time/batch = 0.1648s	
1207/2700 (epoch 22.352), train_loss = 1.37878300, grad/param norm = 4.6834e-01, time/batch = 0.1613s	
1208/2700 (epoch 22.370), train_loss = 1.39768439, grad/param norm = 4.9688e-01, time/batch = 0.1569s	
1209/2700 (epoch 22.389), train_loss = 1.35888005, grad/param norm = 4.7609e-01, time/batch = 0.1660s	
1210/2700 (epoch 22.407), train_loss = 1.41840009, grad/param norm = 4.7979e-01, time/batch = 0.1695s	
1211/2700 (epoch 22.426), train_loss = 1.48019037, grad/param norm = 5.6317e-01, time/batch = 0.1449s	
1212/2700 (epoch 22.444), train_loss = 1.39865397, grad/param norm = 5.3047e-01, time/batch = 0.1732s	
1213/2700 (epoch 22.463), train_loss = 1.42721612, grad/param norm = 4.7271e-01, time/batch = 0.1707s	
1214/2700 (epoch 22.481), train_loss = 1.40947819, grad/param norm = 4.7311e-01, time/batch = 0.1649s	
1215/2700 (epoch 22.500), train_loss = 1.37909422, grad/param norm = 4.7811e-01, time/batch = 0.1626s	
1216/2700 (epoch 22.519), train_loss = 1.42891768, grad/param norm = 4.7612e-01, time/batch = 0.1535s	
1217/2700 (epoch 22.537), train_loss = 1.41976533, grad/param norm = 4.9258e-01, time/batch = 0.1532s	
1218/2700 (epoch 22.556), train_loss = 1.33312799, grad/param norm = 4.7271e-01, time/batch = 0.1582s	
1219/2700 (epoch 22.574), train_loss = 1.35363629, grad/param norm = 5.1088e-01, time/batch = 0.1547s	
1220/2700 (epoch 22.593), train_loss = 1.39964218, grad/param norm = 5.2495e-01, time/batch = 0.1589s	
1221/2700 (epoch 22.611), train_loss = 1.31391122, grad/param norm = 4.8249e-01, time/batch = 0.1581s	
1222/2700 (epoch 22.630), train_loss = 1.32516901, grad/param norm = 4.5503e-01, time/batch = 0.1419s	
1223/2700 (epoch 22.648), train_loss = 1.37371984, grad/param norm = 4.6113e-01, time/batch = 0.1686s	
1224/2700 (epoch 22.667), train_loss = 1.32964213, grad/param norm = 4.7119e-01, time/batch = 0.1796s	
1225/2700 (epoch 22.685), train_loss = 1.39063376, grad/param norm = 5.0663e-01, time/batch = 0.1765s	
1226/2700 (epoch 22.704), train_loss = 1.42436862, grad/param norm = 5.1790e-01, time/batch = 0.1733s	
1227/2700 (epoch 22.722), train_loss = 1.37740427, grad/param norm = 4.5901e-01, time/batch = 0.1786s	
1228/2700 (epoch 22.741), train_loss = 1.38797991, grad/param norm = 4.7291e-01, time/batch = 0.1784s	
1229/2700 (epoch 22.759), train_loss = 1.37576179, grad/param norm = 4.7159e-01, time/batch = 0.1786s	
1230/2700 (epoch 22.778), train_loss = 1.43014447, grad/param norm = 4.6001e-01, time/batch = 0.1785s	
1231/2700 (epoch 22.796), train_loss = 1.36321677, grad/param norm = 5.0375e-01, time/batch = 0.1724s	
1232/2700 (epoch 22.815), train_loss = 1.43342380, grad/param norm = 5.3809e-01, time/batch = 0.1509s	
1233/2700 (epoch 22.833), train_loss = 1.39126330, grad/param norm = 5.1806e-01, time/batch = 0.1631s	
1234/2700 (epoch 22.852), train_loss = 1.38163758, grad/param norm = 5.1581e-01, time/batch = 0.1759s	
1235/2700 (epoch 22.870), train_loss = 1.40659483, grad/param norm = 4.5090e-01, time/batch = 0.1803s	
1236/2700 (epoch 22.889), train_loss = 1.37786878, grad/param norm = 4.7816e-01, time/batch = 0.1656s	
1237/2700 (epoch 22.907), train_loss = 1.47235270, grad/param norm = 5.2145e-01, time/batch = 0.1659s	
1238/2700 (epoch 22.926), train_loss = 1.40143925, grad/param norm = 4.9494e-01, time/batch = 0.1683s	
1239/2700 (epoch 22.944), train_loss = 1.38843476, grad/param norm = 4.7274e-01, time/batch = 0.1739s	
1240/2700 (epoch 22.963), train_loss = 1.39781131, grad/param norm = 4.6357e-01, time/batch = 0.1674s	
1241/2700 (epoch 22.981), train_loss = 1.35498896, grad/param norm = 4.9350e-01, time/batch = 0.1814s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1242/2700 (epoch 23.000), train_loss = 1.47853065, grad/param norm = 5.1928e-01, time/batch = 0.1737s	
1243/2700 (epoch 23.019), train_loss = 1.45826902, grad/param norm = 5.1831e-01, time/batch = 0.1562s	
1244/2700 (epoch 23.037), train_loss = 1.44497470, grad/param norm = 4.9210e-01, time/batch = 0.1549s	
1245/2700 (epoch 23.056), train_loss = 1.36121606, grad/param norm = 4.8714e-01, time/batch = 0.1512s	
1246/2700 (epoch 23.074), train_loss = 1.35298922, grad/param norm = 4.8139e-01, time/batch = 0.1646s	
1247/2700 (epoch 23.093), train_loss = 1.35639869, grad/param norm = 4.8417e-01, time/batch = 0.1632s	
1248/2700 (epoch 23.111), train_loss = 1.32799446, grad/param norm = 4.6600e-01, time/batch = 0.1625s	
1249/2700 (epoch 23.130), train_loss = 1.39132631, grad/param norm = 4.6826e-01, time/batch = 0.1591s	
1250/2700 (epoch 23.148), train_loss = 1.35762648, grad/param norm = 4.5950e-01, time/batch = 0.1572s	
1251/2700 (epoch 23.167), train_loss = 1.40768367, grad/param norm = 4.8984e-01, time/batch = 0.1795s	
1252/2700 (epoch 23.185), train_loss = 1.35337146, grad/param norm = 4.9745e-01, time/batch = 0.1794s	
1253/2700 (epoch 23.204), train_loss = 1.39186542, grad/param norm = 4.8655e-01, time/batch = 0.1642s	
1254/2700 (epoch 23.222), train_loss = 1.35066321, grad/param norm = 4.9072e-01, time/batch = 0.1511s	
1255/2700 (epoch 23.241), train_loss = 1.28157603, grad/param norm = 4.7644e-01, time/batch = 0.1407s	
1256/2700 (epoch 23.259), train_loss = 1.33061652, grad/param norm = 4.7680e-01, time/batch = 0.1582s	
1257/2700 (epoch 23.278), train_loss = 1.39137425, grad/param norm = 4.9145e-01, time/batch = 0.1580s	
1258/2700 (epoch 23.296), train_loss = 1.36418537, grad/param norm = 4.7285e-01, time/batch = 0.1572s	
1259/2700 (epoch 23.315), train_loss = 1.34443385, grad/param norm = 4.7962e-01, time/batch = 0.1534s	
1260/2700 (epoch 23.333), train_loss = 1.37674412, grad/param norm = 5.1596e-01, time/batch = 0.1601s	
1261/2700 (epoch 23.352), train_loss = 1.37156271, grad/param norm = 5.1675e-01, time/batch = 0.1467s	
1262/2700 (epoch 23.370), train_loss = 1.38418242, grad/param norm = 5.3111e-01, time/batch = 0.1525s	
1263/2700 (epoch 23.389), train_loss = 1.34646356, grad/param norm = 5.1752e-01, time/batch = 0.1616s	
1264/2700 (epoch 23.407), train_loss = 1.40394049, grad/param norm = 5.5895e-01, time/batch = 0.1299s	
1265/2700 (epoch 23.426), train_loss = 1.44413942, grad/param norm = 4.9023e-01, time/batch = 0.1803s	
1266/2700 (epoch 23.444), train_loss = 1.36757008, grad/param norm = 4.7364e-01, time/batch = 0.1814s	
1267/2700 (epoch 23.463), train_loss = 1.41151976, grad/param norm = 5.0525e-01, time/batch = 0.1822s	
1268/2700 (epoch 23.481), train_loss = 1.39779691, grad/param norm = 5.4096e-01, time/batch = 0.1823s	
1269/2700 (epoch 23.500), train_loss = 1.36132391, grad/param norm = 5.2544e-01, time/batch = 0.1809s	
1270/2700 (epoch 23.519), train_loss = 1.40547516, grad/param norm = 5.2600e-01, time/batch = 0.1793s	
1271/2700 (epoch 23.537), train_loss = 1.40512601, grad/param norm = 5.2264e-01, time/batch = 0.1770s	
1272/2700 (epoch 23.556), train_loss = 1.31559890, grad/param norm = 4.9456e-01, time/batch = 0.1707s	
1273/2700 (epoch 23.574), train_loss = 1.32885619, grad/param norm = 5.0196e-01, time/batch = 0.1678s	
1274/2700 (epoch 23.593), train_loss = 1.37128327, grad/param norm = 5.0762e-01, time/batch = 0.1537s	
1275/2700 (epoch 23.611), train_loss = 1.29011079, grad/param norm = 4.6318e-01, time/batch = 0.1400s	
1276/2700 (epoch 23.630), train_loss = 1.30928997, grad/param norm = 4.7134e-01, time/batch = 0.1555s	
1277/2700 (epoch 23.648), train_loss = 1.35154329, grad/param norm = 4.7020e-01, time/batch = 0.1630s	
1278/2700 (epoch 23.667), train_loss = 1.30741154, grad/param norm = 4.6761e-01, time/batch = 0.1701s	
1279/2700 (epoch 23.685), train_loss = 1.36833877, grad/param norm = 5.0564e-01, time/batch = 0.1698s	
1280/2700 (epoch 23.704), train_loss = 1.40837887, grad/param norm = 5.4823e-01, time/batch = 0.1706s	
1281/2700 (epoch 23.722), train_loss = 1.35760942, grad/param norm = 4.7441e-01, time/batch = 0.1607s	
1282/2700 (epoch 23.741), train_loss = 1.36437087, grad/param norm = 4.7679e-01, time/batch = 0.1669s	
1283/2700 (epoch 23.759), train_loss = 1.35302775, grad/param norm = 4.8671e-01, time/batch = 0.1631s	
1284/2700 (epoch 23.778), train_loss = 1.41042885, grad/param norm = 4.8282e-01, time/batch = 0.1687s	
1285/2700 (epoch 23.796), train_loss = 1.33355343, grad/param norm = 4.6657e-01, time/batch = 0.1290s	
1286/2700 (epoch 23.815), train_loss = 1.40262949, grad/param norm = 5.1257e-01, time/batch = 0.1525s	
1287/2700 (epoch 23.833), train_loss = 1.37231185, grad/param norm = 5.3582e-01, time/batch = 0.1422s	
1288/2700 (epoch 23.852), train_loss = 1.36785249, grad/param norm = 5.5354e-01, time/batch = 0.1460s	
1289/2700 (epoch 23.870), train_loss = 1.39700907, grad/param norm = 5.0947e-01, time/batch = 0.1540s	
1290/2700 (epoch 23.889), train_loss = 1.36201364, grad/param norm = 5.3290e-01, time/batch = 0.1620s	
1291/2700 (epoch 23.907), train_loss = 1.45351761, grad/param norm = 5.5265e-01, time/batch = 0.1417s	
1292/2700 (epoch 23.926), train_loss = 1.37371178, grad/param norm = 4.9570e-01, time/batch = 0.1482s	
1293/2700 (epoch 23.944), train_loss = 1.36860407, grad/param norm = 4.8662e-01, time/batch = 0.1584s	
1294/2700 (epoch 23.963), train_loss = 1.37433037, grad/param norm = 4.7744e-01, time/batch = 0.1624s	
1295/2700 (epoch 23.981), train_loss = 1.33141913, grad/param norm = 5.0707e-01, time/batch = 0.1341s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1296/2700 (epoch 24.000), train_loss = 1.45343793, grad/param norm = 5.1881e-01, time/batch = 0.1736s	
1297/2700 (epoch 24.019), train_loss = 1.43611909, grad/param norm = 5.2444e-01, time/batch = 0.1580s	
1298/2700 (epoch 24.037), train_loss = 1.42406514, grad/param norm = 5.1831e-01, time/batch = 0.1635s	
1299/2700 (epoch 24.056), train_loss = 1.34175654, grad/param norm = 5.0139e-01, time/batch = 0.1718s	
1300/2700 (epoch 24.074), train_loss = 1.33199526, grad/param norm = 4.8941e-01, time/batch = 0.1772s	
1301/2700 (epoch 24.093), train_loss = 1.33345682, grad/param norm = 4.8174e-01, time/batch = 0.1573s	
1302/2700 (epoch 24.111), train_loss = 1.30876149, grad/param norm = 4.8638e-01, time/batch = 0.1664s	
1303/2700 (epoch 24.130), train_loss = 1.37620980, grad/param norm = 4.9436e-01, time/batch = 0.1726s	
1304/2700 (epoch 24.148), train_loss = 1.33879123, grad/param norm = 4.7328e-01, time/batch = 0.1746s	
1305/2700 (epoch 24.167), train_loss = 1.38476604, grad/param norm = 4.7560e-01, time/batch = 0.1543s	
1306/2700 (epoch 24.185), train_loss = 1.32639563, grad/param norm = 4.6443e-01, time/batch = 0.1709s	
1307/2700 (epoch 24.204), train_loss = 1.37488034, grad/param norm = 5.1115e-01, time/batch = 0.1543s	
1308/2700 (epoch 24.222), train_loss = 1.33543785, grad/param norm = 5.0394e-01, time/batch = 0.1594s	
1309/2700 (epoch 24.241), train_loss = 1.26222795, grad/param norm = 4.7442e-01, time/batch = 0.1566s	
1310/2700 (epoch 24.259), train_loss = 1.31048895, grad/param norm = 4.8815e-01, time/batch = 0.1532s	
1311/2700 (epoch 24.278), train_loss = 1.37452467, grad/param norm = 5.2396e-01, time/batch = 0.1807s	
1312/2700 (epoch 24.296), train_loss = 1.34706919, grad/param norm = 4.9509e-01, time/batch = 0.1791s	
1313/2700 (epoch 24.315), train_loss = 1.32178059, grad/param norm = 5.2534e-01, time/batch = 0.1780s	
1314/2700 (epoch 24.333), train_loss = 1.35853056, grad/param norm = 5.2932e-01, time/batch = 0.1722s	
1315/2700 (epoch 24.352), train_loss = 1.34776185, grad/param norm = 5.3182e-01, time/batch = 0.1710s	
1316/2700 (epoch 24.370), train_loss = 1.36000536, grad/param norm = 5.1440e-01, time/batch = 0.1790s	
1317/2700 (epoch 24.389), train_loss = 1.32070497, grad/param norm = 4.9276e-01, time/batch = 0.1779s	
1318/2700 (epoch 24.407), train_loss = 1.37987182, grad/param norm = 4.9419e-01, time/batch = 0.1460s	
1319/2700 (epoch 24.426), train_loss = 1.43066249, grad/param norm = 5.4305e-01, time/batch = 0.1780s	
1320/2700 (epoch 24.444), train_loss = 1.34960510, grad/param norm = 5.0223e-01, time/batch = 0.1805s	
1321/2700 (epoch 24.463), train_loss = 1.38350919, grad/param norm = 4.9080e-01, time/batch = 0.1534s	
1322/2700 (epoch 24.481), train_loss = 1.36788749, grad/param norm = 5.0996e-01, time/batch = 0.1620s	
1323/2700 (epoch 24.500), train_loss = 1.33635085, grad/param norm = 4.8513e-01, time/batch = 0.1620s	
1324/2700 (epoch 24.519), train_loss = 1.38212187, grad/param norm = 4.7720e-01, time/batch = 0.1561s	
1325/2700 (epoch 24.537), train_loss = 1.37474524, grad/param norm = 5.0423e-01, time/batch = 0.1778s	
1326/2700 (epoch 24.556), train_loss = 1.29773418, grad/param norm = 5.3272e-01, time/batch = 0.1569s	
1327/2700 (epoch 24.574), train_loss = 1.31453987, grad/param norm = 5.4352e-01, time/batch = 0.1647s	
1328/2700 (epoch 24.593), train_loss = 1.36204620, grad/param norm = 5.4489e-01, time/batch = 0.1613s	
1329/2700 (epoch 24.611), train_loss = 1.27212135, grad/param norm = 4.8341e-01, time/batch = 0.1448s	
1330/2700 (epoch 24.630), train_loss = 1.28739325, grad/param norm = 4.5839e-01, time/batch = 0.1427s	
1331/2700 (epoch 24.648), train_loss = 1.33397983, grad/param norm = 4.6438e-01, time/batch = 0.1271s	
1332/2700 (epoch 24.667), train_loss = 1.28298610, grad/param norm = 4.6516e-01, time/batch = 0.1401s	
1333/2700 (epoch 24.685), train_loss = 1.34730831, grad/param norm = 5.1324e-01, time/batch = 0.1513s	
1334/2700 (epoch 24.704), train_loss = 1.38661304, grad/param norm = 5.3741e-01, time/batch = 0.1596s	
1335/2700 (epoch 24.722), train_loss = 1.33531328, grad/param norm = 4.6595e-01, time/batch = 0.1702s	
1336/2700 (epoch 24.741), train_loss = 1.34143555, grad/param norm = 4.7532e-01, time/batch = 0.1531s	
1337/2700 (epoch 24.759), train_loss = 1.32714985, grad/param norm = 4.7434e-01, time/batch = 0.1620s	
1338/2700 (epoch 24.778), train_loss = 1.38574071, grad/param norm = 4.6761e-01, time/batch = 0.1666s	
1339/2700 (epoch 24.796), train_loss = 1.31261926, grad/param norm = 5.0444e-01, time/batch = 0.1646s	
1340/2700 (epoch 24.815), train_loss = 1.38668407, grad/param norm = 5.4373e-01, time/batch = 0.1819s	
1341/2700 (epoch 24.833), train_loss = 1.34580110, grad/param norm = 5.1561e-01, time/batch = 0.1814s	
1342/2700 (epoch 24.852), train_loss = 1.33600152, grad/param norm = 5.0995e-01, time/batch = 0.1800s	
1343/2700 (epoch 24.870), train_loss = 1.36380265, grad/param norm = 4.5627e-01, time/batch = 0.1721s	
1344/2700 (epoch 24.889), train_loss = 1.33367137, grad/param norm = 4.7361e-01, time/batch = 0.1778s	
1345/2700 (epoch 24.907), train_loss = 1.41954371, grad/param norm = 5.0679e-01, time/batch = 0.1789s	
1346/2700 (epoch 24.926), train_loss = 1.34797253, grad/param norm = 4.9178e-01, time/batch = 0.1691s	
1347/2700 (epoch 24.944), train_loss = 1.34603976, grad/param norm = 4.9438e-01, time/batch = 0.1748s	
1348/2700 (epoch 24.963), train_loss = 1.35417218, grad/param norm = 4.8917e-01, time/batch = 0.1727s	
1349/2700 (epoch 24.981), train_loss = 1.31087098, grad/param norm = 5.3018e-01, time/batch = 0.1682s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1350/2700 (epoch 25.000), train_loss = 1.43739379, grad/param norm = 5.3010e-01, time/batch = 0.1424s	
1351/2700 (epoch 25.019), train_loss = 1.41906025, grad/param norm = 5.3645e-01, time/batch = 0.1592s	
1352/2700 (epoch 25.037), train_loss = 1.39792013, grad/param norm = 5.0540e-01, time/batch = 0.1629s	
1353/2700 (epoch 25.056), train_loss = 1.32112081, grad/param norm = 5.0077e-01, time/batch = 0.1623s	
1354/2700 (epoch 25.074), train_loss = 1.31262514, grad/param norm = 4.9616e-01, time/batch = 0.1625s	
1355/2700 (epoch 25.093), train_loss = 1.31542904, grad/param norm = 4.9688e-01, time/batch = 0.1564s	
1356/2700 (epoch 25.111), train_loss = 1.28883817, grad/param norm = 4.7815e-01, time/batch = 0.1640s	
1357/2700 (epoch 25.130), train_loss = 1.34865988, grad/param norm = 4.7955e-01, time/batch = 0.1530s	
1358/2700 (epoch 25.148), train_loss = 1.31654548, grad/param norm = 4.7271e-01, time/batch = 0.1506s	
1359/2700 (epoch 25.167), train_loss = 1.36688244, grad/param norm = 5.1683e-01, time/batch = 0.1578s	
1360/2700 (epoch 25.185), train_loss = 1.31539052, grad/param norm = 4.9171e-01, time/batch = 0.1538s	
1361/2700 (epoch 25.204), train_loss = 1.36230269, grad/param norm = 5.3279e-01, time/batch = 0.1823s	
1362/2700 (epoch 25.222), train_loss = 1.31171588, grad/param norm = 5.0989e-01, time/batch = 0.1792s	
1363/2700 (epoch 25.241), train_loss = 1.23807225, grad/param norm = 4.6754e-01, time/batch = 0.1751s	
1364/2700 (epoch 25.259), train_loss = 1.28573789, grad/param norm = 4.7739e-01, time/batch = 0.1758s	
1365/2700 (epoch 25.278), train_loss = 1.35246263, grad/param norm = 5.2093e-01, time/batch = 0.1672s	
1366/2700 (epoch 25.296), train_loss = 1.32119258, grad/param norm = 4.8507e-01, time/batch = 0.1638s	
1367/2700 (epoch 25.315), train_loss = 1.29162852, grad/param norm = 4.8122e-01, time/batch = 0.1388s	
1368/2700 (epoch 25.333), train_loss = 1.32655245, grad/param norm = 4.8707e-01, time/batch = 0.1590s	
1369/2700 (epoch 25.352), train_loss = 1.32130092, grad/param norm = 5.1789e-01, time/batch = 0.1582s	
1370/2700 (epoch 25.370), train_loss = 1.34051175, grad/param norm = 5.4084e-01, time/batch = 0.1650s	
1371/2700 (epoch 25.389), train_loss = 1.29866827, grad/param norm = 5.0088e-01, time/batch = 0.1406s	
1372/2700 (epoch 25.407), train_loss = 1.35854516, grad/param norm = 5.0675e-01, time/batch = 0.1791s	
1373/2700 (epoch 25.426), train_loss = 1.40032195, grad/param norm = 5.0317e-01, time/batch = 0.1817s	
1374/2700 (epoch 25.444), train_loss = 1.33184844, grad/param norm = 5.0948e-01, time/batch = 0.1799s	
1375/2700 (epoch 25.463), train_loss = 1.36418287, grad/param norm = 4.9398e-01, time/batch = 0.1739s	
1376/2700 (epoch 25.481), train_loss = 1.34542632, grad/param norm = 4.9758e-01, time/batch = 0.1792s	
1377/2700 (epoch 25.500), train_loss = 1.31446008, grad/param norm = 4.9912e-01, time/batch = 0.1721s	
1378/2700 (epoch 25.519), train_loss = 1.36464876, grad/param norm = 5.0210e-01, time/batch = 0.1831s	
1379/2700 (epoch 25.537), train_loss = 1.35840952, grad/param norm = 5.0956e-01, time/batch = 0.1837s	
1380/2700 (epoch 25.556), train_loss = 1.27798742, grad/param norm = 5.1519e-01, time/batch = 0.1826s	
1381/2700 (epoch 25.574), train_loss = 1.28766662, grad/param norm = 5.0976e-01, time/batch = 0.1547s	
1382/2700 (epoch 25.593), train_loss = 1.33404337, grad/param norm = 5.2054e-01, time/batch = 0.1598s	
1383/2700 (epoch 25.611), train_loss = 1.24919003, grad/param norm = 4.7733e-01, time/batch = 0.1581s	
1384/2700 (epoch 25.630), train_loss = 1.27134995, grad/param norm = 4.7553e-01, time/batch = 0.1638s	
1385/2700 (epoch 25.648), train_loss = 1.31634627, grad/param norm = 4.8352e-01, time/batch = 0.1455s	
1386/2700 (epoch 25.667), train_loss = 1.26618415, grad/param norm = 4.8878e-01, time/batch = 0.1547s	
1387/2700 (epoch 25.685), train_loss = 1.33042142, grad/param norm = 5.2107e-01, time/batch = 0.1526s	
1388/2700 (epoch 25.704), train_loss = 1.37114883, grad/param norm = 5.5747e-01, time/batch = 0.1617s	
1389/2700 (epoch 25.722), train_loss = 1.31746636, grad/param norm = 4.8577e-01, time/batch = 0.1659s	
1390/2700 (epoch 25.741), train_loss = 1.32157307, grad/param norm = 4.9752e-01, time/batch = 0.1622s	
1391/2700 (epoch 25.759), train_loss = 1.31014463, grad/param norm = 5.0993e-01, time/batch = 0.1700s	
1392/2700 (epoch 25.778), train_loss = 1.37028585, grad/param norm = 4.9784e-01, time/batch = 0.1622s	
1393/2700 (epoch 25.796), train_loss = 1.28742340, grad/param norm = 4.8033e-01, time/batch = 0.1816s	
1394/2700 (epoch 25.815), train_loss = 1.36180097, grad/param norm = 5.3002e-01, time/batch = 0.1781s	
1395/2700 (epoch 25.833), train_loss = 1.33442506, grad/param norm = 5.6806e-01, time/batch = 0.1807s	
1396/2700 (epoch 25.852), train_loss = 1.32769113, grad/param norm = 5.7435e-01, time/batch = 0.1801s	
1397/2700 (epoch 25.870), train_loss = 1.35725747, grad/param norm = 5.2838e-01, time/batch = 0.1757s	
1398/2700 (epoch 25.889), train_loss = 1.32282904, grad/param norm = 5.3842e-01, time/batch = 0.1801s	
1399/2700 (epoch 25.907), train_loss = 1.40340535, grad/param norm = 5.4613e-01, time/batch = 0.1791s	
1400/2700 (epoch 25.926), train_loss = 1.32427657, grad/param norm = 5.0008e-01, time/batch = 0.1795s	
1401/2700 (epoch 25.944), train_loss = 1.32492278, grad/param norm = 4.9941e-01, time/batch = 0.1767s	
1402/2700 (epoch 25.963), train_loss = 1.32749884, grad/param norm = 4.8045e-01, time/batch = 0.1654s	
1403/2700 (epoch 25.981), train_loss = 1.28381079, grad/param norm = 4.9980e-01, time/batch = 0.1542s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1404/2700 (epoch 26.000), train_loss = 1.41231387, grad/param norm = 5.3440e-01, time/batch = 0.1365s	
1405/2700 (epoch 26.019), train_loss = 1.39886469, grad/param norm = 5.2347e-01, time/batch = 0.1609s	
1406/2700 (epoch 26.037), train_loss = 1.38267037, grad/param norm = 5.3680e-01, time/batch = 0.1651s	
1407/2700 (epoch 26.056), train_loss = 1.30834328, grad/param norm = 5.3261e-01, time/batch = 0.1687s	
1408/2700 (epoch 26.074), train_loss = 1.29677881, grad/param norm = 5.1801e-01, time/batch = 0.1504s	
1409/2700 (epoch 26.093), train_loss = 1.29606584, grad/param norm = 4.9147e-01, time/batch = 0.1575s	
1410/2700 (epoch 26.111), train_loss = 1.26920972, grad/param norm = 4.8946e-01, time/batch = 0.1631s	
1411/2700 (epoch 26.130), train_loss = 1.33500133, grad/param norm = 4.9692e-01, time/batch = 0.1624s	
1412/2700 (epoch 26.148), train_loss = 1.29651294, grad/param norm = 4.7290e-01, time/batch = 0.1558s	
1413/2700 (epoch 26.167), train_loss = 1.34066398, grad/param norm = 4.9127e-01, time/batch = 0.1325s	
1414/2700 (epoch 26.185), train_loss = 1.29109418, grad/param norm = 4.7732e-01, time/batch = 0.1266s	
1415/2700 (epoch 26.204), train_loss = 1.33329038, grad/param norm = 5.0252e-01, time/batch = 0.1447s	
1416/2700 (epoch 26.222), train_loss = 1.28821726, grad/param norm = 4.9319e-01, time/batch = 0.1545s	
1417/2700 (epoch 26.241), train_loss = 1.22100553, grad/param norm = 4.8369e-01, time/batch = 0.1623s	
1418/2700 (epoch 26.259), train_loss = 1.26748275, grad/param norm = 5.0250e-01, time/batch = 0.1611s	
1419/2700 (epoch 26.278), train_loss = 1.33235993, grad/param norm = 5.1807e-01, time/batch = 0.1742s	
1420/2700 (epoch 26.296), train_loss = 1.29926139, grad/param norm = 4.9433e-01, time/batch = 0.1784s	
1421/2700 (epoch 26.315), train_loss = 1.27394545, grad/param norm = 4.9652e-01, time/batch = 0.1652s	
1422/2700 (epoch 26.333), train_loss = 1.30995782, grad/param norm = 5.2868e-01, time/batch = 0.1713s	
1423/2700 (epoch 26.352), train_loss = 1.30065554, grad/param norm = 5.1157e-01, time/batch = 0.1681s	
1424/2700 (epoch 26.370), train_loss = 1.30896245, grad/param norm = 4.9645e-01, time/batch = 0.1541s	
1425/2700 (epoch 26.389), train_loss = 1.27863622, grad/param norm = 4.9793e-01, time/batch = 0.1755s	
1426/2700 (epoch 26.407), train_loss = 1.33815346, grad/param norm = 5.1244e-01, time/batch = 0.1746s	
1427/2700 (epoch 26.426), train_loss = 1.37641190, grad/param norm = 5.0298e-01, time/batch = 0.1737s	
1428/2700 (epoch 26.444), train_loss = 1.30886045, grad/param norm = 5.0315e-01, time/batch = 0.1541s	
1429/2700 (epoch 26.463), train_loss = 1.35161941, grad/param norm = 5.5472e-01, time/batch = 0.1592s	
1430/2700 (epoch 26.481), train_loss = 1.33810035, grad/param norm = 6.0141e-01, time/batch = 0.1631s	
1431/2700 (epoch 26.500), train_loss = 1.29608934, grad/param norm = 5.2077e-01, time/batch = 0.1698s	
1432/2700 (epoch 26.519), train_loss = 1.34136465, grad/param norm = 5.0041e-01, time/batch = 0.1741s	
1433/2700 (epoch 26.537), train_loss = 1.33510071, grad/param norm = 5.2683e-01, time/batch = 0.1773s	
1434/2700 (epoch 26.556), train_loss = 1.24927586, grad/param norm = 4.8758e-01, time/batch = 0.1594s	
1435/2700 (epoch 26.574), train_loss = 1.27596779, grad/param norm = 5.5424e-01, time/batch = 0.1382s	
1436/2700 (epoch 26.593), train_loss = 1.32168348, grad/param norm = 5.4728e-01, time/batch = 0.1737s	
1437/2700 (epoch 26.611), train_loss = 1.23545051, grad/param norm = 5.0609e-01, time/batch = 0.1805s	
1438/2700 (epoch 26.630), train_loss = 1.25419853, grad/param norm = 4.8308e-01, time/batch = 0.1791s	
1439/2700 (epoch 26.648), train_loss = 1.29455162, grad/param norm = 4.8374e-01, time/batch = 0.1570s	
1440/2700 (epoch 26.667), train_loss = 1.24378126, grad/param norm = 4.7367e-01, time/batch = 0.1592s	
1441/2700 (epoch 26.685), train_loss = 1.30608836, grad/param norm = 5.0643e-01, time/batch = 0.1728s	
1442/2700 (epoch 26.704), train_loss = 1.34962380, grad/param norm = 5.3787e-01, time/batch = 0.1797s	
1443/2700 (epoch 26.722), train_loss = 1.29737717, grad/param norm = 4.7833e-01, time/batch = 0.1726s	
1444/2700 (epoch 26.741), train_loss = 1.30124691, grad/param norm = 4.9240e-01, time/batch = 0.1713s	
1445/2700 (epoch 26.759), train_loss = 1.28526955, grad/param norm = 4.9119e-01, time/batch = 0.1446s	
1446/2700 (epoch 26.778), train_loss = 1.34867723, grad/param norm = 5.0061e-01, time/batch = 0.1534s	
1447/2700 (epoch 26.796), train_loss = 1.28039626, grad/param norm = 5.7718e-01, time/batch = 0.1561s	
1448/2700 (epoch 26.815), train_loss = 1.36016966, grad/param norm = 5.9853e-01, time/batch = 0.1569s	
1449/2700 (epoch 26.833), train_loss = 1.30993264, grad/param norm = 5.2429e-01, time/batch = 0.1497s	
1450/2700 (epoch 26.852), train_loss = 1.29136940, grad/param norm = 5.0071e-01, time/batch = 0.1688s	
1451/2700 (epoch 26.870), train_loss = 1.32733490, grad/param norm = 4.8133e-01, time/batch = 0.1721s	
1452/2700 (epoch 26.889), train_loss = 1.30104640, grad/param norm = 5.1916e-01, time/batch = 0.1662s	
1453/2700 (epoch 26.907), train_loss = 1.37567152, grad/param norm = 5.2770e-01, time/batch = 0.1496s	
1454/2700 (epoch 26.926), train_loss = 1.29912867, grad/param norm = 4.9938e-01, time/batch = 0.1646s	
1455/2700 (epoch 26.944), train_loss = 1.30663250, grad/param norm = 5.0915e-01, time/batch = 0.1664s	
1456/2700 (epoch 26.963), train_loss = 1.31102101, grad/param norm = 4.9821e-01, time/batch = 0.1655s	
1457/2700 (epoch 26.981), train_loss = 1.26437562, grad/param norm = 5.2875e-01, time/batch = 0.1779s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1458/2700 (epoch 27.000), train_loss = 1.39419857, grad/param norm = 5.3749e-01, time/batch = 0.1742s	
1459/2700 (epoch 27.019), train_loss = 1.38217649, grad/param norm = 5.4991e-01, time/batch = 0.1743s	
1460/2700 (epoch 27.037), train_loss = 1.35386828, grad/param norm = 5.1406e-01, time/batch = 0.1550s	
1461/2700 (epoch 27.056), train_loss = 1.28211893, grad/param norm = 5.1485e-01, time/batch = 0.1683s	
1462/2700 (epoch 27.074), train_loss = 1.27678996, grad/param norm = 5.2236e-01, time/batch = 0.1659s	
1463/2700 (epoch 27.093), train_loss = 1.27869394, grad/param norm = 5.1889e-01, time/batch = 0.1623s	
1464/2700 (epoch 27.111), train_loss = 1.25429907, grad/param norm = 5.0066e-01, time/batch = 0.1636s	
1465/2700 (epoch 27.130), train_loss = 1.31090562, grad/param norm = 4.9846e-01, time/batch = 0.1615s	
1466/2700 (epoch 27.148), train_loss = 1.28211525, grad/param norm = 4.9126e-01, time/batch = 0.1570s	
1467/2700 (epoch 27.167), train_loss = 1.32202802, grad/param norm = 5.2334e-01, time/batch = 0.1468s	
1468/2700 (epoch 27.185), train_loss = 1.27471314, grad/param norm = 4.8985e-01, time/batch = 0.1520s	
1469/2700 (epoch 27.204), train_loss = 1.32121913, grad/param norm = 5.3502e-01, time/batch = 0.1663s	
1470/2700 (epoch 27.222), train_loss = 1.27054158, grad/param norm = 5.1309e-01, time/batch = 0.1609s	
1471/2700 (epoch 27.241), train_loss = 1.20074731, grad/param norm = 4.8004e-01, time/batch = 0.1635s	
1472/2700 (epoch 27.259), train_loss = 1.24245398, grad/param norm = 4.8506e-01, time/batch = 0.1569s	
1473/2700 (epoch 27.278), train_loss = 1.31006753, grad/param norm = 5.1816e-01, time/batch = 0.1545s	
1474/2700 (epoch 27.296), train_loss = 1.27632168, grad/param norm = 4.8565e-01, time/batch = 0.1672s	
1475/2700 (epoch 27.315), train_loss = 1.24749658, grad/param norm = 4.8026e-01, time/batch = 0.1706s	
1476/2700 (epoch 27.333), train_loss = 1.27988528, grad/param norm = 4.8807e-01, time/batch = 0.1734s	
1477/2700 (epoch 27.352), train_loss = 1.27896381, grad/param norm = 5.1374e-01, time/batch = 0.1574s	
1478/2700 (epoch 27.370), train_loss = 1.29500827, grad/param norm = 5.3169e-01, time/batch = 0.1717s	
1479/2700 (epoch 27.389), train_loss = 1.26376108, grad/param norm = 5.3044e-01, time/batch = 0.1659s	
1480/2700 (epoch 27.407), train_loss = 1.32160342, grad/param norm = 5.1784e-01, time/batch = 0.1663s	
1481/2700 (epoch 27.426), train_loss = 1.36793807, grad/param norm = 5.7091e-01, time/batch = 0.1543s	
1482/2700 (epoch 27.444), train_loss = 1.29234474, grad/param norm = 5.1972e-01, time/batch = 0.1570s	
1483/2700 (epoch 27.463), train_loss = 1.32155469, grad/param norm = 4.9674e-01, time/batch = 0.1512s	
1484/2700 (epoch 27.481), train_loss = 1.30135574, grad/param norm = 5.0115e-01, time/batch = 0.1597s	
1485/2700 (epoch 27.500), train_loss = 1.26871322, grad/param norm = 5.1113e-01, time/batch = 0.1612s	
1486/2700 (epoch 27.519), train_loss = 1.32543735, grad/param norm = 5.1330e-01, time/batch = 0.1644s	
1487/2700 (epoch 27.537), train_loss = 1.31410585, grad/param norm = 5.2674e-01, time/batch = 0.1640s	
1488/2700 (epoch 27.556), train_loss = 1.24104280, grad/param norm = 5.5094e-01, time/batch = 0.1403s	
1489/2700 (epoch 27.574), train_loss = 1.25507053, grad/param norm = 5.4488e-01, time/batch = 0.1789s	
1490/2700 (epoch 27.593), train_loss = 1.30168406, grad/param norm = 5.4383e-01, time/batch = 0.1796s	
1491/2700 (epoch 27.611), train_loss = 1.21369087, grad/param norm = 5.0030e-01, time/batch = 0.1589s	
1492/2700 (epoch 27.630), train_loss = 1.23606931, grad/param norm = 4.8286e-01, time/batch = 0.1762s	
1493/2700 (epoch 27.648), train_loss = 1.28022126, grad/param norm = 4.9164e-01, time/batch = 0.1723s	
1494/2700 (epoch 27.667), train_loss = 1.22767004, grad/param norm = 4.9696e-01, time/batch = 0.1767s	
1495/2700 (epoch 27.685), train_loss = 1.29122958, grad/param norm = 5.3064e-01, time/batch = 0.1786s	
1496/2700 (epoch 27.704), train_loss = 1.32974728, grad/param norm = 5.4677e-01, time/batch = 0.1807s	
1497/2700 (epoch 27.722), train_loss = 1.27701640, grad/param norm = 4.8100e-01, time/batch = 0.1787s	
1498/2700 (epoch 27.741), train_loss = 1.27821158, grad/param norm = 4.8875e-01, time/batch = 0.1637s	
1499/2700 (epoch 27.759), train_loss = 1.26431397, grad/param norm = 4.9068e-01, time/batch = 0.1777s	
1500/2700 (epoch 27.778), train_loss = 1.32853358, grad/param norm = 5.0401e-01, time/batch = 0.1772s	
1501/2700 (epoch 27.796), train_loss = 1.25126753, grad/param norm = 5.1232e-01, time/batch = 0.1727s	
1502/2700 (epoch 27.815), train_loss = 1.32261742, grad/param norm = 5.4734e-01, time/batch = 0.1783s	
1503/2700 (epoch 27.833), train_loss = 1.29968512, grad/param norm = 5.7052e-01, time/batch = 0.1702s	
1504/2700 (epoch 27.852), train_loss = 1.29084413, grad/param norm = 5.8932e-01, time/batch = 0.1715s	
1505/2700 (epoch 27.870), train_loss = 1.32033150, grad/param norm = 5.5664e-01, time/batch = 0.1756s	
1506/2700 (epoch 27.889), train_loss = 1.28645803, grad/param norm = 5.4504e-01, time/batch = 0.1767s	
1507/2700 (epoch 27.907), train_loss = 1.35542052, grad/param norm = 5.3291e-01, time/batch = 0.1789s	
1508/2700 (epoch 27.926), train_loss = 1.27770151, grad/param norm = 5.0581e-01, time/batch = 0.1815s	
1509/2700 (epoch 27.944), train_loss = 1.28640735, grad/param norm = 5.1970e-01, time/batch = 0.1524s	
1510/2700 (epoch 27.963), train_loss = 1.28748768, grad/param norm = 4.9183e-01, time/batch = 0.1717s	
1511/2700 (epoch 27.981), train_loss = 1.24284090, grad/param norm = 5.1475e-01, time/batch = 0.1491s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1512/2700 (epoch 28.000), train_loss = 1.36871412, grad/param norm = 5.3733e-01, time/batch = 0.1568s	
1513/2700 (epoch 28.019), train_loss = 1.36023494, grad/param norm = 5.2997e-01, time/batch = 0.1786s	
1514/2700 (epoch 28.037), train_loss = 1.33900149, grad/param norm = 5.4415e-01, time/batch = 0.1778s	
1515/2700 (epoch 28.056), train_loss = 1.26957128, grad/param norm = 5.4460e-01, time/batch = 0.1754s	
1516/2700 (epoch 28.074), train_loss = 1.26154540, grad/param norm = 5.3313e-01, time/batch = 0.1612s	
1517/2700 (epoch 28.093), train_loss = 1.25864886, grad/param norm = 5.0640e-01, time/batch = 0.1562s	
1518/2700 (epoch 28.111), train_loss = 1.23432364, grad/param norm = 5.1209e-01, time/batch = 0.1590s	
1519/2700 (epoch 28.130), train_loss = 1.29818107, grad/param norm = 5.1590e-01, time/batch = 0.1566s	
1520/2700 (epoch 28.148), train_loss = 1.26064588, grad/param norm = 4.8735e-01, time/batch = 0.1689s	
1521/2700 (epoch 28.167), train_loss = 1.29868674, grad/param norm = 5.1338e-01, time/batch = 0.1587s	
1522/2700 (epoch 28.185), train_loss = 1.25661177, grad/param norm = 5.0182e-01, time/batch = 0.1488s	
1523/2700 (epoch 28.204), train_loss = 1.29959551, grad/param norm = 5.2039e-01, time/batch = 0.1722s	
1524/2700 (epoch 28.222), train_loss = 1.25292882, grad/param norm = 5.1584e-01, time/batch = 0.1656s	
1525/2700 (epoch 28.241), train_loss = 1.18926245, grad/param norm = 5.0443e-01, time/batch = 0.1614s	
1526/2700 (epoch 28.259), train_loss = 1.22644311, grad/param norm = 5.0991e-01, time/batch = 0.1586s	
1527/2700 (epoch 28.278), train_loss = 1.29519565, grad/param norm = 5.2264e-01, time/batch = 0.1681s	
1528/2700 (epoch 28.296), train_loss = 1.25737971, grad/param norm = 5.0690e-01, time/batch = 0.1665s	
1529/2700 (epoch 28.315), train_loss = 1.23279872, grad/param norm = 5.0991e-01, time/batch = 0.1722s	
1530/2700 (epoch 28.333), train_loss = 1.26497563, grad/param norm = 5.2117e-01, time/batch = 0.1656s	
1531/2700 (epoch 28.352), train_loss = 1.25937682, grad/param norm = 5.1548e-01, time/batch = 0.1818s	
1532/2700 (epoch 28.370), train_loss = 1.26719534, grad/param norm = 5.0497e-01, time/batch = 0.1636s	
1533/2700 (epoch 28.389), train_loss = 1.23911086, grad/param norm = 5.0496e-01, time/batch = 0.1789s	
1534/2700 (epoch 28.407), train_loss = 1.29876953, grad/param norm = 5.1778e-01, time/batch = 0.1758s	
1535/2700 (epoch 28.426), train_loss = 1.33323130, grad/param norm = 4.9676e-01, time/batch = 0.1687s	
1536/2700 (epoch 28.444), train_loss = 1.27466425, grad/param norm = 5.1502e-01, time/batch = 0.1575s	
1537/2700 (epoch 28.463), train_loss = 1.31029220, grad/param norm = 5.3685e-01, time/batch = 0.1542s	
1538/2700 (epoch 28.481), train_loss = 1.28823077, grad/param norm = 5.4265e-01, time/batch = 0.1489s	
1539/2700 (epoch 28.500), train_loss = 1.25089045, grad/param norm = 5.4423e-01, time/batch = 0.1439s	
1540/2700 (epoch 28.519), train_loss = 1.30898785, grad/param norm = 5.5593e-01, time/batch = 0.1454s	
1541/2700 (epoch 28.537), train_loss = 1.29669410, grad/param norm = 5.2933e-01, time/batch = 0.1797s	
1542/2700 (epoch 28.556), train_loss = 1.21701302, grad/param norm = 5.1897e-01, time/batch = 0.1786s	
1543/2700 (epoch 28.574), train_loss = 1.22967881, grad/param norm = 5.1899e-01, time/batch = 0.1645s	
1544/2700 (epoch 28.593), train_loss = 1.27785191, grad/param norm = 5.3853e-01, time/batch = 0.1612s	
1545/2700 (epoch 28.611), train_loss = 1.19942812, grad/param norm = 5.2697e-01, time/batch = 0.1583s	
1546/2700 (epoch 28.630), train_loss = 1.22565872, grad/param norm = 5.2138e-01, time/batch = 0.1611s	
1547/2700 (epoch 28.648), train_loss = 1.26047505, grad/param norm = 5.0753e-01, time/batch = 0.1568s	
1548/2700 (epoch 28.667), train_loss = 1.20986776, grad/param norm = 5.0045e-01, time/batch = 0.1567s	
1549/2700 (epoch 28.685), train_loss = 1.27057966, grad/param norm = 5.1503e-01, time/batch = 0.1552s	
1550/2700 (epoch 28.704), train_loss = 1.31493884, grad/param norm = 5.5210e-01, time/batch = 0.1630s	
1551/2700 (epoch 28.722), train_loss = 1.26439006, grad/param norm = 5.0620e-01, time/batch = 0.1253s	
1552/2700 (epoch 28.741), train_loss = 1.26243996, grad/param norm = 5.0674e-01, time/batch = 0.1781s	
1553/2700 (epoch 28.759), train_loss = 1.24752079, grad/param norm = 5.1453e-01, time/batch = 0.1671s	
1554/2700 (epoch 28.778), train_loss = 1.31459449, grad/param norm = 5.1171e-01, time/batch = 0.1790s	
1555/2700 (epoch 28.796), train_loss = 1.22946421, grad/param norm = 5.0997e-01, time/batch = 0.1788s	
1556/2700 (epoch 28.815), train_loss = 1.29860566, grad/param norm = 5.2284e-01, time/batch = 0.1785s	
1557/2700 (epoch 28.833), train_loss = 1.27685514, grad/param norm = 5.5742e-01, time/batch = 0.1794s	
1558/2700 (epoch 28.852), train_loss = 1.26754331, grad/param norm = 5.5498e-01, time/batch = 0.1800s	
1559/2700 (epoch 28.870), train_loss = 1.29492246, grad/param norm = 5.1715e-01, time/batch = 0.1802s	
1560/2700 (epoch 28.889), train_loss = 1.26213636, grad/param norm = 5.0862e-01, time/batch = 0.1787s	
1561/2700 (epoch 28.907), train_loss = 1.32886325, grad/param norm = 5.2580e-01, time/batch = 0.1579s	
1562/2700 (epoch 28.926), train_loss = 1.25752432, grad/param norm = 5.2322e-01, time/batch = 0.1590s	
1563/2700 (epoch 28.944), train_loss = 1.26836503, grad/param norm = 5.3091e-01, time/batch = 0.1462s	
1564/2700 (epoch 28.963), train_loss = 1.27278326, grad/param norm = 5.0873e-01, time/batch = 0.1582s	
1565/2700 (epoch 28.981), train_loss = 1.22319810, grad/param norm = 5.3430e-01, time/batch = 0.1649s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
1566/2700 (epoch 29.000), train_loss = 1.35165665, grad/param norm = 5.4543e-01, time/batch = 0.1695s	
1567/2700 (epoch 29.019), train_loss = 1.34549238, grad/param norm = 5.5727e-01, time/batch = 0.1725s	
1568/2700 (epoch 29.037), train_loss = 1.30987244, grad/param norm = 5.2122e-01, time/batch = 0.1847s	
1569/2700 (epoch 29.056), train_loss = 1.24788247, grad/param norm = 5.4201e-01, time/batch = 0.1716s	
1570/2700 (epoch 29.074), train_loss = 1.24224910, grad/param norm = 5.5492e-01, time/batch = 0.1775s	
1571/2700 (epoch 29.093), train_loss = 1.24255552, grad/param norm = 5.3888e-01, time/batch = 0.1583s	
1572/2700 (epoch 29.111), train_loss = 1.21786755, grad/param norm = 5.0927e-01, time/batch = 0.1651s	
1573/2700 (epoch 29.130), train_loss = 1.27543054, grad/param norm = 5.1158e-01, time/batch = 0.1765s	
1574/2700 (epoch 29.148), train_loss = 1.24750613, grad/param norm = 5.0458e-01, time/batch = 0.1514s	
1575/2700 (epoch 29.167), train_loss = 1.28153353, grad/param norm = 5.4096e-01, time/batch = 0.1436s	
1576/2700 (epoch 29.185), train_loss = 1.23974041, grad/param norm = 5.0282e-01, time/batch = 0.1416s	
1577/2700 (epoch 29.204), train_loss = 1.28361489, grad/param norm = 5.4843e-01, time/batch = 0.1395s	
1578/2700 (epoch 29.222), train_loss = 1.23467411, grad/param norm = 5.2563e-01, time/batch = 0.1330s	
1579/2700 (epoch 29.241), train_loss = 1.16881928, grad/param norm = 4.8948e-01, time/batch = 0.1433s	
1580/2700 (epoch 29.259), train_loss = 1.20396178, grad/param norm = 4.9817e-01, time/batch = 0.1532s	
1581/2700 (epoch 29.278), train_loss = 1.27494496, grad/param norm = 5.3888e-01, time/batch = 0.1322s	
1582/2700 (epoch 29.296), train_loss = 1.24154846, grad/param norm = 5.2615e-01, time/batch = 0.1444s	
1583/2700 (epoch 29.315), train_loss = 1.21707421, grad/param norm = 5.4147e-01, time/batch = 0.1380s	
1584/2700 (epoch 29.333), train_loss = 1.24936130, grad/param norm = 5.4534e-01, time/batch = 0.1511s	
1585/2700 (epoch 29.352), train_loss = 1.24662145, grad/param norm = 5.5323e-01, time/batch = 0.1759s	
1586/2700 (epoch 29.370), train_loss = 1.25844557, grad/param norm = 5.4803e-01, time/batch = 0.1689s	
1587/2700 (epoch 29.389), train_loss = 1.22332912, grad/param norm = 5.2868e-01, time/batch = 0.1633s	
1588/2700 (epoch 29.407), train_loss = 1.28068731, grad/param norm = 5.2313e-01, time/batch = 0.1603s	
1589/2700 (epoch 29.426), train_loss = 1.32350741, grad/param norm = 5.6218e-01, time/batch = 0.1650s	
1590/2700 (epoch 29.444), train_loss = 1.25547202, grad/param norm = 5.2134e-01, time/batch = 0.1722s	
1591/2700 (epoch 29.463), train_loss = 1.28404499, grad/param norm = 5.0760e-01, time/batch = 0.1738s	
1592/2700 (epoch 29.481), train_loss = 1.26226346, grad/param norm = 5.2004e-01, time/batch = 0.1700s	
1593/2700 (epoch 29.500), train_loss = 1.22477675, grad/param norm = 5.1867e-01, time/batch = 0.1605s	
1594/2700 (epoch 29.519), train_loss = 1.28600108, grad/param norm = 5.1508e-01, time/batch = 0.1430s	
1595/2700 (epoch 29.537), train_loss = 1.27126051, grad/param norm = 5.2782e-01, time/batch = 0.1661s	
1596/2700 (epoch 29.556), train_loss = 1.19384816, grad/param norm = 5.1119e-01, time/batch = 0.1631s	
1597/2700 (epoch 29.574), train_loss = 1.21811282, grad/param norm = 5.5646e-01, time/batch = 0.1609s	
1598/2700 (epoch 29.593), train_loss = 1.26207088, grad/param norm = 5.4983e-01, time/batch = 0.1586s	
1599/2700 (epoch 29.611), train_loss = 1.18176490, grad/param norm = 5.2907e-01, time/batch = 0.1591s	
1600/2700 (epoch 29.630), train_loss = 1.20526355, grad/param norm = 5.1335e-01, time/batch = 0.1548s	
1601/2700 (epoch 29.648), train_loss = 1.24188832, grad/param norm = 5.0687e-01, time/batch = 0.1797s	
1602/2700 (epoch 29.667), train_loss = 1.19228127, grad/param norm = 5.0439e-01, time/batch = 0.1782s	
1603/2700 (epoch 29.685), train_loss = 1.25203397, grad/param norm = 5.4008e-01, time/batch = 0.1803s	
1604/2700 (epoch 29.704), train_loss = 1.29593886, grad/param norm = 5.6354e-01, time/batch = 0.1737s	
1605/2700 (epoch 29.722), train_loss = 1.24392221, grad/param norm = 4.9625e-01, time/batch = 0.1385s	
1606/2700 (epoch 29.741), train_loss = 1.24451918, grad/param norm = 5.0833e-01, time/batch = 0.1415s	
1607/2700 (epoch 29.759), train_loss = 1.22695518, grad/param norm = 5.1347e-01, time/batch = 0.1461s	
1608/2700 (epoch 29.778), train_loss = 1.30022219, grad/param norm = 5.5124e-01, time/batch = 0.1507s	
1609/2700 (epoch 29.796), train_loss = 1.22592687, grad/param norm = 5.8708e-01, time/batch = 0.1532s	
1610/2700 (epoch 29.815), train_loss = 1.29248652, grad/param norm = 5.7907e-01, time/batch = 0.1458s	
1611/2700 (epoch 29.833), train_loss = 1.25798735, grad/param norm = 5.4210e-01, time/batch = 0.1639s	
1612/2700 (epoch 29.852), train_loss = 1.23398479, grad/param norm = 5.1465e-01, time/batch = 0.1545s	
1613/2700 (epoch 29.870), train_loss = 1.27606392, grad/param norm = 5.1007e-01, time/batch = 0.1499s	
1614/2700 (epoch 29.889), train_loss = 1.24881198, grad/param norm = 5.3735e-01, time/batch = 0.1467s	
1615/2700 (epoch 29.907), train_loss = 1.31472505, grad/param norm = 5.4609e-01, time/batch = 0.1283s	
1616/2700 (epoch 29.926), train_loss = 1.24032617, grad/param norm = 5.3879e-01, time/batch = 0.1591s	
1617/2700 (epoch 29.944), train_loss = 1.24669454, grad/param norm = 5.2502e-01, time/batch = 0.1626s	
1618/2700 (epoch 29.963), train_loss = 1.25120972, grad/param norm = 5.0569e-01, time/batch = 0.1532s	
1619/2700 (epoch 29.981), train_loss = 1.20981825, grad/param norm = 5.4328e-01, time/batch = 0.1597s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
1620/2700 (epoch 30.000), train_loss = 1.33377185, grad/param norm = 5.6251e-01, time/batch = 0.1561s	
1621/2700 (epoch 30.019), train_loss = 1.32809252, grad/param norm = 5.4230e-01, time/batch = 0.1600s	
1622/2700 (epoch 30.037), train_loss = 1.30087007, grad/param norm = 5.6221e-01, time/batch = 0.1694s	
1623/2700 (epoch 30.056), train_loss = 1.23337734, grad/param norm = 5.5440e-01, time/batch = 0.1697s	
1624/2700 (epoch 30.074), train_loss = 1.22459968, grad/param norm = 5.4093e-01, time/batch = 0.1749s	
1625/2700 (epoch 30.093), train_loss = 1.22008155, grad/param norm = 5.1486e-01, time/batch = 0.1740s	
1626/2700 (epoch 30.111), train_loss = 1.19947270, grad/param norm = 5.2819e-01, time/batch = 0.1596s	
1627/2700 (epoch 30.130), train_loss = 1.26203579, grad/param norm = 5.3454e-01, time/batch = 0.1667s	
1628/2700 (epoch 30.148), train_loss = 1.22765677, grad/param norm = 5.0189e-01, time/batch = 0.1634s	
1629/2700 (epoch 30.167), train_loss = 1.25990136, grad/param norm = 5.2600e-01, time/batch = 0.1545s	
1630/2700 (epoch 30.185), train_loss = 1.21988359, grad/param norm = 5.1608e-01, time/batch = 0.1517s	
1631/2700 (epoch 30.204), train_loss = 1.26597931, grad/param norm = 5.3843e-01, time/batch = 0.1817s	
1632/2700 (epoch 30.222), train_loss = 1.21750947, grad/param norm = 5.2673e-01, time/batch = 0.1441s	
1633/2700 (epoch 30.241), train_loss = 1.15747286, grad/param norm = 5.1402e-01, time/batch = 0.1643s	
1634/2700 (epoch 30.259), train_loss = 1.18574816, grad/param norm = 5.1527e-01, time/batch = 0.1678s	
1635/2700 (epoch 30.278), train_loss = 1.25787314, grad/param norm = 5.3052e-01, time/batch = 0.1736s	
1636/2700 (epoch 30.296), train_loss = 1.21924126, grad/param norm = 5.1937e-01, time/batch = 0.1523s	
1637/2700 (epoch 30.315), train_loss = 1.19516024, grad/param norm = 5.2619e-01, time/batch = 0.1440s	
1638/2700 (epoch 30.333), train_loss = 1.22575206, grad/param norm = 5.2245e-01, time/batch = 0.1611s	
1639/2700 (epoch 30.352), train_loss = 1.22181580, grad/param norm = 5.2973e-01, time/batch = 0.1574s	
1640/2700 (epoch 30.370), train_loss = 1.23221934, grad/param norm = 5.3127e-01, time/batch = 0.1612s	
1641/2700 (epoch 30.389), train_loss = 1.20590853, grad/param norm = 5.2132e-01, time/batch = 0.1808s	
1642/2700 (epoch 30.407), train_loss = 1.26611759, grad/param norm = 5.4690e-01, time/batch = 0.1811s	
1643/2700 (epoch 30.426), train_loss = 1.30041696, grad/param norm = 5.2996e-01, time/batch = 0.1808s	
1644/2700 (epoch 30.444), train_loss = 1.24620298, grad/param norm = 5.4879e-01, time/batch = 0.1805s	
1645/2700 (epoch 30.463), train_loss = 1.27382703, grad/param norm = 5.4267e-01, time/batch = 0.1769s	
1646/2700 (epoch 30.481), train_loss = 1.24556869, grad/param norm = 5.3479e-01, time/batch = 0.1681s	
1647/2700 (epoch 30.500), train_loss = 1.20451813, grad/param norm = 5.2761e-01, time/batch = 0.1628s	
1648/2700 (epoch 30.519), train_loss = 1.26786135, grad/param norm = 5.2846e-01, time/batch = 0.1421s	
1649/2700 (epoch 30.537), train_loss = 1.25059446, grad/param norm = 5.2119e-01, time/batch = 0.1329s	
1650/2700 (epoch 30.556), train_loss = 1.17425899, grad/param norm = 5.1500e-01, time/batch = 0.1476s	
1651/2700 (epoch 30.574), train_loss = 1.19418692, grad/param norm = 5.3615e-01, time/batch = 0.1479s	
1652/2700 (epoch 30.593), train_loss = 1.24259099, grad/param norm = 5.5192e-01, time/batch = 0.1475s	
1653/2700 (epoch 30.611), train_loss = 1.16314173, grad/param norm = 5.2246e-01, time/batch = 0.1513s	
1654/2700 (epoch 30.630), train_loss = 1.18967406, grad/param norm = 5.1579e-01, time/batch = 0.1577s	
1655/2700 (epoch 30.648), train_loss = 1.22239294, grad/param norm = 5.0910e-01, time/batch = 0.1601s	
1656/2700 (epoch 30.667), train_loss = 1.17738631, grad/param norm = 5.1696e-01, time/batch = 0.1501s	
1657/2700 (epoch 30.685), train_loss = 1.23395792, grad/param norm = 5.3233e-01, time/batch = 0.1791s	
1658/2700 (epoch 30.704), train_loss = 1.27406749, grad/param norm = 5.5093e-01, time/batch = 0.1672s	
1659/2700 (epoch 30.722), train_loss = 1.23131951, grad/param norm = 5.1642e-01, time/batch = 0.1645s	
1660/2700 (epoch 30.741), train_loss = 1.22653981, grad/param norm = 5.1272e-01, time/batch = 0.1590s	
1661/2700 (epoch 30.759), train_loss = 1.21013694, grad/param norm = 5.2281e-01, time/batch = 0.1761s	
1662/2700 (epoch 30.778), train_loss = 1.28211448, grad/param norm = 5.4480e-01, time/batch = 0.1778s	
1663/2700 (epoch 30.796), train_loss = 1.19705763, grad/param norm = 5.4221e-01, time/batch = 0.1778s	
1664/2700 (epoch 30.815), train_loss = 1.26867404, grad/param norm = 5.8397e-01, time/batch = 0.1782s	
1665/2700 (epoch 30.833), train_loss = 1.26166566, grad/param norm = 6.3710e-01, time/batch = 0.1736s	
1666/2700 (epoch 30.852), train_loss = 1.23733848, grad/param norm = 5.9124e-01, time/batch = 0.1587s	
1667/2700 (epoch 30.870), train_loss = 1.26320137, grad/param norm = 5.3589e-01, time/batch = 0.1589s	
1668/2700 (epoch 30.889), train_loss = 1.22667025, grad/param norm = 5.1494e-01, time/batch = 0.1608s	
1669/2700 (epoch 30.907), train_loss = 1.28652445, grad/param norm = 5.3154e-01, time/batch = 0.1464s	
1670/2700 (epoch 30.926), train_loss = 1.21826027, grad/param norm = 5.2898e-01, time/batch = 0.1737s	
1671/2700 (epoch 30.944), train_loss = 1.23139356, grad/param norm = 5.4074e-01, time/batch = 0.1797s	
1672/2700 (epoch 30.963), train_loss = 1.23790855, grad/param norm = 5.2471e-01, time/batch = 0.1792s	
1673/2700 (epoch 30.981), train_loss = 1.18925718, grad/param norm = 5.4209e-01, time/batch = 0.1798s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
1674/2700 (epoch 31.000), train_loss = 1.31210596, grad/param norm = 5.4535e-01, time/batch = 0.1805s	
1675/2700 (epoch 31.019), train_loss = 1.31138214, grad/param norm = 5.7313e-01, time/batch = 0.1785s	
1676/2700 (epoch 31.037), train_loss = 1.27253172, grad/param norm = 5.4292e-01, time/batch = 0.1739s	
1677/2700 (epoch 31.056), train_loss = 1.21501600, grad/param norm = 5.5911e-01, time/batch = 0.1577s	
1678/2700 (epoch 31.074), train_loss = 1.20841339, grad/param norm = 5.6311e-01, time/batch = 0.1517s	
1679/2700 (epoch 31.093), train_loss = 1.20224275, grad/param norm = 5.3847e-01, time/batch = 0.1405s	
1680/2700 (epoch 31.111), train_loss = 1.18167169, grad/param norm = 5.1613e-01, time/batch = 0.1450s	
1681/2700 (epoch 31.130), train_loss = 1.24221030, grad/param norm = 5.3124e-01, time/batch = 0.1798s	
1682/2700 (epoch 31.148), train_loss = 1.21699974, grad/param norm = 5.2312e-01, time/batch = 0.1787s	
1683/2700 (epoch 31.167), train_loss = 1.24621869, grad/param norm = 5.5959e-01, time/batch = 0.1721s	
1684/2700 (epoch 31.185), train_loss = 1.20260483, grad/param norm = 5.1317e-01, time/batch = 0.1675s	
1685/2700 (epoch 31.204), train_loss = 1.24705089, grad/param norm = 5.5031e-01, time/batch = 0.1642s	
1686/2700 (epoch 31.222), train_loss = 1.20055960, grad/param norm = 5.3906e-01, time/batch = 0.1597s	
1687/2700 (epoch 31.241), train_loss = 1.14059736, grad/param norm = 5.0346e-01, time/batch = 0.1567s	
1688/2700 (epoch 31.259), train_loss = 1.16941896, grad/param norm = 5.1403e-01, time/batch = 0.1487s	
1689/2700 (epoch 31.278), train_loss = 1.23823503, grad/param norm = 5.4151e-01, time/batch = 0.1357s	
1690/2700 (epoch 31.296), train_loss = 1.20210474, grad/param norm = 5.2270e-01, time/batch = 0.1219s	
1691/2700 (epoch 31.315), train_loss = 1.17584772, grad/param norm = 5.2784e-01, time/batch = 0.1790s	
1692/2700 (epoch 31.333), train_loss = 1.20774130, grad/param norm = 5.2411e-01, time/batch = 0.1785s	
1693/2700 (epoch 31.352), train_loss = 1.20313158, grad/param norm = 5.4773e-01, time/batch = 0.1815s	
1694/2700 (epoch 31.370), train_loss = 1.22043000, grad/param norm = 5.7068e-01, time/batch = 0.1812s	
1695/2700 (epoch 31.389), train_loss = 1.18902139, grad/param norm = 5.4389e-01, time/batch = 0.1805s	
1696/2700 (epoch 31.407), train_loss = 1.24657017, grad/param norm = 5.4408e-01, time/batch = 0.1742s	
1697/2700 (epoch 31.426), train_loss = 1.28816126, grad/param norm = 5.7326e-01, time/batch = 0.1648s	
1698/2700 (epoch 31.444), train_loss = 1.22256855, grad/param norm = 5.2202e-01, time/batch = 0.1546s	
1699/2700 (epoch 31.463), train_loss = 1.25234630, grad/param norm = 5.3220e-01, time/batch = 0.1595s	
1700/2700 (epoch 31.481), train_loss = 1.22980406, grad/param norm = 5.6775e-01, time/batch = 0.1582s	
1701/2700 (epoch 31.500), train_loss = 1.18746804, grad/param norm = 5.4473e-01, time/batch = 0.1791s	
1702/2700 (epoch 31.519), train_loss = 1.25669566, grad/param norm = 5.4623e-01, time/batch = 0.1791s	
1703/2700 (epoch 31.537), train_loss = 1.23347130, grad/param norm = 5.5507e-01, time/batch = 0.1765s	
1704/2700 (epoch 31.556), train_loss = 1.15687220, grad/param norm = 5.2184e-01, time/batch = 0.1699s	
1705/2700 (epoch 31.574), train_loss = 1.18406085, grad/param norm = 5.7801e-01, time/batch = 0.1679s	
1706/2700 (epoch 31.593), train_loss = 1.22690155, grad/param norm = 5.5754e-01, time/batch = 0.1608s	
1707/2700 (epoch 31.611), train_loss = 1.14763553, grad/param norm = 5.3345e-01, time/batch = 0.1612s	
1708/2700 (epoch 31.630), train_loss = 1.17295237, grad/param norm = 5.2626e-01, time/batch = 0.1407s	
1709/2700 (epoch 31.648), train_loss = 1.20704659, grad/param norm = 5.2043e-01, time/batch = 0.1470s	
1710/2700 (epoch 31.667), train_loss = 1.16154392, grad/param norm = 5.2654e-01, time/batch = 0.1398s	
1711/2700 (epoch 31.685), train_loss = 1.21553512, grad/param norm = 5.5783e-01, time/batch = 0.1420s	
1712/2700 (epoch 31.704), train_loss = 1.25989740, grad/param norm = 5.7373e-01, time/batch = 0.1787s	
1713/2700 (epoch 31.722), train_loss = 1.21092682, grad/param norm = 5.0831e-01, time/batch = 0.1799s	
1714/2700 (epoch 31.741), train_loss = 1.21024335, grad/param norm = 5.1984e-01, time/batch = 0.1790s	
1715/2700 (epoch 31.759), train_loss = 1.18913175, grad/param norm = 5.2162e-01, time/batch = 0.1718s	
1716/2700 (epoch 31.778), train_loss = 1.26542044, grad/param norm = 5.5655e-01, time/batch = 0.1682s	
1717/2700 (epoch 31.796), train_loss = 1.18634211, grad/param norm = 5.8524e-01, time/batch = 0.1451s	
1718/2700 (epoch 31.815), train_loss = 1.25459669, grad/param norm = 5.8512e-01, time/batch = 0.1369s	
1719/2700 (epoch 31.833), train_loss = 1.22515890, grad/param norm = 5.5069e-01, time/batch = 0.1610s	
1720/2700 (epoch 31.852), train_loss = 1.19886503, grad/param norm = 5.2390e-01, time/batch = 0.1638s	
1721/2700 (epoch 31.870), train_loss = 1.24437365, grad/param norm = 5.3964e-01, time/batch = 0.1612s	
1722/2700 (epoch 31.889), train_loss = 1.21417730, grad/param norm = 5.4579e-01, time/batch = 0.1525s	
1723/2700 (epoch 31.907), train_loss = 1.27175798, grad/param norm = 5.5647e-01, time/batch = 0.1355s	
1724/2700 (epoch 31.926), train_loss = 1.20106212, grad/param norm = 5.3772e-01, time/batch = 0.1263s	
1725/2700 (epoch 31.944), train_loss = 1.20770427, grad/param norm = 5.2422e-01, time/batch = 0.1335s	
1726/2700 (epoch 31.963), train_loss = 1.21611731, grad/param norm = 5.1977e-01, time/batch = 0.1449s	
1727/2700 (epoch 31.981), train_loss = 1.17216756, grad/param norm = 5.5032e-01, time/batch = 0.1473s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
1728/2700 (epoch 32.000), train_loss = 1.29252680, grad/param norm = 5.5477e-01, time/batch = 0.1630s	
1729/2700 (epoch 32.019), train_loss = 1.28883859, grad/param norm = 5.3898e-01, time/batch = 0.1807s	
1730/2700 (epoch 32.037), train_loss = 1.25949743, grad/param norm = 5.5384e-01, time/batch = 0.1783s	
1731/2700 (epoch 32.056), train_loss = 1.19902694, grad/param norm = 5.6685e-01, time/batch = 0.1669s	
1732/2700 (epoch 32.074), train_loss = 1.19137955, grad/param norm = 5.6088e-01, time/batch = 0.1533s	
1733/2700 (epoch 32.093), train_loss = 1.18586898, grad/param norm = 5.3060e-01, time/batch = 0.1681s	
1734/2700 (epoch 32.111), train_loss = 1.16779766, grad/param norm = 5.4693e-01, time/batch = 0.1666s	
1735/2700 (epoch 32.130), train_loss = 1.23025470, grad/param norm = 5.5720e-01, time/batch = 0.1582s	
1736/2700 (epoch 32.148), train_loss = 1.19885392, grad/param norm = 5.2483e-01, time/batch = 0.1526s	
1737/2700 (epoch 32.167), train_loss = 1.22997209, grad/param norm = 5.5662e-01, time/batch = 0.1455s	
1738/2700 (epoch 32.185), train_loss = 1.19350803, grad/param norm = 5.7136e-01, time/batch = 0.1491s	
1739/2700 (epoch 32.204), train_loss = 1.23868923, grad/param norm = 5.6442e-01, time/batch = 0.1533s	
1740/2700 (epoch 32.222), train_loss = 1.18643760, grad/param norm = 5.4819e-01, time/batch = 0.1479s	
1741/2700 (epoch 32.241), train_loss = 1.13186369, grad/param norm = 5.3538e-01, time/batch = 0.1702s	
1742/2700 (epoch 32.259), train_loss = 1.15389980, grad/param norm = 5.3087e-01, time/batch = 0.1759s	
1743/2700 (epoch 32.278), train_loss = 1.22321303, grad/param norm = 5.4056e-01, time/batch = 0.1641s	
1744/2700 (epoch 32.296), train_loss = 1.18399969, grad/param norm = 5.3188e-01, time/batch = 0.1792s	
1745/2700 (epoch 32.315), train_loss = 1.16035865, grad/param norm = 5.3509e-01, time/batch = 0.1824s	
1746/2700 (epoch 32.333), train_loss = 1.18881883, grad/param norm = 5.2721e-01, time/batch = 0.1803s	
1747/2700 (epoch 32.352), train_loss = 1.18352203, grad/param norm = 5.4179e-01, time/batch = 0.1716s	
1748/2700 (epoch 32.370), train_loss = 1.19662989, grad/param norm = 5.4587e-01, time/batch = 0.1698s	
1749/2700 (epoch 32.389), train_loss = 1.17329531, grad/param norm = 5.3479e-01, time/batch = 0.1639s	
1750/2700 (epoch 32.407), train_loss = 1.23214717, grad/param norm = 5.6249e-01, time/batch = 0.1621s	
1751/2700 (epoch 32.426), train_loss = 1.26222543, grad/param norm = 5.2676e-01, time/batch = 0.1780s	
1752/2700 (epoch 32.444), train_loss = 1.21866900, grad/param norm = 5.8798e-01, time/batch = 0.1763s	
1753/2700 (epoch 32.463), train_loss = 1.24648077, grad/param norm = 5.9533e-01, time/batch = 0.1638s	
1754/2700 (epoch 32.481), train_loss = 1.21298790, grad/param norm = 5.7308e-01, time/batch = 0.1528s	
1755/2700 (epoch 32.500), train_loss = 1.16362119, grad/param norm = 5.1790e-01, time/batch = 0.1436s	
1756/2700 (epoch 32.519), train_loss = 1.23362019, grad/param norm = 5.2818e-01, time/batch = 0.1501s	
1757/2700 (epoch 32.537), train_loss = 1.21155913, grad/param norm = 5.2977e-01, time/batch = 0.1501s	
1758/2700 (epoch 32.556), train_loss = 1.14042183, grad/param norm = 5.3896e-01, time/batch = 0.1428s	
1759/2700 (epoch 32.574), train_loss = 1.16069415, grad/param norm = 5.4464e-01, time/batch = 0.1436s	
1760/2700 (epoch 32.593), train_loss = 1.20841441, grad/param norm = 5.5275e-01, time/batch = 0.1465s	
1761/2700 (epoch 32.611), train_loss = 1.13185224, grad/param norm = 5.3560e-01, time/batch = 0.1717s	
1762/2700 (epoch 32.630), train_loss = 1.15575397, grad/param norm = 5.3275e-01, time/batch = 0.1760s	
1763/2700 (epoch 32.648), train_loss = 1.19126473, grad/param norm = 5.3393e-01, time/batch = 0.1772s	
1764/2700 (epoch 32.667), train_loss = 1.14706738, grad/param norm = 5.4065e-01, time/batch = 0.1644s	
1765/2700 (epoch 32.685), train_loss = 1.19853022, grad/param norm = 5.5408e-01, time/batch = 0.1739s	
1766/2700 (epoch 32.704), train_loss = 1.23746501, grad/param norm = 5.5798e-01, time/batch = 0.1638s	
1767/2700 (epoch 32.722), train_loss = 1.19614383, grad/param norm = 5.1297e-01, time/batch = 0.1642s	
1768/2700 (epoch 32.741), train_loss = 1.19244776, grad/param norm = 5.1855e-01, time/batch = 0.1412s	
1769/2700 (epoch 32.759), train_loss = 1.17066821, grad/param norm = 5.1749e-01, time/batch = 0.1661s	
1770/2700 (epoch 32.778), train_loss = 1.24609046, grad/param norm = 5.5086e-01, time/batch = 0.1600s	
1771/2700 (epoch 32.796), train_loss = 1.16097690, grad/param norm = 5.4613e-01, time/batch = 0.1803s	
1772/2700 (epoch 32.815), train_loss = 1.23196582, grad/param norm = 5.8664e-01, time/batch = 0.1781s	
1773/2700 (epoch 32.833), train_loss = 1.22345683, grad/param norm = 6.2121e-01, time/batch = 0.1798s	
1774/2700 (epoch 32.852), train_loss = 1.19682555, grad/param norm = 5.9011e-01, time/batch = 0.1807s	
1775/2700 (epoch 32.870), train_loss = 1.22914953, grad/param norm = 5.5285e-01, time/batch = 0.1534s	
1776/2700 (epoch 32.889), train_loss = 1.19487438, grad/param norm = 5.3815e-01, time/batch = 0.1699s	
1777/2700 (epoch 32.907), train_loss = 1.24928683, grad/param norm = 5.5372e-01, time/batch = 0.1801s	
1778/2700 (epoch 32.926), train_loss = 1.18336740, grad/param norm = 5.4425e-01, time/batch = 0.1700s	
1779/2700 (epoch 32.944), train_loss = 1.19259807, grad/param norm = 5.5259e-01, time/batch = 0.1783s	
1780/2700 (epoch 32.963), train_loss = 1.20176782, grad/param norm = 5.2815e-01, time/batch = 0.1788s	
1781/2700 (epoch 32.981), train_loss = 1.15376470, grad/param norm = 5.3750e-01, time/batch = 0.1675s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
1782/2700 (epoch 33.000), train_loss = 1.27009926, grad/param norm = 5.4053e-01, time/batch = 0.1660s	
1783/2700 (epoch 33.019), train_loss = 1.27162142, grad/param norm = 5.6044e-01, time/batch = 0.1677s	
1784/2700 (epoch 33.037), train_loss = 1.23965691, grad/param norm = 5.7151e-01, time/batch = 0.1677s	
1785/2700 (epoch 33.056), train_loss = 1.17909614, grad/param norm = 5.6751e-01, time/batch = 0.1523s	
1786/2700 (epoch 33.074), train_loss = 1.17420409, grad/param norm = 5.6019e-01, time/batch = 0.1526s	
1787/2700 (epoch 33.093), train_loss = 1.16743762, grad/param norm = 5.4132e-01, time/batch = 0.1657s	
1788/2700 (epoch 33.111), train_loss = 1.14875419, grad/param norm = 5.3302e-01, time/batch = 0.1498s	
1789/2700 (epoch 33.130), train_loss = 1.21383514, grad/param norm = 5.6653e-01, time/batch = 0.1510s	
1790/2700 (epoch 33.148), train_loss = 1.19409677, grad/param norm = 5.6290e-01, time/batch = 0.1532s	
1791/2700 (epoch 33.167), train_loss = 1.22056689, grad/param norm = 6.0517e-01, time/batch = 0.1599s	
1792/2700 (epoch 33.185), train_loss = 1.17398769, grad/param norm = 5.4626e-01, time/batch = 0.1654s	
1793/2700 (epoch 33.204), train_loss = 1.22482861, grad/param norm = 5.9700e-01, time/batch = 0.1636s	
1794/2700 (epoch 33.222), train_loss = 1.17093406, grad/param norm = 5.5811e-01, time/batch = 0.1555s	
1795/2700 (epoch 33.241), train_loss = 1.11494171, grad/param norm = 5.2189e-01, time/batch = 0.1511s	
1796/2700 (epoch 33.259), train_loss = 1.14407587, grad/param norm = 5.4713e-01, time/batch = 0.1263s	
1797/2700 (epoch 33.278), train_loss = 1.20492388, grad/param norm = 5.6399e-01, time/batch = 0.1470s	
1798/2700 (epoch 33.296), train_loss = 1.16975150, grad/param norm = 5.3847e-01, time/batch = 0.1479s	
1799/2700 (epoch 33.315), train_loss = 1.14198598, grad/param norm = 5.4223e-01, time/batch = 0.1450s	
1800/2700 (epoch 33.333), train_loss = 1.17534782, grad/param norm = 5.4194e-01, time/batch = 0.1439s	
1801/2700 (epoch 33.352), train_loss = 1.16711065, grad/param norm = 5.6459e-01, time/batch = 0.1302s	
1802/2700 (epoch 33.370), train_loss = 1.18444473, grad/param norm = 5.7669e-01, time/batch = 0.1329s	
1803/2700 (epoch 33.389), train_loss = 1.15466109, grad/param norm = 5.4265e-01, time/batch = 0.1344s	
1804/2700 (epoch 33.407), train_loss = 1.21445396, grad/param norm = 5.5528e-01, time/batch = 0.1391s	
1805/2700 (epoch 33.426), train_loss = 1.25198334, grad/param norm = 5.6498e-01, time/batch = 0.1498s	
1806/2700 (epoch 33.444), train_loss = 1.19255203, grad/param norm = 5.3204e-01, time/batch = 0.1511s	
1807/2700 (epoch 33.463), train_loss = 1.21994397, grad/param norm = 5.5451e-01, time/batch = 0.1476s	
1808/2700 (epoch 33.481), train_loss = 1.19198415, grad/param norm = 5.6845e-01, time/batch = 0.1469s	
1809/2700 (epoch 33.500), train_loss = 1.15027508, grad/param norm = 5.5426e-01, time/batch = 0.1408s	
1810/2700 (epoch 33.519), train_loss = 1.22363472, grad/param norm = 5.5493e-01, time/batch = 0.1347s	
1811/2700 (epoch 33.537), train_loss = 1.19637838, grad/param norm = 5.5369e-01, time/batch = 0.1547s	
1812/2700 (epoch 33.556), train_loss = 1.12522999, grad/param norm = 5.4781e-01, time/batch = 0.1290s	
1813/2700 (epoch 33.574), train_loss = 1.14671107, grad/param norm = 5.6134e-01, time/batch = 0.1624s	
1814/2700 (epoch 33.593), train_loss = 1.19294797, grad/param norm = 5.5660e-01, time/batch = 0.1677s	
1815/2700 (epoch 33.611), train_loss = 1.11704246, grad/param norm = 5.3853e-01, time/batch = 0.1718s	
1816/2700 (epoch 33.630), train_loss = 1.13938961, grad/param norm = 5.3477e-01, time/batch = 0.1588s	
1817/2700 (epoch 33.648), train_loss = 1.17422875, grad/param norm = 5.2931e-01, time/batch = 0.1658s	
1818/2700 (epoch 33.667), train_loss = 1.12934450, grad/param norm = 5.2640e-01, time/batch = 0.1558s	
1819/2700 (epoch 33.685), train_loss = 1.17712790, grad/param norm = 5.3804e-01, time/batch = 0.1772s	
1820/2700 (epoch 33.704), train_loss = 1.22086223, grad/param norm = 5.6774e-01, time/batch = 0.1806s	
1821/2700 (epoch 33.722), train_loss = 1.18242079, grad/param norm = 5.3402e-01, time/batch = 0.1828s	
1822/2700 (epoch 33.741), train_loss = 1.17683381, grad/param norm = 5.2996e-01, time/batch = 0.1735s	
1823/2700 (epoch 33.759), train_loss = 1.15640669, grad/param norm = 5.3656e-01, time/batch = 0.1762s	
1824/2700 (epoch 33.778), train_loss = 1.23091044, grad/param norm = 5.5417e-01, time/batch = 0.1731s	
1825/2700 (epoch 33.796), train_loss = 1.14315219, grad/param norm = 5.4960e-01, time/batch = 0.1599s	
1826/2700 (epoch 33.815), train_loss = 1.21412814, grad/param norm = 5.7493e-01, time/batch = 0.1615s	
1827/2700 (epoch 33.833), train_loss = 1.19876830, grad/param norm = 5.9367e-01, time/batch = 0.1551s	
1828/2700 (epoch 33.852), train_loss = 1.17603655, grad/param norm = 5.7021e-01, time/batch = 0.1450s	
1829/2700 (epoch 33.870), train_loss = 1.21080750, grad/param norm = 5.5916e-01, time/batch = 0.1184s	
1830/2700 (epoch 33.889), train_loss = 1.18051355, grad/param norm = 5.4830e-01, time/batch = 0.1619s	
1831/2700 (epoch 33.907), train_loss = 1.23168690, grad/param norm = 5.7855e-01, time/batch = 0.1813s	
1832/2700 (epoch 33.926), train_loss = 1.16766655, grad/param norm = 5.5937e-01, time/batch = 0.1766s	
1833/2700 (epoch 33.944), train_loss = 1.17383767, grad/param norm = 5.5235e-01, time/batch = 0.1604s	
1834/2700 (epoch 33.963), train_loss = 1.18644357, grad/param norm = 5.5154e-01, time/batch = 0.1587s	
1835/2700 (epoch 33.981), train_loss = 1.14253842, grad/param norm = 5.7342e-01, time/batch = 0.1541s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
1836/2700 (epoch 34.000), train_loss = 1.25413078, grad/param norm = 5.5905e-01, time/batch = 0.1626s	
1837/2700 (epoch 34.019), train_loss = 1.25284109, grad/param norm = 5.5852e-01, time/batch = 0.1642s	
1838/2700 (epoch 34.037), train_loss = 1.21749745, grad/param norm = 5.5095e-01, time/batch = 0.1656s	
1839/2700 (epoch 34.056), train_loss = 1.16130684, grad/param norm = 5.6612e-01, time/batch = 0.1656s	
1840/2700 (epoch 34.074), train_loss = 1.15725678, grad/param norm = 5.7460e-01, time/batch = 0.1443s	
1841/2700 (epoch 34.093), train_loss = 1.15431353, grad/param norm = 5.5609e-01, time/batch = 0.1824s	
1842/2700 (epoch 34.111), train_loss = 1.13286816, grad/param norm = 5.4049e-01, time/batch = 0.1791s	
1843/2700 (epoch 34.130), train_loss = 1.19539414, grad/param norm = 5.5876e-01, time/batch = 0.1604s	
1844/2700 (epoch 34.148), train_loss = 1.17341128, grad/param norm = 5.4472e-01, time/batch = 0.1441s	
1845/2700 (epoch 34.167), train_loss = 1.20039100, grad/param norm = 5.6939e-01, time/batch = 0.1234s	
1846/2700 (epoch 34.185), train_loss = 1.16152744, grad/param norm = 5.6651e-01, time/batch = 0.1389s	
1847/2700 (epoch 34.204), train_loss = 1.20644646, grad/param norm = 5.6790e-01, time/batch = 0.1454s	
1848/2700 (epoch 34.222), train_loss = 1.15505550, grad/param norm = 5.6602e-01, time/batch = 0.1571s	
1849/2700 (epoch 34.241), train_loss = 1.10580738, grad/param norm = 5.5458e-01, time/batch = 0.1655s	
1850/2700 (epoch 34.259), train_loss = 1.12790896, grad/param norm = 5.4894e-01, time/batch = 0.1538s	
1851/2700 (epoch 34.278), train_loss = 1.18945724, grad/param norm = 5.5064e-01, time/batch = 0.1789s	
1852/2700 (epoch 34.296), train_loss = 1.15228841, grad/param norm = 5.4595e-01, time/batch = 0.1742s	
1853/2700 (epoch 34.315), train_loss = 1.12986035, grad/param norm = 5.5925e-01, time/batch = 0.1492s	
1854/2700 (epoch 34.333), train_loss = 1.16451479, grad/param norm = 5.7575e-01, time/batch = 0.1448s	
1855/2700 (epoch 34.352), train_loss = 1.15834630, grad/param norm = 5.9945e-01, time/batch = 0.1401s	
1856/2700 (epoch 34.370), train_loss = 1.16955367, grad/param norm = 5.9308e-01, time/batch = 0.1629s	
1857/2700 (epoch 34.389), train_loss = 1.14593116, grad/param norm = 5.5959e-01, time/batch = 0.1662s	
1858/2700 (epoch 34.407), train_loss = 1.19989402, grad/param norm = 5.7189e-01, time/batch = 0.1654s	
1859/2700 (epoch 34.426), train_loss = 1.22950097, grad/param norm = 5.3967e-01, time/batch = 0.1652s	
1860/2700 (epoch 34.444), train_loss = 1.18561367, grad/param norm = 5.8024e-01, time/batch = 0.1668s	
1861/2700 (epoch 34.463), train_loss = 1.20548974, grad/param norm = 5.6992e-01, time/batch = 0.1775s	
1862/2700 (epoch 34.481), train_loss = 1.17340663, grad/param norm = 5.5389e-01, time/batch = 0.1695s	
1863/2700 (epoch 34.500), train_loss = 1.13149065, grad/param norm = 5.3916e-01, time/batch = 0.1512s	
1864/2700 (epoch 34.519), train_loss = 1.20446401, grad/param norm = 5.5563e-01, time/batch = 0.1468s	
1865/2700 (epoch 34.537), train_loss = 1.18154521, grad/param norm = 5.5599e-01, time/batch = 0.1298s	
1866/2700 (epoch 34.556), train_loss = 1.11026345, grad/param norm = 5.5172e-01, time/batch = 0.1397s	
1867/2700 (epoch 34.574), train_loss = 1.12945925, grad/param norm = 5.6386e-01, time/batch = 0.1423s	
1868/2700 (epoch 34.593), train_loss = 1.18012289, grad/param norm = 5.8290e-01, time/batch = 0.1480s	
1869/2700 (epoch 34.611), train_loss = 1.10418647, grad/param norm = 5.5089e-01, time/batch = 0.1576s	
1870/2700 (epoch 34.630), train_loss = 1.12695550, grad/param norm = 5.4190e-01, time/batch = 0.1672s	
1871/2700 (epoch 34.648), train_loss = 1.16082451, grad/param norm = 5.5362e-01, time/batch = 0.1499s	
1872/2700 (epoch 34.667), train_loss = 1.12210067, grad/param norm = 5.6360e-01, time/batch = 0.1723s	
1873/2700 (epoch 34.685), train_loss = 1.16378685, grad/param norm = 5.5517e-01, time/batch = 0.1519s	
1874/2700 (epoch 34.704), train_loss = 1.20700129, grad/param norm = 5.9175e-01, time/batch = 0.1790s	
1875/2700 (epoch 34.722), train_loss = 1.17224663, grad/param norm = 5.5325e-01, time/batch = 0.1716s	
1876/2700 (epoch 34.741), train_loss = 1.16246803, grad/param norm = 5.3475e-01, time/batch = 0.1732s	
1877/2700 (epoch 34.759), train_loss = 1.14011650, grad/param norm = 5.3442e-01, time/batch = 0.1656s	
1878/2700 (epoch 34.778), train_loss = 1.21367530, grad/param norm = 5.6579e-01, time/batch = 0.1595s	
1879/2700 (epoch 34.796), train_loss = 1.12724392, grad/param norm = 5.6042e-01, time/batch = 0.1611s	
1880/2700 (epoch 34.815), train_loss = 1.19857688, grad/param norm = 5.8975e-01, time/batch = 0.1694s	
1881/2700 (epoch 34.833), train_loss = 1.17920376, grad/param norm = 5.7177e-01, time/batch = 0.1793s	
1882/2700 (epoch 34.852), train_loss = 1.15234377, grad/param norm = 5.4951e-01, time/batch = 0.1554s	
1883/2700 (epoch 34.870), train_loss = 1.20051245, grad/param norm = 5.7049e-01, time/batch = 0.1616s	
1884/2700 (epoch 34.889), train_loss = 1.16696513, grad/param norm = 5.7086e-01, time/batch = 0.1663s	
1885/2700 (epoch 34.907), train_loss = 1.21750836, grad/param norm = 5.8248e-01, time/batch = 0.1647s	
1886/2700 (epoch 34.926), train_loss = 1.15328855, grad/param norm = 5.7062e-01, time/batch = 0.1800s	
1887/2700 (epoch 34.944), train_loss = 1.15599735, grad/param norm = 5.5881e-01, time/batch = 0.1795s	
1888/2700 (epoch 34.963), train_loss = 1.17170347, grad/param norm = 5.5121e-01, time/batch = 0.1734s	
1889/2700 (epoch 34.981), train_loss = 1.12908170, grad/param norm = 5.8023e-01, time/batch = 0.1600s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
1890/2700 (epoch 35.000), train_loss = 1.23800406, grad/param norm = 5.7407e-01, time/batch = 0.1524s	
1891/2700 (epoch 35.019), train_loss = 1.23953738, grad/param norm = 5.7137e-01, time/batch = 0.1790s	
1892/2700 (epoch 35.037), train_loss = 1.21135133, grad/param norm = 6.0306e-01, time/batch = 0.1731s	
1893/2700 (epoch 35.056), train_loss = 1.14655532, grad/param norm = 5.7470e-01, time/batch = 0.1757s	
1894/2700 (epoch 35.074), train_loss = 1.13809922, grad/param norm = 5.5907e-01, time/batch = 0.1663s	
1895/2700 (epoch 35.093), train_loss = 1.13550450, grad/param norm = 5.5652e-01, time/batch = 0.1636s	
1896/2700 (epoch 35.111), train_loss = 1.11581693, grad/param norm = 5.5199e-01, time/batch = 0.1615s	
1897/2700 (epoch 35.130), train_loss = 1.18208544, grad/param norm = 5.7869e-01, time/batch = 0.1594s	
1898/2700 (epoch 35.148), train_loss = 1.15908071, grad/param norm = 5.4792e-01, time/batch = 0.1593s	
1899/2700 (epoch 35.167), train_loss = 1.18019561, grad/param norm = 5.6183e-01, time/batch = 0.1605s	
1900/2700 (epoch 35.185), train_loss = 1.13981690, grad/param norm = 5.4712e-01, time/batch = 0.1586s	
1901/2700 (epoch 35.204), train_loss = 1.19116985, grad/param norm = 5.8383e-01, time/batch = 0.1809s	
1902/2700 (epoch 35.222), train_loss = 1.13619424, grad/param norm = 5.5827e-01, time/batch = 0.1762s	
1903/2700 (epoch 35.241), train_loss = 1.08934434, grad/param norm = 5.4305e-01, time/batch = 0.1479s	
1904/2700 (epoch 35.259), train_loss = 1.11608031, grad/param norm = 5.6267e-01, time/batch = 0.1306s	
1905/2700 (epoch 35.278), train_loss = 1.17500723, grad/param norm = 5.7393e-01, time/batch = 0.1515s	
1906/2700 (epoch 35.296), train_loss = 1.13949757, grad/param norm = 5.5294e-01, time/batch = 0.1547s	
1907/2700 (epoch 35.315), train_loss = 1.11260660, grad/param norm = 5.7157e-01, time/batch = 0.1585s	
1908/2700 (epoch 35.333), train_loss = 1.14823894, grad/param norm = 5.7421e-01, time/batch = 0.1606s	
1909/2700 (epoch 35.352), train_loss = 1.13499974, grad/param norm = 5.8047e-01, time/batch = 0.1621s	
1910/2700 (epoch 35.370), train_loss = 1.15524034, grad/param norm = 5.9375e-01, time/batch = 0.1645s	
1911/2700 (epoch 35.389), train_loss = 1.12641163, grad/param norm = 5.7117e-01, time/batch = 0.1742s	
1912/2700 (epoch 35.407), train_loss = 1.18634955, grad/param norm = 5.7510e-01, time/batch = 0.1708s	
1913/2700 (epoch 35.426), train_loss = 1.22070297, grad/param norm = 5.7272e-01, time/batch = 0.1482s	
1914/2700 (epoch 35.444), train_loss = 1.16706123, grad/param norm = 5.5979e-01, time/batch = 0.1340s	
1915/2700 (epoch 35.463), train_loss = 1.18847773, grad/param norm = 5.8128e-01, time/batch = 0.1593s	
1916/2700 (epoch 35.481), train_loss = 1.15618309, grad/param norm = 5.7436e-01, time/batch = 0.1543s	
1917/2700 (epoch 35.500), train_loss = 1.11608246, grad/param norm = 5.5432e-01, time/batch = 0.1510s	
1918/2700 (epoch 35.519), train_loss = 1.18953538, grad/param norm = 5.6052e-01, time/batch = 0.1586s	
1919/2700 (epoch 35.537), train_loss = 1.16517925, grad/param norm = 5.6558e-01, time/batch = 0.1660s	
1920/2700 (epoch 35.556), train_loss = 1.09209721, grad/param norm = 5.3526e-01, time/batch = 0.1662s	
1921/2700 (epoch 35.574), train_loss = 1.11585166, grad/param norm = 5.9044e-01, time/batch = 0.1419s	
1922/2700 (epoch 35.593), train_loss = 1.16335119, grad/param norm = 5.7521e-01, time/batch = 0.1507s	
1923/2700 (epoch 35.611), train_loss = 1.08854814, grad/param norm = 5.5245e-01, time/batch = 0.1577s	
1924/2700 (epoch 35.630), train_loss = 1.11410510, grad/param norm = 5.5893e-01, time/batch = 0.1332s	
1925/2700 (epoch 35.648), train_loss = 1.14211466, grad/param norm = 5.4888e-01, time/batch = 0.1723s	
1926/2700 (epoch 35.667), train_loss = 1.10186982, grad/param norm = 5.4559e-01, time/batch = 0.1656s	
1927/2700 (epoch 35.685), train_loss = 1.14636386, grad/param norm = 5.6252e-01, time/batch = 0.1565s	
1928/2700 (epoch 35.704), train_loss = 1.18970602, grad/param norm = 5.8600e-01, time/batch = 0.1617s	
1929/2700 (epoch 35.722), train_loss = 1.15123012, grad/param norm = 5.4956e-01, time/batch = 0.1679s	
1930/2700 (epoch 35.741), train_loss = 1.15055293, grad/param norm = 5.6696e-01, time/batch = 0.1698s	
1931/2700 (epoch 35.759), train_loss = 1.12772421, grad/param norm = 5.6057e-01, time/batch = 0.1603s	
1932/2700 (epoch 35.778), train_loss = 1.20356686, grad/param norm = 6.0209e-01, time/batch = 0.1635s	
1933/2700 (epoch 35.796), train_loss = 1.11874198, grad/param norm = 6.0783e-01, time/batch = 0.1695s	
1934/2700 (epoch 35.815), train_loss = 1.18734383, grad/param norm = 6.0742e-01, time/batch = 0.1586s	
1935/2700 (epoch 35.833), train_loss = 1.15776994, grad/param norm = 5.7290e-01, time/batch = 0.1543s	
1936/2700 (epoch 35.852), train_loss = 1.13675895, grad/param norm = 5.6031e-01, time/batch = 0.1798s	
1937/2700 (epoch 35.870), train_loss = 1.18330274, grad/param norm = 5.7854e-01, time/batch = 0.1799s	
1938/2700 (epoch 35.889), train_loss = 1.14617383, grad/param norm = 5.5272e-01, time/batch = 0.1829s	
1939/2700 (epoch 35.907), train_loss = 1.19699409, grad/param norm = 5.8192e-01, time/batch = 0.1819s	
1940/2700 (epoch 35.926), train_loss = 1.13611020, grad/param norm = 5.6484e-01, time/batch = 0.1798s	
1941/2700 (epoch 35.944), train_loss = 1.14197030, grad/param norm = 5.7426e-01, time/batch = 0.1794s	
1942/2700 (epoch 35.963), train_loss = 1.16041154, grad/param norm = 5.7901e-01, time/batch = 0.1801s	
1943/2700 (epoch 35.981), train_loss = 1.11216864, grad/param norm = 5.8719e-01, time/batch = 0.1771s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
1944/2700 (epoch 36.000), train_loss = 1.22204910, grad/param norm = 5.6963e-01, time/batch = 0.1681s	
1945/2700 (epoch 36.019), train_loss = 1.22655991, grad/param norm = 6.0148e-01, time/batch = 0.1722s	
1946/2700 (epoch 36.037), train_loss = 1.19171902, grad/param norm = 5.8639e-01, time/batch = 0.1687s	
1947/2700 (epoch 36.056), train_loss = 1.13143778, grad/param norm = 5.8053e-01, time/batch = 0.1608s	
1948/2700 (epoch 36.074), train_loss = 1.12504613, grad/param norm = 5.8125e-01, time/batch = 0.1557s	
1949/2700 (epoch 36.093), train_loss = 1.12403825, grad/param norm = 5.7737e-01, time/batch = 0.1569s	
1950/2700 (epoch 36.111), train_loss = 1.10074324, grad/param norm = 5.4984e-01, time/batch = 0.1592s	
1951/2700 (epoch 36.130), train_loss = 1.16691825, grad/param norm = 5.8213e-01, time/batch = 0.1625s	
1952/2700 (epoch 36.148), train_loss = 1.14857405, grad/param norm = 5.6993e-01, time/batch = 0.1635s	
1953/2700 (epoch 36.167), train_loss = 1.16833583, grad/param norm = 5.8931e-01, time/batch = 0.1613s	
1954/2700 (epoch 36.185), train_loss = 1.12520946, grad/param norm = 5.4430e-01, time/batch = 0.1555s	
1955/2700 (epoch 36.204), train_loss = 1.17556528, grad/param norm = 5.7175e-01, time/batch = 0.1574s	
1956/2700 (epoch 36.222), train_loss = 1.12025311, grad/param norm = 5.6851e-01, time/batch = 0.1547s	
1957/2700 (epoch 36.241), train_loss = 1.07530321, grad/param norm = 5.4047e-01, time/batch = 0.1625s	
1958/2700 (epoch 36.259), train_loss = 1.10300989, grad/param norm = 5.5264e-01, time/batch = 0.1505s	
1959/2700 (epoch 36.278), train_loss = 1.15700603, grad/param norm = 5.5962e-01, time/batch = 0.1446s	
1960/2700 (epoch 36.296), train_loss = 1.12014556, grad/param norm = 5.4416e-01, time/batch = 0.1509s	
1961/2700 (epoch 36.315), train_loss = 1.09512562, grad/param norm = 5.6170e-01, time/batch = 0.1445s	
1962/2700 (epoch 36.333), train_loss = 1.13223758, grad/param norm = 5.8938e-01, time/batch = 0.1540s	
1963/2700 (epoch 36.352), train_loss = 1.12154328, grad/param norm = 5.9724e-01, time/batch = 0.1630s	
1964/2700 (epoch 36.370), train_loss = 1.13510924, grad/param norm = 5.9166e-01, time/batch = 0.1578s	
1965/2700 (epoch 36.389), train_loss = 1.10779273, grad/param norm = 5.6143e-01, time/batch = 0.1541s	
1966/2700 (epoch 36.407), train_loss = 1.17025149, grad/param norm = 5.8969e-01, time/batch = 0.1662s	
1967/2700 (epoch 36.426), train_loss = 1.20138843, grad/param norm = 5.6344e-01, time/batch = 0.1542s	
1968/2700 (epoch 36.444), train_loss = 1.15751622, grad/param norm = 5.8900e-01, time/batch = 0.1714s	
1969/2700 (epoch 36.463), train_loss = 1.17223264, grad/param norm = 5.6663e-01, time/batch = 0.1729s	
1970/2700 (epoch 36.481), train_loss = 1.14191932, grad/param norm = 5.6796e-01, time/batch = 0.1673s	
1971/2700 (epoch 36.500), train_loss = 1.10839336, grad/param norm = 5.9446e-01, time/batch = 0.1812s	
1972/2700 (epoch 36.519), train_loss = 1.17705623, grad/param norm = 5.8743e-01, time/batch = 0.1812s	
1973/2700 (epoch 36.537), train_loss = 1.15382679, grad/param norm = 5.7975e-01, time/batch = 0.1735s	
1974/2700 (epoch 36.556), train_loss = 1.08169437, grad/param norm = 5.6705e-01, time/batch = 0.1781s	
1975/2700 (epoch 36.574), train_loss = 1.09949080, grad/param norm = 5.8794e-01, time/batch = 0.1676s	
1976/2700 (epoch 36.593), train_loss = 1.15176213, grad/param norm = 5.9175e-01, time/batch = 0.1715s	
1977/2700 (epoch 36.611), train_loss = 1.07762193, grad/param norm = 5.6351e-01, time/batch = 0.1618s	
1978/2700 (epoch 36.630), train_loss = 1.09928414, grad/param norm = 5.4831e-01, time/batch = 0.1313s	
1979/2700 (epoch 36.648), train_loss = 1.12756081, grad/param norm = 5.5606e-01, time/batch = 0.1639s	
1980/2700 (epoch 36.667), train_loss = 1.09031768, grad/param norm = 5.6097e-01, time/batch = 0.1608s	
1981/2700 (epoch 36.685), train_loss = 1.13094395, grad/param norm = 5.5574e-01, time/batch = 0.1769s	
1982/2700 (epoch 36.704), train_loss = 1.17262315, grad/param norm = 5.9104e-01, time/batch = 0.1715s	
1983/2700 (epoch 36.722), train_loss = 1.14062705, grad/param norm = 5.5776e-01, time/batch = 0.1618s	
1984/2700 (epoch 36.741), train_loss = 1.13272758, grad/param norm = 5.5018e-01, time/batch = 0.1770s	
1985/2700 (epoch 36.759), train_loss = 1.11261050, grad/param norm = 5.5253e-01, time/batch = 0.1763s	
1986/2700 (epoch 36.778), train_loss = 1.18327904, grad/param norm = 5.8364e-01, time/batch = 0.1589s	
1987/2700 (epoch 36.796), train_loss = 1.09731279, grad/param norm = 5.8266e-01, time/batch = 0.1622s	
1988/2700 (epoch 36.815), train_loss = 1.17405993, grad/param norm = 6.6461e-01, time/batch = 0.1584s	
1989/2700 (epoch 36.833), train_loss = 1.16011094, grad/param norm = 6.5922e-01, time/batch = 0.1457s	
1990/2700 (epoch 36.852), train_loss = 1.12964637, grad/param norm = 5.9308e-01, time/batch = 0.1468s	
1991/2700 (epoch 36.870), train_loss = 1.16842967, grad/param norm = 5.6838e-01, time/batch = 0.1496s	
1992/2700 (epoch 36.889), train_loss = 1.13627577, grad/param norm = 5.7010e-01, time/batch = 0.1442s	
1993/2700 (epoch 36.907), train_loss = 1.18005029, grad/param norm = 5.8754e-01, time/batch = 0.1304s	
1994/2700 (epoch 36.926), train_loss = 1.12140332, grad/param norm = 5.7046e-01, time/batch = 0.1490s	
1995/2700 (epoch 36.944), train_loss = 1.12250634, grad/param norm = 5.6923e-01, time/batch = 0.1570s	
1996/2700 (epoch 36.963), train_loss = 1.13929807, grad/param norm = 5.5349e-01, time/batch = 0.1518s	
1997/2700 (epoch 36.981), train_loss = 1.09598154, grad/param norm = 5.7497e-01, time/batch = 0.1797s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
1998/2700 (epoch 37.000), train_loss = 1.20100648, grad/param norm = 5.6893e-01, time/batch = 0.1779s	
1999/2700 (epoch 37.019), train_loss = 1.20777592, grad/param norm = 5.8506e-01, time/batch = 0.1792s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch37.04_1.8626.t7	
2000/2700 (epoch 37.037), train_loss = 1.17759286, grad/param norm = 6.0418e-01, time/batch = 0.1517s	
2001/2700 (epoch 37.056), train_loss = 1.34257016, grad/param norm = 6.2276e-01, time/batch = 0.1769s	
2002/2700 (epoch 37.074), train_loss = 1.11626001, grad/param norm = 5.9122e-01, time/batch = 0.1774s	
2003/2700 (epoch 37.093), train_loss = 1.11320527, grad/param norm = 5.7937e-01, time/batch = 0.1603s	
2004/2700 (epoch 37.111), train_loss = 1.09037465, grad/param norm = 5.7631e-01, time/batch = 0.1649s	
2005/2700 (epoch 37.130), train_loss = 1.15744159, grad/param norm = 5.9970e-01, time/batch = 0.1635s	
2006/2700 (epoch 37.148), train_loss = 1.13044425, grad/param norm = 5.6114e-01, time/batch = 0.1681s	
2007/2700 (epoch 37.167), train_loss = 1.15221990, grad/param norm = 5.8784e-01, time/batch = 0.1731s	
2008/2700 (epoch 37.185), train_loss = 1.11834841, grad/param norm = 5.9350e-01, time/batch = 0.1736s	
2009/2700 (epoch 37.204), train_loss = 1.16431284, grad/param norm = 5.8235e-01, time/batch = 0.1773s	
2010/2700 (epoch 37.222), train_loss = 1.10902514, grad/param norm = 5.7523e-01, time/batch = 0.1631s	
2011/2700 (epoch 37.241), train_loss = 1.06555408, grad/param norm = 5.5759e-01, time/batch = 0.1774s	
2012/2700 (epoch 37.259), train_loss = 1.09003214, grad/param norm = 5.5966e-01, time/batch = 0.1803s	
2013/2700 (epoch 37.278), train_loss = 1.14383134, grad/param norm = 5.6731e-01, time/batch = 0.1729s	
2014/2700 (epoch 37.296), train_loss = 1.10770011, grad/param norm = 5.5656e-01, time/batch = 0.1807s	
2015/2700 (epoch 37.315), train_loss = 1.07792774, grad/param norm = 5.5920e-01, time/batch = 0.1812s	
2016/2700 (epoch 37.333), train_loss = 1.11007204, grad/param norm = 5.5038e-01, time/batch = 0.1797s	
2017/2700 (epoch 37.352), train_loss = 1.10194055, grad/param norm = 5.5818e-01, time/batch = 0.1789s	
2018/2700 (epoch 37.370), train_loss = 1.11496802, grad/param norm = 5.7133e-01, time/batch = 0.1794s	
2019/2700 (epoch 37.389), train_loss = 1.09233571, grad/param norm = 5.7993e-01, time/batch = 0.1768s	
2020/2700 (epoch 37.407), train_loss = 1.15305220, grad/param norm = 5.8896e-01, time/batch = 0.1587s	
2021/2700 (epoch 37.426), train_loss = 1.18549405, grad/param norm = 5.7019e-01, time/batch = 0.1732s	
2022/2700 (epoch 37.444), train_loss = 1.14039138, grad/param norm = 5.8828e-01, time/batch = 0.1715s	
2023/2700 (epoch 37.463), train_loss = 1.15632594, grad/param norm = 5.9137e-01, time/batch = 0.1600s	
2024/2700 (epoch 37.481), train_loss = 1.12461978, grad/param norm = 5.7853e-01, time/batch = 0.1583s	
2025/2700 (epoch 37.500), train_loss = 1.08592163, grad/param norm = 5.6647e-01, time/batch = 0.1556s	
2026/2700 (epoch 37.519), train_loss = 1.16000861, grad/param norm = 5.8098e-01, time/batch = 0.1526s	
2027/2700 (epoch 37.537), train_loss = 1.14076894, grad/param norm = 6.0383e-01, time/batch = 0.1557s	
2028/2700 (epoch 37.556), train_loss = 1.06768323, grad/param norm = 5.5859e-01, time/batch = 0.1460s	
2029/2700 (epoch 37.574), train_loss = 1.09127175, grad/param norm = 6.5357e-01, time/batch = 0.1379s	
2030/2700 (epoch 37.593), train_loss = 1.13781322, grad/param norm = 6.0242e-01, time/batch = 0.1297s	
2031/2700 (epoch 37.611), train_loss = 1.06321769, grad/param norm = 5.7394e-01, time/batch = 0.1407s	
2032/2700 (epoch 37.630), train_loss = 1.08801347, grad/param norm = 5.7431e-01, time/batch = 0.1781s	
2033/2700 (epoch 37.648), train_loss = 1.11021224, grad/param norm = 5.5854e-01, time/batch = 0.1783s	
2034/2700 (epoch 37.667), train_loss = 1.07488720, grad/param norm = 5.5449e-01, time/batch = 0.1562s	
2035/2700 (epoch 37.685), train_loss = 1.11692464, grad/param norm = 5.6969e-01, time/batch = 0.1795s	
2036/2700 (epoch 37.704), train_loss = 1.15671047, grad/param norm = 5.8356e-01, time/batch = 0.1809s	
2037/2700 (epoch 37.722), train_loss = 1.12213494, grad/param norm = 5.5213e-01, time/batch = 0.1776s	
2038/2700 (epoch 37.741), train_loss = 1.11968416, grad/param norm = 5.6324e-01, time/batch = 0.1780s	
2039/2700 (epoch 37.759), train_loss = 1.09571563, grad/param norm = 5.5318e-01, time/batch = 0.1748s	
2040/2700 (epoch 37.778), train_loss = 1.16862190, grad/param norm = 5.8265e-01, time/batch = 0.1641s	
2041/2700 (epoch 37.796), train_loss = 1.08089114, grad/param norm = 5.8247e-01, time/batch = 0.1441s	
2042/2700 (epoch 37.815), train_loss = 1.15434732, grad/param norm = 6.1401e-01, time/batch = 0.1187s	
2043/2700 (epoch 37.833), train_loss = 1.12893905, grad/param norm = 6.0514e-01, time/batch = 0.1140s	
2044/2700 (epoch 37.852), train_loss = 1.11312241, grad/param norm = 5.9183e-01, time/batch = 0.1012s	
2045/2700 (epoch 37.870), train_loss = 1.15570202, grad/param norm = 5.9743e-01, time/batch = 0.1291s	
2046/2700 (epoch 37.889), train_loss = 1.11906799, grad/param norm = 5.7079e-01, time/batch = 0.1263s	
2047/2700 (epoch 37.907), train_loss = 1.16338041, grad/param norm = 5.9373e-01, time/batch = 0.1288s	
2048/2700 (epoch 37.926), train_loss = 1.10623601, grad/param norm = 5.7404e-01, time/batch = 0.1287s	
2049/2700 (epoch 37.944), train_loss = 1.10625481, grad/param norm = 5.7290e-01, time/batch = 0.1294s	
2050/2700 (epoch 37.963), train_loss = 1.12919414, grad/param norm = 5.8685e-01, time/batch = 0.1304s	
2051/2700 (epoch 37.981), train_loss = 1.08519624, grad/param norm = 5.9503e-01, time/batch = 0.1279s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2052/2700 (epoch 38.000), train_loss = 1.18423787, grad/param norm = 5.6572e-01, time/batch = 0.0959s	
2053/2700 (epoch 38.019), train_loss = 1.19200677, grad/param norm = 5.8939e-01, time/batch = 0.1276s	
2054/2700 (epoch 38.037), train_loss = 1.15773327, grad/param norm = 5.8068e-01, time/batch = 0.1170s	
2055/2700 (epoch 38.056), train_loss = 1.10805666, grad/param norm = 5.8384e-01, time/batch = 0.0892s	
2056/2700 (epoch 38.074), train_loss = 1.09498401, grad/param norm = 5.9584e-01, time/batch = 0.1198s	
2057/2700 (epoch 38.093), train_loss = 1.09426628, grad/param norm = 5.8294e-01, time/batch = 0.1199s	
2058/2700 (epoch 38.111), train_loss = 1.07080931, grad/param norm = 5.6163e-01, time/batch = 0.1218s	
2059/2700 (epoch 38.130), train_loss = 1.13897950, grad/param norm = 5.9907e-01, time/batch = 0.1246s	
2060/2700 (epoch 38.148), train_loss = 1.12322752, grad/param norm = 5.9094e-01, time/batch = 0.1303s	
2061/2700 (epoch 38.167), train_loss = 1.13896008, grad/param norm = 6.0897e-01, time/batch = 0.1230s	
2062/2700 (epoch 38.185), train_loss = 1.10073953, grad/param norm = 5.6869e-01, time/batch = 0.1206s	
2063/2700 (epoch 38.204), train_loss = 1.15786157, grad/param norm = 6.2281e-01, time/batch = 0.1168s	
2064/2700 (epoch 38.222), train_loss = 1.09560737, grad/param norm = 5.8565e-01, time/batch = 0.1308s	
2065/2700 (epoch 38.241), train_loss = 1.05383586, grad/param norm = 5.6112e-01, time/batch = 0.1325s	
2066/2700 (epoch 38.259), train_loss = 1.08438198, grad/param norm = 5.9095e-01, time/batch = 0.1171s	
2067/2700 (epoch 38.278), train_loss = 1.13229019, grad/param norm = 5.9355e-01, time/batch = 0.1461s	
2068/2700 (epoch 38.296), train_loss = 1.09453389, grad/param norm = 5.6291e-01, time/batch = 0.1455s	
2069/2700 (epoch 38.315), train_loss = 1.06686064, grad/param norm = 5.8281e-01, time/batch = 0.1456s	
2070/2700 (epoch 38.333), train_loss = 1.09995715, grad/param norm = 5.7301e-01, time/batch = 0.1330s	
2071/2700 (epoch 38.352), train_loss = 1.08874175, grad/param norm = 5.8337e-01, time/batch = 0.1342s	
2072/2700 (epoch 38.370), train_loss = 1.10574698, grad/param norm = 6.0312e-01, time/batch = 0.1316s	
2073/2700 (epoch 38.389), train_loss = 1.07314980, grad/param norm = 5.7388e-01, time/batch = 0.1206s	
2074/2700 (epoch 38.407), train_loss = 1.13853564, grad/param norm = 5.9383e-01, time/batch = 0.1059s	
2075/2700 (epoch 38.426), train_loss = 1.17584891, grad/param norm = 6.0841e-01, time/batch = 0.1125s	
2076/2700 (epoch 38.444), train_loss = 1.12611730, grad/param norm = 5.8063e-01, time/batch = 0.1236s	
2077/2700 (epoch 38.463), train_loss = 1.13998518, grad/param norm = 5.8067e-01, time/batch = 0.1033s	
2078/2700 (epoch 38.481), train_loss = 1.11071343, grad/param norm = 5.8593e-01, time/batch = 0.1268s	
2079/2700 (epoch 38.500), train_loss = 1.07607509, grad/param norm = 6.1379e-01, time/batch = 0.1294s	
2080/2700 (epoch 38.519), train_loss = 1.14485985, grad/param norm = 5.9047e-01, time/batch = 0.1189s	
2081/2700 (epoch 38.537), train_loss = 1.12279147, grad/param norm = 5.8470e-01, time/batch = 0.1265s	
2082/2700 (epoch 38.556), train_loss = 1.05335109, grad/param norm = 5.6885e-01, time/batch = 0.1186s	
2083/2700 (epoch 38.574), train_loss = 1.06849701, grad/param norm = 5.8271e-01, time/batch = 0.1074s	
2084/2700 (epoch 38.593), train_loss = 1.12331214, grad/param norm = 5.9946e-01, time/batch = 0.1108s	
2085/2700 (epoch 38.611), train_loss = 1.05339698, grad/param norm = 5.9229e-01, time/batch = 0.0806s	
2086/2700 (epoch 38.630), train_loss = 1.07156543, grad/param norm = 5.7340e-01, time/batch = 0.0935s	
2087/2700 (epoch 38.648), train_loss = 1.09845902, grad/param norm = 5.7161e-01, time/batch = 0.0891s	
2088/2700 (epoch 38.667), train_loss = 1.06282327, grad/param norm = 5.6729e-01, time/batch = 0.0799s	
2089/2700 (epoch 38.685), train_loss = 1.10467193, grad/param norm = 5.6835e-01, time/batch = 0.1194s	
2090/2700 (epoch 38.704), train_loss = 1.14269231, grad/param norm = 5.9230e-01, time/batch = 0.1118s	
2091/2700 (epoch 38.722), train_loss = 1.10992646, grad/param norm = 5.6197e-01, time/batch = 0.1284s	
2092/2700 (epoch 38.741), train_loss = 1.10319638, grad/param norm = 5.6344e-01, time/batch = 0.1248s	
2093/2700 (epoch 38.759), train_loss = 1.08354060, grad/param norm = 5.5967e-01, time/batch = 0.1152s	
2094/2700 (epoch 38.778), train_loss = 1.15276593, grad/param norm = 5.8813e-01, time/batch = 0.0992s	
2095/2700 (epoch 38.796), train_loss = 1.06358279, grad/param norm = 5.8311e-01, time/batch = 0.0874s	
2096/2700 (epoch 38.815), train_loss = 1.14104662, grad/param norm = 6.4415e-01, time/batch = 0.0993s	
2097/2700 (epoch 38.833), train_loss = 1.11539966, grad/param norm = 6.1411e-01, time/batch = 0.0880s	
2098/2700 (epoch 38.852), train_loss = 1.09553528, grad/param norm = 5.8146e-01, time/batch = 0.1019s	
2099/2700 (epoch 38.870), train_loss = 1.14177323, grad/param norm = 5.8368e-01, time/batch = 0.0799s	
2100/2700 (epoch 38.889), train_loss = 1.10937119, grad/param norm = 5.9774e-01, time/batch = 0.1296s	
2101/2700 (epoch 38.907), train_loss = 1.15190563, grad/param norm = 6.0457e-01, time/batch = 0.1277s	
2102/2700 (epoch 38.926), train_loss = 1.09322279, grad/param norm = 5.8720e-01, time/batch = 0.1282s	
2103/2700 (epoch 38.944), train_loss = 1.09150283, grad/param norm = 5.8141e-01, time/batch = 0.1275s	
2104/2700 (epoch 38.963), train_loss = 1.11046559, grad/param norm = 5.6812e-01, time/batch = 0.1267s	
2105/2700 (epoch 38.981), train_loss = 1.07115560, grad/param norm = 5.9772e-01, time/batch = 0.1278s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2106/2700 (epoch 39.000), train_loss = 1.16898313, grad/param norm = 5.8593e-01, time/batch = 0.1308s	
2107/2700 (epoch 39.019), train_loss = 1.18020780, grad/param norm = 6.0565e-01, time/batch = 0.1309s	
2108/2700 (epoch 39.037), train_loss = 1.14847272, grad/param norm = 6.1591e-01, time/batch = 0.1236s	
2109/2700 (epoch 39.056), train_loss = 1.09266351, grad/param norm = 5.8538e-01, time/batch = 0.1363s	
2110/2700 (epoch 39.074), train_loss = 1.08015694, grad/param norm = 5.8862e-01, time/batch = 0.1106s	
2111/2700 (epoch 39.093), train_loss = 1.07809162, grad/param norm = 5.7602e-01, time/batch = 0.1449s	
2112/2700 (epoch 39.111), train_loss = 1.05828993, grad/param norm = 5.7772e-01, time/batch = 0.1449s	
2113/2700 (epoch 39.130), train_loss = 1.12634424, grad/param norm = 6.0808e-01, time/batch = 0.1446s	
2114/2700 (epoch 39.148), train_loss = 1.10397036, grad/param norm = 5.7438e-01, time/batch = 0.1456s	
2115/2700 (epoch 39.167), train_loss = 1.11958848, grad/param norm = 5.9244e-01, time/batch = 0.1450s	
2116/2700 (epoch 39.185), train_loss = 1.09001785, grad/param norm = 5.9269e-01, time/batch = 0.1428s	
2117/2700 (epoch 39.204), train_loss = 1.13999359, grad/param norm = 5.9620e-01, time/batch = 0.1409s	
2118/2700 (epoch 39.222), train_loss = 1.08256329, grad/param norm = 5.9048e-01, time/batch = 0.1261s	
2119/2700 (epoch 39.241), train_loss = 1.04353258, grad/param norm = 5.7231e-01, time/batch = 0.1365s	
2120/2700 (epoch 39.259), train_loss = 1.06722838, grad/param norm = 5.7193e-01, time/batch = 0.1206s	
2121/2700 (epoch 39.278), train_loss = 1.11868411, grad/param norm = 5.8573e-01, time/batch = 0.1402s	
2122/2700 (epoch 39.296), train_loss = 1.08265670, grad/param norm = 5.8686e-01, time/batch = 0.1385s	
2123/2700 (epoch 39.315), train_loss = 1.05877061, grad/param norm = 6.1311e-01, time/batch = 0.1350s	
2124/2700 (epoch 39.333), train_loss = 1.09236113, grad/param norm = 6.1968e-01, time/batch = 0.1363s	
2125/2700 (epoch 39.352), train_loss = 1.08159735, grad/param norm = 6.0341e-01, time/batch = 0.1271s	
2126/2700 (epoch 39.370), train_loss = 1.09055173, grad/param norm = 6.0879e-01, time/batch = 0.1292s	
2127/2700 (epoch 39.389), train_loss = 1.06178280, grad/param norm = 5.8923e-01, time/batch = 0.1343s	
2128/2700 (epoch 39.407), train_loss = 1.12803255, grad/param norm = 6.2004e-01, time/batch = 0.1238s	
2129/2700 (epoch 39.426), train_loss = 1.16111718, grad/param norm = 6.0368e-01, time/batch = 0.1330s	
2130/2700 (epoch 39.444), train_loss = 1.11935733, grad/param norm = 6.1623e-01, time/batch = 0.1185s	
2131/2700 (epoch 39.463), train_loss = 1.12840623, grad/param norm = 5.8143e-01, time/batch = 0.1420s	
2132/2700 (epoch 39.481), train_loss = 1.09813959, grad/param norm = 5.8122e-01, time/batch = 0.1386s	
2133/2700 (epoch 39.500), train_loss = 1.06157691, grad/param norm = 6.0652e-01, time/batch = 0.1393s	
2134/2700 (epoch 39.519), train_loss = 1.13049986, grad/param norm = 6.0310e-01, time/batch = 0.1363s	
2135/2700 (epoch 39.537), train_loss = 1.11102855, grad/param norm = 5.9593e-01, time/batch = 0.1342s	
2136/2700 (epoch 39.556), train_loss = 1.04114077, grad/param norm = 5.8492e-01, time/batch = 0.1364s	
2137/2700 (epoch 39.574), train_loss = 1.06079824, grad/param norm = 6.4434e-01, time/batch = 0.1326s	
2138/2700 (epoch 39.593), train_loss = 1.10996242, grad/param norm = 6.1330e-01, time/batch = 0.1217s	
2139/2700 (epoch 39.611), train_loss = 1.03967436, grad/param norm = 5.8872e-01, time/batch = 0.1330s	
2140/2700 (epoch 39.630), train_loss = 1.06123719, grad/param norm = 5.7945e-01, time/batch = 0.1169s	
2141/2700 (epoch 39.648), train_loss = 1.08654155, grad/param norm = 5.8837e-01, time/batch = 0.1442s	
2142/2700 (epoch 39.667), train_loss = 1.05636539, grad/param norm = 5.9633e-01, time/batch = 0.1406s	
2143/2700 (epoch 39.685), train_loss = 1.09301463, grad/param norm = 5.9025e-01, time/batch = 0.1370s	
2144/2700 (epoch 39.704), train_loss = 1.13049842, grad/param norm = 6.0305e-01, time/batch = 0.1363s	
2145/2700 (epoch 39.722), train_loss = 1.09862659, grad/param norm = 5.7581e-01, time/batch = 0.1346s	
2146/2700 (epoch 39.741), train_loss = 1.09109254, grad/param norm = 5.6762e-01, time/batch = 0.1337s	
2147/2700 (epoch 39.759), train_loss = 1.06910314, grad/param norm = 5.6802e-01, time/batch = 0.1331s	
2148/2700 (epoch 39.778), train_loss = 1.13900594, grad/param norm = 5.8812e-01, time/batch = 0.1227s	
2149/2700 (epoch 39.796), train_loss = 1.04926908, grad/param norm = 5.8712e-01, time/batch = 0.1362s	
2150/2700 (epoch 39.815), train_loss = 1.12616000, grad/param norm = 6.3811e-01, time/batch = 0.1175s	
2151/2700 (epoch 39.833), train_loss = 1.10020827, grad/param norm = 6.1724e-01, time/batch = 0.1458s	
2152/2700 (epoch 39.852), train_loss = 1.08299614, grad/param norm = 5.8952e-01, time/batch = 0.1430s	
2153/2700 (epoch 39.870), train_loss = 1.12649556, grad/param norm = 5.8455e-01, time/batch = 0.1383s	
2154/2700 (epoch 39.889), train_loss = 1.09197517, grad/param norm = 5.7641e-01, time/batch = 0.1372s	
2155/2700 (epoch 39.907), train_loss = 1.13147356, grad/param norm = 6.0162e-01, time/batch = 0.1254s	
2156/2700 (epoch 39.926), train_loss = 1.07970935, grad/param norm = 5.9306e-01, time/batch = 0.1179s	
2157/2700 (epoch 39.944), train_loss = 1.07909523, grad/param norm = 5.9568e-01, time/batch = 0.1205s	
2158/2700 (epoch 39.963), train_loss = 1.10113789, grad/param norm = 6.0067e-01, time/batch = 0.1215s	
2159/2700 (epoch 39.981), train_loss = 1.05984667, grad/param norm = 6.1371e-01, time/batch = 0.0955s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2160/2700 (epoch 40.000), train_loss = 1.15523236, grad/param norm = 5.8311e-01, time/batch = 0.1208s	
2161/2700 (epoch 40.019), train_loss = 1.16791771, grad/param norm = 6.1529e-01, time/batch = 0.1264s	
2162/2700 (epoch 40.037), train_loss = 1.12823485, grad/param norm = 5.9271e-01, time/batch = 0.1242s	
2163/2700 (epoch 40.056), train_loss = 1.07590604, grad/param norm = 5.9634e-01, time/batch = 0.1122s	
2164/2700 (epoch 40.074), train_loss = 1.06896838, grad/param norm = 6.1435e-01, time/batch = 0.1060s	
2165/2700 (epoch 40.093), train_loss = 1.06666067, grad/param norm = 5.9709e-01, time/batch = 0.0980s	
2166/2700 (epoch 40.111), train_loss = 1.04496761, grad/param norm = 5.7955e-01, time/batch = 0.0978s	
2167/2700 (epoch 40.130), train_loss = 1.11231534, grad/param norm = 6.1349e-01, time/batch = 0.1095s	
2168/2700 (epoch 40.148), train_loss = 1.09308143, grad/param norm = 5.9684e-01, time/batch = 0.1210s	
2169/2700 (epoch 40.167), train_loss = 1.10665940, grad/param norm = 6.0933e-01, time/batch = 0.1314s	
2170/2700 (epoch 40.185), train_loss = 1.07262368, grad/param norm = 5.6994e-01, time/batch = 0.1152s	
2171/2700 (epoch 40.204), train_loss = 1.12753120, grad/param norm = 6.0468e-01, time/batch = 0.0868s	
2172/2700 (epoch 40.222), train_loss = 1.06947151, grad/param norm = 5.9566e-01, time/batch = 0.0946s	
2173/2700 (epoch 40.241), train_loss = 1.03119563, grad/param norm = 5.6725e-01, time/batch = 0.0964s	
2174/2700 (epoch 40.259), train_loss = 1.05534398, grad/param norm = 5.7926e-01, time/batch = 0.1060s	
2175/2700 (epoch 40.278), train_loss = 1.10560478, grad/param norm = 5.9683e-01, time/batch = 0.1149s	
2176/2700 (epoch 40.296), train_loss = 1.06631401, grad/param norm = 5.7020e-01, time/batch = 0.1198s	
2177/2700 (epoch 40.315), train_loss = 1.03916624, grad/param norm = 5.9390e-01, time/batch = 0.1240s	
2178/2700 (epoch 40.333), train_loss = 1.07284658, grad/param norm = 5.9007e-01, time/batch = 0.1270s	
2179/2700 (epoch 40.352), train_loss = 1.06395323, grad/param norm = 6.0058e-01, time/batch = 0.1163s	
2180/2700 (epoch 40.370), train_loss = 1.08084450, grad/param norm = 6.3244e-01, time/batch = 0.1064s	
2181/2700 (epoch 40.389), train_loss = 1.04583777, grad/param norm = 5.9736e-01, time/batch = 0.1201s	
2182/2700 (epoch 40.407), train_loss = 1.11314035, grad/param norm = 6.2042e-01, time/batch = 0.0814s	
2183/2700 (epoch 40.426), train_loss = 1.15172284, grad/param norm = 6.4156e-01, time/batch = 0.1040s	
2184/2700 (epoch 40.444), train_loss = 1.10369096, grad/param norm = 6.0539e-01, time/batch = 0.1143s	
2185/2700 (epoch 40.463), train_loss = 1.11308695, grad/param norm = 6.0279e-01, time/batch = 0.1053s	
2186/2700 (epoch 40.481), train_loss = 1.08241217, grad/param norm = 5.8679e-01, time/batch = 0.1283s	
2187/2700 (epoch 40.500), train_loss = 1.04354039, grad/param norm = 5.9161e-01, time/batch = 0.1232s	
2188/2700 (epoch 40.519), train_loss = 1.11432831, grad/param norm = 5.9710e-01, time/batch = 0.1418s	
2189/2700 (epoch 40.537), train_loss = 1.09660792, grad/param norm = 6.0787e-01, time/batch = 0.1406s	
2190/2700 (epoch 40.556), train_loss = 1.02689323, grad/param norm = 5.6548e-01, time/batch = 0.1442s	
2191/2700 (epoch 40.574), train_loss = 1.04658752, grad/param norm = 6.3739e-01, time/batch = 0.1097s	
2192/2700 (epoch 40.593), train_loss = 1.09438425, grad/param norm = 6.1018e-01, time/batch = 0.1261s	
2193/2700 (epoch 40.611), train_loss = 1.02598348, grad/param norm = 5.9720e-01, time/batch = 0.0935s	
2194/2700 (epoch 40.630), train_loss = 1.04530598, grad/param norm = 5.8966e-01, time/batch = 0.0964s	
2195/2700 (epoch 40.648), train_loss = 1.06958214, grad/param norm = 5.7425e-01, time/batch = 0.1139s	
2196/2700 (epoch 40.667), train_loss = 1.03789124, grad/param norm = 5.6757e-01, time/batch = 0.1077s	
2197/2700 (epoch 40.685), train_loss = 1.08032683, grad/param norm = 5.9180e-01, time/batch = 0.1127s	
2198/2700 (epoch 40.704), train_loss = 1.11533711, grad/param norm = 5.9760e-01, time/batch = 0.1158s	
2199/2700 (epoch 40.722), train_loss = 1.08168943, grad/param norm = 5.7495e-01, time/batch = 0.1090s	
2200/2700 (epoch 40.741), train_loss = 1.07908879, grad/param norm = 5.8681e-01, time/batch = 0.1045s	
2201/2700 (epoch 40.759), train_loss = 1.05478022, grad/param norm = 5.6942e-01, time/batch = 0.1092s	
2202/2700 (epoch 40.778), train_loss = 1.12568240, grad/param norm = 6.0222e-01, time/batch = 0.1042s	
2203/2700 (epoch 40.796), train_loss = 1.03678922, grad/param norm = 5.9378e-01, time/batch = 0.1153s	
2204/2700 (epoch 40.815), train_loss = 1.11127237, grad/param norm = 6.3167e-01, time/batch = 0.1193s	
2205/2700 (epoch 40.833), train_loss = 1.07960041, grad/param norm = 5.9356e-01, time/batch = 0.0913s	
2206/2700 (epoch 40.852), train_loss = 1.06757079, grad/param norm = 5.8609e-01, time/batch = 0.1039s	
2207/2700 (epoch 40.870), train_loss = 1.11801304, grad/param norm = 5.9890e-01, time/batch = 0.1119s	
2208/2700 (epoch 40.889), train_loss = 1.07896328, grad/param norm = 5.9220e-01, time/batch = 0.1224s	
2209/2700 (epoch 40.907), train_loss = 1.12153875, grad/param norm = 6.0390e-01, time/batch = 0.1285s	
2210/2700 (epoch 40.926), train_loss = 1.06667041, grad/param norm = 5.9632e-01, time/batch = 0.1270s	
2211/2700 (epoch 40.944), train_loss = 1.06077934, grad/param norm = 5.8796e-01, time/batch = 0.1293s	
2212/2700 (epoch 40.963), train_loss = 1.08292165, grad/param norm = 5.8234e-01, time/batch = 0.1308s	
2213/2700 (epoch 40.981), train_loss = 1.04645414, grad/param norm = 6.1249e-01, time/batch = 0.1316s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2214/2700 (epoch 41.000), train_loss = 1.14019382, grad/param norm = 5.9504e-01, time/batch = 0.1336s	
2215/2700 (epoch 41.019), train_loss = 1.15407196, grad/param norm = 6.1149e-01, time/batch = 0.1308s	
2216/2700 (epoch 41.037), train_loss = 1.11958923, grad/param norm = 6.2757e-01, time/batch = 0.1055s	
2217/2700 (epoch 41.056), train_loss = 1.06535312, grad/param norm = 5.9827e-01, time/batch = 0.1084s	
2218/2700 (epoch 41.074), train_loss = 1.05746316, grad/param norm = 6.1510e-01, time/batch = 0.1455s	
2219/2700 (epoch 41.093), train_loss = 1.05425978, grad/param norm = 5.9752e-01, time/batch = 0.1449s	
2220/2700 (epoch 41.111), train_loss = 1.03394540, grad/param norm = 6.0488e-01, time/batch = 0.1467s	
2221/2700 (epoch 41.130), train_loss = 1.10188397, grad/param norm = 6.2263e-01, time/batch = 0.1187s	
2222/2700 (epoch 41.148), train_loss = 1.07586084, grad/param norm = 5.8100e-01, time/batch = 0.1207s	
2223/2700 (epoch 41.167), train_loss = 1.09235736, grad/param norm = 6.1232e-01, time/batch = 0.1266s	
2224/2700 (epoch 41.185), train_loss = 1.06509250, grad/param norm = 6.1117e-01, time/batch = 0.1292s	
2225/2700 (epoch 41.204), train_loss = 1.11600628, grad/param norm = 6.0922e-01, time/batch = 0.1268s	
2226/2700 (epoch 41.222), train_loss = 1.05708452, grad/param norm = 5.9996e-01, time/batch = 0.1163s	
2227/2700 (epoch 41.241), train_loss = 1.02192892, grad/param norm = 5.8222e-01, time/batch = 0.1268s	
2228/2700 (epoch 41.259), train_loss = 1.04409199, grad/param norm = 5.8367e-01, time/batch = 0.1435s	
2229/2700 (epoch 41.278), train_loss = 1.09174449, grad/param norm = 5.9653e-01, time/batch = 0.1424s	
2230/2700 (epoch 41.296), train_loss = 1.05373221, grad/param norm = 5.7937e-01, time/batch = 0.1419s	
2231/2700 (epoch 41.315), train_loss = 1.02428035, grad/param norm = 5.8898e-01, time/batch = 0.1302s	
2232/2700 (epoch 41.333), train_loss = 1.05475822, grad/param norm = 5.7091e-01, time/batch = 0.1298s	
2233/2700 (epoch 41.352), train_loss = 1.04712095, grad/param norm = 5.8033e-01, time/batch = 0.1315s	
2234/2700 (epoch 41.370), train_loss = 1.05898979, grad/param norm = 5.9785e-01, time/batch = 0.1275s	
2235/2700 (epoch 41.389), train_loss = 1.02875292, grad/param norm = 5.8953e-01, time/batch = 0.1284s	
2236/2700 (epoch 41.407), train_loss = 1.09687839, grad/param norm = 6.1462e-01, time/batch = 0.1275s	
2237/2700 (epoch 41.426), train_loss = 1.13026477, grad/param norm = 5.9619e-01, time/batch = 0.1104s	
2238/2700 (epoch 41.444), train_loss = 1.09640249, grad/param norm = 6.4384e-01, time/batch = 0.1409s	
2239/2700 (epoch 41.463), train_loss = 1.10154298, grad/param norm = 6.0382e-01, time/batch = 0.1427s	
2240/2700 (epoch 41.481), train_loss = 1.07331611, grad/param norm = 6.0465e-01, time/batch = 0.1448s	
2241/2700 (epoch 41.500), train_loss = 1.03465217, grad/param norm = 6.3258e-01, time/batch = 0.1380s	
2242/2700 (epoch 41.519), train_loss = 1.10309830, grad/param norm = 6.2258e-01, time/batch = 0.1381s	
2243/2700 (epoch 41.537), train_loss = 1.08469361, grad/param norm = 6.0527e-01, time/batch = 0.1353s	
2244/2700 (epoch 41.556), train_loss = 1.01853516, grad/param norm = 5.9000e-01, time/batch = 0.1187s	
2245/2700 (epoch 41.574), train_loss = 1.02990659, grad/param norm = 5.9447e-01, time/batch = 0.1183s	
2246/2700 (epoch 41.593), train_loss = 1.08236156, grad/param norm = 6.1647e-01, time/batch = 0.1203s	
2247/2700 (epoch 41.611), train_loss = 1.01608037, grad/param norm = 6.0785e-01, time/batch = 0.0884s	
2248/2700 (epoch 41.630), train_loss = 1.03086509, grad/param norm = 5.7822e-01, time/batch = 0.0646s	
2249/2700 (epoch 41.648), train_loss = 1.05915102, grad/param norm = 5.8392e-01, time/batch = 0.0917s	
2250/2700 (epoch 41.667), train_loss = 1.02677449, grad/param norm = 5.8145e-01, time/batch = 0.0918s	
2251/2700 (epoch 41.685), train_loss = 1.06805899, grad/param norm = 5.8799e-01, time/batch = 0.0880s	
2252/2700 (epoch 41.704), train_loss = 1.10255448, grad/param norm = 6.0515e-01, time/batch = 0.0989s	
2253/2700 (epoch 41.722), train_loss = 1.07019480, grad/param norm = 5.8931e-01, time/batch = 0.1114s	
2254/2700 (epoch 41.741), train_loss = 1.06429742, grad/param norm = 5.8117e-01, time/batch = 0.1230s	
2255/2700 (epoch 41.759), train_loss = 1.04518183, grad/param norm = 5.8061e-01, time/batch = 0.1257s	
2256/2700 (epoch 41.778), train_loss = 1.11118766, grad/param norm = 6.0367e-01, time/batch = 0.1276s	
2257/2700 (epoch 41.796), train_loss = 1.02134117, grad/param norm = 6.0075e-01, time/batch = 0.1288s	
2258/2700 (epoch 41.815), train_loss = 1.09914813, grad/param norm = 6.6354e-01, time/batch = 0.1099s	
2259/2700 (epoch 41.833), train_loss = 1.07132998, grad/param norm = 6.3444e-01, time/batch = 0.1011s	
2260/2700 (epoch 41.852), train_loss = 1.05648021, grad/param norm = 5.9948e-01, time/batch = 0.0638s	
2261/2700 (epoch 41.870), train_loss = 1.10361153, grad/param norm = 5.9779e-01, time/batch = 0.1330s	
2262/2700 (epoch 41.889), train_loss = 1.06976539, grad/param norm = 6.0671e-01, time/batch = 0.1331s	
2263/2700 (epoch 41.907), train_loss = 1.10616163, grad/param norm = 6.0997e-01, time/batch = 0.1340s	
2264/2700 (epoch 41.926), train_loss = 1.05439485, grad/param norm = 6.0518e-01, time/batch = 0.1299s	
2265/2700 (epoch 41.944), train_loss = 1.05357497, grad/param norm = 6.1670e-01, time/batch = 0.1144s	
2266/2700 (epoch 41.963), train_loss = 1.07497597, grad/param norm = 6.0660e-01, time/batch = 0.0986s	
2267/2700 (epoch 41.981), train_loss = 1.03357209, grad/param norm = 6.2359e-01, time/batch = 0.0912s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2268/2700 (epoch 42.000), train_loss = 1.12943605, grad/param norm = 6.0167e-01, time/batch = 0.0998s	
2269/2700 (epoch 42.019), train_loss = 1.14375056, grad/param norm = 6.3337e-01, time/batch = 0.0964s	
2270/2700 (epoch 42.037), train_loss = 1.10043383, grad/param norm = 6.0830e-01, time/batch = 0.1308s	
2271/2700 (epoch 42.056), train_loss = 1.04996657, grad/param norm = 6.0921e-01, time/batch = 0.1167s	
2272/2700 (epoch 42.074), train_loss = 1.04639382, grad/param norm = 6.2578e-01, time/batch = 0.1094s	
2273/2700 (epoch 42.093), train_loss = 1.04295807, grad/param norm = 6.1134e-01, time/batch = 0.1087s	
2274/2700 (epoch 42.111), train_loss = 1.02277235, grad/param norm = 6.0117e-01, time/batch = 0.1311s	
2275/2700 (epoch 42.130), train_loss = 1.09088480, grad/param norm = 6.3337e-01, time/batch = 0.1314s	
2276/2700 (epoch 42.148), train_loss = 1.06727932, grad/param norm = 6.1306e-01, time/batch = 0.1327s	
2277/2700 (epoch 42.167), train_loss = 1.07891971, grad/param norm = 6.2573e-01, time/batch = 0.1292s	
2278/2700 (epoch 42.185), train_loss = 1.04882847, grad/param norm = 5.8563e-01, time/batch = 0.1288s	
2279/2700 (epoch 42.204), train_loss = 1.10874409, grad/param norm = 6.3910e-01, time/batch = 0.1271s	
2280/2700 (epoch 42.222), train_loss = 1.04633601, grad/param norm = 6.0868e-01, time/batch = 0.1208s	
2281/2700 (epoch 42.241), train_loss = 1.01147889, grad/param norm = 5.8099e-01, time/batch = 0.1234s	
2282/2700 (epoch 42.259), train_loss = 1.03395806, grad/param norm = 5.9850e-01, time/batch = 0.1132s	
2283/2700 (epoch 42.278), train_loss = 1.08092220, grad/param norm = 6.0737e-01, time/batch = 0.1352s	
2284/2700 (epoch 42.296), train_loss = 1.04053187, grad/param norm = 5.8299e-01, time/batch = 0.1331s	
2285/2700 (epoch 42.315), train_loss = 1.01222684, grad/param norm = 5.9969e-01, time/batch = 0.1335s	
2286/2700 (epoch 42.333), train_loss = 1.04478855, grad/param norm = 5.9139e-01, time/batch = 0.1332s	
2287/2700 (epoch 42.352), train_loss = 1.03381935, grad/param norm = 5.8909e-01, time/batch = 0.1335s	
2288/2700 (epoch 42.370), train_loss = 1.04427382, grad/param norm = 6.0099e-01, time/batch = 0.1341s	
2289/2700 (epoch 42.389), train_loss = 1.01338073, grad/param norm = 5.8835e-01, time/batch = 0.1352s	
2290/2700 (epoch 42.407), train_loss = 1.08586626, grad/param norm = 6.3940e-01, time/batch = 0.1191s	
2291/2700 (epoch 42.426), train_loss = 1.12211278, grad/param norm = 6.4754e-01, time/batch = 0.1422s	
2292/2700 (epoch 42.444), train_loss = 1.07934611, grad/param norm = 6.1433e-01, time/batch = 0.1303s	
2293/2700 (epoch 42.463), train_loss = 1.08646288, grad/param norm = 6.0218e-01, time/batch = 0.1378s	
2294/2700 (epoch 42.481), train_loss = 1.05947762, grad/param norm = 6.1187e-01, time/batch = 0.1378s	
2295/2700 (epoch 42.500), train_loss = 1.02194237, grad/param norm = 6.4833e-01, time/batch = 0.1381s	
2296/2700 (epoch 42.519), train_loss = 1.09024205, grad/param norm = 6.2509e-01, time/batch = 0.1360s	
2297/2700 (epoch 42.537), train_loss = 1.07099442, grad/param norm = 6.3094e-01, time/batch = 0.1318s	
2298/2700 (epoch 42.556), train_loss = 1.00579129, grad/param norm = 5.8147e-01, time/batch = 0.1356s	
2299/2700 (epoch 42.574), train_loss = 1.01961272, grad/param norm = 6.3375e-01, time/batch = 0.1370s	
2300/2700 (epoch 42.593), train_loss = 1.06868282, grad/param norm = 6.2302e-01, time/batch = 0.1190s	
2301/2700 (epoch 42.611), train_loss = 1.00137289, grad/param norm = 5.9473e-01, time/batch = 0.1436s	
2302/2700 (epoch 42.630), train_loss = 1.01785360, grad/param norm = 5.8590e-01, time/batch = 0.1207s	
2303/2700 (epoch 42.648), train_loss = 1.04664746, grad/param norm = 5.9064e-01, time/batch = 0.1159s	
2304/2700 (epoch 42.667), train_loss = 1.01759635, grad/param norm = 5.9168e-01, time/batch = 0.1102s	
2305/2700 (epoch 42.685), train_loss = 1.05528145, grad/param norm = 5.9792e-01, time/batch = 0.1165s	
2306/2700 (epoch 42.704), train_loss = 1.08918036, grad/param norm = 6.0275e-01, time/batch = 0.1165s	
2307/2700 (epoch 42.722), train_loss = 1.05675657, grad/param norm = 5.9099e-01, time/batch = 0.1235s	
2308/2700 (epoch 42.741), train_loss = 1.05140233, grad/param norm = 5.8564e-01, time/batch = 0.1299s	
2309/2700 (epoch 42.759), train_loss = 1.03181149, grad/param norm = 5.8730e-01, time/batch = 0.1331s	
2310/2700 (epoch 42.778), train_loss = 1.09773445, grad/param norm = 6.0597e-01, time/batch = 0.1242s	
2311/2700 (epoch 42.796), train_loss = 1.01015689, grad/param norm = 6.0926e-01, time/batch = 0.1187s	
2312/2700 (epoch 42.815), train_loss = 1.08553655, grad/param norm = 6.4883e-01, time/batch = 0.1287s	
2313/2700 (epoch 42.833), train_loss = 1.05480455, grad/param norm = 6.2716e-01, time/batch = 0.1267s	
2314/2700 (epoch 42.852), train_loss = 1.04440657, grad/param norm = 6.0684e-01, time/batch = 0.1442s	
2315/2700 (epoch 42.870), train_loss = 1.09180322, grad/param norm = 6.0399e-01, time/batch = 0.1449s	
2316/2700 (epoch 42.889), train_loss = 1.05450035, grad/param norm = 6.0189e-01, time/batch = 0.1449s	
2317/2700 (epoch 42.907), train_loss = 1.09356870, grad/param norm = 6.2396e-01, time/batch = 0.1457s	
2318/2700 (epoch 42.926), train_loss = 1.04193743, grad/param norm = 6.1555e-01, time/batch = 0.1460s	
2319/2700 (epoch 42.944), train_loss = 1.03649850, grad/param norm = 6.0796e-01, time/batch = 0.1431s	
2320/2700 (epoch 42.963), train_loss = 1.06122339, grad/param norm = 6.0971e-01, time/batch = 0.1308s	
2321/2700 (epoch 42.981), train_loss = 1.02232223, grad/param norm = 6.2710e-01, time/batch = 0.1204s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
2322/2700 (epoch 43.000), train_loss = 1.11365432, grad/param norm = 5.9805e-01, time/batch = 0.1213s	
2323/2700 (epoch 43.019), train_loss = 1.12733298, grad/param norm = 6.1581e-01, time/batch = 0.1163s	
2324/2700 (epoch 43.037), train_loss = 1.08691224, grad/param norm = 6.2249e-01, time/batch = 0.1388s	
2325/2700 (epoch 43.056), train_loss = 1.03870042, grad/param norm = 6.1214e-01, time/batch = 0.1320s	
2326/2700 (epoch 43.074), train_loss = 1.03650963, grad/param norm = 6.3314e-01, time/batch = 0.1297s	
2327/2700 (epoch 43.093), train_loss = 1.03188195, grad/param norm = 6.1300e-01, time/batch = 0.1290s	
2328/2700 (epoch 43.111), train_loss = 1.00967038, grad/param norm = 6.1651e-01, time/batch = 0.1307s	
2329/2700 (epoch 43.130), train_loss = 1.07956160, grad/param norm = 6.3575e-01, time/batch = 0.1332s	
2330/2700 (epoch 43.148), train_loss = 1.05160219, grad/param norm = 5.9777e-01, time/batch = 0.1227s	
2331/2700 (epoch 43.167), train_loss = 1.06658001, grad/param norm = 6.3255e-01, time/batch = 0.0929s	
2332/2700 (epoch 43.185), train_loss = 1.04128584, grad/param norm = 6.2101e-01, time/batch = 0.1161s	
2333/2700 (epoch 43.204), train_loss = 1.09442920, grad/param norm = 6.2137e-01, time/batch = 0.1061s	
2334/2700 (epoch 43.222), train_loss = 1.03531406, grad/param norm = 6.2424e-01, time/batch = 0.0740s	
2335/2700 (epoch 43.241), train_loss = 1.00441063, grad/param norm = 5.9903e-01, time/batch = 0.0918s	
2336/2700 (epoch 43.259), train_loss = 1.02214285, grad/param norm = 5.9372e-01, time/batch = 0.0918s	
2337/2700 (epoch 43.278), train_loss = 1.06846805, grad/param norm = 6.0839e-01, time/batch = 0.1087s	
2338/2700 (epoch 43.296), train_loss = 1.02976379, grad/param norm = 6.0608e-01, time/batch = 0.1262s	
2339/2700 (epoch 43.315), train_loss = 1.00151733, grad/param norm = 6.1497e-01, time/batch = 0.1306s	
2340/2700 (epoch 43.333), train_loss = 1.03225565, grad/param norm = 5.9721e-01, time/batch = 0.1336s	
2341/2700 (epoch 43.352), train_loss = 1.02306190, grad/param norm = 5.8821e-01, time/batch = 0.1206s	
2342/2700 (epoch 43.370), train_loss = 1.03054022, grad/param norm = 6.0246e-01, time/batch = 0.1168s	
2343/2700 (epoch 43.389), train_loss = 1.00426537, grad/param norm = 6.0687e-01, time/batch = 0.1272s	
2344/2700 (epoch 43.407), train_loss = 1.07222100, grad/param norm = 6.3172e-01, time/batch = 0.1227s	
2345/2700 (epoch 43.426), train_loss = 1.10445491, grad/param norm = 6.1266e-01, time/batch = 0.1178s	
2346/2700 (epoch 43.444), train_loss = 1.07002560, grad/param norm = 6.3354e-01, time/batch = 0.0856s	
2347/2700 (epoch 43.463), train_loss = 1.07257342, grad/param norm = 5.9899e-01, time/batch = 0.1041s	
2348/2700 (epoch 43.481), train_loss = 1.04532827, grad/param norm = 5.9584e-01, time/batch = 0.1159s	
2349/2700 (epoch 43.500), train_loss = 1.00306469, grad/param norm = 6.0632e-01, time/batch = 0.1172s	
2350/2700 (epoch 43.519), train_loss = 1.07352541, grad/param norm = 6.1606e-01, time/batch = 0.1214s	
2351/2700 (epoch 43.537), train_loss = 1.05711273, grad/param norm = 6.1350e-01, time/batch = 0.1088s	
2352/2700 (epoch 43.556), train_loss = 0.99464715, grad/param norm = 5.9928e-01, time/batch = 0.1152s	
2353/2700 (epoch 43.574), train_loss = 1.00754581, grad/param norm = 6.3043e-01, time/batch = 0.0812s	
2354/2700 (epoch 43.593), train_loss = 1.05533814, grad/param norm = 6.2104e-01, time/batch = 0.1014s	
2355/2700 (epoch 43.611), train_loss = 0.99194815, grad/param norm = 6.0833e-01, time/batch = 0.1008s	
2356/2700 (epoch 43.630), train_loss = 1.00786723, grad/param norm = 5.9576e-01, time/batch = 0.1088s	
2357/2700 (epoch 43.648), train_loss = 1.03882707, grad/param norm = 6.1626e-01, time/batch = 0.1051s	
2358/2700 (epoch 43.667), train_loss = 1.00850355, grad/param norm = 6.0677e-01, time/batch = 0.0962s	
2359/2700 (epoch 43.685), train_loss = 1.04556856, grad/param norm = 6.0416e-01, time/batch = 0.1111s	
2360/2700 (epoch 43.704), train_loss = 1.07801151, grad/param norm = 6.1263e-01, time/batch = 0.1266s	
2361/2700 (epoch 43.722), train_loss = 1.04551731, grad/param norm = 6.0436e-01, time/batch = 0.1286s	
2362/2700 (epoch 43.741), train_loss = 1.03991438, grad/param norm = 5.9355e-01, time/batch = 0.1319s	
2363/2700 (epoch 43.759), train_loss = 1.02009102, grad/param norm = 5.8625e-01, time/batch = 0.1336s	
2364/2700 (epoch 43.778), train_loss = 1.08300208, grad/param norm = 6.0762e-01, time/batch = 0.1250s	
2365/2700 (epoch 43.796), train_loss = 0.99794214, grad/param norm = 6.1188e-01, time/batch = 0.1451s	
2366/2700 (epoch 43.815), train_loss = 1.07187208, grad/param norm = 6.5215e-01, time/batch = 0.1338s	
2367/2700 (epoch 43.833), train_loss = 1.04031125, grad/param norm = 6.1598e-01, time/batch = 0.1341s	
2368/2700 (epoch 43.852), train_loss = 1.03424647, grad/param norm = 6.1925e-01, time/batch = 0.1175s	
2369/2700 (epoch 43.870), train_loss = 1.08450422, grad/param norm = 6.2928e-01, time/batch = 0.1079s	
2370/2700 (epoch 43.889), train_loss = 1.04349703, grad/param norm = 6.2126e-01, time/batch = 0.1102s	
2371/2700 (epoch 43.907), train_loss = 1.08329922, grad/param norm = 6.1874e-01, time/batch = 0.1046s	
2372/2700 (epoch 43.926), train_loss = 1.02977445, grad/param norm = 6.1531e-01, time/batch = 0.1209s	
2373/2700 (epoch 43.944), train_loss = 1.02212011, grad/param norm = 6.0511e-01, time/batch = 0.1176s	
2374/2700 (epoch 43.963), train_loss = 1.04680953, grad/param norm = 5.9962e-01, time/batch = 0.1097s	
2375/2700 (epoch 43.981), train_loss = 1.00780538, grad/param norm = 6.2287e-01, time/batch = 0.0891s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
2376/2700 (epoch 44.000), train_loss = 1.10163220, grad/param norm = 6.1005e-01, time/batch = 0.1107s	
2377/2700 (epoch 44.019), train_loss = 1.11796873, grad/param norm = 6.3447e-01, time/batch = 0.0957s	
2378/2700 (epoch 44.037), train_loss = 1.07674464, grad/param norm = 6.4614e-01, time/batch = 0.0988s	
2379/2700 (epoch 44.056), train_loss = 1.02625209, grad/param norm = 6.0867e-01, time/batch = 0.1058s	
2380/2700 (epoch 44.074), train_loss = 1.02209329, grad/param norm = 6.1939e-01, time/batch = 0.0985s	
2381/2700 (epoch 44.093), train_loss = 1.01782915, grad/param norm = 6.0673e-01, time/batch = 0.1124s	
2382/2700 (epoch 44.111), train_loss = 0.99772575, grad/param norm = 6.1584e-01, time/batch = 0.0893s	
2383/2700 (epoch 44.130), train_loss = 1.06935045, grad/param norm = 6.4089e-01, time/batch = 0.0917s	
2384/2700 (epoch 44.148), train_loss = 1.04274178, grad/param norm = 6.1637e-01, time/batch = 0.1038s	
2385/2700 (epoch 44.167), train_loss = 1.05238717, grad/param norm = 6.3557e-01, time/batch = 0.1151s	
2386/2700 (epoch 44.185), train_loss = 1.02665113, grad/param norm = 6.1114e-01, time/batch = 0.1055s	
2387/2700 (epoch 44.204), train_loss = 1.09173519, grad/param norm = 6.7356e-01, time/batch = 0.1304s	
2388/2700 (epoch 44.222), train_loss = 1.02391248, grad/param norm = 6.1963e-01, time/batch = 0.1333s	
2389/2700 (epoch 44.241), train_loss = 0.99539821, grad/param norm = 6.0798e-01, time/batch = 0.1322s	
2390/2700 (epoch 44.259), train_loss = 1.01516209, grad/param norm = 6.2251e-01, time/batch = 0.1338s	
2391/2700 (epoch 44.278), train_loss = 1.05684285, grad/param norm = 6.1853e-01, time/batch = 0.1299s	
2392/2700 (epoch 44.296), train_loss = 1.01742310, grad/param norm = 5.9972e-01, time/batch = 0.1121s	
2393/2700 (epoch 44.315), train_loss = 0.98737639, grad/param norm = 6.1807e-01, time/batch = 0.1135s	
2394/2700 (epoch 44.333), train_loss = 1.02307798, grad/param norm = 6.1956e-01, time/batch = 0.1135s	
2395/2700 (epoch 44.352), train_loss = 1.01451025, grad/param norm = 6.2877e-01, time/batch = 0.1190s	
2396/2700 (epoch 44.370), train_loss = 1.02233603, grad/param norm = 6.2799e-01, time/batch = 0.1180s	
2397/2700 (epoch 44.389), train_loss = 0.99234489, grad/param norm = 6.1160e-01, time/batch = 0.1389s	
2398/2700 (epoch 44.407), train_loss = 1.06113941, grad/param norm = 6.4311e-01, time/batch = 0.1332s	
2399/2700 (epoch 44.426), train_loss = 1.09763366, grad/param norm = 6.5316e-01, time/batch = 0.1291s	
2400/2700 (epoch 44.444), train_loss = 1.05797125, grad/param norm = 6.2984e-01, time/batch = 0.1285s	
2401/2700 (epoch 44.463), train_loss = 1.06079347, grad/param norm = 6.2023e-01, time/batch = 0.1275s	
2402/2700 (epoch 44.481), train_loss = 1.03619296, grad/param norm = 6.1582e-01, time/batch = 0.1222s	
2403/2700 (epoch 44.500), train_loss = 0.99221862, grad/param norm = 6.2740e-01, time/batch = 0.1466s	
2404/2700 (epoch 44.519), train_loss = 1.06091109, grad/param norm = 6.1881e-01, time/batch = 0.1469s	
2405/2700 (epoch 44.537), train_loss = 1.04289526, grad/param norm = 6.2245e-01, time/batch = 0.1403s	
2406/2700 (epoch 44.556), train_loss = 0.98277831, grad/param norm = 5.9160e-01, time/batch = 0.1473s	
2407/2700 (epoch 44.574), train_loss = 0.99493812, grad/param norm = 6.3223e-01, time/batch = 0.1458s	
2408/2700 (epoch 44.593), train_loss = 1.04533837, grad/param norm = 6.4017e-01, time/batch = 0.1438s	
2409/2700 (epoch 44.611), train_loss = 0.98095712, grad/param norm = 6.1216e-01, time/batch = 0.1434s	
2410/2700 (epoch 44.630), train_loss = 0.99440927, grad/param norm = 5.9754e-01, time/batch = 0.1435s	
2411/2700 (epoch 44.648), train_loss = 1.02575106, grad/param norm = 6.0270e-01, time/batch = 0.1373s	
2412/2700 (epoch 44.667), train_loss = 0.99343089, grad/param norm = 5.9079e-01, time/batch = 0.1296s	
2413/2700 (epoch 44.685), train_loss = 1.03688186, grad/param norm = 6.2770e-01, time/batch = 0.1151s	
2414/2700 (epoch 44.704), train_loss = 1.06551429, grad/param norm = 6.2405e-01, time/batch = 0.1081s	
2415/2700 (epoch 44.722), train_loss = 1.03209800, grad/param norm = 6.1724e-01, time/batch = 0.1065s	
2416/2700 (epoch 44.741), train_loss = 1.03033558, grad/param norm = 6.1344e-01, time/batch = 0.1351s	
2417/2700 (epoch 44.759), train_loss = 1.00829218, grad/param norm = 5.9863e-01, time/batch = 0.1399s	
2418/2700 (epoch 44.778), train_loss = 1.07014569, grad/param norm = 6.1954e-01, time/batch = 0.1246s	
2419/2700 (epoch 44.796), train_loss = 0.98764701, grad/param norm = 6.2528e-01, time/batch = 0.1297s	
2420/2700 (epoch 44.815), train_loss = 1.05844757, grad/param norm = 6.4762e-01, time/batch = 0.1339s	
2421/2700 (epoch 44.833), train_loss = 1.02658102, grad/param norm = 6.2780e-01, time/batch = 0.1198s	
2422/2700 (epoch 44.852), train_loss = 1.02032530, grad/param norm = 6.0768e-01, time/batch = 0.1292s	
2423/2700 (epoch 44.870), train_loss = 1.06655266, grad/param norm = 6.0456e-01, time/batch = 0.1130s	
2424/2700 (epoch 44.889), train_loss = 1.03147876, grad/param norm = 6.2090e-01, time/batch = 0.1059s	
2425/2700 (epoch 44.907), train_loss = 1.07080143, grad/param norm = 6.3863e-01, time/batch = 0.1005s	
2426/2700 (epoch 44.926), train_loss = 1.01902882, grad/param norm = 6.3479e-01, time/batch = 0.1056s	
2427/2700 (epoch 44.944), train_loss = 1.01527423, grad/param norm = 6.2863e-01, time/batch = 0.1075s	
2428/2700 (epoch 44.963), train_loss = 1.03857208, grad/param norm = 6.2293e-01, time/batch = 0.1107s	
2429/2700 (epoch 44.981), train_loss = 0.99549953, grad/param norm = 6.3446e-01, time/batch = 0.1149s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
2430/2700 (epoch 45.000), train_loss = 1.09127677, grad/param norm = 6.2101e-01, time/batch = 0.1198s	
2431/2700 (epoch 45.019), train_loss = 1.10536539, grad/param norm = 6.4301e-01, time/batch = 0.1067s	
2432/2700 (epoch 45.037), train_loss = 1.05888986, grad/param norm = 6.2389e-01, time/batch = 0.0988s	
2433/2700 (epoch 45.056), train_loss = 1.01363432, grad/param norm = 6.2443e-01, time/batch = 0.1028s	
2434/2700 (epoch 45.074), train_loss = 1.01394109, grad/param norm = 6.3895e-01, time/batch = 0.1151s	
2435/2700 (epoch 45.093), train_loss = 1.00858101, grad/param norm = 6.2111e-01, time/batch = 0.1047s	
2436/2700 (epoch 45.111), train_loss = 0.98602979, grad/param norm = 6.1361e-01, time/batch = 0.0880s	
2437/2700 (epoch 45.130), train_loss = 1.05868249, grad/param norm = 6.4638e-01, time/batch = 0.1061s	
2438/2700 (epoch 45.148), train_loss = 1.03087274, grad/param norm = 6.1834e-01, time/batch = 0.1082s	
2439/2700 (epoch 45.167), train_loss = 1.03927118, grad/param norm = 6.3216e-01, time/batch = 0.1118s	
2440/2700 (epoch 45.185), train_loss = 1.01323528, grad/param norm = 5.9853e-01, time/batch = 0.1122s	
2441/2700 (epoch 45.204), train_loss = 1.07468845, grad/param norm = 6.4172e-01, time/batch = 0.1295s	
2442/2700 (epoch 45.222), train_loss = 1.01283962, grad/param norm = 6.3853e-01, time/batch = 0.1252s	
2443/2700 (epoch 45.241), train_loss = 0.98563629, grad/param norm = 6.0746e-01, time/batch = 0.1059s	
2444/2700 (epoch 45.259), train_loss = 1.00230628, grad/param norm = 6.0887e-01, time/batch = 0.0865s	
2445/2700 (epoch 45.278), train_loss = 1.04814823, grad/param norm = 6.3028e-01, time/batch = 0.0941s	
2446/2700 (epoch 45.296), train_loss = 1.00715418, grad/param norm = 6.3003e-01, time/batch = 0.1124s	
2447/2700 (epoch 45.315), train_loss = 0.97930112, grad/param norm = 6.3790e-01, time/batch = 0.0842s	
2448/2700 (epoch 45.333), train_loss = 1.01363262, grad/param norm = 6.3036e-01, time/batch = 0.0902s	
2449/2700 (epoch 45.352), train_loss = 1.00166989, grad/param norm = 6.1139e-01, time/batch = 0.1115s	
2450/2700 (epoch 45.370), train_loss = 1.00757540, grad/param norm = 6.2490e-01, time/batch = 0.1086s	
2451/2700 (epoch 45.389), train_loss = 0.98592750, grad/param norm = 6.4156e-01, time/batch = 0.1277s	
2452/2700 (epoch 45.407), train_loss = 1.05126072, grad/param norm = 6.6104e-01, time/batch = 0.1190s	
2453/2700 (epoch 45.426), train_loss = 1.08206545, grad/param norm = 6.3124e-01, time/batch = 0.1115s	
2454/2700 (epoch 45.444), train_loss = 1.05047749, grad/param norm = 6.4881e-01, time/batch = 0.0987s	
2455/2700 (epoch 45.463), train_loss = 1.04892632, grad/param norm = 6.0746e-01, time/batch = 0.0915s	
2456/2700 (epoch 45.481), train_loss = 1.02586341, grad/param norm = 6.1747e-01, time/batch = 0.0992s	
2457/2700 (epoch 45.500), train_loss = 0.98088340, grad/param norm = 6.2356e-01, time/batch = 0.1125s	
2458/2700 (epoch 45.519), train_loss = 1.04783010, grad/param norm = 6.1633e-01, time/batch = 0.1072s	
2459/2700 (epoch 45.537), train_loss = 1.03188586, grad/param norm = 6.1735e-01, time/batch = 0.1009s	
2460/2700 (epoch 45.556), train_loss = 0.97322404, grad/param norm = 6.1032e-01, time/batch = 0.0969s	
2461/2700 (epoch 45.574), train_loss = 0.98371482, grad/param norm = 6.2149e-01, time/batch = 0.1339s	
2462/2700 (epoch 45.593), train_loss = 1.03242119, grad/param norm = 6.3146e-01, time/batch = 0.1320s	
2463/2700 (epoch 45.611), train_loss = 0.97081593, grad/param norm = 6.1363e-01, time/batch = 0.1339s	
2464/2700 (epoch 45.630), train_loss = 0.98452192, grad/param norm = 5.9943e-01, time/batch = 0.1245s	
2465/2700 (epoch 45.648), train_loss = 1.01755137, grad/param norm = 6.2040e-01, time/batch = 0.0971s	
2466/2700 (epoch 45.667), train_loss = 0.98437464, grad/param norm = 6.0201e-01, time/batch = 0.0919s	
2467/2700 (epoch 45.685), train_loss = 1.02440352, grad/param norm = 6.1444e-01, time/batch = 0.0997s	
2468/2700 (epoch 45.704), train_loss = 1.05345909, grad/param norm = 6.2163e-01, time/batch = 0.1143s	
2469/2700 (epoch 45.722), train_loss = 1.02148513, grad/param norm = 6.2251e-01, time/batch = 0.1066s	
2470/2700 (epoch 45.741), train_loss = 1.01682646, grad/param norm = 6.0794e-01, time/batch = 0.1164s	
2471/2700 (epoch 45.759), train_loss = 0.99932827, grad/param norm = 6.0939e-01, time/batch = 0.1324s	
2472/2700 (epoch 45.778), train_loss = 1.05622836, grad/param norm = 6.1483e-01, time/batch = 0.1324s	
2473/2700 (epoch 45.796), train_loss = 0.97398590, grad/param norm = 6.2553e-01, time/batch = 0.1335s	
2474/2700 (epoch 45.815), train_loss = 1.04854245, grad/param norm = 6.8117e-01, time/batch = 0.1301s	
2475/2700 (epoch 45.833), train_loss = 1.01646080, grad/param norm = 6.5430e-01, time/batch = 0.1173s	
2476/2700 (epoch 45.852), train_loss = 1.01273592, grad/param norm = 6.3018e-01, time/batch = 0.0930s	
2477/2700 (epoch 45.870), train_loss = 1.05763295, grad/param norm = 6.2891e-01, time/batch = 0.0929s	
2478/2700 (epoch 45.889), train_loss = 1.02082955, grad/param norm = 6.3218e-01, time/batch = 0.1153s	
2479/2700 (epoch 45.907), train_loss = 1.05767297, grad/param norm = 6.2222e-01, time/batch = 0.1238s	
2480/2700 (epoch 45.926), train_loss = 1.00485758, grad/param norm = 6.2442e-01, time/batch = 0.1174s	
2481/2700 (epoch 45.944), train_loss = 0.99804654, grad/param norm = 6.1210e-01, time/batch = 0.1041s	
2482/2700 (epoch 45.963), train_loss = 1.02402635, grad/param norm = 6.1175e-01, time/batch = 0.1113s	
2483/2700 (epoch 45.981), train_loss = 0.98213695, grad/param norm = 6.2627e-01, time/batch = 0.1053s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
2484/2700 (epoch 46.000), train_loss = 1.07697413, grad/param norm = 6.2125e-01, time/batch = 0.1114s	
2485/2700 (epoch 46.019), train_loss = 1.09272094, grad/param norm = 6.3842e-01, time/batch = 0.1149s	
2486/2700 (epoch 46.037), train_loss = 1.05036629, grad/param norm = 6.5716e-01, time/batch = 0.1264s	
2487/2700 (epoch 46.056), train_loss = 1.00415565, grad/param norm = 6.2238e-01, time/batch = 0.1247s	
2488/2700 (epoch 46.074), train_loss = 1.00453354, grad/param norm = 6.4570e-01, time/batch = 0.1234s	
2489/2700 (epoch 46.093), train_loss = 0.99805373, grad/param norm = 6.2749e-01, time/batch = 0.1230s	
2490/2700 (epoch 46.111), train_loss = 0.97623755, grad/param norm = 6.4140e-01, time/batch = 0.1186s	
2491/2700 (epoch 46.130), train_loss = 1.04999234, grad/param norm = 6.5870e-01, time/batch = 0.1273s	
2492/2700 (epoch 46.148), train_loss = 1.01851243, grad/param norm = 6.1729e-01, time/batch = 0.1226s	
2493/2700 (epoch 46.167), train_loss = 1.02709723, grad/param norm = 6.4271e-01, time/batch = 0.1081s	
2494/2700 (epoch 46.185), train_loss = 1.00629303, grad/param norm = 6.3362e-01, time/batch = 0.1064s	
2495/2700 (epoch 46.204), train_loss = 1.06462928, grad/param norm = 6.4568e-01, time/batch = 0.1113s	
2496/2700 (epoch 46.222), train_loss = 1.00073854, grad/param norm = 6.3726e-01, time/batch = 0.1185s	
2497/2700 (epoch 46.241), train_loss = 0.97749573, grad/param norm = 6.1571e-01, time/batch = 0.1240s	
2498/2700 (epoch 46.259), train_loss = 0.99287662, grad/param norm = 6.1720e-01, time/batch = 0.1252s	
2499/2700 (epoch 46.278), train_loss = 1.03430256, grad/param norm = 6.2219e-01, time/batch = 0.1240s	
2500/2700 (epoch 46.296), train_loss = 0.99274316, grad/param norm = 6.0925e-01, time/batch = 0.1210s	
2501/2700 (epoch 46.315), train_loss = 0.96239148, grad/param norm = 6.1864e-01, time/batch = 0.1249s	
2502/2700 (epoch 46.333), train_loss = 1.00041092, grad/param norm = 6.2383e-01, time/batch = 0.1252s	
2503/2700 (epoch 46.352), train_loss = 0.99071471, grad/param norm = 6.2532e-01, time/batch = 0.1228s	
2504/2700 (epoch 46.370), train_loss = 0.99622654, grad/param norm = 6.2958e-01, time/batch = 0.1050s	
2505/2700 (epoch 46.389), train_loss = 0.97144071, grad/param norm = 6.2596e-01, time/batch = 0.1090s	
2506/2700 (epoch 46.407), train_loss = 1.03653341, grad/param norm = 6.4444e-01, time/batch = 0.1158s	
2507/2700 (epoch 46.426), train_loss = 1.07327535, grad/param norm = 6.5345e-01, time/batch = 0.1236s	
2508/2700 (epoch 46.444), train_loss = 1.04012600, grad/param norm = 6.5683e-01, time/batch = 0.1272s	
2509/2700 (epoch 46.463), train_loss = 1.03761395, grad/param norm = 6.3320e-01, time/batch = 0.1268s	
2510/2700 (epoch 46.481), train_loss = 1.01489718, grad/param norm = 6.2625e-01, time/batch = 0.1191s	
2511/2700 (epoch 46.500), train_loss = 0.96704876, grad/param norm = 6.2313e-01, time/batch = 0.1225s	
2512/2700 (epoch 46.519), train_loss = 1.03719117, grad/param norm = 6.3071e-01, time/batch = 0.1239s	
2513/2700 (epoch 46.537), train_loss = 1.01938725, grad/param norm = 6.2950e-01, time/batch = 0.1253s	
2514/2700 (epoch 46.556), train_loss = 0.96133842, grad/param norm = 6.0080e-01, time/batch = 0.1268s	
2515/2700 (epoch 46.574), train_loss = 0.97504958, grad/param norm = 6.5016e-01, time/batch = 0.1058s	
2516/2700 (epoch 46.593), train_loss = 1.02021941, grad/param norm = 6.3232e-01, time/batch = 0.1062s	
2517/2700 (epoch 46.611), train_loss = 0.96063239, grad/param norm = 6.1942e-01, time/batch = 0.1176s	
2518/2700 (epoch 46.630), train_loss = 0.97378221, grad/param norm = 6.0804e-01, time/batch = 0.1243s	
2519/2700 (epoch 46.648), train_loss = 1.00486077, grad/param norm = 6.1597e-01, time/batch = 0.1249s	
2520/2700 (epoch 46.667), train_loss = 0.97227888, grad/param norm = 5.9933e-01, time/batch = 0.1158s	
2521/2700 (epoch 46.685), train_loss = 1.01454584, grad/param norm = 6.2505e-01, time/batch = 0.1229s	
2522/2700 (epoch 46.704), train_loss = 1.04111762, grad/param norm = 6.2080e-01, time/batch = 0.1255s	
2523/2700 (epoch 46.722), train_loss = 1.00881451, grad/param norm = 6.2197e-01, time/batch = 0.1256s	
2524/2700 (epoch 46.741), train_loss = 1.00708621, grad/param norm = 6.1475e-01, time/batch = 0.1259s	
2525/2700 (epoch 46.759), train_loss = 0.98610140, grad/param norm = 6.1101e-01, time/batch = 0.1276s	
2526/2700 (epoch 46.778), train_loss = 1.04428196, grad/param norm = 6.2635e-01, time/batch = 0.0980s	
2527/2700 (epoch 46.796), train_loss = 0.96660864, grad/param norm = 6.4826e-01, time/batch = 0.1187s	
2528/2700 (epoch 46.815), train_loss = 1.03536796, grad/param norm = 6.6117e-01, time/batch = 0.1260s	
2529/2700 (epoch 46.833), train_loss = 1.00154664, grad/param norm = 6.4959e-01, time/batch = 0.1240s	
2530/2700 (epoch 46.852), train_loss = 1.00266215, grad/param norm = 6.4449e-01, time/batch = 0.1252s	
2531/2700 (epoch 46.870), train_loss = 1.04643218, grad/param norm = 6.3653e-01, time/batch = 0.1160s	
2532/2700 (epoch 46.889), train_loss = 1.00920099, grad/param norm = 6.3929e-01, time/batch = 0.0980s	
2533/2700 (epoch 46.907), train_loss = 1.04891233, grad/param norm = 6.5071e-01, time/batch = 0.0838s	
2534/2700 (epoch 46.926), train_loss = 0.99364588, grad/param norm = 6.3636e-01, time/batch = 0.0906s	
2535/2700 (epoch 46.944), train_loss = 0.98796333, grad/param norm = 6.1621e-01, time/batch = 0.0910s	
2536/2700 (epoch 46.963), train_loss = 1.01414170, grad/param norm = 6.2646e-01, time/batch = 0.0862s	
2537/2700 (epoch 46.981), train_loss = 0.97057153, grad/param norm = 6.2995e-01, time/batch = 0.0611s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
2538/2700 (epoch 47.000), train_loss = 1.06672314, grad/param norm = 6.2844e-01, time/batch = 0.0907s	
2539/2700 (epoch 47.019), train_loss = 1.08081451, grad/param norm = 6.4252e-01, time/batch = 0.0916s	
2540/2700 (epoch 47.037), train_loss = 1.03505714, grad/param norm = 6.3793e-01, time/batch = 0.0908s	
2541/2700 (epoch 47.056), train_loss = 0.99277059, grad/param norm = 6.3372e-01, time/batch = 0.0776s	
2542/2700 (epoch 47.074), train_loss = 0.99360006, grad/param norm = 6.4628e-01, time/batch = 0.0880s	
2543/2700 (epoch 47.093), train_loss = 0.98685995, grad/param norm = 6.3046e-01, time/batch = 0.0912s	
2544/2700 (epoch 47.111), train_loss = 0.96341072, grad/param norm = 6.2338e-01, time/batch = 0.0911s	
2545/2700 (epoch 47.130), train_loss = 1.03784369, grad/param norm = 6.5898e-01, time/batch = 0.0910s	
2546/2700 (epoch 47.148), train_loss = 1.01399539, grad/param norm = 6.4474e-01, time/batch = 0.0906s	
2547/2700 (epoch 47.167), train_loss = 1.01734410, grad/param norm = 6.5114e-01, time/batch = 0.0776s	
2548/2700 (epoch 47.185), train_loss = 0.99297590, grad/param norm = 6.2226e-01, time/batch = 0.0668s	
2549/2700 (epoch 47.204), train_loss = 1.06042351, grad/param norm = 6.8404e-01, time/batch = 0.0713s	
2550/2700 (epoch 47.222), train_loss = 0.98877770, grad/param norm = 6.2968e-01, time/batch = 0.0794s	
2551/2700 (epoch 47.241), train_loss = 0.96691228, grad/param norm = 6.2155e-01, time/batch = 0.0690s	
2552/2700 (epoch 47.259), train_loss = 0.98617370, grad/param norm = 6.3594e-01, time/batch = 0.0780s	
2553/2700 (epoch 47.278), train_loss = 1.02346603, grad/param norm = 6.3205e-01, time/batch = 0.0859s	
2554/2700 (epoch 47.296), train_loss = 0.98241583, grad/param norm = 6.1746e-01, time/batch = 0.0913s	
2555/2700 (epoch 47.315), train_loss = 0.95165911, grad/param norm = 6.2932e-01, time/batch = 0.0907s	
2556/2700 (epoch 47.333), train_loss = 0.99094226, grad/param norm = 6.3183e-01, time/batch = 0.0909s	
2557/2700 (epoch 47.352), train_loss = 0.97642422, grad/param norm = 6.1618e-01, time/batch = 0.0910s	
2558/2700 (epoch 47.370), train_loss = 0.98036041, grad/param norm = 6.1774e-01, time/batch = 0.0780s	
2559/2700 (epoch 47.389), train_loss = 0.95963278, grad/param norm = 6.2553e-01, time/batch = 0.0691s	
2560/2700 (epoch 47.407), train_loss = 1.02438886, grad/param norm = 6.5064e-01, time/batch = 0.0688s	
2561/2700 (epoch 47.426), train_loss = 1.05981340, grad/param norm = 6.3782e-01, time/batch = 0.0911s	
2562/2700 (epoch 47.444), train_loss = 1.02850184, grad/param norm = 6.4950e-01, time/batch = 0.0916s	
2563/2700 (epoch 47.463), train_loss = 1.02543653, grad/param norm = 6.2076e-01, time/batch = 0.0879s	
2564/2700 (epoch 47.481), train_loss = 1.00660308, grad/param norm = 6.3712e-01, time/batch = 0.0810s	
2565/2700 (epoch 47.500), train_loss = 0.95677353, grad/param norm = 6.3330e-01, time/batch = 0.0729s	
2566/2700 (epoch 47.519), train_loss = 1.02549628, grad/param norm = 6.2783e-01, time/batch = 0.0654s	
2567/2700 (epoch 47.537), train_loss = 1.00967487, grad/param norm = 6.3425e-01, time/batch = 0.0744s	
2568/2700 (epoch 47.556), train_loss = 0.95301187, grad/param norm = 6.2318e-01, time/batch = 0.0837s	
2569/2700 (epoch 47.574), train_loss = 0.96295449, grad/param norm = 6.2555e-01, time/batch = 0.0705s	
2570/2700 (epoch 47.593), train_loss = 1.01076673, grad/param norm = 6.4800e-01, time/batch = 0.0755s	
2571/2700 (epoch 47.611), train_loss = 0.95175239, grad/param norm = 6.2430e-01, time/batch = 0.0911s	
2572/2700 (epoch 47.630), train_loss = 0.96394911, grad/param norm = 6.0622e-01, time/batch = 0.0910s	
2573/2700 (epoch 47.648), train_loss = 0.99730223, grad/param norm = 6.3013e-01, time/batch = 0.0904s	
2574/2700 (epoch 47.667), train_loss = 0.96264917, grad/param norm = 6.0597e-01, time/batch = 0.0913s	
2575/2700 (epoch 47.685), train_loss = 1.00521546, grad/param norm = 6.2723e-01, time/batch = 0.0892s	
2576/2700 (epoch 47.704), train_loss = 1.02972770, grad/param norm = 6.2689e-01, time/batch = 0.0917s	
2577/2700 (epoch 47.722), train_loss = 0.99777187, grad/param norm = 6.3057e-01, time/batch = 0.0908s	
2578/2700 (epoch 47.741), train_loss = 0.99611139, grad/param norm = 6.1906e-01, time/batch = 0.0908s	
2579/2700 (epoch 47.759), train_loss = 0.97589272, grad/param norm = 6.1319e-01, time/batch = 0.0901s	
2580/2700 (epoch 47.778), train_loss = 1.03024641, grad/param norm = 6.1983e-01, time/batch = 0.0564s	
2581/2700 (epoch 47.796), train_loss = 0.95307482, grad/param norm = 6.3674e-01, time/batch = 0.0760s	
2582/2700 (epoch 47.815), train_loss = 1.02471957, grad/param norm = 6.7581e-01, time/batch = 0.0854s	
2583/2700 (epoch 47.833), train_loss = 0.98886146, grad/param norm = 6.5375e-01, time/batch = 0.0911s	
2584/2700 (epoch 47.852), train_loss = 0.99225524, grad/param norm = 6.4617e-01, time/batch = 0.0913s	
2585/2700 (epoch 47.870), train_loss = 1.03646056, grad/param norm = 6.4602e-01, time/batch = 0.0914s	
2586/2700 (epoch 47.889), train_loss = 0.99671506, grad/param norm = 6.4170e-01, time/batch = 0.0907s	
2587/2700 (epoch 47.907), train_loss = 1.03640532, grad/param norm = 6.3341e-01, time/batch = 0.0907s	
2588/2700 (epoch 47.926), train_loss = 0.98408516, grad/param norm = 6.4505e-01, time/batch = 0.0913s	
2589/2700 (epoch 47.944), train_loss = 0.97766907, grad/param norm = 6.2274e-01, time/batch = 0.0911s	
2590/2700 (epoch 47.963), train_loss = 1.00239763, grad/param norm = 6.2610e-01, time/batch = 0.0818s	
2591/2700 (epoch 47.981), train_loss = 0.95819831, grad/param norm = 6.3146e-01, time/batch = 0.0917s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
2592/2700 (epoch 48.000), train_loss = 1.05551937, grad/param norm = 6.4207e-01, time/batch = 0.0907s	
2593/2700 (epoch 48.019), train_loss = 1.07105339, grad/param norm = 6.6227e-01, time/batch = 0.0919s	
2594/2700 (epoch 48.037), train_loss = 1.02674491, grad/param norm = 6.6586e-01, time/batch = 0.0912s	
2595/2700 (epoch 48.056), train_loss = 0.98230309, grad/param norm = 6.2680e-01, time/batch = 0.0907s	
2596/2700 (epoch 48.074), train_loss = 0.98304186, grad/param norm = 6.4974e-01, time/batch = 0.0909s	
2597/2700 (epoch 48.093), train_loss = 0.97607726, grad/param norm = 6.2912e-01, time/batch = 0.0911s	
2598/2700 (epoch 48.111), train_loss = 0.95253891, grad/param norm = 6.4181e-01, time/batch = 0.0912s	
2599/2700 (epoch 48.130), train_loss = 1.02795508, grad/param norm = 6.6458e-01, time/batch = 0.0909s	
2600/2700 (epoch 48.148), train_loss = 0.99961466, grad/param norm = 6.2890e-01, time/batch = 0.0877s	
2601/2700 (epoch 48.167), train_loss = 1.00523764, grad/param norm = 6.5149e-01, time/batch = 0.0910s	
2602/2700 (epoch 48.185), train_loss = 0.98603457, grad/param norm = 6.4133e-01, time/batch = 0.0914s	
2603/2700 (epoch 48.204), train_loss = 1.04582075, grad/param norm = 6.6030e-01, time/batch = 0.0909s	
2604/2700 (epoch 48.222), train_loss = 0.97999086, grad/param norm = 6.5716e-01, time/batch = 0.0912s	
2605/2700 (epoch 48.241), train_loss = 0.96040340, grad/param norm = 6.2447e-01, time/batch = 0.0911s	
2606/2700 (epoch 48.259), train_loss = 0.97613277, grad/param norm = 6.2911e-01, time/batch = 0.0914s	
2607/2700 (epoch 48.278), train_loss = 1.01654867, grad/param norm = 6.4502e-01, time/batch = 0.0911s	
2608/2700 (epoch 48.296), train_loss = 0.97145121, grad/param norm = 6.3036e-01, time/batch = 0.0906s	
2609/2700 (epoch 48.315), train_loss = 0.94194777, grad/param norm = 6.3695e-01, time/batch = 0.0860s	
2610/2700 (epoch 48.333), train_loss = 0.98093387, grad/param norm = 6.3970e-01, time/batch = 0.0778s	
2611/2700 (epoch 48.352), train_loss = 0.96817850, grad/param norm = 6.2812e-01, time/batch = 0.0643s	
2612/2700 (epoch 48.370), train_loss = 0.97138831, grad/param norm = 6.3852e-01, time/batch = 0.0799s	
2613/2700 (epoch 48.389), train_loss = 0.95545085, grad/param norm = 6.6281e-01, time/batch = 0.0888s	
2614/2700 (epoch 48.407), train_loss = 1.01377702, grad/param norm = 6.6434e-01, time/batch = 0.0909s	
2615/2700 (epoch 48.426), train_loss = 1.04957610, grad/param norm = 6.4074e-01, time/batch = 0.0905s	
2616/2700 (epoch 48.444), train_loss = 1.02069265, grad/param norm = 6.5425e-01, time/batch = 0.0906s	
2617/2700 (epoch 48.463), train_loss = 1.01523659, grad/param norm = 6.2992e-01, time/batch = 0.0909s	
2618/2700 (epoch 48.481), train_loss = 0.99579313, grad/param norm = 6.3896e-01, time/batch = 0.0915s	
2619/2700 (epoch 48.500), train_loss = 0.94467752, grad/param norm = 6.2225e-01, time/batch = 0.0907s	
2620/2700 (epoch 48.519), train_loss = 1.01554220, grad/param norm = 6.4052e-01, time/batch = 0.0906s	
2621/2700 (epoch 48.537), train_loss = 0.99747066, grad/param norm = 6.3183e-01, time/batch = 0.0610s	
2622/2700 (epoch 48.556), train_loss = 0.94106330, grad/param norm = 6.1542e-01, time/batch = 0.0752s	
2623/2700 (epoch 48.574), train_loss = 0.95494138, grad/param norm = 6.5816e-01, time/batch = 0.0670s	
2624/2700 (epoch 48.593), train_loss = 0.99790292, grad/param norm = 6.4198e-01, time/batch = 0.0708s	
2625/2700 (epoch 48.611), train_loss = 0.94305430, grad/param norm = 6.3526e-01, time/batch = 0.0806s	
2626/2700 (epoch 48.630), train_loss = 0.95557317, grad/param norm = 6.1889e-01, time/batch = 0.0883s	
2627/2700 (epoch 48.648), train_loss = 0.98646835, grad/param norm = 6.3129e-01, time/batch = 0.0913s	
2628/2700 (epoch 48.667), train_loss = 0.95280599, grad/param norm = 6.1004e-01, time/batch = 0.0909s	
2629/2700 (epoch 48.685), train_loss = 0.99571273, grad/param norm = 6.3362e-01, time/batch = 0.0914s	
2630/2700 (epoch 48.704), train_loss = 1.01940211, grad/param norm = 6.2928e-01, time/batch = 0.0908s	
2631/2700 (epoch 48.722), train_loss = 0.98745082, grad/param norm = 6.3491e-01, time/batch = 0.0781s	
2632/2700 (epoch 48.741), train_loss = 0.98807903, grad/param norm = 6.2902e-01, time/batch = 0.0647s	
2633/2700 (epoch 48.759), train_loss = 0.96545181, grad/param norm = 6.2546e-01, time/batch = 0.0756s	
2634/2700 (epoch 48.778), train_loss = 1.01987087, grad/param norm = 6.3511e-01, time/batch = 0.0668s	
2635/2700 (epoch 48.796), train_loss = 0.94515165, grad/param norm = 6.5802e-01, time/batch = 0.0709s	
2636/2700 (epoch 48.815), train_loss = 1.01333989, grad/param norm = 6.7328e-01, time/batch = 0.0798s	
2637/2700 (epoch 48.833), train_loss = 0.97714076, grad/param norm = 6.6180e-01, time/batch = 0.0890s	
2638/2700 (epoch 48.852), train_loss = 0.98220689, grad/param norm = 6.5069e-01, time/batch = 0.0912s	
2639/2700 (epoch 48.870), train_loss = 1.02370536, grad/param norm = 6.4347e-01, time/batch = 0.0914s	
2640/2700 (epoch 48.889), train_loss = 0.98851560, grad/param norm = 6.5540e-01, time/batch = 0.0915s	
2641/2700 (epoch 48.907), train_loss = 1.02733883, grad/param norm = 6.6342e-01, time/batch = 0.0784s	
2642/2700 (epoch 48.926), train_loss = 0.97166270, grad/param norm = 6.4419e-01, time/batch = 0.0861s	
2643/2700 (epoch 48.944), train_loss = 0.96683943, grad/param norm = 6.2165e-01, time/batch = 0.0718s	
2644/2700 (epoch 48.963), train_loss = 0.99159617, grad/param norm = 6.3612e-01, time/batch = 0.0724s	
2645/2700 (epoch 48.981), train_loss = 0.94810695, grad/param norm = 6.3550e-01, time/batch = 0.0659s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
2646/2700 (epoch 49.000), train_loss = 1.04463711, grad/param norm = 6.4435e-01, time/batch = 0.0746s	
2647/2700 (epoch 49.019), train_loss = 1.05867484, grad/param norm = 6.5180e-01, time/batch = 0.0835s	
2648/2700 (epoch 49.037), train_loss = 1.01369954, grad/param norm = 6.5561e-01, time/batch = 0.0905s	
2649/2700 (epoch 49.056), train_loss = 0.97260734, grad/param norm = 6.4524e-01, time/batch = 0.0913s	
2650/2700 (epoch 49.074), train_loss = 0.97488218, grad/param norm = 6.5795e-01, time/batch = 0.0915s	
2651/2700 (epoch 49.093), train_loss = 0.96585739, grad/param norm = 6.3052e-01, time/batch = 0.0760s	
2652/2700 (epoch 49.111), train_loss = 0.93989994, grad/param norm = 6.2671e-01, time/batch = 0.0853s	
2653/2700 (epoch 49.130), train_loss = 1.01578135, grad/param norm = 6.6391e-01, time/batch = 0.0910s	
2654/2700 (epoch 49.148), train_loss = 0.99363605, grad/param norm = 6.4624e-01, time/batch = 0.0735s	
2655/2700 (epoch 49.167), train_loss = 0.99511052, grad/param norm = 6.5520e-01, time/batch = 0.0722s	
2656/2700 (epoch 49.185), train_loss = 0.97229803, grad/param norm = 6.2678e-01, time/batch = 0.0670s	
2657/2700 (epoch 49.204), train_loss = 1.03776957, grad/param norm = 6.7814e-01, time/batch = 0.0734s	
2658/2700 (epoch 49.222), train_loss = 0.96649751, grad/param norm = 6.4146e-01, time/batch = 0.0836s	
2659/2700 (epoch 49.241), train_loss = 0.94922396, grad/param norm = 6.2561e-01, time/batch = 0.0908s	
2660/2700 (epoch 49.259), train_loss = 0.96927412, grad/param norm = 6.4650e-01, time/batch = 0.0908s	
2661/2700 (epoch 49.278), train_loss = 1.00429270, grad/param norm = 6.4524e-01, time/batch = 0.0748s	
2662/2700 (epoch 49.296), train_loss = 0.96072588, grad/param norm = 6.2423e-01, time/batch = 0.0831s	
2663/2700 (epoch 49.315), train_loss = 0.93156843, grad/param norm = 6.4644e-01, time/batch = 0.0909s	
2664/2700 (epoch 49.333), train_loss = 0.97433929, grad/param norm = 6.5575e-01, time/batch = 0.0908s	
2665/2700 (epoch 49.352), train_loss = 0.95762710, grad/param norm = 6.4147e-01, time/batch = 0.0743s	
2666/2700 (epoch 49.370), train_loss = 0.95936226, grad/param norm = 6.4207e-01, time/batch = 0.0724s	
2667/2700 (epoch 49.389), train_loss = 0.94137800, grad/param norm = 6.3912e-01, time/batch = 0.0664s	
2668/2700 (epoch 49.407), train_loss = 1.00319297, grad/param norm = 6.6777e-01, time/batch = 0.0747s	
2669/2700 (epoch 49.426), train_loss = 1.04447518, grad/param norm = 6.8245e-01, time/batch = 0.0826s	
2670/2700 (epoch 49.444), train_loss = 1.01171235, grad/param norm = 6.7086e-01, time/batch = 0.0905s	
2671/2700 (epoch 49.463), train_loss = 1.00580540, grad/param norm = 6.4943e-01, time/batch = 0.0739s	
2672/2700 (epoch 49.481), train_loss = 0.98651354, grad/param norm = 6.4553e-01, time/batch = 0.0829s	
2673/2700 (epoch 49.500), train_loss = 0.93363901, grad/param norm = 6.2762e-01, time/batch = 0.0902s	
2674/2700 (epoch 49.519), train_loss = 1.00536279, grad/param norm = 6.4299e-01, time/batch = 0.0907s	
2675/2700 (epoch 49.537), train_loss = 0.98685388, grad/param norm = 6.3612e-01, time/batch = 0.0914s	
2676/2700 (epoch 49.556), train_loss = 0.93189633, grad/param norm = 6.2462e-01, time/batch = 0.0763s	
2677/2700 (epoch 49.574), train_loss = 0.94515475, grad/param norm = 6.5654e-01, time/batch = 0.0690s	
2678/2700 (epoch 49.593), train_loss = 0.98784860, grad/param norm = 6.5091e-01, time/batch = 0.0681s	
2679/2700 (epoch 49.611), train_loss = 0.93405044, grad/param norm = 6.3674e-01, time/batch = 0.0779s	
2680/2700 (epoch 49.630), train_loss = 0.94583789, grad/param norm = 6.1740e-01, time/batch = 0.0863s	
2681/2700 (epoch 49.648), train_loss = 0.97758511, grad/param norm = 6.4218e-01, time/batch = 0.0696s	
2682/2700 (epoch 49.667), train_loss = 0.94276221, grad/param norm = 6.1715e-01, time/batch = 0.0905s	
2683/2700 (epoch 49.685), train_loss = 0.98614614, grad/param norm = 6.3950e-01, time/batch = 0.0912s	
2684/2700 (epoch 49.704), train_loss = 1.00876976, grad/param norm = 6.3581e-01, time/batch = 0.0913s	
2685/2700 (epoch 49.722), train_loss = 0.97707069, grad/param norm = 6.4136e-01, time/batch = 0.0911s	
2686/2700 (epoch 49.741), train_loss = 0.97866390, grad/param norm = 6.3302e-01, time/batch = 0.0906s	
2687/2700 (epoch 49.759), train_loss = 0.95433220, grad/param norm = 6.2137e-01, time/batch = 0.0801s	
2688/2700 (epoch 49.778), train_loss = 1.00758512, grad/param norm = 6.3474e-01, time/batch = 0.0656s	
2689/2700 (epoch 49.796), train_loss = 0.93412769, grad/param norm = 6.5134e-01, time/batch = 0.0733s	
2690/2700 (epoch 49.815), train_loss = 1.00227670, grad/param norm = 6.7085e-01, time/batch = 0.0807s	
2691/2700 (epoch 49.833), train_loss = 0.96332956, grad/param norm = 6.4992e-01, time/batch = 0.0687s	
2692/2700 (epoch 49.852), train_loss = 0.97066342, grad/param norm = 6.5201e-01, time/batch = 0.0780s	
2693/2700 (epoch 49.870), train_loss = 1.01466607, grad/param norm = 6.5193e-01, time/batch = 0.0854s	
2694/2700 (epoch 49.889), train_loss = 0.97303248, grad/param norm = 6.4450e-01, time/batch = 0.0911s	
2695/2700 (epoch 49.907), train_loss = 1.01494928, grad/param norm = 6.4365e-01, time/batch = 0.0909s	
2696/2700 (epoch 49.926), train_loss = 0.96453232, grad/param norm = 6.6318e-01, time/batch = 0.0914s	
2697/2700 (epoch 49.944), train_loss = 0.95781196, grad/param norm = 6.3012e-01, time/batch = 0.0910s	
2698/2700 (epoch 49.963), train_loss = 0.98168497, grad/param norm = 6.3752e-01, time/batch = 0.0771s	
2699/2700 (epoch 49.981), train_loss = 0.93726685, grad/param norm = 6.3759e-01, time/batch = 0.0704s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch50.00_1.9854.t7	
2700/2700 (epoch 50.000), train_loss = 1.03353846, grad/param norm = 6.5198e-01, time/batch = 0.0692s	
