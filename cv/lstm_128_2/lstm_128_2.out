using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 54, val: 3, test: 0	
vocab size: 91	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 256987	
cloning rnn	
cloning criterion	
1/2700 (epoch 0.019), train_loss = 4.52351083, grad/param norm = 6.0031e-01, time/batch = 0.2754s	
2/2700 (epoch 0.037), train_loss = 4.14079740, grad/param norm = 1.7836e+00, time/batch = 0.0803s	
3/2700 (epoch 0.056), train_loss = 3.45991099, grad/param norm = 1.0830e+00, time/batch = 0.0783s	
4/2700 (epoch 0.074), train_loss = 3.34578372, grad/param norm = 7.4523e-01, time/batch = 0.0804s	
5/2700 (epoch 0.093), train_loss = 3.32826829, grad/param norm = 7.0898e-01, time/batch = 0.0772s	
6/2700 (epoch 0.111), train_loss = 3.28265510, grad/param norm = 4.8519e-01, time/batch = 0.0759s	
7/2700 (epoch 0.130), train_loss = 3.29652324, grad/param norm = 4.1902e-01, time/batch = 0.0759s	
8/2700 (epoch 0.148), train_loss = 3.25525288, grad/param norm = 3.8805e-01, time/batch = 0.0750s	
9/2700 (epoch 0.167), train_loss = 3.26162208, grad/param norm = 4.9908e-01, time/batch = 0.0780s	
10/2700 (epoch 0.185), train_loss = 3.24640692, grad/param norm = 3.9177e-01, time/batch = 0.0747s	
11/2700 (epoch 0.204), train_loss = 3.18415438, grad/param norm = 4.4876e-01, time/batch = 0.0751s	
12/2700 (epoch 0.222), train_loss = 3.15769181, grad/param norm = 5.9446e-01, time/batch = 0.0731s	
13/2700 (epoch 0.241), train_loss = 3.17456866, grad/param norm = 3.7968e-01, time/batch = 0.0753s	
14/2700 (epoch 0.259), train_loss = 3.20419194, grad/param norm = 3.6729e-01, time/batch = 0.0750s	
15/2700 (epoch 0.278), train_loss = 3.27620499, grad/param norm = 4.0707e-01, time/batch = 0.0754s	
16/2700 (epoch 0.296), train_loss = 3.28127692, grad/param norm = 4.4238e-01, time/batch = 0.0779s	
17/2700 (epoch 0.315), train_loss = 3.25554308, grad/param norm = 4.5473e-01, time/batch = 0.0799s	
18/2700 (epoch 0.333), train_loss = 3.33876383, grad/param norm = 4.5546e-01, time/batch = 0.0820s	
19/2700 (epoch 0.352), train_loss = 3.33969264, grad/param norm = 4.9651e-01, time/batch = 0.0805s	
20/2700 (epoch 0.370), train_loss = 3.28378619, grad/param norm = 4.0663e-01, time/batch = 0.0813s	
21/2700 (epoch 0.389), train_loss = 3.25215221, grad/param norm = 2.9727e-01, time/batch = 0.0818s	
22/2700 (epoch 0.407), train_loss = 3.27582542, grad/param norm = 3.3701e-01, time/batch = 0.0800s	
23/2700 (epoch 0.426), train_loss = 3.27788714, grad/param norm = 3.2884e-01, time/batch = 0.0823s	
24/2700 (epoch 0.444), train_loss = 3.20947557, grad/param norm = 3.0708e-01, time/batch = 0.0754s	
25/2700 (epoch 0.463), train_loss = 3.24853218, grad/param norm = 3.9266e-01, time/batch = 0.0819s	
26/2700 (epoch 0.481), train_loss = 3.32605864, grad/param norm = 4.3570e-01, time/batch = 0.0779s	
27/2700 (epoch 0.500), train_loss = 3.36769505, grad/param norm = 5.5320e-01, time/batch = 0.0817s	
28/2700 (epoch 0.519), train_loss = 3.32238183, grad/param norm = 4.4924e-01, time/batch = 0.0810s	
29/2700 (epoch 0.537), train_loss = 3.32553597, grad/param norm = 4.5709e-01, time/batch = 0.0816s	
30/2700 (epoch 0.556), train_loss = 3.26112419, grad/param norm = 3.3683e-01, time/batch = 0.0782s	
31/2700 (epoch 0.574), train_loss = 3.23074701, grad/param norm = 3.8220e-01, time/batch = 0.0837s	
32/2700 (epoch 0.593), train_loss = 3.22860452, grad/param norm = 4.3275e-01, time/batch = 0.0835s	
33/2700 (epoch 0.611), train_loss = 3.17083616, grad/param norm = 2.7478e-01, time/batch = 0.0768s	
34/2700 (epoch 0.630), train_loss = 3.21178401, grad/param norm = 3.3658e-01, time/batch = 0.0755s	
35/2700 (epoch 0.648), train_loss = 3.27786610, grad/param norm = 3.6183e-01, time/batch = 0.0741s	
36/2700 (epoch 0.667), train_loss = 3.21192637, grad/param norm = 2.9446e-01, time/batch = 0.0740s	
37/2700 (epoch 0.685), train_loss = 3.21111176, grad/param norm = 3.8206e-01, time/batch = 0.0774s	
38/2700 (epoch 0.704), train_loss = 3.18233642, grad/param norm = 4.8544e-01, time/batch = 0.0757s	
39/2700 (epoch 0.722), train_loss = 3.17227198, grad/param norm = 3.6060e-01, time/batch = 0.0745s	
40/2700 (epoch 0.741), train_loss = 3.30709687, grad/param norm = 5.4462e-01, time/batch = 0.0744s	
41/2700 (epoch 0.759), train_loss = 3.25416031, grad/param norm = 5.1549e-01, time/batch = 0.0767s	
42/2700 (epoch 0.778), train_loss = 3.24578507, grad/param norm = 4.2741e-01, time/batch = 0.0795s	
43/2700 (epoch 0.796), train_loss = 3.23763133, grad/param norm = 3.9845e-01, time/batch = 0.0765s	
44/2700 (epoch 0.815), train_loss = 3.19047718, grad/param norm = 3.0874e-01, time/batch = 0.0742s	
45/2700 (epoch 0.833), train_loss = 3.22787502, grad/param norm = 3.3991e-01, time/batch = 0.0739s	
46/2700 (epoch 0.852), train_loss = 3.21567297, grad/param norm = 3.5682e-01, time/batch = 0.0748s	
47/2700 (epoch 0.870), train_loss = 3.20953888, grad/param norm = 2.4578e-01, time/batch = 0.0796s	
48/2700 (epoch 0.889), train_loss = 3.24854652, grad/param norm = 3.2216e-01, time/batch = 0.0761s	
49/2700 (epoch 0.907), train_loss = 3.29908839, grad/param norm = 4.4254e-01, time/batch = 0.0775s	
50/2700 (epoch 0.926), train_loss = 3.24867998, grad/param norm = 4.2941e-01, time/batch = 0.0756s	
51/2700 (epoch 0.944), train_loss = 3.25761040, grad/param norm = 3.8804e-01, time/batch = 0.0792s	
52/2700 (epoch 0.963), train_loss = 3.33626199, grad/param norm = 3.5697e-01, time/batch = 0.0780s	
53/2700 (epoch 0.981), train_loss = 3.39635410, grad/param norm = 4.0184e-01, time/batch = 0.0815s	
54/2700 (epoch 1.000), train_loss = 3.29681134, grad/param norm = 4.0131e-01, time/batch = 0.0820s	
55/2700 (epoch 1.019), train_loss = 3.23044239, grad/param norm = 4.4934e-01, time/batch = 0.0872s	
56/2700 (epoch 1.037), train_loss = 3.24936298, grad/param norm = 3.2632e-01, time/batch = 0.1088s	
57/2700 (epoch 1.056), train_loss = 3.25766239, grad/param norm = 3.6067e-01, time/batch = 0.1044s	
58/2700 (epoch 1.074), train_loss = 3.28656945, grad/param norm = 4.8872e-01, time/batch = 0.1372s	
59/2700 (epoch 1.093), train_loss = 3.28916285, grad/param norm = 4.7699e-01, time/batch = 0.1442s	
60/2700 (epoch 1.111), train_loss = 3.26083239, grad/param norm = 3.6371e-01, time/batch = 0.1440s	
61/2700 (epoch 1.130), train_loss = 3.27539675, grad/param norm = 3.4006e-01, time/batch = 0.1304s	
62/2700 (epoch 1.148), train_loss = 3.23970872, grad/param norm = 3.5219e-01, time/batch = 0.1411s	
63/2700 (epoch 1.167), train_loss = 3.24761015, grad/param norm = 4.3719e-01, time/batch = 0.1434s	
64/2700 (epoch 1.185), train_loss = 3.23280220, grad/param norm = 2.8865e-01, time/batch = 0.1459s	
65/2700 (epoch 1.204), train_loss = 3.17339674, grad/param norm = 4.1734e-01, time/batch = 0.1439s	
66/2700 (epoch 1.222), train_loss = 3.14546899, grad/param norm = 5.6352e-01, time/batch = 0.1357s	
67/2700 (epoch 1.241), train_loss = 3.16846737, grad/param norm = 5.7382e-01, time/batch = 0.1290s	
68/2700 (epoch 1.259), train_loss = 3.20023704, grad/param norm = 5.8357e-01, time/batch = 0.1180s	
69/2700 (epoch 1.278), train_loss = 3.26786036, grad/param norm = 4.1412e-01, time/batch = 0.1186s	
70/2700 (epoch 1.296), train_loss = 3.26773587, grad/param norm = 3.5594e-01, time/batch = 0.1243s	
71/2700 (epoch 1.315), train_loss = 3.24429337, grad/param norm = 3.1741e-01, time/batch = 0.1175s	
72/2700 (epoch 1.333), train_loss = 3.32292652, grad/param norm = 3.2541e-01, time/batch = 0.1192s	
73/2700 (epoch 1.352), train_loss = 3.32579639, grad/param norm = 4.1540e-01, time/batch = 0.1265s	
74/2700 (epoch 1.370), train_loss = 3.27253036, grad/param norm = 4.3160e-01, time/batch = 0.1361s	
75/2700 (epoch 1.389), train_loss = 3.24466326, grad/param norm = 3.5021e-01, time/batch = 0.1454s	
76/2700 (epoch 1.407), train_loss = 3.26608898, grad/param norm = 4.1341e-01, time/batch = 0.1437s	
77/2700 (epoch 1.426), train_loss = 3.26284325, grad/param norm = 3.2175e-01, time/batch = 0.1335s	
78/2700 (epoch 1.444), train_loss = 3.19238342, grad/param norm = 3.0029e-01, time/batch = 0.1258s	
79/2700 (epoch 1.463), train_loss = 3.23233489, grad/param norm = 4.4549e-01, time/batch = 0.1178s	
80/2700 (epoch 1.481), train_loss = 3.30675205, grad/param norm = 5.2100e-01, time/batch = 0.1191s	
81/2700 (epoch 1.500), train_loss = 3.34480527, grad/param norm = 6.3184e-01, time/batch = 0.1360s	
82/2700 (epoch 1.519), train_loss = 3.30892609, grad/param norm = 5.9131e-01, time/batch = 0.1197s	
83/2700 (epoch 1.537), train_loss = 3.31429241, grad/param norm = 5.2961e-01, time/batch = 0.1200s	
84/2700 (epoch 1.556), train_loss = 3.24385647, grad/param norm = 3.9144e-01, time/batch = 0.1212s	
85/2700 (epoch 1.574), train_loss = 3.20204870, grad/param norm = 3.5996e-01, time/batch = 0.1320s	
86/2700 (epoch 1.593), train_loss = 3.19373888, grad/param norm = 3.4445e-01, time/batch = 0.1412s	
87/2700 (epoch 1.611), train_loss = 3.13766510, grad/param norm = 3.7856e-01, time/batch = 0.1429s	
88/2700 (epoch 1.630), train_loss = 3.18127835, grad/param norm = 4.9351e-01, time/batch = 0.1324s	
89/2700 (epoch 1.648), train_loss = 3.23436566, grad/param norm = 5.2566e-01, time/batch = 0.1286s	
90/2700 (epoch 1.667), train_loss = 3.17637856, grad/param norm = 4.9299e-01, time/batch = 0.1172s	
91/2700 (epoch 1.685), train_loss = 3.17741140, grad/param norm = 7.1153e-01, time/batch = 0.1460s	
92/2700 (epoch 1.704), train_loss = 3.13445565, grad/param norm = 6.2023e-01, time/batch = 0.1438s	
93/2700 (epoch 1.722), train_loss = 3.11121640, grad/param norm = 5.5281e-01, time/batch = 0.1371s	
94/2700 (epoch 1.741), train_loss = 3.25295725, grad/param norm = 6.6782e-01, time/batch = 0.1295s	
95/2700 (epoch 1.759), train_loss = 3.18555251, grad/param norm = 5.9480e-01, time/batch = 0.1155s	
96/2700 (epoch 1.778), train_loss = 3.15548572, grad/param norm = 4.2940e-01, time/batch = 0.1202s	
97/2700 (epoch 1.796), train_loss = 3.14979997, grad/param norm = 5.2967e-01, time/batch = 0.1235s	
98/2700 (epoch 1.815), train_loss = 3.12533247, grad/param norm = 8.3836e-01, time/batch = 0.1330s	
99/2700 (epoch 1.833), train_loss = 3.14097847, grad/param norm = 8.0646e-01, time/batch = 0.1301s	
100/2700 (epoch 1.852), train_loss = 3.09256492, grad/param norm = 4.8410e-01, time/batch = 0.1335s	
101/2700 (epoch 1.870), train_loss = 3.06153424, grad/param norm = 4.1421e-01, time/batch = 0.1471s	
102/2700 (epoch 1.889), train_loss = 3.11295233, grad/param norm = 7.1661e-01, time/batch = 0.1456s	
103/2700 (epoch 1.907), train_loss = 3.16141951, grad/param norm = 7.5472e-01, time/batch = 0.1439s	
104/2700 (epoch 1.926), train_loss = 3.08644708, grad/param norm = 6.2137e-01, time/batch = 0.1453s	
105/2700 (epoch 1.944), train_loss = 3.09518096, grad/param norm = 5.3094e-01, time/batch = 0.1436s	
106/2700 (epoch 1.963), train_loss = 3.13945458, grad/param norm = 4.5705e-01, time/batch = 0.1462s	
107/2700 (epoch 1.981), train_loss = 3.18286721, grad/param norm = 5.6674e-01, time/batch = 0.1421s	
108/2700 (epoch 2.000), train_loss = 3.37766277, grad/param norm = 1.4338e+00, time/batch = 0.1365s	
109/2700 (epoch 2.019), train_loss = 3.03771693, grad/param norm = 3.6310e-01, time/batch = 0.1205s	
110/2700 (epoch 2.037), train_loss = 3.03250128, grad/param norm = 4.2413e-01, time/batch = 0.0875s	
111/2700 (epoch 2.056), train_loss = 3.01613695, grad/param norm = 6.1243e-01, time/batch = 0.1480s	
112/2700 (epoch 2.074), train_loss = 3.07011642, grad/param norm = 6.4695e-01, time/batch = 0.1444s	
113/2700 (epoch 2.093), train_loss = 3.04471037, grad/param norm = 5.8573e-01, time/batch = 0.1438s	
114/2700 (epoch 2.111), train_loss = 3.00214610, grad/param norm = 5.5823e-01, time/batch = 0.1452s	
115/2700 (epoch 2.130), train_loss = 3.02471188, grad/param norm = 8.0050e-01, time/batch = 0.1451s	
116/2700 (epoch 2.148), train_loss = 3.00853248, grad/param norm = 1.1837e+00, time/batch = 0.1439s	
117/2700 (epoch 2.167), train_loss = 2.99608930, grad/param norm = 8.2451e-01, time/batch = 0.1450s	
118/2700 (epoch 2.185), train_loss = 2.92386806, grad/param norm = 3.6887e-01, time/batch = 0.1425s	
119/2700 (epoch 2.204), train_loss = 2.85724450, grad/param norm = 3.3167e-01, time/batch = 0.1367s	
120/2700 (epoch 2.222), train_loss = 2.80246420, grad/param norm = 3.9075e-01, time/batch = 0.1258s	
121/2700 (epoch 2.241), train_loss = 2.84944093, grad/param norm = 5.9033e-01, time/batch = 0.0929s	
122/2700 (epoch 2.259), train_loss = 2.89522248, grad/param norm = 1.0998e+00, time/batch = 0.1447s	
123/2700 (epoch 2.278), train_loss = 2.99135855, grad/param norm = 8.4396e-01, time/batch = 0.1464s	
124/2700 (epoch 2.296), train_loss = 2.91423578, grad/param norm = 5.5091e-01, time/batch = 0.1438s	
125/2700 (epoch 2.315), train_loss = 2.92171591, grad/param norm = 5.8764e-01, time/batch = 0.1450s	
126/2700 (epoch 2.333), train_loss = 2.95019075, grad/param norm = 7.0622e-01, time/batch = 0.1435s	
127/2700 (epoch 2.352), train_loss = 2.98660688, grad/param norm = 6.8081e-01, time/batch = 0.1441s	
128/2700 (epoch 2.370), train_loss = 2.90900525, grad/param norm = 5.9317e-01, time/batch = 0.1369s	
129/2700 (epoch 2.389), train_loss = 2.85466317, grad/param norm = 5.2974e-01, time/batch = 0.1436s	
130/2700 (epoch 2.407), train_loss = 2.86226820, grad/param norm = 6.2881e-01, time/batch = 0.1503s	
131/2700 (epoch 2.426), train_loss = 2.92211202, grad/param norm = 9.5022e-01, time/batch = 0.1581s	
132/2700 (epoch 2.444), train_loss = 2.83394842, grad/param norm = 8.8836e-01, time/batch = 0.1556s	
133/2700 (epoch 2.463), train_loss = 2.84019391, grad/param norm = 4.1907e-01, time/batch = 0.1857s	
134/2700 (epoch 2.481), train_loss = 2.89021574, grad/param norm = 3.1818e-01, time/batch = 0.1793s	
135/2700 (epoch 2.500), train_loss = 2.92475793, grad/param norm = 7.4893e-01, time/batch = 0.1703s	
136/2700 (epoch 2.519), train_loss = 3.00043238, grad/param norm = 1.9915e+00, time/batch = 0.1630s	
137/2700 (epoch 2.537), train_loss = 2.97776140, grad/param norm = 1.1160e+00, time/batch = 0.1616s	
138/2700 (epoch 2.556), train_loss = 2.82784937, grad/param norm = 3.1503e-01, time/batch = 0.1600s	
139/2700 (epoch 2.574), train_loss = 2.77809878, grad/param norm = 3.8782e-01, time/batch = 0.1624s	
140/2700 (epoch 2.593), train_loss = 2.76169426, grad/param norm = 3.9276e-01, time/batch = 0.1471s	
141/2700 (epoch 2.611), train_loss = 2.71872458, grad/param norm = 5.7707e-01, time/batch = 0.1754s	
142/2700 (epoch 2.630), train_loss = 2.77386792, grad/param norm = 7.5404e-01, time/batch = 0.1773s	
143/2700 (epoch 2.648), train_loss = 2.78992489, grad/param norm = 6.3201e-01, time/batch = 0.1780s	
144/2700 (epoch 2.667), train_loss = 2.71041422, grad/param norm = 5.2870e-01, time/batch = 0.1545s	
145/2700 (epoch 2.685), train_loss = 2.73672678, grad/param norm = 4.7937e-01, time/batch = 0.1520s	
146/2700 (epoch 2.704), train_loss = 2.69552685, grad/param norm = 5.8299e-01, time/batch = 0.1527s	
147/2700 (epoch 2.722), train_loss = 2.70033905, grad/param norm = 7.4899e-01, time/batch = 0.1498s	
148/2700 (epoch 2.741), train_loss = 2.88621387, grad/param norm = 8.9252e-01, time/batch = 0.1521s	
149/2700 (epoch 2.759), train_loss = 2.80975321, grad/param norm = 6.6608e-01, time/batch = 0.1519s	
150/2700 (epoch 2.778), train_loss = 2.75244114, grad/param norm = 3.6815e-01, time/batch = 0.1524s	
151/2700 (epoch 2.796), train_loss = 2.74175013, grad/param norm = 3.3964e-01, time/batch = 0.1361s	
152/2700 (epoch 2.815), train_loss = 2.70022430, grad/param norm = 3.6451e-01, time/batch = 0.1530s	
153/2700 (epoch 2.833), train_loss = 2.71623264, grad/param norm = 5.2424e-01, time/batch = 0.1536s	
154/2700 (epoch 2.852), train_loss = 2.74749095, grad/param norm = 6.2902e-01, time/batch = 0.1500s	
155/2700 (epoch 2.870), train_loss = 2.71798539, grad/param norm = 7.2115e-01, time/batch = 0.1513s	
156/2700 (epoch 2.889), train_loss = 2.74802510, grad/param norm = 7.5045e-01, time/batch = 0.1519s	
157/2700 (epoch 2.907), train_loss = 2.81840318, grad/param norm = 7.5150e-01, time/batch = 0.1505s	
158/2700 (epoch 2.926), train_loss = 2.74871423, grad/param norm = 7.0630e-01, time/batch = 0.1542s	
159/2700 (epoch 2.944), train_loss = 2.76842622, grad/param norm = 9.2062e-01, time/batch = 0.1532s	
160/2700 (epoch 2.963), train_loss = 2.87422377, grad/param norm = 1.0901e+00, time/batch = 0.1531s	
161/2700 (epoch 2.981), train_loss = 2.84926138, grad/param norm = 9.1402e-01, time/batch = 0.1393s	
162/2700 (epoch 3.000), train_loss = 2.78608155, grad/param norm = 5.8821e-01, time/batch = 0.1603s	
163/2700 (epoch 3.019), train_loss = 2.71304723, grad/param norm = 4.5280e-01, time/batch = 0.1691s	
164/2700 (epoch 3.037), train_loss = 2.76447245, grad/param norm = 4.2366e-01, time/batch = 0.1697s	
165/2700 (epoch 3.056), train_loss = 2.71172415, grad/param norm = 4.8508e-01, time/batch = 0.2034s	
166/2700 (epoch 3.074), train_loss = 2.74259489, grad/param norm = 6.7174e-01, time/batch = 0.1782s	
167/2700 (epoch 3.093), train_loss = 2.75896892, grad/param norm = 6.8425e-01, time/batch = 0.2292s	
168/2700 (epoch 3.111), train_loss = 2.72162620, grad/param norm = 4.8437e-01, time/batch = 0.2072s	
169/2700 (epoch 3.130), train_loss = 2.72165457, grad/param norm = 2.8806e-01, time/batch = 0.1938s	
170/2700 (epoch 3.148), train_loss = 2.66046926, grad/param norm = 2.5290e-01, time/batch = 0.2409s	
171/2700 (epoch 3.167), train_loss = 2.68441581, grad/param norm = 3.6339e-01, time/batch = 0.1906s	
172/2700 (epoch 3.185), train_loss = 2.64595020, grad/param norm = 4.8194e-01, time/batch = 0.2133s	
173/2700 (epoch 3.204), train_loss = 2.62933127, grad/param norm = 6.9624e-01, time/batch = 0.2153s	
174/2700 (epoch 3.222), train_loss = 2.62286230, grad/param norm = 1.1316e+00, time/batch = 0.2448s	
175/2700 (epoch 3.241), train_loss = 2.67898302, grad/param norm = 1.0121e+00, time/batch = 0.2220s	
176/2700 (epoch 3.259), train_loss = 2.63552406, grad/param norm = 6.6896e-01, time/batch = 0.2013s	
177/2700 (epoch 3.278), train_loss = 2.68911016, grad/param norm = 5.4714e-01, time/batch = 0.2282s	
178/2700 (epoch 3.296), train_loss = 2.67281808, grad/param norm = 5.8227e-01, time/batch = 0.2383s	
179/2700 (epoch 3.315), train_loss = 2.72940908, grad/param norm = 5.6783e-01, time/batch = 0.1778s	
180/2700 (epoch 3.333), train_loss = 2.70985919, grad/param norm = 6.0820e-01, time/batch = 0.2292s	
181/2700 (epoch 3.352), train_loss = 2.78313015, grad/param norm = 9.2550e-01, time/batch = 0.1879s	
182/2700 (epoch 3.370), train_loss = 2.75756805, grad/param norm = 1.1135e+00, time/batch = 0.2055s	
183/2700 (epoch 3.389), train_loss = 2.69668958, grad/param norm = 7.4835e-01, time/batch = 0.2282s	
184/2700 (epoch 3.407), train_loss = 2.65001122, grad/param norm = 4.0541e-01, time/batch = 0.2431s	
185/2700 (epoch 3.426), train_loss = 2.67038803, grad/param norm = 2.6255e-01, time/batch = 0.2364s	
186/2700 (epoch 3.444), train_loss = 2.57167284, grad/param norm = 2.8043e-01, time/batch = 0.2010s	
187/2700 (epoch 3.463), train_loss = 2.65680368, grad/param norm = 3.5048e-01, time/batch = 0.2103s	
188/2700 (epoch 3.481), train_loss = 2.70427283, grad/param norm = 3.7095e-01, time/batch = 0.2332s	
189/2700 (epoch 3.500), train_loss = 2.72610170, grad/param norm = 3.7765e-01, time/batch = 0.2212s	
190/2700 (epoch 3.519), train_loss = 2.65725229, grad/param norm = 3.5834e-01, time/batch = 0.2280s	
191/2700 (epoch 3.537), train_loss = 2.64201163, grad/param norm = 3.3469e-01, time/batch = 0.2126s	
192/2700 (epoch 3.556), train_loss = 2.63365888, grad/param norm = 4.1061e-01, time/batch = 0.1825s	
193/2700 (epoch 3.574), train_loss = 2.60517377, grad/param norm = 7.6339e-01, time/batch = 0.2082s	
194/2700 (epoch 3.593), train_loss = 2.65023932, grad/param norm = 1.0174e+00, time/batch = 0.2327s	
195/2700 (epoch 3.611), train_loss = 2.59965040, grad/param norm = 1.0484e+00, time/batch = 0.2629s	
196/2700 (epoch 3.630), train_loss = 2.61891547, grad/param norm = 6.9220e-01, time/batch = 0.2740s	
197/2700 (epoch 3.648), train_loss = 2.60862762, grad/param norm = 4.5984e-01, time/batch = 0.2682s	
198/2700 (epoch 3.667), train_loss = 2.53541000, grad/param norm = 5.1242e-01, time/batch = 0.2645s	
199/2700 (epoch 3.685), train_loss = 2.62022313, grad/param norm = 8.3290e-01, time/batch = 0.2608s	
200/2700 (epoch 3.704), train_loss = 2.61781074, grad/param norm = 8.0993e-01, time/batch = 0.2430s	
201/2700 (epoch 3.722), train_loss = 2.56570999, grad/param norm = 5.3134e-01, time/batch = 0.2396s	
202/2700 (epoch 3.741), train_loss = 2.73174704, grad/param norm = 5.2542e-01, time/batch = 0.2101s	
203/2700 (epoch 3.759), train_loss = 2.65726016, grad/param norm = 5.3864e-01, time/batch = 0.1922s	
204/2700 (epoch 3.778), train_loss = 2.62436977, grad/param norm = 4.0482e-01, time/batch = 0.2146s	
205/2700 (epoch 3.796), train_loss = 2.59432954, grad/param norm = 3.1599e-01, time/batch = 0.1920s	
206/2700 (epoch 3.815), train_loss = 2.56640213, grad/param norm = 2.7633e-01, time/batch = 0.2465s	
207/2700 (epoch 3.833), train_loss = 2.56668933, grad/param norm = 4.3772e-01, time/batch = 0.2750s	
208/2700 (epoch 3.852), train_loss = 2.61274515, grad/param norm = 6.6825e-01, time/batch = 0.2834s	
209/2700 (epoch 3.870), train_loss = 2.60890387, grad/param norm = 9.3770e-01, time/batch = 0.3358s	
210/2700 (epoch 3.889), train_loss = 2.62101575, grad/param norm = 7.1599e-01, time/batch = 0.3353s	
211/2700 (epoch 3.907), train_loss = 2.67941323, grad/param norm = 3.5173e-01, time/batch = 0.3098s	
212/2700 (epoch 3.926), train_loss = 2.59743393, grad/param norm = 3.1221e-01, time/batch = 0.3096s	
213/2700 (epoch 3.944), train_loss = 2.61316226, grad/param norm = 3.5671e-01, time/batch = 0.2673s	
214/2700 (epoch 3.963), train_loss = 2.69087876, grad/param norm = 5.4256e-01, time/batch = 0.2795s	
215/2700 (epoch 3.981), train_loss = 2.68663656, grad/param norm = 6.1759e-01, time/batch = 0.2919s	
216/2700 (epoch 4.000), train_loss = 2.68052147, grad/param norm = 6.3527e-01, time/batch = 0.2936s	
217/2700 (epoch 4.019), train_loss = 2.59699558, grad/param norm = 3.6917e-01, time/batch = 0.2679s	
218/2700 (epoch 4.037), train_loss = 2.64520200, grad/param norm = 3.0656e-01, time/batch = 0.2916s	
219/2700 (epoch 4.056), train_loss = 2.59399015, grad/param norm = 3.9945e-01, time/batch = 0.2868s	
220/2700 (epoch 4.074), train_loss = 2.60745486, grad/param norm = 4.4984e-01, time/batch = 0.2971s	
221/2700 (epoch 4.093), train_loss = 2.62243275, grad/param norm = 4.2591e-01, time/batch = 0.3106s	
222/2700 (epoch 4.111), train_loss = 2.59653753, grad/param norm = 4.3184e-01, time/batch = 0.3048s	
223/2700 (epoch 4.130), train_loss = 2.61187166, grad/param norm = 5.2121e-01, time/batch = 0.2900s	
224/2700 (epoch 4.148), train_loss = 2.58784820, grad/param norm = 9.6297e-01, time/batch = 0.2777s	
225/2700 (epoch 4.167), train_loss = 2.65627154, grad/param norm = 9.4204e-01, time/batch = 0.2621s	
226/2700 (epoch 4.185), train_loss = 2.57165492, grad/param norm = 6.2231e-01, time/batch = 0.2588s	
227/2700 (epoch 4.204), train_loss = 2.52123115, grad/param norm = 3.4583e-01, time/batch = 0.2975s	
228/2700 (epoch 4.222), train_loss = 2.46418341, grad/param norm = 2.7228e-01, time/batch = 0.3006s	
229/2700 (epoch 4.241), train_loss = 2.47361429, grad/param norm = 2.3510e-01, time/batch = 0.2650s	
230/2700 (epoch 4.259), train_loss = 2.49185355, grad/param norm = 2.8011e-01, time/batch = 0.2845s	
231/2700 (epoch 4.278), train_loss = 2.57513115, grad/param norm = 3.6804e-01, time/batch = 0.2842s	
232/2700 (epoch 4.296), train_loss = 2.55670415, grad/param norm = 3.8155e-01, time/batch = 0.3110s	
233/2700 (epoch 4.315), train_loss = 2.58861048, grad/param norm = 3.2197e-01, time/batch = 0.3049s	
234/2700 (epoch 4.333), train_loss = 2.57407611, grad/param norm = 2.8171e-01, time/batch = 0.2980s	
235/2700 (epoch 4.352), train_loss = 2.62914093, grad/param norm = 3.7652e-01, time/batch = 0.2955s	
236/2700 (epoch 4.370), train_loss = 2.59134714, grad/param norm = 4.7616e-01, time/batch = 0.2876s	
237/2700 (epoch 4.389), train_loss = 2.55612203, grad/param norm = 4.5131e-01, time/batch = 0.2620s	
238/2700 (epoch 4.407), train_loss = 2.53199644, grad/param norm = 3.8608e-01, time/batch = 0.2679s	
239/2700 (epoch 4.426), train_loss = 2.57704762, grad/param norm = 5.7383e-01, time/batch = 0.3052s	
240/2700 (epoch 4.444), train_loss = 2.52382586, grad/param norm = 9.2087e-01, time/batch = 0.2907s	
241/2700 (epoch 4.463), train_loss = 2.62272311, grad/param norm = 9.3366e-01, time/batch = 0.2903s	
242/2700 (epoch 4.481), train_loss = 2.68186635, grad/param norm = 1.1074e+00, time/batch = 0.2682s	
243/2700 (epoch 4.500), train_loss = 2.66970222, grad/param norm = 4.9334e-01, time/batch = 0.2727s	
244/2700 (epoch 4.519), train_loss = 2.55677035, grad/param norm = 3.0257e-01, time/batch = 0.2991s	
245/2700 (epoch 4.537), train_loss = 2.54601351, grad/param norm = 2.5876e-01, time/batch = 0.2936s	
246/2700 (epoch 4.556), train_loss = 2.53093402, grad/param norm = 2.6166e-01, time/batch = 0.2935s	
247/2700 (epoch 4.574), train_loss = 2.49240166, grad/param norm = 2.8717e-01, time/batch = 0.2966s	
248/2700 (epoch 4.593), train_loss = 2.48061691, grad/param norm = 3.1094e-01, time/batch = 0.2952s	
249/2700 (epoch 4.611), train_loss = 2.43451744, grad/param norm = 3.9628e-01, time/batch = 0.2618s	
250/2700 (epoch 4.630), train_loss = 2.48875794, grad/param norm = 4.8847e-01, time/batch = 0.2784s	
251/2700 (epoch 4.648), train_loss = 2.51321121, grad/param norm = 4.3689e-01, time/batch = 0.2631s	
252/2700 (epoch 4.667), train_loss = 2.42543891, grad/param norm = 3.0640e-01, time/batch = 0.2799s	
253/2700 (epoch 4.685), train_loss = 2.48062805, grad/param norm = 2.4145e-01, time/batch = 0.2942s	
254/2700 (epoch 4.704), train_loss = 2.46965122, grad/param norm = 2.2445e-01, time/batch = 0.2720s	
255/2700 (epoch 4.722), train_loss = 2.44879560, grad/param norm = 2.6746e-01, time/batch = 0.2578s	
256/2700 (epoch 4.741), train_loss = 2.62669285, grad/param norm = 5.4634e-01, time/batch = 0.2977s	
257/2700 (epoch 4.759), train_loss = 2.58228666, grad/param norm = 8.3326e-01, time/batch = 0.3046s	
258/2700 (epoch 4.778), train_loss = 2.57159793, grad/param norm = 7.5904e-01, time/batch = 0.2760s	
259/2700 (epoch 4.796), train_loss = 2.53440953, grad/param norm = 6.1819e-01, time/batch = 0.2781s	
260/2700 (epoch 4.815), train_loss = 2.49415460, grad/param norm = 3.8011e-01, time/batch = 0.2623s	
261/2700 (epoch 4.833), train_loss = 2.47036814, grad/param norm = 3.4986e-01, time/batch = 0.2623s	
262/2700 (epoch 4.852), train_loss = 2.50565891, grad/param norm = 3.6113e-01, time/batch = 0.2811s	
263/2700 (epoch 4.870), train_loss = 2.47642023, grad/param norm = 3.4307e-01, time/batch = 0.3106s	
264/2700 (epoch 4.889), train_loss = 2.48162314, grad/param norm = 3.2056e-01, time/batch = 0.2998s	
265/2700 (epoch 4.907), train_loss = 2.58706998, grad/param norm = 3.1364e-01, time/batch = 0.2948s	
266/2700 (epoch 4.926), train_loss = 2.51796632, grad/param norm = 3.3832e-01, time/batch = 0.2570s	
267/2700 (epoch 4.944), train_loss = 2.51795706, grad/param norm = 2.8000e-01, time/batch = 0.2774s	
268/2700 (epoch 4.963), train_loss = 2.57344412, grad/param norm = 2.8004e-01, time/batch = 0.3042s	
269/2700 (epoch 4.981), train_loss = 2.54792561, grad/param norm = 3.1323e-01, time/batch = 0.2729s	
270/2700 (epoch 5.000), train_loss = 2.55033431, grad/param norm = 3.0430e-01, time/batch = 0.2913s	
271/2700 (epoch 5.019), train_loss = 2.50889245, grad/param norm = 3.6793e-01, time/batch = 0.2746s	
272/2700 (epoch 5.037), train_loss = 2.55320947, grad/param norm = 4.6208e-01, time/batch = 0.2673s	
273/2700 (epoch 5.056), train_loss = 2.50949413, grad/param norm = 5.4182e-01, time/batch = 0.2825s	
274/2700 (epoch 5.074), train_loss = 2.51891983, grad/param norm = 6.1363e-01, time/batch = 0.3158s	
275/2700 (epoch 5.093), train_loss = 2.56541067, grad/param norm = 7.5678e-01, time/batch = 0.3291s	
276/2700 (epoch 5.111), train_loss = 2.53130644, grad/param norm = 5.7622e-01, time/batch = 0.3093s	
277/2700 (epoch 5.130), train_loss = 2.51579644, grad/param norm = 3.3853e-01, time/batch = 0.2985s	
278/2700 (epoch 5.148), train_loss = 2.46765597, grad/param norm = 4.5376e-01, time/batch = 0.2652s	
279/2700 (epoch 5.167), train_loss = 2.51880965, grad/param norm = 4.2488e-01, time/batch = 0.2626s	
280/2700 (epoch 5.185), train_loss = 2.44950821, grad/param norm = 3.1195e-01, time/batch = 0.2681s	
281/2700 (epoch 5.204), train_loss = 2.43712206, grad/param norm = 3.2618e-01, time/batch = 0.2708s	
282/2700 (epoch 5.222), train_loss = 2.37996366, grad/param norm = 3.1745e-01, time/batch = 0.2663s	
283/2700 (epoch 5.241), train_loss = 2.37413268, grad/param norm = 2.7597e-01, time/batch = 0.2673s	
284/2700 (epoch 5.259), train_loss = 2.40567908, grad/param norm = 3.7776e-01, time/batch = 0.2777s	
285/2700 (epoch 5.278), train_loss = 2.50555840, grad/param norm = 5.2069e-01, time/batch = 0.3135s	
286/2700 (epoch 5.296), train_loss = 2.48859084, grad/param norm = 4.6001e-01, time/batch = 0.3333s	
287/2700 (epoch 5.315), train_loss = 2.49493171, grad/param norm = 2.8096e-01, time/batch = 0.3333s	
288/2700 (epoch 5.333), train_loss = 2.47361893, grad/param norm = 2.4598e-01, time/batch = 0.3167s	
289/2700 (epoch 5.352), train_loss = 2.51313764, grad/param norm = 3.0811e-01, time/batch = 0.3172s	
290/2700 (epoch 5.370), train_loss = 2.48063752, grad/param norm = 4.1078e-01, time/batch = 0.2778s	
291/2700 (epoch 5.389), train_loss = 2.46419343, grad/param norm = 5.6944e-01, time/batch = 0.3255s	
292/2700 (epoch 5.407), train_loss = 2.46889820, grad/param norm = 5.9953e-01, time/batch = 0.3023s	
293/2700 (epoch 5.426), train_loss = 2.51468913, grad/param norm = 5.7837e-01, time/batch = 0.2908s	
294/2700 (epoch 5.444), train_loss = 2.40448616, grad/param norm = 4.5906e-01, time/batch = 0.2948s	
295/2700 (epoch 5.463), train_loss = 2.46162018, grad/param norm = 3.3682e-01, time/batch = 0.2447s	
296/2700 (epoch 5.481), train_loss = 2.49597185, grad/param norm = 2.5002e-01, time/batch = 0.2809s	
297/2700 (epoch 5.500), train_loss = 2.49944252, grad/param norm = 2.4045e-01, time/batch = 0.2665s	
298/2700 (epoch 5.519), train_loss = 2.43802729, grad/param norm = 2.9060e-01, time/batch = 0.2943s	
299/2700 (epoch 5.537), train_loss = 2.45883359, grad/param norm = 3.6341e-01, time/batch = 0.3210s	
300/2700 (epoch 5.556), train_loss = 2.43814668, grad/param norm = 3.2732e-01, time/batch = 0.3151s	
301/2700 (epoch 5.574), train_loss = 2.40066418, grad/param norm = 2.8993e-01, time/batch = 0.2963s	
302/2700 (epoch 5.593), train_loss = 2.38624914, grad/param norm = 2.8623e-01, time/batch = 0.3194s	
303/2700 (epoch 5.611), train_loss = 2.33263709, grad/param norm = 3.7285e-01, time/batch = 0.2975s	
304/2700 (epoch 5.630), train_loss = 2.39727105, grad/param norm = 6.3657e-01, time/batch = 0.3011s	
305/2700 (epoch 5.648), train_loss = 2.46374061, grad/param norm = 7.2272e-01, time/batch = 0.3124s	
306/2700 (epoch 5.667), train_loss = 2.40474064, grad/param norm = 6.6732e-01, time/batch = 0.3161s	
307/2700 (epoch 5.685), train_loss = 2.43748852, grad/param norm = 4.8741e-01, time/batch = 0.3072s	
308/2700 (epoch 5.704), train_loss = 2.40667907, grad/param norm = 3.2450e-01, time/batch = 0.2872s	
309/2700 (epoch 5.722), train_loss = 2.36817274, grad/param norm = 1.8474e-01, time/batch = 0.2810s	
310/2700 (epoch 5.741), train_loss = 2.49414705, grad/param norm = 1.8544e-01, time/batch = 0.2551s	
311/2700 (epoch 5.759), train_loss = 2.45215529, grad/param norm = 2.9332e-01, time/batch = 0.2581s	
312/2700 (epoch 5.778), train_loss = 2.44003016, grad/param norm = 3.5227e-01, time/batch = 0.2448s	
313/2700 (epoch 5.796), train_loss = 2.42852288, grad/param norm = 3.9764e-01, time/batch = 0.2834s	
314/2700 (epoch 5.815), train_loss = 2.40866894, grad/param norm = 3.1452e-01, time/batch = 0.2931s	
315/2700 (epoch 5.833), train_loss = 2.37040618, grad/param norm = 2.2296e-01, time/batch = 0.3171s	
316/2700 (epoch 5.852), train_loss = 2.39921940, grad/param norm = 1.8089e-01, time/batch = 0.3243s	
317/2700 (epoch 5.870), train_loss = 2.37080329, grad/param norm = 2.8434e-01, time/batch = 0.3298s	
318/2700 (epoch 5.889), train_loss = 2.38789529, grad/param norm = 4.9014e-01, time/batch = 0.3227s	
319/2700 (epoch 5.907), train_loss = 2.53566632, grad/param norm = 7.2110e-01, time/batch = 0.3081s	
320/2700 (epoch 5.926), train_loss = 2.48215778, grad/param norm = 6.1654e-01, time/batch = 0.2942s	
321/2700 (epoch 5.944), train_loss = 2.45059548, grad/param norm = 4.4904e-01, time/batch = 0.3354s	
322/2700 (epoch 5.963), train_loss = 2.48405389, grad/param norm = 3.1617e-01, time/batch = 0.3273s	
323/2700 (epoch 5.981), train_loss = 2.43811390, grad/param norm = 2.7844e-01, time/batch = 0.3287s	
324/2700 (epoch 6.000), train_loss = 2.45001744, grad/param norm = 2.0839e-01, time/batch = 0.2639s	
325/2700 (epoch 6.019), train_loss = 2.42762738, grad/param norm = 2.6938e-01, time/batch = 0.3234s	
326/2700 (epoch 6.037), train_loss = 2.46607624, grad/param norm = 3.4009e-01, time/batch = 0.3150s	
327/2700 (epoch 6.056), train_loss = 2.41862853, grad/param norm = 4.5091e-01, time/batch = 0.2546s	
328/2700 (epoch 6.074), train_loss = 2.41273911, grad/param norm = 4.9869e-01, time/batch = 0.2634s	
329/2700 (epoch 6.093), train_loss = 2.42611476, grad/param norm = 4.0638e-01, time/batch = 0.2721s	
330/2700 (epoch 6.111), train_loss = 2.38259913, grad/param norm = 2.8474e-01, time/batch = 0.3046s	
331/2700 (epoch 6.130), train_loss = 2.41193441, grad/param norm = 2.2233e-01, time/batch = 0.2868s	
332/2700 (epoch 6.148), train_loss = 2.35594956, grad/param norm = 2.0612e-01, time/batch = 0.3056s	
333/2700 (epoch 6.167), train_loss = 2.40809900, grad/param norm = 2.3098e-01, time/batch = 0.3019s	
334/2700 (epoch 6.185), train_loss = 2.34948938, grad/param norm = 2.4830e-01, time/batch = 0.3314s	
335/2700 (epoch 6.204), train_loss = 2.35408374, grad/param norm = 3.7958e-01, time/batch = 0.3103s	
336/2700 (epoch 6.222), train_loss = 2.31896829, grad/param norm = 6.0426e-01, time/batch = 0.2618s	
337/2700 (epoch 6.241), train_loss = 2.32726802, grad/param norm = 6.6470e-01, time/batch = 0.3339s	
338/2700 (epoch 6.259), train_loss = 2.33376083, grad/param norm = 5.1927e-01, time/batch = 0.3075s	
339/2700 (epoch 6.278), train_loss = 2.40375161, grad/param norm = 3.5500e-01, time/batch = 0.2921s	
340/2700 (epoch 6.296), train_loss = 2.37270684, grad/param norm = 2.5461e-01, time/batch = 0.2645s	
341/2700 (epoch 6.315), train_loss = 2.38303915, grad/param norm = 2.3998e-01, time/batch = 0.2585s	
342/2700 (epoch 6.333), train_loss = 2.37998259, grad/param norm = 2.5113e-01, time/batch = 0.2517s	
343/2700 (epoch 6.352), train_loss = 2.41457396, grad/param norm = 2.6253e-01, time/batch = 0.2958s	
344/2700 (epoch 6.370), train_loss = 2.38103781, grad/param norm = 2.5671e-01, time/batch = 0.3067s	
345/2700 (epoch 6.389), train_loss = 2.35584898, grad/param norm = 2.2081e-01, time/batch = 0.3347s	
346/2700 (epoch 6.407), train_loss = 2.34485452, grad/param norm = 1.7052e-01, time/batch = 0.3215s	
347/2700 (epoch 6.426), train_loss = 2.38354056, grad/param norm = 1.9441e-01, time/batch = 0.3069s	
348/2700 (epoch 6.444), train_loss = 2.29614681, grad/param norm = 2.9632e-01, time/batch = 0.2733s	
349/2700 (epoch 6.463), train_loss = 2.39267676, grad/param norm = 5.6317e-01, time/batch = 0.3273s	
350/2700 (epoch 6.481), train_loss = 2.44989641, grad/param norm = 6.1594e-01, time/batch = 0.3131s	
351/2700 (epoch 6.500), train_loss = 2.43912612, grad/param norm = 4.4431e-01, time/batch = 0.3357s	
352/2700 (epoch 6.519), train_loss = 2.35923098, grad/param norm = 3.1362e-01, time/batch = 0.3344s	
353/2700 (epoch 6.537), train_loss = 2.37014094, grad/param norm = 3.3132e-01, time/batch = 0.3395s	
354/2700 (epoch 6.556), train_loss = 2.35782335, grad/param norm = 3.5466e-01, time/batch = 0.3301s	
355/2700 (epoch 6.574), train_loss = 2.33016443, grad/param norm = 3.5981e-01, time/batch = 0.3379s	
356/2700 (epoch 6.593), train_loss = 2.31279502, grad/param norm = 3.0302e-01, time/batch = 0.3290s	
357/2700 (epoch 6.611), train_loss = 2.25341114, grad/param norm = 3.0525e-01, time/batch = 0.3094s	
358/2700 (epoch 6.630), train_loss = 2.29908011, grad/param norm = 3.9363e-01, time/batch = 0.2922s	
359/2700 (epoch 6.648), train_loss = 2.33579450, grad/param norm = 3.9060e-01, time/batch = 0.2386s	
360/2700 (epoch 6.667), train_loss = 2.27530083, grad/param norm = 3.6705e-01, time/batch = 0.2555s	
361/2700 (epoch 6.685), train_loss = 2.32007362, grad/param norm = 3.6498e-01, time/batch = 0.2676s	
362/2700 (epoch 6.704), train_loss = 2.32783636, grad/param norm = 3.7540e-01, time/batch = 0.2451s	
363/2700 (epoch 6.722), train_loss = 2.29150630, grad/param norm = 3.1985e-01, time/batch = 0.2750s	
364/2700 (epoch 6.741), train_loss = 2.40146692, grad/param norm = 3.2515e-01, time/batch = 0.3115s	
365/2700 (epoch 6.759), train_loss = 2.39839741, grad/param norm = 4.9812e-01, time/batch = 0.3153s	
366/2700 (epoch 6.778), train_loss = 2.39178985, grad/param norm = 5.7897e-01, time/batch = 0.3345s	
367/2700 (epoch 6.796), train_loss = 2.37522295, grad/param norm = 4.8153e-01, time/batch = 0.3269s	
368/2700 (epoch 6.815), train_loss = 2.33857039, grad/param norm = 2.7284e-01, time/batch = 0.3060s	
369/2700 (epoch 6.833), train_loss = 2.29064147, grad/param norm = 1.8710e-01, time/batch = 0.2870s	
370/2700 (epoch 6.852), train_loss = 2.32220969, grad/param norm = 1.7156e-01, time/batch = 0.2991s	
371/2700 (epoch 6.870), train_loss = 2.29464447, grad/param norm = 2.2675e-01, time/batch = 0.3012s	
372/2700 (epoch 6.889), train_loss = 2.29079086, grad/param norm = 2.5997e-01, time/batch = 0.3401s	
373/2700 (epoch 6.907), train_loss = 2.41182190, grad/param norm = 3.5246e-01, time/batch = 0.3378s	
374/2700 (epoch 6.926), train_loss = 2.36706209, grad/param norm = 4.0886e-01, time/batch = 0.3365s	
375/2700 (epoch 6.944), train_loss = 2.35844056, grad/param norm = 4.3813e-01, time/batch = 0.3141s	
376/2700 (epoch 6.963), train_loss = 2.40198556, grad/param norm = 4.3236e-01, time/batch = 0.2938s	
377/2700 (epoch 6.981), train_loss = 2.34790337, grad/param norm = 2.9903e-01, time/batch = 0.2772s	
378/2700 (epoch 7.000), train_loss = 2.36664683, grad/param norm = 2.7608e-01, time/batch = 0.2795s	
379/2700 (epoch 7.019), train_loss = 2.35660518, grad/param norm = 3.0439e-01, time/batch = 0.2692s	
380/2700 (epoch 7.037), train_loss = 2.37877351, grad/param norm = 3.4230e-01, time/batch = 0.2534s	
381/2700 (epoch 7.056), train_loss = 2.32966815, grad/param norm = 3.3029e-01, time/batch = 0.2826s	
382/2700 (epoch 7.074), train_loss = 2.30211011, grad/param norm = 2.9677e-01, time/batch = 0.2794s	
383/2700 (epoch 7.093), train_loss = 2.33498074, grad/param norm = 3.1558e-01, time/batch = 0.2853s	
384/2700 (epoch 7.111), train_loss = 2.29542839, grad/param norm = 3.2978e-01, time/batch = 0.3343s	
385/2700 (epoch 7.130), train_loss = 2.33353508, grad/param norm = 3.5630e-01, time/batch = 0.3346s	
386/2700 (epoch 7.148), train_loss = 2.28468633, grad/param norm = 3.9172e-01, time/batch = 0.3084s	
387/2700 (epoch 7.167), train_loss = 2.34447836, grad/param norm = 3.9324e-01, time/batch = 0.3030s	
388/2700 (epoch 7.185), train_loss = 2.27964374, grad/param norm = 3.6287e-01, time/batch = 0.2755s	
389/2700 (epoch 7.204), train_loss = 2.28460666, grad/param norm = 3.2789e-01, time/batch = 0.2744s	
390/2700 (epoch 7.222), train_loss = 2.22862728, grad/param norm = 3.4117e-01, time/batch = 0.2906s	
391/2700 (epoch 7.241), train_loss = 2.20158583, grad/param norm = 3.0132e-01, time/batch = 0.3150s	
392/2700 (epoch 7.259), train_loss = 2.22856372, grad/param norm = 3.3846e-01, time/batch = 0.3029s	
393/2700 (epoch 7.278), train_loss = 2.32517164, grad/param norm = 3.5329e-01, time/batch = 0.2976s	
394/2700 (epoch 7.296), train_loss = 2.30053750, grad/param norm = 3.0349e-01, time/batch = 0.2715s	
395/2700 (epoch 7.315), train_loss = 2.29252945, grad/param norm = 2.8920e-01, time/batch = 0.2073s	
396/2700 (epoch 7.333), train_loss = 2.29346131, grad/param norm = 2.8875e-01, time/batch = 0.2819s	
397/2700 (epoch 7.352), train_loss = 2.32381692, grad/param norm = 3.0995e-01, time/batch = 0.2503s	
398/2700 (epoch 7.370), train_loss = 2.30943675, grad/param norm = 3.4908e-01, time/batch = 0.2809s	
399/2700 (epoch 7.389), train_loss = 2.30214508, grad/param norm = 3.9740e-01, time/batch = 0.2973s	
400/2700 (epoch 7.407), train_loss = 2.29011461, grad/param norm = 4.1292e-01, time/batch = 0.3004s	
401/2700 (epoch 7.426), train_loss = 2.32948748, grad/param norm = 3.7980e-01, time/batch = 0.2744s	
402/2700 (epoch 7.444), train_loss = 2.23279098, grad/param norm = 3.8020e-01, time/batch = 0.2726s	
403/2700 (epoch 7.463), train_loss = 2.30663820, grad/param norm = 3.6219e-01, time/batch = 0.2669s	
404/2700 (epoch 7.481), train_loss = 2.32244648, grad/param norm = 2.8888e-01, time/batch = 0.2940s	
405/2700 (epoch 7.500), train_loss = 2.32093409, grad/param norm = 2.8101e-01, time/batch = 0.3183s	
406/2700 (epoch 7.519), train_loss = 2.27384531, grad/param norm = 2.8075e-01, time/batch = 0.3183s	
407/2700 (epoch 7.537), train_loss = 2.29063521, grad/param norm = 3.0817e-01, time/batch = 0.3116s	
408/2700 (epoch 7.556), train_loss = 2.27333460, grad/param norm = 3.0447e-01, time/batch = 0.2599s	
409/2700 (epoch 7.574), train_loss = 2.24450754, grad/param norm = 2.9676e-01, time/batch = 0.2596s	
410/2700 (epoch 7.593), train_loss = 2.23678946, grad/param norm = 2.7810e-01, time/batch = 0.2642s	
411/2700 (epoch 7.611), train_loss = 2.17715220, grad/param norm = 3.1568e-01, time/batch = 0.2727s	
412/2700 (epoch 7.630), train_loss = 2.22311718, grad/param norm = 3.2812e-01, time/batch = 0.2441s	
413/2700 (epoch 7.648), train_loss = 2.25086780, grad/param norm = 2.5175e-01, time/batch = 0.2739s	
414/2700 (epoch 7.667), train_loss = 2.18886648, grad/param norm = 2.3376e-01, time/batch = 0.2866s	
415/2700 (epoch 7.685), train_loss = 2.23853316, grad/param norm = 2.8585e-01, time/batch = 0.3139s	
416/2700 (epoch 7.704), train_loss = 2.25462005, grad/param norm = 3.9099e-01, time/batch = 0.3337s	
417/2700 (epoch 7.722), train_loss = 2.24401519, grad/param norm = 5.1846e-01, time/batch = 0.3368s	
418/2700 (epoch 7.741), train_loss = 2.34684103, grad/param norm = 5.1845e-01, time/batch = 0.3323s	
419/2700 (epoch 7.759), train_loss = 2.32431715, grad/param norm = 3.8766e-01, time/batch = 0.3144s	
420/2700 (epoch 7.778), train_loss = 2.27682968, grad/param norm = 2.5026e-01, time/batch = 0.3038s	
421/2700 (epoch 7.796), train_loss = 2.24782587, grad/param norm = 2.6672e-01, time/batch = 0.3170s	
422/2700 (epoch 7.815), train_loss = 2.26046269, grad/param norm = 2.5925e-01, time/batch = 0.2856s	
423/2700 (epoch 7.833), train_loss = 2.22271242, grad/param norm = 2.6377e-01, time/batch = 0.2794s	
424/2700 (epoch 7.852), train_loss = 2.25111190, grad/param norm = 2.2312e-01, time/batch = 0.2928s	
425/2700 (epoch 7.870), train_loss = 2.21903678, grad/param norm = 1.8815e-01, time/batch = 0.2848s	
426/2700 (epoch 7.889), train_loss = 2.21870909, grad/param norm = 2.1179e-01, time/batch = 0.2860s	
427/2700 (epoch 7.907), train_loss = 2.34664628, grad/param norm = 3.2489e-01, time/batch = 0.2549s	
428/2700 (epoch 7.926), train_loss = 2.30527815, grad/param norm = 3.3732e-01, time/batch = 0.2719s	
429/2700 (epoch 7.944), train_loss = 2.27409675, grad/param norm = 2.9063e-01, time/batch = 0.3021s	
430/2700 (epoch 7.963), train_loss = 2.30899290, grad/param norm = 3.2434e-01, time/batch = 0.3192s	
431/2700 (epoch 7.981), train_loss = 2.26670830, grad/param norm = 2.8672e-01, time/batch = 0.2863s	
432/2700 (epoch 8.000), train_loss = 2.28877151, grad/param norm = 3.0642e-01, time/batch = 0.2816s	
433/2700 (epoch 8.019), train_loss = 2.29219989, grad/param norm = 3.4706e-01, time/batch = 0.2888s	
434/2700 (epoch 8.037), train_loss = 2.29910619, grad/param norm = 3.3249e-01, time/batch = 0.3125s	
435/2700 (epoch 8.056), train_loss = 2.24220385, grad/param norm = 2.7171e-01, time/batch = 0.3279s	
436/2700 (epoch 8.074), train_loss = 2.21461893, grad/param norm = 2.3114e-01, time/batch = 0.3329s	
437/2700 (epoch 8.093), train_loss = 2.24876959, grad/param norm = 3.0085e-01, time/batch = 0.3338s	
438/2700 (epoch 8.111), train_loss = 2.21459836, grad/param norm = 3.6365e-01, time/batch = 0.3290s	
439/2700 (epoch 8.130), train_loss = 2.26295784, grad/param norm = 4.1750e-01, time/batch = 0.3260s	
440/2700 (epoch 8.148), train_loss = 2.22174887, grad/param norm = 4.8836e-01, time/batch = 0.3070s	
441/2700 (epoch 8.167), train_loss = 2.28734549, grad/param norm = 4.3215e-01, time/batch = 0.3404s	
442/2700 (epoch 8.185), train_loss = 2.20533948, grad/param norm = 3.0582e-01, time/batch = 0.3343s	
443/2700 (epoch 8.204), train_loss = 2.20888247, grad/param norm = 2.4098e-01, time/batch = 0.2702s	
444/2700 (epoch 8.222), train_loss = 2.14914370, grad/param norm = 2.6009e-01, time/batch = 0.3087s	
445/2700 (epoch 8.241), train_loss = 2.11360142, grad/param norm = 2.6227e-01, time/batch = 0.3038s	
446/2700 (epoch 8.259), train_loss = 2.14692141, grad/param norm = 2.7962e-01, time/batch = 0.2957s	
447/2700 (epoch 8.278), train_loss = 2.23894975, grad/param norm = 2.7071e-01, time/batch = 0.2937s	
448/2700 (epoch 8.296), train_loss = 2.21573935, grad/param norm = 2.0984e-01, time/batch = 0.2744s	
449/2700 (epoch 8.315), train_loss = 2.20449310, grad/param norm = 1.7042e-01, time/batch = 0.2653s	
450/2700 (epoch 8.333), train_loss = 2.21041685, grad/param norm = 1.9041e-01, time/batch = 0.2840s	
451/2700 (epoch 8.352), train_loss = 2.23428105, grad/param norm = 2.3155e-01, time/batch = 0.2683s	
452/2700 (epoch 8.370), train_loss = 2.23074834, grad/param norm = 2.6848e-01, time/batch = 0.3217s	
453/2700 (epoch 8.389), train_loss = 2.23394387, grad/param norm = 3.1396e-01, time/batch = 0.3271s	
454/2700 (epoch 8.407), train_loss = 2.22057847, grad/param norm = 3.2959e-01, time/batch = 0.3155s	
455/2700 (epoch 8.426), train_loss = 2.24982081, grad/param norm = 2.6141e-01, time/batch = 0.2778s	
456/2700 (epoch 8.444), train_loss = 2.14996628, grad/param norm = 2.7551e-01, time/batch = 0.3084s	
457/2700 (epoch 8.463), train_loss = 2.22443209, grad/param norm = 3.4727e-01, time/batch = 0.3255s	
458/2700 (epoch 8.481), train_loss = 2.25023779, grad/param norm = 3.0090e-01, time/batch = 0.3361s	
459/2700 (epoch 8.500), train_loss = 2.24373881, grad/param norm = 3.4147e-01, time/batch = 0.3347s	
460/2700 (epoch 8.519), train_loss = 2.21291506, grad/param norm = 3.4180e-01, time/batch = 0.3377s	
461/2700 (epoch 8.537), train_loss = 2.23604972, grad/param norm = 3.1515e-01, time/batch = 0.3142s	
462/2700 (epoch 8.556), train_loss = 2.21276114, grad/param norm = 2.8666e-01, time/batch = 0.3396s	
463/2700 (epoch 8.574), train_loss = 2.18023163, grad/param norm = 3.4076e-01, time/batch = 0.3412s	
464/2700 (epoch 8.593), train_loss = 2.19750948, grad/param norm = 4.2428e-01, time/batch = 0.3302s	
465/2700 (epoch 8.611), train_loss = 2.12934343, grad/param norm = 4.7779e-01, time/batch = 0.3320s	
466/2700 (epoch 8.630), train_loss = 2.16506379, grad/param norm = 3.3300e-01, time/batch = 0.2824s	
467/2700 (epoch 8.648), train_loss = 2.17526487, grad/param norm = 1.9373e-01, time/batch = 0.3137s	
468/2700 (epoch 8.667), train_loss = 2.11553312, grad/param norm = 1.8192e-01, time/batch = 0.3297s	
469/2700 (epoch 8.685), train_loss = 2.16398610, grad/param norm = 2.4476e-01, time/batch = 0.3343s	
470/2700 (epoch 8.704), train_loss = 2.17771061, grad/param norm = 3.2068e-01, time/batch = 0.3376s	
471/2700 (epoch 8.722), train_loss = 2.15450933, grad/param norm = 3.5633e-01, time/batch = 0.3218s	
472/2700 (epoch 8.741), train_loss = 2.24532556, grad/param norm = 3.3406e-01, time/batch = 0.3406s	
473/2700 (epoch 8.759), train_loss = 2.23728335, grad/param norm = 2.8719e-01, time/batch = 0.3373s	
474/2700 (epoch 8.778), train_loss = 2.20557140, grad/param norm = 2.3685e-01, time/batch = 0.3328s	
475/2700 (epoch 8.796), train_loss = 2.17738847, grad/param norm = 2.4829e-01, time/batch = 0.3370s	
476/2700 (epoch 8.815), train_loss = 2.19649807, grad/param norm = 2.4775e-01, time/batch = 0.3341s	
477/2700 (epoch 8.833), train_loss = 2.15361995, grad/param norm = 2.4650e-01, time/batch = 0.2768s	
478/2700 (epoch 8.852), train_loss = 2.17566352, grad/param norm = 1.7871e-01, time/batch = 0.3319s	
479/2700 (epoch 8.870), train_loss = 2.14660046, grad/param norm = 1.7667e-01, time/batch = 0.3367s	
480/2700 (epoch 8.889), train_loss = 2.15794011, grad/param norm = 2.7390e-01, time/batch = 0.3403s	
481/2700 (epoch 8.907), train_loss = 2.29108816, grad/param norm = 4.2955e-01, time/batch = 0.3090s	
482/2700 (epoch 8.926), train_loss = 2.24839924, grad/param norm = 4.0307e-01, time/batch = 0.3246s	
483/2700 (epoch 8.944), train_loss = 2.21450044, grad/param norm = 3.3192e-01, time/batch = 0.3323s	
484/2700 (epoch 8.963), train_loss = 2.23786962, grad/param norm = 2.9630e-01, time/batch = 0.3262s	
485/2700 (epoch 8.981), train_loss = 2.19312371, grad/param norm = 2.3094e-01, time/batch = 0.3255s	
486/2700 (epoch 9.000), train_loss = 2.21343237, grad/param norm = 2.5754e-01, time/batch = 0.3082s	
487/2700 (epoch 9.019), train_loss = 2.22359788, grad/param norm = 2.7240e-01, time/batch = 0.2821s	
488/2700 (epoch 9.037), train_loss = 2.21824672, grad/param norm = 2.5157e-01, time/batch = 0.2648s	
489/2700 (epoch 9.056), train_loss = 2.16957864, grad/param norm = 2.3617e-01, time/batch = 0.2956s	
490/2700 (epoch 9.074), train_loss = 2.14051191, grad/param norm = 2.2210e-01, time/batch = 0.2622s	
491/2700 (epoch 9.093), train_loss = 2.16941180, grad/param norm = 2.5128e-01, time/batch = 0.2620s	
492/2700 (epoch 9.111), train_loss = 2.13111740, grad/param norm = 2.6180e-01, time/batch = 0.2161s	
493/2700 (epoch 9.130), train_loss = 2.18137960, grad/param norm = 2.9795e-01, time/batch = 0.2876s	
494/2700 (epoch 9.148), train_loss = 2.13267752, grad/param norm = 3.3228e-01, time/batch = 0.2897s	
495/2700 (epoch 9.167), train_loss = 2.19487313, grad/param norm = 3.1059e-01, time/batch = 0.2686s	
496/2700 (epoch 9.185), train_loss = 2.12504745, grad/param norm = 2.7692e-01, time/batch = 0.2574s	
497/2700 (epoch 9.204), train_loss = 2.14403430, grad/param norm = 2.4360e-01, time/batch = 0.2874s	
498/2700 (epoch 9.222), train_loss = 2.08622688, grad/param norm = 2.3877e-01, time/batch = 0.3075s	
499/2700 (epoch 9.241), train_loss = 2.03358436, grad/param norm = 1.9370e-01, time/batch = 0.3125s	
500/2700 (epoch 9.259), train_loss = 2.06685717, grad/param norm = 2.4875e-01, time/batch = 0.2951s	
501/2700 (epoch 9.278), train_loss = 2.17299578, grad/param norm = 3.0054e-01, time/batch = 0.3201s	
502/2700 (epoch 9.296), train_loss = 2.15731722, grad/param norm = 3.2985e-01, time/batch = 0.3164s	
503/2700 (epoch 9.315), train_loss = 2.14948105, grad/param norm = 3.1311e-01, time/batch = 0.2744s	
504/2700 (epoch 9.333), train_loss = 2.15664412, grad/param norm = 2.8206e-01, time/batch = 0.2749s	
505/2700 (epoch 9.352), train_loss = 2.17256068, grad/param norm = 3.1351e-01, time/batch = 0.2680s	
506/2700 (epoch 9.370), train_loss = 2.18922200, grad/param norm = 3.6096e-01, time/batch = 0.2477s	
507/2700 (epoch 9.389), train_loss = 2.17631897, grad/param norm = 3.0467e-01, time/batch = 0.2851s	
508/2700 (epoch 9.407), train_loss = 2.15250136, grad/param norm = 2.7820e-01, time/batch = 0.2808s	
509/2700 (epoch 9.426), train_loss = 2.19979040, grad/param norm = 2.9299e-01, time/batch = 0.3015s	
510/2700 (epoch 9.444), train_loss = 2.09268761, grad/param norm = 2.6653e-01, time/batch = 0.3239s	
511/2700 (epoch 9.463), train_loss = 2.16596365, grad/param norm = 2.9753e-01, time/batch = 0.3010s	
512/2700 (epoch 9.481), train_loss = 2.18688459, grad/param norm = 3.0676e-01, time/batch = 0.3038s	
513/2700 (epoch 9.500), train_loss = 2.17785038, grad/param norm = 3.3643e-01, time/batch = 0.3176s	
514/2700 (epoch 9.519), train_loss = 2.13936666, grad/param norm = 3.0507e-01, time/batch = 0.2895s	
515/2700 (epoch 9.537), train_loss = 2.16337067, grad/param norm = 2.7678e-01, time/batch = 0.2928s	
516/2700 (epoch 9.556), train_loss = 2.13365688, grad/param norm = 2.5808e-01, time/batch = 0.3040s	
517/2700 (epoch 9.574), train_loss = 2.10951358, grad/param norm = 2.6200e-01, time/batch = 0.2908s	
518/2700 (epoch 9.593), train_loss = 2.11342086, grad/param norm = 2.4894e-01, time/batch = 0.2749s	
519/2700 (epoch 9.611), train_loss = 2.03571514, grad/param norm = 2.5466e-01, time/batch = 0.2538s	
520/2700 (epoch 9.630), train_loss = 2.08175087, grad/param norm = 2.9802e-01, time/batch = 0.2639s	
521/2700 (epoch 9.648), train_loss = 2.11997907, grad/param norm = 2.6383e-01, time/batch = 0.2611s	
522/2700 (epoch 9.667), train_loss = 2.06693885, grad/param norm = 2.4451e-01, time/batch = 0.3005s	
523/2700 (epoch 9.685), train_loss = 2.10963802, grad/param norm = 2.6781e-01, time/batch = 0.3264s	
524/2700 (epoch 9.704), train_loss = 2.12250468, grad/param norm = 3.0540e-01, time/batch = 0.3201s	
525/2700 (epoch 9.722), train_loss = 2.09310391, grad/param norm = 3.0359e-01, time/batch = 0.2611s	
526/2700 (epoch 9.741), train_loss = 2.17283817, grad/param norm = 2.8642e-01, time/batch = 0.2923s	
527/2700 (epoch 9.759), train_loss = 2.18206881, grad/param norm = 3.3567e-01, time/batch = 0.2860s	
528/2700 (epoch 9.778), train_loss = 2.16269836, grad/param norm = 4.2535e-01, time/batch = 0.2851s	
529/2700 (epoch 9.796), train_loss = 2.16354475, grad/param norm = 4.2207e-01, time/batch = 0.2854s	
530/2700 (epoch 9.815), train_loss = 2.15942886, grad/param norm = 3.3275e-01, time/batch = 0.2568s	
531/2700 (epoch 9.833), train_loss = 2.10223399, grad/param norm = 2.8325e-01, time/batch = 0.2424s	
532/2700 (epoch 9.852), train_loss = 2.12210416, grad/param norm = 2.4723e-01, time/batch = 0.2794s	
533/2700 (epoch 9.870), train_loss = 2.09223273, grad/param norm = 2.4282e-01, time/batch = 0.3148s	
534/2700 (epoch 9.889), train_loss = 2.10482298, grad/param norm = 2.6032e-01, time/batch = 0.3210s	
535/2700 (epoch 9.907), train_loss = 2.21193318, grad/param norm = 2.6588e-01, time/batch = 0.3237s	
536/2700 (epoch 9.926), train_loss = 2.16673612, grad/param norm = 2.2573e-01, time/batch = 0.3030s	
537/2700 (epoch 9.944), train_loss = 2.13227306, grad/param norm = 1.7628e-01, time/batch = 0.2666s	
538/2700 (epoch 9.963), train_loss = 2.16185724, grad/param norm = 1.5883e-01, time/batch = 0.2884s	
539/2700 (epoch 9.981), train_loss = 2.12560015, grad/param norm = 1.6287e-01, time/batch = 0.2903s	
decayed learning rate by a factor 0.97 to 0.00194	
540/2700 (epoch 10.000), train_loss = 2.13999410, grad/param norm = 1.6021e-01, time/batch = 0.2929s	
541/2700 (epoch 10.019), train_loss = 2.16074236, grad/param norm = 2.0842e-01, time/batch = 0.3094s	
542/2700 (epoch 10.037), train_loss = 2.15966751, grad/param norm = 2.6349e-01, time/batch = 0.2957s	
543/2700 (epoch 10.056), train_loss = 2.12148901, grad/param norm = 3.4835e-01, time/batch = 0.2762s	
544/2700 (epoch 10.074), train_loss = 2.09215786, grad/param norm = 3.4566e-01, time/batch = 0.2545s	
545/2700 (epoch 10.093), train_loss = 2.10500597, grad/param norm = 2.7360e-01, time/batch = 0.2743s	
546/2700 (epoch 10.111), train_loss = 2.05174005, grad/param norm = 1.9495e-01, time/batch = 0.3037s	
547/2700 (epoch 10.130), train_loss = 2.11391361, grad/param norm = 1.9851e-01, time/batch = 0.2970s	
548/2700 (epoch 10.148), train_loss = 2.05523710, grad/param norm = 2.0769e-01, time/batch = 0.3073s	
549/2700 (epoch 10.167), train_loss = 2.12475357, grad/param norm = 1.9836e-01, time/batch = 0.2426s	
550/2700 (epoch 10.185), train_loss = 2.05054772, grad/param norm = 1.8267e-01, time/batch = 0.2803s	
551/2700 (epoch 10.204), train_loss = 2.09138700, grad/param norm = 2.5162e-01, time/batch = 0.2995s	
552/2700 (epoch 10.222), train_loss = 2.04065529, grad/param norm = 3.2193e-01, time/batch = 0.3008s	
553/2700 (epoch 10.241), train_loss = 1.99147751, grad/param norm = 3.3275e-01, time/batch = 0.2968s	
554/2700 (epoch 10.259), train_loss = 2.02452822, grad/param norm = 3.0859e-01, time/batch = 0.2947s	
555/2700 (epoch 10.278), train_loss = 2.10916397, grad/param norm = 2.8676e-01, time/batch = 0.2778s	
556/2700 (epoch 10.296), train_loss = 2.09136109, grad/param norm = 2.4506e-01, time/batch = 0.2718s	
557/2700 (epoch 10.315), train_loss = 2.08377123, grad/param norm = 2.5356e-01, time/batch = 0.2835s	
558/2700 (epoch 10.333), train_loss = 2.10750991, grad/param norm = 3.1775e-01, time/batch = 0.2877s	
559/2700 (epoch 10.352), train_loss = 2.10650492, grad/param norm = 3.0235e-01, time/batch = 0.2859s	
560/2700 (epoch 10.370), train_loss = 2.11923204, grad/param norm = 2.8872e-01, time/batch = 0.2704s	
561/2700 (epoch 10.389), train_loss = 2.10255822, grad/param norm = 2.4804e-01, time/batch = 0.2692s	
562/2700 (epoch 10.407), train_loss = 2.09209797, grad/param norm = 2.0955e-01, time/batch = 0.3045s	
563/2700 (epoch 10.426), train_loss = 2.12708114, grad/param norm = 1.9652e-01, time/batch = 0.3026s	
564/2700 (epoch 10.444), train_loss = 2.02025323, grad/param norm = 1.6227e-01, time/batch = 0.2949s	
565/2700 (epoch 10.463), train_loss = 2.09477095, grad/param norm = 1.9948e-01, time/batch = 0.3089s	
566/2700 (epoch 10.481), train_loss = 2.11698860, grad/param norm = 1.7124e-01, time/batch = 0.3016s	
567/2700 (epoch 10.500), train_loss = 2.09274261, grad/param norm = 1.9850e-01, time/batch = 0.2885s	
568/2700 (epoch 10.519), train_loss = 2.07492331, grad/param norm = 2.3980e-01, time/batch = 0.2969s	
569/2700 (epoch 10.537), train_loss = 2.10812134, grad/param norm = 2.7877e-01, time/batch = 0.3035s	
570/2700 (epoch 10.556), train_loss = 2.07782524, grad/param norm = 2.6896e-01, time/batch = 0.3207s	
571/2700 (epoch 10.574), train_loss = 2.05399644, grad/param norm = 2.6263e-01, time/batch = 0.3315s	
572/2700 (epoch 10.593), train_loss = 2.06980875, grad/param norm = 2.9699e-01, time/batch = 0.3192s	
573/2700 (epoch 10.611), train_loss = 1.98626556, grad/param norm = 2.6560e-01, time/batch = 0.3154s	
574/2700 (epoch 10.630), train_loss = 2.01207605, grad/param norm = 2.3880e-01, time/batch = 0.2949s	
575/2700 (epoch 10.648), train_loss = 2.05802210, grad/param norm = 2.4055e-01, time/batch = 0.2880s	
576/2700 (epoch 10.667), train_loss = 2.01062119, grad/param norm = 2.2582e-01, time/batch = 0.2888s	
577/2700 (epoch 10.685), train_loss = 2.05753513, grad/param norm = 2.5037e-01, time/batch = 0.2716s	
578/2700 (epoch 10.704), train_loss = 2.07022575, grad/param norm = 3.1275e-01, time/batch = 0.2601s	
579/2700 (epoch 10.722), train_loss = 2.04089502, grad/param norm = 3.0619e-01, time/batch = 0.2468s	
580/2700 (epoch 10.741), train_loss = 2.11176427, grad/param norm = 3.0150e-01, time/batch = 0.2687s	
581/2700 (epoch 10.759), train_loss = 2.12617210, grad/param norm = 3.3197e-01, time/batch = 0.2730s	
582/2700 (epoch 10.778), train_loss = 2.09945157, grad/param norm = 3.4113e-01, time/batch = 0.3237s	
583/2700 (epoch 10.796), train_loss = 2.07837307, grad/param norm = 3.4312e-01, time/batch = 0.3138s	
584/2700 (epoch 10.815), train_loss = 2.09558413, grad/param norm = 3.0392e-01, time/batch = 0.3013s	
585/2700 (epoch 10.833), train_loss = 2.04409871, grad/param norm = 2.7782e-01, time/batch = 0.2543s	
586/2700 (epoch 10.852), train_loss = 2.07250696, grad/param norm = 2.9513e-01, time/batch = 0.2865s	
587/2700 (epoch 10.870), train_loss = 2.04540987, grad/param norm = 2.8691e-01, time/batch = 0.3053s	
588/2700 (epoch 10.889), train_loss = 2.06057338, grad/param norm = 2.4464e-01, time/batch = 0.3114s	
589/2700 (epoch 10.907), train_loss = 2.15169090, grad/param norm = 2.0857e-01, time/batch = 0.2949s	
590/2700 (epoch 10.926), train_loss = 2.10879497, grad/param norm = 1.8702e-01, time/batch = 0.2947s	
591/2700 (epoch 10.944), train_loss = 2.07292941, grad/param norm = 1.6423e-01, time/batch = 0.2932s	
592/2700 (epoch 10.963), train_loss = 2.10420725, grad/param norm = 1.5115e-01, time/batch = 0.2586s	
593/2700 (epoch 10.981), train_loss = 2.06900582, grad/param norm = 1.4499e-01, time/batch = 0.2840s	
decayed learning rate by a factor 0.97 to 0.0018818	
594/2700 (epoch 11.000), train_loss = 2.08469777, grad/param norm = 1.5181e-01, time/batch = 0.2675s	
595/2700 (epoch 11.019), train_loss = 2.10642498, grad/param norm = 1.9346e-01, time/batch = 0.2865s	
596/2700 (epoch 11.037), train_loss = 2.09925278, grad/param norm = 2.4130e-01, time/batch = 0.2945s	
597/2700 (epoch 11.056), train_loss = 2.06644572, grad/param norm = 3.1050e-01, time/batch = 0.2744s	
598/2700 (epoch 11.074), train_loss = 2.02300301, grad/param norm = 2.7193e-01, time/batch = 0.2909s	
599/2700 (epoch 11.093), train_loss = 2.03674210, grad/param norm = 2.0607e-01, time/batch = 0.3091s	
600/2700 (epoch 11.111), train_loss = 1.98821867, grad/param norm = 1.6820e-01, time/batch = 0.3130s	
601/2700 (epoch 11.130), train_loss = 2.06194491, grad/param norm = 2.1833e-01, time/batch = 0.3114s	
602/2700 (epoch 11.148), train_loss = 2.00122197, grad/param norm = 2.4819e-01, time/batch = 0.3072s	
603/2700 (epoch 11.167), train_loss = 2.07528659, grad/param norm = 2.4071e-01, time/batch = 0.2938s	
604/2700 (epoch 11.185), train_loss = 1.99831136, grad/param norm = 2.1164e-01, time/batch = 0.3050s	
605/2700 (epoch 11.204), train_loss = 2.04246398, grad/param norm = 2.1263e-01, time/batch = 0.3021s	
606/2700 (epoch 11.222), train_loss = 1.98198109, grad/param norm = 1.9235e-01, time/batch = 0.2879s	
607/2700 (epoch 11.241), train_loss = 1.91755144, grad/param norm = 1.6910e-01, time/batch = 0.2755s	
608/2700 (epoch 11.259), train_loss = 1.95808157, grad/param norm = 2.0983e-01, time/batch = 0.2514s	
609/2700 (epoch 11.278), train_loss = 2.04311601, grad/param norm = 2.1305e-01, time/batch = 0.2736s	
610/2700 (epoch 11.296), train_loss = 2.03454925, grad/param norm = 2.3643e-01, time/batch = 0.2712s	
611/2700 (epoch 11.315), train_loss = 2.03994186, grad/param norm = 2.6812e-01, time/batch = 0.2689s	
612/2700 (epoch 11.333), train_loss = 2.04518293, grad/param norm = 2.4507e-01, time/batch = 0.2992s	
613/2700 (epoch 11.352), train_loss = 2.04283038, grad/param norm = 2.4537e-01, time/batch = 0.3071s	
614/2700 (epoch 11.370), train_loss = 2.06923528, grad/param norm = 2.9193e-01, time/batch = 0.3111s	
615/2700 (epoch 11.389), train_loss = 2.06433372, grad/param norm = 3.1956e-01, time/batch = 0.3027s	
616/2700 (epoch 11.407), train_loss = 2.06155046, grad/param norm = 3.1730e-01, time/batch = 0.2954s	
617/2700 (epoch 11.426), train_loss = 2.09212592, grad/param norm = 2.9970e-01, time/batch = 0.2909s	
618/2700 (epoch 11.444), train_loss = 1.98521835, grad/param norm = 2.6642e-01, time/batch = 0.2668s	
619/2700 (epoch 11.463), train_loss = 2.05721910, grad/param norm = 2.7972e-01, time/batch = 0.2760s	
620/2700 (epoch 11.481), train_loss = 2.07164470, grad/param norm = 1.9420e-01, time/batch = 0.2782s	
621/2700 (epoch 11.500), train_loss = 2.03723967, grad/param norm = 1.8104e-01, time/batch = 0.2950s	
622/2700 (epoch 11.519), train_loss = 2.02309062, grad/param norm = 1.9225e-01, time/batch = 0.2790s	
623/2700 (epoch 11.537), train_loss = 2.05309248, grad/param norm = 2.4023e-01, time/batch = 0.2642s	
624/2700 (epoch 11.556), train_loss = 2.02605080, grad/param norm = 2.4247e-01, time/batch = 0.2720s	
625/2700 (epoch 11.574), train_loss = 2.00683008, grad/param norm = 2.8719e-01, time/batch = 0.3180s	
626/2700 (epoch 11.593), train_loss = 2.03114045, grad/param norm = 3.2231e-01, time/batch = 0.3085s	
627/2700 (epoch 11.611), train_loss = 1.94357757, grad/param norm = 3.4513e-01, time/batch = 0.2934s	
628/2700 (epoch 11.630), train_loss = 1.97943102, grad/param norm = 2.7337e-01, time/batch = 0.2999s	
629/2700 (epoch 11.648), train_loss = 2.00406044, grad/param norm = 2.0953e-01, time/batch = 0.2980s	
630/2700 (epoch 11.667), train_loss = 1.95563786, grad/param norm = 1.8366e-01, time/batch = 0.2800s	
631/2700 (epoch 11.685), train_loss = 1.99711607, grad/param norm = 2.0445e-01, time/batch = 0.2652s	
632/2700 (epoch 11.704), train_loss = 2.01059859, grad/param norm = 2.3406e-01, time/batch = 0.2494s	
633/2700 (epoch 11.722), train_loss = 1.97756482, grad/param norm = 2.3830e-01, time/batch = 0.2794s	
634/2700 (epoch 11.741), train_loss = 2.03910574, grad/param norm = 1.9160e-01, time/batch = 0.2656s	
635/2700 (epoch 11.759), train_loss = 2.05568725, grad/param norm = 2.1388e-01, time/batch = 0.2770s	
636/2700 (epoch 11.778), train_loss = 2.04155514, grad/param norm = 2.0362e-01, time/batch = 0.3092s	
637/2700 (epoch 11.796), train_loss = 2.00907502, grad/param norm = 2.2158e-01, time/batch = 0.3033s	
638/2700 (epoch 11.815), train_loss = 2.04042791, grad/param norm = 2.3430e-01, time/batch = 0.2958s	
639/2700 (epoch 11.833), train_loss = 1.99613139, grad/param norm = 2.6019e-01, time/batch = 0.2957s	
640/2700 (epoch 11.852), train_loss = 2.01269877, grad/param norm = 2.3444e-01, time/batch = 0.2785s	
641/2700 (epoch 11.870), train_loss = 1.99127124, grad/param norm = 2.3318e-01, time/batch = 0.2582s	
642/2700 (epoch 11.889), train_loss = 2.01575342, grad/param norm = 2.3307e-01, time/batch = 0.2582s	
643/2700 (epoch 11.907), train_loss = 2.11759641, grad/param norm = 2.9088e-01, time/batch = 0.2890s	
644/2700 (epoch 11.926), train_loss = 2.07966565, grad/param norm = 2.9715e-01, time/batch = 0.2910s	
645/2700 (epoch 11.944), train_loss = 2.03176952, grad/param norm = 2.5515e-01, time/batch = 0.2716s	
646/2700 (epoch 11.963), train_loss = 2.06131650, grad/param norm = 2.1485e-01, time/batch = 0.2757s	
647/2700 (epoch 11.981), train_loss = 2.02995067, grad/param norm = 2.2051e-01, time/batch = 0.2936s	
decayed learning rate by a factor 0.97 to 0.001825346	
648/2700 (epoch 12.000), train_loss = 2.04414637, grad/param norm = 2.0233e-01, time/batch = 0.2995s	
649/2700 (epoch 12.019), train_loss = 2.05815555, grad/param norm = 2.1543e-01, time/batch = 0.2906s	
650/2700 (epoch 12.037), train_loss = 2.05338746, grad/param norm = 2.6028e-01, time/batch = 0.2930s	
651/2700 (epoch 12.056), train_loss = 2.01953064, grad/param norm = 2.9505e-01, time/batch = 0.2947s	
652/2700 (epoch 12.074), train_loss = 1.96946617, grad/param norm = 2.3674e-01, time/batch = 0.2673s	
653/2700 (epoch 12.093), train_loss = 1.98132574, grad/param norm = 1.7154e-01, time/batch = 0.2540s	
654/2700 (epoch 12.111), train_loss = 1.93385673, grad/param norm = 1.5045e-01, time/batch = 0.2811s	
655/2700 (epoch 12.130), train_loss = 2.01421292, grad/param norm = 2.0323e-01, time/batch = 0.3068s	
656/2700 (epoch 12.148), train_loss = 1.95407724, grad/param norm = 2.7168e-01, time/batch = 0.3069s	
657/2700 (epoch 12.167), train_loss = 2.04270331, grad/param norm = 2.8021e-01, time/batch = 0.2504s	
658/2700 (epoch 12.185), train_loss = 1.95507615, grad/param norm = 2.1995e-01, time/batch = 0.2825s	
659/2700 (epoch 12.204), train_loss = 2.00474453, grad/param norm = 2.3148e-01, time/batch = 0.3020s	
660/2700 (epoch 12.222), train_loss = 1.94685018, grad/param norm = 2.5512e-01, time/batch = 0.2910s	
661/2700 (epoch 12.241), train_loss = 1.88859389, grad/param norm = 2.7963e-01, time/batch = 0.3356s	
662/2700 (epoch 12.259), train_loss = 1.93150227, grad/param norm = 2.6675e-01, time/batch = 0.3355s	
663/2700 (epoch 12.278), train_loss = 1.99894742, grad/param norm = 2.2575e-01, time/batch = 0.3362s	
664/2700 (epoch 12.296), train_loss = 1.98145062, grad/param norm = 1.8935e-01, time/batch = 0.3213s	
665/2700 (epoch 12.315), train_loss = 1.98028902, grad/param norm = 1.5560e-01, time/batch = 0.2946s	
666/2700 (epoch 12.333), train_loss = 1.99080728, grad/param norm = 1.8796e-01, time/batch = 0.2643s	
667/2700 (epoch 12.352), train_loss = 1.98907394, grad/param norm = 2.3992e-01, time/batch = 0.2563s	
668/2700 (epoch 12.370), train_loss = 2.01528560, grad/param norm = 2.5220e-01, time/batch = 0.2394s	
669/2700 (epoch 12.389), train_loss = 2.00620728, grad/param norm = 3.0016e-01, time/batch = 0.2853s	
670/2700 (epoch 12.407), train_loss = 2.00859923, grad/param norm = 2.7130e-01, time/batch = 0.3110s	
671/2700 (epoch 12.426), train_loss = 2.03728180, grad/param norm = 2.2741e-01, time/batch = 0.3122s	
672/2700 (epoch 12.444), train_loss = 1.92501848, grad/param norm = 1.6697e-01, time/batch = 0.3354s	
673/2700 (epoch 12.463), train_loss = 2.00435160, grad/param norm = 1.8855e-01, time/batch = 0.3404s	
674/2700 (epoch 12.481), train_loss = 2.02200732, grad/param norm = 1.6525e-01, time/batch = 0.3368s	
675/2700 (epoch 12.500), train_loss = 1.98585927, grad/param norm = 2.0997e-01, time/batch = 0.3378s	
676/2700 (epoch 12.519), train_loss = 1.98236417, grad/param norm = 2.2956e-01, time/batch = 0.3311s	
677/2700 (epoch 12.537), train_loss = 2.00526088, grad/param norm = 2.2133e-01, time/batch = 0.3208s	
678/2700 (epoch 12.556), train_loss = 1.96498985, grad/param norm = 1.9250e-01, time/batch = 0.2632s	
679/2700 (epoch 12.574), train_loss = 1.94664289, grad/param norm = 1.8123e-01, time/batch = 0.2850s	
680/2700 (epoch 12.593), train_loss = 1.96545740, grad/param norm = 1.9470e-01, time/batch = 0.2677s	
681/2700 (epoch 12.611), train_loss = 1.87784681, grad/param norm = 1.9054e-01, time/batch = 0.3382s	
682/2700 (epoch 12.630), train_loss = 1.91303443, grad/param norm = 2.1298e-01, time/batch = 0.3360s	
683/2700 (epoch 12.648), train_loss = 1.95471422, grad/param norm = 1.9419e-01, time/batch = 0.3182s	
684/2700 (epoch 12.667), train_loss = 1.91809464, grad/param norm = 2.1731e-01, time/batch = 0.2901s	
685/2700 (epoch 12.685), train_loss = 1.96817796, grad/param norm = 2.4262e-01, time/batch = 0.2645s	
686/2700 (epoch 12.704), train_loss = 1.97699996, grad/param norm = 2.5827e-01, time/batch = 0.2606s	
687/2700 (epoch 12.722), train_loss = 1.93487705, grad/param norm = 2.2213e-01, time/batch = 0.2717s	
688/2700 (epoch 12.741), train_loss = 1.98989374, grad/param norm = 2.1199e-01, time/batch = 0.2877s	
689/2700 (epoch 12.759), train_loss = 2.01980401, grad/param norm = 2.9722e-01, time/batch = 0.2375s	
690/2700 (epoch 12.778), train_loss = 2.01535545, grad/param norm = 3.7031e-01, time/batch = 0.2900s	
691/2700 (epoch 12.796), train_loss = 2.00384161, grad/param norm = 3.7764e-01, time/batch = 0.3122s	
692/2700 (epoch 12.815), train_loss = 2.00981554, grad/param norm = 2.8855e-01, time/batch = 0.3205s	
693/2700 (epoch 12.833), train_loss = 1.95153052, grad/param norm = 2.3515e-01, time/batch = 0.3214s	
694/2700 (epoch 12.852), train_loss = 1.96673582, grad/param norm = 2.3454e-01, time/batch = 0.2985s	
695/2700 (epoch 12.870), train_loss = 1.95101437, grad/param norm = 2.3633e-01, time/batch = 0.2821s	
696/2700 (epoch 12.889), train_loss = 1.97320553, grad/param norm = 2.1931e-01, time/batch = 0.2902s	
697/2700 (epoch 12.907), train_loss = 2.06474203, grad/param norm = 2.0584e-01, time/batch = 0.2776s	
698/2700 (epoch 12.926), train_loss = 2.02144711, grad/param norm = 1.9704e-01, time/batch = 0.2639s	
699/2700 (epoch 12.944), train_loss = 1.98219376, grad/param norm = 1.8344e-01, time/batch = 0.2555s	
700/2700 (epoch 12.963), train_loss = 2.01278124, grad/param norm = 1.6823e-01, time/batch = 0.2413s	
701/2700 (epoch 12.981), train_loss = 1.98042437, grad/param norm = 1.4379e-01, time/batch = 0.3141s	
decayed learning rate by a factor 0.97 to 0.00177058562	
702/2700 (epoch 13.000), train_loss = 1.99793566, grad/param norm = 1.6075e-01, time/batch = 0.3325s	
703/2700 (epoch 13.019), train_loss = 2.01647756, grad/param norm = 1.8067e-01, time/batch = 0.3364s	
704/2700 (epoch 13.037), train_loss = 2.00155318, grad/param norm = 1.9372e-01, time/batch = 0.3318s	
705/2700 (epoch 13.056), train_loss = 1.96635736, grad/param norm = 2.1606e-01, time/batch = 0.2806s	
706/2700 (epoch 13.074), train_loss = 1.91660963, grad/param norm = 1.7210e-01, time/batch = 0.3199s	
707/2700 (epoch 13.093), train_loss = 1.93230173, grad/param norm = 1.5173e-01, time/batch = 0.3343s	
708/2700 (epoch 13.111), train_loss = 1.89026641, grad/param norm = 1.7360e-01, time/batch = 0.3367s	
709/2700 (epoch 13.130), train_loss = 1.97728324, grad/param norm = 2.6091e-01, time/batch = 0.3369s	
710/2700 (epoch 13.148), train_loss = 1.91419019, grad/param norm = 3.0559e-01, time/batch = 0.3271s	
711/2700 (epoch 13.167), train_loss = 1.99936788, grad/param norm = 2.6810e-01, time/batch = 0.3241s	
712/2700 (epoch 13.185), train_loss = 1.91096546, grad/param norm = 2.1744e-01, time/batch = 0.3288s	
713/2700 (epoch 13.204), train_loss = 1.96330574, grad/param norm = 2.0711e-01, time/batch = 0.3295s	
714/2700 (epoch 13.222), train_loss = 1.89785152, grad/param norm = 1.7487e-01, time/batch = 0.3213s	
715/2700 (epoch 13.241), train_loss = 1.82975697, grad/param norm = 1.6154e-01, time/batch = 0.2970s	
716/2700 (epoch 13.259), train_loss = 1.87141153, grad/param norm = 1.8178e-01, time/batch = 0.2404s	
717/2700 (epoch 13.278), train_loss = 1.94531607, grad/param norm = 1.7070e-01, time/batch = 0.2972s	
718/2700 (epoch 13.296), train_loss = 1.93729639, grad/param norm = 1.7759e-01, time/batch = 0.3006s	
719/2700 (epoch 13.315), train_loss = 1.94545522, grad/param norm = 1.9499e-01, time/batch = 0.2978s	
720/2700 (epoch 13.333), train_loss = 1.94785499, grad/param norm = 1.8015e-01, time/batch = 0.2704s	
721/2700 (epoch 13.352), train_loss = 1.94364722, grad/param norm = 2.0069e-01, time/batch = 0.2246s	
722/2700 (epoch 13.370), train_loss = 1.97441540, grad/param norm = 2.2535e-01, time/batch = 0.2775s	
723/2700 (epoch 13.389), train_loss = 1.95580297, grad/param norm = 2.1136e-01, time/batch = 0.2742s	
724/2700 (epoch 13.407), train_loss = 1.95919915, grad/param norm = 2.1392e-01, time/batch = 0.2704s	
725/2700 (epoch 13.426), train_loss = 1.99995952, grad/param norm = 2.3259e-01, time/batch = 0.2643s	
726/2700 (epoch 13.444), train_loss = 1.90190426, grad/param norm = 3.3870e-01, time/batch = 0.2829s	
727/2700 (epoch 13.463), train_loss = 2.00464811, grad/param norm = 3.5699e-01, time/batch = 0.3118s	
728/2700 (epoch 13.481), train_loss = 2.00455447, grad/param norm = 2.8666e-01, time/batch = 0.3130s	
729/2700 (epoch 13.500), train_loss = 1.95471344, grad/param norm = 2.6859e-01, time/batch = 0.2952s	
730/2700 (epoch 13.519), train_loss = 1.94301927, grad/param norm = 2.0440e-01, time/batch = 0.2930s	
731/2700 (epoch 13.537), train_loss = 1.95742856, grad/param norm = 1.6905e-01, time/batch = 0.2787s	
732/2700 (epoch 13.556), train_loss = 1.91829064, grad/param norm = 1.5519e-01, time/batch = 0.2866s	
733/2700 (epoch 13.574), train_loss = 1.90506863, grad/param norm = 1.6976e-01, time/batch = 0.3128s	
734/2700 (epoch 13.593), train_loss = 1.92233531, grad/param norm = 1.8716e-01, time/batch = 0.3036s	
735/2700 (epoch 13.611), train_loss = 1.83990693, grad/param norm = 2.1690e-01, time/batch = 0.2947s	
736/2700 (epoch 13.630), train_loss = 1.88229345, grad/param norm = 2.3762e-01, time/batch = 0.2402s	
737/2700 (epoch 13.648), train_loss = 1.91667465, grad/param norm = 2.0381e-01, time/batch = 0.2589s	
738/2700 (epoch 13.667), train_loss = 1.87600471, grad/param norm = 1.9906e-01, time/batch = 0.3076s	
739/2700 (epoch 13.685), train_loss = 1.92131424, grad/param norm = 2.1130e-01, time/batch = 0.3182s	
740/2700 (epoch 13.704), train_loss = 1.93163494, grad/param norm = 2.2510e-01, time/batch = 0.3167s	
741/2700 (epoch 13.722), train_loss = 1.89280790, grad/param norm = 1.9913e-01, time/batch = 0.2542s	
742/2700 (epoch 13.741), train_loss = 1.94006628, grad/param norm = 1.6283e-01, time/batch = 0.2693s	
743/2700 (epoch 13.759), train_loss = 1.95994029, grad/param norm = 1.7167e-01, time/batch = 0.2900s	
744/2700 (epoch 13.778), train_loss = 1.95265067, grad/param norm = 1.7421e-01, time/batch = 0.3294s	
745/2700 (epoch 13.796), train_loss = 1.91962466, grad/param norm = 1.9061e-01, time/batch = 0.3378s	
746/2700 (epoch 13.815), train_loss = 1.95182331, grad/param norm = 1.9210e-01, time/batch = 0.3393s	
747/2700 (epoch 13.833), train_loss = 1.90999051, grad/param norm = 2.0213e-01, time/batch = 0.3370s	
748/2700 (epoch 13.852), train_loss = 1.91830808, grad/param norm = 1.8347e-01, time/batch = 0.3276s	
749/2700 (epoch 13.870), train_loss = 1.90678694, grad/param norm = 1.9022e-01, time/batch = 0.3174s	
750/2700 (epoch 13.889), train_loss = 1.93487094, grad/param norm = 2.4882e-01, time/batch = 0.2864s	
751/2700 (epoch 13.907), train_loss = 2.04716858, grad/param norm = 3.1667e-01, time/batch = 0.3065s	
752/2700 (epoch 13.926), train_loss = 2.00012796, grad/param norm = 3.0620e-01, time/batch = 0.2710s	
753/2700 (epoch 13.944), train_loss = 1.95776841, grad/param norm = 2.6787e-01, time/batch = 0.2987s	
754/2700 (epoch 13.963), train_loss = 1.98102758, grad/param norm = 2.3535e-01, time/batch = 0.2756s	
755/2700 (epoch 13.981), train_loss = 1.94696419, grad/param norm = 1.9854e-01, time/batch = 0.2421s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
756/2700 (epoch 14.000), train_loss = 1.96849548, grad/param norm = 1.9628e-01, time/batch = 0.2705s	
757/2700 (epoch 14.019), train_loss = 1.98833046, grad/param norm = 2.1011e-01, time/batch = 0.3074s	
758/2700 (epoch 14.037), train_loss = 1.96530340, grad/param norm = 2.1127e-01, time/batch = 0.3305s	
759/2700 (epoch 14.056), train_loss = 1.92499102, grad/param norm = 2.0567e-01, time/batch = 0.3306s	
760/2700 (epoch 14.074), train_loss = 1.87776264, grad/param norm = 1.5480e-01, time/batch = 0.3315s	
761/2700 (epoch 14.093), train_loss = 1.89176406, grad/param norm = 1.6439e-01, time/batch = 0.2990s	
762/2700 (epoch 14.111), train_loss = 1.85346393, grad/param norm = 1.9167e-01, time/batch = 0.3024s	
763/2700 (epoch 14.130), train_loss = 1.93894633, grad/param norm = 2.6346e-01, time/batch = 0.2824s	
764/2700 (epoch 14.148), train_loss = 1.87405667, grad/param norm = 2.8510e-01, time/batch = 0.2655s	
765/2700 (epoch 14.167), train_loss = 1.96178809, grad/param norm = 2.2708e-01, time/batch = 0.3154s	
766/2700 (epoch 14.185), train_loss = 1.86532301, grad/param norm = 1.7834e-01, time/batch = 0.3114s	
767/2700 (epoch 14.204), train_loss = 1.92484127, grad/param norm = 1.9163e-01, time/batch = 0.2578s	
768/2700 (epoch 14.222), train_loss = 1.86053699, grad/param norm = 1.7552e-01, time/batch = 0.2420s	
769/2700 (epoch 14.241), train_loss = 1.79338500, grad/param norm = 1.6546e-01, time/batch = 0.2884s	
770/2700 (epoch 14.259), train_loss = 1.83526398, grad/param norm = 1.7540e-01, time/batch = 0.2999s	
771/2700 (epoch 14.278), train_loss = 1.90555422, grad/param norm = 1.5922e-01, time/batch = 0.2703s	
772/2700 (epoch 14.296), train_loss = 1.89910018, grad/param norm = 1.6928e-01, time/batch = 0.2846s	
773/2700 (epoch 14.315), train_loss = 1.90936826, grad/param norm = 1.9238e-01, time/batch = 0.2925s	
774/2700 (epoch 14.333), train_loss = 1.90981900, grad/param norm = 1.8032e-01, time/batch = 0.2939s	
775/2700 (epoch 14.352), train_loss = 1.89980130, grad/param norm = 1.8369e-01, time/batch = 0.3027s	
776/2700 (epoch 14.370), train_loss = 1.92764920, grad/param norm = 1.7707e-01, time/batch = 0.3191s	
777/2700 (epoch 14.389), train_loss = 1.90868045, grad/param norm = 1.8153e-01, time/batch = 0.3381s	
778/2700 (epoch 14.407), train_loss = 1.91529167, grad/param norm = 1.7917e-01, time/batch = 0.3234s	
779/2700 (epoch 14.426), train_loss = 1.95564225, grad/param norm = 1.7617e-01, time/batch = 0.2999s	
780/2700 (epoch 14.444), train_loss = 1.85011362, grad/param norm = 2.1467e-01, time/batch = 0.2711s	
781/2700 (epoch 14.463), train_loss = 1.94801707, grad/param norm = 2.5228e-01, time/batch = 0.2827s	
782/2700 (epoch 14.481), train_loss = 1.95612846, grad/param norm = 2.3440e-01, time/batch = 0.2937s	
783/2700 (epoch 14.500), train_loss = 1.91066005, grad/param norm = 2.6893e-01, time/batch = 0.2869s	
784/2700 (epoch 14.519), train_loss = 1.91348695, grad/param norm = 2.3906e-01, time/batch = 0.2721s	
785/2700 (epoch 14.537), train_loss = 1.92298962, grad/param norm = 1.9006e-01, time/batch = 0.2302s	
786/2700 (epoch 14.556), train_loss = 1.87795217, grad/param norm = 1.6639e-01, time/batch = 0.2677s	
787/2700 (epoch 14.574), train_loss = 1.86720758, grad/param norm = 1.6767e-01, time/batch = 0.3161s	
788/2700 (epoch 14.593), train_loss = 1.88438204, grad/param norm = 1.8401e-01, time/batch = 0.3195s	
789/2700 (epoch 14.611), train_loss = 1.80201544, grad/param norm = 2.0592e-01, time/batch = 0.3118s	
790/2700 (epoch 14.630), train_loss = 1.84173727, grad/param norm = 2.2972e-01, time/batch = 0.2913s	
791/2700 (epoch 14.648), train_loss = 1.87893792, grad/param norm = 1.9731e-01, time/batch = 0.2926s	
792/2700 (epoch 14.667), train_loss = 1.83896788, grad/param norm = 1.9319e-01, time/batch = 0.3055s	
793/2700 (epoch 14.685), train_loss = 1.88627072, grad/param norm = 2.0503e-01, time/batch = 0.3202s	
794/2700 (epoch 14.704), train_loss = 1.89582316, grad/param norm = 2.2055e-01, time/batch = 0.3322s	
795/2700 (epoch 14.722), train_loss = 1.85769267, grad/param norm = 1.8765e-01, time/batch = 0.3367s	
796/2700 (epoch 14.741), train_loss = 1.89890279, grad/param norm = 1.5990e-01, time/batch = 0.3061s	
797/2700 (epoch 14.759), train_loss = 1.92194587, grad/param norm = 1.7790e-01, time/batch = 0.2865s	
798/2700 (epoch 14.778), train_loss = 1.91807629, grad/param norm = 1.8707e-01, time/batch = 0.2364s	
799/2700 (epoch 14.796), train_loss = 1.88341630, grad/param norm = 2.0640e-01, time/batch = 0.2644s	
800/2700 (epoch 14.815), train_loss = 1.91970231, grad/param norm = 2.4457e-01, time/batch = 0.2853s	
801/2700 (epoch 14.833), train_loss = 1.88512078, grad/param norm = 2.9190e-01, time/batch = 0.2564s	
802/2700 (epoch 14.852), train_loss = 1.89653832, grad/param norm = 3.2144e-01, time/batch = 0.2583s	
803/2700 (epoch 14.870), train_loss = 1.89645071, grad/param norm = 3.1419e-01, time/batch = 0.3035s	
804/2700 (epoch 14.889), train_loss = 1.90947887, grad/param norm = 2.6460e-01, time/batch = 0.3290s	
805/2700 (epoch 14.907), train_loss = 1.99812293, grad/param norm = 2.2824e-01, time/batch = 0.3365s	
806/2700 (epoch 14.926), train_loss = 1.95022146, grad/param norm = 1.9712e-01, time/batch = 0.3257s	
807/2700 (epoch 14.944), train_loss = 1.90423881, grad/param norm = 1.6949e-01, time/batch = 0.3239s	
808/2700 (epoch 14.963), train_loss = 1.93414677, grad/param norm = 1.5616e-01, time/batch = 0.3383s	
809/2700 (epoch 14.981), train_loss = 1.90718849, grad/param norm = 1.4324e-01, time/batch = 0.3257s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
810/2700 (epoch 15.000), train_loss = 1.92517252, grad/param norm = 1.5353e-01, time/batch = 0.3035s	
811/2700 (epoch 15.019), train_loss = 1.94264590, grad/param norm = 1.6249e-01, time/batch = 0.3256s	
812/2700 (epoch 15.037), train_loss = 1.92526407, grad/param norm = 1.6988e-01, time/batch = 0.2651s	
813/2700 (epoch 15.056), train_loss = 1.88568897, grad/param norm = 1.9388e-01, time/batch = 0.3318s	
814/2700 (epoch 15.074), train_loss = 1.84403193, grad/param norm = 1.7962e-01, time/batch = 0.3387s	
815/2700 (epoch 15.093), train_loss = 1.85408527, grad/param norm = 1.7654e-01, time/batch = 0.3384s	
816/2700 (epoch 15.111), train_loss = 1.81629217, grad/param norm = 1.8697e-01, time/batch = 0.3222s	
817/2700 (epoch 15.130), train_loss = 1.89973879, grad/param norm = 2.0934e-01, time/batch = 0.2927s	
818/2700 (epoch 15.148), train_loss = 1.83019543, grad/param norm = 2.0458e-01, time/batch = 0.2440s	
819/2700 (epoch 15.167), train_loss = 1.92472888, grad/param norm = 1.7784e-01, time/batch = 0.2627s	
820/2700 (epoch 15.185), train_loss = 1.82293843, grad/param norm = 1.3883e-01, time/batch = 0.2918s	
821/2700 (epoch 15.204), train_loss = 1.88709333, grad/param norm = 1.6491e-01, time/batch = 0.2695s	
822/2700 (epoch 15.222), train_loss = 1.82758951, grad/param norm = 1.9329e-01, time/batch = 0.2833s	
823/2700 (epoch 15.241), train_loss = 1.77057804, grad/param norm = 2.3544e-01, time/batch = 0.2888s	
824/2700 (epoch 15.259), train_loss = 1.81982544, grad/param norm = 2.4680e-01, time/batch = 0.2847s	
825/2700 (epoch 15.278), train_loss = 1.88686185, grad/param norm = 2.3555e-01, time/batch = 0.3376s	
826/2700 (epoch 15.296), train_loss = 1.87630517, grad/param norm = 2.1369e-01, time/batch = 0.3370s	
827/2700 (epoch 15.315), train_loss = 1.87855691, grad/param norm = 1.8872e-01, time/batch = 0.3260s	
828/2700 (epoch 15.333), train_loss = 1.88281650, grad/param norm = 2.1644e-01, time/batch = 0.3257s	
829/2700 (epoch 15.352), train_loss = 1.86935069, grad/param norm = 2.2620e-01, time/batch = 0.3370s	
830/2700 (epoch 15.370), train_loss = 1.89605304, grad/param norm = 2.0945e-01, time/batch = 0.3265s	
831/2700 (epoch 15.389), train_loss = 1.87200512, grad/param norm = 2.0443e-01, time/batch = 0.3425s	
832/2700 (epoch 15.407), train_loss = 1.88327058, grad/param norm = 1.9577e-01, time/batch = 0.3321s	
833/2700 (epoch 15.426), train_loss = 1.92287769, grad/param norm = 1.7738e-01, time/batch = 0.3117s	
834/2700 (epoch 15.444), train_loss = 1.80916721, grad/param norm = 1.5876e-01, time/batch = 0.2906s	
835/2700 (epoch 15.463), train_loss = 1.90251045, grad/param norm = 1.8504e-01, time/batch = 0.2883s	
836/2700 (epoch 15.481), train_loss = 1.91093542, grad/param norm = 1.5735e-01, time/batch = 0.3373s	
837/2700 (epoch 15.500), train_loss = 1.85866508, grad/param norm = 1.8579e-01, time/batch = 0.3348s	
838/2700 (epoch 15.519), train_loss = 1.87427075, grad/param norm = 1.8338e-01, time/batch = 0.3102s	
839/2700 (epoch 15.537), train_loss = 1.88594192, grad/param norm = 1.7700e-01, time/batch = 0.2945s	
840/2700 (epoch 15.556), train_loss = 1.83932631, grad/param norm = 1.6469e-01, time/batch = 0.2429s	
841/2700 (epoch 15.574), train_loss = 1.83060576, grad/param norm = 1.5005e-01, time/batch = 0.2474s	
842/2700 (epoch 15.593), train_loss = 1.84815747, grad/param norm = 1.7193e-01, time/batch = 0.2626s	
843/2700 (epoch 15.611), train_loss = 1.76448120, grad/param norm = 1.8335e-01, time/batch = 0.2927s	
844/2700 (epoch 15.630), train_loss = 1.80199078, grad/param norm = 2.0545e-01, time/batch = 0.3007s	
845/2700 (epoch 15.648), train_loss = 1.84432656, grad/param norm = 2.0135e-01, time/batch = 0.3040s	
846/2700 (epoch 15.667), train_loss = 1.80644022, grad/param norm = 1.9995e-01, time/batch = 0.2968s	
847/2700 (epoch 15.685), train_loss = 1.85599521, grad/param norm = 2.3914e-01, time/batch = 0.2968s	
848/2700 (epoch 15.704), train_loss = 1.87064396, grad/param norm = 2.8587e-01, time/batch = 0.3298s	
849/2700 (epoch 15.722), train_loss = 1.84150810, grad/param norm = 2.8651e-01, time/batch = 0.3245s	
850/2700 (epoch 15.741), train_loss = 1.87357769, grad/param norm = 2.2298e-01, time/batch = 0.3382s	
851/2700 (epoch 15.759), train_loss = 1.88961913, grad/param norm = 1.8358e-01, time/batch = 0.3393s	
852/2700 (epoch 15.778), train_loss = 1.88339895, grad/param norm = 1.6932e-01, time/batch = 0.3356s	
853/2700 (epoch 15.796), train_loss = 1.84451042, grad/param norm = 2.0708e-01, time/batch = 0.3371s	
854/2700 (epoch 15.815), train_loss = 1.88666332, grad/param norm = 2.0833e-01, time/batch = 0.3341s	
855/2700 (epoch 15.833), train_loss = 1.84087661, grad/param norm = 1.9544e-01, time/batch = 0.3271s	
856/2700 (epoch 15.852), train_loss = 1.83970123, grad/param norm = 1.8885e-01, time/batch = 0.3112s	
857/2700 (epoch 15.870), train_loss = 1.84488159, grad/param norm = 2.1992e-01, time/batch = 0.2914s	
858/2700 (epoch 15.889), train_loss = 1.86954576, grad/param norm = 2.3279e-01, time/batch = 0.2938s	
859/2700 (epoch 15.907), train_loss = 1.96820738, grad/param norm = 2.7319e-01, time/batch = 0.3051s	
860/2700 (epoch 15.926), train_loss = 1.93364185, grad/param norm = 2.6271e-01, time/batch = 0.3019s	
861/2700 (epoch 15.944), train_loss = 1.87374537, grad/param norm = 2.0587e-01, time/batch = 0.3382s	
862/2700 (epoch 15.963), train_loss = 1.90240228, grad/param norm = 1.6507e-01, time/batch = 0.3384s	
863/2700 (epoch 15.981), train_loss = 1.87720484, grad/param norm = 1.6999e-01, time/batch = 0.3261s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
864/2700 (epoch 16.000), train_loss = 1.89365306, grad/param norm = 1.6492e-01, time/batch = 0.3010s	
865/2700 (epoch 16.019), train_loss = 1.90958105, grad/param norm = 1.6726e-01, time/batch = 0.2818s	
866/2700 (epoch 16.037), train_loss = 1.89193102, grad/param norm = 1.7668e-01, time/batch = 0.2705s	
867/2700 (epoch 16.056), train_loss = 1.85561692, grad/param norm = 2.0842e-01, time/batch = 0.2665s	
868/2700 (epoch 16.074), train_loss = 1.81608862, grad/param norm = 1.9919e-01, time/batch = 0.2690s	
869/2700 (epoch 16.093), train_loss = 1.81726055, grad/param norm = 1.7494e-01, time/batch = 0.2579s	
870/2700 (epoch 16.111), train_loss = 1.78126583, grad/param norm = 1.6739e-01, time/batch = 0.2561s	
871/2700 (epoch 16.130), train_loss = 1.86516866, grad/param norm = 2.0505e-01, time/batch = 0.3342s	
872/2700 (epoch 16.148), train_loss = 1.79675073, grad/param norm = 2.0362e-01, time/batch = 0.3392s	
873/2700 (epoch 16.167), train_loss = 1.89444320, grad/param norm = 1.6876e-01, time/batch = 0.3336s	
874/2700 (epoch 16.185), train_loss = 1.79210130, grad/param norm = 1.5330e-01, time/batch = 0.3360s	
875/2700 (epoch 16.204), train_loss = 1.85978858, grad/param norm = 1.8345e-01, time/batch = 0.3264s	
876/2700 (epoch 16.222), train_loss = 1.79497796, grad/param norm = 1.7003e-01, time/batch = 0.3062s	
877/2700 (epoch 16.241), train_loss = 1.73021101, grad/param norm = 1.6699e-01, time/batch = 0.2959s	
878/2700 (epoch 16.259), train_loss = 1.77319118, grad/param norm = 1.6941e-01, time/batch = 0.3167s	
879/2700 (epoch 16.278), train_loss = 1.84191575, grad/param norm = 1.6589e-01, time/batch = 0.3291s	
880/2700 (epoch 16.296), train_loss = 1.83567246, grad/param norm = 1.7574e-01, time/batch = 0.2986s	
881/2700 (epoch 16.315), train_loss = 1.84538676, grad/param norm = 1.8357e-01, time/batch = 0.3212s	
882/2700 (epoch 16.333), train_loss = 1.83999711, grad/param norm = 1.7044e-01, time/batch = 0.3248s	
883/2700 (epoch 16.352), train_loss = 1.82768076, grad/param norm = 1.6322e-01, time/batch = 0.3074s	
884/2700 (epoch 16.370), train_loss = 1.85589567, grad/param norm = 1.6125e-01, time/batch = 0.2891s	
885/2700 (epoch 16.389), train_loss = 1.83540190, grad/param norm = 1.8425e-01, time/batch = 0.2920s	
886/2700 (epoch 16.407), train_loss = 1.84982842, grad/param norm = 1.9960e-01, time/batch = 0.2822s	
887/2700 (epoch 16.426), train_loss = 1.89785963, grad/param norm = 2.0629e-01, time/batch = 0.2695s	
888/2700 (epoch 16.444), train_loss = 1.79244293, grad/param norm = 2.7830e-01, time/batch = 0.2532s	
889/2700 (epoch 16.463), train_loss = 1.89606768, grad/param norm = 2.8988e-01, time/batch = 0.2703s	
890/2700 (epoch 16.481), train_loss = 1.89538460, grad/param norm = 2.4967e-01, time/batch = 0.2968s	
891/2700 (epoch 16.500), train_loss = 1.83705800, grad/param norm = 2.5036e-01, time/batch = 0.2797s	
892/2700 (epoch 16.519), train_loss = 1.84669643, grad/param norm = 1.8960e-01, time/batch = 0.3288s	
893/2700 (epoch 16.537), train_loss = 1.85356951, grad/param norm = 1.6743e-01, time/batch = 0.3258s	
894/2700 (epoch 16.556), train_loss = 1.80415183, grad/param norm = 1.6179e-01, time/batch = 0.2973s	
895/2700 (epoch 16.574), train_loss = 1.80221312, grad/param norm = 1.7267e-01, time/batch = 0.3010s	
896/2700 (epoch 16.593), train_loss = 1.81783065, grad/param norm = 1.9104e-01, time/batch = 0.3146s	
897/2700 (epoch 16.611), train_loss = 1.73287457, grad/param norm = 1.9600e-01, time/batch = 0.3307s	
898/2700 (epoch 16.630), train_loss = 1.76885408, grad/param norm = 1.9328e-01, time/batch = 0.3359s	
899/2700 (epoch 16.648), train_loss = 1.80510112, grad/param norm = 1.6276e-01, time/batch = 0.3379s	
900/2700 (epoch 16.667), train_loss = 1.77124923, grad/param norm = 1.5019e-01, time/batch = 0.3291s	
901/2700 (epoch 16.685), train_loss = 1.81633277, grad/param norm = 1.6934e-01, time/batch = 0.3293s	
902/2700 (epoch 16.704), train_loss = 1.82815176, grad/param norm = 1.9701e-01, time/batch = 0.3376s	
903/2700 (epoch 16.722), train_loss = 1.79498562, grad/param norm = 1.7365e-01, time/batch = 0.3312s	
904/2700 (epoch 16.741), train_loss = 1.82908493, grad/param norm = 1.6547e-01, time/batch = 0.3189s	
905/2700 (epoch 16.759), train_loss = 1.85644659, grad/param norm = 1.8424e-01, time/batch = 0.2502s	
906/2700 (epoch 16.778), train_loss = 1.85637037, grad/param norm = 1.8603e-01, time/batch = 0.3139s	
907/2700 (epoch 16.796), train_loss = 1.81125747, grad/param norm = 1.9327e-01, time/batch = 0.2886s	
908/2700 (epoch 16.815), train_loss = 1.85299449, grad/param norm = 2.1139e-01, time/batch = 0.2391s	
909/2700 (epoch 16.833), train_loss = 1.81098755, grad/param norm = 2.0990e-01, time/batch = 0.2631s	
910/2700 (epoch 16.852), train_loss = 1.80610507, grad/param norm = 2.0256e-01, time/batch = 0.3030s	
911/2700 (epoch 16.870), train_loss = 1.81625013, grad/param norm = 2.1735e-01, time/batch = 0.2743s	
912/2700 (epoch 16.889), train_loss = 1.83730110, grad/param norm = 2.1900e-01, time/batch = 0.3139s	
913/2700 (epoch 16.907), train_loss = 1.93227714, grad/param norm = 2.4087e-01, time/batch = 0.3348s	
914/2700 (epoch 16.926), train_loss = 1.89732826, grad/param norm = 2.3839e-01, time/batch = 0.3268s	
915/2700 (epoch 16.944), train_loss = 1.84770331, grad/param norm = 2.1504e-01, time/batch = 0.3044s	
916/2700 (epoch 16.963), train_loss = 1.87394012, grad/param norm = 1.9487e-01, time/batch = 0.2945s	
917/2700 (epoch 16.981), train_loss = 1.84341523, grad/param norm = 1.5387e-01, time/batch = 0.2982s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
918/2700 (epoch 17.000), train_loss = 1.86482867, grad/param norm = 1.6828e-01, time/batch = 0.3375s	
919/2700 (epoch 17.019), train_loss = 1.88484439, grad/param norm = 1.8842e-01, time/batch = 0.3374s	
920/2700 (epoch 17.037), train_loss = 1.86485999, grad/param norm = 1.8667e-01, time/batch = 0.3342s	
921/2700 (epoch 17.056), train_loss = 1.82265742, grad/param norm = 1.8753e-01, time/batch = 0.3233s	
922/2700 (epoch 17.074), train_loss = 1.78301961, grad/param norm = 1.6055e-01, time/batch = 0.3267s	
923/2700 (epoch 17.093), train_loss = 1.78412595, grad/param norm = 1.6311e-01, time/batch = 0.3276s	
924/2700 (epoch 17.111), train_loss = 1.75459418, grad/param norm = 1.8072e-01, time/batch = 0.3014s	
925/2700 (epoch 17.130), train_loss = 1.83676806, grad/param norm = 2.2643e-01, time/batch = 0.3019s	
926/2700 (epoch 17.148), train_loss = 1.77267569, grad/param norm = 2.4075e-01, time/batch = 0.3148s	
927/2700 (epoch 17.167), train_loss = 1.86891366, grad/param norm = 1.8199e-01, time/batch = 0.3186s	
928/2700 (epoch 17.185), train_loss = 1.76144792, grad/param norm = 1.4232e-01, time/batch = 0.3093s	
929/2700 (epoch 17.204), train_loss = 1.82847781, grad/param norm = 1.6868e-01, time/batch = 0.2293s	
930/2700 (epoch 17.222), train_loss = 1.76336240, grad/param norm = 1.5131e-01, time/batch = 0.2670s	
931/2700 (epoch 17.241), train_loss = 1.70011212, grad/param norm = 1.5867e-01, time/batch = 0.2695s	
932/2700 (epoch 17.259), train_loss = 1.74517999, grad/param norm = 1.6705e-01, time/batch = 0.2449s	
933/2700 (epoch 17.278), train_loss = 1.81515295, grad/param norm = 1.7597e-01, time/batch = 0.2671s	
934/2700 (epoch 17.296), train_loss = 1.80696611, grad/param norm = 1.7612e-01, time/batch = 0.3020s	
935/2700 (epoch 17.315), train_loss = 1.81627295, grad/param norm = 1.7291e-01, time/batch = 0.3175s	
936/2700 (epoch 17.333), train_loss = 1.81644629, grad/param norm = 2.0430e-01, time/batch = 0.3326s	
937/2700 (epoch 17.352), train_loss = 1.80712261, grad/param norm = 2.2723e-01, time/batch = 0.3367s	
938/2700 (epoch 17.370), train_loss = 1.83699014, grad/param norm = 2.3376e-01, time/batch = 0.3388s	
939/2700 (epoch 17.389), train_loss = 1.81345621, grad/param norm = 2.3019e-01, time/batch = 0.3335s	
940/2700 (epoch 17.407), train_loss = 1.82201745, grad/param norm = 1.9697e-01, time/batch = 0.3155s	
941/2700 (epoch 17.426), train_loss = 1.86538239, grad/param norm = 1.6736e-01, time/batch = 0.2810s	
942/2700 (epoch 17.444), train_loss = 1.75269416, grad/param norm = 1.6985e-01, time/batch = 0.3132s	
943/2700 (epoch 17.463), train_loss = 1.84736663, grad/param norm = 1.8591e-01, time/batch = 0.3183s	
944/2700 (epoch 17.481), train_loss = 1.85156307, grad/param norm = 1.6158e-01, time/batch = 0.3352s	
945/2700 (epoch 17.500), train_loss = 1.79332922, grad/param norm = 1.7805e-01, time/batch = 0.3383s	
946/2700 (epoch 17.519), train_loss = 1.82009599, grad/param norm = 1.6457e-01, time/batch = 0.3396s	
947/2700 (epoch 17.537), train_loss = 1.82525815, grad/param norm = 1.6679e-01, time/batch = 0.3304s	
948/2700 (epoch 17.556), train_loss = 1.77230686, grad/param norm = 1.5843e-01, time/batch = 0.3066s	
949/2700 (epoch 17.574), train_loss = 1.77270625, grad/param norm = 1.6997e-01, time/batch = 0.2845s	
950/2700 (epoch 17.593), train_loss = 1.79181392, grad/param norm = 2.1707e-01, time/batch = 0.2686s	
951/2700 (epoch 17.611), train_loss = 1.71103800, grad/param norm = 2.4063e-01, time/batch = 0.2860s	
952/2700 (epoch 17.630), train_loss = 1.74472083, grad/param norm = 2.1860e-01, time/batch = 0.2830s	
953/2700 (epoch 17.648), train_loss = 1.77876284, grad/param norm = 1.9050e-01, time/batch = 0.2540s	
954/2700 (epoch 17.667), train_loss = 1.74745965, grad/param norm = 1.7822e-01, time/batch = 0.2067s	
955/2700 (epoch 17.685), train_loss = 1.79396323, grad/param norm = 2.1662e-01, time/batch = 0.3117s	
956/2700 (epoch 17.704), train_loss = 1.80614186, grad/param norm = 2.3551e-01, time/batch = 0.3002s	
957/2700 (epoch 17.722), train_loss = 1.77213178, grad/param norm = 1.9931e-01, time/batch = 0.2970s	
958/2700 (epoch 17.741), train_loss = 1.79981160, grad/param norm = 1.7309e-01, time/batch = 0.2708s	
959/2700 (epoch 17.759), train_loss = 1.82492993, grad/param norm = 1.7602e-01, time/batch = 0.2738s	
960/2700 (epoch 17.778), train_loss = 1.82569584, grad/param norm = 1.6751e-01, time/batch = 0.2924s	
961/2700 (epoch 17.796), train_loss = 1.77460159, grad/param norm = 1.6699e-01, time/batch = 0.2848s	
962/2700 (epoch 17.815), train_loss = 1.81994546, grad/param norm = 1.6970e-01, time/batch = 0.3160s	
963/2700 (epoch 17.833), train_loss = 1.77434938, grad/param norm = 1.6276e-01, time/batch = 0.3149s	
964/2700 (epoch 17.852), train_loss = 1.76748963, grad/param norm = 1.5593e-01, time/batch = 0.2960s	
965/2700 (epoch 17.870), train_loss = 1.77841148, grad/param norm = 1.4409e-01, time/batch = 0.2339s	
966/2700 (epoch 17.889), train_loss = 1.79727367, grad/param norm = 1.3847e-01, time/batch = 0.2729s	
967/2700 (epoch 17.907), train_loss = 1.89172109, grad/param norm = 1.6928e-01, time/batch = 0.2732s	
968/2700 (epoch 17.926), train_loss = 1.86066206, grad/param norm = 1.8552e-01, time/batch = 0.2768s	
969/2700 (epoch 17.944), train_loss = 1.81532925, grad/param norm = 1.7725e-01, time/batch = 0.2835s	
970/2700 (epoch 17.963), train_loss = 1.84179319, grad/param norm = 1.7299e-01, time/batch = 0.2833s	
971/2700 (epoch 17.981), train_loss = 1.81313916, grad/param norm = 1.6347e-01, time/batch = 0.2783s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
972/2700 (epoch 18.000), train_loss = 1.83859339, grad/param norm = 1.8196e-01, time/batch = 0.3062s	
973/2700 (epoch 18.019), train_loss = 1.85981784, grad/param norm = 1.9164e-01, time/batch = 0.3274s	
974/2700 (epoch 18.037), train_loss = 1.83789036, grad/param norm = 1.9143e-01, time/batch = 0.3262s	
975/2700 (epoch 18.056), train_loss = 1.79153857, grad/param norm = 1.7484e-01, time/batch = 0.3205s	
976/2700 (epoch 18.074), train_loss = 1.75502382, grad/param norm = 1.5775e-01, time/batch = 0.3026s	
977/2700 (epoch 18.093), train_loss = 1.75386125, grad/param norm = 1.6760e-01, time/batch = 0.2535s	
978/2700 (epoch 18.111), train_loss = 1.73302239, grad/param norm = 2.0521e-01, time/batch = 0.2653s	
979/2700 (epoch 18.130), train_loss = 1.81869975, grad/param norm = 2.9023e-01, time/batch = 0.2620s	
980/2700 (epoch 18.148), train_loss = 1.75498970, grad/param norm = 2.9949e-01, time/batch = 0.2832s	
981/2700 (epoch 18.167), train_loss = 1.84470064, grad/param norm = 1.9241e-01, time/batch = 0.2684s	
982/2700 (epoch 18.185), train_loss = 1.73608100, grad/param norm = 1.5247e-01, time/batch = 0.2658s	
983/2700 (epoch 18.204), train_loss = 1.79845357, grad/param norm = 1.6374e-01, time/batch = 0.2987s	
984/2700 (epoch 18.222), train_loss = 1.73715622, grad/param norm = 1.5035e-01, time/batch = 0.3177s	
985/2700 (epoch 18.241), train_loss = 1.67457099, grad/param norm = 1.5838e-01, time/batch = 0.3264s	
986/2700 (epoch 18.259), train_loss = 1.71867022, grad/param norm = 1.6637e-01, time/batch = 0.3239s	
987/2700 (epoch 18.278), train_loss = 1.78864902, grad/param norm = 1.7287e-01, time/batch = 0.3008s	
988/2700 (epoch 18.296), train_loss = 1.77907212, grad/param norm = 1.7310e-01, time/batch = 0.3067s	
989/2700 (epoch 18.315), train_loss = 1.78730672, grad/param norm = 1.8409e-01, time/batch = 0.2313s	
990/2700 (epoch 18.333), train_loss = 1.78147846, grad/param norm = 1.7713e-01, time/batch = 0.2676s	
991/2700 (epoch 18.352), train_loss = 1.76711987, grad/param norm = 1.5834e-01, time/batch = 0.3009s	
992/2700 (epoch 18.370), train_loss = 1.79344699, grad/param norm = 1.5565e-01, time/batch = 0.2802s	
993/2700 (epoch 18.389), train_loss = 1.77139797, grad/param norm = 1.7596e-01, time/batch = 0.2461s	
994/2700 (epoch 18.407), train_loss = 1.79173154, grad/param norm = 1.7845e-01, time/batch = 0.2608s	
995/2700 (epoch 18.426), train_loss = 1.84147641, grad/param norm = 1.8082e-01, time/batch = 0.3063s	
996/2700 (epoch 18.444), train_loss = 1.73530059, grad/param norm = 2.3240e-01, time/batch = 0.3158s	
997/2700 (epoch 18.463), train_loss = 1.83256329, grad/param norm = 2.3755e-01, time/batch = 0.3272s	
998/2700 (epoch 18.481), train_loss = 1.83114685, grad/param norm = 2.0764e-01, time/batch = 0.3169s	
999/2700 (epoch 18.500), train_loss = 1.76895520, grad/param norm = 2.2186e-01, time/batch = 0.3327s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch18.52_1.8710.t7	
1000/2700 (epoch 18.519), train_loss = 1.79746143, grad/param norm = 1.8717e-01, time/batch = 0.3218s	
1001/2700 (epoch 18.537), train_loss = 1.89560085, grad/param norm = 1.8237e-01, time/batch = 0.2712s	
1002/2700 (epoch 18.556), train_loss = 1.74927647, grad/param norm = 1.8387e-01, time/batch = 0.3088s	
1003/2700 (epoch 18.574), train_loss = 1.74729425, grad/param norm = 1.7543e-01, time/batch = 0.3276s	
1004/2700 (epoch 18.593), train_loss = 1.75907968, grad/param norm = 1.8240e-01, time/batch = 0.3203s	
1005/2700 (epoch 18.611), train_loss = 1.67594059, grad/param norm = 1.8222e-01, time/batch = 0.3324s	
1006/2700 (epoch 18.630), train_loss = 1.70987669, grad/param norm = 1.7679e-01, time/batch = 0.3148s	
1007/2700 (epoch 18.648), train_loss = 1.74845978, grad/param norm = 1.6411e-01, time/batch = 0.3089s	
1008/2700 (epoch 18.667), train_loss = 1.72201691, grad/param norm = 1.9038e-01, time/batch = 0.2943s	
1009/2700 (epoch 18.685), train_loss = 1.77344927, grad/param norm = 2.1153e-01, time/batch = 0.3136s	
1010/2700 (epoch 18.704), train_loss = 1.78032436, grad/param norm = 2.1918e-01, time/batch = 0.3059s	
1011/2700 (epoch 18.722), train_loss = 1.74486850, grad/param norm = 1.7529e-01, time/batch = 0.3399s	
1012/2700 (epoch 18.741), train_loss = 1.77217227, grad/param norm = 1.8415e-01, time/batch = 0.3409s	
1013/2700 (epoch 18.759), train_loss = 1.79933597, grad/param norm = 2.0517e-01, time/batch = 0.3384s	
1014/2700 (epoch 18.778), train_loss = 1.80594117, grad/param norm = 2.1230e-01, time/batch = 0.3249s	
1015/2700 (epoch 18.796), train_loss = 1.75418175, grad/param norm = 2.0483e-01, time/batch = 0.3090s	
1016/2700 (epoch 18.815), train_loss = 1.79717162, grad/param norm = 2.0709e-01, time/batch = 0.2784s	
1017/2700 (epoch 18.833), train_loss = 1.75244534, grad/param norm = 2.1208e-01, time/batch = 0.2507s	
1018/2700 (epoch 18.852), train_loss = 1.74910276, grad/param norm = 2.2844e-01, time/batch = 0.2720s	
1019/2700 (epoch 18.870), train_loss = 1.76089212, grad/param norm = 2.0433e-01, time/batch = 0.2862s	
1020/2700 (epoch 18.889), train_loss = 1.77506997, grad/param norm = 1.6582e-01, time/batch = 0.2901s	
1021/2700 (epoch 18.907), train_loss = 1.86562286, grad/param norm = 1.7212e-01, time/batch = 0.2725s	
1022/2700 (epoch 18.926), train_loss = 1.83268009, grad/param norm = 1.7545e-01, time/batch = 0.2666s	
1023/2700 (epoch 18.944), train_loss = 1.78511091, grad/param norm = 1.7265e-01, time/batch = 0.3307s	
1024/2700 (epoch 18.963), train_loss = 1.81239926, grad/param norm = 1.6795e-01, time/batch = 0.3332s	
1025/2700 (epoch 18.981), train_loss = 1.78233102, grad/param norm = 1.5359e-01, time/batch = 0.3248s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1026/2700 (epoch 19.000), train_loss = 1.80792756, grad/param norm = 1.6449e-01, time/batch = 0.3317s	
1027/2700 (epoch 19.019), train_loss = 1.83041232, grad/param norm = 1.7035e-01, time/batch = 0.2866s	
1028/2700 (epoch 19.037), train_loss = 1.80686798, grad/param norm = 1.6443e-01, time/batch = 0.2750s	
1029/2700 (epoch 19.056), train_loss = 1.76321402, grad/param norm = 1.6626e-01, time/batch = 0.2816s	
1030/2700 (epoch 19.074), train_loss = 1.73092962, grad/param norm = 1.5779e-01, time/batch = 0.2919s	
1031/2700 (epoch 19.093), train_loss = 1.72537596, grad/param norm = 1.5895e-01, time/batch = 0.3153s	
1032/2700 (epoch 19.111), train_loss = 1.70160630, grad/param norm = 1.7684e-01, time/batch = 0.3031s	
1033/2700 (epoch 19.130), train_loss = 1.77711830, grad/param norm = 1.9398e-01, time/batch = 0.2958s	
1034/2700 (epoch 19.148), train_loss = 1.71156050, grad/param norm = 1.7907e-01, time/batch = 0.2586s	
1035/2700 (epoch 19.167), train_loss = 1.81401363, grad/param norm = 1.6416e-01, time/batch = 0.3028s	
1036/2700 (epoch 19.185), train_loss = 1.71466090, grad/param norm = 2.0186e-01, time/batch = 0.2894s	
1037/2700 (epoch 19.204), train_loss = 1.78060591, grad/param norm = 2.2135e-01, time/batch = 0.3072s	
1038/2700 (epoch 19.222), train_loss = 1.72142149, grad/param norm = 2.0670e-01, time/batch = 0.2941s	
1039/2700 (epoch 19.241), train_loss = 1.65450253, grad/param norm = 1.9510e-01, time/batch = 0.3067s	
1040/2700 (epoch 19.259), train_loss = 1.69446553, grad/param norm = 1.6493e-01, time/batch = 0.2928s	
1041/2700 (epoch 19.278), train_loss = 1.76163786, grad/param norm = 1.6292e-01, time/batch = 0.2884s	
1042/2700 (epoch 19.296), train_loss = 1.75459940, grad/param norm = 1.6579e-01, time/batch = 0.2753s	
1043/2700 (epoch 19.315), train_loss = 1.76228215, grad/param norm = 1.7960e-01, time/batch = 0.2778s	
1044/2700 (epoch 19.333), train_loss = 1.75714763, grad/param norm = 1.8684e-01, time/batch = 0.3018s	
1045/2700 (epoch 19.352), train_loss = 1.74287873, grad/param norm = 1.7269e-01, time/batch = 0.3029s	
1046/2700 (epoch 19.370), train_loss = 1.76598588, grad/param norm = 1.5818e-01, time/batch = 0.2643s	
1047/2700 (epoch 19.389), train_loss = 1.74444102, grad/param norm = 1.7639e-01, time/batch = 0.2822s	
1048/2700 (epoch 19.407), train_loss = 1.76784792, grad/param norm = 1.7156e-01, time/batch = 0.2957s	
1049/2700 (epoch 19.426), train_loss = 1.81427787, grad/param norm = 1.6695e-01, time/batch = 0.2810s	
1050/2700 (epoch 19.444), train_loss = 1.70349383, grad/param norm = 1.6907e-01, time/batch = 0.2860s	
1051/2700 (epoch 19.463), train_loss = 1.79753861, grad/param norm = 1.8901e-01, time/batch = 0.2998s	
1052/2700 (epoch 19.481), train_loss = 1.79932189, grad/param norm = 1.7474e-01, time/batch = 0.2932s	
1053/2700 (epoch 19.500), train_loss = 1.73625962, grad/param norm = 1.8981e-01, time/batch = 0.2545s	
1054/2700 (epoch 19.519), train_loss = 1.77705761, grad/param norm = 1.9938e-01, time/batch = 0.2607s	
1055/2700 (epoch 19.537), train_loss = 1.78443885, grad/param norm = 2.3974e-01, time/batch = 0.2987s	
1056/2700 (epoch 19.556), train_loss = 1.72829652, grad/param norm = 2.2601e-01, time/batch = 0.3182s	
1057/2700 (epoch 19.574), train_loss = 1.73683300, grad/param norm = 2.4374e-01, time/batch = 0.2955s	
1058/2700 (epoch 19.593), train_loss = 1.74985610, grad/param norm = 2.5538e-01, time/batch = 0.2790s	
1059/2700 (epoch 19.611), train_loss = 1.65548744, grad/param norm = 2.0012e-01, time/batch = 0.2964s	
1060/2700 (epoch 19.630), train_loss = 1.68222869, grad/param norm = 1.5346e-01, time/batch = 0.3001s	
1061/2700 (epoch 19.648), train_loss = 1.72058457, grad/param norm = 1.5239e-01, time/batch = 0.3186s	
1062/2700 (epoch 19.667), train_loss = 1.69312284, grad/param norm = 1.6214e-01, time/batch = 0.3327s	
1063/2700 (epoch 19.685), train_loss = 1.74518445, grad/param norm = 2.0924e-01, time/batch = 0.3363s	
1064/2700 (epoch 19.704), train_loss = 1.75323200, grad/param norm = 2.1645e-01, time/batch = 0.3379s	
1065/2700 (epoch 19.722), train_loss = 1.71959155, grad/param norm = 1.6358e-01, time/batch = 0.3260s	
1066/2700 (epoch 19.741), train_loss = 1.74219105, grad/param norm = 1.7215e-01, time/batch = 0.3017s	
1067/2700 (epoch 19.759), train_loss = 1.76829852, grad/param norm = 1.7844e-01, time/batch = 0.2763s	
1068/2700 (epoch 19.778), train_loss = 1.77680184, grad/param norm = 1.6970e-01, time/batch = 0.2296s	
1069/2700 (epoch 19.796), train_loss = 1.71895234, grad/param norm = 1.6397e-01, time/batch = 0.2828s	
1070/2700 (epoch 19.815), train_loss = 1.76732218, grad/param norm = 1.6795e-01, time/batch = 0.2656s	
1071/2700 (epoch 19.833), train_loss = 1.72177727, grad/param norm = 1.5156e-01, time/batch = 0.2433s	
1072/2700 (epoch 19.852), train_loss = 1.70755423, grad/param norm = 1.4737e-01, time/batch = 0.3092s	
1073/2700 (epoch 19.870), train_loss = 1.72673152, grad/param norm = 1.4902e-01, time/batch = 0.3294s	
1074/2700 (epoch 19.889), train_loss = 1.74589283, grad/param norm = 1.6188e-01, time/batch = 0.3358s	
1075/2700 (epoch 19.907), train_loss = 1.84026373, grad/param norm = 2.0153e-01, time/batch = 0.3381s	
1076/2700 (epoch 19.926), train_loss = 1.81215898, grad/param norm = 2.1345e-01, time/batch = 0.3368s	
1077/2700 (epoch 19.944), train_loss = 1.76380804, grad/param norm = 1.9178e-01, time/batch = 0.3339s	
1078/2700 (epoch 19.963), train_loss = 1.78719769, grad/param norm = 1.6421e-01, time/batch = 0.2963s	
1079/2700 (epoch 19.981), train_loss = 1.76119605, grad/param norm = 2.3369e-01, time/batch = 0.2732s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1080/2700 (epoch 20.000), train_loss = 1.78951704, grad/param norm = 1.8769e-01, time/batch = 0.2768s	
1081/2700 (epoch 20.019), train_loss = 1.81243849, grad/param norm = 1.7251e-01, time/batch = 0.2965s	
1082/2700 (epoch 20.037), train_loss = 1.78806915, grad/param norm = 1.9100e-01, time/batch = 0.2976s	
1083/2700 (epoch 20.056), train_loss = 1.74692613, grad/param norm = 2.2058e-01, time/batch = 0.2888s	
1084/2700 (epoch 20.074), train_loss = 1.72156500, grad/param norm = 2.4687e-01, time/batch = 0.2624s	
1085/2700 (epoch 20.093), train_loss = 1.70886027, grad/param norm = 2.0371e-01, time/batch = 0.2624s	
1086/2700 (epoch 20.111), train_loss = 1.67781548, grad/param norm = 1.7710e-01, time/batch = 0.3004s	
1087/2700 (epoch 20.130), train_loss = 1.75376534, grad/param norm = 2.0518e-01, time/batch = 0.3137s	
1088/2700 (epoch 20.148), train_loss = 1.68712064, grad/param norm = 1.7776e-01, time/batch = 0.3176s	
1089/2700 (epoch 20.167), train_loss = 1.78859957, grad/param norm = 1.5353e-01, time/batch = 0.3131s	
1090/2700 (epoch 20.185), train_loss = 1.68442106, grad/param norm = 1.7115e-01, time/batch = 0.3306s	
1091/2700 (epoch 20.204), train_loss = 1.74930179, grad/param norm = 1.8477e-01, time/batch = 0.3185s	
1092/2700 (epoch 20.222), train_loss = 1.69138360, grad/param norm = 1.6690e-01, time/batch = 0.2792s	
1093/2700 (epoch 20.241), train_loss = 1.62595852, grad/param norm = 1.6142e-01, time/batch = 0.2403s	
1094/2700 (epoch 20.259), train_loss = 1.66992338, grad/param norm = 1.5208e-01, time/batch = 0.2922s	
1095/2700 (epoch 20.278), train_loss = 1.73628752, grad/param norm = 1.5524e-01, time/batch = 0.2934s	
1096/2700 (epoch 20.296), train_loss = 1.72735112, grad/param norm = 1.5195e-01, time/batch = 0.2874s	
1097/2700 (epoch 20.315), train_loss = 1.73543884, grad/param norm = 1.5961e-01, time/batch = 0.2937s	
1098/2700 (epoch 20.333), train_loss = 1.72747628, grad/param norm = 1.5500e-01, time/batch = 0.3086s	
1099/2700 (epoch 20.352), train_loss = 1.71697674, grad/param norm = 1.5620e-01, time/batch = 0.3286s	
1100/2700 (epoch 20.370), train_loss = 1.74181521, grad/param norm = 1.7423e-01, time/batch = 0.3041s	
1101/2700 (epoch 20.389), train_loss = 1.71950325, grad/param norm = 1.8508e-01, time/batch = 0.3255s	
1102/2700 (epoch 20.407), train_loss = 1.74243655, grad/param norm = 1.6952e-01, time/batch = 0.3268s	
1103/2700 (epoch 20.426), train_loss = 1.79255117, grad/param norm = 1.6923e-01, time/batch = 0.3054s	
1104/2700 (epoch 20.444), train_loss = 1.68264455, grad/param norm = 1.9045e-01, time/batch = 0.3057s	
1105/2700 (epoch 20.463), train_loss = 1.77521763, grad/param norm = 1.8910e-01, time/batch = 0.2248s	
1106/2700 (epoch 20.481), train_loss = 1.77523092, grad/param norm = 1.8571e-01, time/batch = 0.2758s	
1107/2700 (epoch 20.500), train_loss = 1.71290407, grad/param norm = 2.1073e-01, time/batch = 0.2729s	
1108/2700 (epoch 20.519), train_loss = 1.75001958, grad/param norm = 1.8222e-01, time/batch = 0.2794s	
1109/2700 (epoch 20.537), train_loss = 1.74985122, grad/param norm = 1.7476e-01, time/batch = 0.2769s	
1110/2700 (epoch 20.556), train_loss = 1.68967934, grad/param norm = 1.6562e-01, time/batch = 0.2998s	
1111/2700 (epoch 20.574), train_loss = 1.69559567, grad/param norm = 1.6559e-01, time/batch = 0.2928s	
1112/2700 (epoch 20.593), train_loss = 1.70773517, grad/param norm = 1.6240e-01, time/batch = 0.3105s	
1113/2700 (epoch 20.611), train_loss = 1.62535362, grad/param norm = 1.5019e-01, time/batch = 0.3256s	
1114/2700 (epoch 20.630), train_loss = 1.65783810, grad/param norm = 1.5705e-01, time/batch = 0.3081s	
1115/2700 (epoch 20.648), train_loss = 1.69845072, grad/param norm = 1.5272e-01, time/batch = 0.3296s	
1116/2700 (epoch 20.667), train_loss = 1.66958218, grad/param norm = 1.7004e-01, time/batch = 0.3218s	
1117/2700 (epoch 20.685), train_loss = 1.72223459, grad/param norm = 1.9510e-01, time/batch = 0.2428s	
1118/2700 (epoch 20.704), train_loss = 1.72953538, grad/param norm = 2.0249e-01, time/batch = 0.2844s	
1119/2700 (epoch 20.722), train_loss = 1.69905280, grad/param norm = 1.7514e-01, time/batch = 0.2748s	
1120/2700 (epoch 20.741), train_loss = 1.72108149, grad/param norm = 1.9772e-01, time/batch = 0.2503s	
1121/2700 (epoch 20.759), train_loss = 1.74522851, grad/param norm = 2.2364e-01, time/batch = 0.2324s	
1122/2700 (epoch 20.778), train_loss = 1.76313476, grad/param norm = 2.3646e-01, time/batch = 0.2809s	
1123/2700 (epoch 20.796), train_loss = 1.70257595, grad/param norm = 2.1055e-01, time/batch = 0.3101s	
1124/2700 (epoch 20.815), train_loss = 1.74825279, grad/param norm = 2.0399e-01, time/batch = 0.3235s	
1125/2700 (epoch 20.833), train_loss = 1.70168315, grad/param norm = 1.9249e-01, time/batch = 0.3205s	
1126/2700 (epoch 20.852), train_loss = 1.69072434, grad/param norm = 2.0102e-01, time/batch = 0.2799s	
1127/2700 (epoch 20.870), train_loss = 1.70904566, grad/param norm = 1.8356e-01, time/batch = 0.2506s	
1128/2700 (epoch 20.889), train_loss = 1.72243987, grad/param norm = 1.5860e-01, time/batch = 0.2446s	
1129/2700 (epoch 20.907), train_loss = 1.81076989, grad/param norm = 1.6444e-01, time/batch = 0.2293s	
1130/2700 (epoch 20.926), train_loss = 1.78310767, grad/param norm = 1.8055e-01, time/batch = 0.2598s	
1131/2700 (epoch 20.944), train_loss = 1.74413114, grad/param norm = 2.0852e-01, time/batch = 0.2488s	
1132/2700 (epoch 20.963), train_loss = 1.76616101, grad/param norm = 1.8995e-01, time/batch = 0.2715s	
1133/2700 (epoch 20.981), train_loss = 1.73158921, grad/param norm = 1.6620e-01, time/batch = 0.3209s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1134/2700 (epoch 21.000), train_loss = 1.76210047, grad/param norm = 1.7373e-01, time/batch = 0.3349s	
1135/2700 (epoch 21.019), train_loss = 1.78618086, grad/param norm = 1.7503e-01, time/batch = 0.3349s	
1136/2700 (epoch 21.037), train_loss = 1.76107565, grad/param norm = 1.6747e-01, time/batch = 0.3368s	
1137/2700 (epoch 21.056), train_loss = 1.71674562, grad/param norm = 1.5923e-01, time/batch = 0.3379s	
1138/2700 (epoch 21.074), train_loss = 1.68662070, grad/param norm = 1.5005e-01, time/batch = 0.3295s	
1139/2700 (epoch 21.093), train_loss = 1.67690896, grad/param norm = 1.6207e-01, time/batch = 0.3372s	
1140/2700 (epoch 21.111), train_loss = 1.65914022, grad/param norm = 1.8804e-01, time/batch = 0.3301s	
1141/2700 (epoch 21.130), train_loss = 1.73175441, grad/param norm = 2.3056e-01, time/batch = 0.2844s	
1142/2700 (epoch 21.148), train_loss = 1.66902667, grad/param norm = 2.1212e-01, time/batch = 0.2944s	
1143/2700 (epoch 21.167), train_loss = 1.76608449, grad/param norm = 1.5050e-01, time/batch = 0.3211s	
1144/2700 (epoch 21.185), train_loss = 1.66051563, grad/param norm = 1.4590e-01, time/batch = 0.3325s	
1145/2700 (epoch 21.204), train_loss = 1.72131660, grad/param norm = 1.5235e-01, time/batch = 0.3341s	
1146/2700 (epoch 21.222), train_loss = 1.66781748, grad/param norm = 1.4543e-01, time/batch = 0.3332s	
1147/2700 (epoch 21.241), train_loss = 1.60213520, grad/param norm = 1.4989e-01, time/batch = 0.3342s	
1148/2700 (epoch 21.259), train_loss = 1.65027854, grad/param norm = 1.6527e-01, time/batch = 0.3189s	
1149/2700 (epoch 21.278), train_loss = 1.71655235, grad/param norm = 1.8003e-01, time/batch = 0.3064s	
1150/2700 (epoch 21.296), train_loss = 1.70581630, grad/param norm = 1.7902e-01, time/batch = 0.2776s	
1151/2700 (epoch 21.315), train_loss = 1.71488115, grad/param norm = 1.7235e-01, time/batch = 0.2911s	
1152/2700 (epoch 21.333), train_loss = 1.70282559, grad/param norm = 1.5126e-01, time/batch = 0.2636s	
1153/2700 (epoch 21.352), train_loss = 1.69277957, grad/param norm = 1.6204e-01, time/batch = 0.2520s	
1154/2700 (epoch 21.370), train_loss = 1.72089345, grad/param norm = 2.1504e-01, time/batch = 0.2635s	
1155/2700 (epoch 21.389), train_loss = 1.70058225, grad/param norm = 2.1673e-01, time/batch = 0.2738s	
1156/2700 (epoch 21.407), train_loss = 1.72381966, grad/param norm = 1.8282e-01, time/batch = 0.3018s	
1157/2700 (epoch 21.426), train_loss = 1.77260761, grad/param norm = 1.6823e-01, time/batch = 0.3259s	
1158/2700 (epoch 21.444), train_loss = 1.65977331, grad/param norm = 1.7611e-01, time/batch = 0.3281s	
1159/2700 (epoch 21.463), train_loss = 1.75014605, grad/param norm = 1.7599e-01, time/batch = 0.3180s	
1160/2700 (epoch 21.481), train_loss = 1.74703615, grad/param norm = 1.6271e-01, time/batch = 0.3362s	
1161/2700 (epoch 21.500), train_loss = 1.68294475, grad/param norm = 1.7239e-01, time/batch = 0.3309s	
1162/2700 (epoch 21.519), train_loss = 1.72609770, grad/param norm = 1.5808e-01, time/batch = 0.3354s	
1163/2700 (epoch 21.537), train_loss = 1.72673669, grad/param norm = 1.7445e-01, time/batch = 0.3102s	
1164/2700 (epoch 21.556), train_loss = 1.66541925, grad/param norm = 1.6299e-01, time/batch = 0.2658s	
1165/2700 (epoch 21.574), train_loss = 1.67297558, grad/param norm = 1.7005e-01, time/batch = 0.3287s	
1166/2700 (epoch 21.593), train_loss = 1.68823648, grad/param norm = 1.8726e-01, time/batch = 0.3333s	
1167/2700 (epoch 21.611), train_loss = 1.60935755, grad/param norm = 1.8191e-01, time/batch = 0.3352s	
1168/2700 (epoch 21.630), train_loss = 1.63708393, grad/param norm = 1.6194e-01, time/batch = 0.3398s	
1169/2700 (epoch 21.648), train_loss = 1.67438212, grad/param norm = 1.6127e-01, time/batch = 0.3298s	
1170/2700 (epoch 21.667), train_loss = 1.64571117, grad/param norm = 1.6483e-01, time/batch = 0.3230s	
1171/2700 (epoch 21.685), train_loss = 1.70065442, grad/param norm = 2.0822e-01, time/batch = 0.3382s	
1172/2700 (epoch 21.704), train_loss = 1.71149860, grad/param norm = 2.1080e-01, time/batch = 0.3357s	
1173/2700 (epoch 21.722), train_loss = 1.67695967, grad/param norm = 1.7462e-01, time/batch = 0.2953s	
1174/2700 (epoch 21.741), train_loss = 1.69627003, grad/param norm = 1.8074e-01, time/batch = 0.2721s	
1175/2700 (epoch 21.759), train_loss = 1.71602211, grad/param norm = 1.8436e-01, time/batch = 0.2613s	
1176/2700 (epoch 21.778), train_loss = 1.73505940, grad/param norm = 1.8057e-01, time/batch = 0.2785s	
1177/2700 (epoch 21.796), train_loss = 1.67347475, grad/param norm = 1.9799e-01, time/batch = 0.2480s	
1178/2700 (epoch 21.815), train_loss = 1.72501620, grad/param norm = 1.9885e-01, time/batch = 0.2576s	
1179/2700 (epoch 21.833), train_loss = 1.68259475, grad/param norm = 1.8093e-01, time/batch = 0.2985s	
1180/2700 (epoch 21.852), train_loss = 1.66643645, grad/param norm = 2.0041e-01, time/batch = 0.3053s	
1181/2700 (epoch 21.870), train_loss = 1.69188199, grad/param norm = 2.2089e-01, time/batch = 0.3058s	
1182/2700 (epoch 21.889), train_loss = 1.71010296, grad/param norm = 2.3607e-01, time/batch = 0.3128s	
1183/2700 (epoch 21.907), train_loss = 1.79912504, grad/param norm = 2.4433e-01, time/batch = 0.3185s	
1184/2700 (epoch 21.926), train_loss = 1.76319956, grad/param norm = 2.0615e-01, time/batch = 0.2921s	
1185/2700 (epoch 21.944), train_loss = 1.71716476, grad/param norm = 1.7584e-01, time/batch = 0.2958s	
1186/2700 (epoch 21.963), train_loss = 1.74035371, grad/param norm = 1.5763e-01, time/batch = 0.3059s	
1187/2700 (epoch 21.981), train_loss = 1.71171244, grad/param norm = 2.1489e-01, time/batch = 0.3063s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1188/2700 (epoch 22.000), train_loss = 1.74087252, grad/param norm = 1.7281e-01, time/batch = 0.3403s	
1189/2700 (epoch 22.019), train_loss = 1.76873796, grad/param norm = 1.8522e-01, time/batch = 0.3369s	
1190/2700 (epoch 22.037), train_loss = 1.74402823, grad/param norm = 1.8930e-01, time/batch = 0.3207s	
1191/2700 (epoch 22.056), train_loss = 1.69674144, grad/param norm = 1.7585e-01, time/batch = 0.3361s	
1192/2700 (epoch 22.074), train_loss = 1.67206853, grad/param norm = 1.8436e-01, time/batch = 0.3333s	
1193/2700 (epoch 22.093), train_loss = 1.65478441, grad/param norm = 1.6223e-01, time/batch = 0.3143s	
1194/2700 (epoch 22.111), train_loss = 1.63377769, grad/param norm = 1.7224e-01, time/batch = 0.2837s	
1195/2700 (epoch 22.130), train_loss = 1.70344210, grad/param norm = 1.9167e-01, time/batch = 0.2826s	
1196/2700 (epoch 22.148), train_loss = 1.64243067, grad/param norm = 1.7151e-01, time/batch = 0.2891s	
1197/2700 (epoch 22.167), train_loss = 1.74573650, grad/param norm = 1.6270e-01, time/batch = 0.2639s	
1198/2700 (epoch 22.185), train_loss = 1.64562848, grad/param norm = 2.0518e-01, time/batch = 0.2618s	
1199/2700 (epoch 22.204), train_loss = 1.70533582, grad/param norm = 1.9577e-01, time/batch = 0.2420s	
1200/2700 (epoch 22.222), train_loss = 1.65084193, grad/param norm = 1.7272e-01, time/batch = 0.3162s	
1201/2700 (epoch 22.241), train_loss = 1.58349499, grad/param norm = 1.6110e-01, time/batch = 0.2756s	
1202/2700 (epoch 22.259), train_loss = 1.62864877, grad/param norm = 1.5771e-01, time/batch = 0.3198s	
1203/2700 (epoch 22.278), train_loss = 1.69106933, grad/param norm = 1.6082e-01, time/batch = 0.3187s	
1204/2700 (epoch 22.296), train_loss = 1.68350533, grad/param norm = 1.5965e-01, time/batch = 0.3073s	
1205/2700 (epoch 22.315), train_loss = 1.69180224, grad/param norm = 1.6108e-01, time/batch = 0.2721s	
1206/2700 (epoch 22.333), train_loss = 1.68069335, grad/param norm = 1.5395e-01, time/batch = 0.3100s	
1207/2700 (epoch 22.352), train_loss = 1.67065046, grad/param norm = 1.6239e-01, time/batch = 0.3120s	
1208/2700 (epoch 22.370), train_loss = 1.69013642, grad/param norm = 1.6243e-01, time/batch = 0.3136s	
1209/2700 (epoch 22.389), train_loss = 1.66655401, grad/param norm = 1.6798e-01, time/batch = 0.2711s	
1210/2700 (epoch 22.407), train_loss = 1.70030055, grad/param norm = 1.5785e-01, time/batch = 0.2447s	
1211/2700 (epoch 22.426), train_loss = 1.75019670, grad/param norm = 1.5899e-01, time/batch = 0.2096s	
1212/2700 (epoch 22.444), train_loss = 1.63976727, grad/param norm = 1.6210e-01, time/batch = 0.2118s	
1213/2700 (epoch 22.463), train_loss = 1.72910081, grad/param norm = 1.8011e-01, time/batch = 0.2745s	
1214/2700 (epoch 22.481), train_loss = 1.72377938, grad/param norm = 1.5179e-01, time/batch = 0.3007s	
1215/2700 (epoch 22.500), train_loss = 1.65678417, grad/param norm = 1.5472e-01, time/batch = 0.2918s	
1216/2700 (epoch 22.519), train_loss = 1.70718770, grad/param norm = 1.6774e-01, time/batch = 0.2987s	
1217/2700 (epoch 22.537), train_loss = 1.71062838, grad/param norm = 2.2012e-01, time/batch = 0.3127s	
1218/2700 (epoch 22.556), train_loss = 1.65221083, grad/param norm = 2.2375e-01, time/batch = 0.3056s	
1219/2700 (epoch 22.574), train_loss = 1.65860526, grad/param norm = 2.1429e-01, time/batch = 0.2795s	
1220/2700 (epoch 22.593), train_loss = 1.67657859, grad/param norm = 2.2994e-01, time/batch = 0.2580s	
1221/2700 (epoch 22.611), train_loss = 1.59336679, grad/param norm = 2.0491e-01, time/batch = 0.2787s	
1222/2700 (epoch 22.630), train_loss = 1.61579889, grad/param norm = 1.6145e-01, time/batch = 0.2954s	
1223/2700 (epoch 22.648), train_loss = 1.65181936, grad/param norm = 1.5779e-01, time/batch = 0.2878s	
1224/2700 (epoch 22.667), train_loss = 1.62681075, grad/param norm = 1.6674e-01, time/batch = 0.2372s	
1225/2700 (epoch 22.685), train_loss = 1.68008158, grad/param norm = 1.9755e-01, time/batch = 0.2670s	
1226/2700 (epoch 22.704), train_loss = 1.68536694, grad/param norm = 1.9735e-01, time/batch = 0.3120s	
1227/2700 (epoch 22.722), train_loss = 1.65584019, grad/param norm = 1.5602e-01, time/batch = 0.3124s	
1228/2700 (epoch 22.741), train_loss = 1.66545552, grad/param norm = 1.5272e-01, time/batch = 0.3241s	
1229/2700 (epoch 22.759), train_loss = 1.68637274, grad/param norm = 1.6851e-01, time/batch = 0.3334s	
1230/2700 (epoch 22.778), train_loss = 1.71286118, grad/param norm = 1.7585e-01, time/batch = 0.3243s	
1231/2700 (epoch 22.796), train_loss = 1.64380373, grad/param norm = 1.6104e-01, time/batch = 0.3202s	
1232/2700 (epoch 22.815), train_loss = 1.69760969, grad/param norm = 1.7506e-01, time/batch = 0.3127s	
1233/2700 (epoch 22.833), train_loss = 1.66170158, grad/param norm = 1.8928e-01, time/batch = 0.2962s	
1234/2700 (epoch 22.852), train_loss = 1.64491316, grad/param norm = 2.0079e-01, time/batch = 0.2882s	
1235/2700 (epoch 22.870), train_loss = 1.66807341, grad/param norm = 1.7823e-01, time/batch = 0.2665s	
1236/2700 (epoch 22.889), train_loss = 1.67852195, grad/param norm = 1.6362e-01, time/batch = 0.2881s	
1237/2700 (epoch 22.907), train_loss = 1.76982246, grad/param norm = 1.9295e-01, time/batch = 0.2769s	
1238/2700 (epoch 22.926), train_loss = 1.74726970, grad/param norm = 2.5570e-01, time/batch = 0.2499s	
1239/2700 (epoch 22.944), train_loss = 1.71227056, grad/param norm = 2.5626e-01, time/batch = 0.2823s	
1240/2700 (epoch 22.963), train_loss = 1.72624165, grad/param norm = 2.0432e-01, time/batch = 0.3100s	
1241/2700 (epoch 22.981), train_loss = 1.68368804, grad/param norm = 1.6975e-01, time/batch = 0.2890s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1242/2700 (epoch 23.000), train_loss = 1.71737102, grad/param norm = 1.6977e-01, time/batch = 0.3000s	
1243/2700 (epoch 23.019), train_loss = 1.74960585, grad/param norm = 1.7415e-01, time/batch = 0.3079s	
1244/2700 (epoch 23.037), train_loss = 1.71885636, grad/param norm = 1.6738e-01, time/batch = 0.2984s	
1245/2700 (epoch 23.056), train_loss = 1.67592095, grad/param norm = 1.6013e-01, time/batch = 0.2811s	
1246/2700 (epoch 23.074), train_loss = 1.64918588, grad/param norm = 1.6527e-01, time/batch = 0.2679s	
1247/2700 (epoch 23.093), train_loss = 1.63508826, grad/param norm = 1.6588e-01, time/batch = 0.2696s	
1248/2700 (epoch 23.111), train_loss = 1.61677756, grad/param norm = 1.7766e-01, time/batch = 0.2603s	
1249/2700 (epoch 23.130), train_loss = 1.68197429, grad/param norm = 2.0219e-01, time/batch = 0.2658s	
1250/2700 (epoch 23.148), train_loss = 1.62202572, grad/param norm = 1.7591e-01, time/batch = 0.2873s	
1251/2700 (epoch 23.167), train_loss = 1.72408974, grad/param norm = 1.5065e-01, time/batch = 0.2967s	
1252/2700 (epoch 23.185), train_loss = 1.62353142, grad/param norm = 1.7690e-01, time/batch = 0.3030s	
1253/2700 (epoch 23.204), train_loss = 1.68057892, grad/param norm = 1.6644e-01, time/batch = 0.2925s	
1254/2700 (epoch 23.222), train_loss = 1.62873810, grad/param norm = 1.5029e-01, time/batch = 0.3020s	
1255/2700 (epoch 23.241), train_loss = 1.56234254, grad/param norm = 1.4936e-01, time/batch = 0.2972s	
1256/2700 (epoch 23.259), train_loss = 1.61035655, grad/param norm = 1.6416e-01, time/batch = 0.2890s	
1257/2700 (epoch 23.278), train_loss = 1.67237048, grad/param norm = 1.6970e-01, time/batch = 0.2686s	
1258/2700 (epoch 23.296), train_loss = 1.66251597, grad/param norm = 1.6756e-01, time/batch = 0.2876s	
1259/2700 (epoch 23.315), train_loss = 1.67163312, grad/param norm = 1.6385e-01, time/batch = 0.2814s	
1260/2700 (epoch 23.333), train_loss = 1.65946668, grad/param norm = 1.4996e-01, time/batch = 0.2656s	
1261/2700 (epoch 23.352), train_loss = 1.64905990, grad/param norm = 1.5874e-01, time/batch = 0.2606s	
1262/2700 (epoch 23.370), train_loss = 1.66723550, grad/param norm = 1.7336e-01, time/batch = 0.2603s	
1263/2700 (epoch 23.389), train_loss = 1.64257282, grad/param norm = 1.6860e-01, time/batch = 0.2974s	
1264/2700 (epoch 23.407), train_loss = 1.68073745, grad/param norm = 1.5892e-01, time/batch = 0.3081s	
1265/2700 (epoch 23.426), train_loss = 1.73128083, grad/param norm = 1.5888e-01, time/batch = 0.3154s	
1266/2700 (epoch 23.444), train_loss = 1.61992892, grad/param norm = 1.6700e-01, time/batch = 0.3184s	
1267/2700 (epoch 23.463), train_loss = 1.70772420, grad/param norm = 1.7942e-01, time/batch = 0.2962s	
1268/2700 (epoch 23.481), train_loss = 1.70337036, grad/param norm = 1.7450e-01, time/batch = 0.2730s	
1269/2700 (epoch 23.500), train_loss = 1.64057262, grad/param norm = 2.0380e-01, time/batch = 0.2639s	
1270/2700 (epoch 23.519), train_loss = 1.68955766, grad/param norm = 1.8451e-01, time/batch = 0.2988s	
1271/2700 (epoch 23.537), train_loss = 1.68585865, grad/param norm = 1.8199e-01, time/batch = 0.2231s	
1272/2700 (epoch 23.556), train_loss = 1.62133943, grad/param norm = 1.7316e-01, time/batch = 0.2199s	
1273/2700 (epoch 23.574), train_loss = 1.63127542, grad/param norm = 1.6654e-01, time/batch = 0.2418s	
1274/2700 (epoch 23.593), train_loss = 1.64666397, grad/param norm = 1.6016e-01, time/batch = 0.2776s	
1275/2700 (epoch 23.611), train_loss = 1.56745229, grad/param norm = 1.4489e-01, time/batch = 0.3145s	
1276/2700 (epoch 23.630), train_loss = 1.59300385, grad/param norm = 1.5200e-01, time/batch = 0.3193s	
1277/2700 (epoch 23.648), train_loss = 1.63242353, grad/param norm = 1.5593e-01, time/batch = 0.3195s	
1278/2700 (epoch 23.667), train_loss = 1.60781708, grad/param norm = 1.8165e-01, time/batch = 0.2807s	
1279/2700 (epoch 23.685), train_loss = 1.66354304, grad/param norm = 1.9744e-01, time/batch = 0.2756s	
1280/2700 (epoch 23.704), train_loss = 1.66767868, grad/param norm = 1.9649e-01, time/batch = 0.2816s	
1281/2700 (epoch 23.722), train_loss = 1.63963426, grad/param norm = 1.7502e-01, time/batch = 0.3034s	
1282/2700 (epoch 23.741), train_loss = 1.64921013, grad/param norm = 1.8730e-01, time/batch = 0.3056s	
1283/2700 (epoch 23.759), train_loss = 1.66921188, grad/param norm = 2.2167e-01, time/batch = 0.2731s	
1284/2700 (epoch 23.778), train_loss = 1.70084133, grad/param norm = 2.2186e-01, time/batch = 0.2602s	
1285/2700 (epoch 23.796), train_loss = 1.62682289, grad/param norm = 1.8562e-01, time/batch = 0.2713s	
1286/2700 (epoch 23.815), train_loss = 1.67773822, grad/param norm = 1.7479e-01, time/batch = 0.2973s	
1287/2700 (epoch 23.833), train_loss = 1.63819073, grad/param norm = 1.6280e-01, time/batch = 0.3033s	
1288/2700 (epoch 23.852), train_loss = 1.61878275, grad/param norm = 1.6754e-01, time/batch = 0.3091s	
1289/2700 (epoch 23.870), train_loss = 1.64591265, grad/param norm = 1.4885e-01, time/batch = 0.2991s	
1290/2700 (epoch 23.889), train_loss = 1.65482752, grad/param norm = 1.5225e-01, time/batch = 0.3021s	
1291/2700 (epoch 23.907), train_loss = 1.74622476, grad/param norm = 1.8181e-01, time/batch = 0.2959s	
1292/2700 (epoch 23.926), train_loss = 1.71879255, grad/param norm = 2.0395e-01, time/batch = 0.2785s	
1293/2700 (epoch 23.944), train_loss = 1.68137740, grad/param norm = 2.0284e-01, time/batch = 0.2658s	
1294/2700 (epoch 23.963), train_loss = 1.69981156, grad/param norm = 1.7490e-01, time/batch = 0.2700s	
1295/2700 (epoch 23.981), train_loss = 1.66049754, grad/param norm = 1.5363e-01, time/batch = 0.2839s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1296/2700 (epoch 24.000), train_loss = 1.69757571, grad/param norm = 1.6817e-01, time/batch = 0.2867s	
1297/2700 (epoch 24.019), train_loss = 1.73063466, grad/param norm = 1.7022e-01, time/batch = 0.2638s	
1298/2700 (epoch 24.037), train_loss = 1.69876149, grad/param norm = 1.6700e-01, time/batch = 0.2739s	
1299/2700 (epoch 24.056), train_loss = 1.65595921, grad/param norm = 1.6136e-01, time/batch = 0.3118s	
1300/2700 (epoch 24.074), train_loss = 1.63261912, grad/param norm = 1.7758e-01, time/batch = 0.3009s	
1301/2700 (epoch 24.093), train_loss = 1.61443536, grad/param norm = 1.6963e-01, time/batch = 0.2922s	
1302/2700 (epoch 24.111), train_loss = 1.59445138, grad/param norm = 1.7025e-01, time/batch = 0.3051s	
1303/2700 (epoch 24.130), train_loss = 1.65958018, grad/param norm = 1.8679e-01, time/batch = 0.3006s	
1304/2700 (epoch 24.148), train_loss = 1.60144968, grad/param norm = 1.6987e-01, time/batch = 0.2726s	
1305/2700 (epoch 24.167), train_loss = 1.70475572, grad/param norm = 1.5526e-01, time/batch = 0.2567s	
1306/2700 (epoch 24.185), train_loss = 1.60775305, grad/param norm = 1.9909e-01, time/batch = 0.2829s	
1307/2700 (epoch 24.204), train_loss = 1.66366328, grad/param norm = 1.8397e-01, time/batch = 0.2825s	
1308/2700 (epoch 24.222), train_loss = 1.61134083, grad/param norm = 1.6405e-01, time/batch = 0.2922s	
1309/2700 (epoch 24.241), train_loss = 1.54610564, grad/param norm = 1.5814e-01, time/batch = 0.2549s	
1310/2700 (epoch 24.259), train_loss = 1.59207933, grad/param norm = 1.6001e-01, time/batch = 0.2750s	
1311/2700 (epoch 24.278), train_loss = 1.65230358, grad/param norm = 1.6183e-01, time/batch = 0.2605s	
1312/2700 (epoch 24.296), train_loss = 1.64561043, grad/param norm = 1.7368e-01, time/batch = 0.2751s	
1313/2700 (epoch 24.315), train_loss = 1.65433330, grad/param norm = 1.7124e-01, time/batch = 0.2668s	
1314/2700 (epoch 24.333), train_loss = 1.64150306, grad/param norm = 1.6385e-01, time/batch = 0.2653s	
1315/2700 (epoch 24.352), train_loss = 1.63113158, grad/param norm = 1.7060e-01, time/batch = 0.2830s	
1316/2700 (epoch 24.370), train_loss = 1.64309153, grad/param norm = 1.5950e-01, time/batch = 0.3022s	
1317/2700 (epoch 24.389), train_loss = 1.61814591, grad/param norm = 1.6009e-01, time/batch = 0.3209s	
1318/2700 (epoch 24.407), train_loss = 1.66283215, grad/param norm = 1.5284e-01, time/batch = 0.3276s	
1319/2700 (epoch 24.426), train_loss = 1.71057254, grad/param norm = 1.5206e-01, time/batch = 0.3079s	
1320/2700 (epoch 24.444), train_loss = 1.60155739, grad/param norm = 1.5044e-01, time/batch = 0.3019s	
1321/2700 (epoch 24.463), train_loss = 1.68671670, grad/param norm = 1.7700e-01, time/batch = 0.3213s	
1322/2700 (epoch 24.481), train_loss = 1.68212116, grad/param norm = 1.6527e-01, time/batch = 0.3008s	
1323/2700 (epoch 24.500), train_loss = 1.61701961, grad/param norm = 1.8097e-01, time/batch = 0.2978s	
1324/2700 (epoch 24.519), train_loss = 1.67566092, grad/param norm = 2.1064e-01, time/batch = 0.2846s	
1325/2700 (epoch 24.537), train_loss = 1.67714554, grad/param norm = 2.5467e-01, time/batch = 0.2996s	
1326/2700 (epoch 24.556), train_loss = 1.61456162, grad/param norm = 2.3587e-01, time/batch = 0.2783s	
1327/2700 (epoch 24.574), train_loss = 1.62419954, grad/param norm = 2.2703e-01, time/batch = 0.2371s	
1328/2700 (epoch 24.593), train_loss = 1.64369896, grad/param norm = 2.3883e-01, time/batch = 0.2746s	
1329/2700 (epoch 24.611), train_loss = 1.55725837, grad/param norm = 1.9326e-01, time/batch = 0.2968s	
1330/2700 (epoch 24.630), train_loss = 1.57570024, grad/param norm = 1.5823e-01, time/batch = 0.3190s	
1331/2700 (epoch 24.648), train_loss = 1.61199023, grad/param norm = 1.5936e-01, time/batch = 0.2782s	
1332/2700 (epoch 24.667), train_loss = 1.58600623, grad/param norm = 1.5572e-01, time/batch = 0.3234s	
1333/2700 (epoch 24.685), train_loss = 1.64125202, grad/param norm = 1.8715e-01, time/batch = 0.3191s	
1334/2700 (epoch 24.704), train_loss = 1.64610817, grad/param norm = 1.7958e-01, time/batch = 0.3282s	
1335/2700 (epoch 24.722), train_loss = 1.61784450, grad/param norm = 1.5182e-01, time/batch = 0.3086s	
1336/2700 (epoch 24.741), train_loss = 1.62420097, grad/param norm = 1.5990e-01, time/batch = 0.2955s	
1337/2700 (epoch 24.759), train_loss = 1.64353048, grad/param norm = 1.8481e-01, time/batch = 0.3059s	
1338/2700 (epoch 24.778), train_loss = 1.67719296, grad/param norm = 1.7413e-01, time/batch = 0.2712s	
1339/2700 (epoch 24.796), train_loss = 1.59934966, grad/param norm = 1.6100e-01, time/batch = 0.2851s	
1340/2700 (epoch 24.815), train_loss = 1.65573757, grad/param norm = 1.6989e-01, time/batch = 0.2803s	
1341/2700 (epoch 24.833), train_loss = 1.62212443, grad/param norm = 1.6873e-01, time/batch = 0.2856s	
1342/2700 (epoch 24.852), train_loss = 1.59753364, grad/param norm = 1.6718e-01, time/batch = 0.2552s	
1343/2700 (epoch 24.870), train_loss = 1.62892084, grad/param norm = 1.6803e-01, time/batch = 0.2437s	
1344/2700 (epoch 24.889), train_loss = 1.63840597, grad/param norm = 1.7719e-01, time/batch = 0.2667s	
1345/2700 (epoch 24.907), train_loss = 1.72857280, grad/param norm = 1.8885e-01, time/batch = 0.2886s	
1346/2700 (epoch 24.926), train_loss = 1.69816542, grad/param norm = 1.9521e-01, time/batch = 0.3120s	
1347/2700 (epoch 24.944), train_loss = 1.65873852, grad/param norm = 1.8926e-01, time/batch = 0.3317s	
1348/2700 (epoch 24.963), train_loss = 1.67882081, grad/param norm = 1.5827e-01, time/batch = 0.3277s	
1349/2700 (epoch 24.981), train_loss = 1.63895230, grad/param norm = 1.6240e-01, time/batch = 0.3280s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1350/2700 (epoch 25.000), train_loss = 1.67557071, grad/param norm = 1.6341e-01, time/batch = 0.3166s	
1351/2700 (epoch 25.019), train_loss = 1.71298944, grad/param norm = 1.6390e-01, time/batch = 0.3384s	
1352/2700 (epoch 25.037), train_loss = 1.68071568, grad/param norm = 1.6926e-01, time/batch = 0.3364s	
1353/2700 (epoch 25.056), train_loss = 1.63730292, grad/param norm = 1.6653e-01, time/batch = 0.3348s	
1354/2700 (epoch 25.074), train_loss = 1.61496939, grad/param norm = 1.6982e-01, time/batch = 0.3169s	
1355/2700 (epoch 25.093), train_loss = 1.59431092, grad/param norm = 1.5846e-01, time/batch = 0.2695s	
1356/2700 (epoch 25.111), train_loss = 1.57616453, grad/param norm = 1.7136e-01, time/batch = 0.2544s	
1357/2700 (epoch 25.130), train_loss = 1.64031452, grad/param norm = 1.7280e-01, time/batch = 0.2049s	
1358/2700 (epoch 25.148), train_loss = 1.58226340, grad/param norm = 1.6389e-01, time/batch = 0.2342s	
1359/2700 (epoch 25.167), train_loss = 1.68667271, grad/param norm = 1.5546e-01, time/batch = 0.2601s	
1360/2700 (epoch 25.185), train_loss = 1.58793782, grad/param norm = 1.7715e-01, time/batch = 0.3259s	
1361/2700 (epoch 25.204), train_loss = 1.64303834, grad/param norm = 1.7004e-01, time/batch = 0.2986s	
1362/2700 (epoch 25.222), train_loss = 1.59286667, grad/param norm = 1.5692e-01, time/batch = 0.3242s	
1363/2700 (epoch 25.241), train_loss = 1.52814804, grad/param norm = 1.5600e-01, time/batch = 0.3259s	
1364/2700 (epoch 25.259), train_loss = 1.57416496, grad/param norm = 1.5951e-01, time/batch = 0.3181s	
1365/2700 (epoch 25.278), train_loss = 1.63336927, grad/param norm = 1.6476e-01, time/batch = 0.2802s	
1366/2700 (epoch 25.296), train_loss = 1.62628622, grad/param norm = 1.7412e-01, time/batch = 0.2770s	
1367/2700 (epoch 25.315), train_loss = 1.63522720, grad/param norm = 1.5742e-01, time/batch = 0.2889s	
1368/2700 (epoch 25.333), train_loss = 1.62426200, grad/param norm = 1.6941e-01, time/batch = 0.2928s	
1369/2700 (epoch 25.352), train_loss = 1.61563523, grad/param norm = 1.9025e-01, time/batch = 0.2904s	
1370/2700 (epoch 25.370), train_loss = 1.62796722, grad/param norm = 1.8554e-01, time/batch = 0.2472s	
1371/2700 (epoch 25.389), train_loss = 1.60073677, grad/param norm = 1.8004e-01, time/batch = 0.2532s	
1372/2700 (epoch 25.407), train_loss = 1.64824125, grad/param norm = 1.6946e-01, time/batch = 0.2583s	
1373/2700 (epoch 25.426), train_loss = 1.69522577, grad/param norm = 1.6795e-01, time/batch = 0.3071s	
1374/2700 (epoch 25.444), train_loss = 1.58554136, grad/param norm = 1.5617e-01, time/batch = 0.3147s	
1375/2700 (epoch 25.463), train_loss = 1.66820412, grad/param norm = 1.7364e-01, time/batch = 0.3189s	
1376/2700 (epoch 25.481), train_loss = 1.66157895, grad/param norm = 1.6308e-01, time/batch = 0.2845s	
1377/2700 (epoch 25.500), train_loss = 1.59628178, grad/param norm = 1.8124e-01, time/batch = 0.2742s	
1378/2700 (epoch 25.519), train_loss = 1.65090998, grad/param norm = 1.6243e-01, time/batch = 0.2732s	
1379/2700 (epoch 25.537), train_loss = 1.64994067, grad/param norm = 1.8176e-01, time/batch = 0.2975s	
1380/2700 (epoch 25.556), train_loss = 1.58552045, grad/param norm = 1.8647e-01, time/batch = 0.3024s	
1381/2700 (epoch 25.574), train_loss = 1.59960525, grad/param norm = 1.9831e-01, time/batch = 0.2842s	
1382/2700 (epoch 25.593), train_loss = 1.62373865, grad/param norm = 2.2198e-01, time/batch = 0.2742s	
1383/2700 (epoch 25.611), train_loss = 1.54015118, grad/param norm = 1.9021e-01, time/batch = 0.2609s	
1384/2700 (epoch 25.630), train_loss = 1.55501520, grad/param norm = 1.5494e-01, time/batch = 0.2817s	
1385/2700 (epoch 25.648), train_loss = 1.59354644, grad/param norm = 1.5484e-01, time/batch = 0.2930s	
1386/2700 (epoch 25.667), train_loss = 1.56997387, grad/param norm = 1.6587e-01, time/batch = 0.3049s	
1387/2700 (epoch 25.685), train_loss = 1.62567056, grad/param norm = 1.8699e-01, time/batch = 0.3006s	
1388/2700 (epoch 25.704), train_loss = 1.62787183, grad/param norm = 1.8037e-01, time/batch = 0.2990s	
1389/2700 (epoch 25.722), train_loss = 1.60273449, grad/param norm = 1.5249e-01, time/batch = 0.2827s	
1390/2700 (epoch 25.741), train_loss = 1.60244158, grad/param norm = 1.5972e-01, time/batch = 0.2623s	
1391/2700 (epoch 25.759), train_loss = 1.61797807, grad/param norm = 1.6020e-01, time/batch = 0.2549s	
1392/2700 (epoch 25.778), train_loss = 1.65685675, grad/param norm = 1.6017e-01, time/batch = 0.2827s	
1393/2700 (epoch 25.796), train_loss = 1.57993592, grad/param norm = 1.7613e-01, time/batch = 0.2828s	
1394/2700 (epoch 25.815), train_loss = 1.63755347, grad/param norm = 1.7840e-01, time/batch = 0.2931s	
1395/2700 (epoch 25.833), train_loss = 1.60788667, grad/param norm = 1.8392e-01, time/batch = 0.2601s	
1396/2700 (epoch 25.852), train_loss = 1.58606910, grad/param norm = 2.0705e-01, time/batch = 0.2664s	
1397/2700 (epoch 25.870), train_loss = 1.61742104, grad/param norm = 1.9598e-01, time/batch = 0.3012s	
1398/2700 (epoch 25.889), train_loss = 1.62256686, grad/param norm = 1.9835e-01, time/batch = 0.3001s	
1399/2700 (epoch 25.907), train_loss = 1.70808832, grad/param norm = 1.9054e-01, time/batch = 0.2738s	
1400/2700 (epoch 25.926), train_loss = 1.67584591, grad/param norm = 1.8784e-01, time/batch = 0.2873s	
1401/2700 (epoch 25.944), train_loss = 1.63805198, grad/param norm = 1.8922e-01, time/batch = 0.2646s	
1402/2700 (epoch 25.963), train_loss = 1.65997319, grad/param norm = 1.5696e-01, time/batch = 0.2764s	
1403/2700 (epoch 25.981), train_loss = 1.61802738, grad/param norm = 1.7632e-01, time/batch = 0.3116s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1404/2700 (epoch 26.000), train_loss = 1.65929521, grad/param norm = 1.7162e-01, time/batch = 0.3273s	
1405/2700 (epoch 26.019), train_loss = 1.69928640, grad/param norm = 1.6981e-01, time/batch = 0.3153s	
1406/2700 (epoch 26.037), train_loss = 1.66623039, grad/param norm = 1.7942e-01, time/batch = 0.3138s	
1407/2700 (epoch 26.056), train_loss = 1.61950226, grad/param norm = 1.6914e-01, time/batch = 0.2928s	
1408/2700 (epoch 26.074), train_loss = 1.59973737, grad/param norm = 1.8001e-01, time/batch = 0.2579s	
1409/2700 (epoch 26.093), train_loss = 1.57664901, grad/param norm = 1.5624e-01, time/batch = 0.2760s	
1410/2700 (epoch 26.111), train_loss = 1.56140065, grad/param norm = 2.4209e-01, time/batch = 0.2606s	
1411/2700 (epoch 26.130), train_loss = 1.63425024, grad/param norm = 2.8147e-01, time/batch = 0.2644s	
1412/2700 (epoch 26.148), train_loss = 1.57127553, grad/param norm = 1.7600e-01, time/batch = 0.2704s	
1413/2700 (epoch 26.167), train_loss = 1.67073670, grad/param norm = 1.5795e-01, time/batch = 0.2668s	
1414/2700 (epoch 26.185), train_loss = 1.57430132, grad/param norm = 1.8665e-01, time/batch = 0.3049s	
1415/2700 (epoch 26.204), train_loss = 1.62526767, grad/param norm = 1.6431e-01, time/batch = 0.3216s	
1416/2700 (epoch 26.222), train_loss = 1.57462132, grad/param norm = 1.4609e-01, time/batch = 0.3323s	
1417/2700 (epoch 26.241), train_loss = 1.50991026, grad/param norm = 1.4903e-01, time/batch = 0.3152s	
1418/2700 (epoch 26.259), train_loss = 1.55791706, grad/param norm = 1.6758e-01, time/batch = 0.3081s	
1419/2700 (epoch 26.278), train_loss = 1.61908997, grad/param norm = 1.7715e-01, time/batch = 0.2800s	
1420/2700 (epoch 26.296), train_loss = 1.61048826, grad/param norm = 1.6899e-01, time/batch = 0.2554s	
1421/2700 (epoch 26.315), train_loss = 1.61764840, grad/param norm = 1.6002e-01, time/batch = 0.2822s	
1422/2700 (epoch 26.333), train_loss = 1.60694179, grad/param norm = 1.6247e-01, time/batch = 0.2883s	
1423/2700 (epoch 26.352), train_loss = 1.59386726, grad/param norm = 1.6667e-01, time/batch = 0.2667s	
1424/2700 (epoch 26.370), train_loss = 1.60346807, grad/param norm = 1.7326e-01, time/batch = 0.2404s	
1425/2700 (epoch 26.389), train_loss = 1.57892235, grad/param norm = 1.6646e-01, time/batch = 0.2756s	
1426/2700 (epoch 26.407), train_loss = 1.63057792, grad/param norm = 1.6104e-01, time/batch = 0.3064s	
1427/2700 (epoch 26.426), train_loss = 1.67741070, grad/param norm = 1.6451e-01, time/batch = 0.3275s	
1428/2700 (epoch 26.444), train_loss = 1.57086195, grad/param norm = 1.8379e-01, time/batch = 0.3322s	
1429/2700 (epoch 26.463), train_loss = 1.65493417, grad/param norm = 1.9577e-01, time/batch = 0.3187s	
1430/2700 (epoch 26.481), train_loss = 1.64890326, grad/param norm = 2.0783e-01, time/batch = 0.3143s	
1431/2700 (epoch 26.500), train_loss = 1.58704729, grad/param norm = 2.3936e-01, time/batch = 0.3101s	
1432/2700 (epoch 26.519), train_loss = 1.63625218, grad/param norm = 1.9784e-01, time/batch = 0.3106s	
1433/2700 (epoch 26.537), train_loss = 1.63225353, grad/param norm = 1.8623e-01, time/batch = 0.2940s	
1434/2700 (epoch 26.556), train_loss = 1.56344456, grad/param norm = 1.6921e-01, time/batch = 0.3128s	
1435/2700 (epoch 26.574), train_loss = 1.57386237, grad/param norm = 1.5931e-01, time/batch = 0.2816s	
1436/2700 (epoch 26.593), train_loss = 1.59747735, grad/param norm = 1.6390e-01, time/batch = 0.2830s	
1437/2700 (epoch 26.611), train_loss = 1.51881439, grad/param norm = 1.4633e-01, time/batch = 0.2750s	
1438/2700 (epoch 26.630), train_loss = 1.53745801, grad/param norm = 1.6040e-01, time/batch = 0.2552s	
1439/2700 (epoch 26.648), train_loss = 1.57587920, grad/param norm = 1.5675e-01, time/batch = 0.2777s	
1440/2700 (epoch 26.667), train_loss = 1.55306139, grad/param norm = 1.7811e-01, time/batch = 0.3092s	
1441/2700 (epoch 26.685), train_loss = 1.61059584, grad/param norm = 1.8857e-01, time/batch = 0.2676s	
1442/2700 (epoch 26.704), train_loss = 1.61086652, grad/param norm = 1.8971e-01, time/batch = 0.2609s	
1443/2700 (epoch 26.722), train_loss = 1.59090417, grad/param norm = 1.8531e-01, time/batch = 0.2986s	
1444/2700 (epoch 26.741), train_loss = 1.58980308, grad/param norm = 1.9301e-01, time/batch = 0.3185s	
1445/2700 (epoch 26.759), train_loss = 1.60297907, grad/param norm = 2.0532e-01, time/batch = 0.3250s	
1446/2700 (epoch 26.778), train_loss = 1.64331401, grad/param norm = 1.9236e-01, time/batch = 0.3193s	
1447/2700 (epoch 26.796), train_loss = 1.55930515, grad/param norm = 1.5800e-01, time/batch = 0.3070s	
1448/2700 (epoch 26.815), train_loss = 1.61611055, grad/param norm = 1.7031e-01, time/batch = 0.2956s	
1449/2700 (epoch 26.833), train_loss = 1.58712861, grad/param norm = 1.7160e-01, time/batch = 0.2607s	
1450/2700 (epoch 26.852), train_loss = 1.55960875, grad/param norm = 1.6068e-01, time/batch = 0.2532s	
1451/2700 (epoch 26.870), train_loss = 1.59374415, grad/param norm = 1.5268e-01, time/batch = 0.2626s	
1452/2700 (epoch 26.889), train_loss = 1.59879391, grad/param norm = 1.5380e-01, time/batch = 0.2952s	
1453/2700 (epoch 26.907), train_loss = 1.69201275, grad/param norm = 1.9237e-01, time/batch = 0.2893s	
1454/2700 (epoch 26.926), train_loss = 1.66612613, grad/param norm = 2.3688e-01, time/batch = 0.2798s	
1455/2700 (epoch 26.944), train_loss = 1.62688428, grad/param norm = 2.3019e-01, time/batch = 0.3093s	
1456/2700 (epoch 26.963), train_loss = 1.64651887, grad/param norm = 1.9450e-01, time/batch = 0.3151s	
1457/2700 (epoch 26.981), train_loss = 1.60026953, grad/param norm = 1.7348e-01, time/batch = 0.3318s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1458/2700 (epoch 27.000), train_loss = 1.64451412, grad/param norm = 1.9173e-01, time/batch = 0.3361s	
1459/2700 (epoch 27.019), train_loss = 1.68477455, grad/param norm = 1.7610e-01, time/batch = 0.3374s	
1460/2700 (epoch 27.037), train_loss = 1.64434689, grad/param norm = 1.6868e-01, time/batch = 0.3325s	
1461/2700 (epoch 27.056), train_loss = 1.60071758, grad/param norm = 1.5913e-01, time/batch = 0.3295s	
1462/2700 (epoch 27.074), train_loss = 1.57933694, grad/param norm = 1.6077e-01, time/batch = 0.3352s	
1463/2700 (epoch 27.093), train_loss = 1.55919804, grad/param norm = 1.5916e-01, time/batch = 0.3257s	
1464/2700 (epoch 27.111), train_loss = 1.54536124, grad/param norm = 1.7884e-01, time/batch = 0.3336s	
1465/2700 (epoch 27.130), train_loss = 1.60697576, grad/param norm = 1.9188e-01, time/batch = 0.2836s	
1466/2700 (epoch 27.148), train_loss = 1.55001249, grad/param norm = 1.7483e-01, time/batch = 0.3089s	
1467/2700 (epoch 27.167), train_loss = 1.65386807, grad/param norm = 1.5807e-01, time/batch = 0.3204s	
1468/2700 (epoch 27.185), train_loss = 1.55669549, grad/param norm = 1.6341e-01, time/batch = 0.3090s	
1469/2700 (epoch 27.204), train_loss = 1.60917681, grad/param norm = 1.7446e-01, time/batch = 0.2961s	
1470/2700 (epoch 27.222), train_loss = 1.56122311, grad/param norm = 1.6243e-01, time/batch = 0.2898s	
1471/2700 (epoch 27.241), train_loss = 1.49702200, grad/param norm = 1.5841e-01, time/batch = 0.3013s	
1472/2700 (epoch 27.259), train_loss = 1.54518036, grad/param norm = 1.7725e-01, time/batch = 0.2674s	
1473/2700 (epoch 27.278), train_loss = 1.60122707, grad/param norm = 1.7766e-01, time/batch = 0.2478s	
1474/2700 (epoch 27.296), train_loss = 1.59051655, grad/param norm = 1.6134e-01, time/batch = 0.2648s	
1475/2700 (epoch 27.315), train_loss = 1.59982835, grad/param norm = 1.5295e-01, time/batch = 0.3257s	
1476/2700 (epoch 27.333), train_loss = 1.59133521, grad/param norm = 1.6794e-01, time/batch = 0.3195s	
1477/2700 (epoch 27.352), train_loss = 1.57803044, grad/param norm = 1.7897e-01, time/batch = 0.2730s	
1478/2700 (epoch 27.370), train_loss = 1.58547801, grad/param norm = 1.7333e-01, time/batch = 0.3037s	
1479/2700 (epoch 27.389), train_loss = 1.56131173, grad/param norm = 1.6709e-01, time/batch = 0.3145s	
1480/2700 (epoch 27.407), train_loss = 1.61387593, grad/param norm = 1.5180e-01, time/batch = 0.3221s	
1481/2700 (epoch 27.426), train_loss = 1.66006737, grad/param norm = 1.5360e-01, time/batch = 0.3179s	
1482/2700 (epoch 27.444), train_loss = 1.55401674, grad/param norm = 1.5064e-01, time/batch = 0.3263s	
1483/2700 (epoch 27.463), train_loss = 1.63231911, grad/param norm = 1.6555e-01, time/batch = 0.3271s	
1484/2700 (epoch 27.481), train_loss = 1.62478735, grad/param norm = 1.5683e-01, time/batch = 0.3161s	
1485/2700 (epoch 27.500), train_loss = 1.55737808, grad/param norm = 1.6665e-01, time/batch = 0.3372s	
1486/2700 (epoch 27.519), train_loss = 1.61504900, grad/param norm = 1.5566e-01, time/batch = 0.3249s	
1487/2700 (epoch 27.537), train_loss = 1.61580355, grad/param norm = 1.8139e-01, time/batch = 0.3015s	
1488/2700 (epoch 27.556), train_loss = 1.54971830, grad/param norm = 1.8160e-01, time/batch = 0.2128s	
1489/2700 (epoch 27.574), train_loss = 1.56216989, grad/param norm = 1.9101e-01, time/batch = 0.2667s	
1490/2700 (epoch 27.593), train_loss = 1.58958201, grad/param norm = 2.1594e-01, time/batch = 0.2458s	
1491/2700 (epoch 27.611), train_loss = 1.50906697, grad/param norm = 1.8273e-01, time/batch = 0.2491s	
1492/2700 (epoch 27.630), train_loss = 1.52053274, grad/param norm = 1.5428e-01, time/batch = 0.2803s	
1493/2700 (epoch 27.648), train_loss = 1.55757203, grad/param norm = 1.6039e-01, time/batch = 0.3184s	
1494/2700 (epoch 27.667), train_loss = 1.53553884, grad/param norm = 1.6167e-01, time/batch = 0.3310s	
1495/2700 (epoch 27.685), train_loss = 1.59261137, grad/param norm = 1.8420e-01, time/batch = 0.3145s	
1496/2700 (epoch 27.704), train_loss = 1.59455588, grad/param norm = 1.8048e-01, time/batch = 0.3201s	
1497/2700 (epoch 27.722), train_loss = 1.57267629, grad/param norm = 1.6043e-01, time/batch = 0.2983s	
1498/2700 (epoch 27.741), train_loss = 1.57227631, grad/param norm = 1.9300e-01, time/batch = 0.2919s	
1499/2700 (epoch 27.759), train_loss = 1.58231012, grad/param norm = 1.7847e-01, time/batch = 0.3007s	
1500/2700 (epoch 27.778), train_loss = 1.62408427, grad/param norm = 1.6824e-01, time/batch = 0.2995s	
1501/2700 (epoch 27.796), train_loss = 1.54364905, grad/param norm = 1.9476e-01, time/batch = 0.3407s	
1502/2700 (epoch 27.815), train_loss = 1.60436073, grad/param norm = 1.9405e-01, time/batch = 0.3366s	
1503/2700 (epoch 27.833), train_loss = 1.57591169, grad/param norm = 1.8817e-01, time/batch = 0.3353s	
1504/2700 (epoch 27.852), train_loss = 1.54795914, grad/param norm = 1.9227e-01, time/batch = 0.3250s	
1505/2700 (epoch 27.870), train_loss = 1.58346512, grad/param norm = 1.8722e-01, time/batch = 0.3000s	
1506/2700 (epoch 27.889), train_loss = 1.58712446, grad/param norm = 1.9242e-01, time/batch = 0.2766s	
1507/2700 (epoch 27.907), train_loss = 1.67416634, grad/param norm = 1.9297e-01, time/batch = 0.2792s	
1508/2700 (epoch 27.926), train_loss = 1.64234175, grad/param norm = 1.9756e-01, time/batch = 0.2650s	
1509/2700 (epoch 27.944), train_loss = 1.60269329, grad/param norm = 1.8507e-01, time/batch = 0.2602s	
1510/2700 (epoch 27.963), train_loss = 1.62442785, grad/param norm = 1.5208e-01, time/batch = 0.2955s	
1511/2700 (epoch 27.981), train_loss = 1.57835176, grad/param norm = 1.5843e-01, time/batch = 0.2867s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1512/2700 (epoch 28.000), train_loss = 1.62369565, grad/param norm = 1.6560e-01, time/batch = 0.2766s	
1513/2700 (epoch 28.019), train_loss = 1.66697328, grad/param norm = 1.7147e-01, time/batch = 0.3371s	
1514/2700 (epoch 28.037), train_loss = 1.63257200, grad/param norm = 1.8608e-01, time/batch = 0.3342s	
1515/2700 (epoch 28.056), train_loss = 1.58509672, grad/param norm = 1.6476e-01, time/batch = 0.3344s	
1516/2700 (epoch 28.074), train_loss = 1.56723037, grad/param norm = 1.6617e-01, time/batch = 0.3252s	
1517/2700 (epoch 28.093), train_loss = 1.54815571, grad/param norm = 1.7873e-01, time/batch = 0.3240s	
1518/2700 (epoch 28.111), train_loss = 1.53052885, grad/param norm = 1.7891e-01, time/batch = 0.3071s	
1519/2700 (epoch 28.130), train_loss = 1.58882168, grad/param norm = 1.9666e-01, time/batch = 0.2887s	
1520/2700 (epoch 28.148), train_loss = 1.53291863, grad/param norm = 1.6936e-01, time/batch = 0.2821s	
1521/2700 (epoch 28.167), train_loss = 1.63742745, grad/param norm = 1.5556e-01, time/batch = 0.3120s	
1522/2700 (epoch 28.185), train_loss = 1.54222892, grad/param norm = 1.7791e-01, time/batch = 0.3298s	
1523/2700 (epoch 28.204), train_loss = 1.59126713, grad/param norm = 1.5816e-01, time/batch = 0.3342s	
1524/2700 (epoch 28.222), train_loss = 1.54419046, grad/param norm = 1.4602e-01, time/batch = 0.2972s	
1525/2700 (epoch 28.241), train_loss = 1.48133291, grad/param norm = 1.6437e-01, time/batch = 0.3093s	
1526/2700 (epoch 28.259), train_loss = 1.52971274, grad/param norm = 1.7336e-01, time/batch = 0.3112s	
1527/2700 (epoch 28.278), train_loss = 1.58337934, grad/param norm = 1.6555e-01, time/batch = 0.2800s	
1528/2700 (epoch 28.296), train_loss = 1.57639277, grad/param norm = 1.6737e-01, time/batch = 0.3101s	
1529/2700 (epoch 28.315), train_loss = 1.58582024, grad/param norm = 1.6581e-01, time/batch = 0.3012s	
1530/2700 (epoch 28.333), train_loss = 1.57743503, grad/param norm = 1.8338e-01, time/batch = 0.2380s	
1531/2700 (epoch 28.352), train_loss = 1.56324155, grad/param norm = 1.7960e-01, time/batch = 0.2640s	
1532/2700 (epoch 28.370), train_loss = 1.56602010, grad/param norm = 1.7008e-01, time/batch = 0.2919s	
1533/2700 (epoch 28.389), train_loss = 1.54208511, grad/param norm = 1.6091e-01, time/batch = 0.3187s	
1534/2700 (epoch 28.407), train_loss = 1.60131193, grad/param norm = 1.5952e-01, time/batch = 0.3102s	
1535/2700 (epoch 28.426), train_loss = 1.64615673, grad/param norm = 1.6523e-01, time/batch = 0.3027s	
1536/2700 (epoch 28.444), train_loss = 1.54106908, grad/param norm = 1.6665e-01, time/batch = 0.2358s	
1537/2700 (epoch 28.463), train_loss = 1.61970863, grad/param norm = 1.8077e-01, time/batch = 0.2982s	
1538/2700 (epoch 28.481), train_loss = 1.61023693, grad/param norm = 1.7507e-01, time/batch = 0.3081s	
1539/2700 (epoch 28.500), train_loss = 1.54433701, grad/param norm = 1.9285e-01, time/batch = 0.3374s	
1540/2700 (epoch 28.519), train_loss = 1.60044694, grad/param norm = 1.7563e-01, time/batch = 0.3315s	
1541/2700 (epoch 28.537), train_loss = 1.60159976, grad/param norm = 1.9209e-01, time/batch = 0.3201s	
1542/2700 (epoch 28.556), train_loss = 1.53281146, grad/param norm = 1.8053e-01, time/batch = 0.3280s	
1543/2700 (epoch 28.574), train_loss = 1.54228653, grad/param norm = 1.6271e-01, time/batch = 0.3332s	
1544/2700 (epoch 28.593), train_loss = 1.56794547, grad/param norm = 1.6347e-01, time/batch = 0.3334s	
1545/2700 (epoch 28.611), train_loss = 1.48971882, grad/param norm = 1.5095e-01, time/batch = 0.3296s	
1546/2700 (epoch 28.630), train_loss = 1.50400154, grad/param norm = 1.5618e-01, time/batch = 0.3136s	
1547/2700 (epoch 28.648), train_loss = 1.54123949, grad/param norm = 1.5534e-01, time/batch = 0.2563s	
1548/2700 (epoch 28.667), train_loss = 1.52246110, grad/param norm = 1.8648e-01, time/batch = 0.3326s	
1549/2700 (epoch 28.685), train_loss = 1.58093313, grad/param norm = 1.8665e-01, time/batch = 0.3051s	
1550/2700 (epoch 28.704), train_loss = 1.57826056, grad/param norm = 1.8880e-01, time/batch = 0.2899s	
1551/2700 (epoch 28.722), train_loss = 1.56214732, grad/param norm = 1.9125e-01, time/batch = 0.3248s	
1552/2700 (epoch 28.741), train_loss = 1.55420607, grad/param norm = 1.9513e-01, time/batch = 0.3014s	
1553/2700 (epoch 28.759), train_loss = 1.56804491, grad/param norm = 2.2219e-01, time/batch = 0.2636s	
1554/2700 (epoch 28.778), train_loss = 1.61416644, grad/param norm = 2.0664e-01, time/batch = 0.2569s	
1555/2700 (epoch 28.796), train_loss = 1.52483230, grad/param norm = 1.6904e-01, time/batch = 0.2753s	
1556/2700 (epoch 28.815), train_loss = 1.58174142, grad/param norm = 1.8012e-01, time/batch = 0.3056s	
1557/2700 (epoch 28.833), train_loss = 1.55969118, grad/param norm = 1.9851e-01, time/batch = 0.2995s	
1558/2700 (epoch 28.852), train_loss = 1.52956951, grad/param norm = 1.8134e-01, time/batch = 0.2915s	
1559/2700 (epoch 28.870), train_loss = 1.56456451, grad/param norm = 1.6067e-01, time/batch = 0.2549s	
1560/2700 (epoch 28.889), train_loss = 1.56699785, grad/param norm = 1.5981e-01, time/batch = 0.3099s	
1561/2700 (epoch 28.907), train_loss = 1.65954817, grad/param norm = 1.9803e-01, time/batch = 0.2820s	
1562/2700 (epoch 28.926), train_loss = 1.63551734, grad/param norm = 2.5578e-01, time/batch = 0.3054s	
1563/2700 (epoch 28.944), train_loss = 1.59411271, grad/param norm = 2.2710e-01, time/batch = 0.2930s	
1564/2700 (epoch 28.963), train_loss = 1.61242184, grad/param norm = 1.7941e-01, time/batch = 0.2694s	
1565/2700 (epoch 28.981), train_loss = 1.56090681, grad/param norm = 1.6335e-01, time/batch = 0.2784s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
1566/2700 (epoch 29.000), train_loss = 1.61042305, grad/param norm = 1.7369e-01, time/batch = 0.3025s	
1567/2700 (epoch 29.019), train_loss = 1.65451963, grad/param norm = 1.7022e-01, time/batch = 0.3202s	
1568/2700 (epoch 29.037), train_loss = 1.61410393, grad/param norm = 1.7702e-01, time/batch = 0.3051s	
1569/2700 (epoch 29.056), train_loss = 1.56862618, grad/param norm = 1.6143e-01, time/batch = 0.2908s	
1570/2700 (epoch 29.074), train_loss = 1.55144906, grad/param norm = 1.6783e-01, time/batch = 0.2861s	
1571/2700 (epoch 29.093), train_loss = 1.53195762, grad/param norm = 1.6947e-01, time/batch = 0.2888s	
1572/2700 (epoch 29.111), train_loss = 1.51466025, grad/param norm = 1.7913e-01, time/batch = 0.2355s	
1573/2700 (epoch 29.130), train_loss = 1.57459558, grad/param norm = 1.7664e-01, time/batch = 0.3008s	
1574/2700 (epoch 29.148), train_loss = 1.51775915, grad/param norm = 1.5867e-01, time/batch = 0.2948s	
1575/2700 (epoch 29.167), train_loss = 1.62436014, grad/param norm = 1.7329e-01, time/batch = 0.3058s	
1576/2700 (epoch 29.185), train_loss = 1.53292424, grad/param norm = 2.0733e-01, time/batch = 0.3069s	
1577/2700 (epoch 29.204), train_loss = 1.57773521, grad/param norm = 1.6369e-01, time/batch = 0.2964s	
1578/2700 (epoch 29.222), train_loss = 1.52956268, grad/param norm = 1.5204e-01, time/batch = 0.2826s	
1579/2700 (epoch 29.241), train_loss = 1.46839189, grad/param norm = 1.6740e-01, time/batch = 0.3034s	
1580/2700 (epoch 29.259), train_loss = 1.51509494, grad/param norm = 1.6704e-01, time/batch = 0.3109s	
1581/2700 (epoch 29.278), train_loss = 1.56724609, grad/param norm = 1.5945e-01, time/batch = 0.3125s	
1582/2700 (epoch 29.296), train_loss = 1.55975898, grad/param norm = 1.6249e-01, time/batch = 0.3127s	
1583/2700 (epoch 29.315), train_loss = 1.57152119, grad/param norm = 1.6338e-01, time/batch = 0.3068s	
1584/2700 (epoch 29.333), train_loss = 1.56394322, grad/param norm = 1.8127e-01, time/batch = 0.2683s	
1585/2700 (epoch 29.352), train_loss = 1.54664627, grad/param norm = 1.7367e-01, time/batch = 0.2523s	
1586/2700 (epoch 29.370), train_loss = 1.54654358, grad/param norm = 1.6512e-01, time/batch = 0.2794s	
1587/2700 (epoch 29.389), train_loss = 1.52449843, grad/param norm = 1.5714e-01, time/batch = 0.2874s	
1588/2700 (epoch 29.407), train_loss = 1.58655057, grad/param norm = 1.5314e-01, time/batch = 0.3054s	
1589/2700 (epoch 29.426), train_loss = 1.62947553, grad/param norm = 1.5357e-01, time/batch = 0.2909s	
1590/2700 (epoch 29.444), train_loss = 1.52726361, grad/param norm = 1.5603e-01, time/batch = 0.2859s	
1591/2700 (epoch 29.463), train_loss = 1.60178387, grad/param norm = 1.6417e-01, time/batch = 0.2706s	
1592/2700 (epoch 29.481), train_loss = 1.59251711, grad/param norm = 1.5815e-01, time/batch = 0.2854s	
1593/2700 (epoch 29.500), train_loss = 1.52413013, grad/param norm = 1.6692e-01, time/batch = 0.3193s	
1594/2700 (epoch 29.519), train_loss = 1.58413265, grad/param norm = 1.6573e-01, time/batch = 0.3221s	
1595/2700 (epoch 29.537), train_loss = 1.58533686, grad/param norm = 1.8151e-01, time/batch = 0.3165s	
1596/2700 (epoch 29.556), train_loss = 1.51729736, grad/param norm = 1.7460e-01, time/batch = 0.2816s	
1597/2700 (epoch 29.574), train_loss = 1.52890557, grad/param norm = 1.8890e-01, time/batch = 0.2763s	
1598/2700 (epoch 29.593), train_loss = 1.56038176, grad/param norm = 2.1813e-01, time/batch = 0.2740s	
1599/2700 (epoch 29.611), train_loss = 1.48021707, grad/param norm = 1.7575e-01, time/batch = 0.2641s	
1600/2700 (epoch 29.630), train_loss = 1.48926595, grad/param norm = 1.5643e-01, time/batch = 0.2620s	
1601/2700 (epoch 29.648), train_loss = 1.52555563, grad/param norm = 1.6131e-01, time/batch = 0.2470s	
1602/2700 (epoch 29.667), train_loss = 1.50445533, grad/param norm = 1.5430e-01, time/batch = 0.2759s	
1603/2700 (epoch 29.685), train_loss = 1.56231534, grad/param norm = 1.7366e-01, time/batch = 0.2887s	
1604/2700 (epoch 29.704), train_loss = 1.56185413, grad/param norm = 1.7387e-01, time/batch = 0.3239s	
1605/2700 (epoch 29.722), train_loss = 1.54424217, grad/param norm = 1.6010e-01, time/batch = 0.3326s	
1606/2700 (epoch 29.741), train_loss = 1.53488076, grad/param norm = 1.6924e-01, time/batch = 0.3285s	
1607/2700 (epoch 29.759), train_loss = 1.54749468, grad/param norm = 1.8576e-01, time/batch = 0.2982s	
1608/2700 (epoch 29.778), train_loss = 1.59406319, grad/param norm = 1.6649e-01, time/batch = 0.2720s	
1609/2700 (epoch 29.796), train_loss = 1.50829805, grad/param norm = 1.8515e-01, time/batch = 0.2785s	
1610/2700 (epoch 29.815), train_loss = 1.56847851, grad/param norm = 1.8507e-01, time/batch = 0.2947s	
1611/2700 (epoch 29.833), train_loss = 1.54794897, grad/param norm = 1.9520e-01, time/batch = 0.3051s	
1612/2700 (epoch 29.852), train_loss = 1.51757342, grad/param norm = 2.0146e-01, time/batch = 0.2959s	
1613/2700 (epoch 29.870), train_loss = 1.55501915, grad/param norm = 1.9715e-01, time/batch = 0.2966s	
1614/2700 (epoch 29.889), train_loss = 1.55713927, grad/param norm = 2.0124e-01, time/batch = 0.2701s	
1615/2700 (epoch 29.907), train_loss = 1.64298869, grad/param norm = 1.9107e-01, time/batch = 0.2690s	
1616/2700 (epoch 29.926), train_loss = 1.60783378, grad/param norm = 1.8737e-01, time/batch = 0.2697s	
1617/2700 (epoch 29.944), train_loss = 1.56997092, grad/param norm = 1.8684e-01, time/batch = 0.2776s	
1618/2700 (epoch 29.963), train_loss = 1.59544734, grad/param norm = 1.7026e-01, time/batch = 0.2707s	
1619/2700 (epoch 29.981), train_loss = 1.54615893, grad/param norm = 1.7710e-01, time/batch = 0.2624s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
1620/2700 (epoch 30.000), train_loss = 1.59378261, grad/param norm = 1.7218e-01, time/batch = 0.3038s	
1621/2700 (epoch 30.019), train_loss = 1.63974868, grad/param norm = 1.7455e-01, time/batch = 0.2729s	
1622/2700 (epoch 30.037), train_loss = 1.60038439, grad/param norm = 1.8455e-01, time/batch = 0.3051s	
1623/2700 (epoch 30.056), train_loss = 1.55567933, grad/param norm = 1.7287e-01, time/batch = 0.3257s	
1624/2700 (epoch 30.074), train_loss = 1.53847597, grad/param norm = 1.7882e-01, time/batch = 0.3324s	
1625/2700 (epoch 30.093), train_loss = 1.51744246, grad/param norm = 1.7011e-01, time/batch = 0.3103s	
1626/2700 (epoch 30.111), train_loss = 1.49930269, grad/param norm = 1.6933e-01, time/batch = 0.3296s	
1627/2700 (epoch 30.130), train_loss = 1.55665635, grad/param norm = 1.8668e-01, time/batch = 0.3148s	
1628/2700 (epoch 30.148), train_loss = 1.50298925, grad/param norm = 1.6395e-01, time/batch = 0.2838s	
1629/2700 (epoch 30.167), train_loss = 1.60836558, grad/param norm = 1.6801e-01, time/batch = 0.2819s	
1630/2700 (epoch 30.185), train_loss = 1.51848398, grad/param norm = 2.0331e-01, time/batch = 0.2559s	
1631/2700 (epoch 30.204), train_loss = 1.56187678, grad/param norm = 1.5982e-01, time/batch = 0.3370s	
1632/2700 (epoch 30.222), train_loss = 1.51554073, grad/param norm = 1.4719e-01, time/batch = 0.3282s	
1633/2700 (epoch 30.241), train_loss = 1.45310414, grad/param norm = 1.6338e-01, time/batch = 0.3049s	
1634/2700 (epoch 30.259), train_loss = 1.50176608, grad/param norm = 1.6724e-01, time/batch = 0.2638s	
1635/2700 (epoch 30.278), train_loss = 1.55153466, grad/param norm = 1.6246e-01, time/batch = 0.2516s	
1636/2700 (epoch 30.296), train_loss = 1.54486657, grad/param norm = 1.6068e-01, time/batch = 0.2366s	
1637/2700 (epoch 30.315), train_loss = 1.55694259, grad/param norm = 1.5867e-01, time/batch = 0.3372s	
1638/2700 (epoch 30.333), train_loss = 1.54801392, grad/param norm = 1.7765e-01, time/batch = 0.3325s	
1639/2700 (epoch 30.352), train_loss = 1.53611099, grad/param norm = 1.8345e-01, time/batch = 0.3134s	
1640/2700 (epoch 30.370), train_loss = 1.53471697, grad/param norm = 1.9847e-01, time/batch = 0.2941s	
1641/2700 (epoch 30.389), train_loss = 1.51361089, grad/param norm = 1.8267e-01, time/batch = 0.3014s	
1642/2700 (epoch 30.407), train_loss = 1.57655024, grad/param norm = 1.7720e-01, time/batch = 0.2821s	
1643/2700 (epoch 30.426), train_loss = 1.61878972, grad/param norm = 1.7293e-01, time/batch = 0.3359s	
1644/2700 (epoch 30.444), train_loss = 1.51466188, grad/param norm = 1.6930e-01, time/batch = 0.3391s	
1645/2700 (epoch 30.463), train_loss = 1.59001266, grad/param norm = 1.7464e-01, time/batch = 0.3245s	
1646/2700 (epoch 30.481), train_loss = 1.57942056, grad/param norm = 1.9388e-01, time/batch = 0.3053s	
1647/2700 (epoch 30.500), train_loss = 1.51498520, grad/param norm = 2.0657e-01, time/batch = 0.2606s	
1648/2700 (epoch 30.519), train_loss = 1.56915176, grad/param norm = 1.7760e-01, time/batch = 0.2523s	
1649/2700 (epoch 30.537), train_loss = 1.57168360, grad/param norm = 1.9035e-01, time/batch = 0.2805s	
1650/2700 (epoch 30.556), train_loss = 1.50216937, grad/param norm = 1.7078e-01, time/batch = 0.2934s	
1651/2700 (epoch 30.574), train_loss = 1.51072648, grad/param norm = 1.6467e-01, time/batch = 0.2689s	
1652/2700 (epoch 30.593), train_loss = 1.53996422, grad/param norm = 1.6682e-01, time/batch = 0.2732s	
1653/2700 (epoch 30.611), train_loss = 1.46239616, grad/param norm = 1.5100e-01, time/batch = 0.2909s	
1654/2700 (epoch 30.630), train_loss = 1.47376765, grad/param norm = 1.5944e-01, time/batch = 0.2914s	
1655/2700 (epoch 30.648), train_loss = 1.51036661, grad/param norm = 1.5613e-01, time/batch = 0.3128s	
1656/2700 (epoch 30.667), train_loss = 1.49328875, grad/param norm = 1.9035e-01, time/batch = 0.2912s	
1657/2700 (epoch 30.685), train_loss = 1.55306606, grad/param norm = 1.8640e-01, time/batch = 0.2896s	
1658/2700 (epoch 30.704), train_loss = 1.54704291, grad/param norm = 1.8674e-01, time/batch = 0.2918s	
1659/2700 (epoch 30.722), train_loss = 1.53515601, grad/param norm = 1.8929e-01, time/batch = 0.2731s	
1660/2700 (epoch 30.741), train_loss = 1.51890002, grad/param norm = 1.8169e-01, time/batch = 0.2649s	
1661/2700 (epoch 30.759), train_loss = 1.52964485, grad/param norm = 1.9521e-01, time/batch = 0.2568s	
1662/2700 (epoch 30.778), train_loss = 1.58073887, grad/param norm = 1.8007e-01, time/batch = 0.2475s	
1663/2700 (epoch 30.796), train_loss = 1.49104093, grad/param norm = 1.7062e-01, time/batch = 0.2878s	
1664/2700 (epoch 30.815), train_loss = 1.54779193, grad/param norm = 1.6592e-01, time/batch = 0.3202s	
1665/2700 (epoch 30.833), train_loss = 1.53045587, grad/param norm = 1.8378e-01, time/batch = 0.3274s	
1666/2700 (epoch 30.852), train_loss = 1.49921903, grad/param norm = 1.8166e-01, time/batch = 0.3189s	
1667/2700 (epoch 30.870), train_loss = 1.53665287, grad/param norm = 1.5963e-01, time/batch = 0.2808s	
1668/2700 (epoch 30.889), train_loss = 1.53665556, grad/param norm = 1.6210e-01, time/batch = 0.2759s	
1669/2700 (epoch 30.907), train_loss = 1.62753119, grad/param norm = 1.9812e-01, time/batch = 0.3054s	
1670/2700 (epoch 30.926), train_loss = 1.59855561, grad/param norm = 2.3163e-01, time/batch = 0.2976s	
1671/2700 (epoch 30.944), train_loss = 1.55873149, grad/param norm = 2.1217e-01, time/batch = 0.3260s	
1672/2700 (epoch 30.963), train_loss = 1.58158589, grad/param norm = 1.8250e-01, time/batch = 0.3059s	
1673/2700 (epoch 30.981), train_loss = 1.52931029, grad/param norm = 1.8759e-01, time/batch = 0.2897s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
1674/2700 (epoch 31.000), train_loss = 1.58410682, grad/param norm = 1.9123e-01, time/batch = 0.2784s	
1675/2700 (epoch 31.019), train_loss = 1.62877201, grad/param norm = 1.7985e-01, time/batch = 0.2740s	
1676/2700 (epoch 31.037), train_loss = 1.58251317, grad/param norm = 1.7331e-01, time/batch = 0.2953s	
1677/2700 (epoch 31.056), train_loss = 1.54021217, grad/param norm = 1.6094e-01, time/batch = 0.3138s	
1678/2700 (epoch 31.074), train_loss = 1.52356052, grad/param norm = 1.6368e-01, time/batch = 0.2886s	
1679/2700 (epoch 31.093), train_loss = 1.50502355, grad/param norm = 1.7205e-01, time/batch = 0.2264s	
1680/2700 (epoch 31.111), train_loss = 1.48524734, grad/param norm = 1.7935e-01, time/batch = 0.2708s	
1681/2700 (epoch 31.130), train_loss = 1.54565098, grad/param norm = 2.0003e-01, time/batch = 0.2972s	
1682/2700 (epoch 31.148), train_loss = 1.48980278, grad/param norm = 1.6691e-01, time/batch = 0.3138s	
1683/2700 (epoch 31.167), train_loss = 1.59464370, grad/param norm = 1.6097e-01, time/batch = 0.3018s	
1684/2700 (epoch 31.185), train_loss = 1.50375419, grad/param norm = 1.7721e-01, time/batch = 0.3016s	
1685/2700 (epoch 31.204), train_loss = 1.55277067, grad/param norm = 1.9015e-01, time/batch = 0.3024s	
1686/2700 (epoch 31.222), train_loss = 1.50493736, grad/param norm = 1.6884e-01, time/batch = 0.2938s	
1687/2700 (epoch 31.241), train_loss = 1.44024145, grad/param norm = 1.5988e-01, time/batch = 0.2816s	
1688/2700 (epoch 31.259), train_loss = 1.49066923, grad/param norm = 1.7339e-01, time/batch = 0.2975s	
1689/2700 (epoch 31.278), train_loss = 1.53898016, grad/param norm = 1.7180e-01, time/batch = 0.3086s	
1690/2700 (epoch 31.296), train_loss = 1.53138970, grad/param norm = 1.6136e-01, time/batch = 0.2632s	
1691/2700 (epoch 31.315), train_loss = 1.54302358, grad/param norm = 1.5319e-01, time/batch = 0.3100s	
1692/2700 (epoch 31.333), train_loss = 1.53429489, grad/param norm = 1.6748e-01, time/batch = 0.2723s	
1693/2700 (epoch 31.352), train_loss = 1.52007621, grad/param norm = 1.7534e-01, time/batch = 0.2473s	
1694/2700 (epoch 31.370), train_loss = 1.51775747, grad/param norm = 1.8221e-01, time/batch = 0.2703s	
1695/2700 (epoch 31.389), train_loss = 1.49501377, grad/param norm = 1.6125e-01, time/batch = 0.3044s	
1696/2700 (epoch 31.407), train_loss = 1.56316957, grad/param norm = 1.6183e-01, time/batch = 0.3144s	
1697/2700 (epoch 31.426), train_loss = 1.60257046, grad/param norm = 1.5563e-01, time/batch = 0.3093s	
1698/2700 (epoch 31.444), train_loss = 1.50333966, grad/param norm = 1.6214e-01, time/batch = 0.2932s	
1699/2700 (epoch 31.463), train_loss = 1.57559474, grad/param norm = 1.7022e-01, time/batch = 0.2953s	
1700/2700 (epoch 31.481), train_loss = 1.56360886, grad/param norm = 1.6162e-01, time/batch = 0.3086s	
1701/2700 (epoch 31.500), train_loss = 1.49535071, grad/param norm = 1.7899e-01, time/batch = 0.2875s	
1702/2700 (epoch 31.519), train_loss = 1.55794100, grad/param norm = 1.9275e-01, time/batch = 0.3168s	
1703/2700 (epoch 31.537), train_loss = 1.55963275, grad/param norm = 2.0310e-01, time/batch = 0.3390s	
1704/2700 (epoch 31.556), train_loss = 1.49167078, grad/param norm = 1.9241e-01, time/batch = 0.3382s	
1705/2700 (epoch 31.574), train_loss = 1.49976668, grad/param norm = 1.9150e-01, time/batch = 0.3224s	
1706/2700 (epoch 31.593), train_loss = 1.53338702, grad/param norm = 2.1025e-01, time/batch = 0.2950s	
1707/2700 (epoch 31.611), train_loss = 1.45270168, grad/param norm = 1.6486e-01, time/batch = 0.2762s	
1708/2700 (epoch 31.630), train_loss = 1.45992762, grad/param norm = 1.4933e-01, time/batch = 0.2825s	
1709/2700 (epoch 31.648), train_loss = 1.49598780, grad/param norm = 1.5879e-01, time/batch = 0.2664s	
1710/2700 (epoch 31.667), train_loss = 1.47724174, grad/param norm = 1.6699e-01, time/batch = 0.2645s	
1711/2700 (epoch 31.685), train_loss = 1.53791662, grad/param norm = 1.7430e-01, time/batch = 0.2418s	
1712/2700 (epoch 31.704), train_loss = 1.53273110, grad/param norm = 1.7571e-01, time/batch = 0.2508s	
1713/2700 (epoch 31.722), train_loss = 1.51762245, grad/param norm = 1.6230e-01, time/batch = 0.3116s	
1714/2700 (epoch 31.741), train_loss = 1.50432910, grad/param norm = 1.7574e-01, time/batch = 0.3167s	
1715/2700 (epoch 31.759), train_loss = 1.51560090, grad/param norm = 1.9620e-01, time/batch = 0.3398s	
1716/2700 (epoch 31.778), train_loss = 1.56588743, grad/param norm = 1.7016e-01, time/batch = 0.3417s	
1717/2700 (epoch 31.796), train_loss = 1.47646928, grad/param norm = 1.9502e-01, time/batch = 0.3253s	
1718/2700 (epoch 31.815), train_loss = 1.53731637, grad/param norm = 1.8383e-01, time/batch = 0.3024s	
1719/2700 (epoch 31.833), train_loss = 1.51859630, grad/param norm = 1.8917e-01, time/batch = 0.2805s	
1720/2700 (epoch 31.852), train_loss = 1.48327069, grad/param norm = 1.7335e-01, time/batch = 0.2890s	
1721/2700 (epoch 31.870), train_loss = 1.52669392, grad/param norm = 1.8704e-01, time/batch = 0.3104s	
1722/2700 (epoch 31.889), train_loss = 1.52768776, grad/param norm = 1.9249e-01, time/batch = 0.2985s	
1723/2700 (epoch 31.907), train_loss = 1.61620259, grad/param norm = 1.9760e-01, time/batch = 0.2807s	
1724/2700 (epoch 31.926), train_loss = 1.57853571, grad/param norm = 2.0541e-01, time/batch = 0.2493s	
1725/2700 (epoch 31.944), train_loss = 1.54109622, grad/param norm = 1.9092e-01, time/batch = 0.2556s	
1726/2700 (epoch 31.963), train_loss = 1.56584633, grad/param norm = 1.6138e-01, time/batch = 0.2661s	
1727/2700 (epoch 31.981), train_loss = 1.51557582, grad/param norm = 1.7648e-01, time/batch = 0.2922s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
1728/2700 (epoch 32.000), train_loss = 1.56544422, grad/param norm = 1.7115e-01, time/batch = 0.2944s	
1729/2700 (epoch 32.019), train_loss = 1.61424813, grad/param norm = 1.7735e-01, time/batch = 0.3171s	
1730/2700 (epoch 32.037), train_loss = 1.57188129, grad/param norm = 1.9205e-01, time/batch = 0.3274s	
1731/2700 (epoch 32.056), train_loss = 1.52878047, grad/param norm = 1.7339e-01, time/batch = 0.3050s	
1732/2700 (epoch 32.074), train_loss = 1.51064033, grad/param norm = 1.6890e-01, time/batch = 0.3174s	
1733/2700 (epoch 32.093), train_loss = 1.49128485, grad/param norm = 1.7594e-01, time/batch = 0.3188s	
1734/2700 (epoch 32.111), train_loss = 1.47042830, grad/param norm = 1.7388e-01, time/batch = 0.3362s	
1735/2700 (epoch 32.130), train_loss = 1.52771084, grad/param norm = 1.8773e-01, time/batch = 0.3369s	
1736/2700 (epoch 32.148), train_loss = 1.47602664, grad/param norm = 1.5960e-01, time/batch = 0.3366s	
1737/2700 (epoch 32.167), train_loss = 1.58115627, grad/param norm = 1.7343e-01, time/batch = 0.3205s	
1738/2700 (epoch 32.185), train_loss = 1.49393928, grad/param norm = 2.0802e-01, time/batch = 0.2470s	
1739/2700 (epoch 32.204), train_loss = 1.53574347, grad/param norm = 1.5972e-01, time/batch = 0.3105s	
1740/2700 (epoch 32.222), train_loss = 1.49046322, grad/param norm = 1.5129e-01, time/batch = 0.2942s	
1741/2700 (epoch 32.241), train_loss = 1.42851449, grad/param norm = 1.7566e-01, time/batch = 0.3410s	
1742/2700 (epoch 32.259), train_loss = 1.47804691, grad/param norm = 1.6903e-01, time/batch = 0.3247s	
1743/2700 (epoch 32.278), train_loss = 1.52433708, grad/param norm = 1.6052e-01, time/batch = 0.2854s	
1744/2700 (epoch 32.296), train_loss = 1.51865577, grad/param norm = 1.6568e-01, time/batch = 0.2451s	
1745/2700 (epoch 32.315), train_loss = 1.53234782, grad/param norm = 1.7616e-01, time/batch = 0.2571s	
1746/2700 (epoch 32.333), train_loss = 1.52415311, grad/param norm = 1.8773e-01, time/batch = 0.2984s	
1747/2700 (epoch 32.352), train_loss = 1.50699101, grad/param norm = 1.7554e-01, time/batch = 0.3110s	
1748/2700 (epoch 32.370), train_loss = 1.50073880, grad/param norm = 1.7003e-01, time/batch = 0.3126s	
1749/2700 (epoch 32.389), train_loss = 1.48135283, grad/param norm = 1.6802e-01, time/batch = 0.3106s	
1750/2700 (epoch 32.407), train_loss = 1.55206008, grad/param norm = 1.6389e-01, time/batch = 0.2756s	
1751/2700 (epoch 32.426), train_loss = 1.58881393, grad/param norm = 1.5984e-01, time/batch = 0.3028s	
1752/2700 (epoch 32.444), train_loss = 1.49158303, grad/param norm = 1.5871e-01, time/batch = 0.3217s	
1753/2700 (epoch 32.463), train_loss = 1.56182413, grad/param norm = 1.6724e-01, time/batch = 0.3190s	
1754/2700 (epoch 32.481), train_loss = 1.54856595, grad/param norm = 1.6055e-01, time/batch = 0.3275s	
1755/2700 (epoch 32.500), train_loss = 1.47949969, grad/param norm = 1.6548e-01, time/batch = 0.3386s	
1756/2700 (epoch 32.519), train_loss = 1.54019850, grad/param norm = 1.5778e-01, time/batch = 0.3357s	
1757/2700 (epoch 32.537), train_loss = 1.54240756, grad/param norm = 1.7911e-01, time/batch = 0.3234s	
1758/2700 (epoch 32.556), train_loss = 1.47547104, grad/param norm = 1.6895e-01, time/batch = 0.3011s	
1759/2700 (epoch 32.574), train_loss = 1.48238058, grad/param norm = 1.7004e-01, time/batch = 0.3002s	
1760/2700 (epoch 32.593), train_loss = 1.51740851, grad/param norm = 1.8848e-01, time/batch = 0.3166s	
1761/2700 (epoch 32.611), train_loss = 1.43946299, grad/param norm = 1.5994e-01, time/batch = 0.3094s	
1762/2700 (epoch 32.630), train_loss = 1.44512280, grad/param norm = 1.4745e-01, time/batch = 0.3404s	
1763/2700 (epoch 32.648), train_loss = 1.48227869, grad/param norm = 1.5455e-01, time/batch = 0.3261s	
1764/2700 (epoch 32.667), train_loss = 1.46533694, grad/param norm = 1.7892e-01, time/batch = 0.3190s	
1765/2700 (epoch 32.685), train_loss = 1.52629727, grad/param norm = 1.7656e-01, time/batch = 0.3010s	
1766/2700 (epoch 32.704), train_loss = 1.51787764, grad/param norm = 1.7032e-01, time/batch = 0.2843s	
1767/2700 (epoch 32.722), train_loss = 1.50512598, grad/param norm = 1.5786e-01, time/batch = 0.2663s	
1768/2700 (epoch 32.741), train_loss = 1.48579747, grad/param norm = 1.6409e-01, time/batch = 0.2668s	
1769/2700 (epoch 32.759), train_loss = 1.49896513, grad/param norm = 1.7495e-01, time/batch = 0.2748s	
1770/2700 (epoch 32.778), train_loss = 1.55556552, grad/param norm = 1.9755e-01, time/batch = 0.2782s	
1771/2700 (epoch 32.796), train_loss = 1.47095719, grad/param norm = 2.4244e-01, time/batch = 0.2637s	
1772/2700 (epoch 32.815), train_loss = 1.52528941, grad/param norm = 2.0080e-01, time/batch = 0.2989s	
1773/2700 (epoch 32.833), train_loss = 1.50919400, grad/param norm = 2.0636e-01, time/batch = 0.2983s	
1774/2700 (epoch 32.852), train_loss = 1.47495208, grad/param norm = 2.1239e-01, time/batch = 0.2961s	
1775/2700 (epoch 32.870), train_loss = 1.51554590, grad/param norm = 1.9408e-01, time/batch = 0.2716s	
1776/2700 (epoch 32.889), train_loss = 1.51427189, grad/param norm = 1.9917e-01, time/batch = 0.3004s	
1777/2700 (epoch 32.907), train_loss = 1.60266317, grad/param norm = 1.9487e-01, time/batch = 0.3050s	
1778/2700 (epoch 32.926), train_loss = 1.56318011, grad/param norm = 1.8706e-01, time/batch = 0.2982s	
1779/2700 (epoch 32.944), train_loss = 1.52783685, grad/param norm = 1.9299e-01, time/batch = 0.2718s	
1780/2700 (epoch 32.963), train_loss = 1.55404030, grad/param norm = 1.8231e-01, time/batch = 0.2363s	
1781/2700 (epoch 32.981), train_loss = 1.50513741, grad/param norm = 1.8838e-01, time/batch = 0.2462s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
1782/2700 (epoch 33.000), train_loss = 1.55341370, grad/param norm = 1.8490e-01, time/batch = 0.2922s	
1783/2700 (epoch 33.019), train_loss = 1.60238123, grad/param norm = 1.7433e-01, time/batch = 0.3220s	
1784/2700 (epoch 33.037), train_loss = 1.55464083, grad/param norm = 1.7614e-01, time/batch = 0.3247s	
1785/2700 (epoch 33.056), train_loss = 1.51635834, grad/param norm = 1.7828e-01, time/batch = 0.3205s	
1786/2700 (epoch 33.074), train_loss = 1.49755028, grad/param norm = 1.7648e-01, time/batch = 0.2580s	
1787/2700 (epoch 33.093), train_loss = 1.47896504, grad/param norm = 1.7093e-01, time/batch = 0.3056s	
1788/2700 (epoch 33.111), train_loss = 1.45643761, grad/param norm = 1.7038e-01, time/batch = 0.3008s	
1789/2700 (epoch 33.130), train_loss = 1.51464157, grad/param norm = 1.8401e-01, time/batch = 0.2967s	
1790/2700 (epoch 33.148), train_loss = 1.46293982, grad/param norm = 1.5889e-01, time/batch = 0.3091s	
1791/2700 (epoch 33.167), train_loss = 1.57120467, grad/param norm = 1.8489e-01, time/batch = 0.2939s	
1792/2700 (epoch 33.185), train_loss = 1.48266863, grad/param norm = 2.1087e-01, time/batch = 0.2773s	
1793/2700 (epoch 33.204), train_loss = 1.52234095, grad/param norm = 1.6096e-01, time/batch = 0.2616s	
1794/2700 (epoch 33.222), train_loss = 1.47746879, grad/param norm = 1.4995e-01, time/batch = 0.2932s	
1795/2700 (epoch 33.241), train_loss = 1.41609040, grad/param norm = 1.7030e-01, time/batch = 0.3221s	
1796/2700 (epoch 33.259), train_loss = 1.46636493, grad/param norm = 1.6723e-01, time/batch = 0.2995s	
1797/2700 (epoch 33.278), train_loss = 1.51059499, grad/param norm = 1.5987e-01, time/batch = 0.2794s	
1798/2700 (epoch 33.296), train_loss = 1.50508642, grad/param norm = 1.6422e-01, time/batch = 0.2527s	
1799/2700 (epoch 33.315), train_loss = 1.51875020, grad/param norm = 1.6212e-01, time/batch = 0.2608s	
1800/2700 (epoch 33.333), train_loss = 1.51005558, grad/param norm = 1.7508e-01, time/batch = 0.2980s	
1801/2700 (epoch 33.352), train_loss = 1.49519754, grad/param norm = 1.7865e-01, time/batch = 0.2848s	
1802/2700 (epoch 33.370), train_loss = 1.48827710, grad/param norm = 1.9236e-01, time/batch = 0.2990s	
1803/2700 (epoch 33.389), train_loss = 1.46811728, grad/param norm = 1.7203e-01, time/batch = 0.3056s	
1804/2700 (epoch 33.407), train_loss = 1.53829390, grad/param norm = 1.5971e-01, time/batch = 0.2844s	
1805/2700 (epoch 33.426), train_loss = 1.57743798, grad/param norm = 1.6927e-01, time/batch = 0.2760s	
1806/2700 (epoch 33.444), train_loss = 1.47982548, grad/param norm = 1.6751e-01, time/batch = 0.3010s	
1807/2700 (epoch 33.463), train_loss = 1.55007939, grad/param norm = 1.7089e-01, time/batch = 0.3052s	
1808/2700 (epoch 33.481), train_loss = 1.53730582, grad/param norm = 1.7723e-01, time/batch = 0.2946s	
1809/2700 (epoch 33.500), train_loss = 1.47022817, grad/param norm = 1.9215e-01, time/batch = 0.2792s	
1810/2700 (epoch 33.519), train_loss = 1.52903873, grad/param norm = 1.7732e-01, time/batch = 0.2509s	
1811/2700 (epoch 33.537), train_loss = 1.52962212, grad/param norm = 1.8362e-01, time/batch = 0.2397s	
1812/2700 (epoch 33.556), train_loss = 1.46239132, grad/param norm = 1.7868e-01, time/batch = 0.2672s	
1813/2700 (epoch 33.574), train_loss = 1.46731920, grad/param norm = 1.6307e-01, time/batch = 0.3120s	
1814/2700 (epoch 33.593), train_loss = 1.50186126, grad/param norm = 1.6691e-01, time/batch = 0.3215s	
1815/2700 (epoch 33.611), train_loss = 1.42594201, grad/param norm = 1.5808e-01, time/batch = 0.3197s	
1816/2700 (epoch 33.630), train_loss = 1.43351204, grad/param norm = 1.6598e-01, time/batch = 0.3099s	
1817/2700 (epoch 33.648), train_loss = 1.47067555, grad/param norm = 1.7314e-01, time/batch = 0.2764s	
1818/2700 (epoch 33.667), train_loss = 1.45551532, grad/param norm = 2.1576e-01, time/batch = 0.2762s	
1819/2700 (epoch 33.685), train_loss = 1.51794652, grad/param norm = 1.8757e-01, time/batch = 0.2961s	
1820/2700 (epoch 33.704), train_loss = 1.50462482, grad/param norm = 1.8723e-01, time/batch = 0.2806s	
1821/2700 (epoch 33.722), train_loss = 1.49769328, grad/param norm = 1.9676e-01, time/batch = 0.3267s	
1822/2700 (epoch 33.741), train_loss = 1.47440304, grad/param norm = 1.9130e-01, time/batch = 0.2853s	
1823/2700 (epoch 33.759), train_loss = 1.48495518, grad/param norm = 2.0909e-01, time/batch = 0.2824s	
1824/2700 (epoch 33.778), train_loss = 1.54138770, grad/param norm = 1.9139e-01, time/batch = 0.2836s	
1825/2700 (epoch 33.796), train_loss = 1.44827187, grad/param norm = 1.7661e-01, time/batch = 0.2641s	
1826/2700 (epoch 33.815), train_loss = 1.50885390, grad/param norm = 1.8444e-01, time/batch = 0.2468s	
1827/2700 (epoch 33.833), train_loss = 1.49231676, grad/param norm = 2.0402e-01, time/batch = 0.2669s	
1828/2700 (epoch 33.852), train_loss = 1.45627861, grad/param norm = 1.7815e-01, time/batch = 0.2977s	
1829/2700 (epoch 33.870), train_loss = 1.50161097, grad/param norm = 1.8580e-01, time/batch = 0.3310s	
1830/2700 (epoch 33.889), train_loss = 1.50229400, grad/param norm = 1.8898e-01, time/batch = 0.3200s	
1831/2700 (epoch 33.907), train_loss = 1.59559007, grad/param norm = 2.3958e-01, time/batch = 0.3230s	
1832/2700 (epoch 33.926), train_loss = 1.55669728, grad/param norm = 2.5443e-01, time/batch = 0.3351s	
1833/2700 (epoch 33.944), train_loss = 1.51712728, grad/param norm = 2.0571e-01, time/batch = 0.3223s	
1834/2700 (epoch 33.963), train_loss = 1.53975667, grad/param norm = 1.7138e-01, time/batch = 0.2844s	
1835/2700 (epoch 33.981), train_loss = 1.48473264, grad/param norm = 1.6658e-01, time/batch = 0.3022s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
1836/2700 (epoch 34.000), train_loss = 1.54053782, grad/param norm = 1.7498e-01, time/batch = 0.3201s	
1837/2700 (epoch 34.019), train_loss = 1.59169084, grad/param norm = 1.7696e-01, time/batch = 0.3293s	
1838/2700 (epoch 34.037), train_loss = 1.54353936, grad/param norm = 1.8482e-01, time/batch = 0.3354s	
1839/2700 (epoch 34.056), train_loss = 1.50281361, grad/param norm = 1.7051e-01, time/batch = 0.3110s	
1840/2700 (epoch 34.074), train_loss = 1.48613090, grad/param norm = 1.7196e-01, time/batch = 0.2866s	
1841/2700 (epoch 34.093), train_loss = 1.46733938, grad/param norm = 1.9282e-01, time/batch = 0.3249s	
1842/2700 (epoch 34.111), train_loss = 1.44874790, grad/param norm = 1.7821e-01, time/batch = 0.3042s	
1843/2700 (epoch 34.130), train_loss = 1.50053740, grad/param norm = 1.8697e-01, time/batch = 0.2570s	
1844/2700 (epoch 34.148), train_loss = 1.45177308, grad/param norm = 1.5968e-01, time/batch = 0.2445s	
1845/2700 (epoch 34.167), train_loss = 1.55728743, grad/param norm = 1.7637e-01, time/batch = 0.2636s	
1846/2700 (epoch 34.185), train_loss = 1.46950814, grad/param norm = 1.9142e-01, time/batch = 0.2639s	
1847/2700 (epoch 34.204), train_loss = 1.51220450, grad/param norm = 1.6667e-01, time/batch = 0.2839s	
1848/2700 (epoch 34.222), train_loss = 1.46657908, grad/param norm = 1.5214e-01, time/batch = 0.3176s	
1849/2700 (epoch 34.241), train_loss = 1.40391368, grad/param norm = 1.6490e-01, time/batch = 0.3253s	
1850/2700 (epoch 34.259), train_loss = 1.45642073, grad/param norm = 1.6959e-01, time/batch = 0.3210s	
1851/2700 (epoch 34.278), train_loss = 1.49816987, grad/param norm = 1.6178e-01, time/batch = 0.3074s	
1852/2700 (epoch 34.296), train_loss = 1.49265118, grad/param norm = 1.6160e-01, time/batch = 0.3337s	
1853/2700 (epoch 34.315), train_loss = 1.50739609, grad/param norm = 1.6435e-01, time/batch = 0.3356s	
1854/2700 (epoch 34.333), train_loss = 1.49735569, grad/param norm = 1.7174e-01, time/batch = 0.3380s	
1855/2700 (epoch 34.352), train_loss = 1.48186326, grad/param norm = 1.7600e-01, time/batch = 0.3246s	
1856/2700 (epoch 34.370), train_loss = 1.47383345, grad/param norm = 1.7839e-01, time/batch = 0.3024s	
1857/2700 (epoch 34.389), train_loss = 1.45542354, grad/param norm = 1.7049e-01, time/batch = 0.2353s	
1858/2700 (epoch 34.407), train_loss = 1.52872605, grad/param norm = 1.6627e-01, time/batch = 0.2907s	
1859/2700 (epoch 34.426), train_loss = 1.56420264, grad/param norm = 1.6442e-01, time/batch = 0.2437s	
1860/2700 (epoch 34.444), train_loss = 1.46935660, grad/param norm = 1.6461e-01, time/batch = 0.2423s	
1861/2700 (epoch 34.463), train_loss = 1.53769729, grad/param norm = 1.6645e-01, time/batch = 0.2629s	
1862/2700 (epoch 34.481), train_loss = 1.52424081, grad/param norm = 1.6307e-01, time/batch = 0.2852s	
1863/2700 (epoch 34.500), train_loss = 1.45237187, grad/param norm = 1.6680e-01, time/batch = 0.3333s	
1864/2700 (epoch 34.519), train_loss = 1.51556666, grad/param norm = 1.6247e-01, time/batch = 0.3348s	
1865/2700 (epoch 34.537), train_loss = 1.51791243, grad/param norm = 1.8406e-01, time/batch = 0.3339s	
1866/2700 (epoch 34.556), train_loss = 1.44902751, grad/param norm = 1.6873e-01, time/batch = 0.3237s	
1867/2700 (epoch 34.574), train_loss = 1.45770368, grad/param norm = 1.8760e-01, time/batch = 0.3023s	
1868/2700 (epoch 34.593), train_loss = 1.49544351, grad/param norm = 2.0430e-01, time/batch = 0.2798s	
1869/2700 (epoch 34.611), train_loss = 1.41599013, grad/param norm = 1.5825e-01, time/batch = 0.2538s	
1870/2700 (epoch 34.630), train_loss = 1.42054431, grad/param norm = 1.5477e-01, time/batch = 0.2719s	
1871/2700 (epoch 34.648), train_loss = 1.45630049, grad/param norm = 1.5370e-01, time/batch = 0.2655s	
1872/2700 (epoch 34.667), train_loss = 1.43845250, grad/param norm = 1.5853e-01, time/batch = 0.2884s	
1873/2700 (epoch 34.685), train_loss = 1.50364294, grad/param norm = 1.7326e-01, time/batch = 0.2433s	
1874/2700 (epoch 34.704), train_loss = 1.49302485, grad/param norm = 1.8394e-01, time/batch = 0.3183s	
1875/2700 (epoch 34.722), train_loss = 1.48318028, grad/param norm = 1.6715e-01, time/batch = 0.3339s	
1876/2700 (epoch 34.741), train_loss = 1.45967118, grad/param norm = 1.7304e-01, time/batch = 0.3332s	
1877/2700 (epoch 34.759), train_loss = 1.47099857, grad/param norm = 1.8550e-01, time/batch = 0.3336s	
1878/2700 (epoch 34.778), train_loss = 1.52573892, grad/param norm = 1.7610e-01, time/batch = 0.3333s	
1879/2700 (epoch 34.796), train_loss = 1.43758488, grad/param norm = 2.1345e-01, time/batch = 0.3243s	
1880/2700 (epoch 34.815), train_loss = 1.49845099, grad/param norm = 1.9285e-01, time/batch = 0.2993s	
1881/2700 (epoch 34.833), train_loss = 1.48087174, grad/param norm = 1.9008e-01, time/batch = 0.2625s	
1882/2700 (epoch 34.852), train_loss = 1.44539819, grad/param norm = 1.8419e-01, time/batch = 0.3183s	
1883/2700 (epoch 34.870), train_loss = 1.48814753, grad/param norm = 1.8265e-01, time/batch = 0.3066s	
1884/2700 (epoch 34.889), train_loss = 1.48849564, grad/param norm = 1.8794e-01, time/batch = 0.2989s	
1885/2700 (epoch 34.907), train_loss = 1.57716265, grad/param norm = 1.9126e-01, time/batch = 0.2709s	
1886/2700 (epoch 34.926), train_loss = 1.53609593, grad/param norm = 1.8590e-01, time/batch = 0.2403s	
1887/2700 (epoch 34.944), train_loss = 1.49968549, grad/param norm = 1.8936e-01, time/batch = 0.2813s	
1888/2700 (epoch 34.963), train_loss = 1.52859282, grad/param norm = 1.7779e-01, time/batch = 0.3159s	
1889/2700 (epoch 34.981), train_loss = 1.47559074, grad/param norm = 1.8579e-01, time/batch = 0.3258s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
1890/2700 (epoch 35.000), train_loss = 1.52649889, grad/param norm = 1.7396e-01, time/batch = 0.3276s	
1891/2700 (epoch 35.019), train_loss = 1.57844195, grad/param norm = 1.7711e-01, time/batch = 0.2915s	
1892/2700 (epoch 35.037), train_loss = 1.53082729, grad/param norm = 1.8245e-01, time/batch = 0.2724s	
1893/2700 (epoch 35.056), train_loss = 1.49277274, grad/param norm = 1.8493e-01, time/batch = 0.2479s	
1894/2700 (epoch 35.074), train_loss = 1.47452627, grad/param norm = 1.7396e-01, time/batch = 0.3210s	
1895/2700 (epoch 35.093), train_loss = 1.45484568, grad/param norm = 1.8063e-01, time/batch = 0.3334s	
1896/2700 (epoch 35.111), train_loss = 1.43254258, grad/param norm = 1.7565e-01, time/batch = 0.3132s	
1897/2700 (epoch 35.130), train_loss = 1.49076049, grad/param norm = 1.8469e-01, time/batch = 0.2834s	
1898/2700 (epoch 35.148), train_loss = 1.44070109, grad/param norm = 1.6159e-01, time/batch = 0.2518s	
1899/2700 (epoch 35.167), train_loss = 1.54603437, grad/param norm = 1.8138e-01, time/batch = 0.2629s	
1900/2700 (epoch 35.185), train_loss = 1.45854223, grad/param norm = 2.0317e-01, time/batch = 0.2838s	
1901/2700 (epoch 35.204), train_loss = 1.50024617, grad/param norm = 1.6955e-01, time/batch = 0.2667s	
1902/2700 (epoch 35.222), train_loss = 1.45604588, grad/param norm = 1.5454e-01, time/batch = 0.2628s	
1903/2700 (epoch 35.241), train_loss = 1.39349428, grad/param norm = 1.6895e-01, time/batch = 0.2585s	
1904/2700 (epoch 35.259), train_loss = 1.44634818, grad/param norm = 1.6819e-01, time/batch = 0.3022s	
1905/2700 (epoch 35.278), train_loss = 1.48743203, grad/param norm = 1.6446e-01, time/batch = 0.2793s	
1906/2700 (epoch 35.296), train_loss = 1.48171258, grad/param norm = 1.6592e-01, time/batch = 0.3022s	
1907/2700 (epoch 35.315), train_loss = 1.49625041, grad/param norm = 1.6392e-01, time/batch = 0.2493s	
1908/2700 (epoch 35.333), train_loss = 1.48682112, grad/param norm = 1.7841e-01, time/batch = 0.2552s	
1909/2700 (epoch 35.352), train_loss = 1.47095836, grad/param norm = 1.8180e-01, time/batch = 0.2876s	
1910/2700 (epoch 35.370), train_loss = 1.46206169, grad/param norm = 1.9272e-01, time/batch = 0.3014s	
1911/2700 (epoch 35.389), train_loss = 1.44133985, grad/param norm = 1.6290e-01, time/batch = 0.2815s	
1912/2700 (epoch 35.407), train_loss = 1.51507057, grad/param norm = 1.5889e-01, time/batch = 0.2852s	
1913/2700 (epoch 35.426), train_loss = 1.55331587, grad/param norm = 1.6991e-01, time/batch = 0.2853s	
1914/2700 (epoch 35.444), train_loss = 1.45822497, grad/param norm = 1.6933e-01, time/batch = 0.2899s	
1915/2700 (epoch 35.463), train_loss = 1.52775257, grad/param norm = 1.6998e-01, time/batch = 0.3173s	
1916/2700 (epoch 35.481), train_loss = 1.51260884, grad/param norm = 1.6854e-01, time/batch = 0.3115s	
1917/2700 (epoch 35.500), train_loss = 1.44160869, grad/param norm = 1.7804e-01, time/batch = 0.3033s	
1918/2700 (epoch 35.519), train_loss = 1.50375623, grad/param norm = 1.6529e-01, time/batch = 0.2827s	
1919/2700 (epoch 35.537), train_loss = 1.50430891, grad/param norm = 1.7659e-01, time/batch = 0.2447s	
1920/2700 (epoch 35.556), train_loss = 1.43763651, grad/param norm = 1.7422e-01, time/batch = 0.2640s	
1921/2700 (epoch 35.574), train_loss = 1.44296060, grad/param norm = 1.6669e-01, time/batch = 0.2677s	
1922/2700 (epoch 35.593), train_loss = 1.48001822, grad/param norm = 1.7115e-01, time/batch = 0.2893s	
1923/2700 (epoch 35.611), train_loss = 1.40408419, grad/param norm = 1.6221e-01, time/batch = 0.3021s	
1924/2700 (epoch 35.630), train_loss = 1.40915470, grad/param norm = 1.6704e-01, time/batch = 0.2923s	
1925/2700 (epoch 35.648), train_loss = 1.44670003, grad/param norm = 1.7792e-01, time/batch = 0.2738s	
1926/2700 (epoch 35.667), train_loss = 1.43301576, grad/param norm = 2.2765e-01, time/batch = 0.2965s	
1927/2700 (epoch 35.685), train_loss = 1.49608196, grad/param norm = 1.8690e-01, time/batch = 0.3020s	
1928/2700 (epoch 35.704), train_loss = 1.48007881, grad/param norm = 1.8872e-01, time/batch = 0.2940s	
1929/2700 (epoch 35.722), train_loss = 1.47294741, grad/param norm = 1.8294e-01, time/batch = 0.2776s	
1930/2700 (epoch 35.741), train_loss = 1.44622576, grad/param norm = 1.9041e-01, time/batch = 0.1993s	
1931/2700 (epoch 35.759), train_loss = 1.46018956, grad/param norm = 1.8883e-01, time/batch = 0.2703s	
1932/2700 (epoch 35.778), train_loss = 1.51763652, grad/param norm = 1.9319e-01, time/batch = 0.2683s	
1933/2700 (epoch 35.796), train_loss = 1.42504721, grad/param norm = 2.0327e-01, time/batch = 0.2594s	
1934/2700 (epoch 35.815), train_loss = 1.48198641, grad/param norm = 1.6295e-01, time/batch = 0.2917s	
1935/2700 (epoch 35.833), train_loss = 1.46917550, grad/param norm = 1.9410e-01, time/batch = 0.3231s	
1936/2700 (epoch 35.852), train_loss = 1.43551426, grad/param norm = 2.0358e-01, time/batch = 0.3237s	
1937/2700 (epoch 35.870), train_loss = 1.47688625, grad/param norm = 1.6575e-01, time/batch = 0.3240s	
1938/2700 (epoch 35.889), train_loss = 1.47628437, grad/param norm = 1.8467e-01, time/batch = 0.3029s	
1939/2700 (epoch 35.907), train_loss = 1.56531439, grad/param norm = 2.0356e-01, time/batch = 0.3047s	
1940/2700 (epoch 35.926), train_loss = 1.52451636, grad/param norm = 2.1222e-01, time/batch = 0.2673s	
1941/2700 (epoch 35.944), train_loss = 1.49086327, grad/param norm = 2.1499e-01, time/batch = 0.2789s	
1942/2700 (epoch 35.963), train_loss = 1.51705250, grad/param norm = 1.8753e-01, time/batch = 0.2108s	
1943/2700 (epoch 35.981), train_loss = 1.46680110, grad/param norm = 2.5224e-01, time/batch = 0.2573s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
1944/2700 (epoch 36.000), train_loss = 1.52102926, grad/param norm = 2.0797e-01, time/batch = 0.2519s	
1945/2700 (epoch 36.019), train_loss = 1.57199407, grad/param norm = 2.0623e-01, time/batch = 0.3008s	
1946/2700 (epoch 36.037), train_loss = 1.52186148, grad/param norm = 1.9646e-01, time/batch = 0.3295s	
1947/2700 (epoch 36.056), train_loss = 1.48044086, grad/param norm = 1.6712e-01, time/batch = 0.3250s	
1948/2700 (epoch 36.074), train_loss = 1.46711057, grad/param norm = 1.8396e-01, time/batch = 0.3298s	
1949/2700 (epoch 36.093), train_loss = 1.44856681, grad/param norm = 1.9347e-01, time/batch = 0.3287s	
1950/2700 (epoch 36.111), train_loss = 1.42491929, grad/param norm = 1.8415e-01, time/batch = 0.3363s	
1951/2700 (epoch 36.130), train_loss = 1.47692271, grad/param norm = 1.9126e-01, time/batch = 0.3359s	
1952/2700 (epoch 36.148), train_loss = 1.42937741, grad/param norm = 1.5949e-01, time/batch = 0.3306s	
1953/2700 (epoch 36.167), train_loss = 1.53519449, grad/param norm = 1.7497e-01, time/batch = 0.3140s	
1954/2700 (epoch 36.185), train_loss = 1.44637712, grad/param norm = 1.8417e-01, time/batch = 0.2671s	
1955/2700 (epoch 36.204), train_loss = 1.49114381, grad/param norm = 1.7914e-01, time/batch = 0.3343s	
1956/2700 (epoch 36.222), train_loss = 1.44514977, grad/param norm = 1.5809e-01, time/batch = 0.3370s	
1957/2700 (epoch 36.241), train_loss = 1.38262064, grad/param norm = 1.7132e-01, time/batch = 0.3305s	
1958/2700 (epoch 36.259), train_loss = 1.43666652, grad/param norm = 1.7286e-01, time/batch = 0.3160s	
1959/2700 (epoch 36.278), train_loss = 1.47577643, grad/param norm = 1.6365e-01, time/batch = 0.2921s	
1960/2700 (epoch 36.296), train_loss = 1.47039864, grad/param norm = 1.6916e-01, time/batch = 0.2546s	
1961/2700 (epoch 36.315), train_loss = 1.48604354, grad/param norm = 1.7026e-01, time/batch = 0.2658s	
1962/2700 (epoch 36.333), train_loss = 1.47617790, grad/param norm = 1.7254e-01, time/batch = 0.2579s	
1963/2700 (epoch 36.352), train_loss = 1.45850985, grad/param norm = 1.7889e-01, time/batch = 0.2752s	
1964/2700 (epoch 36.370), train_loss = 1.45018844, grad/param norm = 1.9225e-01, time/batch = 0.2711s	
1965/2700 (epoch 36.389), train_loss = 1.43066054, grad/param norm = 1.7409e-01, time/batch = 0.2721s	
1966/2700 (epoch 36.407), train_loss = 1.50565377, grad/param norm = 1.6471e-01, time/batch = 0.2895s	
1967/2700 (epoch 36.426), train_loss = 1.54058308, grad/param norm = 1.6213e-01, time/batch = 0.3341s	
1968/2700 (epoch 36.444), train_loss = 1.44886586, grad/param norm = 1.7316e-01, time/batch = 0.2964s	
1969/2700 (epoch 36.463), train_loss = 1.51598208, grad/param norm = 1.6941e-01, time/batch = 0.2897s	
1970/2700 (epoch 36.481), train_loss = 1.50140586, grad/param norm = 1.6180e-01, time/batch = 0.2769s	
1971/2700 (epoch 36.500), train_loss = 1.42825637, grad/param norm = 1.7090e-01, time/batch = 0.2992s	
1972/2700 (epoch 36.519), train_loss = 1.49167268, grad/param norm = 1.6919e-01, time/batch = 0.3240s	
1973/2700 (epoch 36.537), train_loss = 1.49207375, grad/param norm = 1.8292e-01, time/batch = 0.3327s	
1974/2700 (epoch 36.556), train_loss = 1.42649625, grad/param norm = 1.6927e-01, time/batch = 0.3206s	
1975/2700 (epoch 36.574), train_loss = 1.43251038, grad/param norm = 1.7910e-01, time/batch = 0.3137s	
1976/2700 (epoch 36.593), train_loss = 1.47123940, grad/param norm = 1.9385e-01, time/batch = 0.2509s	
1977/2700 (epoch 36.611), train_loss = 1.39471775, grad/param norm = 1.5907e-01, time/batch = 0.2511s	
1978/2700 (epoch 36.630), train_loss = 1.39881502, grad/param norm = 1.5981e-01, time/batch = 0.2703s	
1979/2700 (epoch 36.648), train_loss = 1.43385821, grad/param norm = 1.6298e-01, time/batch = 0.2391s	
1980/2700 (epoch 36.667), train_loss = 1.41634381, grad/param norm = 1.6475e-01, time/batch = 0.2854s	
1981/2700 (epoch 36.685), train_loss = 1.48382503, grad/param norm = 1.8084e-01, time/batch = 0.2687s	
1982/2700 (epoch 36.704), train_loss = 1.47043895, grad/param norm = 1.8960e-01, time/batch = 0.3145s	
1983/2700 (epoch 36.722), train_loss = 1.46099169, grad/param norm = 1.6905e-01, time/batch = 0.3290s	
1984/2700 (epoch 36.741), train_loss = 1.43714538, grad/param norm = 1.9967e-01, time/batch = 0.3336s	
1985/2700 (epoch 36.759), train_loss = 1.44647104, grad/param norm = 1.8828e-01, time/batch = 0.3366s	
1986/2700 (epoch 36.778), train_loss = 1.50092643, grad/param norm = 1.6909e-01, time/batch = 0.3201s	
1987/2700 (epoch 36.796), train_loss = 1.41083688, grad/param norm = 2.0074e-01, time/batch = 0.2977s	
1988/2700 (epoch 36.815), train_loss = 1.47524799, grad/param norm = 1.8410e-01, time/batch = 0.2746s	
1989/2700 (epoch 36.833), train_loss = 1.45472106, grad/param norm = 1.7901e-01, time/batch = 0.2626s	
1990/2700 (epoch 36.852), train_loss = 1.41954030, grad/param norm = 1.6684e-01, time/batch = 0.2412s	
1991/2700 (epoch 36.870), train_loss = 1.46607154, grad/param norm = 1.8298e-01, time/batch = 0.2910s	
1992/2700 (epoch 36.889), train_loss = 1.46697178, grad/param norm = 1.8308e-01, time/batch = 0.2340s	
1993/2700 (epoch 36.907), train_loss = 1.55541144, grad/param norm = 1.9968e-01, time/batch = 0.3070s	
1994/2700 (epoch 36.926), train_loss = 1.50975065, grad/param norm = 2.0236e-01, time/batch = 0.3267s	
1995/2700 (epoch 36.944), train_loss = 1.47539162, grad/param norm = 1.9974e-01, time/batch = 0.3353s	
1996/2700 (epoch 36.963), train_loss = 1.50605553, grad/param norm = 1.8448e-01, time/batch = 0.3365s	
1997/2700 (epoch 36.981), train_loss = 1.45437145, grad/param norm = 2.0423e-01, time/batch = 0.3347s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
1998/2700 (epoch 37.000), train_loss = 1.50765699, grad/param norm = 1.9252e-01, time/batch = 0.3354s	
1999/2700 (epoch 37.019), train_loss = 1.55827559, grad/param norm = 1.8705e-01, time/batch = 0.3244s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch37.04_1.7808.t7	
2000/2700 (epoch 37.037), train_loss = 1.51139912, grad/param norm = 1.9140e-01, time/batch = 0.2852s	
2001/2700 (epoch 37.056), train_loss = 1.61933148, grad/param norm = 1.8813e-01, time/batch = 0.2875s	
2002/2700 (epoch 37.074), train_loss = 1.45615842, grad/param norm = 1.9697e-01, time/batch = 0.3084s	
2003/2700 (epoch 37.093), train_loss = 1.43450693, grad/param norm = 1.9500e-01, time/batch = 0.3077s	
2004/2700 (epoch 37.111), train_loss = 1.41273971, grad/param norm = 1.7556e-01, time/batch = 0.3004s	
2005/2700 (epoch 37.130), train_loss = 1.46608461, grad/param norm = 1.9302e-01, time/batch = 0.2848s	
2006/2700 (epoch 37.148), train_loss = 1.42091271, grad/param norm = 1.6373e-01, time/batch = 0.2589s	
2007/2700 (epoch 37.167), train_loss = 1.52526508, grad/param norm = 1.9071e-01, time/batch = 0.2834s	
2008/2700 (epoch 37.185), train_loss = 1.43799446, grad/param norm = 1.9424e-01, time/batch = 0.3125s	
2009/2700 (epoch 37.204), train_loss = 1.47958206, grad/param norm = 1.7342e-01, time/batch = 0.2995s	
2010/2700 (epoch 37.222), train_loss = 1.43525729, grad/param norm = 1.5653e-01, time/batch = 0.3003s	
2011/2700 (epoch 37.241), train_loss = 1.37323183, grad/param norm = 1.7137e-01, time/batch = 0.2798s	
2012/2700 (epoch 37.259), train_loss = 1.42694013, grad/param norm = 1.7234e-01, time/batch = 0.2875s	
2013/2700 (epoch 37.278), train_loss = 1.46519856, grad/param norm = 1.6264e-01, time/batch = 0.2614s	
2014/2700 (epoch 37.296), train_loss = 1.45904715, grad/param norm = 1.6417e-01, time/batch = 0.2695s	
2015/2700 (epoch 37.315), train_loss = 1.47467037, grad/param norm = 1.6898e-01, time/batch = 0.2654s	
2016/2700 (epoch 37.333), train_loss = 1.46230043, grad/param norm = 1.6718e-01, time/batch = 0.2780s	
2017/2700 (epoch 37.352), train_loss = 1.44758084, grad/param norm = 1.7576e-01, time/batch = 0.2759s	
2018/2700 (epoch 37.370), train_loss = 1.43958320, grad/param norm = 1.9465e-01, time/batch = 0.2957s	
2019/2700 (epoch 37.389), train_loss = 1.41878652, grad/param norm = 1.6503e-01, time/batch = 0.3057s	
2020/2700 (epoch 37.407), train_loss = 1.49429188, grad/param norm = 1.7326e-01, time/batch = 0.3186s	
2021/2700 (epoch 37.426), train_loss = 1.53051149, grad/param norm = 1.6942e-01, time/batch = 0.3170s	
2022/2700 (epoch 37.444), train_loss = 1.43796626, grad/param norm = 1.7190e-01, time/batch = 0.3108s	
2023/2700 (epoch 37.463), train_loss = 1.50523552, grad/param norm = 1.6846e-01, time/batch = 0.3296s	
2024/2700 (epoch 37.481), train_loss = 1.49048016, grad/param norm = 1.6659e-01, time/batch = 0.2890s	
2025/2700 (epoch 37.500), train_loss = 1.41801411, grad/param norm = 1.7149e-01, time/batch = 0.2948s	
2026/2700 (epoch 37.519), train_loss = 1.48271826, grad/param norm = 1.6748e-01, time/batch = 0.3031s	
2027/2700 (epoch 37.537), train_loss = 1.48257972, grad/param norm = 1.8894e-01, time/batch = 0.3050s	
2028/2700 (epoch 37.556), train_loss = 1.41543213, grad/param norm = 1.6762e-01, time/batch = 0.2938s	
2029/2700 (epoch 37.574), train_loss = 1.41894293, grad/param norm = 1.6222e-01, time/batch = 0.2493s	
2030/2700 (epoch 37.593), train_loss = 1.45849659, grad/param norm = 1.7182e-01, time/batch = 0.2324s	
2031/2700 (epoch 37.611), train_loss = 1.38366847, grad/param norm = 1.6062e-01, time/batch = 0.2629s	
2032/2700 (epoch 37.630), train_loss = 1.38813292, grad/param norm = 1.6797e-01, time/batch = 0.2967s	
2033/2700 (epoch 37.648), train_loss = 1.42269078, grad/param norm = 1.6015e-01, time/batch = 0.3046s	
2034/2700 (epoch 37.667), train_loss = 1.40750855, grad/param norm = 1.8611e-01, time/batch = 0.3365s	
2035/2700 (epoch 37.685), train_loss = 1.47203793, grad/param norm = 1.6854e-01, time/batch = 0.3338s	
2036/2700 (epoch 37.704), train_loss = 1.45660655, grad/param norm = 1.7999e-01, time/batch = 0.2746s	
2037/2700 (epoch 37.722), train_loss = 1.45200820, grad/param norm = 1.7972e-01, time/batch = 0.3105s	
2038/2700 (epoch 37.741), train_loss = 1.41959159, grad/param norm = 1.7838e-01, time/batch = 0.3278s	
2039/2700 (epoch 37.759), train_loss = 1.43103882, grad/param norm = 1.7439e-01, time/batch = 0.3334s	
2040/2700 (epoch 37.778), train_loss = 1.49080217, grad/param norm = 1.7912e-01, time/batch = 0.3347s	
2041/2700 (epoch 37.796), train_loss = 1.40078521, grad/param norm = 1.9224e-01, time/batch = 0.3338s	
2042/2700 (epoch 37.815), train_loss = 1.46092488, grad/param norm = 1.6574e-01, time/batch = 0.3322s	
2043/2700 (epoch 37.833), train_loss = 1.44691396, grad/param norm = 1.9840e-01, time/batch = 0.3267s	
2044/2700 (epoch 37.852), train_loss = 1.41037271, grad/param norm = 1.8623e-01, time/batch = 0.3304s	
2045/2700 (epoch 37.870), train_loss = 1.45370263, grad/param norm = 1.7284e-01, time/batch = 0.3072s	
2046/2700 (epoch 37.889), train_loss = 1.45323870, grad/param norm = 1.8209e-01, time/batch = 0.2836s	
2047/2700 (epoch 37.907), train_loss = 1.54696427, grad/param norm = 2.2992e-01, time/batch = 0.2269s	
2048/2700 (epoch 37.926), train_loss = 1.50200073, grad/param norm = 2.4074e-01, time/batch = 0.2542s	
2049/2700 (epoch 37.944), train_loss = 1.46731397, grad/param norm = 2.1632e-01, time/batch = 0.2454s	
2050/2700 (epoch 37.963), train_loss = 1.49245176, grad/param norm = 1.8071e-01, time/batch = 0.2927s	
2051/2700 (epoch 37.981), train_loss = 1.43872563, grad/param norm = 1.8576e-01, time/batch = 0.2777s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2052/2700 (epoch 38.000), train_loss = 1.49382817, grad/param norm = 1.8872e-01, time/batch = 0.3244s	
2053/2700 (epoch 38.019), train_loss = 1.54775313, grad/param norm = 1.8108e-01, time/batch = 0.3314s	
2054/2700 (epoch 38.037), train_loss = 1.49473861, grad/param norm = 1.7287e-01, time/batch = 0.3261s	
2055/2700 (epoch 38.056), train_loss = 1.46242374, grad/param norm = 1.7984e-01, time/batch = 0.3373s	
2056/2700 (epoch 38.074), train_loss = 1.44374953, grad/param norm = 1.7304e-01, time/batch = 0.3263s	
2057/2700 (epoch 38.093), train_loss = 1.42464301, grad/param norm = 1.9668e-01, time/batch = 0.3069s	
2058/2700 (epoch 38.111), train_loss = 1.39976993, grad/param norm = 1.7813e-01, time/batch = 0.2829s	
2059/2700 (epoch 38.130), train_loss = 1.45393328, grad/param norm = 1.8663e-01, time/batch = 0.2648s	
2060/2700 (epoch 38.148), train_loss = 1.41101613, grad/param norm = 1.6378e-01, time/batch = 0.2947s	
2061/2700 (epoch 38.167), train_loss = 1.51306708, grad/param norm = 1.7351e-01, time/batch = 0.3374s	
2062/2700 (epoch 38.185), train_loss = 1.42747789, grad/param norm = 1.9048e-01, time/batch = 0.3118s	
2063/2700 (epoch 38.204), train_loss = 1.47493335, grad/param norm = 2.3211e-01, time/batch = 0.2924s	
2064/2700 (epoch 38.222), train_loss = 1.42726349, grad/param norm = 1.6894e-01, time/batch = 0.2511s	
2065/2700 (epoch 38.241), train_loss = 1.36355467, grad/param norm = 1.6845e-01, time/batch = 0.2450s	
2066/2700 (epoch 38.259), train_loss = 1.41828855, grad/param norm = 1.7336e-01, time/batch = 0.3078s	
2067/2700 (epoch 38.278), train_loss = 1.45488594, grad/param norm = 1.6475e-01, time/batch = 0.3212s	
2068/2700 (epoch 38.296), train_loss = 1.44834904, grad/param norm = 1.6602e-01, time/batch = 0.3241s	
2069/2700 (epoch 38.315), train_loss = 1.46522755, grad/param norm = 1.7059e-01, time/batch = 0.3123s	
2070/2700 (epoch 38.333), train_loss = 1.45377097, grad/param norm = 1.7172e-01, time/batch = 0.2920s	
2071/2700 (epoch 38.352), train_loss = 1.43735032, grad/param norm = 1.8282e-01, time/batch = 0.2637s	
2072/2700 (epoch 38.370), train_loss = 1.42763241, grad/param norm = 2.0521e-01, time/batch = 0.3187s	
2073/2700 (epoch 38.389), train_loss = 1.40739918, grad/param norm = 1.8823e-01, time/batch = 0.3307s	
2074/2700 (epoch 38.407), train_loss = 1.48828122, grad/param norm = 1.7603e-01, time/batch = 0.3305s	
2075/2700 (epoch 38.426), train_loss = 1.52135876, grad/param norm = 1.7035e-01, time/batch = 0.3237s	
2076/2700 (epoch 38.444), train_loss = 1.42792395, grad/param norm = 1.7290e-01, time/batch = 0.3350s	
2077/2700 (epoch 38.463), train_loss = 1.49619236, grad/param norm = 1.6995e-01, time/batch = 0.3235s	
2078/2700 (epoch 38.481), train_loss = 1.48196012, grad/param norm = 1.7796e-01, time/batch = 0.3022s	
2079/2700 (epoch 38.500), train_loss = 1.40770021, grad/param norm = 1.7907e-01, time/batch = 0.2742s	
2080/2700 (epoch 38.519), train_loss = 1.47203298, grad/param norm = 1.6433e-01, time/batch = 0.2538s	
2081/2700 (epoch 38.537), train_loss = 1.47044523, grad/param norm = 1.7296e-01, time/batch = 0.2688s	
2082/2700 (epoch 38.556), train_loss = 1.40506700, grad/param norm = 1.7295e-01, time/batch = 0.2574s	
2083/2700 (epoch 38.574), train_loss = 1.41000257, grad/param norm = 1.6633e-01, time/batch = 0.2313s	
2084/2700 (epoch 38.593), train_loss = 1.44877674, grad/param norm = 1.7507e-01, time/batch = 0.2865s	
2085/2700 (epoch 38.611), train_loss = 1.37434165, grad/param norm = 1.6286e-01, time/batch = 0.3138s	
2086/2700 (epoch 38.630), train_loss = 1.37764877, grad/param norm = 1.6673e-01, time/batch = 0.3208s	
2087/2700 (epoch 38.648), train_loss = 1.41074955, grad/param norm = 1.6080e-01, time/batch = 0.3332s	
2088/2700 (epoch 38.667), train_loss = 1.39645805, grad/param norm = 1.7997e-01, time/batch = 0.3302s	
2089/2700 (epoch 38.685), train_loss = 1.46308278, grad/param norm = 1.7318e-01, time/batch = 0.3195s	
2090/2700 (epoch 38.704), train_loss = 1.44467344, grad/param norm = 1.7452e-01, time/batch = 0.2963s	
2091/2700 (epoch 38.722), train_loss = 1.43996190, grad/param norm = 1.6358e-01, time/batch = 0.3339s	
2092/2700 (epoch 38.741), train_loss = 1.40727296, grad/param norm = 1.6926e-01, time/batch = 0.3090s	
2093/2700 (epoch 38.759), train_loss = 1.42188794, grad/param norm = 1.9685e-01, time/batch = 0.2821s	
2094/2700 (epoch 38.778), train_loss = 1.47981444, grad/param norm = 1.7780e-01, time/batch = 0.2268s	
2095/2700 (epoch 38.796), train_loss = 1.38887037, grad/param norm = 1.9975e-01, time/batch = 0.2558s	
2096/2700 (epoch 38.815), train_loss = 1.45203243, grad/param norm = 1.7742e-01, time/batch = 0.2447s	
2097/2700 (epoch 38.833), train_loss = 1.43277236, grad/param norm = 1.8336e-01, time/batch = 0.2687s	
2098/2700 (epoch 38.852), train_loss = 1.39792703, grad/param norm = 1.7516e-01, time/batch = 0.3298s	
2099/2700 (epoch 38.870), train_loss = 1.44413759, grad/param norm = 1.8090e-01, time/batch = 0.3311s	
2100/2700 (epoch 38.889), train_loss = 1.44319101, grad/param norm = 1.8670e-01, time/batch = 0.3321s	
2101/2700 (epoch 38.907), train_loss = 1.53251456, grad/param norm = 2.0229e-01, time/batch = 0.3176s	
2102/2700 (epoch 38.926), train_loss = 1.48415215, grad/param norm = 1.8531e-01, time/batch = 0.3222s	
2103/2700 (epoch 38.944), train_loss = 1.45236377, grad/param norm = 2.0678e-01, time/batch = 0.3322s	
2104/2700 (epoch 38.963), train_loss = 1.48519674, grad/param norm = 1.9655e-01, time/batch = 0.3151s	
2105/2700 (epoch 38.981), train_loss = 1.42998526, grad/param norm = 2.0375e-01, time/batch = 0.3048s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2106/2700 (epoch 39.000), train_loss = 1.48325488, grad/param norm = 1.8739e-01, time/batch = 0.2482s	
2107/2700 (epoch 39.019), train_loss = 1.53871898, grad/param norm = 1.8991e-01, time/batch = 0.3138s	
2108/2700 (epoch 39.037), train_loss = 1.49035595, grad/param norm = 1.9518e-01, time/batch = 0.2502s	
2109/2700 (epoch 39.056), train_loss = 1.45034178, grad/param norm = 1.8688e-01, time/batch = 0.2694s	
2110/2700 (epoch 39.074), train_loss = 1.43438936, grad/param norm = 1.7875e-01, time/batch = 0.2690s	
2111/2700 (epoch 39.093), train_loss = 1.41298787, grad/param norm = 1.8385e-01, time/batch = 0.2835s	
2112/2700 (epoch 39.111), train_loss = 1.38893019, grad/param norm = 1.7447e-01, time/batch = 0.2807s	
2113/2700 (epoch 39.130), train_loss = 1.44154103, grad/param norm = 1.8627e-01, time/batch = 0.2817s	
2114/2700 (epoch 39.148), train_loss = 1.40063671, grad/param norm = 1.6240e-01, time/batch = 0.2591s	
2115/2700 (epoch 39.167), train_loss = 1.50417787, grad/param norm = 1.8639e-01, time/batch = 0.2558s	
2116/2700 (epoch 39.185), train_loss = 1.41627009, grad/param norm = 1.8885e-01, time/batch = 0.2934s	
2117/2700 (epoch 39.204), train_loss = 1.45784346, grad/param norm = 1.7201e-01, time/batch = 0.3187s	
2118/2700 (epoch 39.222), train_loss = 1.41703719, grad/param norm = 1.6398e-01, time/batch = 0.3074s	
2119/2700 (epoch 39.241), train_loss = 1.35526331, grad/param norm = 1.8380e-01, time/batch = 0.2790s	
2120/2700 (epoch 39.259), train_loss = 1.40941905, grad/param norm = 1.7518e-01, time/batch = 0.2775s	
2121/2700 (epoch 39.278), train_loss = 1.44389370, grad/param norm = 1.6212e-01, time/batch = 0.2796s	
2122/2700 (epoch 39.296), train_loss = 1.43861070, grad/param norm = 1.7186e-01, time/batch = 0.2916s	
2123/2700 (epoch 39.315), train_loss = 1.45531136, grad/param norm = 1.7657e-01, time/batch = 0.2891s	
2124/2700 (epoch 39.333), train_loss = 1.44404171, grad/param norm = 1.7250e-01, time/batch = 0.2658s	
2125/2700 (epoch 39.352), train_loss = 1.42641933, grad/param norm = 1.7909e-01, time/batch = 0.2433s	
2126/2700 (epoch 39.370), train_loss = 1.41587212, grad/param norm = 1.9175e-01, time/batch = 0.2618s	
2127/2700 (epoch 39.389), train_loss = 1.39490793, grad/param norm = 1.7214e-01, time/batch = 0.3109s	
2128/2700 (epoch 39.407), train_loss = 1.47644641, grad/param norm = 1.7238e-01, time/batch = 0.3270s	
2129/2700 (epoch 39.426), train_loss = 1.50987674, grad/param norm = 1.6774e-01, time/batch = 0.3289s	
2130/2700 (epoch 39.444), train_loss = 1.42057445, grad/param norm = 1.7819e-01, time/batch = 0.3133s	
2131/2700 (epoch 39.463), train_loss = 1.48592595, grad/param norm = 1.6964e-01, time/batch = 0.3124s	
2132/2700 (epoch 39.481), train_loss = 1.47007722, grad/param norm = 1.6251e-01, time/batch = 0.2911s	
2133/2700 (epoch 39.500), train_loss = 1.39489515, grad/param norm = 1.6934e-01, time/batch = 0.2924s	
2134/2700 (epoch 39.519), train_loss = 1.46123622, grad/param norm = 1.6987e-01, time/batch = 0.3128s	
2135/2700 (epoch 39.537), train_loss = 1.46004493, grad/param norm = 1.8131e-01, time/batch = 0.3289s	
2136/2700 (epoch 39.556), train_loss = 1.39574344, grad/param norm = 1.7293e-01, time/batch = 0.3345s	
2137/2700 (epoch 39.574), train_loss = 1.40074986, grad/param norm = 1.7745e-01, time/batch = 0.3112s	
2138/2700 (epoch 39.593), train_loss = 1.44110011, grad/param norm = 1.8696e-01, time/batch = 0.2912s	
2139/2700 (epoch 39.611), train_loss = 1.36544082, grad/param norm = 1.6196e-01, time/batch = 0.2648s	
2140/2700 (epoch 39.630), train_loss = 1.36833645, grad/param norm = 1.6619e-01, time/batch = 0.2574s	
2141/2700 (epoch 39.648), train_loss = 1.40084162, grad/param norm = 1.5834e-01, time/batch = 0.2424s	
2142/2700 (epoch 39.667), train_loss = 1.38570577, grad/param norm = 1.6712e-01, time/batch = 0.2764s	
2143/2700 (epoch 39.685), train_loss = 1.45472487, grad/param norm = 1.8472e-01, time/batch = 0.2641s	
2144/2700 (epoch 39.704), train_loss = 1.43592818, grad/param norm = 1.8307e-01, time/batch = 0.2909s	
2145/2700 (epoch 39.722), train_loss = 1.43009225, grad/param norm = 1.6530e-01, time/batch = 0.3194s	
2146/2700 (epoch 39.741), train_loss = 1.39689730, grad/param norm = 1.7601e-01, time/batch = 0.3366s	
2147/2700 (epoch 39.759), train_loss = 1.40982810, grad/param norm = 1.8050e-01, time/batch = 0.3248s	
2148/2700 (epoch 39.778), train_loss = 1.46873290, grad/param norm = 1.7984e-01, time/batch = 0.3209s	
2149/2700 (epoch 39.796), train_loss = 1.38125189, grad/param norm = 2.2654e-01, time/batch = 0.3137s	
2150/2700 (epoch 39.815), train_loss = 1.44221262, grad/param norm = 1.7640e-01, time/batch = 0.2934s	
2151/2700 (epoch 39.833), train_loss = 1.42425444, grad/param norm = 1.9561e-01, time/batch = 0.3309s	
2152/2700 (epoch 39.852), train_loss = 1.38882212, grad/param norm = 1.8815e-01, time/batch = 0.3248s	
2153/2700 (epoch 39.870), train_loss = 1.43471409, grad/param norm = 1.7523e-01, time/batch = 0.2965s	
2154/2700 (epoch 39.889), train_loss = 1.43356411, grad/param norm = 1.8273e-01, time/batch = 0.2458s	
2155/2700 (epoch 39.907), train_loss = 1.52114785, grad/param norm = 2.0185e-01, time/batch = 0.2905s	
2156/2700 (epoch 39.926), train_loss = 1.47368665, grad/param norm = 2.0323e-01, time/batch = 0.2479s	
2157/2700 (epoch 39.944), train_loss = 1.44260983, grad/param norm = 2.0851e-01, time/batch = 0.2515s	
2158/2700 (epoch 39.963), train_loss = 1.47200072, grad/param norm = 1.7903e-01, time/batch = 0.2938s	
2159/2700 (epoch 39.981), train_loss = 1.41735527, grad/param norm = 1.8433e-01, time/batch = 0.3314s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2160/2700 (epoch 40.000), train_loss = 1.47320768, grad/param norm = 1.8500e-01, time/batch = 0.3288s	
2161/2700 (epoch 40.019), train_loss = 1.52821020, grad/param norm = 1.7840e-01, time/batch = 0.3220s	
2162/2700 (epoch 40.037), train_loss = 1.47587950, grad/param norm = 1.7784e-01, time/batch = 0.3185s	
2163/2700 (epoch 40.056), train_loss = 1.43950014, grad/param norm = 1.7685e-01, time/batch = 0.3318s	
2164/2700 (epoch 40.074), train_loss = 1.42534464, grad/param norm = 1.7790e-01, time/batch = 0.3119s	
2165/2700 (epoch 40.093), train_loss = 1.40543947, grad/param norm = 2.0724e-01, time/batch = 0.2874s	
2166/2700 (epoch 40.111), train_loss = 1.38249953, grad/param norm = 1.9101e-01, time/batch = 0.2822s	
2167/2700 (epoch 40.130), train_loss = 1.43123132, grad/param norm = 1.9847e-01, time/batch = 0.3365s	
2168/2700 (epoch 40.148), train_loss = 1.39143088, grad/param norm = 1.6064e-01, time/batch = 0.3344s	
2169/2700 (epoch 40.167), train_loss = 1.49315515, grad/param norm = 1.7015e-01, time/batch = 0.3238s	
2170/2700 (epoch 40.185), train_loss = 1.40662452, grad/param norm = 1.8246e-01, time/batch = 0.3058s	
2171/2700 (epoch 40.204), train_loss = 1.45060988, grad/param norm = 2.0487e-01, time/batch = 0.3296s	
2172/2700 (epoch 40.222), train_loss = 1.40757327, grad/param norm = 1.6547e-01, time/batch = 0.3052s	
2173/2700 (epoch 40.241), train_loss = 1.34552539, grad/param norm = 1.7269e-01, time/batch = 0.2693s	
2174/2700 (epoch 40.259), train_loss = 1.39986960, grad/param norm = 1.7483e-01, time/batch = 0.2649s	
2175/2700 (epoch 40.278), train_loss = 1.43409992, grad/param norm = 1.6541e-01, time/batch = 0.2770s	
2176/2700 (epoch 40.296), train_loss = 1.42731411, grad/param norm = 1.6584e-01, time/batch = 0.2808s	
2177/2700 (epoch 40.315), train_loss = 1.44536279, grad/param norm = 1.6943e-01, time/batch = 0.2719s	
2178/2700 (epoch 40.333), train_loss = 1.43305934, grad/param norm = 1.7214e-01, time/batch = 0.2614s	
2179/2700 (epoch 40.352), train_loss = 1.41593608, grad/param norm = 1.7562e-01, time/batch = 0.3245s	
2180/2700 (epoch 40.370), train_loss = 1.40737109, grad/param norm = 2.0497e-01, time/batch = 0.3345s	
2181/2700 (epoch 40.389), train_loss = 1.38730347, grad/param norm = 1.7918e-01, time/batch = 0.3174s	
2182/2700 (epoch 40.407), train_loss = 1.46719360, grad/param norm = 1.7368e-01, time/batch = 0.3216s	
2183/2700 (epoch 40.426), train_loss = 1.50096339, grad/param norm = 1.7396e-01, time/batch = 0.2884s	
2184/2700 (epoch 40.444), train_loss = 1.41040291, grad/param norm = 1.7669e-01, time/batch = 0.2767s	
2185/2700 (epoch 40.463), train_loss = 1.47543083, grad/param norm = 1.6865e-01, time/batch = 0.2730s	
2186/2700 (epoch 40.481), train_loss = 1.46171242, grad/param norm = 1.6748e-01, time/batch = 0.2857s	
2187/2700 (epoch 40.500), train_loss = 1.38596016, grad/param norm = 1.7453e-01, time/batch = 0.3001s	
2188/2700 (epoch 40.519), train_loss = 1.45234890, grad/param norm = 1.6857e-01, time/batch = 0.3143s	
2189/2700 (epoch 40.537), train_loss = 1.45050658, grad/param norm = 1.7677e-01, time/batch = 0.3101s	
2190/2700 (epoch 40.556), train_loss = 1.38582984, grad/param norm = 1.6826e-01, time/batch = 0.2319s	
2191/2700 (epoch 40.574), train_loss = 1.38855480, grad/param norm = 1.6481e-01, time/batch = 0.3205s	
2192/2700 (epoch 40.593), train_loss = 1.43003638, grad/param norm = 1.7395e-01, time/batch = 0.3312s	
2193/2700 (epoch 40.611), train_loss = 1.35575170, grad/param norm = 1.6411e-01, time/batch = 0.3288s	
2194/2700 (epoch 40.630), train_loss = 1.35955477, grad/param norm = 1.6809e-01, time/batch = 0.3099s	
2195/2700 (epoch 40.648), train_loss = 1.39034841, grad/param norm = 1.5668e-01, time/batch = 0.3170s	
2196/2700 (epoch 40.667), train_loss = 1.37716228, grad/param norm = 1.8516e-01, time/batch = 0.2892s	
2197/2700 (epoch 40.685), train_loss = 1.44458543, grad/param norm = 1.7086e-01, time/batch = 0.2497s	
2198/2700 (epoch 40.704), train_loss = 1.42401670, grad/param norm = 1.7860e-01, time/batch = 0.2510s	
2199/2700 (epoch 40.722), train_loss = 1.42218090, grad/param norm = 1.7673e-01, time/batch = 0.2968s	
2200/2700 (epoch 40.741), train_loss = 1.38895340, grad/param norm = 2.2569e-01, time/batch = 0.2978s	
2201/2700 (epoch 40.759), train_loss = 1.40111345, grad/param norm = 1.9599e-01, time/batch = 0.2837s	
2202/2700 (epoch 40.778), train_loss = 1.46009303, grad/param norm = 2.0439e-01, time/batch = 0.2634s	
2203/2700 (epoch 40.796), train_loss = 1.37001522, grad/param norm = 1.9799e-01, time/batch = 0.2844s	
2204/2700 (epoch 40.815), train_loss = 1.43079204, grad/param norm = 1.6400e-01, time/batch = 0.3137s	
2205/2700 (epoch 40.833), train_loss = 1.41658926, grad/param norm = 2.1525e-01, time/batch = 0.3318s	
2206/2700 (epoch 40.852), train_loss = 1.37944564, grad/param norm = 1.9439e-01, time/batch = 0.2868s	
2207/2700 (epoch 40.870), train_loss = 1.42574483, grad/param norm = 1.7040e-01, time/batch = 0.2850s	
2208/2700 (epoch 40.889), train_loss = 1.42378023, grad/param norm = 1.8060e-01, time/batch = 0.2795s	
2209/2700 (epoch 40.907), train_loss = 1.51608105, grad/param norm = 2.4717e-01, time/batch = 0.3096s	
2210/2700 (epoch 40.926), train_loss = 1.46448039, grad/param norm = 2.0520e-01, time/batch = 0.2874s	
2211/2700 (epoch 40.944), train_loss = 1.42999134, grad/param norm = 2.0083e-01, time/batch = 0.2950s	
2212/2700 (epoch 40.963), train_loss = 1.46245557, grad/param norm = 1.9453e-01, time/batch = 0.2783s	
2213/2700 (epoch 40.981), train_loss = 1.40792129, grad/param norm = 1.9529e-01, time/batch = 0.2828s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2214/2700 (epoch 41.000), train_loss = 1.46063035, grad/param norm = 1.8516e-01, time/batch = 0.3165s	
2215/2700 (epoch 41.019), train_loss = 1.51757213, grad/param norm = 1.7255e-01, time/batch = 0.2869s	
2216/2700 (epoch 41.037), train_loss = 1.46615041, grad/param norm = 1.7614e-01, time/batch = 0.2413s	
2217/2700 (epoch 41.056), train_loss = 1.43024699, grad/param norm = 1.8015e-01, time/batch = 0.2610s	
2218/2700 (epoch 41.074), train_loss = 1.41565697, grad/param norm = 1.8527e-01, time/batch = 0.2994s	
2219/2700 (epoch 41.093), train_loss = 1.39591955, grad/param norm = 2.0458e-01, time/batch = 0.3029s	
2220/2700 (epoch 41.111), train_loss = 1.37168395, grad/param norm = 1.7852e-01, time/batch = 0.3222s	
2221/2700 (epoch 41.130), train_loss = 1.42164948, grad/param norm = 2.1381e-01, time/batch = 0.2790s	
2222/2700 (epoch 41.148), train_loss = 1.38388233, grad/param norm = 1.6396e-01, time/batch = 0.2938s	
2223/2700 (epoch 41.167), train_loss = 1.48716117, grad/param norm = 1.8527e-01, time/batch = 0.2948s	
2224/2700 (epoch 41.185), train_loss = 1.39758484, grad/param norm = 1.8478e-01, time/batch = 0.3168s	
2225/2700 (epoch 41.204), train_loss = 1.43948579, grad/param norm = 1.8216e-01, time/batch = 0.3189s	
2226/2700 (epoch 41.222), train_loss = 1.39892367, grad/param norm = 1.6966e-01, time/batch = 0.3397s	
2227/2700 (epoch 41.241), train_loss = 1.33819257, grad/param norm = 1.8415e-01, time/batch = 0.3240s	
2228/2700 (epoch 41.259), train_loss = 1.39184281, grad/param norm = 1.7677e-01, time/batch = 0.2973s	
2229/2700 (epoch 41.278), train_loss = 1.42644786, grad/param norm = 1.6615e-01, time/batch = 0.2788s	
2230/2700 (epoch 41.296), train_loss = 1.41891727, grad/param norm = 1.7441e-01, time/batch = 0.2323s	
2231/2700 (epoch 41.315), train_loss = 1.43601845, grad/param norm = 1.7057e-01, time/batch = 0.3002s	
2232/2700 (epoch 41.333), train_loss = 1.42465160, grad/param norm = 1.9049e-01, time/batch = 0.2862s	
2233/2700 (epoch 41.352), train_loss = 1.40516385, grad/param norm = 1.7202e-01, time/batch = 0.3203s	
2234/2700 (epoch 41.370), train_loss = 1.39438107, grad/param norm = 1.8935e-01, time/batch = 0.3077s	
2235/2700 (epoch 41.389), train_loss = 1.37351765, grad/param norm = 1.6714e-01, time/batch = 0.2902s	
2236/2700 (epoch 41.407), train_loss = 1.45671653, grad/param norm = 1.6474e-01, time/batch = 0.2940s	
2237/2700 (epoch 41.426), train_loss = 1.49178211, grad/param norm = 1.7622e-01, time/batch = 0.2991s	
2238/2700 (epoch 41.444), train_loss = 1.40092624, grad/param norm = 1.7640e-01, time/batch = 0.3334s	
2239/2700 (epoch 41.463), train_loss = 1.46591516, grad/param norm = 1.7565e-01, time/batch = 0.3333s	
2240/2700 (epoch 41.481), train_loss = 1.45175684, grad/param norm = 1.7897e-01, time/batch = 0.3234s	
2241/2700 (epoch 41.500), train_loss = 1.37738939, grad/param norm = 1.7718e-01, time/batch = 0.3334s	
2242/2700 (epoch 41.519), train_loss = 1.44215882, grad/param norm = 1.6960e-01, time/batch = 0.3273s	
2243/2700 (epoch 41.537), train_loss = 1.44052426, grad/param norm = 1.7692e-01, time/batch = 0.3266s	
2244/2700 (epoch 41.556), train_loss = 1.37665502, grad/param norm = 1.6747e-01, time/batch = 0.3016s	
2245/2700 (epoch 41.574), train_loss = 1.37882270, grad/param norm = 1.6743e-01, time/batch = 0.2807s	
2246/2700 (epoch 41.593), train_loss = 1.42038110, grad/param norm = 1.7192e-01, time/batch = 0.2822s	
2247/2700 (epoch 41.611), train_loss = 1.34765565, grad/param norm = 1.6970e-01, time/batch = 0.2885s	
2248/2700 (epoch 41.630), train_loss = 1.35003566, grad/param norm = 1.7487e-01, time/batch = 0.2697s	
2249/2700 (epoch 41.648), train_loss = 1.38056861, grad/param norm = 1.6322e-01, time/batch = 0.2432s	
2250/2700 (epoch 41.667), train_loss = 1.36615590, grad/param norm = 1.6858e-01, time/batch = 0.2774s	
2251/2700 (epoch 41.685), train_loss = 1.43540996, grad/param norm = 1.7285e-01, time/batch = 0.2572s	
2252/2700 (epoch 41.704), train_loss = 1.41504714, grad/param norm = 1.8426e-01, time/batch = 0.2885s	
2253/2700 (epoch 41.722), train_loss = 1.41213657, grad/param norm = 1.6922e-01, time/batch = 0.2710s	
2254/2700 (epoch 41.741), train_loss = 1.37540505, grad/param norm = 1.7677e-01, time/batch = 0.2728s	
2255/2700 (epoch 41.759), train_loss = 1.38936940, grad/param norm = 1.9118e-01, time/batch = 0.2640s	
2256/2700 (epoch 41.778), train_loss = 1.44679889, grad/param norm = 1.7564e-01, time/batch = 0.2977s	
2257/2700 (epoch 41.796), train_loss = 1.36015901, grad/param norm = 2.0104e-01, time/batch = 0.3185s	
2258/2700 (epoch 41.815), train_loss = 1.42393931, grad/param norm = 1.7979e-01, time/batch = 0.3170s	
2259/2700 (epoch 41.833), train_loss = 1.40285209, grad/param norm = 1.8540e-01, time/batch = 0.3077s	
2260/2700 (epoch 41.852), train_loss = 1.36733422, grad/param norm = 1.7219e-01, time/batch = 0.2824s	
2261/2700 (epoch 41.870), train_loss = 1.41898500, grad/param norm = 2.0046e-01, time/batch = 0.2632s	
2262/2700 (epoch 41.889), train_loss = 1.41591218, grad/param norm = 1.9682e-01, time/batch = 0.3168s	
2263/2700 (epoch 41.907), train_loss = 1.50521994, grad/param norm = 2.1758e-01, time/batch = 0.3313s	
2264/2700 (epoch 41.926), train_loss = 1.45261909, grad/param norm = 1.9078e-01, time/batch = 0.3096s	
2265/2700 (epoch 41.944), train_loss = 1.42043880, grad/param norm = 2.1357e-01, time/batch = 0.2942s	
2266/2700 (epoch 41.963), train_loss = 1.45432887, grad/param norm = 2.0858e-01, time/batch = 0.2742s	
2267/2700 (epoch 41.981), train_loss = 1.40498047, grad/param norm = 2.6988e-01, time/batch = 0.2512s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2268/2700 (epoch 42.000), train_loss = 1.45901536, grad/param norm = 2.1376e-01, time/batch = 0.2866s	
2269/2700 (epoch 42.019), train_loss = 1.51157124, grad/param norm = 2.0218e-01, time/batch = 0.3122s	
2270/2700 (epoch 42.037), train_loss = 1.46118542, grad/param norm = 1.9039e-01, time/batch = 0.3164s	
2271/2700 (epoch 42.056), train_loss = 1.41979782, grad/param norm = 1.7274e-01, time/batch = 0.2946s	
2272/2700 (epoch 42.074), train_loss = 1.40950330, grad/param norm = 1.8862e-01, time/batch = 0.2988s	
2273/2700 (epoch 42.093), train_loss = 1.38862704, grad/param norm = 2.1526e-01, time/batch = 0.2518s	
2274/2700 (epoch 42.111), train_loss = 1.36288414, grad/param norm = 1.8571e-01, time/batch = 0.2935s	
2275/2700 (epoch 42.130), train_loss = 1.41192197, grad/param norm = 2.0082e-01, time/batch = 0.3207s	
2276/2700 (epoch 42.148), train_loss = 1.37350351, grad/param norm = 1.6686e-01, time/batch = 0.3294s	
2277/2700 (epoch 42.167), train_loss = 1.47675316, grad/param norm = 1.8014e-01, time/batch = 0.3318s	
2278/2700 (epoch 42.185), train_loss = 1.38822734, grad/param norm = 1.8176e-01, time/batch = 0.3214s	
2279/2700 (epoch 42.204), train_loss = 1.43202871, grad/param norm = 2.0078e-01, time/batch = 0.3044s	
2280/2700 (epoch 42.222), train_loss = 1.38998369, grad/param norm = 1.7134e-01, time/batch = 0.2698s	
2281/2700 (epoch 42.241), train_loss = 1.33061856, grad/param norm = 1.8456e-01, time/batch = 0.2824s	
2282/2700 (epoch 42.259), train_loss = 1.38490616, grad/param norm = 1.7618e-01, time/batch = 0.2666s	
2283/2700 (epoch 42.278), train_loss = 1.41849845, grad/param norm = 1.7178e-01, time/batch = 0.2588s	
2284/2700 (epoch 42.296), train_loss = 1.41047913, grad/param norm = 1.8017e-01, time/batch = 0.2330s	
2285/2700 (epoch 42.315), train_loss = 1.42781943, grad/param norm = 1.7823e-01, time/batch = 0.2369s	
2286/2700 (epoch 42.333), train_loss = 1.41674187, grad/param norm = 1.7552e-01, time/batch = 0.3073s	
2287/2700 (epoch 42.352), train_loss = 1.39729811, grad/param norm = 1.7884e-01, time/batch = 0.3027s	
2288/2700 (epoch 42.370), train_loss = 1.38603891, grad/param norm = 1.9381e-01, time/batch = 0.2945s	
2289/2700 (epoch 42.389), train_loss = 1.36267315, grad/param norm = 1.6000e-01, time/batch = 0.2639s	
2290/2700 (epoch 42.407), train_loss = 1.44785689, grad/param norm = 1.7532e-01, time/batch = 0.2614s	
2291/2700 (epoch 42.426), train_loss = 1.48269186, grad/param norm = 1.7775e-01, time/batch = 0.2681s	
2292/2700 (epoch 42.444), train_loss = 1.39397606, grad/param norm = 1.8420e-01, time/batch = 0.2975s	
2293/2700 (epoch 42.463), train_loss = 1.45804279, grad/param norm = 1.7210e-01, time/batch = 0.3100s	
2294/2700 (epoch 42.481), train_loss = 1.44339330, grad/param norm = 1.7095e-01, time/batch = 0.3121s	
2295/2700 (epoch 42.500), train_loss = 1.36592256, grad/param norm = 1.7300e-01, time/batch = 0.2794s	
2296/2700 (epoch 42.519), train_loss = 1.43373592, grad/param norm = 1.7560e-01, time/batch = 0.2596s	
2297/2700 (epoch 42.537), train_loss = 1.43086715, grad/param norm = 1.8319e-01, time/batch = 0.2427s	
2298/2700 (epoch 42.556), train_loss = 1.36911806, grad/param norm = 1.7101e-01, time/batch = 0.2895s	
2299/2700 (epoch 42.574), train_loss = 1.37094949, grad/param norm = 1.7263e-01, time/batch = 0.2780s	
2300/2700 (epoch 42.593), train_loss = 1.41240462, grad/param norm = 1.7995e-01, time/batch = 0.2573s	
2301/2700 (epoch 42.611), train_loss = 1.33927014, grad/param norm = 1.6924e-01, time/batch = 0.2649s	
2302/2700 (epoch 42.630), train_loss = 1.34196169, grad/param norm = 1.7210e-01, time/batch = 0.2955s	
2303/2700 (epoch 42.648), train_loss = 1.37133716, grad/param norm = 1.5734e-01, time/batch = 0.3150s	
2304/2700 (epoch 42.667), train_loss = 1.35756178, grad/param norm = 1.7188e-01, time/batch = 0.3160s	
2305/2700 (epoch 42.685), train_loss = 1.42676532, grad/param norm = 1.7629e-01, time/batch = 0.3194s	
2306/2700 (epoch 42.704), train_loss = 1.40445648, grad/param norm = 1.7832e-01, time/batch = 0.2946s	
2307/2700 (epoch 42.722), train_loss = 1.40344672, grad/param norm = 1.6788e-01, time/batch = 0.2691s	
2308/2700 (epoch 42.741), train_loss = 1.36473272, grad/param norm = 1.7850e-01, time/batch = 0.2606s	
2309/2700 (epoch 42.759), train_loss = 1.37760954, grad/param norm = 1.8224e-01, time/batch = 0.2657s	
2310/2700 (epoch 42.778), train_loss = 1.43758505, grad/param norm = 1.8722e-01, time/batch = 0.2855s	
2311/2700 (epoch 42.796), train_loss = 1.35141828, grad/param norm = 2.0513e-01, time/batch = 0.2811s	
2312/2700 (epoch 42.815), train_loss = 1.41265126, grad/param norm = 1.6061e-01, time/batch = 0.2737s	
2313/2700 (epoch 42.833), train_loss = 1.39571903, grad/param norm = 2.1137e-01, time/batch = 0.2798s	
2314/2700 (epoch 42.852), train_loss = 1.35926430, grad/param norm = 1.9684e-01, time/batch = 0.2953s	
2315/2700 (epoch 42.870), train_loss = 1.40726310, grad/param norm = 1.6888e-01, time/batch = 0.3111s	
2316/2700 (epoch 42.889), train_loss = 1.40387602, grad/param norm = 1.8200e-01, time/batch = 0.3184s	
2317/2700 (epoch 42.907), train_loss = 1.49279437, grad/param norm = 2.2126e-01, time/batch = 0.3131s	
2318/2700 (epoch 42.926), train_loss = 1.44397662, grad/param norm = 2.2357e-01, time/batch = 0.2868s	
2319/2700 (epoch 42.944), train_loss = 1.41184967, grad/param norm = 2.1781e-01, time/batch = 0.2713s	
2320/2700 (epoch 42.963), train_loss = 1.44259125, grad/param norm = 1.7735e-01, time/batch = 0.2617s	
2321/2700 (epoch 42.981), train_loss = 1.38924656, grad/param norm = 2.0674e-01, time/batch = 0.2421s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
2322/2700 (epoch 43.000), train_loss = 1.44681548, grad/param norm = 2.0506e-01, time/batch = 0.2891s	
2323/2700 (epoch 43.019), train_loss = 1.50372192, grad/param norm = 1.9628e-01, time/batch = 0.2860s	
2324/2700 (epoch 43.037), train_loss = 1.44870422, grad/param norm = 1.7005e-01, time/batch = 0.2619s	
2325/2700 (epoch 43.056), train_loss = 1.41286578, grad/param norm = 1.8882e-01, time/batch = 0.2813s	
2326/2700 (epoch 43.074), train_loss = 1.40072302, grad/param norm = 1.8829e-01, time/batch = 0.3133s	
2327/2700 (epoch 43.093), train_loss = 1.37707768, grad/param norm = 2.0115e-01, time/batch = 0.3194s	
2328/2700 (epoch 43.111), train_loss = 1.35172388, grad/param norm = 1.7700e-01, time/batch = 0.3179s	
2329/2700 (epoch 43.130), train_loss = 1.40416831, grad/param norm = 1.9579e-01, time/batch = 0.2900s	
2330/2700 (epoch 43.148), train_loss = 1.36812326, grad/param norm = 1.7275e-01, time/batch = 0.2941s	
2331/2700 (epoch 43.167), train_loss = 1.46875055, grad/param norm = 1.8864e-01, time/batch = 0.3234s	
2332/2700 (epoch 43.185), train_loss = 1.37964311, grad/param norm = 1.8461e-01, time/batch = 0.2991s	
2333/2700 (epoch 43.204), train_loss = 1.42204318, grad/param norm = 1.8370e-01, time/batch = 0.2384s	
2334/2700 (epoch 43.222), train_loss = 1.38294579, grad/param norm = 1.7752e-01, time/batch = 0.2965s	
2335/2700 (epoch 43.241), train_loss = 1.32319213, grad/param norm = 1.8511e-01, time/batch = 0.2917s	
2336/2700 (epoch 43.259), train_loss = 1.37735382, grad/param norm = 1.7624e-01, time/batch = 0.2799s	
2337/2700 (epoch 43.278), train_loss = 1.40874731, grad/param norm = 1.6926e-01, time/batch = 0.2689s	
2338/2700 (epoch 43.296), train_loss = 1.40164171, grad/param norm = 1.7745e-01, time/batch = 0.2891s	
2339/2700 (epoch 43.315), train_loss = 1.41834883, grad/param norm = 1.7288e-01, time/batch = 0.2863s	
2340/2700 (epoch 43.333), train_loss = 1.40649278, grad/param norm = 1.7368e-01, time/batch = 0.2769s	
2341/2700 (epoch 43.352), train_loss = 1.38788704, grad/param norm = 1.7555e-01, time/batch = 0.2898s	
2342/2700 (epoch 43.370), train_loss = 1.37967923, grad/param norm = 2.0410e-01, time/batch = 0.2752s	
2343/2700 (epoch 43.389), train_loss = 1.35613114, grad/param norm = 1.8242e-01, time/batch = 0.3342s	
2344/2700 (epoch 43.407), train_loss = 1.43820877, grad/param norm = 1.6434e-01, time/batch = 0.3186s	
2345/2700 (epoch 43.426), train_loss = 1.47261800, grad/param norm = 1.7176e-01, time/batch = 0.2603s	
2346/2700 (epoch 43.444), train_loss = 1.38431588, grad/param norm = 1.7523e-01, time/batch = 0.3327s	
2347/2700 (epoch 43.463), train_loss = 1.44776297, grad/param norm = 1.7324e-01, time/batch = 0.3289s	
2348/2700 (epoch 43.481), train_loss = 1.43451699, grad/param norm = 1.6957e-01, time/batch = 0.3134s	
2349/2700 (epoch 43.500), train_loss = 1.35713531, grad/param norm = 1.7365e-01, time/batch = 0.2757s	
2350/2700 (epoch 43.519), train_loss = 1.42494616, grad/param norm = 1.7398e-01, time/batch = 0.2154s	
2351/2700 (epoch 43.537), train_loss = 1.42422326, grad/param norm = 1.9073e-01, time/batch = 0.2838s	
2352/2700 (epoch 43.556), train_loss = 1.35894975, grad/param norm = 1.6714e-01, time/batch = 0.3020s	
2353/2700 (epoch 43.574), train_loss = 1.36167743, grad/param norm = 1.6968e-01, time/batch = 0.2894s	
2354/2700 (epoch 43.593), train_loss = 1.40345434, grad/param norm = 1.7626e-01, time/batch = 0.3311s	
2355/2700 (epoch 43.611), train_loss = 1.33093947, grad/param norm = 1.6919e-01, time/batch = 0.3197s	
2356/2700 (epoch 43.630), train_loss = 1.33374392, grad/param norm = 1.7323e-01, time/batch = 0.2937s	
2357/2700 (epoch 43.648), train_loss = 1.36221755, grad/param norm = 1.5745e-01, time/batch = 0.2623s	
2358/2700 (epoch 43.667), train_loss = 1.34934390, grad/param norm = 1.6996e-01, time/batch = 0.3228s	
2359/2700 (epoch 43.685), train_loss = 1.41782053, grad/param norm = 1.7100e-01, time/batch = 0.3076s	
2360/2700 (epoch 43.704), train_loss = 1.39497339, grad/param norm = 1.7854e-01, time/batch = 0.2807s	
2361/2700 (epoch 43.722), train_loss = 1.39556525, grad/param norm = 1.7327e-01, time/batch = 0.2424s	
2362/2700 (epoch 43.741), train_loss = 1.35392415, grad/param norm = 1.8560e-01, time/batch = 0.2835s	
2363/2700 (epoch 43.759), train_loss = 1.36723914, grad/param norm = 1.8043e-01, time/batch = 0.3088s	
2364/2700 (epoch 43.778), train_loss = 1.42738926, grad/param norm = 1.8298e-01, time/batch = 0.2936s	
2365/2700 (epoch 43.796), train_loss = 1.34198419, grad/param norm = 1.9648e-01, time/batch = 0.3005s	
2366/2700 (epoch 43.815), train_loss = 1.40358006, grad/param norm = 1.6391e-01, time/batch = 0.2985s	
2367/2700 (epoch 43.833), train_loss = 1.38566725, grad/param norm = 1.9954e-01, time/batch = 0.2934s	
2368/2700 (epoch 43.852), train_loss = 1.34790486, grad/param norm = 1.7596e-01, time/batch = 0.2677s	
2369/2700 (epoch 43.870), train_loss = 1.39901538, grad/param norm = 1.7778e-01, time/batch = 0.2527s	
2370/2700 (epoch 43.889), train_loss = 1.39421100, grad/param norm = 1.8135e-01, time/batch = 0.2773s	
2371/2700 (epoch 43.907), train_loss = 1.48401670, grad/param norm = 2.1892e-01, time/batch = 0.2767s	
2372/2700 (epoch 43.926), train_loss = 1.43093702, grad/param norm = 1.8479e-01, time/batch = 0.2480s	
2373/2700 (epoch 43.944), train_loss = 1.39814035, grad/param norm = 2.0982e-01, time/batch = 0.3090s	
2374/2700 (epoch 43.963), train_loss = 1.43465616, grad/param norm = 1.9709e-01, time/batch = 0.3255s	
2375/2700 (epoch 43.981), train_loss = 1.38207038, grad/param norm = 2.1678e-01, time/batch = 0.3196s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
2376/2700 (epoch 44.000), train_loss = 1.43834680, grad/param norm = 1.9642e-01, time/batch = 0.3134s	
2377/2700 (epoch 44.019), train_loss = 1.49368700, grad/param norm = 1.8431e-01, time/batch = 0.2968s	
2378/2700 (epoch 44.037), train_loss = 1.44309340, grad/param norm = 1.8615e-01, time/batch = 0.2791s	
2379/2700 (epoch 44.056), train_loss = 1.40286833, grad/param norm = 1.8633e-01, time/batch = 0.2591s	
2380/2700 (epoch 44.074), train_loss = 1.39097686, grad/param norm = 1.8530e-01, time/batch = 0.2766s	
2381/2700 (epoch 44.093), train_loss = 1.36992635, grad/param norm = 2.0790e-01, time/batch = 0.2451s	
2382/2700 (epoch 44.111), train_loss = 1.34344946, grad/param norm = 1.7537e-01, time/batch = 0.2715s	
2383/2700 (epoch 44.130), train_loss = 1.39346309, grad/param norm = 1.9473e-01, time/batch = 0.2571s	
2384/2700 (epoch 44.148), train_loss = 1.35935386, grad/param norm = 1.6788e-01, time/batch = 0.3164s	
2385/2700 (epoch 44.167), train_loss = 1.45981935, grad/param norm = 1.8144e-01, time/batch = 0.3239s	
2386/2700 (epoch 44.185), train_loss = 1.37043278, grad/param norm = 1.8446e-01, time/batch = 0.3187s	
2387/2700 (epoch 44.204), train_loss = 1.41481993, grad/param norm = 1.9536e-01, time/batch = 0.3090s	
2388/2700 (epoch 44.222), train_loss = 1.37481750, grad/param norm = 1.7437e-01, time/batch = 0.2953s	
2389/2700 (epoch 44.241), train_loss = 1.31495226, grad/param norm = 1.8154e-01, time/batch = 0.2769s	
2390/2700 (epoch 44.259), train_loss = 1.36927263, grad/param norm = 1.7896e-01, time/batch = 0.2557s	
2391/2700 (epoch 44.278), train_loss = 1.40002431, grad/param norm = 1.7093e-01, time/batch = 0.2506s	
2392/2700 (epoch 44.296), train_loss = 1.39206121, grad/param norm = 1.7222e-01, time/batch = 0.2743s	
2393/2700 (epoch 44.315), train_loss = 1.41015869, grad/param norm = 1.7886e-01, time/batch = 0.2887s	
2394/2700 (epoch 44.333), train_loss = 1.39800338, grad/param norm = 1.7452e-01, time/batch = 0.2542s	
2395/2700 (epoch 44.352), train_loss = 1.38153351, grad/param norm = 1.9628e-01, time/batch = 0.2965s	
2396/2700 (epoch 44.370), train_loss = 1.36991862, grad/param norm = 2.0102e-01, time/batch = 0.3073s	
2397/2700 (epoch 44.389), train_loss = 1.34469160, grad/param norm = 1.6965e-01, time/batch = 0.3150s	
2398/2700 (epoch 44.407), train_loss = 1.43141892, grad/param norm = 1.6712e-01, time/batch = 0.3140s	
2399/2700 (epoch 44.426), train_loss = 1.46405727, grad/param norm = 1.7397e-01, time/batch = 0.3039s	
2400/2700 (epoch 44.444), train_loss = 1.37673163, grad/param norm = 1.7824e-01, time/batch = 0.2886s	
2401/2700 (epoch 44.463), train_loss = 1.43976917, grad/param norm = 1.7262e-01, time/batch = 0.2972s	
2402/2700 (epoch 44.481), train_loss = 1.42607147, grad/param norm = 1.7074e-01, time/batch = 0.2641s	
2403/2700 (epoch 44.500), train_loss = 1.34863618, grad/param norm = 1.7555e-01, time/batch = 0.2504s	
2404/2700 (epoch 44.519), train_loss = 1.41519236, grad/param norm = 1.7057e-01, time/batch = 0.2820s	
2405/2700 (epoch 44.537), train_loss = 1.41426814, grad/param norm = 1.7962e-01, time/batch = 0.2877s	
2406/2700 (epoch 44.556), train_loss = 1.35188781, grad/param norm = 1.6956e-01, time/batch = 0.2667s	
2407/2700 (epoch 44.574), train_loss = 1.35285481, grad/param norm = 1.6921e-01, time/batch = 0.2932s	
2408/2700 (epoch 44.593), train_loss = 1.39502959, grad/param norm = 1.7388e-01, time/batch = 0.3201s	
2409/2700 (epoch 44.611), train_loss = 1.32390430, grad/param norm = 1.7513e-01, time/batch = 0.3273s	
2410/2700 (epoch 44.630), train_loss = 1.32638809, grad/param norm = 1.7511e-01, time/batch = 0.3186s	
2411/2700 (epoch 44.648), train_loss = 1.35407318, grad/param norm = 1.6250e-01, time/batch = 0.3250s	
2412/2700 (epoch 44.667), train_loss = 1.34204625, grad/param norm = 1.8784e-01, time/batch = 0.3310s	
2413/2700 (epoch 44.685), train_loss = 1.40966767, grad/param norm = 1.7263e-01, time/batch = 0.3335s	
2414/2700 (epoch 44.704), train_loss = 1.38532830, grad/param norm = 1.7346e-01, time/batch = 0.3331s	
2415/2700 (epoch 44.722), train_loss = 1.38823795, grad/param norm = 1.7776e-01, time/batch = 0.3246s	
2416/2700 (epoch 44.741), train_loss = 1.34507453, grad/param norm = 1.8318e-01, time/batch = 0.3150s	
2417/2700 (epoch 44.759), train_loss = 1.35839999, grad/param norm = 1.7834e-01, time/batch = 0.2361s	
2418/2700 (epoch 44.778), train_loss = 1.41777314, grad/param norm = 1.7686e-01, time/batch = 0.2500s	
2419/2700 (epoch 44.796), train_loss = 1.33254200, grad/param norm = 2.0711e-01, time/batch = 0.2667s	
2420/2700 (epoch 44.815), train_loss = 1.39672657, grad/param norm = 1.6936e-01, time/batch = 0.2658s	
2421/2700 (epoch 44.833), train_loss = 1.37522278, grad/param norm = 1.9099e-01, time/batch = 0.2664s	
2422/2700 (epoch 44.852), train_loss = 1.33973071, grad/param norm = 1.7669e-01, time/batch = 0.2999s	
2423/2700 (epoch 44.870), train_loss = 1.39164782, grad/param norm = 1.8510e-01, time/batch = 0.3176s	
2424/2700 (epoch 44.889), train_loss = 1.38600078, grad/param norm = 1.8319e-01, time/batch = 0.3236s	
2425/2700 (epoch 44.907), train_loss = 1.47330188, grad/param norm = 2.0326e-01, time/batch = 0.3332s	
2426/2700 (epoch 44.926), train_loss = 1.42189479, grad/param norm = 1.8857e-01, time/batch = 0.3226s	
2427/2700 (epoch 44.944), train_loss = 1.39081341, grad/param norm = 2.2018e-01, time/batch = 0.3245s	
2428/2700 (epoch 44.963), train_loss = 1.42578929, grad/param norm = 1.9272e-01, time/batch = 0.3020s	
2429/2700 (epoch 44.981), train_loss = 1.37224078, grad/param norm = 2.0387e-01, time/batch = 0.2304s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
2430/2700 (epoch 45.000), train_loss = 1.42818497, grad/param norm = 1.9282e-01, time/batch = 0.2761s	
2431/2700 (epoch 45.019), train_loss = 1.48514188, grad/param norm = 1.9618e-01, time/batch = 0.3190s	
2432/2700 (epoch 45.037), train_loss = 1.43426501, grad/param norm = 1.8609e-01, time/batch = 0.2902s	
2433/2700 (epoch 45.056), train_loss = 1.39237767, grad/param norm = 1.7361e-01, time/batch = 0.2453s	
2434/2700 (epoch 45.074), train_loss = 1.38324564, grad/param norm = 1.8796e-01, time/batch = 0.2570s	
2435/2700 (epoch 45.093), train_loss = 1.36243009, grad/param norm = 2.1159e-01, time/batch = 0.2947s	
2436/2700 (epoch 45.111), train_loss = 1.33470513, grad/param norm = 1.8004e-01, time/batch = 0.3085s	
2437/2700 (epoch 45.130), train_loss = 1.38489133, grad/param norm = 1.9670e-01, time/batch = 0.2817s	
2438/2700 (epoch 45.148), train_loss = 1.35352025, grad/param norm = 1.7181e-01, time/batch = 0.2795s	
2439/2700 (epoch 45.167), train_loss = 1.45054641, grad/param norm = 1.8344e-01, time/batch = 0.2582s	
2440/2700 (epoch 45.185), train_loss = 1.36270990, grad/param norm = 1.8517e-01, time/batch = 0.2807s	
2441/2700 (epoch 45.204), train_loss = 1.40534706, grad/param norm = 1.8401e-01, time/batch = 0.2965s	
2442/2700 (epoch 45.222), train_loss = 1.36729149, grad/param norm = 1.8322e-01, time/batch = 0.3099s	
2443/2700 (epoch 45.241), train_loss = 1.30904075, grad/param norm = 1.8824e-01, time/batch = 0.2744s	
2444/2700 (epoch 45.259), train_loss = 1.36257861, grad/param norm = 1.7920e-01, time/batch = 0.2511s	
2445/2700 (epoch 45.278), train_loss = 1.39133474, grad/param norm = 1.7092e-01, time/batch = 0.2799s	
2446/2700 (epoch 45.296), train_loss = 1.38492981, grad/param norm = 1.7872e-01, time/batch = 0.3024s	
2447/2700 (epoch 45.315), train_loss = 1.40082884, grad/param norm = 1.7440e-01, time/batch = 0.3108s	
2448/2700 (epoch 45.333), train_loss = 1.38976269, grad/param norm = 1.7259e-01, time/batch = 0.2641s	
2449/2700 (epoch 45.352), train_loss = 1.36969722, grad/param norm = 1.7131e-01, time/batch = 0.2739s	
2450/2700 (epoch 45.370), train_loss = 1.35990042, grad/param norm = 2.0131e-01, time/batch = 0.2665s	
2451/2700 (epoch 45.389), train_loss = 1.33657058, grad/param norm = 1.6625e-01, time/batch = 0.2916s	
2452/2700 (epoch 45.407), train_loss = 1.42229142, grad/param norm = 1.6877e-01, time/batch = 0.2947s	
2453/2700 (epoch 45.426), train_loss = 1.45604738, grad/param norm = 1.7555e-01, time/batch = 0.2964s	
2454/2700 (epoch 45.444), train_loss = 1.37010063, grad/param norm = 1.8163e-01, time/batch = 0.2483s	
2455/2700 (epoch 45.463), train_loss = 1.43178836, grad/param norm = 1.7377e-01, time/batch = 0.2818s	
2456/2700 (epoch 45.481), train_loss = 1.41830507, grad/param norm = 1.7086e-01, time/batch = 0.3076s	
2457/2700 (epoch 45.500), train_loss = 1.34005415, grad/param norm = 1.7726e-01, time/batch = 0.3066s	
2458/2700 (epoch 45.519), train_loss = 1.40917404, grad/param norm = 1.7952e-01, time/batch = 0.3117s	
2459/2700 (epoch 45.537), train_loss = 1.40542451, grad/param norm = 1.8735e-01, time/batch = 0.2869s	
2460/2700 (epoch 45.556), train_loss = 1.34455127, grad/param norm = 1.7117e-01, time/batch = 0.2857s	
2461/2700 (epoch 45.574), train_loss = 1.34533950, grad/param norm = 1.7237e-01, time/batch = 0.2570s	
2462/2700 (epoch 45.593), train_loss = 1.38745157, grad/param norm = 1.7641e-01, time/batch = 0.2640s	
2463/2700 (epoch 45.611), train_loss = 1.31611628, grad/param norm = 1.7287e-01, time/batch = 0.2757s	
2464/2700 (epoch 45.630), train_loss = 1.31816957, grad/param norm = 1.7550e-01, time/batch = 0.2903s	
2465/2700 (epoch 45.648), train_loss = 1.34520772, grad/param norm = 1.6151e-01, time/batch = 0.2953s	
2466/2700 (epoch 45.667), train_loss = 1.33309557, grad/param norm = 1.7085e-01, time/batch = 0.2415s	
2467/2700 (epoch 45.685), train_loss = 1.40227306, grad/param norm = 1.7775e-01, time/batch = 0.3025s	
2468/2700 (epoch 45.704), train_loss = 1.37839576, grad/param norm = 1.8429e-01, time/batch = 0.3104s	
2469/2700 (epoch 45.722), train_loss = 1.37972165, grad/param norm = 1.7369e-01, time/batch = 0.3190s	
2470/2700 (epoch 45.741), train_loss = 1.33418965, grad/param norm = 1.7433e-01, time/batch = 0.3058s	
2471/2700 (epoch 45.759), train_loss = 1.34939365, grad/param norm = 1.7401e-01, time/batch = 0.3015s	
2472/2700 (epoch 45.778), train_loss = 1.40938881, grad/param norm = 1.7759e-01, time/batch = 0.2741s	
2473/2700 (epoch 45.796), train_loss = 1.32613381, grad/param norm = 2.1736e-01, time/batch = 0.2656s	
2474/2700 (epoch 45.815), train_loss = 1.38853365, grad/param norm = 1.7184e-01, time/batch = 0.2725s	
2475/2700 (epoch 45.833), train_loss = 1.36652752, grad/param norm = 1.9287e-01, time/batch = 0.2888s	
2476/2700 (epoch 45.852), train_loss = 1.33052754, grad/param norm = 1.7529e-01, time/batch = 0.2948s	
2477/2700 (epoch 45.870), train_loss = 1.38336487, grad/param norm = 1.8345e-01, time/batch = 0.2782s	
2478/2700 (epoch 45.889), train_loss = 1.37867726, grad/param norm = 1.9829e-01, time/batch = 0.2169s	
2479/2700 (epoch 45.907), train_loss = 1.46746372, grad/param norm = 2.1906e-01, time/batch = 0.2985s	
2480/2700 (epoch 45.926), train_loss = 1.41187747, grad/param norm = 1.9815e-01, time/batch = 0.2918s	
2481/2700 (epoch 45.944), train_loss = 1.38341972, grad/param norm = 2.2518e-01, time/batch = 0.2858s	
2482/2700 (epoch 45.963), train_loss = 1.41623165, grad/param norm = 1.8108e-01, time/batch = 0.2504s	
2483/2700 (epoch 45.981), train_loss = 1.35875029, grad/param norm = 1.9147e-01, time/batch = 0.2634s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
2484/2700 (epoch 46.000), train_loss = 1.41799773, grad/param norm = 1.8567e-01, time/batch = 0.3012s	
2485/2700 (epoch 46.019), train_loss = 1.47717836, grad/param norm = 1.8590e-01, time/batch = 0.3151s	
2486/2700 (epoch 46.037), train_loss = 1.42561451, grad/param norm = 1.7584e-01, time/batch = 0.3140s	
2487/2700 (epoch 46.056), train_loss = 1.38555869, grad/param norm = 1.8534e-01, time/batch = 0.3070s	
2488/2700 (epoch 46.074), train_loss = 1.37523117, grad/param norm = 1.8451e-01, time/batch = 0.2665s	
2489/2700 (epoch 46.093), train_loss = 1.35315607, grad/param norm = 1.9810e-01, time/batch = 0.2686s	
2490/2700 (epoch 46.111), train_loss = 1.32570015, grad/param norm = 1.9526e-01, time/batch = 0.2621s	
2491/2700 (epoch 46.130), train_loss = 1.37559252, grad/param norm = 2.0775e-01, time/batch = 0.3017s	
2492/2700 (epoch 46.148), train_loss = 1.34669212, grad/param norm = 1.6812e-01, time/batch = 0.2771s	
2493/2700 (epoch 46.167), train_loss = 1.44328194, grad/param norm = 1.8257e-01, time/batch = 0.2279s	
2494/2700 (epoch 46.185), train_loss = 1.35468543, grad/param norm = 1.8869e-01, time/batch = 0.2736s	
2495/2700 (epoch 46.204), train_loss = 1.40017218, grad/param norm = 2.1149e-01, time/batch = 0.3169s	
2496/2700 (epoch 46.222), train_loss = 1.35999119, grad/param norm = 1.7918e-01, time/batch = 0.3252s	
2497/2700 (epoch 46.241), train_loss = 1.30070140, grad/param norm = 1.7983e-01, time/batch = 0.3311s	
2498/2700 (epoch 46.259), train_loss = 1.35598320, grad/param norm = 1.7889e-01, time/batch = 0.3334s	
2499/2700 (epoch 46.278), train_loss = 1.38462111, grad/param norm = 1.7518e-01, time/batch = 0.3335s	
2500/2700 (epoch 46.296), train_loss = 1.37776151, grad/param norm = 1.8018e-01, time/batch = 0.3203s	
2501/2700 (epoch 46.315), train_loss = 1.39299778, grad/param norm = 1.7788e-01, time/batch = 0.3277s	
2502/2700 (epoch 46.333), train_loss = 1.38243550, grad/param norm = 1.7463e-01, time/batch = 0.2827s	
2503/2700 (epoch 46.352), train_loss = 1.36136217, grad/param norm = 1.7185e-01, time/batch = 0.2900s	
2504/2700 (epoch 46.370), train_loss = 1.35121939, grad/param norm = 1.9625e-01, time/batch = 0.2917s	
2505/2700 (epoch 46.389), train_loss = 1.32731339, grad/param norm = 1.6957e-01, time/batch = 0.2883s	
2506/2700 (epoch 46.407), train_loss = 1.41580785, grad/param norm = 1.7458e-01, time/batch = 0.2811s	
2507/2700 (epoch 46.426), train_loss = 1.44794327, grad/param norm = 1.8157e-01, time/batch = 0.2548s	
2508/2700 (epoch 46.444), train_loss = 1.36156120, grad/param norm = 1.8245e-01, time/batch = 0.2674s	
2509/2700 (epoch 46.463), train_loss = 1.42441650, grad/param norm = 1.7926e-01, time/batch = 0.3111s	
2510/2700 (epoch 46.481), train_loss = 1.40981472, grad/param norm = 1.7172e-01, time/batch = 0.3249s	
2511/2700 (epoch 46.500), train_loss = 1.33227505, grad/param norm = 1.7659e-01, time/batch = 0.3032s	
2512/2700 (epoch 46.519), train_loss = 1.39965575, grad/param norm = 1.7295e-01, time/batch = 0.3120s	
2513/2700 (epoch 46.537), train_loss = 1.39798844, grad/param norm = 1.8405e-01, time/batch = 0.3073s	
2514/2700 (epoch 46.556), train_loss = 1.33595555, grad/param norm = 1.6704e-01, time/batch = 0.2504s	
2515/2700 (epoch 46.574), train_loss = 1.33653954, grad/param norm = 1.7141e-01, time/batch = 0.2788s	
2516/2700 (epoch 46.593), train_loss = 1.37886189, grad/param norm = 1.7500e-01, time/batch = 0.2896s	
2517/2700 (epoch 46.611), train_loss = 1.30890444, grad/param norm = 1.7490e-01, time/batch = 0.2940s	
2518/2700 (epoch 46.630), train_loss = 1.31142384, grad/param norm = 1.7625e-01, time/batch = 0.2926s	
2519/2700 (epoch 46.648), train_loss = 1.33764703, grad/param norm = 1.6281e-01, time/batch = 0.2663s	
2520/2700 (epoch 46.667), train_loss = 1.32564710, grad/param norm = 1.7868e-01, time/batch = 0.2723s	
2521/2700 (epoch 46.685), train_loss = 1.39424853, grad/param norm = 1.7577e-01, time/batch = 0.2835s	
2522/2700 (epoch 46.704), train_loss = 1.36997848, grad/param norm = 1.9116e-01, time/batch = 0.3053s	
2523/2700 (epoch 46.722), train_loss = 1.37384229, grad/param norm = 1.7679e-01, time/batch = 0.3157s	
2524/2700 (epoch 46.741), train_loss = 1.32803712, grad/param norm = 1.8728e-01, time/batch = 0.3172s	
2525/2700 (epoch 46.759), train_loss = 1.34423510, grad/param norm = 2.1204e-01, time/batch = 0.3055s	
2526/2700 (epoch 46.778), train_loss = 1.40089640, grad/param norm = 1.8677e-01, time/batch = 0.2314s	
2527/2700 (epoch 46.796), train_loss = 1.31787207, grad/param norm = 2.0935e-01, time/batch = 0.2841s	
2528/2700 (epoch 46.815), train_loss = 1.38198105, grad/param norm = 1.6749e-01, time/batch = 0.2965s	
2529/2700 (epoch 46.833), train_loss = 1.35860460, grad/param norm = 2.0133e-01, time/batch = 0.3001s	
2530/2700 (epoch 46.852), train_loss = 1.32440958, grad/param norm = 1.9113e-01, time/batch = 0.2860s	
2531/2700 (epoch 46.870), train_loss = 1.37460035, grad/param norm = 1.7380e-01, time/batch = 0.2776s	
2532/2700 (epoch 46.889), train_loss = 1.36993574, grad/param norm = 1.8363e-01, time/batch = 0.2732s	
2533/2700 (epoch 46.907), train_loss = 1.45859582, grad/param norm = 2.2603e-01, time/batch = 0.2927s	
2534/2700 (epoch 46.926), train_loss = 1.40383868, grad/param norm = 1.8768e-01, time/batch = 0.3035s	
2535/2700 (epoch 46.944), train_loss = 1.37369694, grad/param norm = 2.2683e-01, time/batch = 0.3065s	
2536/2700 (epoch 46.963), train_loss = 1.40950948, grad/param norm = 2.0121e-01, time/batch = 0.3057s	
2537/2700 (epoch 46.981), train_loss = 1.35286716, grad/param norm = 1.9995e-01, time/batch = 0.2610s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
2538/2700 (epoch 47.000), train_loss = 1.40971363, grad/param norm = 1.8636e-01, time/batch = 0.2216s	
2539/2700 (epoch 47.019), train_loss = 1.46851305, grad/param norm = 1.8338e-01, time/batch = 0.3022s	
2540/2700 (epoch 47.037), train_loss = 1.41677913, grad/param norm = 1.7230e-01, time/batch = 0.3006s	
2541/2700 (epoch 47.056), train_loss = 1.37632194, grad/param norm = 1.8140e-01, time/batch = 0.2874s	
2542/2700 (epoch 47.074), train_loss = 1.36812509, grad/param norm = 1.8980e-01, time/batch = 0.2876s	
2543/2700 (epoch 47.093), train_loss = 1.34634821, grad/param norm = 2.1469e-01, time/batch = 0.2732s	
2544/2700 (epoch 47.111), train_loss = 1.31921289, grad/param norm = 1.8730e-01, time/batch = 0.2957s	
2545/2700 (epoch 47.130), train_loss = 1.37179505, grad/param norm = 2.0856e-01, time/batch = 0.3030s	
2546/2700 (epoch 47.148), train_loss = 1.33958227, grad/param norm = 1.7923e-01, time/batch = 0.3062s	
2547/2700 (epoch 47.167), train_loss = 1.43451566, grad/param norm = 1.8346e-01, time/batch = 0.3167s	
2548/2700 (epoch 47.185), train_loss = 1.34770802, grad/param norm = 1.8770e-01, time/batch = 0.2661s	
2549/2700 (epoch 47.204), train_loss = 1.39192777, grad/param norm = 2.0348e-01, time/batch = 0.2587s	
2550/2700 (epoch 47.222), train_loss = 1.35445658, grad/param norm = 1.9063e-01, time/batch = 0.2763s	
2551/2700 (epoch 47.241), train_loss = 1.29548717, grad/param norm = 1.8561e-01, time/batch = 0.2458s	
2552/2700 (epoch 47.259), train_loss = 1.34904332, grad/param norm = 1.8017e-01, time/batch = 0.2233s	
2553/2700 (epoch 47.278), train_loss = 1.37764733, grad/param norm = 1.7606e-01, time/batch = 0.2508s	
2554/2700 (epoch 47.296), train_loss = 1.36928832, grad/param norm = 1.7796e-01, time/batch = 0.2940s	
2555/2700 (epoch 47.315), train_loss = 1.38455535, grad/param norm = 1.8029e-01, time/batch = 0.3186s	
2556/2700 (epoch 47.333), train_loss = 1.37381811, grad/param norm = 1.7117e-01, time/batch = 0.3070s	
2557/2700 (epoch 47.352), train_loss = 1.35428522, grad/param norm = 1.8088e-01, time/batch = 0.2981s	
2558/2700 (epoch 47.370), train_loss = 1.34361634, grad/param norm = 2.0626e-01, time/batch = 0.2677s	
2559/2700 (epoch 47.389), train_loss = 1.31968749, grad/param norm = 1.7375e-01, time/batch = 0.2372s	
2560/2700 (epoch 47.407), train_loss = 1.40807405, grad/param norm = 1.8389e-01, time/batch = 0.2665s	
2561/2700 (epoch 47.426), train_loss = 1.44065471, grad/param norm = 1.7842e-01, time/batch = 0.2738s	
2562/2700 (epoch 47.444), train_loss = 1.35375267, grad/param norm = 1.8291e-01, time/batch = 0.2935s	
2563/2700 (epoch 47.463), train_loss = 1.41560836, grad/param norm = 1.7779e-01, time/batch = 0.3083s	
2564/2700 (epoch 47.481), train_loss = 1.40365476, grad/param norm = 1.7333e-01, time/batch = 0.2998s	
2565/2700 (epoch 47.500), train_loss = 1.32469144, grad/param norm = 1.7750e-01, time/batch = 0.2361s	
2566/2700 (epoch 47.519), train_loss = 1.39335888, grad/param norm = 1.8663e-01, time/batch = 0.3101s	
2567/2700 (epoch 47.537), train_loss = 1.39132252, grad/param norm = 2.0588e-01, time/batch = 0.3034s	
2568/2700 (epoch 47.556), train_loss = 1.32975438, grad/param norm = 1.7463e-01, time/batch = 0.2930s	
2569/2700 (epoch 47.574), train_loss = 1.32997200, grad/param norm = 1.8122e-01, time/batch = 0.2703s	
2570/2700 (epoch 47.593), train_loss = 1.37271557, grad/param norm = 1.7709e-01, time/batch = 0.2395s	
2571/2700 (epoch 47.611), train_loss = 1.30174921, grad/param norm = 1.7695e-01, time/batch = 0.2567s	
2572/2700 (epoch 47.630), train_loss = 1.30430634, grad/param norm = 1.7580e-01, time/batch = 0.2881s	
2573/2700 (epoch 47.648), train_loss = 1.33001181, grad/param norm = 1.6806e-01, time/batch = 0.3060s	
2574/2700 (epoch 47.667), train_loss = 1.31870447, grad/param norm = 1.8066e-01, time/batch = 0.3145s	
2575/2700 (epoch 47.685), train_loss = 1.38625655, grad/param norm = 1.7463e-01, time/batch = 0.3149s	
2576/2700 (epoch 47.704), train_loss = 1.36358745, grad/param norm = 2.2168e-01, time/batch = 0.2860s	
2577/2700 (epoch 47.722), train_loss = 1.36810931, grad/param norm = 1.9651e-01, time/batch = 0.2382s	
2578/2700 (epoch 47.741), train_loss = 1.32026402, grad/param norm = 2.0941e-01, time/batch = 0.2938s	
2579/2700 (epoch 47.759), train_loss = 1.33615985, grad/param norm = 1.8934e-01, time/batch = 0.2656s	
2580/2700 (epoch 47.778), train_loss = 1.39434767, grad/param norm = 2.0411e-01, time/batch = 0.2441s	
2581/2700 (epoch 47.796), train_loss = 1.31264094, grad/param norm = 2.3277e-01, time/batch = 0.2302s	
2582/2700 (epoch 47.815), train_loss = 1.37322796, grad/param norm = 1.6720e-01, time/batch = 0.3153s	
2583/2700 (epoch 47.833), train_loss = 1.35190545, grad/param norm = 2.0812e-01, time/batch = 0.3259s	
2584/2700 (epoch 47.852), train_loss = 1.31466752, grad/param norm = 1.8551e-01, time/batch = 0.3288s	
2585/2700 (epoch 47.870), train_loss = 1.36847666, grad/param norm = 1.7854e-01, time/batch = 0.3284s	
2586/2700 (epoch 47.889), train_loss = 1.36129053, grad/param norm = 1.8412e-01, time/batch = 0.3296s	
2587/2700 (epoch 47.907), train_loss = 1.44902306, grad/param norm = 2.0616e-01, time/batch = 0.3102s	
2588/2700 (epoch 47.926), train_loss = 1.39535112, grad/param norm = 1.9963e-01, time/batch = 0.2848s	
2589/2700 (epoch 47.944), train_loss = 1.36326809, grad/param norm = 2.1947e-01, time/batch = 0.2275s	
2590/2700 (epoch 47.963), train_loss = 1.40026162, grad/param norm = 1.8401e-01, time/batch = 0.2595s	
2591/2700 (epoch 47.981), train_loss = 1.34416868, grad/param norm = 2.0086e-01, time/batch = 0.2657s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
2592/2700 (epoch 48.000), train_loss = 1.40099635, grad/param norm = 1.9010e-01, time/batch = 0.1771s	
2593/2700 (epoch 48.019), train_loss = 1.46089504, grad/param norm = 1.8133e-01, time/batch = 0.3267s	
2594/2700 (epoch 48.037), train_loss = 1.40867939, grad/param norm = 1.7214e-01, time/batch = 0.3362s	
2595/2700 (epoch 48.056), train_loss = 1.36924595, grad/param norm = 1.8329e-01, time/batch = 0.3389s	
2596/2700 (epoch 48.074), train_loss = 1.36063763, grad/param norm = 1.9296e-01, time/batch = 0.3254s	
2597/2700 (epoch 48.093), train_loss = 1.33876168, grad/param norm = 2.0470e-01, time/batch = 0.3020s	
2598/2700 (epoch 48.111), train_loss = 1.30995620, grad/param norm = 1.7549e-01, time/batch = 0.2810s	
2599/2700 (epoch 48.130), train_loss = 1.35794392, grad/param norm = 2.0053e-01, time/batch = 0.2591s	
2600/2700 (epoch 48.148), train_loss = 1.33143954, grad/param norm = 1.7721e-01, time/batch = 0.2630s	
2601/2700 (epoch 48.167), train_loss = 1.42699287, grad/param norm = 1.8543e-01, time/batch = 0.2577s	
2602/2700 (epoch 48.185), train_loss = 1.33913579, grad/param norm = 1.8565e-01, time/batch = 0.2445s	
2603/2700 (epoch 48.204), train_loss = 1.38259717, grad/param norm = 1.9486e-01, time/batch = 0.2257s	
2604/2700 (epoch 48.222), train_loss = 1.34734039, grad/param norm = 1.9741e-01, time/batch = 0.3105s	
2605/2700 (epoch 48.241), train_loss = 1.28985147, grad/param norm = 1.9163e-01, time/batch = 0.3046s	
2606/2700 (epoch 48.259), train_loss = 1.34322589, grad/param norm = 1.8100e-01, time/batch = 0.2658s	
2607/2700 (epoch 48.278), train_loss = 1.36982114, grad/param norm = 1.7999e-01, time/batch = 0.2471s	
2608/2700 (epoch 48.296), train_loss = 1.36169139, grad/param norm = 1.8489e-01, time/batch = 0.2796s	
2609/2700 (epoch 48.315), train_loss = 1.37751090, grad/param norm = 1.7930e-01, time/batch = 0.3114s	
2610/2700 (epoch 48.333), train_loss = 1.36638310, grad/param norm = 1.7756e-01, time/batch = 0.3225s	
2611/2700 (epoch 48.352), train_loss = 1.34595460, grad/param norm = 1.7737e-01, time/batch = 0.2913s	
2612/2700 (epoch 48.370), train_loss = 1.33536467, grad/param norm = 2.0262e-01, time/batch = 0.3016s	
2613/2700 (epoch 48.389), train_loss = 1.31164513, grad/param norm = 1.7721e-01, time/batch = 0.3002s	
2614/2700 (epoch 48.407), train_loss = 1.40335582, grad/param norm = 1.8487e-01, time/batch = 0.2354s	
2615/2700 (epoch 48.426), train_loss = 1.43187139, grad/param norm = 1.7617e-01, time/batch = 0.3059s	
2616/2700 (epoch 48.444), train_loss = 1.34697031, grad/param norm = 1.7949e-01, time/batch = 0.2994s	
2617/2700 (epoch 48.463), train_loss = 1.40871076, grad/param norm = 1.7828e-01, time/batch = 0.2597s	
2618/2700 (epoch 48.481), train_loss = 1.39678354, grad/param norm = 1.7801e-01, time/batch = 0.2479s	
2619/2700 (epoch 48.500), train_loss = 1.31817585, grad/param norm = 1.8370e-01, time/batch = 0.2816s	
2620/2700 (epoch 48.519), train_loss = 1.38659825, grad/param norm = 1.8813e-01, time/batch = 0.3170s	
2621/2700 (epoch 48.537), train_loss = 1.38320963, grad/param norm = 1.9216e-01, time/batch = 0.2943s	
2622/2700 (epoch 48.556), train_loss = 1.32239205, grad/param norm = 1.7036e-01, time/batch = 0.3023s	
2623/2700 (epoch 48.574), train_loss = 1.32368808, grad/param norm = 1.7736e-01, time/batch = 0.3018s	
2624/2700 (epoch 48.593), train_loss = 1.36390510, grad/param norm = 1.7645e-01, time/batch = 0.2889s	
2625/2700 (epoch 48.611), train_loss = 1.29475326, grad/param norm = 1.7947e-01, time/batch = 0.2683s	
2626/2700 (epoch 48.630), train_loss = 1.29759751, grad/param norm = 1.7874e-01, time/batch = 0.2766s	
2627/2700 (epoch 48.648), train_loss = 1.32312759, grad/param norm = 1.7671e-01, time/batch = 0.2968s	
2628/2700 (epoch 48.667), train_loss = 1.31156820, grad/param norm = 1.7767e-01, time/batch = 0.2516s	
2629/2700 (epoch 48.685), train_loss = 1.37918166, grad/param norm = 1.8361e-01, time/batch = 0.2554s	
2630/2700 (epoch 48.704), train_loss = 1.35783159, grad/param norm = 1.9684e-01, time/batch = 0.3062s	
2631/2700 (epoch 48.722), train_loss = 1.35854828, grad/param norm = 1.7399e-01, time/batch = 0.2897s	
2632/2700 (epoch 48.741), train_loss = 1.31243195, grad/param norm = 1.9647e-01, time/batch = 0.3119s	
2633/2700 (epoch 48.759), train_loss = 1.32801425, grad/param norm = 1.9727e-01, time/batch = 0.3118s	
2634/2700 (epoch 48.778), train_loss = 1.38503819, grad/param norm = 1.7686e-01, time/batch = 0.2928s	
2635/2700 (epoch 48.796), train_loss = 1.30136719, grad/param norm = 2.1295e-01, time/batch = 0.2807s	
2636/2700 (epoch 48.815), train_loss = 1.36820630, grad/param norm = 1.7840e-01, time/batch = 0.2883s	
2637/2700 (epoch 48.833), train_loss = 1.34219179, grad/param norm = 1.9566e-01, time/batch = 0.2866s	
2638/2700 (epoch 48.852), train_loss = 1.30783862, grad/param norm = 1.8444e-01, time/batch = 0.2839s	
2639/2700 (epoch 48.870), train_loss = 1.36425947, grad/param norm = 1.9415e-01, time/batch = 0.2613s	
2640/2700 (epoch 48.889), train_loss = 1.35451541, grad/param norm = 1.9722e-01, time/batch = 0.2791s	
2641/2700 (epoch 48.907), train_loss = 1.44336710, grad/param norm = 2.2798e-01, time/batch = 0.2862s	
2642/2700 (epoch 48.926), train_loss = 1.38558719, grad/param norm = 1.9100e-01, time/batch = 0.3108s	
2643/2700 (epoch 48.944), train_loss = 1.35762047, grad/param norm = 2.2833e-01, time/batch = 0.3097s	
2644/2700 (epoch 48.963), train_loss = 1.39505253, grad/param norm = 1.8908e-01, time/batch = 0.2990s	
2645/2700 (epoch 48.981), train_loss = 1.33552643, grad/param norm = 1.9487e-01, time/batch = 0.2833s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
2646/2700 (epoch 49.000), train_loss = 1.39465221, grad/param norm = 1.9060e-01, time/batch = 0.2588s	
2647/2700 (epoch 49.019), train_loss = 1.45401286, grad/param norm = 1.9280e-01, time/batch = 0.2683s	
2648/2700 (epoch 49.037), train_loss = 1.40263798, grad/param norm = 1.7890e-01, time/batch = 0.2653s	
2649/2700 (epoch 49.056), train_loss = 1.36037003, grad/param norm = 1.8148e-01, time/batch = 0.3286s	
2650/2700 (epoch 49.074), train_loss = 1.35242925, grad/param norm = 1.8900e-01, time/batch = 0.3329s	
2651/2700 (epoch 49.093), train_loss = 1.32846228, grad/param norm = 1.9938e-01, time/batch = 0.2815s	
2652/2700 (epoch 49.111), train_loss = 1.30222893, grad/param norm = 1.8101e-01, time/batch = 0.2873s	
2653/2700 (epoch 49.130), train_loss = 1.35016829, grad/param norm = 1.9187e-01, time/batch = 0.3136s	
2654/2700 (epoch 49.148), train_loss = 1.32624956, grad/param norm = 1.7914e-01, time/batch = 0.3302s	
2655/2700 (epoch 49.167), train_loss = 1.41946701, grad/param norm = 1.8691e-01, time/batch = 0.3336s	
2656/2700 (epoch 49.185), train_loss = 1.33136825, grad/param norm = 1.8549e-01, time/batch = 0.3357s	
2657/2700 (epoch 49.204), train_loss = 1.37598520, grad/param norm = 1.9005e-01, time/batch = 0.3288s	
2658/2700 (epoch 49.222), train_loss = 1.33980980, grad/param norm = 1.9546e-01, time/batch = 0.3055s	
2659/2700 (epoch 49.241), train_loss = 1.28354675, grad/param norm = 1.8761e-01, time/batch = 0.2983s	
2660/2700 (epoch 49.259), train_loss = 1.33700189, grad/param norm = 1.8300e-01, time/batch = 0.2573s	
2661/2700 (epoch 49.278), train_loss = 1.36319606, grad/param norm = 1.7731e-01, time/batch = 0.2672s	
2662/2700 (epoch 49.296), train_loss = 1.35513337, grad/param norm = 1.8326e-01, time/batch = 0.2262s	
2663/2700 (epoch 49.315), train_loss = 1.36876961, grad/param norm = 1.7828e-01, time/batch = 0.2553s	
2664/2700 (epoch 49.333), train_loss = 1.36052003, grad/param norm = 1.7634e-01, time/batch = 0.2546s	
2665/2700 (epoch 49.352), train_loss = 1.33805143, grad/param norm = 1.7727e-01, time/batch = 0.3011s	
2666/2700 (epoch 49.370), train_loss = 1.32657225, grad/param norm = 2.0015e-01, time/batch = 0.3314s	
2667/2700 (epoch 49.389), train_loss = 1.30351885, grad/param norm = 1.7634e-01, time/batch = 0.3347s	
2668/2700 (epoch 49.407), train_loss = 1.39394830, grad/param norm = 1.8075e-01, time/batch = 0.3241s	
2669/2700 (epoch 49.426), train_loss = 1.42455624, grad/param norm = 1.7888e-01, time/batch = 0.3254s	
2670/2700 (epoch 49.444), train_loss = 1.33970290, grad/param norm = 1.8181e-01, time/batch = 0.3368s	
2671/2700 (epoch 49.463), train_loss = 1.40057570, grad/param norm = 1.7749e-01, time/batch = 0.3340s	
2672/2700 (epoch 49.481), train_loss = 1.39002090, grad/param norm = 1.8154e-01, time/batch = 0.3308s	
2673/2700 (epoch 49.500), train_loss = 1.31038891, grad/param norm = 1.8253e-01, time/batch = 0.3160s	
2674/2700 (epoch 49.519), train_loss = 1.37839358, grad/param norm = 1.7842e-01, time/batch = 0.2683s	
2675/2700 (epoch 49.537), train_loss = 1.37537607, grad/param norm = 1.9247e-01, time/batch = 0.3318s	
2676/2700 (epoch 49.556), train_loss = 1.31411433, grad/param norm = 1.6937e-01, time/batch = 0.3350s	
2677/2700 (epoch 49.574), train_loss = 1.31527531, grad/param norm = 1.7643e-01, time/batch = 0.3356s	
2678/2700 (epoch 49.593), train_loss = 1.35735835, grad/param norm = 1.7677e-01, time/batch = 0.3289s	
2679/2700 (epoch 49.611), train_loss = 1.28849387, grad/param norm = 1.7831e-01, time/batch = 0.3043s	
2680/2700 (epoch 49.630), train_loss = 1.29059010, grad/param norm = 1.7811e-01, time/batch = 0.2741s	
2681/2700 (epoch 49.648), train_loss = 1.31526550, grad/param norm = 1.6877e-01, time/batch = 0.3037s	
2682/2700 (epoch 49.667), train_loss = 1.30462631, grad/param norm = 1.8157e-01, time/batch = 0.2798s	
2683/2700 (epoch 49.685), train_loss = 1.37143990, grad/param norm = 1.7688e-01, time/batch = 0.2827s	
2684/2700 (epoch 49.704), train_loss = 1.34770980, grad/param norm = 1.8147e-01, time/batch = 0.2613s	
2685/2700 (epoch 49.722), train_loss = 1.35223754, grad/param norm = 1.7866e-01, time/batch = 0.2726s	
2686/2700 (epoch 49.741), train_loss = 1.30225616, grad/param norm = 1.7850e-01, time/batch = 0.2510s	
2687/2700 (epoch 49.759), train_loss = 1.31966111, grad/param norm = 1.9421e-01, time/batch = 0.3068s	
2688/2700 (epoch 49.778), train_loss = 1.37741641, grad/param norm = 1.8744e-01, time/batch = 0.3285s	
2689/2700 (epoch 49.796), train_loss = 1.29464982, grad/param norm = 2.1082e-01, time/batch = 0.3257s	
2690/2700 (epoch 49.815), train_loss = 1.35970967, grad/param norm = 1.7887e-01, time/batch = 0.3278s	
2691/2700 (epoch 49.833), train_loss = 1.33872830, grad/param norm = 2.3391e-01, time/batch = 0.3340s	
2692/2700 (epoch 49.852), train_loss = 1.30106471, grad/param norm = 1.9980e-01, time/batch = 0.3354s	
2693/2700 (epoch 49.870), train_loss = 1.35355713, grad/param norm = 1.7284e-01, time/batch = 0.3328s	
2694/2700 (epoch 49.889), train_loss = 1.34856988, grad/param norm = 1.9981e-01, time/batch = 0.3285s	
2695/2700 (epoch 49.907), train_loss = 1.43699219, grad/param norm = 2.2675e-01, time/batch = 0.3059s	
2696/2700 (epoch 49.926), train_loss = 1.37884416, grad/param norm = 1.9642e-01, time/batch = 0.2833s	
2697/2700 (epoch 49.944), train_loss = 1.34716906, grad/param norm = 2.1994e-01, time/batch = 0.2899s	
2698/2700 (epoch 49.963), train_loss = 1.38558775, grad/param norm = 1.8524e-01, time/batch = 0.3352s	
2699/2700 (epoch 49.981), train_loss = 1.32831877, grad/param norm = 1.9604e-01, time/batch = 0.3338s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch50.00_1.7950.t7	
2700/2700 (epoch 50.000), train_loss = 1.38705546, grad/param norm = 1.9705e-01, time/batch = 0.3087s	
