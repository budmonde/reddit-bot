using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 54, val: 3, test: 0	
vocab size: 91	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 907099	
cloning rnn	
cloning criterion	
1/2700 (epoch 0.019), train_loss = 4.49180795, grad/param norm = 6.3528e-01, time/batch = 0.8007s	
2/2700 (epoch 0.037), train_loss = 3.54513751, grad/param norm = 1.0335e+00, time/batch = 0.2864s	
3/2700 (epoch 0.056), train_loss = 3.52716830, grad/param norm = 1.3976e+00, time/batch = 0.2846s	
4/2700 (epoch 0.074), train_loss = 3.34883969, grad/param norm = 9.1045e-01, time/batch = 0.2987s	
5/2700 (epoch 0.093), train_loss = 3.32652397, grad/param norm = 6.5552e-01, time/batch = 0.3028s	
6/2700 (epoch 0.111), train_loss = 3.27784218, grad/param norm = 4.3065e-01, time/batch = 0.2483s	
7/2700 (epoch 0.130), train_loss = 3.30007207, grad/param norm = 3.7082e-01, time/batch = 0.3176s	
8/2700 (epoch 0.148), train_loss = 3.25247221, grad/param norm = 3.7579e-01, time/batch = 0.3046s	
9/2700 (epoch 0.167), train_loss = 3.26547473, grad/param norm = 4.5860e-01, time/batch = 0.2567s	
10/2700 (epoch 0.185), train_loss = 3.24684119, grad/param norm = 3.1940e-01, time/batch = 0.3274s	
11/2700 (epoch 0.204), train_loss = 3.18686940, grad/param norm = 3.7049e-01, time/batch = 0.3218s	
12/2700 (epoch 0.222), train_loss = 3.15822835, grad/param norm = 4.2196e-01, time/batch = 0.3240s	
13/2700 (epoch 0.241), train_loss = 3.17568582, grad/param norm = 3.0857e-01, time/batch = 0.2882s	
14/2700 (epoch 0.259), train_loss = 3.20804028, grad/param norm = 2.8483e-01, time/batch = 0.3197s	
15/2700 (epoch 0.278), train_loss = 3.28191408, grad/param norm = 3.8197e-01, time/batch = 0.3147s	
16/2700 (epoch 0.296), train_loss = 3.28390411, grad/param norm = 3.7731e-01, time/batch = 0.3023s	
17/2700 (epoch 0.315), train_loss = 3.26139542, grad/param norm = 3.4810e-01, time/batch = 0.3211s	
18/2700 (epoch 0.333), train_loss = 3.33953316, grad/param norm = 3.0721e-01, time/batch = 0.3174s	
19/2700 (epoch 0.352), train_loss = 3.34375096, grad/param norm = 3.3803e-01, time/batch = 0.3021s	
20/2700 (epoch 0.370), train_loss = 3.29114629, grad/param norm = 3.7239e-01, time/batch = 0.2518s	
21/2700 (epoch 0.389), train_loss = 3.25569707, grad/param norm = 2.9866e-01, time/batch = 0.3232s	
22/2700 (epoch 0.407), train_loss = 3.27665363, grad/param norm = 2.5838e-01, time/batch = 0.3083s	
23/2700 (epoch 0.426), train_loss = 3.28009899, grad/param norm = 2.7309e-01, time/batch = 0.3183s	
24/2700 (epoch 0.444), train_loss = 3.21062446, grad/param norm = 3.1000e-01, time/batch = 0.3238s	
25/2700 (epoch 0.463), train_loss = 3.25360004, grad/param norm = 4.4164e-01, time/batch = 0.3191s	
26/2700 (epoch 0.481), train_loss = 3.33470523, grad/param norm = 5.2588e-01, time/batch = 0.3005s	
27/2700 (epoch 0.500), train_loss = 3.37905074, grad/param norm = 5.9597e-01, time/batch = 0.3220s	
28/2700 (epoch 0.519), train_loss = 3.33201647, grad/param norm = 5.2214e-01, time/batch = 0.3229s	
29/2700 (epoch 0.537), train_loss = 3.33066297, grad/param norm = 4.4870e-01, time/batch = 0.3199s	
30/2700 (epoch 0.556), train_loss = 3.26585605, grad/param norm = 3.3419e-01, time/batch = 0.3041s	
31/2700 (epoch 0.574), train_loss = 3.23227681, grad/param norm = 3.1881e-01, time/batch = 0.2477s	
32/2700 (epoch 0.593), train_loss = 3.23517942, grad/param norm = 4.1111e-01, time/batch = 0.3078s	
33/2700 (epoch 0.611), train_loss = 3.17356369, grad/param norm = 3.0287e-01, time/batch = 0.3207s	
34/2700 (epoch 0.630), train_loss = 3.21355618, grad/param norm = 3.0873e-01, time/batch = 0.3237s	
35/2700 (epoch 0.648), train_loss = 3.28491659, grad/param norm = 3.4051e-01, time/batch = 0.3220s	
36/2700 (epoch 0.667), train_loss = 3.21570753, grad/param norm = 2.8994e-01, time/batch = 0.3009s	
37/2700 (epoch 0.685), train_loss = 3.21220409, grad/param norm = 2.8001e-01, time/batch = 0.3231s	
38/2700 (epoch 0.704), train_loss = 3.18434311, grad/param norm = 3.5896e-01, time/batch = 0.3282s	
39/2700 (epoch 0.722), train_loss = 3.17411405, grad/param norm = 2.7215e-01, time/batch = 0.3245s	
40/2700 (epoch 0.741), train_loss = 3.30894580, grad/param norm = 3.7767e-01, time/batch = 0.3157s	
41/2700 (epoch 0.759), train_loss = 3.25884793, grad/param norm = 4.3693e-01, time/batch = 0.3178s	
42/2700 (epoch 0.778), train_loss = 3.25068208, grad/param norm = 3.9765e-01, time/batch = 0.3004s	
43/2700 (epoch 0.796), train_loss = 3.24270256, grad/param norm = 3.7837e-01, time/batch = 0.3030s	
44/2700 (epoch 0.815), train_loss = 3.19395717, grad/param norm = 2.8932e-01, time/batch = 0.2899s	
45/2700 (epoch 0.833), train_loss = 3.23072148, grad/param norm = 2.7217e-01, time/batch = 0.2940s	
46/2700 (epoch 0.852), train_loss = 3.21853971, grad/param norm = 2.8023e-01, time/batch = 0.2884s	
47/2700 (epoch 0.870), train_loss = 3.21199221, grad/param norm = 2.2416e-01, time/batch = 0.3094s	
48/2700 (epoch 0.889), train_loss = 3.24845356, grad/param norm = 2.6598e-01, time/batch = 0.3237s	
49/2700 (epoch 0.907), train_loss = 3.30167723, grad/param norm = 3.7736e-01, time/batch = 0.3167s	
50/2700 (epoch 0.926), train_loss = 3.25496956, grad/param norm = 4.4196e-01, time/batch = 0.3217s	
51/2700 (epoch 0.944), train_loss = 3.26898400, grad/param norm = 5.4533e-01, time/batch = 0.3280s	
52/2700 (epoch 0.963), train_loss = 3.34574144, grad/param norm = 5.3337e-01, time/batch = 0.3102s	
53/2700 (epoch 0.981), train_loss = 3.39822867, grad/param norm = 3.9304e-01, time/batch = 0.3050s	
54/2700 (epoch 1.000), train_loss = 3.30686402, grad/param norm = 4.7330e-01, time/batch = 0.2927s	
55/2700 (epoch 1.019), train_loss = 3.23910855, grad/param norm = 5.5448e-01, time/batch = 0.2868s	
56/2700 (epoch 1.037), train_loss = 3.25738670, grad/param norm = 4.6910e-01, time/batch = 0.2819s	
57/2700 (epoch 1.056), train_loss = 3.25358227, grad/param norm = 2.4346e-01, time/batch = 0.3072s	
58/2700 (epoch 1.074), train_loss = 3.28325753, grad/param norm = 2.5497e-01, time/batch = 0.3063s	
59/2700 (epoch 1.093), train_loss = 3.28829973, grad/param norm = 3.1041e-01, time/batch = 0.3167s	
60/2700 (epoch 1.111), train_loss = 3.26005875, grad/param norm = 2.9331e-01, time/batch = 0.3223s	
61/2700 (epoch 1.130), train_loss = 3.27320282, grad/param norm = 2.6225e-01, time/batch = 0.3256s	
62/2700 (epoch 1.148), train_loss = 3.23798127, grad/param norm = 3.3247e-01, time/batch = 0.3208s	
63/2700 (epoch 1.167), train_loss = 3.24978689, grad/param norm = 4.3811e-01, time/batch = 0.3116s	
64/2700 (epoch 1.185), train_loss = 3.23639097, grad/param norm = 4.3710e-01, time/batch = 0.2869s	
65/2700 (epoch 1.204), train_loss = 3.18754571, grad/param norm = 6.2695e-01, time/batch = 0.2895s	
66/2700 (epoch 1.222), train_loss = 3.16017334, grad/param norm = 8.3467e-01, time/batch = 0.2812s	
67/2700 (epoch 1.241), train_loss = 3.18028339, grad/param norm = 6.8918e-01, time/batch = 0.3028s	
68/2700 (epoch 1.259), train_loss = 3.19383730, grad/param norm = 3.4988e-01, time/batch = 0.3120s	
69/2700 (epoch 1.278), train_loss = 3.26061662, grad/param norm = 2.8973e-01, time/batch = 0.3168s	
70/2700 (epoch 1.296), train_loss = 3.26013457, grad/param norm = 2.7377e-01, time/batch = 0.3199s	
71/2700 (epoch 1.315), train_loss = 3.23782444, grad/param norm = 2.8187e-01, time/batch = 0.3284s	
72/2700 (epoch 1.333), train_loss = 3.31612144, grad/param norm = 3.0648e-01, time/batch = 0.3259s	
73/2700 (epoch 1.352), train_loss = 3.32453317, grad/param norm = 4.1102e-01, time/batch = 0.3244s	
74/2700 (epoch 1.370), train_loss = 3.26632738, grad/param norm = 4.2729e-01, time/batch = 0.3218s	
75/2700 (epoch 1.389), train_loss = 3.23043091, grad/param norm = 3.6156e-01, time/batch = 0.2891s	
76/2700 (epoch 1.407), train_loss = 3.24863616, grad/param norm = 3.5094e-01, time/batch = 0.2821s	
77/2700 (epoch 1.426), train_loss = 3.25276133, grad/param norm = 4.3461e-01, time/batch = 0.2689s	
78/2700 (epoch 1.444), train_loss = 3.18178220, grad/param norm = 5.2177e-01, time/batch = 0.3078s	
79/2700 (epoch 1.463), train_loss = 3.23638859, grad/param norm = 6.1614e-01, time/batch = 0.3085s	
80/2700 (epoch 1.481), train_loss = 3.29804802, grad/param norm = 5.1966e-01, time/batch = 0.3145s	
81/2700 (epoch 1.500), train_loss = 3.32751827, grad/param norm = 4.3626e-01, time/batch = 0.3102s	
82/2700 (epoch 1.519), train_loss = 3.26020330, grad/param norm = 2.1946e-01, time/batch = 0.3229s	
83/2700 (epoch 1.537), train_loss = 3.25548386, grad/param norm = 2.4503e-01, time/batch = 0.3289s	
84/2700 (epoch 1.556), train_loss = 3.18892313, grad/param norm = 2.2248e-01, time/batch = 0.3248s	
85/2700 (epoch 1.574), train_loss = 3.15048714, grad/param norm = 3.4966e-01, time/batch = 0.3201s	
86/2700 (epoch 1.593), train_loss = 3.15865416, grad/param norm = 5.8076e-01, time/batch = 0.2500s	
87/2700 (epoch 1.611), train_loss = 3.13302212, grad/param norm = 6.6792e-01, time/batch = 0.2885s	
88/2700 (epoch 1.630), train_loss = 3.18692235, grad/param norm = 8.4181e-01, time/batch = 0.2982s	
89/2700 (epoch 1.648), train_loss = 3.21452205, grad/param norm = 6.4010e-01, time/batch = 0.3083s	
90/2700 (epoch 1.667), train_loss = 3.09020300, grad/param norm = 2.8979e-01, time/batch = 0.3046s	
91/2700 (epoch 1.685), train_loss = 3.07477055, grad/param norm = 3.5831e-01, time/batch = 0.3080s	
92/2700 (epoch 1.704), train_loss = 3.04577925, grad/param norm = 6.0520e-01, time/batch = 0.3185s	
93/2700 (epoch 1.722), train_loss = 3.22023506, grad/param norm = 1.2605e+00, time/batch = 0.3217s	
94/2700 (epoch 1.741), train_loss = 3.27641266, grad/param norm = 7.8059e-01, time/batch = 0.3210s	
95/2700 (epoch 1.759), train_loss = 3.10557571, grad/param norm = 2.9507e-01, time/batch = 0.3186s	
96/2700 (epoch 1.778), train_loss = 3.07616402, grad/param norm = 1.6842e-01, time/batch = 0.3062s	
97/2700 (epoch 1.796), train_loss = 3.06596061, grad/param norm = 1.8775e-01, time/batch = 0.2375s	
98/2700 (epoch 1.815), train_loss = 2.99091413, grad/param norm = 1.4386e-01, time/batch = 0.3183s	
99/2700 (epoch 1.833), train_loss = 2.99945260, grad/param norm = 1.8665e-01, time/batch = 0.3198s	
100/2700 (epoch 1.852), train_loss = 3.00694211, grad/param norm = 3.0145e-01, time/batch = 0.3179s	
101/2700 (epoch 1.870), train_loss = 3.02564638, grad/param norm = 7.4913e-01, time/batch = 0.3199s	
102/2700 (epoch 1.889), train_loss = 3.21093069, grad/param norm = 9.2855e-01, time/batch = 0.3205s	
103/2700 (epoch 1.907), train_loss = 3.10872418, grad/param norm = 3.7651e-01, time/batch = 0.3168s	
104/2700 (epoch 1.926), train_loss = 3.01904275, grad/param norm = 2.9845e-01, time/batch = 0.3159s	
105/2700 (epoch 1.944), train_loss = 3.02851786, grad/param norm = 2.5481e-01, time/batch = 0.2778s	
106/2700 (epoch 1.963), train_loss = 3.07837921, grad/param norm = 2.5057e-01, time/batch = 0.2984s	
107/2700 (epoch 1.981), train_loss = 3.11420545, grad/param norm = 3.4846e-01, time/batch = 0.2940s	
108/2700 (epoch 2.000), train_loss = 3.08419137, grad/param norm = 6.3224e-01, time/batch = 0.2502s	
109/2700 (epoch 2.019), train_loss = 3.00932382, grad/param norm = 9.1855e-01, time/batch = 0.3079s	
110/2700 (epoch 2.037), train_loss = 3.02117952, grad/param norm = 5.7804e-01, time/batch = 0.3180s	
111/2700 (epoch 2.056), train_loss = 2.94236857, grad/param norm = 3.2271e-01, time/batch = 0.3325s	
112/2700 (epoch 2.074), train_loss = 3.02585641, grad/param norm = 6.0685e-01, time/batch = 0.3284s	
113/2700 (epoch 2.093), train_loss = 3.21467579, grad/param norm = 8.8567e-01, time/batch = 0.3247s	
114/2700 (epoch 2.111), train_loss = 3.01626913, grad/param norm = 5.3283e-01, time/batch = 0.3113s	
115/2700 (epoch 2.130), train_loss = 2.97593172, grad/param norm = 2.9766e-01, time/batch = 0.3081s	
116/2700 (epoch 2.148), train_loss = 2.89645970, grad/param norm = 3.3786e-01, time/batch = 0.2730s	
117/2700 (epoch 2.167), train_loss = 2.92597449, grad/param norm = 5.0333e-01, time/batch = 0.2877s	
118/2700 (epoch 2.185), train_loss = 2.88840090, grad/param norm = 3.5645e-01, time/batch = 0.2945s	
119/2700 (epoch 2.204), train_loss = 2.80091634, grad/param norm = 3.1463e-01, time/batch = 0.2832s	
120/2700 (epoch 2.222), train_loss = 2.74308468, grad/param norm = 4.0951e-01, time/batch = 0.3134s	
121/2700 (epoch 2.241), train_loss = 2.79274606, grad/param norm = 5.6040e-01, time/batch = 0.3148s	
122/2700 (epoch 2.259), train_loss = 2.87853305, grad/param norm = 9.9677e-01, time/batch = 0.3214s	
123/2700 (epoch 2.278), train_loss = 2.97869573, grad/param norm = 7.0670e-01, time/batch = 0.3189s	
124/2700 (epoch 2.296), train_loss = 2.86011860, grad/param norm = 2.5668e-01, time/batch = 0.3083s	
125/2700 (epoch 2.315), train_loss = 2.85362474, grad/param norm = 2.3742e-01, time/batch = 0.2965s	
126/2700 (epoch 2.333), train_loss = 2.89581964, grad/param norm = 3.8528e-01, time/batch = 0.2907s	
127/2700 (epoch 2.352), train_loss = 3.17966411, grad/param norm = 2.0341e+00, time/batch = 0.2791s	
128/2700 (epoch 2.370), train_loss = 2.97821280, grad/param norm = 5.8993e-01, time/batch = 0.2929s	
129/2700 (epoch 2.389), train_loss = 2.86959852, grad/param norm = 4.5738e-01, time/batch = 0.3022s	
130/2700 (epoch 2.407), train_loss = 2.83183455, grad/param norm = 3.3107e-01, time/batch = 0.2946s	
131/2700 (epoch 2.426), train_loss = 2.85519745, grad/param norm = 2.5258e-01, time/batch = 0.3212s	
132/2700 (epoch 2.444), train_loss = 2.73628229, grad/param norm = 2.3505e-01, time/batch = 0.3179s	
133/2700 (epoch 2.463), train_loss = 2.80199376, grad/param norm = 2.5321e-01, time/batch = 0.2868s	
134/2700 (epoch 2.481), train_loss = 2.86237132, grad/param norm = 2.9042e-01, time/batch = 0.3139s	
135/2700 (epoch 2.500), train_loss = 2.90745066, grad/param norm = 3.8190e-01, time/batch = 0.3133s	
136/2700 (epoch 2.519), train_loss = 2.87247441, grad/param norm = 5.5079e-01, time/batch = 0.2954s	
137/2700 (epoch 2.537), train_loss = 2.90997291, grad/param norm = 7.5104e-01, time/batch = 0.2889s	
138/2700 (epoch 2.556), train_loss = 2.86870951, grad/param norm = 5.6762e-01, time/batch = 0.2846s	
139/2700 (epoch 2.574), train_loss = 2.76220223, grad/param norm = 3.4789e-01, time/batch = 0.2883s	
140/2700 (epoch 2.593), train_loss = 2.73119781, grad/param norm = 3.1664e-01, time/batch = 0.3007s	
141/2700 (epoch 2.611), train_loss = 2.65874436, grad/param norm = 3.2241e-01, time/batch = 0.2794s	
142/2700 (epoch 2.630), train_loss = 2.70437715, grad/param norm = 3.4553e-01, time/batch = 0.3188s	
143/2700 (epoch 2.648), train_loss = 2.74215534, grad/param norm = 3.6250e-01, time/batch = 0.3192s	
144/2700 (epoch 2.667), train_loss = 2.68234439, grad/param norm = 4.0154e-01, time/batch = 0.3042s	
145/2700 (epoch 2.685), train_loss = 2.71559679, grad/param norm = 4.5313e-01, time/batch = 0.2977s	
146/2700 (epoch 2.704), train_loss = 2.67809846, grad/param norm = 4.8510e-01, time/batch = 0.2951s	
147/2700 (epoch 2.722), train_loss = 2.65229947, grad/param norm = 3.9145e-01, time/batch = 0.2586s	
148/2700 (epoch 2.741), train_loss = 2.83521698, grad/param norm = 3.8439e-01, time/batch = 0.3016s	
149/2700 (epoch 2.759), train_loss = 2.74799265, grad/param norm = 3.1177e-01, time/batch = 0.3006s	
150/2700 (epoch 2.778), train_loss = 2.71905722, grad/param norm = 3.0706e-01, time/batch = 0.3066s	
151/2700 (epoch 2.796), train_loss = 2.72053519, grad/param norm = 4.4215e-01, time/batch = 0.3131s	
152/2700 (epoch 2.815), train_loss = 2.72442186, grad/param norm = 4.8817e-01, time/batch = 0.2816s	
153/2700 (epoch 2.833), train_loss = 2.71103162, grad/param norm = 4.4566e-01, time/batch = 0.3093s	
154/2700 (epoch 2.852), train_loss = 2.74253110, grad/param norm = 4.9792e-01, time/batch = 0.2944s	
155/2700 (epoch 2.870), train_loss = 2.74072669, grad/param norm = 5.2576e-01, time/batch = 0.2945s	
156/2700 (epoch 2.889), train_loss = 2.73281559, grad/param norm = 5.3334e-01, time/batch = 0.2857s	
157/2700 (epoch 2.907), train_loss = 2.83022185, grad/param norm = 5.3591e-01, time/batch = 0.2616s	
158/2700 (epoch 2.926), train_loss = 2.72997956, grad/param norm = 4.7745e-01, time/batch = 0.3105s	
159/2700 (epoch 2.944), train_loss = 2.75340633, grad/param norm = 4.1951e-01, time/batch = 0.3123s	
160/2700 (epoch 2.963), train_loss = 2.80081218, grad/param norm = 2.9421e-01, time/batch = 0.3020s	
161/2700 (epoch 2.981), train_loss = 2.80934250, grad/param norm = 2.7093e-01, time/batch = 0.3074s	
162/2700 (epoch 3.000), train_loss = 2.77850356, grad/param norm = 5.1186e-01, time/batch = 0.3145s	
163/2700 (epoch 3.019), train_loss = 2.71072484, grad/param norm = 3.8060e-01, time/batch = 0.3146s	
164/2700 (epoch 3.037), train_loss = 2.73134917, grad/param norm = 3.4759e-01, time/batch = 0.2805s	
165/2700 (epoch 3.056), train_loss = 2.69379272, grad/param norm = 4.2284e-01, time/batch = 0.2916s	
166/2700 (epoch 3.074), train_loss = 2.73209540, grad/param norm = 4.8762e-01, time/batch = 0.2935s	
167/2700 (epoch 3.093), train_loss = 2.72921885, grad/param norm = 4.3372e-01, time/batch = 0.2574s	
168/2700 (epoch 3.111), train_loss = 2.68201205, grad/param norm = 3.1267e-01, time/batch = 0.3239s	
169/2700 (epoch 3.130), train_loss = 2.68360163, grad/param norm = 2.7749e-01, time/batch = 0.3261s	
170/2700 (epoch 3.148), train_loss = 2.61952893, grad/param norm = 3.1311e-01, time/batch = 0.3184s	
171/2700 (epoch 3.167), train_loss = 2.65814376, grad/param norm = 4.0589e-01, time/batch = 0.2726s	
172/2700 (epoch 3.185), train_loss = 2.64928098, grad/param norm = 4.2247e-01, time/batch = 0.3052s	
173/2700 (epoch 3.204), train_loss = 2.59530426, grad/param norm = 3.9768e-01, time/batch = 0.2940s	
174/2700 (epoch 3.222), train_loss = 2.54333600, grad/param norm = 3.7228e-01, time/batch = 0.2867s	
175/2700 (epoch 3.241), train_loss = 2.54491737, grad/param norm = 2.7631e-01, time/batch = 0.2362s	
176/2700 (epoch 3.259), train_loss = 2.55498844, grad/param norm = 3.1952e-01, time/batch = 0.3021s	
177/2700 (epoch 3.278), train_loss = 2.64794235, grad/param norm = 3.9328e-01, time/batch = 0.2590s	
178/2700 (epoch 3.296), train_loss = 2.65622211, grad/param norm = 5.5926e-01, time/batch = 0.2942s	
179/2700 (epoch 3.315), train_loss = 2.73682683, grad/param norm = 6.5187e-01, time/batch = 0.2942s	
180/2700 (epoch 3.333), train_loss = 2.66811319, grad/param norm = 3.6509e-01, time/batch = 0.2995s	
181/2700 (epoch 3.352), train_loss = 2.73240868, grad/param norm = 7.7563e-01, time/batch = 0.3052s	
182/2700 (epoch 3.370), train_loss = 2.80808388, grad/param norm = 6.5601e-01, time/batch = 0.3263s	
183/2700 (epoch 3.389), train_loss = 2.66798339, grad/param norm = 4.2728e-01, time/batch = 0.3262s	
184/2700 (epoch 3.407), train_loss = 2.61709807, grad/param norm = 2.5227e-01, time/batch = 0.3262s	
185/2700 (epoch 3.426), train_loss = 2.64307614, grad/param norm = 2.6452e-01, time/batch = 0.3176s	
186/2700 (epoch 3.444), train_loss = 2.53427955, grad/param norm = 2.6117e-01, time/batch = 0.3055s	
187/2700 (epoch 3.463), train_loss = 2.61283903, grad/param norm = 2.9450e-01, time/batch = 0.2588s	
188/2700 (epoch 3.481), train_loss = 2.66345062, grad/param norm = 3.1968e-01, time/batch = 0.2978s	
189/2700 (epoch 3.500), train_loss = 2.69298863, grad/param norm = 7.5143e-01, time/batch = 0.3016s	
190/2700 (epoch 3.519), train_loss = 2.77625171, grad/param norm = 6.4334e-01, time/batch = 0.3125s	
191/2700 (epoch 3.537), train_loss = 2.67509280, grad/param norm = 4.5529e-01, time/batch = 0.3149s	
192/2700 (epoch 3.556), train_loss = 2.65297241, grad/param norm = 4.2781e-01, time/batch = 0.3268s	
193/2700 (epoch 3.574), train_loss = 2.57101325, grad/param norm = 3.9784e-01, time/batch = 0.3287s	
194/2700 (epoch 3.593), train_loss = 2.53030567, grad/param norm = 2.9216e-01, time/batch = 0.3216s	
195/2700 (epoch 3.611), train_loss = 2.45948353, grad/param norm = 2.2551e-01, time/batch = 0.3254s	
196/2700 (epoch 3.630), train_loss = 2.50511563, grad/param norm = 2.4556e-01, time/batch = 0.3206s	
197/2700 (epoch 3.648), train_loss = 2.54462341, grad/param norm = 2.9314e-01, time/batch = 0.3078s	
198/2700 (epoch 3.667), train_loss = 2.47833449, grad/param norm = 3.5367e-01, time/batch = 0.2512s	
199/2700 (epoch 3.685), train_loss = 2.55462062, grad/param norm = 4.1424e-01, time/batch = 0.3044s	
200/2700 (epoch 3.704), train_loss = 2.53232987, grad/param norm = 4.1960e-01, time/batch = 0.3156s	
201/2700 (epoch 3.722), train_loss = 2.50840366, grad/param norm = 3.1657e-01, time/batch = 0.3033s	
202/2700 (epoch 3.741), train_loss = 2.65282501, grad/param norm = 2.4487e-01, time/batch = 0.3090s	
203/2700 (epoch 3.759), train_loss = 2.56817282, grad/param norm = 2.9166e-01, time/batch = 0.3152s	
204/2700 (epoch 3.778), train_loss = 2.56689705, grad/param norm = 3.1030e-01, time/batch = 0.3193s	
205/2700 (epoch 3.796), train_loss = 2.51850365, grad/param norm = 2.8084e-01, time/batch = 0.3213s	
206/2700 (epoch 3.815), train_loss = 2.50254176, grad/param norm = 2.8475e-01, time/batch = 0.3222s	
207/2700 (epoch 3.833), train_loss = 2.48781571, grad/param norm = 3.7816e-01, time/batch = 0.3039s	
208/2700 (epoch 3.852), train_loss = 2.55421466, grad/param norm = 4.9545e-01, time/batch = 0.2778s	
209/2700 (epoch 3.870), train_loss = 2.52825808, grad/param norm = 6.0766e-01, time/batch = 0.2337s	
210/2700 (epoch 3.889), train_loss = 2.56802722, grad/param norm = 5.3965e-01, time/batch = 0.3056s	
211/2700 (epoch 3.907), train_loss = 2.65092501, grad/param norm = 3.9303e-01, time/batch = 0.3284s	
212/2700 (epoch 3.926), train_loss = 2.56403227, grad/param norm = 3.6292e-01, time/batch = 0.3231s	
213/2700 (epoch 3.944), train_loss = 2.57040646, grad/param norm = 3.2074e-01, time/batch = 0.3244s	
214/2700 (epoch 3.963), train_loss = 2.61539060, grad/param norm = 3.5314e-01, time/batch = 0.3204s	
215/2700 (epoch 3.981), train_loss = 2.66857624, grad/param norm = 5.2674e-01, time/batch = 0.3136s	
216/2700 (epoch 4.000), train_loss = 2.73429908, grad/param norm = 1.5913e+00, time/batch = 0.3125s	
217/2700 (epoch 4.019), train_loss = 2.67180232, grad/param norm = 5.4052e-01, time/batch = 0.3048s	
218/2700 (epoch 4.037), train_loss = 2.67210133, grad/param norm = 4.7700e-01, time/batch = 0.2619s	
219/2700 (epoch 4.056), train_loss = 2.59574685, grad/param norm = 3.7643e-01, time/batch = 0.2983s	
220/2700 (epoch 4.074), train_loss = 2.57174037, grad/param norm = 2.7230e-01, time/batch = 0.2450s	
221/2700 (epoch 4.093), train_loss = 2.55688667, grad/param norm = 2.1742e-01, time/batch = 0.3126s	
222/2700 (epoch 4.111), train_loss = 2.51759470, grad/param norm = 2.0814e-01, time/batch = 0.3205s	
223/2700 (epoch 4.130), train_loss = 2.52436368, grad/param norm = 2.0822e-01, time/batch = 0.3190s	
224/2700 (epoch 4.148), train_loss = 2.46215298, grad/param norm = 2.0344e-01, time/batch = 0.3197s	
225/2700 (epoch 4.167), train_loss = 2.49417489, grad/param norm = 2.0037e-01, time/batch = 0.3201s	
226/2700 (epoch 4.185), train_loss = 2.45361873, grad/param norm = 1.9736e-01, time/batch = 0.3213s	
227/2700 (epoch 4.204), train_loss = 2.42791682, grad/param norm = 2.7116e-01, time/batch = 0.2970s	
228/2700 (epoch 4.222), train_loss = 2.39175103, grad/param norm = 3.9030e-01, time/batch = 0.2972s	
229/2700 (epoch 4.241), train_loss = 2.42035293, grad/param norm = 4.9214e-01, time/batch = 0.2942s	
230/2700 (epoch 4.259), train_loss = 2.43945639, grad/param norm = 5.0351e-01, time/batch = 0.2915s	
231/2700 (epoch 4.278), train_loss = 2.53119700, grad/param norm = 4.2990e-01, time/batch = 0.2546s	
232/2700 (epoch 4.296), train_loss = 2.49772419, grad/param norm = 3.7336e-01, time/batch = 0.3272s	
233/2700 (epoch 4.315), train_loss = 2.49970216, grad/param norm = 2.5792e-01, time/batch = 0.3240s	
234/2700 (epoch 4.333), train_loss = 2.49291888, grad/param norm = 2.6793e-01, time/batch = 0.3271s	
235/2700 (epoch 4.352), train_loss = 2.53779820, grad/param norm = 2.5844e-01, time/batch = 0.3211s	
236/2700 (epoch 4.370), train_loss = 2.47780115, grad/param norm = 2.4266e-01, time/batch = 0.3152s	
237/2700 (epoch 4.389), train_loss = 2.45705546, grad/param norm = 2.5900e-01, time/batch = 0.2995s	
238/2700 (epoch 4.407), train_loss = 2.45625860, grad/param norm = 2.9810e-01, time/batch = 0.3114s	
239/2700 (epoch 4.426), train_loss = 2.51455484, grad/param norm = 3.7480e-01, time/batch = 0.2971s	
240/2700 (epoch 4.444), train_loss = 2.39347410, grad/param norm = 2.9726e-01, time/batch = 0.2937s	
241/2700 (epoch 4.463), train_loss = 2.45143049, grad/param norm = 2.1778e-01, time/batch = 0.3091s	
242/2700 (epoch 4.481), train_loss = 2.49099223, grad/param norm = 2.2513e-01, time/batch = 0.2337s	
243/2700 (epoch 4.500), train_loss = 2.49168914, grad/param norm = 2.4556e-01, time/batch = 0.3197s	
244/2700 (epoch 4.519), train_loss = 2.45955214, grad/param norm = 2.9856e-01, time/batch = 0.3110s	
245/2700 (epoch 4.537), train_loss = 2.49212890, grad/param norm = 5.9876e-01, time/batch = 0.3139s	
246/2700 (epoch 4.556), train_loss = 2.54417986, grad/param norm = 4.1252e-01, time/batch = 0.3173s	
247/2700 (epoch 4.574), train_loss = 2.43763403, grad/param norm = 3.4119e-01, time/batch = 0.2968s	
248/2700 (epoch 4.593), train_loss = 2.41496890, grad/param norm = 3.8316e-01, time/batch = 0.2663s	
249/2700 (epoch 4.611), train_loss = 2.35169896, grad/param norm = 4.4704e-01, time/batch = 0.2817s	
250/2700 (epoch 4.630), train_loss = 2.40715773, grad/param norm = 4.7347e-01, time/batch = 0.2872s	
251/2700 (epoch 4.648), train_loss = 2.46771307, grad/param norm = 4.6391e-01, time/batch = 0.2909s	
252/2700 (epoch 4.667), train_loss = 2.35620697, grad/param norm = 3.4820e-01, time/batch = 0.2837s	
253/2700 (epoch 4.685), train_loss = 2.39210718, grad/param norm = 2.6861e-01, time/batch = 0.2585s	
254/2700 (epoch 4.704), train_loss = 2.37508196, grad/param norm = 2.5363e-01, time/batch = 0.3046s	
255/2700 (epoch 4.722), train_loss = 2.35205519, grad/param norm = 2.3639e-01, time/batch = 0.3001s	
256/2700 (epoch 4.741), train_loss = 2.49580296, grad/param norm = 2.6331e-01, time/batch = 0.2827s	
257/2700 (epoch 4.759), train_loss = 2.43973041, grad/param norm = 2.9402e-01, time/batch = 0.2615s	
258/2700 (epoch 4.778), train_loss = 2.43832879, grad/param norm = 3.0030e-01, time/batch = 0.2369s	
259/2700 (epoch 4.796), train_loss = 2.39282740, grad/param norm = 3.0200e-01, time/batch = 0.3102s	
260/2700 (epoch 4.815), train_loss = 2.39832628, grad/param norm = 2.9962e-01, time/batch = 0.3200s	
261/2700 (epoch 4.833), train_loss = 2.36911743, grad/param norm = 3.0399e-01, time/batch = 0.3034s	
262/2700 (epoch 4.852), train_loss = 2.40736238, grad/param norm = 2.6321e-01, time/batch = 0.3165s	
263/2700 (epoch 4.870), train_loss = 2.36947341, grad/param norm = 3.2515e-01, time/batch = 0.3185s	
264/2700 (epoch 4.889), train_loss = 2.39732773, grad/param norm = 3.8759e-01, time/batch = 0.2985s	
265/2700 (epoch 4.907), train_loss = 2.49495815, grad/param norm = 3.0541e-01, time/batch = 0.2969s	
266/2700 (epoch 4.926), train_loss = 2.40733142, grad/param norm = 2.6185e-01, time/batch = 0.2888s	
267/2700 (epoch 4.944), train_loss = 2.41049111, grad/param norm = 2.9221e-01, time/batch = 0.2597s	
268/2700 (epoch 4.963), train_loss = 2.46442133, grad/param norm = 2.8685e-01, time/batch = 0.2521s	
269/2700 (epoch 4.981), train_loss = 2.42846457, grad/param norm = 3.1410e-01, time/batch = 0.3032s	
270/2700 (epoch 5.000), train_loss = 2.43716912, grad/param norm = 2.9420e-01, time/batch = 0.3169s	
271/2700 (epoch 5.019), train_loss = 2.41739772, grad/param norm = 2.9843e-01, time/batch = 0.3255s	
272/2700 (epoch 5.037), train_loss = 2.44748487, grad/param norm = 3.5132e-01, time/batch = 0.3290s	
273/2700 (epoch 5.056), train_loss = 2.41048455, grad/param norm = 3.7924e-01, time/batch = 0.3240s	
274/2700 (epoch 5.074), train_loss = 2.38167017, grad/param norm = 2.9924e-01, time/batch = 0.3154s	
275/2700 (epoch 5.093), train_loss = 2.39314986, grad/param norm = 2.4350e-01, time/batch = 0.3046s	
276/2700 (epoch 5.111), train_loss = 2.36050835, grad/param norm = 2.5942e-01, time/batch = 0.2578s	
277/2700 (epoch 5.130), train_loss = 2.37841045, grad/param norm = 2.4344e-01, time/batch = 0.2917s	
278/2700 (epoch 5.148), train_loss = 2.33686845, grad/param norm = 2.5996e-01, time/batch = 0.2859s	
279/2700 (epoch 5.167), train_loss = 2.39137345, grad/param norm = 3.1255e-01, time/batch = 0.2960s	
280/2700 (epoch 5.185), train_loss = 2.36244993, grad/param norm = 3.2792e-01, time/batch = 0.3045s	
281/2700 (epoch 5.204), train_loss = 2.34326760, grad/param norm = 3.1510e-01, time/batch = 0.3016s	
282/2700 (epoch 5.222), train_loss = 2.28749721, grad/param norm = 3.6773e-01, time/batch = 0.3248s	
283/2700 (epoch 5.241), train_loss = 2.26362370, grad/param norm = 3.0584e-01, time/batch = 0.3273s	
284/2700 (epoch 5.259), train_loss = 2.27151088, grad/param norm = 2.6739e-01, time/batch = 0.3248s	
285/2700 (epoch 5.278), train_loss = 2.36063300, grad/param norm = 2.5637e-01, time/batch = 0.3164s	
286/2700 (epoch 5.296), train_loss = 2.32716999, grad/param norm = 2.3577e-01, time/batch = 0.3225s	
287/2700 (epoch 5.315), train_loss = 2.35712176, grad/param norm = 2.8959e-01, time/batch = 0.2593s	
288/2700 (epoch 5.333), train_loss = 2.36135449, grad/param norm = 3.3350e-01, time/batch = 0.2967s	
289/2700 (epoch 5.352), train_loss = 2.39629109, grad/param norm = 3.2672e-01, time/batch = 0.2908s	
290/2700 (epoch 5.370), train_loss = 2.34449954, grad/param norm = 2.8577e-01, time/batch = 0.3061s	
291/2700 (epoch 5.389), train_loss = 2.32555361, grad/param norm = 2.6171e-01, time/batch = 0.3104s	
292/2700 (epoch 5.407), train_loss = 2.30668199, grad/param norm = 2.6039e-01, time/batch = 0.3155s	
293/2700 (epoch 5.426), train_loss = 2.35403935, grad/param norm = 2.7145e-01, time/batch = 0.3193s	
294/2700 (epoch 5.444), train_loss = 2.26577352, grad/param norm = 3.0177e-01, time/batch = 0.3206s	
295/2700 (epoch 5.463), train_loss = 2.35875167, grad/param norm = 3.2784e-01, time/batch = 0.3139s	
296/2700 (epoch 5.481), train_loss = 2.37902764, grad/param norm = 2.8933e-01, time/batch = 0.3021s	
297/2700 (epoch 5.500), train_loss = 2.35024652, grad/param norm = 2.4786e-01, time/batch = 0.2933s	
298/2700 (epoch 5.519), train_loss = 2.32724702, grad/param norm = 3.3096e-01, time/batch = 0.2595s	
299/2700 (epoch 5.537), train_loss = 2.38766508, grad/param norm = 3.5451e-01, time/batch = 0.2686s	
300/2700 (epoch 5.556), train_loss = 2.32423670, grad/param norm = 2.4648e-01, time/batch = 0.3114s	
301/2700 (epoch 5.574), train_loss = 2.26256667, grad/param norm = 1.9409e-01, time/batch = 0.3042s	
302/2700 (epoch 5.593), train_loss = 2.26140463, grad/param norm = 2.1243e-01, time/batch = 0.3023s	
303/2700 (epoch 5.611), train_loss = 2.20838613, grad/param norm = 3.0561e-01, time/batch = 0.2895s	
304/2700 (epoch 5.630), train_loss = 2.26406995, grad/param norm = 3.2329e-01, time/batch = 0.2863s	
305/2700 (epoch 5.648), train_loss = 2.32204924, grad/param norm = 3.3047e-01, time/batch = 0.2815s	
306/2700 (epoch 5.667), train_loss = 2.23980992, grad/param norm = 3.0397e-01, time/batch = 0.2810s	
307/2700 (epoch 5.685), train_loss = 2.27516605, grad/param norm = 2.8701e-01, time/batch = 0.2923s	
308/2700 (epoch 5.704), train_loss = 2.27109027, grad/param norm = 2.6256e-01, time/batch = 0.3067s	
309/2700 (epoch 5.722), train_loss = 2.23795630, grad/param norm = 2.2795e-01, time/batch = 0.2738s	
310/2700 (epoch 5.741), train_loss = 2.33436196, grad/param norm = 2.7555e-01, time/batch = 0.3102s	
311/2700 (epoch 5.759), train_loss = 2.33461838, grad/param norm = 3.1859e-01, time/batch = 0.3108s	
312/2700 (epoch 5.778), train_loss = 2.33824127, grad/param norm = 3.6169e-01, time/batch = 0.3152s	
313/2700 (epoch 5.796), train_loss = 2.37894522, grad/param norm = 9.4945e-01, time/batch = 0.2843s	
314/2700 (epoch 5.815), train_loss = 2.35747313, grad/param norm = 2.7125e-01, time/batch = 0.2966s	
315/2700 (epoch 5.833), train_loss = 2.29394455, grad/param norm = 3.1564e-01, time/batch = 0.2991s	
316/2700 (epoch 5.852), train_loss = 2.33556998, grad/param norm = 4.0400e-01, time/batch = 0.2974s	
317/2700 (epoch 5.870), train_loss = 2.31390647, grad/param norm = 4.0775e-01, time/batch = 0.3094s	
318/2700 (epoch 5.889), train_loss = 2.27871962, grad/param norm = 2.7751e-01, time/batch = 0.3171s	
319/2700 (epoch 5.907), train_loss = 2.37862246, grad/param norm = 2.2816e-01, time/batch = 0.2948s	
320/2700 (epoch 5.926), train_loss = 2.30513205, grad/param norm = 2.3385e-01, time/batch = 0.3085s	
321/2700 (epoch 5.944), train_loss = 2.29211414, grad/param norm = 1.9083e-01, time/batch = 0.3259s	
322/2700 (epoch 5.963), train_loss = 2.32496547, grad/param norm = 1.6993e-01, time/batch = 0.3015s	
323/2700 (epoch 5.981), train_loss = 2.29219265, grad/param norm = 2.4071e-01, time/batch = 0.3143s	
324/2700 (epoch 6.000), train_loss = 2.32484218, grad/param norm = 2.5798e-01, time/batch = 0.2995s	
325/2700 (epoch 6.019), train_loss = 2.29976007, grad/param norm = 2.3406e-01, time/batch = 0.2977s	
326/2700 (epoch 6.037), train_loss = 2.29795823, grad/param norm = 2.0068e-01, time/batch = 0.2942s	
327/2700 (epoch 6.056), train_loss = 2.24923673, grad/param norm = 1.8288e-01, time/batch = 0.2999s	
328/2700 (epoch 6.074), train_loss = 2.21589565, grad/param norm = 1.6548e-01, time/batch = 0.3119s	
329/2700 (epoch 6.093), train_loss = 2.26610470, grad/param norm = 2.1720e-01, time/batch = 0.3002s	
330/2700 (epoch 6.111), train_loss = 2.23127785, grad/param norm = 2.2711e-01, time/batch = 0.3101s	
331/2700 (epoch 6.130), train_loss = 2.24789060, grad/param norm = 2.1386e-01, time/batch = 0.2919s	
332/2700 (epoch 6.148), train_loss = 2.21450169, grad/param norm = 2.6095e-01, time/batch = 0.3053s	
333/2700 (epoch 6.167), train_loss = 2.27821213, grad/param norm = 3.2264e-01, time/batch = 0.3007s	
334/2700 (epoch 6.185), train_loss = 2.24290657, grad/param norm = 3.2865e-01, time/batch = 0.2937s	
335/2700 (epoch 6.204), train_loss = 2.23355794, grad/param norm = 2.5216e-01, time/batch = 0.2966s	
336/2700 (epoch 6.222), train_loss = 2.14988497, grad/param norm = 2.2476e-01, time/batch = 0.3020s	
337/2700 (epoch 6.241), train_loss = 2.11553010, grad/param norm = 2.0777e-01, time/batch = 0.3114s	
338/2700 (epoch 6.259), train_loss = 2.16035496, grad/param norm = 2.2265e-01, time/batch = 0.3172s	
339/2700 (epoch 6.278), train_loss = 2.24928733, grad/param norm = 2.2150e-01, time/batch = 0.3189s	
340/2700 (epoch 6.296), train_loss = 2.23186148, grad/param norm = 2.5136e-01, time/batch = 0.2932s	
341/2700 (epoch 6.315), train_loss = 2.24371296, grad/param norm = 2.4383e-01, time/batch = 0.2830s	
342/2700 (epoch 6.333), train_loss = 2.21820811, grad/param norm = 1.9023e-01, time/batch = 0.3191s	
343/2700 (epoch 6.352), train_loss = 2.23778509, grad/param norm = 2.0397e-01, time/batch = 0.2600s	
344/2700 (epoch 6.370), train_loss = 2.23366835, grad/param norm = 2.4720e-01, time/batch = 0.2974s	
345/2700 (epoch 6.389), train_loss = 2.22217945, grad/param norm = 2.5673e-01, time/batch = 0.3088s	
346/2700 (epoch 6.407), train_loss = 2.21284696, grad/param norm = 2.8870e-01, time/batch = 0.3186s	
347/2700 (epoch 6.426), train_loss = 2.26407277, grad/param norm = 2.7955e-01, time/batch = 0.3107s	
348/2700 (epoch 6.444), train_loss = 2.14672943, grad/param norm = 2.3781e-01, time/batch = 0.3188s	
349/2700 (epoch 6.463), train_loss = 2.21826993, grad/param norm = 2.6069e-01, time/batch = 0.3239s	
350/2700 (epoch 6.481), train_loss = 2.25335512, grad/param norm = 2.6863e-01, time/batch = 0.2342s	
351/2700 (epoch 6.500), train_loss = 2.24645280, grad/param norm = 2.8044e-01, time/batch = 0.2941s	
352/2700 (epoch 6.519), train_loss = 2.21352566, grad/param norm = 2.7760e-01, time/batch = 0.2936s	
353/2700 (epoch 6.537), train_loss = 2.23050701, grad/param norm = 2.0917e-01, time/batch = 0.2902s	
354/2700 (epoch 6.556), train_loss = 2.18252846, grad/param norm = 1.7535e-01, time/batch = 0.2790s	
355/2700 (epoch 6.574), train_loss = 2.16729232, grad/param norm = 1.9700e-01, time/batch = 0.3293s	
356/2700 (epoch 6.593), train_loss = 2.17295803, grad/param norm = 2.3391e-01, time/batch = 0.3236s	
357/2700 (epoch 6.611), train_loss = 2.09759782, grad/param norm = 2.4641e-01, time/batch = 0.3208s	
358/2700 (epoch 6.630), train_loss = 2.13642698, grad/param norm = 2.5359e-01, time/batch = 0.3203s	
359/2700 (epoch 6.648), train_loss = 2.18619705, grad/param norm = 2.4512e-01, time/batch = 0.3134s	
360/2700 (epoch 6.667), train_loss = 2.11931459, grad/param norm = 2.3109e-01, time/batch = 0.2774s	
361/2700 (epoch 6.685), train_loss = 2.16511317, grad/param norm = 2.4956e-01, time/batch = 0.3303s	
362/2700 (epoch 6.704), train_loss = 2.16677554, grad/param norm = 2.5378e-01, time/batch = 0.3294s	
363/2700 (epoch 6.722), train_loss = 2.13861965, grad/param norm = 2.4969e-01, time/batch = 0.3266s	
364/2700 (epoch 6.741), train_loss = 2.21456900, grad/param norm = 2.7742e-01, time/batch = 0.3134s	
365/2700 (epoch 6.759), train_loss = 2.22368481, grad/param norm = 2.7528e-01, time/batch = 0.2631s	
366/2700 (epoch 6.778), train_loss = 2.21894560, grad/param norm = 2.4701e-01, time/batch = 0.3269s	
367/2700 (epoch 6.796), train_loss = 2.15888689, grad/param norm = 2.3099e-01, time/batch = 0.3244s	
368/2700 (epoch 6.815), train_loss = 2.19814958, grad/param norm = 2.3381e-01, time/batch = 0.3203s	
369/2700 (epoch 6.833), train_loss = 2.18501344, grad/param norm = 3.1012e-01, time/batch = 0.2939s	
370/2700 (epoch 6.852), train_loss = 2.21852380, grad/param norm = 3.1739e-01, time/batch = 0.3092s	
371/2700 (epoch 6.870), train_loss = 2.16278723, grad/param norm = 2.1825e-01, time/batch = 0.3241s	
372/2700 (epoch 6.889), train_loss = 2.13377658, grad/param norm = 1.6226e-01, time/batch = 0.3170s	
373/2700 (epoch 6.907), train_loss = 2.24893328, grad/param norm = 1.8101e-01, time/batch = 0.3201s	
374/2700 (epoch 6.926), train_loss = 2.19791286, grad/param norm = 2.1271e-01, time/batch = 0.3232s	
375/2700 (epoch 6.944), train_loss = 2.19072075, grad/param norm = 2.0944e-01, time/batch = 0.3172s	
376/2700 (epoch 6.963), train_loss = 2.21936363, grad/param norm = 2.1243e-01, time/batch = 0.2587s	
377/2700 (epoch 6.981), train_loss = 2.17927892, grad/param norm = 2.1452e-01, time/batch = 0.3237s	
378/2700 (epoch 7.000), train_loss = 2.20373493, grad/param norm = 2.2527e-01, time/batch = 0.3261s	
379/2700 (epoch 7.019), train_loss = 2.20216107, grad/param norm = 2.2739e-01, time/batch = 0.3317s	
380/2700 (epoch 7.037), train_loss = 2.19012129, grad/param norm = 2.1847e-01, time/batch = 0.3223s	
381/2700 (epoch 7.056), train_loss = 2.15396392, grad/param norm = 2.0154e-01, time/batch = 0.3087s	
382/2700 (epoch 7.074), train_loss = 2.11769469, grad/param norm = 2.1544e-01, time/batch = 0.3228s	
383/2700 (epoch 7.093), train_loss = 2.17074789, grad/param norm = 2.4833e-01, time/batch = 0.3198s	
384/2700 (epoch 7.111), train_loss = 2.12458243, grad/param norm = 2.4168e-01, time/batch = 0.3187s	
385/2700 (epoch 7.130), train_loss = 2.14710206, grad/param norm = 2.0166e-01, time/batch = 0.3182s	
386/2700 (epoch 7.148), train_loss = 2.09164893, grad/param norm = 1.7309e-01, time/batch = 0.3180s	
387/2700 (epoch 7.167), train_loss = 2.14348708, grad/param norm = 1.7749e-01, time/batch = 0.2467s	
388/2700 (epoch 7.185), train_loss = 2.09254854, grad/param norm = 1.8746e-01, time/batch = 0.3245s	
389/2700 (epoch 7.204), train_loss = 2.12551461, grad/param norm = 2.3923e-01, time/batch = 0.3299s	
390/2700 (epoch 7.222), train_loss = 2.07456251, grad/param norm = 2.9693e-01, time/batch = 0.3283s	
391/2700 (epoch 7.241), train_loss = 2.03765396, grad/param norm = 3.0168e-01, time/batch = 0.3197s	
392/2700 (epoch 7.259), train_loss = 2.08541429, grad/param norm = 2.9529e-01, time/batch = 0.3227s	
393/2700 (epoch 7.278), train_loss = 2.18740638, grad/param norm = 2.9628e-01, time/batch = 0.3197s	
394/2700 (epoch 7.296), train_loss = 2.16250696, grad/param norm = 2.6816e-01, time/batch = 0.3172s	
395/2700 (epoch 7.315), train_loss = 2.13328379, grad/param norm = 2.0098e-01, time/batch = 0.3252s	
396/2700 (epoch 7.333), train_loss = 2.11341929, grad/param norm = 1.5407e-01, time/batch = 0.3137s	
397/2700 (epoch 7.352), train_loss = 2.12500791, grad/param norm = 1.7494e-01, time/batch = 0.3194s	
398/2700 (epoch 7.370), train_loss = 2.14461354, grad/param norm = 1.8640e-01, time/batch = 0.2525s	
399/2700 (epoch 7.389), train_loss = 2.13302083, grad/param norm = 2.2898e-01, time/batch = 0.3245s	
400/2700 (epoch 7.407), train_loss = 2.13485531, grad/param norm = 2.2566e-01, time/batch = 0.3253s	
401/2700 (epoch 7.426), train_loss = 2.16184108, grad/param norm = 2.4114e-01, time/batch = 0.3100s	
402/2700 (epoch 7.444), train_loss = 2.06323689, grad/param norm = 2.1771e-01, time/batch = 0.3194s	
403/2700 (epoch 7.463), train_loss = 2.12364402, grad/param norm = 2.0689e-01, time/batch = 0.3213s	
404/2700 (epoch 7.481), train_loss = 2.14693593, grad/param norm = 1.9880e-01, time/batch = 0.3182s	
405/2700 (epoch 7.500), train_loss = 2.10595304, grad/param norm = 1.8628e-01, time/batch = 0.3174s	
406/2700 (epoch 7.519), train_loss = 2.09195512, grad/param norm = 1.9452e-01, time/batch = 0.3141s	
407/2700 (epoch 7.537), train_loss = 2.12671950, grad/param norm = 2.0139e-01, time/batch = 0.3056s	
408/2700 (epoch 7.556), train_loss = 2.08817139, grad/param norm = 1.9403e-01, time/batch = 0.2983s	
409/2700 (epoch 7.574), train_loss = 2.08112408, grad/param norm = 2.2035e-01, time/batch = 0.2650s	
410/2700 (epoch 7.593), train_loss = 2.08853956, grad/param norm = 2.5475e-01, time/batch = 0.3270s	
411/2700 (epoch 7.611), train_loss = 2.01139568, grad/param norm = 2.7253e-01, time/batch = 0.3118s	
412/2700 (epoch 7.630), train_loss = 2.05842465, grad/param norm = 2.3060e-01, time/batch = 0.3172s	
413/2700 (epoch 7.648), train_loss = 2.08463097, grad/param norm = 2.0131e-01, time/batch = 0.3169s	
414/2700 (epoch 7.667), train_loss = 2.03912077, grad/param norm = 2.1836e-01, time/batch = 0.3191s	
415/2700 (epoch 7.685), train_loss = 2.08486608, grad/param norm = 2.5702e-01, time/batch = 0.3209s	
416/2700 (epoch 7.704), train_loss = 2.08455994, grad/param norm = 2.4163e-01, time/batch = 0.3193s	
417/2700 (epoch 7.722), train_loss = 2.03761901, grad/param norm = 1.9122e-01, time/batch = 0.3085s	
418/2700 (epoch 7.741), train_loss = 2.08285897, grad/param norm = 1.7866e-01, time/batch = 0.2959s	
419/2700 (epoch 7.759), train_loss = 2.12452003, grad/param norm = 2.1478e-01, time/batch = 0.2952s	
420/2700 (epoch 7.778), train_loss = 2.13778415, grad/param norm = 2.4580e-01, time/batch = 0.2732s	
421/2700 (epoch 7.796), train_loss = 2.08618289, grad/param norm = 2.3928e-01, time/batch = 0.3162s	
422/2700 (epoch 7.815), train_loss = 2.10031648, grad/param norm = 2.2634e-01, time/batch = 0.3103s	
423/2700 (epoch 7.833), train_loss = 2.06793021, grad/param norm = 2.1984e-01, time/batch = 0.3137s	
424/2700 (epoch 7.852), train_loss = 2.07105454, grad/param norm = 2.1860e-01, time/batch = 0.2791s	
425/2700 (epoch 7.870), train_loss = 2.06066196, grad/param norm = 2.3198e-01, time/batch = 0.3167s	
426/2700 (epoch 7.889), train_loss = 2.06471876, grad/param norm = 2.1707e-01, time/batch = 0.3143s	
427/2700 (epoch 7.907), train_loss = 2.17130284, grad/param norm = 2.0090e-01, time/batch = 0.3004s	
428/2700 (epoch 7.926), train_loss = 2.11648951, grad/param norm = 2.0577e-01, time/batch = 0.3013s	
429/2700 (epoch 7.944), train_loss = 2.09771912, grad/param norm = 1.7847e-01, time/batch = 0.3008s	
430/2700 (epoch 7.963), train_loss = 2.10367347, grad/param norm = 1.4464e-01, time/batch = 0.2978s	
431/2700 (epoch 7.981), train_loss = 2.06340640, grad/param norm = 1.3214e-01, time/batch = 0.2476s	
432/2700 (epoch 8.000), train_loss = 2.09415323, grad/param norm = 1.5006e-01, time/batch = 0.3186s	
433/2700 (epoch 8.019), train_loss = 2.10766846, grad/param norm = 1.7729e-01, time/batch = 0.3087s	
434/2700 (epoch 8.037), train_loss = 2.09519885, grad/param norm = 1.7453e-01, time/batch = 0.3135s	
435/2700 (epoch 8.056), train_loss = 2.06887810, grad/param norm = 2.1271e-01, time/batch = 0.3020s	
436/2700 (epoch 8.074), train_loss = 2.03993397, grad/param norm = 2.2863e-01, time/batch = 0.2927s	
437/2700 (epoch 8.093), train_loss = 2.06897691, grad/param norm = 2.3287e-01, time/batch = 0.2908s	
438/2700 (epoch 8.111), train_loss = 2.03004688, grad/param norm = 2.1306e-01, time/batch = 0.2863s	
439/2700 (epoch 8.130), train_loss = 2.06375955, grad/param norm = 2.0334e-01, time/batch = 0.2959s	
440/2700 (epoch 8.148), train_loss = 2.01976088, grad/param norm = 2.1550e-01, time/batch = 0.3068s	
441/2700 (epoch 8.167), train_loss = 2.08278747, grad/param norm = 2.0700e-01, time/batch = 0.3003s	
442/2700 (epoch 8.185), train_loss = 2.00876061, grad/param norm = 1.7910e-01, time/batch = 0.2769s	
443/2700 (epoch 8.204), train_loss = 2.05020519, grad/param norm = 1.9430e-01, time/batch = 0.2575s	
444/2700 (epoch 8.222), train_loss = 1.97476987, grad/param norm = 1.9753e-01, time/batch = 0.2814s	
445/2700 (epoch 8.241), train_loss = 1.91357545, grad/param norm = 1.7739e-01, time/batch = 0.2850s	
446/2700 (epoch 8.259), train_loss = 1.95905278, grad/param norm = 1.6586e-01, time/batch = 0.2960s	
447/2700 (epoch 8.278), train_loss = 2.03767443, grad/param norm = 1.4234e-01, time/batch = 0.2953s	
448/2700 (epoch 8.296), train_loss = 2.02040806, grad/param norm = 1.8848e-01, time/batch = 0.2960s	
449/2700 (epoch 8.315), train_loss = 2.05718217, grad/param norm = 2.3120e-01, time/batch = 0.2987s	
450/2700 (epoch 8.333), train_loss = 2.03556783, grad/param norm = 1.8831e-01, time/batch = 0.2988s	
451/2700 (epoch 8.352), train_loss = 2.03601042, grad/param norm = 1.8220e-01, time/batch = 0.2843s	
452/2700 (epoch 8.370), train_loss = 2.06117017, grad/param norm = 1.9391e-01, time/batch = 0.2729s	
453/2700 (epoch 8.389), train_loss = 2.02867179, grad/param norm = 1.7800e-01, time/batch = 0.2989s	
454/2700 (epoch 8.407), train_loss = 2.01688541, grad/param norm = 1.5794e-01, time/batch = 0.2401s	
455/2700 (epoch 8.426), train_loss = 2.05902834, grad/param norm = 1.5690e-01, time/batch = 0.3018s	
456/2700 (epoch 8.444), train_loss = 1.96020001, grad/param norm = 1.6493e-01, time/batch = 0.3100s	
457/2700 (epoch 8.463), train_loss = 2.03551406, grad/param norm = 1.8073e-01, time/batch = 0.3095s	
458/2700 (epoch 8.481), train_loss = 2.04819757, grad/param norm = 1.8406e-01, time/batch = 0.3083s	
459/2700 (epoch 8.500), train_loss = 2.02831478, grad/param norm = 1.9996e-01, time/batch = 0.3030s	
460/2700 (epoch 8.519), train_loss = 2.01352854, grad/param norm = 2.0289e-01, time/batch = 0.3077s	
461/2700 (epoch 8.537), train_loss = 2.04493945, grad/param norm = 1.8729e-01, time/batch = 0.2574s	
462/2700 (epoch 8.556), train_loss = 1.99506695, grad/param norm = 1.8167e-01, time/batch = 0.2971s	
463/2700 (epoch 8.574), train_loss = 2.00025694, grad/param norm = 2.1210e-01, time/batch = 0.2821s	
464/2700 (epoch 8.593), train_loss = 2.00995414, grad/param norm = 2.3714e-01, time/batch = 0.2831s	
465/2700 (epoch 8.611), train_loss = 1.93588244, grad/param norm = 2.5256e-01, time/batch = 0.2377s	
466/2700 (epoch 8.630), train_loss = 1.99115862, grad/param norm = 2.7555e-01, time/batch = 0.3042s	
467/2700 (epoch 8.648), train_loss = 2.01203516, grad/param norm = 2.1961e-01, time/batch = 0.3008s	
468/2700 (epoch 8.667), train_loss = 1.94993885, grad/param norm = 1.9228e-01, time/batch = 0.2881s	
469/2700 (epoch 8.685), train_loss = 1.98132101, grad/param norm = 1.9627e-01, time/batch = 0.2838s	
470/2700 (epoch 8.704), train_loss = 1.97903305, grad/param norm = 1.7791e-01, time/batch = 0.2803s	
471/2700 (epoch 8.722), train_loss = 1.94823099, grad/param norm = 1.3557e-01, time/batch = 0.2161s	
472/2700 (epoch 8.741), train_loss = 1.98491651, grad/param norm = 1.4461e-01, time/batch = 0.2971s	
473/2700 (epoch 8.759), train_loss = 2.03252544, grad/param norm = 1.8472e-01, time/batch = 0.3143s	
474/2700 (epoch 8.778), train_loss = 2.02595376, grad/param norm = 2.0783e-01, time/batch = 0.3231s	
475/2700 (epoch 8.796), train_loss = 1.99534895, grad/param norm = 2.2267e-01, time/batch = 0.3266s	
476/2700 (epoch 8.815), train_loss = 2.02187414, grad/param norm = 2.2522e-01, time/batch = 0.3175s	
477/2700 (epoch 8.833), train_loss = 1.98313377, grad/param norm = 1.8938e-01, time/batch = 0.3039s	
478/2700 (epoch 8.852), train_loss = 1.97514366, grad/param norm = 1.5862e-01, time/batch = 0.2967s	
479/2700 (epoch 8.870), train_loss = 1.96612870, grad/param norm = 1.5281e-01, time/batch = 0.2965s	
480/2700 (epoch 8.889), train_loss = 1.97672869, grad/param norm = 1.5865e-01, time/batch = 0.2964s	
481/2700 (epoch 8.907), train_loss = 2.08468360, grad/param norm = 1.7951e-01, time/batch = 0.2369s	
482/2700 (epoch 8.926), train_loss = 2.04525821, grad/param norm = 2.1237e-01, time/batch = 0.3082s	
483/2700 (epoch 8.944), train_loss = 2.02236876, grad/param norm = 1.7605e-01, time/batch = 0.3115s	
484/2700 (epoch 8.963), train_loss = 2.01791352, grad/param norm = 1.3802e-01, time/batch = 0.3151s	
485/2700 (epoch 8.981), train_loss = 1.97961072, grad/param norm = 1.2905e-01, time/batch = 0.3201s	
486/2700 (epoch 9.000), train_loss = 2.00971426, grad/param norm = 1.3525e-01, time/batch = 0.3209s	
487/2700 (epoch 9.019), train_loss = 2.02516353, grad/param norm = 1.8065e-01, time/batch = 0.3198s	
488/2700 (epoch 9.037), train_loss = 2.03118385, grad/param norm = 2.1960e-01, time/batch = 0.2390s	
489/2700 (epoch 9.056), train_loss = 2.00330935, grad/param norm = 2.4445e-01, time/batch = 0.3164s	
490/2700 (epoch 9.074), train_loss = 1.94138750, grad/param norm = 1.9643e-01, time/batch = 0.3098s	
491/2700 (epoch 9.093), train_loss = 1.95278127, grad/param norm = 1.6922e-01, time/batch = 0.3157s	
492/2700 (epoch 9.111), train_loss = 1.90927708, grad/param norm = 1.6316e-01, time/batch = 0.3083s	
493/2700 (epoch 9.130), train_loss = 1.96932749, grad/param norm = 1.7072e-01, time/batch = 0.3192s	
494/2700 (epoch 9.148), train_loss = 1.92444721, grad/param norm = 1.8531e-01, time/batch = 0.3225s	
495/2700 (epoch 9.167), train_loss = 1.98748837, grad/param norm = 1.7008e-01, time/batch = 0.3112s	
496/2700 (epoch 9.185), train_loss = 1.91316297, grad/param norm = 1.5117e-01, time/batch = 0.2969s	
497/2700 (epoch 9.204), train_loss = 1.95355751, grad/param norm = 1.5518e-01, time/batch = 0.2903s	
498/2700 (epoch 9.222), train_loss = 1.87980175, grad/param norm = 1.4626e-01, time/batch = 0.2913s	
499/2700 (epoch 9.241), train_loss = 1.80984454, grad/param norm = 1.4342e-01, time/batch = 0.2787s	
500/2700 (epoch 9.259), train_loss = 1.87119522, grad/param norm = 1.5143e-01, time/batch = 0.3216s	
501/2700 (epoch 9.278), train_loss = 1.96654562, grad/param norm = 1.8261e-01, time/batch = 0.3201s	
502/2700 (epoch 9.296), train_loss = 1.98752450, grad/param norm = 2.3546e-01, time/batch = 0.3096s	
503/2700 (epoch 9.315), train_loss = 2.00960196, grad/param norm = 2.4925e-01, time/batch = 0.3147s	
504/2700 (epoch 9.333), train_loss = 1.96425389, grad/param norm = 1.7756e-01, time/batch = 0.3159s	
505/2700 (epoch 9.352), train_loss = 1.95616163, grad/param norm = 1.6208e-01, time/batch = 0.3038s	
506/2700 (epoch 9.370), train_loss = 1.97883049, grad/param norm = 1.5489e-01, time/batch = 0.2914s	
507/2700 (epoch 9.389), train_loss = 1.93733128, grad/param norm = 1.6572e-01, time/batch = 0.2992s	
508/2700 (epoch 9.407), train_loss = 1.95135607, grad/param norm = 1.7045e-01, time/batch = 0.2926s	
509/2700 (epoch 9.426), train_loss = 1.99326861, grad/param norm = 1.8108e-01, time/batch = 0.2772s	
510/2700 (epoch 9.444), train_loss = 1.89400504, grad/param norm = 1.6541e-01, time/batch = 0.2824s	
511/2700 (epoch 9.463), train_loss = 1.97072688, grad/param norm = 1.6940e-01, time/batch = 0.3078s	
512/2700 (epoch 9.481), train_loss = 1.96899254, grad/param norm = 1.4994e-01, time/batch = 0.3210s	
513/2700 (epoch 9.500), train_loss = 1.92563212, grad/param norm = 1.3726e-01, time/batch = 0.3245s	
514/2700 (epoch 9.519), train_loss = 1.92056952, grad/param norm = 1.3940e-01, time/batch = 0.3084s	
515/2700 (epoch 9.537), train_loss = 1.95079967, grad/param norm = 1.5369e-01, time/batch = 0.2916s	
516/2700 (epoch 9.556), train_loss = 1.90441133, grad/param norm = 1.6148e-01, time/batch = 0.2940s	
517/2700 (epoch 9.574), train_loss = 1.92510806, grad/param norm = 2.1309e-01, time/batch = 0.2892s	
518/2700 (epoch 9.593), train_loss = 1.93024395, grad/param norm = 2.4631e-01, time/batch = 0.2920s	
519/2700 (epoch 9.611), train_loss = 1.84612718, grad/param norm = 2.2745e-01, time/batch = 0.3017s	
520/2700 (epoch 9.630), train_loss = 1.87862623, grad/param norm = 1.7990e-01, time/batch = 0.3084s	
521/2700 (epoch 9.648), train_loss = 1.90706239, grad/param norm = 1.4849e-01, time/batch = 0.2994s	
522/2700 (epoch 9.667), train_loss = 1.85232064, grad/param norm = 1.3552e-01, time/batch = 0.2950s	
523/2700 (epoch 9.685), train_loss = 1.89429776, grad/param norm = 1.7250e-01, time/batch = 0.2920s	
524/2700 (epoch 9.704), train_loss = 1.90456237, grad/param norm = 1.8173e-01, time/batch = 0.2907s	
525/2700 (epoch 9.722), train_loss = 1.88819371, grad/param norm = 1.7302e-01, time/batch = 0.2779s	
526/2700 (epoch 9.741), train_loss = 1.91397815, grad/param norm = 1.6312e-01, time/batch = 0.2858s	
527/2700 (epoch 9.759), train_loss = 1.94213702, grad/param norm = 1.4764e-01, time/batch = 0.2884s	
528/2700 (epoch 9.778), train_loss = 1.93911938, grad/param norm = 1.2649e-01, time/batch = 0.2997s	
529/2700 (epoch 9.796), train_loss = 1.87573400, grad/param norm = 1.3085e-01, time/batch = 0.3050s	
530/2700 (epoch 9.815), train_loss = 1.92352144, grad/param norm = 1.5049e-01, time/batch = 0.3116s	
531/2700 (epoch 9.833), train_loss = 1.89096322, grad/param norm = 1.5130e-01, time/batch = 0.3211s	
532/2700 (epoch 9.852), train_loss = 1.89534685, grad/param norm = 1.5091e-01, time/batch = 0.2997s	
533/2700 (epoch 9.870), train_loss = 1.89387917, grad/param norm = 1.4231e-01, time/batch = 0.3098s	
534/2700 (epoch 9.889), train_loss = 1.90776541, grad/param norm = 1.4652e-01, time/batch = 0.2923s	
535/2700 (epoch 9.907), train_loss = 2.02050623, grad/param norm = 1.7187e-01, time/batch = 0.2900s	
536/2700 (epoch 9.926), train_loss = 1.97536020, grad/param norm = 1.9092e-01, time/batch = 0.2937s	
537/2700 (epoch 9.944), train_loss = 1.93679769, grad/param norm = 1.4676e-01, time/batch = 0.2504s	
538/2700 (epoch 9.963), train_loss = 1.93961559, grad/param norm = 1.3687e-01, time/batch = 0.3070s	
539/2700 (epoch 9.981), train_loss = 1.90300945, grad/param norm = 1.3413e-01, time/batch = 0.3029s	
decayed learning rate by a factor 0.97 to 0.00194	
540/2700 (epoch 10.000), train_loss = 1.93944478, grad/param norm = 1.4958e-01, time/batch = 0.3058s	
541/2700 (epoch 10.019), train_loss = 1.96449569, grad/param norm = 2.0518e-01, time/batch = 0.3231s	
542/2700 (epoch 10.037), train_loss = 1.97139102, grad/param norm = 2.1368e-01, time/batch = 0.3136s	
543/2700 (epoch 10.056), train_loss = 1.90918350, grad/param norm = 1.6697e-01, time/batch = 0.3071s	
544/2700 (epoch 10.074), train_loss = 1.85369642, grad/param norm = 1.6117e-01, time/batch = 0.2479s	
545/2700 (epoch 10.093), train_loss = 1.86157662, grad/param norm = 1.4803e-01, time/batch = 0.3044s	
546/2700 (epoch 10.111), train_loss = 1.83258589, grad/param norm = 1.7438e-01, time/batch = 0.2994s	
547/2700 (epoch 10.130), train_loss = 1.90964270, grad/param norm = 2.0152e-01, time/batch = 0.3072s	
548/2700 (epoch 10.148), train_loss = 1.85836822, grad/param norm = 2.0573e-01, time/batch = 0.3046s	
549/2700 (epoch 10.167), train_loss = 1.93229689, grad/param norm = 1.7876e-01, time/batch = 0.3049s	
550/2700 (epoch 10.185), train_loss = 1.85045807, grad/param norm = 1.5286e-01, time/batch = 0.3008s	
551/2700 (epoch 10.204), train_loss = 1.88503719, grad/param norm = 1.3599e-01, time/batch = 0.3100s	
552/2700 (epoch 10.222), train_loss = 1.82189439, grad/param norm = 1.4478e-01, time/batch = 0.3196s	
553/2700 (epoch 10.241), train_loss = 1.74014005, grad/param norm = 1.3837e-01, time/batch = 0.3122s	
554/2700 (epoch 10.259), train_loss = 1.80862792, grad/param norm = 1.7506e-01, time/batch = 0.2920s	
555/2700 (epoch 10.278), train_loss = 1.91366246, grad/param norm = 2.0304e-01, time/batch = 0.2541s	
556/2700 (epoch 10.296), train_loss = 1.88784032, grad/param norm = 1.8251e-01, time/batch = 0.3194s	
557/2700 (epoch 10.315), train_loss = 1.89048565, grad/param norm = 1.5207e-01, time/batch = 0.3218s	
558/2700 (epoch 10.333), train_loss = 1.85934524, grad/param norm = 1.2663e-01, time/batch = 0.3128s	
559/2700 (epoch 10.352), train_loss = 1.86643723, grad/param norm = 1.4336e-01, time/batch = 0.2970s	
560/2700 (epoch 10.370), train_loss = 1.90610245, grad/param norm = 1.6312e-01, time/batch = 0.2877s	
561/2700 (epoch 10.389), train_loss = 1.86850205, grad/param norm = 1.6963e-01, time/batch = 0.3066s	
562/2700 (epoch 10.407), train_loss = 1.87998995, grad/param norm = 1.7484e-01, time/batch = 0.3025s	
563/2700 (epoch 10.426), train_loss = 1.92325675, grad/param norm = 1.7581e-01, time/batch = 0.2950s	
564/2700 (epoch 10.444), train_loss = 1.81993773, grad/param norm = 1.4796e-01, time/batch = 0.2977s	
565/2700 (epoch 10.463), train_loss = 1.88666485, grad/param norm = 1.4093e-01, time/batch = 0.2735s	
566/2700 (epoch 10.481), train_loss = 1.87909949, grad/param norm = 1.2677e-01, time/batch = 0.2745s	
567/2700 (epoch 10.500), train_loss = 1.84219980, grad/param norm = 1.2711e-01, time/batch = 0.3070s	
568/2700 (epoch 10.519), train_loss = 1.84788318, grad/param norm = 1.3111e-01, time/batch = 0.3019s	
569/2700 (epoch 10.537), train_loss = 1.88024859, grad/param norm = 1.4645e-01, time/batch = 0.2850s	
570/2700 (epoch 10.556), train_loss = 1.82770035, grad/param norm = 1.4816e-01, time/batch = 0.2811s	
571/2700 (epoch 10.574), train_loss = 1.84203280, grad/param norm = 1.8489e-01, time/batch = 0.3009s	
572/2700 (epoch 10.593), train_loss = 1.84157392, grad/param norm = 1.8764e-01, time/batch = 0.2923s	
573/2700 (epoch 10.611), train_loss = 1.75209135, grad/param norm = 1.7358e-01, time/batch = 0.2880s	
574/2700 (epoch 10.630), train_loss = 1.79341065, grad/param norm = 1.5475e-01, time/batch = 0.2879s	
575/2700 (epoch 10.648), train_loss = 1.83026557, grad/param norm = 1.4959e-01, time/batch = 0.2994s	
576/2700 (epoch 10.667), train_loss = 1.79495686, grad/param norm = 1.5731e-01, time/batch = 0.2943s	
577/2700 (epoch 10.685), train_loss = 1.83079064, grad/param norm = 1.7678e-01, time/batch = 0.2991s	
578/2700 (epoch 10.704), train_loss = 1.83036437, grad/param norm = 1.6598e-01, time/batch = 0.2871s	
579/2700 (epoch 10.722), train_loss = 1.81997863, grad/param norm = 1.5362e-01, time/batch = 0.2948s	
580/2700 (epoch 10.741), train_loss = 1.83132731, grad/param norm = 1.4849e-01, time/batch = 0.2868s	
581/2700 (epoch 10.759), train_loss = 1.86799071, grad/param norm = 1.4820e-01, time/batch = 0.3064s	
582/2700 (epoch 10.778), train_loss = 1.86892341, grad/param norm = 1.3911e-01, time/batch = 0.2973s	
583/2700 (epoch 10.796), train_loss = 1.81262499, grad/param norm = 1.4270e-01, time/batch = 0.2869s	
584/2700 (epoch 10.815), train_loss = 1.85275277, grad/param norm = 1.3875e-01, time/batch = 0.2772s	
585/2700 (epoch 10.833), train_loss = 1.81547224, grad/param norm = 1.4272e-01, time/batch = 0.2857s	
586/2700 (epoch 10.852), train_loss = 1.83063892, grad/param norm = 1.6762e-01, time/batch = 0.2939s	
587/2700 (epoch 10.870), train_loss = 1.83488268, grad/param norm = 1.7261e-01, time/batch = 0.3059s	
588/2700 (epoch 10.889), train_loss = 1.85268503, grad/param norm = 1.7602e-01, time/batch = 0.2900s	
589/2700 (epoch 10.907), train_loss = 1.96352032, grad/param norm = 2.1829e-01, time/batch = 0.2983s	
590/2700 (epoch 10.926), train_loss = 1.90762916, grad/param norm = 2.0814e-01, time/batch = 0.2835s	
591/2700 (epoch 10.944), train_loss = 1.87513781, grad/param norm = 1.6270e-01, time/batch = 0.3091s	
592/2700 (epoch 10.963), train_loss = 1.87778502, grad/param norm = 1.5591e-01, time/batch = 0.3073s	
593/2700 (epoch 10.981), train_loss = 1.83809160, grad/param norm = 1.4305e-01, time/batch = 0.2907s	
decayed learning rate by a factor 0.97 to 0.0018818	
594/2700 (epoch 11.000), train_loss = 1.87515102, grad/param norm = 1.3852e-01, time/batch = 0.2959s	
595/2700 (epoch 11.019), train_loss = 1.88054523, grad/param norm = 1.4131e-01, time/batch = 0.2942s	
596/2700 (epoch 11.037), train_loss = 1.86619576, grad/param norm = 1.3670e-01, time/batch = 0.2967s	
597/2700 (epoch 11.056), train_loss = 1.82214812, grad/param norm = 1.4804e-01, time/batch = 0.3044s	
598/2700 (epoch 11.074), train_loss = 1.78452324, grad/param norm = 1.4519e-01, time/batch = 0.3094s	
599/2700 (epoch 11.093), train_loss = 1.78283013, grad/param norm = 1.3575e-01, time/batch = 0.3045s	
600/2700 (epoch 11.111), train_loss = 1.75749354, grad/param norm = 1.3821e-01, time/batch = 0.2966s	
601/2700 (epoch 11.130), train_loss = 1.81680281, grad/param norm = 1.4429e-01, time/batch = 0.3157s	
602/2700 (epoch 11.148), train_loss = 1.76191293, grad/param norm = 1.5496e-01, time/batch = 0.3149s	
603/2700 (epoch 11.167), train_loss = 1.84557006, grad/param norm = 1.4226e-01, time/batch = 0.2986s	
604/2700 (epoch 11.185), train_loss = 1.76694740, grad/param norm = 1.2066e-01, time/batch = 0.2975s	
605/2700 (epoch 11.204), train_loss = 1.81034579, grad/param norm = 1.1578e-01, time/batch = 0.2917s	
606/2700 (epoch 11.222), train_loss = 1.75116695, grad/param norm = 1.1923e-01, time/batch = 0.2876s	
607/2700 (epoch 11.241), train_loss = 1.66669625, grad/param norm = 1.1375e-01, time/batch = 0.2904s	
608/2700 (epoch 11.259), train_loss = 1.72680563, grad/param norm = 1.3334e-01, time/batch = 0.2982s	
609/2700 (epoch 11.278), train_loss = 1.82330657, grad/param norm = 1.5018e-01, time/batch = 0.3103s	
610/2700 (epoch 11.296), train_loss = 1.81862858, grad/param norm = 1.7451e-01, time/batch = 0.2917s	
611/2700 (epoch 11.315), train_loss = 1.83289311, grad/param norm = 1.8929e-01, time/batch = 0.3091s	
612/2700 (epoch 11.333), train_loss = 1.81323783, grad/param norm = 1.7456e-01, time/batch = 0.3192s	
613/2700 (epoch 11.352), train_loss = 1.81607287, grad/param norm = 1.7513e-01, time/batch = 0.2783s	
614/2700 (epoch 11.370), train_loss = 1.84447405, grad/param norm = 1.7221e-01, time/batch = 0.3025s	
615/2700 (epoch 11.389), train_loss = 1.80936353, grad/param norm = 1.8363e-01, time/batch = 0.2927s	
616/2700 (epoch 11.407), train_loss = 1.81866384, grad/param norm = 1.6062e-01, time/batch = 0.2885s	
617/2700 (epoch 11.426), train_loss = 1.85200137, grad/param norm = 1.4637e-01, time/batch = 0.2892s	
618/2700 (epoch 11.444), train_loss = 1.75381912, grad/param norm = 1.3138e-01, time/batch = 0.2973s	
619/2700 (epoch 11.463), train_loss = 1.83039478, grad/param norm = 1.4989e-01, time/batch = 0.3030s	
620/2700 (epoch 11.481), train_loss = 1.81717970, grad/param norm = 1.3370e-01, time/batch = 0.2995s	
621/2700 (epoch 11.500), train_loss = 1.77724763, grad/param norm = 1.3915e-01, time/batch = 0.3104s	
622/2700 (epoch 11.519), train_loss = 1.78553889, grad/param norm = 1.2587e-01, time/batch = 0.2894s	
623/2700 (epoch 11.537), train_loss = 1.81693381, grad/param norm = 1.4069e-01, time/batch = 0.2890s	
624/2700 (epoch 11.556), train_loss = 1.76923092, grad/param norm = 1.7554e-01, time/batch = 0.2835s	
625/2700 (epoch 11.574), train_loss = 1.77610219, grad/param norm = 1.6789e-01, time/batch = 0.2841s	
626/2700 (epoch 11.593), train_loss = 1.76618393, grad/param norm = 1.4365e-01, time/batch = 0.2871s	
627/2700 (epoch 11.611), train_loss = 1.67991351, grad/param norm = 1.3143e-01, time/batch = 0.2981s	
628/2700 (epoch 11.630), train_loss = 1.72609120, grad/param norm = 1.4676e-01, time/batch = 0.3053s	
629/2700 (epoch 11.648), train_loss = 1.76713190, grad/param norm = 1.4724e-01, time/batch = 0.3132s	
630/2700 (epoch 11.667), train_loss = 1.72749286, grad/param norm = 1.5166e-01, time/batch = 0.3024s	
631/2700 (epoch 11.685), train_loss = 1.76992058, grad/param norm = 1.5980e-01, time/batch = 0.3062s	
632/2700 (epoch 11.704), train_loss = 1.77540054, grad/param norm = 1.7071e-01, time/batch = 0.2713s	
633/2700 (epoch 11.722), train_loss = 1.76204046, grad/param norm = 1.4331e-01, time/batch = 0.2717s	
634/2700 (epoch 11.741), train_loss = 1.76207474, grad/param norm = 1.3354e-01, time/batch = 0.2941s	
635/2700 (epoch 11.759), train_loss = 1.81100225, grad/param norm = 1.4977e-01, time/batch = 0.3045s	
636/2700 (epoch 11.778), train_loss = 1.80965703, grad/param norm = 1.6338e-01, time/batch = 0.3097s	
637/2700 (epoch 11.796), train_loss = 1.76991666, grad/param norm = 1.8640e-01, time/batch = 0.3039s	
638/2700 (epoch 11.815), train_loss = 1.80597007, grad/param norm = 1.7370e-01, time/batch = 0.3062s	
639/2700 (epoch 11.833), train_loss = 1.76283874, grad/param norm = 1.6650e-01, time/batch = 0.3122s	
640/2700 (epoch 11.852), train_loss = 1.76997224, grad/param norm = 1.4818e-01, time/batch = 0.3063s	
641/2700 (epoch 11.870), train_loss = 1.75972409, grad/param norm = 1.2824e-01, time/batch = 0.3172s	
642/2700 (epoch 11.889), train_loss = 1.77342148, grad/param norm = 1.1687e-01, time/batch = 0.3135s	
643/2700 (epoch 11.907), train_loss = 1.86460916, grad/param norm = 1.2185e-01, time/batch = 0.3155s	
644/2700 (epoch 11.926), train_loss = 1.81549753, grad/param norm = 1.3793e-01, time/batch = 0.2438s	
645/2700 (epoch 11.944), train_loss = 1.80569642, grad/param norm = 1.4026e-01, time/batch = 0.3166s	
646/2700 (epoch 11.963), train_loss = 1.81233722, grad/param norm = 1.3470e-01, time/batch = 0.3115s	
647/2700 (epoch 11.981), train_loss = 1.76525944, grad/param norm = 1.3773e-01, time/batch = 0.3061s	
decayed learning rate by a factor 0.97 to 0.001825346	
648/2700 (epoch 12.000), train_loss = 1.81386958, grad/param norm = 1.4447e-01, time/batch = 0.3116s	
649/2700 (epoch 12.019), train_loss = 1.82282966, grad/param norm = 1.4697e-01, time/batch = 0.2924s	
650/2700 (epoch 12.037), train_loss = 1.80459502, grad/param norm = 1.3129e-01, time/batch = 0.2845s	
651/2700 (epoch 12.056), train_loss = 1.75316037, grad/param norm = 1.4230e-01, time/batch = 0.2755s	
652/2700 (epoch 12.074), train_loss = 1.72384425, grad/param norm = 1.4343e-01, time/batch = 0.2711s	
653/2700 (epoch 12.093), train_loss = 1.71088085, grad/param norm = 1.3819e-01, time/batch = 0.2830s	
654/2700 (epoch 12.111), train_loss = 1.69414175, grad/param norm = 1.3697e-01, time/batch = 0.2801s	
655/2700 (epoch 12.130), train_loss = 1.75691439, grad/param norm = 1.3763e-01, time/batch = 0.2654s	
656/2700 (epoch 12.148), train_loss = 1.70066799, grad/param norm = 1.5782e-01, time/batch = 0.3079s	
657/2700 (epoch 12.167), train_loss = 1.79335763, grad/param norm = 1.5239e-01, time/batch = 0.2950s	
658/2700 (epoch 12.185), train_loss = 1.71002069, grad/param norm = 1.3713e-01, time/batch = 0.2855s	
659/2700 (epoch 12.204), train_loss = 1.76272158, grad/param norm = 1.4034e-01, time/batch = 0.2794s	
660/2700 (epoch 12.222), train_loss = 1.70696641, grad/param norm = 1.4017e-01, time/batch = 0.2811s	
661/2700 (epoch 12.241), train_loss = 1.62409903, grad/param norm = 1.4205e-01, time/batch = 0.2905s	
662/2700 (epoch 12.259), train_loss = 1.68079461, grad/param norm = 1.5182e-01, time/batch = 0.2673s	
663/2700 (epoch 12.278), train_loss = 1.76914171, grad/param norm = 1.4552e-01, time/batch = 0.2971s	
664/2700 (epoch 12.296), train_loss = 1.74009937, grad/param norm = 1.4229e-01, time/batch = 0.3025s	
665/2700 (epoch 12.315), train_loss = 1.75138958, grad/param norm = 1.3725e-01, time/batch = 0.3074s	
666/2700 (epoch 12.333), train_loss = 1.73218146, grad/param norm = 1.2537e-01, time/batch = 0.2956s	
667/2700 (epoch 12.352), train_loss = 1.73913976, grad/param norm = 1.5616e-01, time/batch = 0.2923s	
668/2700 (epoch 12.370), train_loss = 1.77351784, grad/param norm = 1.5454e-01, time/batch = 0.2829s	
669/2700 (epoch 12.389), train_loss = 1.72611541, grad/param norm = 1.4228e-01, time/batch = 0.2856s	
670/2700 (epoch 12.407), train_loss = 1.74750934, grad/param norm = 1.4235e-01, time/batch = 0.2735s	
671/2700 (epoch 12.426), train_loss = 1.80663277, grad/param norm = 1.5793e-01, time/batch = 0.2787s	
672/2700 (epoch 12.444), train_loss = 1.70854367, grad/param norm = 1.5753e-01, time/batch = 0.2846s	
673/2700 (epoch 12.463), train_loss = 1.78223787, grad/param norm = 1.6694e-01, time/batch = 0.2908s	
674/2700 (epoch 12.481), train_loss = 1.76039453, grad/param norm = 1.5231e-01, time/batch = 0.3079s	
675/2700 (epoch 12.500), train_loss = 1.72419656, grad/param norm = 1.5965e-01, time/batch = 0.3021s	
676/2700 (epoch 12.519), train_loss = 1.73589081, grad/param norm = 1.4007e-01, time/batch = 0.2946s	
677/2700 (epoch 12.537), train_loss = 1.75803600, grad/param norm = 1.3563e-01, time/batch = 0.3087s	
678/2700 (epoch 12.556), train_loss = 1.68991657, grad/param norm = 1.3885e-01, time/batch = 0.2465s	
679/2700 (epoch 12.574), train_loss = 1.70339720, grad/param norm = 1.5140e-01, time/batch = 0.2977s	
680/2700 (epoch 12.593), train_loss = 1.71248169, grad/param norm = 1.6007e-01, time/batch = 0.2973s	
681/2700 (epoch 12.611), train_loss = 1.63498497, grad/param norm = 1.6249e-01, time/batch = 0.3119s	
682/2700 (epoch 12.630), train_loss = 1.67791962, grad/param norm = 1.6562e-01, time/batch = 0.3104s	
683/2700 (epoch 12.648), train_loss = 1.70704369, grad/param norm = 1.2451e-01, time/batch = 0.3036s	
684/2700 (epoch 12.667), train_loss = 1.65572083, grad/param norm = 1.0493e-01, time/batch = 0.3049s	
685/2700 (epoch 12.685), train_loss = 1.69674101, grad/param norm = 1.2486e-01, time/batch = 0.3039s	
686/2700 (epoch 12.704), train_loss = 1.70991183, grad/param norm = 1.4185e-01, time/batch = 0.2920s	
687/2700 (epoch 12.722), train_loss = 1.69305620, grad/param norm = 1.2457e-01, time/batch = 0.2810s	
688/2700 (epoch 12.741), train_loss = 1.69791817, grad/param norm = 1.2626e-01, time/batch = 0.2814s	
689/2700 (epoch 12.759), train_loss = 1.73848251, grad/param norm = 1.3269e-01, time/batch = 0.2295s	
690/2700 (epoch 12.778), train_loss = 1.74709390, grad/param norm = 1.4468e-01, time/batch = 0.3042s	
691/2700 (epoch 12.796), train_loss = 1.69545482, grad/param norm = 1.5393e-01, time/batch = 0.3114s	
692/2700 (epoch 12.815), train_loss = 1.73634379, grad/param norm = 1.4178e-01, time/batch = 0.2709s	
693/2700 (epoch 12.833), train_loss = 1.69961798, grad/param norm = 1.5073e-01, time/batch = 0.2888s	
694/2700 (epoch 12.852), train_loss = 1.71690663, grad/param norm = 1.7118e-01, time/batch = 0.2808s	
695/2700 (epoch 12.870), train_loss = 1.72679718, grad/param norm = 1.7326e-01, time/batch = 0.2755s	
696/2700 (epoch 12.889), train_loss = 1.73098171, grad/param norm = 1.5105e-01, time/batch = 0.2862s	
697/2700 (epoch 12.907), train_loss = 1.81419650, grad/param norm = 1.4227e-01, time/batch = 0.3011s	
698/2700 (epoch 12.926), train_loss = 1.76147650, grad/param norm = 1.4778e-01, time/batch = 0.3119s	
699/2700 (epoch 12.944), train_loss = 1.74202686, grad/param norm = 1.3693e-01, time/batch = 0.2816s	
700/2700 (epoch 12.963), train_loss = 1.74781434, grad/param norm = 1.2489e-01, time/batch = 0.2996s	
701/2700 (epoch 12.981), train_loss = 1.69261624, grad/param norm = 1.2085e-01, time/batch = 0.3067s	
decayed learning rate by a factor 0.97 to 0.00177058562	
702/2700 (epoch 13.000), train_loss = 1.74712769, grad/param norm = 1.2173e-01, time/batch = 0.2109s	
703/2700 (epoch 13.019), train_loss = 1.75999537, grad/param norm = 1.3136e-01, time/batch = 0.2873s	
704/2700 (epoch 13.037), train_loss = 1.75148607, grad/param norm = 1.3529e-01, time/batch = 0.3096s	
705/2700 (epoch 13.056), train_loss = 1.69150224, grad/param norm = 1.3132e-01, time/batch = 0.3228s	
706/2700 (epoch 13.074), train_loss = 1.66514408, grad/param norm = 1.2742e-01, time/batch = 0.3288s	
707/2700 (epoch 13.093), train_loss = 1.64291320, grad/param norm = 1.1969e-01, time/batch = 0.3273s	
708/2700 (epoch 13.111), train_loss = 1.63616182, grad/param norm = 1.3312e-01, time/batch = 0.3233s	
709/2700 (epoch 13.130), train_loss = 1.70497568, grad/param norm = 1.4986e-01, time/batch = 0.3186s	
710/2700 (epoch 13.148), train_loss = 1.64555917, grad/param norm = 1.4817e-01, time/batch = 0.3176s	
711/2700 (epoch 13.167), train_loss = 1.73126954, grad/param norm = 1.2242e-01, time/batch = 0.3034s	
712/2700 (epoch 13.185), train_loss = 1.64659613, grad/param norm = 1.0983e-01, time/batch = 0.2520s	
713/2700 (epoch 13.204), train_loss = 1.69562236, grad/param norm = 1.0944e-01, time/batch = 0.2967s	
714/2700 (epoch 13.222), train_loss = 1.63951828, grad/param norm = 1.1711e-01, time/batch = 0.3052s	
715/2700 (epoch 13.241), train_loss = 1.56102317, grad/param norm = 1.1706e-01, time/batch = 0.3102s	
716/2700 (epoch 13.259), train_loss = 1.60889754, grad/param norm = 1.2663e-01, time/batch = 0.3171s	
717/2700 (epoch 13.278), train_loss = 1.70413929, grad/param norm = 1.2417e-01, time/batch = 0.3168s	
718/2700 (epoch 13.296), train_loss = 1.68357258, grad/param norm = 1.4328e-01, time/batch = 0.3213s	
719/2700 (epoch 13.315), train_loss = 1.69546191, grad/param norm = 1.6101e-01, time/batch = 0.3187s	
720/2700 (epoch 13.333), train_loss = 1.68411753, grad/param norm = 1.5483e-01, time/batch = 0.3093s	
721/2700 (epoch 13.352), train_loss = 1.68635244, grad/param norm = 1.5449e-01, time/batch = 0.3182s	
722/2700 (epoch 13.370), train_loss = 1.71811447, grad/param norm = 1.6636e-01, time/batch = 0.3001s	
723/2700 (epoch 13.389), train_loss = 1.68827559, grad/param norm = 1.6650e-01, time/batch = 0.2672s	
724/2700 (epoch 13.407), train_loss = 1.70490942, grad/param norm = 1.4065e-01, time/batch = 0.3010s	
725/2700 (epoch 13.426), train_loss = 1.74499678, grad/param norm = 1.4036e-01, time/batch = 0.3099s	
726/2700 (epoch 13.444), train_loss = 1.64874322, grad/param norm = 1.2624e-01, time/batch = 0.3094s	
727/2700 (epoch 13.463), train_loss = 1.71923062, grad/param norm = 1.4308e-01, time/batch = 0.3182s	
728/2700 (epoch 13.481), train_loss = 1.69824365, grad/param norm = 1.3249e-01, time/batch = 0.3230s	
729/2700 (epoch 13.500), train_loss = 1.66010982, grad/param norm = 1.4682e-01, time/batch = 0.3184s	
730/2700 (epoch 13.519), train_loss = 1.69331615, grad/param norm = 1.4092e-01, time/batch = 0.3127s	
731/2700 (epoch 13.537), train_loss = 1.71377740, grad/param norm = 1.6110e-01, time/batch = 0.3211s	
732/2700 (epoch 13.556), train_loss = 1.65388909, grad/param norm = 1.5924e-01, time/batch = 0.2989s	
733/2700 (epoch 13.574), train_loss = 1.65600634, grad/param norm = 1.7402e-01, time/batch = 0.3183s	
734/2700 (epoch 13.593), train_loss = 1.66140085, grad/param norm = 1.6410e-01, time/batch = 0.2486s	
735/2700 (epoch 13.611), train_loss = 1.57302036, grad/param norm = 1.3583e-01, time/batch = 0.3099s	
736/2700 (epoch 13.630), train_loss = 1.60415928, grad/param norm = 1.2618e-01, time/batch = 0.3035s	
737/2700 (epoch 13.648), train_loss = 1.63932043, grad/param norm = 1.1451e-01, time/batch = 0.3204s	
738/2700 (epoch 13.667), train_loss = 1.60656587, grad/param norm = 1.1660e-01, time/batch = 0.3216s	
739/2700 (epoch 13.685), train_loss = 1.64637770, grad/param norm = 1.3662e-01, time/batch = 0.3080s	
740/2700 (epoch 13.704), train_loss = 1.66874118, grad/param norm = 1.5240e-01, time/batch = 0.2959s	
741/2700 (epoch 13.722), train_loss = 1.64865666, grad/param norm = 1.3214e-01, time/batch = 0.3152s	
742/2700 (epoch 13.741), train_loss = 1.63900556, grad/param norm = 1.2167e-01, time/batch = 0.2887s	
743/2700 (epoch 13.759), train_loss = 1.67670289, grad/param norm = 1.2425e-01, time/batch = 0.2851s	
744/2700 (epoch 13.778), train_loss = 1.68759766, grad/param norm = 1.2905e-01, time/batch = 0.2937s	
745/2700 (epoch 13.796), train_loss = 1.62695406, grad/param norm = 1.3489e-01, time/batch = 0.2629s	
746/2700 (epoch 13.815), train_loss = 1.67669572, grad/param norm = 1.3080e-01, time/batch = 0.2823s	
747/2700 (epoch 13.833), train_loss = 1.64488909, grad/param norm = 1.4595e-01, time/batch = 0.2588s	
748/2700 (epoch 13.852), train_loss = 1.66103196, grad/param norm = 1.4955e-01, time/batch = 0.2907s	
749/2700 (epoch 13.870), train_loss = 1.65429866, grad/param norm = 1.2742e-01, time/batch = 0.2876s	
750/2700 (epoch 13.889), train_loss = 1.65946405, grad/param norm = 1.1608e-01, time/batch = 0.2867s	
751/2700 (epoch 13.907), train_loss = 1.75141583, grad/param norm = 1.2131e-01, time/batch = 0.2882s	
752/2700 (epoch 13.926), train_loss = 1.69666966, grad/param norm = 1.3414e-01, time/batch = 0.2850s	
753/2700 (epoch 13.944), train_loss = 1.68710201, grad/param norm = 1.3997e-01, time/batch = 0.2804s	
754/2700 (epoch 13.963), train_loss = 1.70257790, grad/param norm = 1.5334e-01, time/batch = 0.3095s	
755/2700 (epoch 13.981), train_loss = 1.64426897, grad/param norm = 1.4389e-01, time/batch = 0.3069s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
756/2700 (epoch 14.000), train_loss = 1.70406559, grad/param norm = 1.3412e-01, time/batch = 0.2830s	
757/2700 (epoch 14.019), train_loss = 1.71750795, grad/param norm = 1.4545e-01, time/batch = 0.2796s	
758/2700 (epoch 14.037), train_loss = 1.70227176, grad/param norm = 1.4612e-01, time/batch = 0.2820s	
759/2700 (epoch 14.056), train_loss = 1.63715867, grad/param norm = 1.3044e-01, time/batch = 0.2882s	
760/2700 (epoch 14.074), train_loss = 1.60366550, grad/param norm = 1.1657e-01, time/batch = 0.2868s	
761/2700 (epoch 14.093), train_loss = 1.58661347, grad/param norm = 1.2331e-01, time/batch = 0.2904s	
762/2700 (epoch 14.111), train_loss = 1.58762996, grad/param norm = 1.4231e-01, time/batch = 0.2906s	
763/2700 (epoch 14.130), train_loss = 1.65297055, grad/param norm = 1.4733e-01, time/batch = 0.2797s	
764/2700 (epoch 14.148), train_loss = 1.58889887, grad/param norm = 1.3688e-01, time/batch = 0.2962s	
765/2700 (epoch 14.167), train_loss = 1.68006436, grad/param norm = 1.1921e-01, time/batch = 0.3006s	
766/2700 (epoch 14.185), train_loss = 1.59367983, grad/param norm = 1.1151e-01, time/batch = 0.2966s	
767/2700 (epoch 14.204), train_loss = 1.65076982, grad/param norm = 1.2530e-01, time/batch = 0.2980s	
768/2700 (epoch 14.222), train_loss = 1.59550798, grad/param norm = 1.3669e-01, time/batch = 0.2723s	
769/2700 (epoch 14.241), train_loss = 1.51440320, grad/param norm = 1.2222e-01, time/batch = 0.2792s	
770/2700 (epoch 14.259), train_loss = 1.56133040, grad/param norm = 1.2649e-01, time/batch = 0.2823s	
771/2700 (epoch 14.278), train_loss = 1.65946892, grad/param norm = 1.4853e-01, time/batch = 0.2808s	
772/2700 (epoch 14.296), train_loss = 1.63536781, grad/param norm = 1.5717e-01, time/batch = 0.3011s	
773/2700 (epoch 14.315), train_loss = 1.63480624, grad/param norm = 1.4337e-01, time/batch = 0.2673s	
774/2700 (epoch 14.333), train_loss = 1.63048680, grad/param norm = 1.3785e-01, time/batch = 0.3245s	
775/2700 (epoch 14.352), train_loss = 1.63383336, grad/param norm = 1.5728e-01, time/batch = 0.3158s	
776/2700 (epoch 14.370), train_loss = 1.65532416, grad/param norm = 1.4816e-01, time/batch = 0.3025s	
777/2700 (epoch 14.389), train_loss = 1.61703084, grad/param norm = 1.4115e-01, time/batch = 0.3016s	
778/2700 (epoch 14.407), train_loss = 1.64744629, grad/param norm = 1.2598e-01, time/batch = 0.2899s	
779/2700 (epoch 14.426), train_loss = 1.69413635, grad/param norm = 1.3093e-01, time/batch = 0.2841s	
780/2700 (epoch 14.444), train_loss = 1.59592886, grad/param norm = 1.1835e-01, time/batch = 0.3273s	
781/2700 (epoch 14.463), train_loss = 1.66500291, grad/param norm = 1.4205e-01, time/batch = 0.3170s	
782/2700 (epoch 14.481), train_loss = 1.64658077, grad/param norm = 1.4643e-01, time/batch = 0.3124s	
783/2700 (epoch 14.500), train_loss = 1.60811691, grad/param norm = 1.5641e-01, time/batch = 0.2893s	
784/2700 (epoch 14.519), train_loss = 1.63885519, grad/param norm = 1.2849e-01, time/batch = 0.3271s	
785/2700 (epoch 14.537), train_loss = 1.64906955, grad/param norm = 1.2768e-01, time/batch = 0.3249s	
786/2700 (epoch 14.556), train_loss = 1.58467175, grad/param norm = 1.3897e-01, time/batch = 0.3196s	
787/2700 (epoch 14.574), train_loss = 1.58427215, grad/param norm = 1.3984e-01, time/batch = 0.3195s	
788/2700 (epoch 14.593), train_loss = 1.59891297, grad/param norm = 1.3665e-01, time/batch = 0.3120s	
789/2700 (epoch 14.611), train_loss = 1.52583250, grad/param norm = 1.3395e-01, time/batch = 0.3005s	
790/2700 (epoch 14.630), train_loss = 1.56298181, grad/param norm = 1.4261e-01, time/batch = 0.2598s	
791/2700 (epoch 14.648), train_loss = 1.59488947, grad/param norm = 1.2221e-01, time/batch = 0.3134s	
792/2700 (epoch 14.667), train_loss = 1.55794007, grad/param norm = 1.2040e-01, time/batch = 0.3211s	
793/2700 (epoch 14.685), train_loss = 1.59710375, grad/param norm = 1.2328e-01, time/batch = 0.3040s	
794/2700 (epoch 14.704), train_loss = 1.60914098, grad/param norm = 1.3183e-01, time/batch = 0.3111s	
795/2700 (epoch 14.722), train_loss = 1.59426691, grad/param norm = 1.1923e-01, time/batch = 0.3125s	
796/2700 (epoch 14.741), train_loss = 1.57931855, grad/param norm = 1.1695e-01, time/batch = 0.3221s	
797/2700 (epoch 14.759), train_loss = 1.62414030, grad/param norm = 1.2943e-01, time/batch = 0.3214s	
798/2700 (epoch 14.778), train_loss = 1.64061164, grad/param norm = 1.3397e-01, time/batch = 0.3110s	
799/2700 (epoch 14.796), train_loss = 1.58417194, grad/param norm = 1.5054e-01, time/batch = 0.2978s	
800/2700 (epoch 14.815), train_loss = 1.62986732, grad/param norm = 1.4049e-01, time/batch = 0.2939s	
801/2700 (epoch 14.833), train_loss = 1.59057634, grad/param norm = 1.3156e-01, time/batch = 0.2583s	
802/2700 (epoch 14.852), train_loss = 1.60208546, grad/param norm = 1.3673e-01, time/batch = 0.3273s	
803/2700 (epoch 14.870), train_loss = 1.60376615, grad/param norm = 1.3247e-01, time/batch = 0.3049s	
804/2700 (epoch 14.889), train_loss = 1.61105391, grad/param norm = 1.3429e-01, time/batch = 0.2878s	
805/2700 (epoch 14.907), train_loss = 1.70058845, grad/param norm = 1.3347e-01, time/batch = 0.3179s	
806/2700 (epoch 14.926), train_loss = 1.64851878, grad/param norm = 1.3798e-01, time/batch = 0.3186s	
807/2700 (epoch 14.944), train_loss = 1.63497178, grad/param norm = 1.4785e-01, time/batch = 0.3072s	
808/2700 (epoch 14.963), train_loss = 1.64900211, grad/param norm = 1.4381e-01, time/batch = 0.2929s	
809/2700 (epoch 14.981), train_loss = 1.58394310, grad/param norm = 1.3889e-01, time/batch = 0.2984s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
810/2700 (epoch 15.000), train_loss = 1.64822246, grad/param norm = 1.2939e-01, time/batch = 0.2979s	
811/2700 (epoch 15.019), train_loss = 1.66055802, grad/param norm = 1.2448e-01, time/batch = 0.2921s	
812/2700 (epoch 15.037), train_loss = 1.64581139, grad/param norm = 1.2288e-01, time/batch = 0.2757s	
813/2700 (epoch 15.056), train_loss = 1.58938113, grad/param norm = 1.4115e-01, time/batch = 0.3235s	
814/2700 (epoch 15.074), train_loss = 1.56549540, grad/param norm = 1.3498e-01, time/batch = 0.3092s	
815/2700 (epoch 15.093), train_loss = 1.53400068, grad/param norm = 1.2914e-01, time/batch = 0.3006s	
816/2700 (epoch 15.111), train_loss = 1.53422529, grad/param norm = 1.3319e-01, time/batch = 0.2894s	
817/2700 (epoch 15.130), train_loss = 1.59585175, grad/param norm = 1.3501e-01, time/batch = 0.2789s	
818/2700 (epoch 15.148), train_loss = 1.53493885, grad/param norm = 1.2610e-01, time/batch = 0.2860s	
819/2700 (epoch 15.167), train_loss = 1.63870943, grad/param norm = 1.3308e-01, time/batch = 0.2846s	
820/2700 (epoch 15.185), train_loss = 1.56508880, grad/param norm = 1.4557e-01, time/batch = 0.2926s	
821/2700 (epoch 15.204), train_loss = 1.61641215, grad/param norm = 1.5435e-01, time/batch = 0.2980s	
822/2700 (epoch 15.222), train_loss = 1.54759230, grad/param norm = 1.3385e-01, time/batch = 0.3067s	
823/2700 (epoch 15.241), train_loss = 1.48109179, grad/param norm = 1.6099e-01, time/batch = 0.2525s	
824/2700 (epoch 15.259), train_loss = 1.53222033, grad/param norm = 1.6417e-01, time/batch = 0.2387s	
825/2700 (epoch 15.278), train_loss = 1.60953106, grad/param norm = 1.3507e-01, time/batch = 0.2969s	
826/2700 (epoch 15.296), train_loss = 1.58507785, grad/param norm = 1.4458e-01, time/batch = 0.3003s	
827/2700 (epoch 15.315), train_loss = 1.57814699, grad/param norm = 1.4908e-01, time/batch = 0.2994s	
828/2700 (epoch 15.333), train_loss = 1.57968347, grad/param norm = 1.4427e-01, time/batch = 0.3075s	
829/2700 (epoch 15.352), train_loss = 1.57400760, grad/param norm = 1.3207e-01, time/batch = 0.3132s	
830/2700 (epoch 15.370), train_loss = 1.58969405, grad/param norm = 1.3222e-01, time/batch = 0.3155s	
831/2700 (epoch 15.389), train_loss = 1.55182614, grad/param norm = 1.2107e-01, time/batch = 0.2974s	
832/2700 (epoch 15.407), train_loss = 1.59395835, grad/param norm = 1.0898e-01, time/batch = 0.2960s	
833/2700 (epoch 15.426), train_loss = 1.63781029, grad/param norm = 1.1761e-01, time/batch = 0.3001s	
834/2700 (epoch 15.444), train_loss = 1.54308367, grad/param norm = 1.0252e-01, time/batch = 0.2789s	
835/2700 (epoch 15.463), train_loss = 1.61062866, grad/param norm = 1.2693e-01, time/batch = 0.2748s	
836/2700 (epoch 15.481), train_loss = 1.59349000, grad/param norm = 1.3791e-01, time/batch = 0.2987s	
837/2700 (epoch 15.500), train_loss = 1.56811725, grad/param norm = 1.9185e-01, time/batch = 0.3103s	
838/2700 (epoch 15.519), train_loss = 1.61510417, grad/param norm = 1.4882e-01, time/batch = 0.3201s	
839/2700 (epoch 15.537), train_loss = 1.61245668, grad/param norm = 1.5120e-01, time/batch = 0.3228s	
840/2700 (epoch 15.556), train_loss = 1.54282632, grad/param norm = 1.4188e-01, time/batch = 0.3195s	
841/2700 (epoch 15.574), train_loss = 1.53716285, grad/param norm = 1.5116e-01, time/batch = 0.3180s	
842/2700 (epoch 15.593), train_loss = 1.55504709, grad/param norm = 1.4143e-01, time/batch = 0.2877s	
843/2700 (epoch 15.611), train_loss = 1.47535458, grad/param norm = 1.2250e-01, time/batch = 0.3244s	
844/2700 (epoch 15.630), train_loss = 1.50363130, grad/param norm = 1.2436e-01, time/batch = 0.3014s	
845/2700 (epoch 15.648), train_loss = 1.54839750, grad/param norm = 1.3742e-01, time/batch = 0.3213s	
846/2700 (epoch 15.667), train_loss = 1.52925896, grad/param norm = 1.4440e-01, time/batch = 0.2595s	
847/2700 (epoch 15.685), train_loss = 1.56039013, grad/param norm = 1.4445e-01, time/batch = 0.3047s	
848/2700 (epoch 15.704), train_loss = 1.56340211, grad/param norm = 1.2872e-01, time/batch = 0.3116s	
849/2700 (epoch 15.722), train_loss = 1.54988809, grad/param norm = 1.2280e-01, time/batch = 0.3170s	
850/2700 (epoch 15.741), train_loss = 1.53226170, grad/param norm = 1.4960e-01, time/batch = 0.3193s	
851/2700 (epoch 15.759), train_loss = 1.58517377, grad/param norm = 1.6015e-01, time/batch = 0.3230s	
852/2700 (epoch 15.778), train_loss = 1.61063858, grad/param norm = 1.5761e-01, time/batch = 0.3300s	
853/2700 (epoch 15.796), train_loss = 1.53317977, grad/param norm = 1.4815e-01, time/batch = 0.3258s	
854/2700 (epoch 15.815), train_loss = 1.57423331, grad/param norm = 1.3115e-01, time/batch = 0.3054s	
855/2700 (epoch 15.833), train_loss = 1.54714231, grad/param norm = 1.3605e-01, time/batch = 0.3142s	
856/2700 (epoch 15.852), train_loss = 1.55612767, grad/param norm = 1.3463e-01, time/batch = 0.3154s	
857/2700 (epoch 15.870), train_loss = 1.55051401, grad/param norm = 1.1802e-01, time/batch = 0.2493s	
858/2700 (epoch 15.889), train_loss = 1.56190904, grad/param norm = 1.2758e-01, time/batch = 0.3101s	
859/2700 (epoch 15.907), train_loss = 1.66245236, grad/param norm = 1.6651e-01, time/batch = 0.3177s	
860/2700 (epoch 15.926), train_loss = 1.61439342, grad/param norm = 1.7479e-01, time/batch = 0.3195s	
861/2700 (epoch 15.944), train_loss = 1.58766279, grad/param norm = 1.5149e-01, time/batch = 0.3314s	
862/2700 (epoch 15.963), train_loss = 1.59964015, grad/param norm = 1.5219e-01, time/batch = 0.3266s	
863/2700 (epoch 15.981), train_loss = 1.52867084, grad/param norm = 1.3536e-01, time/batch = 0.3247s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
864/2700 (epoch 16.000), train_loss = 1.60178110, grad/param norm = 1.2896e-01, time/batch = 0.3187s	
865/2700 (epoch 16.019), train_loss = 1.61676687, grad/param norm = 1.2530e-01, time/batch = 0.2691s	
866/2700 (epoch 16.037), train_loss = 1.59467495, grad/param norm = 1.2725e-01, time/batch = 0.2574s	
867/2700 (epoch 16.056), train_loss = 1.53169230, grad/param norm = 1.2603e-01, time/batch = 0.2961s	
868/2700 (epoch 16.074), train_loss = 1.50943987, grad/param norm = 1.2330e-01, time/batch = 0.2401s	
869/2700 (epoch 16.093), train_loss = 1.48165200, grad/param norm = 1.3334e-01, time/batch = 0.2989s	
870/2700 (epoch 16.111), train_loss = 1.48679925, grad/param norm = 1.3652e-01, time/batch = 0.3066s	
871/2700 (epoch 16.130), train_loss = 1.54912662, grad/param norm = 1.3787e-01, time/batch = 0.3271s	
872/2700 (epoch 16.148), train_loss = 1.49101991, grad/param norm = 1.3612e-01, time/batch = 0.3255s	
873/2700 (epoch 16.167), train_loss = 1.58970690, grad/param norm = 1.2305e-01, time/batch = 0.3166s	
874/2700 (epoch 16.185), train_loss = 1.50327077, grad/param norm = 1.1724e-01, time/batch = 0.3147s	
875/2700 (epoch 16.204), train_loss = 1.55607597, grad/param norm = 1.2850e-01, time/batch = 0.3110s	
876/2700 (epoch 16.222), train_loss = 1.49995667, grad/param norm = 1.3627e-01, time/batch = 0.2958s	
877/2700 (epoch 16.241), train_loss = 1.43462123, grad/param norm = 1.4910e-01, time/batch = 0.2907s	
878/2700 (epoch 16.259), train_loss = 1.46892437, grad/param norm = 1.2548e-01, time/batch = 0.2822s	
879/2700 (epoch 16.278), train_loss = 1.55555497, grad/param norm = 1.2469e-01, time/batch = 0.2257s	
880/2700 (epoch 16.296), train_loss = 1.53684135, grad/param norm = 1.5575e-01, time/batch = 0.3091s	
881/2700 (epoch 16.315), train_loss = 1.51827420, grad/param norm = 1.3231e-01, time/batch = 0.3260s	
882/2700 (epoch 16.333), train_loss = 1.53139179, grad/param norm = 1.4497e-01, time/batch = 0.3230s	
883/2700 (epoch 16.352), train_loss = 1.53264489, grad/param norm = 1.4982e-01, time/batch = 0.3151s	
884/2700 (epoch 16.370), train_loss = 1.54077185, grad/param norm = 1.4481e-01, time/batch = 0.3155s	
885/2700 (epoch 16.389), train_loss = 1.50773489, grad/param norm = 1.3178e-01, time/batch = 0.3113s	
886/2700 (epoch 16.407), train_loss = 1.55918086, grad/param norm = 1.3347e-01, time/batch = 0.2919s	
887/2700 (epoch 16.426), train_loss = 1.60617916, grad/param norm = 1.5125e-01, time/batch = 0.2945s	
888/2700 (epoch 16.444), train_loss = 1.50649824, grad/param norm = 1.2193e-01, time/batch = 0.2906s	
889/2700 (epoch 16.463), train_loss = 1.56081825, grad/param norm = 1.3167e-01, time/batch = 0.2510s	
890/2700 (epoch 16.481), train_loss = 1.53613552, grad/param norm = 1.2906e-01, time/batch = 0.2803s	
891/2700 (epoch 16.500), train_loss = 1.49737065, grad/param norm = 1.3785e-01, time/batch = 0.3271s	
892/2700 (epoch 16.519), train_loss = 1.56214846, grad/param norm = 1.5931e-01, time/batch = 0.3308s	
893/2700 (epoch 16.537), train_loss = 1.57462091, grad/param norm = 1.6006e-01, time/batch = 0.3285s	
894/2700 (epoch 16.556), train_loss = 1.49562901, grad/param norm = 1.4708e-01, time/batch = 0.3164s	
895/2700 (epoch 16.574), train_loss = 1.48160400, grad/param norm = 1.4626e-01, time/batch = 0.3147s	
896/2700 (epoch 16.593), train_loss = 1.51359168, grad/param norm = 1.4558e-01, time/batch = 0.2978s	
897/2700 (epoch 16.611), train_loss = 1.43832356, grad/param norm = 1.3241e-01, time/batch = 0.2981s	
898/2700 (epoch 16.630), train_loss = 1.46190717, grad/param norm = 1.2943e-01, time/batch = 0.2852s	
899/2700 (epoch 16.648), train_loss = 1.49753160, grad/param norm = 1.2466e-01, time/batch = 0.2911s	
900/2700 (epoch 16.667), train_loss = 1.47680121, grad/param norm = 1.2452e-01, time/batch = 0.2906s	
901/2700 (epoch 16.685), train_loss = 1.51623872, grad/param norm = 1.3705e-01, time/batch = 0.2581s	
902/2700 (epoch 16.704), train_loss = 1.53585059, grad/param norm = 1.6789e-01, time/batch = 0.3157s	
903/2700 (epoch 16.722), train_loss = 1.51370931, grad/param norm = 1.2806e-01, time/batch = 0.3149s	
904/2700 (epoch 16.741), train_loss = 1.48886364, grad/param norm = 1.3735e-01, time/batch = 0.3179s	
905/2700 (epoch 16.759), train_loss = 1.52682285, grad/param norm = 1.4797e-01, time/batch = 0.3107s	
906/2700 (epoch 16.778), train_loss = 1.54699752, grad/param norm = 1.3705e-01, time/batch = 0.2959s	
907/2700 (epoch 16.796), train_loss = 1.47964770, grad/param norm = 1.2720e-01, time/batch = 0.2762s	
908/2700 (epoch 16.815), train_loss = 1.52045105, grad/param norm = 1.3050e-01, time/batch = 0.2814s	
909/2700 (epoch 16.833), train_loss = 1.51251907, grad/param norm = 1.6281e-01, time/batch = 0.2848s	
910/2700 (epoch 16.852), train_loss = 1.51979508, grad/param norm = 1.5123e-01, time/batch = 0.2870s	
911/2700 (epoch 16.870), train_loss = 1.51299155, grad/param norm = 1.3836e-01, time/batch = 0.2963s	
912/2700 (epoch 16.889), train_loss = 1.52242800, grad/param norm = 1.4511e-01, time/batch = 0.2882s	
913/2700 (epoch 16.907), train_loss = 1.61797740, grad/param norm = 1.7725e-01, time/batch = 0.3224s	
914/2700 (epoch 16.926), train_loss = 1.55967647, grad/param norm = 1.4706e-01, time/batch = 0.3142s	
915/2700 (epoch 16.944), train_loss = 1.52858115, grad/param norm = 1.3091e-01, time/batch = 0.2982s	
916/2700 (epoch 16.963), train_loss = 1.53269137, grad/param norm = 1.2533e-01, time/batch = 0.2885s	
917/2700 (epoch 16.981), train_loss = 1.47271858, grad/param norm = 1.2031e-01, time/batch = 0.2454s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
918/2700 (epoch 17.000), train_loss = 1.54814485, grad/param norm = 1.3072e-01, time/batch = 0.3012s	
919/2700 (epoch 17.019), train_loss = 1.57734980, grad/param norm = 1.3353e-01, time/batch = 0.3049s	
920/2700 (epoch 17.037), train_loss = 1.55145964, grad/param norm = 1.3224e-01, time/batch = 0.2993s	
921/2700 (epoch 17.056), train_loss = 1.48664848, grad/param norm = 1.3122e-01, time/batch = 0.3051s	
922/2700 (epoch 17.074), train_loss = 1.46058404, grad/param norm = 1.2255e-01, time/batch = 0.3113s	
923/2700 (epoch 17.093), train_loss = 1.43078410, grad/param norm = 1.2873e-01, time/batch = 0.2932s	
924/2700 (epoch 17.111), train_loss = 1.44145450, grad/param norm = 1.2954e-01, time/batch = 0.2861s	
925/2700 (epoch 17.130), train_loss = 1.49754546, grad/param norm = 1.3114e-01, time/batch = 0.2806s	
926/2700 (epoch 17.148), train_loss = 1.43894551, grad/param norm = 1.2718e-01, time/batch = 0.2807s	
927/2700 (epoch 17.167), train_loss = 1.54802322, grad/param norm = 1.3341e-01, time/batch = 0.2473s	
928/2700 (epoch 17.185), train_loss = 1.46567251, grad/param norm = 1.2919e-01, time/batch = 0.2989s	
929/2700 (epoch 17.204), train_loss = 1.51579788, grad/param norm = 1.3705e-01, time/batch = 0.3061s	
930/2700 (epoch 17.222), train_loss = 1.45576145, grad/param norm = 1.4260e-01, time/batch = 0.3072s	
931/2700 (epoch 17.241), train_loss = 1.39687407, grad/param norm = 1.5229e-01, time/batch = 0.3158s	
932/2700 (epoch 17.259), train_loss = 1.43724097, grad/param norm = 1.4098e-01, time/batch = 0.3166s	
933/2700 (epoch 17.278), train_loss = 1.52332965, grad/param norm = 1.6233e-01, time/batch = 0.3107s	
934/2700 (epoch 17.296), train_loss = 1.49200373, grad/param norm = 1.5272e-01, time/batch = 0.3127s	
935/2700 (epoch 17.315), train_loss = 1.47258454, grad/param norm = 1.3929e-01, time/batch = 0.2761s	
936/2700 (epoch 17.333), train_loss = 1.49372617, grad/param norm = 1.6097e-01, time/batch = 0.2878s	
937/2700 (epoch 17.352), train_loss = 1.49688423, grad/param norm = 1.7358e-01, time/batch = 0.2464s	
938/2700 (epoch 17.370), train_loss = 1.49671798, grad/param norm = 1.4429e-01, time/batch = 0.3084s	
939/2700 (epoch 17.389), train_loss = 1.45275788, grad/param norm = 1.2674e-01, time/batch = 0.3129s	
940/2700 (epoch 17.407), train_loss = 1.51522695, grad/param norm = 1.3209e-01, time/batch = 0.3166s	
941/2700 (epoch 17.426), train_loss = 1.55654787, grad/param norm = 1.4222e-01, time/batch = 0.3060s	
942/2700 (epoch 17.444), train_loss = 1.46059907, grad/param norm = 1.2659e-01, time/batch = 0.3053s	
943/2700 (epoch 17.463), train_loss = 1.52062145, grad/param norm = 1.5483e-01, time/batch = 0.3093s	
944/2700 (epoch 17.481), train_loss = 1.49146021, grad/param norm = 1.4822e-01, time/batch = 0.3078s	
945/2700 (epoch 17.500), train_loss = 1.44740701, grad/param norm = 1.4117e-01, time/batch = 0.2853s	
946/2700 (epoch 17.519), train_loss = 1.52139929, grad/param norm = 1.5596e-01, time/batch = 0.2381s	
947/2700 (epoch 17.537), train_loss = 1.51834683, grad/param norm = 1.4792e-01, time/batch = 0.2481s	
948/2700 (epoch 17.556), train_loss = 1.44622476, grad/param norm = 1.3601e-01, time/batch = 0.3029s	
949/2700 (epoch 17.574), train_loss = 1.43427993, grad/param norm = 1.4448e-01, time/batch = 0.2986s	
950/2700 (epoch 17.593), train_loss = 1.47246833, grad/param norm = 1.5775e-01, time/batch = 0.2976s	
951/2700 (epoch 17.611), train_loss = 1.39854983, grad/param norm = 1.3367e-01, time/batch = 0.3045s	
952/2700 (epoch 17.630), train_loss = 1.41498981, grad/param norm = 1.2774e-01, time/batch = 0.2937s	
953/2700 (epoch 17.648), train_loss = 1.45161582, grad/param norm = 1.2727e-01, time/batch = 0.2934s	
954/2700 (epoch 17.667), train_loss = 1.43670395, grad/param norm = 1.3684e-01, time/batch = 0.2910s	
955/2700 (epoch 17.685), train_loss = 1.46974365, grad/param norm = 1.3925e-01, time/batch = 0.2702s	
956/2700 (epoch 17.704), train_loss = 1.47964465, grad/param norm = 1.3950e-01, time/batch = 0.3179s	
957/2700 (epoch 17.722), train_loss = 1.47951999, grad/param norm = 1.4573e-01, time/batch = 0.2934s	
958/2700 (epoch 17.741), train_loss = 1.44070504, grad/param norm = 1.4974e-01, time/batch = 0.3102s	
959/2700 (epoch 17.759), train_loss = 1.47649638, grad/param norm = 1.4686e-01, time/batch = 0.2983s	
960/2700 (epoch 17.778), train_loss = 1.51195761, grad/param norm = 1.4789e-01, time/batch = 0.2952s	
961/2700 (epoch 17.796), train_loss = 1.43996645, grad/param norm = 1.4679e-01, time/batch = 0.3040s	
962/2700 (epoch 17.815), train_loss = 1.48111218, grad/param norm = 1.3435e-01, time/batch = 0.2907s	
963/2700 (epoch 17.833), train_loss = 1.45603067, grad/param norm = 1.4075e-01, time/batch = 0.2847s	
964/2700 (epoch 17.852), train_loss = 1.46746284, grad/param norm = 1.4404e-01, time/batch = 0.2774s	
965/2700 (epoch 17.870), train_loss = 1.46895347, grad/param norm = 1.3813e-01, time/batch = 0.2973s	
966/2700 (epoch 17.889), train_loss = 1.46722569, grad/param norm = 1.3309e-01, time/batch = 0.3129s	
967/2700 (epoch 17.907), train_loss = 1.55643352, grad/param norm = 1.3646e-01, time/batch = 0.3173s	
968/2700 (epoch 17.926), train_loss = 1.50444322, grad/param norm = 1.4537e-01, time/batch = 0.2634s	
969/2700 (epoch 17.944), train_loss = 1.48192798, grad/param norm = 1.3987e-01, time/batch = 0.2858s	
970/2700 (epoch 17.963), train_loss = 1.48163193, grad/param norm = 1.2827e-01, time/batch = 0.2960s	
971/2700 (epoch 17.981), train_loss = 1.43130467, grad/param norm = 1.4185e-01, time/batch = 0.2930s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
972/2700 (epoch 18.000), train_loss = 1.50734901, grad/param norm = 1.3989e-01, time/batch = 0.2910s	
973/2700 (epoch 18.019), train_loss = 1.53756066, grad/param norm = 1.3523e-01, time/batch = 0.3020s	
974/2700 (epoch 18.037), train_loss = 1.51158307, grad/param norm = 1.3518e-01, time/batch = 0.3190s	
975/2700 (epoch 18.056), train_loss = 1.44815547, grad/param norm = 1.5784e-01, time/batch = 0.3121s	
976/2700 (epoch 18.074), train_loss = 1.43162522, grad/param norm = 1.5343e-01, time/batch = 0.3087s	
977/2700 (epoch 18.093), train_loss = 1.40040087, grad/param norm = 1.8353e-01, time/batch = 0.3181s	
978/2700 (epoch 18.111), train_loss = 1.41027438, grad/param norm = 1.5642e-01, time/batch = 0.3064s	
979/2700 (epoch 18.130), train_loss = 1.46045312, grad/param norm = 1.4510e-01, time/batch = 0.3194s	
980/2700 (epoch 18.148), train_loss = 1.40164099, grad/param norm = 1.4786e-01, time/batch = 0.2573s	
981/2700 (epoch 18.167), train_loss = 1.50766911, grad/param norm = 1.3853e-01, time/batch = 0.3094s	
982/2700 (epoch 18.185), train_loss = 1.42757118, grad/param norm = 1.3945e-01, time/batch = 0.3200s	
983/2700 (epoch 18.204), train_loss = 1.47411422, grad/param norm = 1.4458e-01, time/batch = 0.2905s	
984/2700 (epoch 18.222), train_loss = 1.40937917, grad/param norm = 1.4120e-01, time/batch = 0.3212s	
985/2700 (epoch 18.241), train_loss = 1.34864754, grad/param norm = 1.4586e-01, time/batch = 0.3188s	
986/2700 (epoch 18.259), train_loss = 1.38616292, grad/param norm = 1.2780e-01, time/batch = 0.3125s	
987/2700 (epoch 18.278), train_loss = 1.46812319, grad/param norm = 1.4498e-01, time/batch = 0.3206s	
988/2700 (epoch 18.296), train_loss = 1.43915606, grad/param norm = 1.4984e-01, time/batch = 0.3124s	
989/2700 (epoch 18.315), train_loss = 1.42004956, grad/param norm = 1.4358e-01, time/batch = 0.3203s	
990/2700 (epoch 18.333), train_loss = 1.45058674, grad/param norm = 1.7737e-01, time/batch = 0.3163s	
991/2700 (epoch 18.352), train_loss = 1.44761140, grad/param norm = 1.4403e-01, time/batch = 0.2893s	
992/2700 (epoch 18.370), train_loss = 1.44862148, grad/param norm = 1.6096e-01, time/batch = 0.2690s	
993/2700 (epoch 18.389), train_loss = 1.41997542, grad/param norm = 1.6953e-01, time/batch = 0.3006s	
994/2700 (epoch 18.407), train_loss = 1.49036271, grad/param norm = 1.6425e-01, time/batch = 0.3058s	
995/2700 (epoch 18.426), train_loss = 1.52812981, grad/param norm = 1.4663e-01, time/batch = 0.3155s	
996/2700 (epoch 18.444), train_loss = 1.44462037, grad/param norm = 1.6081e-01, time/batch = 0.3125s	
997/2700 (epoch 18.463), train_loss = 1.48377489, grad/param norm = 1.5429e-01, time/batch = 0.3141s	
998/2700 (epoch 18.481), train_loss = 1.44755596, grad/param norm = 1.5327e-01, time/batch = 0.3107s	
999/2700 (epoch 18.500), train_loss = 1.41300716, grad/param norm = 1.5083e-01, time/batch = 0.3276s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch18.52_1.7279.t7	
1000/2700 (epoch 18.519), train_loss = 1.45893774, grad/param norm = 1.3376e-01, time/batch = 0.3196s	
1001/2700 (epoch 18.537), train_loss = 1.62376969, grad/param norm = 1.4178e-01, time/batch = 0.2891s	
1002/2700 (epoch 18.556), train_loss = 1.41659915, grad/param norm = 1.5017e-01, time/batch = 0.2779s	
1003/2700 (epoch 18.574), train_loss = 1.38939480, grad/param norm = 1.4286e-01, time/batch = 0.2924s	
1004/2700 (epoch 18.593), train_loss = 1.42477970, grad/param norm = 1.3913e-01, time/batch = 0.3058s	
1005/2700 (epoch 18.611), train_loss = 1.35193623, grad/param norm = 1.2042e-01, time/batch = 0.2908s	
1006/2700 (epoch 18.630), train_loss = 1.37379090, grad/param norm = 1.3070e-01, time/batch = 0.2816s	
1007/2700 (epoch 18.648), train_loss = 1.41872754, grad/param norm = 1.5254e-01, time/batch = 0.3174s	
1008/2700 (epoch 18.667), train_loss = 1.40171920, grad/param norm = 1.4732e-01, time/batch = 0.2999s	
1009/2700 (epoch 18.685), train_loss = 1.42643714, grad/param norm = 1.3064e-01, time/batch = 0.2982s	
1010/2700 (epoch 18.704), train_loss = 1.43777699, grad/param norm = 1.4230e-01, time/batch = 0.2927s	
1011/2700 (epoch 18.722), train_loss = 1.42899026, grad/param norm = 1.2217e-01, time/batch = 0.2648s	
1012/2700 (epoch 18.741), train_loss = 1.38509910, grad/param norm = 1.2773e-01, time/batch = 0.3119s	
1013/2700 (epoch 18.759), train_loss = 1.42993236, grad/param norm = 1.6735e-01, time/batch = 0.3251s	
1014/2700 (epoch 18.778), train_loss = 1.46982065, grad/param norm = 1.5748e-01, time/batch = 0.3197s	
1015/2700 (epoch 18.796), train_loss = 1.40069902, grad/param norm = 1.5317e-01, time/batch = 0.3147s	
1016/2700 (epoch 18.815), train_loss = 1.43763936, grad/param norm = 1.3788e-01, time/batch = 0.3062s	
1017/2700 (epoch 18.833), train_loss = 1.41125612, grad/param norm = 1.5059e-01, time/batch = 0.3274s	
1018/2700 (epoch 18.852), train_loss = 1.41845301, grad/param norm = 1.3455e-01, time/batch = 0.3187s	
1019/2700 (epoch 18.870), train_loss = 1.42102461, grad/param norm = 1.3193e-01, time/batch = 0.3198s	
1020/2700 (epoch 18.889), train_loss = 1.41705433, grad/param norm = 1.2798e-01, time/batch = 0.3210s	
1021/2700 (epoch 18.907), train_loss = 1.50889261, grad/param norm = 1.4940e-01, time/batch = 0.3212s	
1022/2700 (epoch 18.926), train_loss = 1.45560556, grad/param norm = 1.4948e-01, time/batch = 0.2892s	
1023/2700 (epoch 18.944), train_loss = 1.44037044, grad/param norm = 1.5343e-01, time/batch = 0.3068s	
1024/2700 (epoch 18.963), train_loss = 1.44804858, grad/param norm = 1.5807e-01, time/batch = 0.2973s	
1025/2700 (epoch 18.981), train_loss = 1.38234962, grad/param norm = 1.4531e-01, time/batch = 0.3029s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1026/2700 (epoch 19.000), train_loss = 1.46062510, grad/param norm = 1.4218e-01, time/batch = 0.2881s	
1027/2700 (epoch 19.019), train_loss = 1.49630250, grad/param norm = 1.3965e-01, time/batch = 0.3142s	
1028/2700 (epoch 19.037), train_loss = 1.47108622, grad/param norm = 1.4541e-01, time/batch = 0.3179s	
1029/2700 (epoch 19.056), train_loss = 1.39285402, grad/param norm = 1.3495e-01, time/batch = 0.3206s	
1030/2700 (epoch 19.074), train_loss = 1.37914397, grad/param norm = 1.3965e-01, time/batch = 0.3212s	
1031/2700 (epoch 19.093), train_loss = 1.34397782, grad/param norm = 1.4944e-01, time/batch = 0.3298s	
1032/2700 (epoch 19.111), train_loss = 1.37067400, grad/param norm = 1.6315e-01, time/batch = 0.3197s	
1033/2700 (epoch 19.130), train_loss = 1.42559287, grad/param norm = 1.5987e-01, time/batch = 0.3001s	
1034/2700 (epoch 19.148), train_loss = 1.36216228, grad/param norm = 1.5013e-01, time/batch = 0.2852s	
1035/2700 (epoch 19.167), train_loss = 1.45768425, grad/param norm = 1.3657e-01, time/batch = 0.2900s	
1036/2700 (epoch 19.185), train_loss = 1.38479424, grad/param norm = 1.3658e-01, time/batch = 0.2836s	
1037/2700 (epoch 19.204), train_loss = 1.43170960, grad/param norm = 1.4471e-01, time/batch = 0.3111s	
1038/2700 (epoch 19.222), train_loss = 1.36289728, grad/param norm = 1.4209e-01, time/batch = 0.3147s	
1039/2700 (epoch 19.241), train_loss = 1.30500237, grad/param norm = 1.3963e-01, time/batch = 0.3200s	
1040/2700 (epoch 19.259), train_loss = 1.34796576, grad/param norm = 1.2762e-01, time/batch = 0.3200s	
1041/2700 (epoch 19.278), train_loss = 1.42141146, grad/param norm = 1.4223e-01, time/batch = 0.3270s	
1042/2700 (epoch 19.296), train_loss = 1.38937039, grad/param norm = 1.3870e-01, time/batch = 0.3215s	
1043/2700 (epoch 19.315), train_loss = 1.37299535, grad/param norm = 1.6089e-01, time/batch = 0.3108s	
1044/2700 (epoch 19.333), train_loss = 1.41623251, grad/param norm = 2.1036e-01, time/batch = 0.2874s	
1045/2700 (epoch 19.352), train_loss = 1.40869079, grad/param norm = 1.6382e-01, time/batch = 0.2604s	
1046/2700 (epoch 19.370), train_loss = 1.39606299, grad/param norm = 1.3344e-01, time/batch = 0.2878s	
1047/2700 (epoch 19.389), train_loss = 1.36726427, grad/param norm = 1.4773e-01, time/batch = 0.3019s	
1048/2700 (epoch 19.407), train_loss = 1.45144308, grad/param norm = 1.6416e-01, time/batch = 0.3080s	
1049/2700 (epoch 19.426), train_loss = 1.47838238, grad/param norm = 1.5213e-01, time/batch = 0.3097s	
1050/2700 (epoch 19.444), train_loss = 1.38890767, grad/param norm = 1.2897e-01, time/batch = 0.3044s	
1051/2700 (epoch 19.463), train_loss = 1.42983841, grad/param norm = 1.3852e-01, time/batch = 0.3222s	
1052/2700 (epoch 19.481), train_loss = 1.39341340, grad/param norm = 1.4570e-01, time/batch = 0.3258s	
1053/2700 (epoch 19.500), train_loss = 1.35143052, grad/param norm = 1.3152e-01, time/batch = 0.3245s	
1054/2700 (epoch 19.519), train_loss = 1.41070807, grad/param norm = 1.2568e-01, time/batch = 0.3166s	
1055/2700 (epoch 19.537), train_loss = 1.43043835, grad/param norm = 1.5667e-01, time/batch = 0.2875s	
1056/2700 (epoch 19.556), train_loss = 1.36457671, grad/param norm = 1.4643e-01, time/batch = 0.2835s	
1057/2700 (epoch 19.574), train_loss = 1.34087940, grad/param norm = 1.4338e-01, time/batch = 0.2895s	
1058/2700 (epoch 19.593), train_loss = 1.38562001, grad/param norm = 1.5464e-01, time/batch = 0.3009s	
1059/2700 (epoch 19.611), train_loss = 1.32129430, grad/param norm = 1.4328e-01, time/batch = 0.3074s	
1060/2700 (epoch 19.630), train_loss = 1.34410934, grad/param norm = 1.5815e-01, time/batch = 0.3087s	
1061/2700 (epoch 19.648), train_loss = 1.38021944, grad/param norm = 1.6499e-01, time/batch = 0.3099s	
1062/2700 (epoch 19.667), train_loss = 1.36227891, grad/param norm = 1.4804e-01, time/batch = 0.3146s	
1063/2700 (epoch 19.685), train_loss = 1.38443768, grad/param norm = 1.3130e-01, time/batch = 0.3228s	
1064/2700 (epoch 19.704), train_loss = 1.39963974, grad/param norm = 1.4634e-01, time/batch = 0.3214s	
1065/2700 (epoch 19.722), train_loss = 1.40073556, grad/param norm = 1.4530e-01, time/batch = 0.3219s	
1066/2700 (epoch 19.741), train_loss = 1.35079766, grad/param norm = 1.5041e-01, time/batch = 0.2463s	
1067/2700 (epoch 19.759), train_loss = 1.38251579, grad/param norm = 1.5973e-01, time/batch = 0.2763s	
1068/2700 (epoch 19.778), train_loss = 1.42648776, grad/param norm = 1.6754e-01, time/batch = 0.3071s	
1069/2700 (epoch 19.796), train_loss = 1.36085574, grad/param norm = 1.5848e-01, time/batch = 0.3041s	
1070/2700 (epoch 19.815), train_loss = 1.39137402, grad/param norm = 1.4008e-01, time/batch = 0.2992s	
1071/2700 (epoch 19.833), train_loss = 1.37319150, grad/param norm = 1.4495e-01, time/batch = 0.3118s	
1072/2700 (epoch 19.852), train_loss = 1.38211259, grad/param norm = 1.5350e-01, time/batch = 0.3205s	
1073/2700 (epoch 19.870), train_loss = 1.39210886, grad/param norm = 1.4490e-01, time/batch = 0.2831s	
1074/2700 (epoch 19.889), train_loss = 1.38000441, grad/param norm = 1.4433e-01, time/batch = 0.2969s	
1075/2700 (epoch 19.907), train_loss = 1.46557351, grad/param norm = 1.4461e-01, time/batch = 0.2912s	
1076/2700 (epoch 19.926), train_loss = 1.40795585, grad/param norm = 1.4513e-01, time/batch = 0.2945s	
1077/2700 (epoch 19.944), train_loss = 1.39072530, grad/param norm = 1.3989e-01, time/batch = 0.2667s	
1078/2700 (epoch 19.963), train_loss = 1.38834302, grad/param norm = 1.3433e-01, time/batch = 0.2578s	
1079/2700 (epoch 19.981), train_loss = 1.33301362, grad/param norm = 1.3931e-01, time/batch = 0.2337s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1080/2700 (epoch 20.000), train_loss = 1.41350350, grad/param norm = 1.4372e-01, time/batch = 0.2822s	
1081/2700 (epoch 20.019), train_loss = 1.45003231, grad/param norm = 1.3940e-01, time/batch = 0.3137s	
1082/2700 (epoch 20.037), train_loss = 1.41683367, grad/param norm = 1.3358e-01, time/batch = 0.2920s	
1083/2700 (epoch 20.056), train_loss = 1.35450167, grad/param norm = 1.4534e-01, time/batch = 0.2940s	
1084/2700 (epoch 20.074), train_loss = 1.33730823, grad/param norm = 1.4665e-01, time/batch = 0.2921s	
1085/2700 (epoch 20.093), train_loss = 1.29254451, grad/param norm = 1.3844e-01, time/batch = 0.2980s	
1086/2700 (epoch 20.111), train_loss = 1.31147707, grad/param norm = 1.3385e-01, time/batch = 0.3068s	
1087/2700 (epoch 20.130), train_loss = 1.36640494, grad/param norm = 1.4864e-01, time/batch = 0.2644s	
1088/2700 (epoch 20.148), train_loss = 1.31997143, grad/param norm = 1.4117e-01, time/batch = 0.3209s	
1089/2700 (epoch 20.167), train_loss = 1.42727504, grad/param norm = 1.7606e-01, time/batch = 0.3160s	
1090/2700 (epoch 20.185), train_loss = 1.36621480, grad/param norm = 1.7017e-01, time/batch = 0.3116s	
1091/2700 (epoch 20.204), train_loss = 1.40203021, grad/param norm = 1.6641e-01, time/batch = 0.2758s	
1092/2700 (epoch 20.222), train_loss = 1.32720142, grad/param norm = 1.5484e-01, time/batch = 0.2713s	
1093/2700 (epoch 20.241), train_loss = 1.27186256, grad/param norm = 1.4469e-01, time/batch = 0.2863s	
1094/2700 (epoch 20.259), train_loss = 1.32481659, grad/param norm = 1.7694e-01, time/batch = 0.2971s	
1095/2700 (epoch 20.278), train_loss = 1.39185961, grad/param norm = 1.7408e-01, time/batch = 0.3027s	
1096/2700 (epoch 20.296), train_loss = 1.35166692, grad/param norm = 1.5097e-01, time/batch = 0.3012s	
1097/2700 (epoch 20.315), train_loss = 1.32917571, grad/param norm = 1.5785e-01, time/batch = 0.2856s	
1098/2700 (epoch 20.333), train_loss = 1.37368168, grad/param norm = 1.9421e-01, time/batch = 0.3235s	
1099/2700 (epoch 20.352), train_loss = 1.37612520, grad/param norm = 1.8635e-01, time/batch = 0.3173s	
1100/2700 (epoch 20.370), train_loss = 1.36487837, grad/param norm = 1.7489e-01, time/batch = 0.3078s	
1101/2700 (epoch 20.389), train_loss = 1.31149954, grad/param norm = 1.3268e-01, time/batch = 0.2967s	
1102/2700 (epoch 20.407), train_loss = 1.39105710, grad/param norm = 1.2709e-01, time/batch = 0.2663s	
1103/2700 (epoch 20.426), train_loss = 1.42159808, grad/param norm = 1.3683e-01, time/batch = 0.3069s	
1104/2700 (epoch 20.444), train_loss = 1.36416957, grad/param norm = 1.7728e-01, time/batch = 0.3170s	
1105/2700 (epoch 20.463), train_loss = 1.40071920, grad/param norm = 1.5717e-01, time/batch = 0.3202s	
1106/2700 (epoch 20.481), train_loss = 1.33986454, grad/param norm = 1.4160e-01, time/batch = 0.3169s	
1107/2700 (epoch 20.500), train_loss = 1.30659073, grad/param norm = 1.3854e-01, time/batch = 0.2983s	
1108/2700 (epoch 20.519), train_loss = 1.37200256, grad/param norm = 1.5190e-01, time/batch = 0.3273s	
1109/2700 (epoch 20.537), train_loss = 1.38295195, grad/param norm = 1.3981e-01, time/batch = 0.3298s	
1110/2700 (epoch 20.556), train_loss = 1.31289470, grad/param norm = 1.3888e-01, time/batch = 0.3155s	
1111/2700 (epoch 20.574), train_loss = 1.29362512, grad/param norm = 1.4471e-01, time/batch = 0.3293s	
1112/2700 (epoch 20.593), train_loss = 1.34448200, grad/param norm = 1.5350e-01, time/batch = 0.3183s	
1113/2700 (epoch 20.611), train_loss = 1.28553881, grad/param norm = 1.4677e-01, time/batch = 0.2964s	
1114/2700 (epoch 20.630), train_loss = 1.30349224, grad/param norm = 1.5068e-01, time/batch = 0.2889s	
1115/2700 (epoch 20.648), train_loss = 1.33553450, grad/param norm = 1.6452e-01, time/batch = 0.2868s	
1116/2700 (epoch 20.667), train_loss = 1.32061336, grad/param norm = 1.5470e-01, time/batch = 0.2952s	
1117/2700 (epoch 20.685), train_loss = 1.36685053, grad/param norm = 1.7834e-01, time/batch = 0.3107s	
1118/2700 (epoch 20.704), train_loss = 1.37563911, grad/param norm = 1.7278e-01, time/batch = 0.3130s	
1119/2700 (epoch 20.722), train_loss = 1.35163029, grad/param norm = 1.2758e-01, time/batch = 0.3133s	
1120/2700 (epoch 20.741), train_loss = 1.29577259, grad/param norm = 1.2669e-01, time/batch = 0.3203s	
1121/2700 (epoch 20.759), train_loss = 1.33209335, grad/param norm = 1.4230e-01, time/batch = 0.3297s	
1122/2700 (epoch 20.778), train_loss = 1.37256940, grad/param norm = 1.5634e-01, time/batch = 0.3233s	
1123/2700 (epoch 20.796), train_loss = 1.31511888, grad/param norm = 1.4974e-01, time/batch = 0.3145s	
1124/2700 (epoch 20.815), train_loss = 1.36234280, grad/param norm = 1.8949e-01, time/batch = 0.2906s	
1125/2700 (epoch 20.833), train_loss = 1.35550869, grad/param norm = 2.0371e-01, time/batch = 0.2970s	
1126/2700 (epoch 20.852), train_loss = 1.35094390, grad/param norm = 1.5390e-01, time/batch = 0.2925s	
1127/2700 (epoch 20.870), train_loss = 1.34121733, grad/param norm = 1.4593e-01, time/batch = 0.2930s	
1128/2700 (epoch 20.889), train_loss = 1.33336125, grad/param norm = 1.4185e-01, time/batch = 0.2982s	
1129/2700 (epoch 20.907), train_loss = 1.42553526, grad/param norm = 1.6345e-01, time/batch = 0.3056s	
1130/2700 (epoch 20.926), train_loss = 1.36446327, grad/param norm = 1.4087e-01, time/batch = 0.3107s	
1131/2700 (epoch 20.944), train_loss = 1.34505197, grad/param norm = 1.3745e-01, time/batch = 0.3299s	
1132/2700 (epoch 20.963), train_loss = 1.34605310, grad/param norm = 1.3391e-01, time/batch = 0.3272s	
1133/2700 (epoch 20.981), train_loss = 1.28851514, grad/param norm = 1.5024e-01, time/batch = 0.3219s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1134/2700 (epoch 21.000), train_loss = 1.36810245, grad/param norm = 1.4827e-01, time/batch = 0.3159s	
1135/2700 (epoch 21.019), train_loss = 1.42048242, grad/param norm = 1.6410e-01, time/batch = 0.2833s	
1136/2700 (epoch 21.037), train_loss = 1.38950411, grad/param norm = 1.6455e-01, time/batch = 0.2933s	
1137/2700 (epoch 21.056), train_loss = 1.31600242, grad/param norm = 1.4811e-01, time/batch = 0.2880s	
1138/2700 (epoch 21.074), train_loss = 1.30133290, grad/param norm = 1.5550e-01, time/batch = 0.2697s	
1139/2700 (epoch 21.093), train_loss = 1.25863411, grad/param norm = 1.6359e-01, time/batch = 0.3041s	
1140/2700 (epoch 21.111), train_loss = 1.28641548, grad/param norm = 1.7433e-01, time/batch = 0.3072s	
1141/2700 (epoch 21.130), train_loss = 1.33307447, grad/param norm = 1.5859e-01, time/batch = 0.3282s	
1142/2700 (epoch 21.148), train_loss = 1.27869215, grad/param norm = 1.4283e-01, time/batch = 0.3274s	
1143/2700 (epoch 21.167), train_loss = 1.37011101, grad/param norm = 1.5377e-01, time/batch = 0.3267s	
1144/2700 (epoch 21.185), train_loss = 1.31481387, grad/param norm = 1.6399e-01, time/batch = 0.3234s	
1145/2700 (epoch 21.204), train_loss = 1.35757977, grad/param norm = 1.5619e-01, time/batch = 0.3230s	
1146/2700 (epoch 21.222), train_loss = 1.28752552, grad/param norm = 1.6685e-01, time/batch = 0.2774s	
1147/2700 (epoch 21.241), train_loss = 1.23183555, grad/param norm = 1.4544e-01, time/batch = 0.2809s	
1148/2700 (epoch 21.259), train_loss = 1.27365849, grad/param norm = 1.4859e-01, time/batch = 0.2917s	
1149/2700 (epoch 21.278), train_loss = 1.33594223, grad/param norm = 1.4440e-01, time/batch = 0.3084s	
1150/2700 (epoch 21.296), train_loss = 1.30985295, grad/param norm = 1.7132e-01, time/batch = 0.3076s	
1151/2700 (epoch 21.315), train_loss = 1.28989179, grad/param norm = 1.7275e-01, time/batch = 0.3111s	
1152/2700 (epoch 21.333), train_loss = 1.32215645, grad/param norm = 1.7362e-01, time/batch = 0.3128s	
1153/2700 (epoch 21.352), train_loss = 1.32781538, grad/param norm = 1.8621e-01, time/batch = 0.3182s	
1154/2700 (epoch 21.370), train_loss = 1.32425134, grad/param norm = 1.7528e-01, time/batch = 0.3214s	
1155/2700 (epoch 21.389), train_loss = 1.27363815, grad/param norm = 1.5440e-01, time/batch = 0.3211s	
1156/2700 (epoch 21.407), train_loss = 1.36462708, grad/param norm = 1.5677e-01, time/batch = 0.3050s	
1157/2700 (epoch 21.426), train_loss = 1.37643983, grad/param norm = 1.3365e-01, time/batch = 0.2395s	
1158/2700 (epoch 21.444), train_loss = 1.30915818, grad/param norm = 1.4179e-01, time/batch = 0.2857s	
1159/2700 (epoch 21.463), train_loss = 1.34643374, grad/param norm = 1.3965e-01, time/batch = 0.3088s	
1160/2700 (epoch 21.481), train_loss = 1.29392521, grad/param norm = 1.5509e-01, time/batch = 0.3041s	
1161/2700 (epoch 21.500), train_loss = 1.26102264, grad/param norm = 1.4313e-01, time/batch = 0.3197s	
1162/2700 (epoch 21.519), train_loss = 1.32746741, grad/param norm = 1.5092e-01, time/batch = 0.3258s	
1163/2700 (epoch 21.537), train_loss = 1.34639865, grad/param norm = 1.8410e-01, time/batch = 0.3208s	
1164/2700 (epoch 21.556), train_loss = 1.27773404, grad/param norm = 1.5721e-01, time/batch = 0.3156s	
1165/2700 (epoch 21.574), train_loss = 1.25143746, grad/param norm = 1.4567e-01, time/batch = 0.3032s	
1166/2700 (epoch 21.593), train_loss = 1.29431456, grad/param norm = 1.4859e-01, time/batch = 0.2987s	
1167/2700 (epoch 21.611), train_loss = 1.23915606, grad/param norm = 1.3285e-01, time/batch = 0.2880s	
1168/2700 (epoch 21.630), train_loss = 1.25187361, grad/param norm = 1.3316e-01, time/batch = 0.2505s	
1169/2700 (epoch 21.648), train_loss = 1.27738905, grad/param norm = 1.3805e-01, time/batch = 0.3057s	
1170/2700 (epoch 21.667), train_loss = 1.27380629, grad/param norm = 1.4662e-01, time/batch = 0.3020s	
1171/2700 (epoch 21.685), train_loss = 1.31033963, grad/param norm = 1.5784e-01, time/batch = 0.3256s	
1172/2700 (epoch 21.704), train_loss = 1.32269832, grad/param norm = 1.4789e-01, time/batch = 0.3237s	
1173/2700 (epoch 21.722), train_loss = 1.31505788, grad/param norm = 1.4298e-01, time/batch = 0.3131s	
1174/2700 (epoch 21.741), train_loss = 1.25294709, grad/param norm = 1.3531e-01, time/batch = 0.3151s	
1175/2700 (epoch 21.759), train_loss = 1.28476633, grad/param norm = 1.4879e-01, time/batch = 0.2982s	
1176/2700 (epoch 21.778), train_loss = 1.33314830, grad/param norm = 1.6182e-01, time/batch = 0.2927s	
1177/2700 (epoch 21.796), train_loss = 1.27073847, grad/param norm = 1.6728e-01, time/batch = 0.2862s	
1178/2700 (epoch 21.815), train_loss = 1.32356278, grad/param norm = 1.4951e-01, time/batch = 0.2723s	
1179/2700 (epoch 21.833), train_loss = 1.28600750, grad/param norm = 1.5490e-01, time/batch = 0.2650s	
1180/2700 (epoch 21.852), train_loss = 1.30336592, grad/param norm = 1.5817e-01, time/batch = 0.3062s	
1181/2700 (epoch 21.870), train_loss = 1.30629919, grad/param norm = 1.5026e-01, time/batch = 0.3148s	
1182/2700 (epoch 21.889), train_loss = 1.28906863, grad/param norm = 1.4538e-01, time/batch = 0.3215s	
1183/2700 (epoch 21.907), train_loss = 1.37812749, grad/param norm = 1.4830e-01, time/batch = 0.3218s	
1184/2700 (epoch 21.926), train_loss = 1.32714031, grad/param norm = 1.6319e-01, time/batch = 0.3176s	
1185/2700 (epoch 21.944), train_loss = 1.32023557, grad/param norm = 1.6964e-01, time/batch = 0.3075s	
1186/2700 (epoch 21.963), train_loss = 1.30808502, grad/param norm = 1.5542e-01, time/batch = 0.3149s	
1187/2700 (epoch 21.981), train_loss = 1.24139732, grad/param norm = 1.3859e-01, time/batch = 0.2987s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1188/2700 (epoch 22.000), train_loss = 1.32220566, grad/param norm = 1.4605e-01, time/batch = 0.2922s	
1189/2700 (epoch 22.019), train_loss = 1.37536119, grad/param norm = 1.5959e-01, time/batch = 0.2943s	
1190/2700 (epoch 22.037), train_loss = 1.34329880, grad/param norm = 1.5976e-01, time/batch = 0.2651s	
1191/2700 (epoch 22.056), train_loss = 1.28054080, grad/param norm = 1.7931e-01, time/batch = 0.3279s	
1192/2700 (epoch 22.074), train_loss = 1.26398883, grad/param norm = 1.7239e-01, time/batch = 0.3265s	
1193/2700 (epoch 22.093), train_loss = 1.22591282, grad/param norm = 1.9171e-01, time/batch = 0.3190s	
1194/2700 (epoch 22.111), train_loss = 1.23990821, grad/param norm = 1.5345e-01, time/batch = 0.3025s	
1195/2700 (epoch 22.130), train_loss = 1.28503244, grad/param norm = 1.4994e-01, time/batch = 0.3254s	
1196/2700 (epoch 22.148), train_loss = 1.23412147, grad/param norm = 1.3440e-01, time/batch = 0.3178s	
1197/2700 (epoch 22.167), train_loss = 1.32902205, grad/param norm = 1.5418e-01, time/batch = 0.3001s	
1198/2700 (epoch 22.185), train_loss = 1.27088466, grad/param norm = 1.5443e-01, time/batch = 0.3045s	
1199/2700 (epoch 22.204), train_loss = 1.30853409, grad/param norm = 1.4794e-01, time/batch = 0.2900s	
1200/2700 (epoch 22.222), train_loss = 1.23983907, grad/param norm = 1.5171e-01, time/batch = 0.2950s	
1201/2700 (epoch 22.241), train_loss = 1.20255486, grad/param norm = 1.6599e-01, time/batch = 0.2388s	
1202/2700 (epoch 22.259), train_loss = 1.24091530, grad/param norm = 1.5429e-01, time/batch = 0.3206s	
1203/2700 (epoch 22.278), train_loss = 1.29948191, grad/param norm = 1.5545e-01, time/batch = 0.3216s	
1204/2700 (epoch 22.296), train_loss = 1.27470794, grad/param norm = 1.7097e-01, time/batch = 0.3144s	
1205/2700 (epoch 22.315), train_loss = 1.26117699, grad/param norm = 2.0661e-01, time/batch = 0.2918s	
1206/2700 (epoch 22.333), train_loss = 1.30651691, grad/param norm = 2.0029e-01, time/batch = 0.2929s	
1207/2700 (epoch 22.352), train_loss = 1.28957093, grad/param norm = 1.9456e-01, time/batch = 0.2939s	
1208/2700 (epoch 22.370), train_loss = 1.27547799, grad/param norm = 1.5896e-01, time/batch = 0.2591s	
1209/2700 (epoch 22.389), train_loss = 1.23255471, grad/param norm = 1.5894e-01, time/batch = 0.3028s	
1210/2700 (epoch 22.407), train_loss = 1.32772932, grad/param norm = 1.5881e-01, time/batch = 0.3071s	
1211/2700 (epoch 22.426), train_loss = 1.33712994, grad/param norm = 1.4670e-01, time/batch = 0.3076s	
1212/2700 (epoch 22.444), train_loss = 1.26956803, grad/param norm = 1.4956e-01, time/batch = 0.3001s	
1213/2700 (epoch 22.463), train_loss = 1.30835700, grad/param norm = 1.4725e-01, time/batch = 0.2814s	
1214/2700 (epoch 22.481), train_loss = 1.25258927, grad/param norm = 1.6199e-01, time/batch = 0.3015s	
1215/2700 (epoch 22.500), train_loss = 1.21991024, grad/param norm = 1.5034e-01, time/batch = 0.2863s	
1216/2700 (epoch 22.519), train_loss = 1.28501451, grad/param norm = 1.5751e-01, time/batch = 0.2934s	
1217/2700 (epoch 22.537), train_loss = 1.29147237, grad/param norm = 1.4968e-01, time/batch = 0.2969s	
1218/2700 (epoch 22.556), train_loss = 1.23523957, grad/param norm = 1.6757e-01, time/batch = 0.2797s	
1219/2700 (epoch 22.574), train_loss = 1.21555824, grad/param norm = 1.6760e-01, time/batch = 0.3132s	
1220/2700 (epoch 22.593), train_loss = 1.26299081, grad/param norm = 1.5728e-01, time/batch = 0.3035s	
1221/2700 (epoch 22.611), train_loss = 1.21015322, grad/param norm = 1.6178e-01, time/batch = 0.3126s	
1222/2700 (epoch 22.630), train_loss = 1.22969990, grad/param norm = 1.7481e-01, time/batch = 0.3096s	
1223/2700 (epoch 22.648), train_loss = 1.24970584, grad/param norm = 1.7522e-01, time/batch = 0.3144s	
1224/2700 (epoch 22.667), train_loss = 1.23724307, grad/param norm = 1.4535e-01, time/batch = 0.3138s	
1225/2700 (epoch 22.685), train_loss = 1.26899604, grad/param norm = 1.5381e-01, time/batch = 0.2993s	
1226/2700 (epoch 22.704), train_loss = 1.27828247, grad/param norm = 1.5564e-01, time/batch = 0.2908s	
1227/2700 (epoch 22.722), train_loss = 1.28174518, grad/param norm = 1.6365e-01, time/batch = 0.2947s	
1228/2700 (epoch 22.741), train_loss = 1.21696348, grad/param norm = 1.4992e-01, time/batch = 0.2586s	
1229/2700 (epoch 22.759), train_loss = 1.25079614, grad/param norm = 1.7400e-01, time/batch = 0.3029s	
1230/2700 (epoch 22.778), train_loss = 1.29078371, grad/param norm = 1.6693e-01, time/batch = 0.3102s	
1231/2700 (epoch 22.796), train_loss = 1.22531023, grad/param norm = 1.5521e-01, time/batch = 0.3104s	
1232/2700 (epoch 22.815), train_loss = 1.27539665, grad/param norm = 1.6084e-01, time/batch = 0.2628s	
1233/2700 (epoch 22.833), train_loss = 1.25204144, grad/param norm = 1.7274e-01, time/batch = 0.3019s	
1234/2700 (epoch 22.852), train_loss = 1.26819591, grad/param norm = 1.8693e-01, time/batch = 0.3093s	
1235/2700 (epoch 22.870), train_loss = 1.26890944, grad/param norm = 1.5237e-01, time/batch = 0.2342s	
1236/2700 (epoch 22.889), train_loss = 1.25045834, grad/param norm = 1.5547e-01, time/batch = 0.3020s	
1237/2700 (epoch 22.907), train_loss = 1.33242497, grad/param norm = 1.4858e-01, time/batch = 0.3031s	
1238/2700 (epoch 22.926), train_loss = 1.27565344, grad/param norm = 1.5337e-01, time/batch = 0.2483s	
1239/2700 (epoch 22.944), train_loss = 1.27321556, grad/param norm = 1.6266e-01, time/batch = 0.3124s	
1240/2700 (epoch 22.963), train_loss = 1.26715532, grad/param norm = 1.5687e-01, time/batch = 0.2907s	
1241/2700 (epoch 22.981), train_loss = 1.20854649, grad/param norm = 1.6319e-01, time/batch = 0.3094s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1242/2700 (epoch 23.000), train_loss = 1.28290234, grad/param norm = 1.6253e-01, time/batch = 0.3018s	
1243/2700 (epoch 23.019), train_loss = 1.34065271, grad/param norm = 1.6424e-01, time/batch = 0.2822s	
1244/2700 (epoch 23.037), train_loss = 1.30641800, grad/param norm = 1.7051e-01, time/batch = 0.2819s	
1245/2700 (epoch 23.056), train_loss = 1.23849764, grad/param norm = 1.7266e-01, time/batch = 0.3005s	
1246/2700 (epoch 23.074), train_loss = 1.22060957, grad/param norm = 1.5978e-01, time/batch = 0.3070s	
1247/2700 (epoch 23.093), train_loss = 1.16985652, grad/param norm = 1.4497e-01, time/batch = 0.3211s	
1248/2700 (epoch 23.111), train_loss = 1.19713154, grad/param norm = 1.6061e-01, time/batch = 0.3082s	
1249/2700 (epoch 23.130), train_loss = 1.25031895, grad/param norm = 1.8281e-01, time/batch = 0.3061s	
1250/2700 (epoch 23.148), train_loss = 1.21034124, grad/param norm = 1.6940e-01, time/batch = 0.2966s	
1251/2700 (epoch 23.167), train_loss = 1.28396074, grad/param norm = 1.6179e-01, time/batch = 0.2970s	
1252/2700 (epoch 23.185), train_loss = 1.22970479, grad/param norm = 1.5958e-01, time/batch = 0.3125s	
1253/2700 (epoch 23.204), train_loss = 1.27556320, grad/param norm = 1.7036e-01, time/batch = 0.2981s	
1254/2700 (epoch 23.222), train_loss = 1.20202971, grad/param norm = 1.6483e-01, time/batch = 0.2880s	
1255/2700 (epoch 23.241), train_loss = 1.17112123, grad/param norm = 1.8521e-01, time/batch = 0.2840s	
1256/2700 (epoch 23.259), train_loss = 1.19937399, grad/param norm = 1.5687e-01, time/batch = 0.2911s	
1257/2700 (epoch 23.278), train_loss = 1.25052942, grad/param norm = 1.4922e-01, time/batch = 0.2845s	
1258/2700 (epoch 23.296), train_loss = 1.22687853, grad/param norm = 1.5842e-01, time/batch = 0.3146s	
1259/2700 (epoch 23.315), train_loss = 1.20024481, grad/param norm = 1.6858e-01, time/batch = 0.2421s	
1260/2700 (epoch 23.333), train_loss = 1.24166762, grad/param norm = 1.8026e-01, time/batch = 0.2957s	
1261/2700 (epoch 23.352), train_loss = 1.23335605, grad/param norm = 1.7232e-01, time/batch = 0.2573s	
1262/2700 (epoch 23.370), train_loss = 1.24484032, grad/param norm = 2.3237e-01, time/batch = 0.2826s	
1263/2700 (epoch 23.389), train_loss = 1.22285771, grad/param norm = 1.8466e-01, time/batch = 0.2910s	
1264/2700 (epoch 23.407), train_loss = 1.29612458, grad/param norm = 1.6171e-01, time/batch = 0.3002s	
1265/2700 (epoch 23.426), train_loss = 1.30195104, grad/param norm = 1.6565e-01, time/batch = 0.3096s	
1266/2700 (epoch 23.444), train_loss = 1.23892385, grad/param norm = 1.6278e-01, time/batch = 0.3021s	
1267/2700 (epoch 23.463), train_loss = 1.26283236, grad/param norm = 1.4911e-01, time/batch = 0.2952s	
1268/2700 (epoch 23.481), train_loss = 1.20722699, grad/param norm = 1.4881e-01, time/batch = 0.3013s	
1269/2700 (epoch 23.500), train_loss = 1.17827029, grad/param norm = 1.5936e-01, time/batch = 0.2396s	
1270/2700 (epoch 23.519), train_loss = 1.25547638, grad/param norm = 1.8406e-01, time/batch = 0.2961s	
1271/2700 (epoch 23.537), train_loss = 1.26319022, grad/param norm = 1.8435e-01, time/batch = 0.2908s	
1272/2700 (epoch 23.556), train_loss = 1.19180688, grad/param norm = 1.5892e-01, time/batch = 0.2978s	
1273/2700 (epoch 23.574), train_loss = 1.16871960, grad/param norm = 1.5341e-01, time/batch = 0.3112s	
1274/2700 (epoch 23.593), train_loss = 1.21673833, grad/param norm = 1.5045e-01, time/batch = 0.3252s	
1275/2700 (epoch 23.611), train_loss = 1.16906038, grad/param norm = 1.5517e-01, time/batch = 0.3289s	
1276/2700 (epoch 23.630), train_loss = 1.18483682, grad/param norm = 1.6581e-01, time/batch = 0.3175s	
1277/2700 (epoch 23.648), train_loss = 1.19678548, grad/param norm = 1.5283e-01, time/batch = 0.3217s	
1278/2700 (epoch 23.667), train_loss = 1.19960117, grad/param norm = 1.6257e-01, time/batch = 0.3162s	
1279/2700 (epoch 23.685), train_loss = 1.22909394, grad/param norm = 1.6911e-01, time/batch = 0.3006s	
1280/2700 (epoch 23.704), train_loss = 1.24955442, grad/param norm = 1.8852e-01, time/batch = 0.2602s	
1281/2700 (epoch 23.722), train_loss = 1.25996429, grad/param norm = 1.9943e-01, time/batch = 0.3079s	
1282/2700 (epoch 23.741), train_loss = 1.17543815, grad/param norm = 1.4444e-01, time/batch = 0.3014s	
1283/2700 (epoch 23.759), train_loss = 1.19755333, grad/param norm = 1.4810e-01, time/batch = 0.2910s	
1284/2700 (epoch 23.778), train_loss = 1.25221624, grad/param norm = 1.7896e-01, time/batch = 0.2969s	
1285/2700 (epoch 23.796), train_loss = 1.20766214, grad/param norm = 2.0261e-01, time/batch = 0.3019s	
1286/2700 (epoch 23.815), train_loss = 1.23806752, grad/param norm = 1.6107e-01, time/batch = 0.3142s	
1287/2700 (epoch 23.833), train_loss = 1.19866955, grad/param norm = 1.5272e-01, time/batch = 0.3219s	
1288/2700 (epoch 23.852), train_loss = 1.21109403, grad/param norm = 1.6429e-01, time/batch = 0.3160s	
1289/2700 (epoch 23.870), train_loss = 1.22458090, grad/param norm = 1.5461e-01, time/batch = 0.3024s	
1290/2700 (epoch 23.889), train_loss = 1.20408121, grad/param norm = 1.5260e-01, time/batch = 0.3057s	
1291/2700 (epoch 23.907), train_loss = 1.29771046, grad/param norm = 1.8378e-01, time/batch = 0.3043s	
1292/2700 (epoch 23.926), train_loss = 1.24962084, grad/param norm = 1.6867e-01, time/batch = 0.2955s	
1293/2700 (epoch 23.944), train_loss = 1.23279441, grad/param norm = 1.7388e-01, time/batch = 0.2933s	
1294/2700 (epoch 23.963), train_loss = 1.22039568, grad/param norm = 1.4518e-01, time/batch = 0.2953s	
1295/2700 (epoch 23.981), train_loss = 1.16126455, grad/param norm = 1.5394e-01, time/batch = 0.3026s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1296/2700 (epoch 24.000), train_loss = 1.24054539, grad/param norm = 1.5834e-01, time/batch = 0.3097s	
1297/2700 (epoch 24.019), train_loss = 1.30934670, grad/param norm = 1.7759e-01, time/batch = 0.3182s	
1298/2700 (epoch 24.037), train_loss = 1.25921587, grad/param norm = 1.6147e-01, time/batch = 0.3178s	
1299/2700 (epoch 24.056), train_loss = 1.20101967, grad/param norm = 1.7675e-01, time/batch = 0.3217s	
1300/2700 (epoch 24.074), train_loss = 1.19620134, grad/param norm = 1.8254e-01, time/batch = 0.2826s	
1301/2700 (epoch 24.093), train_loss = 1.13066980, grad/param norm = 1.5190e-01, time/batch = 0.3137s	
1302/2700 (epoch 24.111), train_loss = 1.15146458, grad/param norm = 1.5718e-01, time/batch = 0.2735s	
1303/2700 (epoch 24.130), train_loss = 1.20257926, grad/param norm = 1.6736e-01, time/batch = 0.2951s	
1304/2700 (epoch 24.148), train_loss = 1.16084462, grad/param norm = 1.4966e-01, time/batch = 0.3095s	
1305/2700 (epoch 24.167), train_loss = 1.24675876, grad/param norm = 1.8345e-01, time/batch = 0.3105s	
1306/2700 (epoch 24.185), train_loss = 1.19945835, grad/param norm = 1.7476e-01, time/batch = 0.3130s	
1307/2700 (epoch 24.204), train_loss = 1.24084645, grad/param norm = 1.7843e-01, time/batch = 0.3169s	
1308/2700 (epoch 24.222), train_loss = 1.16652957, grad/param norm = 1.7526e-01, time/batch = 0.3235s	
1309/2700 (epoch 24.241), train_loss = 1.13446518, grad/param norm = 1.6348e-01, time/batch = 0.3161s	
1310/2700 (epoch 24.259), train_loss = 1.17402224, grad/param norm = 1.9575e-01, time/batch = 0.2235s	
1311/2700 (epoch 24.278), train_loss = 1.22676645, grad/param norm = 1.7416e-01, time/batch = 0.2883s	
1312/2700 (epoch 24.296), train_loss = 1.18542739, grad/param norm = 1.6251e-01, time/batch = 0.2885s	
1313/2700 (epoch 24.315), train_loss = 1.16779452, grad/param norm = 1.7936e-01, time/batch = 0.2712s	
1314/2700 (epoch 24.333), train_loss = 1.20257240, grad/param norm = 1.9798e-01, time/batch = 0.3245s	
1315/2700 (epoch 24.352), train_loss = 1.20481674, grad/param norm = 2.0374e-01, time/batch = 0.3262s	
1316/2700 (epoch 24.370), train_loss = 1.18472489, grad/param norm = 1.8431e-01, time/batch = 0.3165s	
1317/2700 (epoch 24.389), train_loss = 1.15237676, grad/param norm = 1.5149e-01, time/batch = 0.3029s	
1318/2700 (epoch 24.407), train_loss = 1.24313096, grad/param norm = 1.4936e-01, time/batch = 0.2987s	
1319/2700 (epoch 24.426), train_loss = 1.25087316, grad/param norm = 1.6274e-01, time/batch = 0.2954s	
1320/2700 (epoch 24.444), train_loss = 1.19595234, grad/param norm = 1.5493e-01, time/batch = 0.2793s	
1321/2700 (epoch 24.463), train_loss = 1.22895778, grad/param norm = 1.8447e-01, time/batch = 0.2924s	
1322/2700 (epoch 24.481), train_loss = 1.18282163, grad/param norm = 1.9791e-01, time/batch = 0.2937s	
1323/2700 (epoch 24.500), train_loss = 1.14841792, grad/param norm = 1.9404e-01, time/batch = 0.3037s	
1324/2700 (epoch 24.519), train_loss = 1.21914831, grad/param norm = 1.8857e-01, time/batch = 0.3000s	
1325/2700 (epoch 24.537), train_loss = 1.22012340, grad/param norm = 1.7241e-01, time/batch = 0.3222s	
1326/2700 (epoch 24.556), train_loss = 1.15207932, grad/param norm = 1.6772e-01, time/batch = 0.3170s	
1327/2700 (epoch 24.574), train_loss = 1.12886319, grad/param norm = 1.5431e-01, time/batch = 0.3167s	
1328/2700 (epoch 24.593), train_loss = 1.18426348, grad/param norm = 1.6363e-01, time/batch = 0.2977s	
1329/2700 (epoch 24.611), train_loss = 1.13823405, grad/param norm = 1.7274e-01, time/batch = 0.2951s	
1330/2700 (epoch 24.630), train_loss = 1.15423194, grad/param norm = 1.6200e-01, time/batch = 0.2915s	
1331/2700 (epoch 24.648), train_loss = 1.17360614, grad/param norm = 1.9424e-01, time/batch = 0.2899s	
1332/2700 (epoch 24.667), train_loss = 1.18110076, grad/param norm = 2.0027e-01, time/batch = 0.2922s	
1333/2700 (epoch 24.685), train_loss = 1.19461090, grad/param norm = 1.6428e-01, time/batch = 0.2952s	
1334/2700 (epoch 24.704), train_loss = 1.20471763, grad/param norm = 1.6166e-01, time/batch = 0.3071s	
1335/2700 (epoch 24.722), train_loss = 1.20336122, grad/param norm = 1.5658e-01, time/batch = 0.2921s	
1336/2700 (epoch 24.741), train_loss = 1.13923597, grad/param norm = 1.6614e-01, time/batch = 0.2759s	
1337/2700 (epoch 24.759), train_loss = 1.17204208, grad/param norm = 1.9110e-01, time/batch = 0.2957s	
1338/2700 (epoch 24.778), train_loss = 1.20522158, grad/param norm = 1.6652e-01, time/batch = 0.2910s	
1339/2700 (epoch 24.796), train_loss = 1.14847006, grad/param norm = 1.6893e-01, time/batch = 0.2925s	
1340/2700 (epoch 24.815), train_loss = 1.19447425, grad/param norm = 1.5660e-01, time/batch = 0.2918s	
1341/2700 (epoch 24.833), train_loss = 1.16376705, grad/param norm = 1.8276e-01, time/batch = 0.2665s	
1342/2700 (epoch 24.852), train_loss = 1.16844742, grad/param norm = 1.7153e-01, time/batch = 0.2818s	
1343/2700 (epoch 24.870), train_loss = 1.19100739, grad/param norm = 1.7764e-01, time/batch = 0.2897s	
1344/2700 (epoch 24.889), train_loss = 1.17535543, grad/param norm = 1.7883e-01, time/batch = 0.3081s	
1345/2700 (epoch 24.907), train_loss = 1.25852030, grad/param norm = 1.8617e-01, time/batch = 0.3007s	
1346/2700 (epoch 24.926), train_loss = 1.20475665, grad/param norm = 1.6520e-01, time/batch = 0.2922s	
1347/2700 (epoch 24.944), train_loss = 1.18969267, grad/param norm = 1.6372e-01, time/batch = 0.2952s	
1348/2700 (epoch 24.963), train_loss = 1.18312364, grad/param norm = 1.6142e-01, time/batch = 0.2733s	
1349/2700 (epoch 24.981), train_loss = 1.12975597, grad/param norm = 1.6910e-01, time/batch = 0.2841s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1350/2700 (epoch 25.000), train_loss = 1.21749754, grad/param norm = 2.1720e-01, time/batch = 0.2882s	
1351/2700 (epoch 25.019), train_loss = 1.27410622, grad/param norm = 1.6566e-01, time/batch = 0.2822s	
1352/2700 (epoch 25.037), train_loss = 1.21404773, grad/param norm = 1.7073e-01, time/batch = 0.2843s	
1353/2700 (epoch 25.056), train_loss = 1.16755004, grad/param norm = 1.9510e-01, time/batch = 0.2975s	
1354/2700 (epoch 25.074), train_loss = 1.15109288, grad/param norm = 1.6819e-01, time/batch = 0.2939s	
1355/2700 (epoch 25.093), train_loss = 1.09849810, grad/param norm = 1.5970e-01, time/batch = 0.3018s	
1356/2700 (epoch 25.111), train_loss = 1.12113120, grad/param norm = 1.8261e-01, time/batch = 0.3068s	
1357/2700 (epoch 25.130), train_loss = 1.17225589, grad/param norm = 1.9529e-01, time/batch = 0.3073s	
1358/2700 (epoch 25.148), train_loss = 1.13009825, grad/param norm = 1.6555e-01, time/batch = 0.2279s	
1359/2700 (epoch 25.167), train_loss = 1.19622356, grad/param norm = 1.5774e-01, time/batch = 0.3068s	
1360/2700 (epoch 25.185), train_loss = 1.15620868, grad/param norm = 1.7528e-01, time/batch = 0.3081s	
1361/2700 (epoch 25.204), train_loss = 1.18791819, grad/param norm = 1.5469e-01, time/batch = 0.2778s	
1362/2700 (epoch 25.222), train_loss = 1.11497493, grad/param norm = 1.6007e-01, time/batch = 0.3033s	
1363/2700 (epoch 25.241), train_loss = 1.09714474, grad/param norm = 1.8638e-01, time/batch = 0.3031s	
1364/2700 (epoch 25.259), train_loss = 1.12300141, grad/param norm = 1.6258e-01, time/batch = 0.2908s	
1365/2700 (epoch 25.278), train_loss = 1.17934284, grad/param norm = 1.8008e-01, time/batch = 0.2871s	
1366/2700 (epoch 25.296), train_loss = 1.15391181, grad/param norm = 1.9898e-01, time/batch = 0.2763s	
1367/2700 (epoch 25.315), train_loss = 1.12175928, grad/param norm = 1.8309e-01, time/batch = 0.2794s	
1368/2700 (epoch 25.333), train_loss = 1.15576187, grad/param norm = 1.8598e-01, time/batch = 0.2859s	
1369/2700 (epoch 25.352), train_loss = 1.15750329, grad/param norm = 1.9589e-01, time/batch = 0.2742s	
1370/2700 (epoch 25.370), train_loss = 1.15534410, grad/param norm = 2.0085e-01, time/batch = 0.3045s	
1371/2700 (epoch 25.389), train_loss = 1.16058081, grad/param norm = 2.7997e-01, time/batch = 0.2526s	
1372/2700 (epoch 25.407), train_loss = 1.25565067, grad/param norm = 2.1388e-01, time/batch = 0.3077s	
1373/2700 (epoch 25.426), train_loss = 1.21707881, grad/param norm = 1.7238e-01, time/batch = 0.2823s	
1374/2700 (epoch 25.444), train_loss = 1.15673995, grad/param norm = 1.5343e-01, time/batch = 0.2922s	
1375/2700 (epoch 25.463), train_loss = 1.18636593, grad/param norm = 1.6977e-01, time/batch = 0.2968s	
1376/2700 (epoch 25.481), train_loss = 1.13607652, grad/param norm = 1.8907e-01, time/batch = 0.3065s	
1377/2700 (epoch 25.500), train_loss = 1.11321768, grad/param norm = 1.9433e-01, time/batch = 0.3189s	
1378/2700 (epoch 25.519), train_loss = 1.19191958, grad/param norm = 2.0624e-01, time/batch = 0.3274s	
1379/2700 (epoch 25.537), train_loss = 1.19410215, grad/param norm = 1.9938e-01, time/batch = 0.3150s	
1380/2700 (epoch 25.556), train_loss = 1.12202543, grad/param norm = 1.9651e-01, time/batch = 0.3043s	
1381/2700 (epoch 25.574), train_loss = 1.10154126, grad/param norm = 1.7894e-01, time/batch = 0.2977s	
1382/2700 (epoch 25.593), train_loss = 1.14744844, grad/param norm = 1.6034e-01, time/batch = 0.3066s	
1383/2700 (epoch 25.611), train_loss = 1.09374706, grad/param norm = 1.5555e-01, time/batch = 0.3048s	
1384/2700 (epoch 25.630), train_loss = 1.10432052, grad/param norm = 1.4470e-01, time/batch = 0.2963s	
1385/2700 (epoch 25.648), train_loss = 1.11442850, grad/param norm = 1.4683e-01, time/batch = 0.2917s	
1386/2700 (epoch 25.667), train_loss = 1.12403502, grad/param norm = 1.7336e-01, time/batch = 0.2999s	
1387/2700 (epoch 25.685), train_loss = 1.14800097, grad/param norm = 1.6066e-01, time/batch = 0.3038s	
1388/2700 (epoch 25.704), train_loss = 1.16966823, grad/param norm = 1.8060e-01, time/batch = 0.3185s	
1389/2700 (epoch 25.722), train_loss = 1.18359566, grad/param norm = 1.9653e-01, time/batch = 0.3273s	
1390/2700 (epoch 25.741), train_loss = 1.10811811, grad/param norm = 1.6609e-01, time/batch = 0.3208s	
1391/2700 (epoch 25.759), train_loss = 1.12540073, grad/param norm = 1.7429e-01, time/batch = 0.2516s	
1392/2700 (epoch 25.778), train_loss = 1.17045537, grad/param norm = 1.8857e-01, time/batch = 0.3063s	
1393/2700 (epoch 25.796), train_loss = 1.12316543, grad/param norm = 2.1494e-01, time/batch = 0.3048s	
1394/2700 (epoch 25.815), train_loss = 1.17095906, grad/param norm = 1.9705e-01, time/batch = 0.2978s	
1395/2700 (epoch 25.833), train_loss = 1.13491643, grad/param norm = 2.0942e-01, time/batch = 0.2969s	
1396/2700 (epoch 25.852), train_loss = 1.13102595, grad/param norm = 1.8430e-01, time/batch = 0.2928s	
1397/2700 (epoch 25.870), train_loss = 1.14215948, grad/param norm = 1.6470e-01, time/batch = 0.3002s	
1398/2700 (epoch 25.889), train_loss = 1.12091692, grad/param norm = 1.6027e-01, time/batch = 0.3095s	
1399/2700 (epoch 25.907), train_loss = 1.21040828, grad/param norm = 1.6538e-01, time/batch = 0.3169s	
1400/2700 (epoch 25.926), train_loss = 1.17743795, grad/param norm = 2.1837e-01, time/batch = 0.3183s	
1401/2700 (epoch 25.944), train_loss = 1.16564334, grad/param norm = 1.8899e-01, time/batch = 0.2969s	
1402/2700 (epoch 25.963), train_loss = 1.14410694, grad/param norm = 1.6969e-01, time/batch = 0.3018s	
1403/2700 (epoch 25.981), train_loss = 1.08487534, grad/param norm = 1.5750e-01, time/batch = 0.3103s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1404/2700 (epoch 26.000), train_loss = 1.16279405, grad/param norm = 1.9509e-01, time/batch = 0.3003s	
1405/2700 (epoch 26.019), train_loss = 1.24024263, grad/param norm = 2.0334e-01, time/batch = 0.2896s	
1406/2700 (epoch 26.037), train_loss = 1.18624416, grad/param norm = 1.8246e-01, time/batch = 0.2966s	
1407/2700 (epoch 26.056), train_loss = 1.12329245, grad/param norm = 1.7506e-01, time/batch = 0.3011s	
1408/2700 (epoch 26.074), train_loss = 1.13978623, grad/param norm = 2.3930e-01, time/batch = 0.3109s	
1409/2700 (epoch 26.093), train_loss = 1.08305998, grad/param norm = 1.9624e-01, time/batch = 0.3128s	
1410/2700 (epoch 26.111), train_loss = 1.09152044, grad/param norm = 2.2328e-01, time/batch = 0.3105s	
1411/2700 (epoch 26.130), train_loss = 1.13119166, grad/param norm = 1.7928e-01, time/batch = 0.3202s	
1412/2700 (epoch 26.148), train_loss = 1.09389687, grad/param norm = 1.6475e-01, time/batch = 0.3160s	
1413/2700 (epoch 26.167), train_loss = 1.16133526, grad/param norm = 1.8154e-01, time/batch = 0.3022s	
1414/2700 (epoch 26.185), train_loss = 1.11196357, grad/param norm = 1.5159e-01, time/batch = 0.3109s	
1415/2700 (epoch 26.204), train_loss = 1.14779507, grad/param norm = 1.6640e-01, time/batch = 0.2958s	
1416/2700 (epoch 26.222), train_loss = 1.08264655, grad/param norm = 1.7708e-01, time/batch = 0.2900s	
1417/2700 (epoch 26.241), train_loss = 1.06559434, grad/param norm = 1.8239e-01, time/batch = 0.2911s	
1418/2700 (epoch 26.259), train_loss = 1.09486127, grad/param norm = 2.0501e-01, time/batch = 0.2949s	
1419/2700 (epoch 26.278), train_loss = 1.14507577, grad/param norm = 1.7882e-01, time/batch = 0.3098s	
1420/2700 (epoch 26.296), train_loss = 1.11212382, grad/param norm = 1.7307e-01, time/batch = 0.2594s	
1421/2700 (epoch 26.315), train_loss = 1.08243702, grad/param norm = 1.9584e-01, time/batch = 0.3014s	
1422/2700 (epoch 26.333), train_loss = 1.13541079, grad/param norm = 2.4852e-01, time/batch = 0.3136s	
1423/2700 (epoch 26.352), train_loss = 1.12270885, grad/param norm = 2.0462e-01, time/batch = 0.3239s	
1424/2700 (epoch 26.370), train_loss = 1.10007109, grad/param norm = 1.6913e-01, time/batch = 0.3195s	
1425/2700 (epoch 26.389), train_loss = 1.08434470, grad/param norm = 1.6828e-01, time/batch = 0.2391s	
1426/2700 (epoch 26.407), train_loss = 1.17696754, grad/param norm = 1.6245e-01, time/batch = 0.3167s	
1427/2700 (epoch 26.426), train_loss = 1.17794036, grad/param norm = 1.8933e-01, time/batch = 0.3206s	
1428/2700 (epoch 26.444), train_loss = 1.12168199, grad/param norm = 1.8110e-01, time/batch = 0.3186s	
1429/2700 (epoch 26.463), train_loss = 1.14403141, grad/param norm = 1.6049e-01, time/batch = 0.3086s	
1430/2700 (epoch 26.481), train_loss = 1.08865807, grad/param norm = 1.6784e-01, time/batch = 0.3030s	
1431/2700 (epoch 26.500), train_loss = 1.06752759, grad/param norm = 1.8434e-01, time/batch = 0.3128s	
1432/2700 (epoch 26.519), train_loss = 1.13181763, grad/param norm = 1.6706e-01, time/batch = 0.3162s	
1433/2700 (epoch 26.537), train_loss = 1.13430638, grad/param norm = 1.8533e-01, time/batch = 0.3149s	
1434/2700 (epoch 26.556), train_loss = 1.08875752, grad/param norm = 1.9214e-01, time/batch = 0.3011s	
1435/2700 (epoch 26.574), train_loss = 1.06914394, grad/param norm = 1.9283e-01, time/batch = 0.2902s	
1436/2700 (epoch 26.593), train_loss = 1.12920368, grad/param norm = 1.9970e-01, time/batch = 0.2571s	
1437/2700 (epoch 26.611), train_loss = 1.07468866, grad/param norm = 1.8950e-01, time/batch = 0.3175s	
1438/2700 (epoch 26.630), train_loss = 1.09336888, grad/param norm = 2.0440e-01, time/batch = 0.3226s	
1439/2700 (epoch 26.648), train_loss = 1.10419498, grad/param norm = 2.1800e-01, time/batch = 0.2700s	
1440/2700 (epoch 26.667), train_loss = 1.10248603, grad/param norm = 2.0408e-01, time/batch = 0.2927s	
1441/2700 (epoch 26.685), train_loss = 1.11475405, grad/param norm = 1.6610e-01, time/batch = 0.3039s	
1442/2700 (epoch 26.704), train_loss = 1.12963549, grad/param norm = 1.8857e-01, time/batch = 0.2921s	
1443/2700 (epoch 26.722), train_loss = 1.12822456, grad/param norm = 1.4486e-01, time/batch = 0.2921s	
1444/2700 (epoch 26.741), train_loss = 1.06702406, grad/param norm = 1.7400e-01, time/batch = 0.2890s	
1445/2700 (epoch 26.759), train_loss = 1.08976722, grad/param norm = 1.7942e-01, time/batch = 0.2965s	
1446/2700 (epoch 26.778), train_loss = 1.13283549, grad/param norm = 1.8886e-01, time/batch = 0.3045s	
1447/2700 (epoch 26.796), train_loss = 1.07837276, grad/param norm = 1.9308e-01, time/batch = 0.2968s	
1448/2700 (epoch 26.815), train_loss = 1.13993966, grad/param norm = 2.0634e-01, time/batch = 0.2901s	
1449/2700 (epoch 26.833), train_loss = 1.11034046, grad/param norm = 2.1274e-01, time/batch = 0.2822s	
1450/2700 (epoch 26.852), train_loss = 1.10754848, grad/param norm = 2.2432e-01, time/batch = 0.2819s	
1451/2700 (epoch 26.870), train_loss = 1.11682078, grad/param norm = 1.9652e-01, time/batch = 0.2929s	
1452/2700 (epoch 26.889), train_loss = 1.09184797, grad/param norm = 1.7941e-01, time/batch = 0.2853s	
1453/2700 (epoch 26.907), train_loss = 1.16972796, grad/param norm = 1.8124e-01, time/batch = 0.2856s	
1454/2700 (epoch 26.926), train_loss = 1.11478611, grad/param norm = 1.6479e-01, time/batch = 0.2862s	
1455/2700 (epoch 26.944), train_loss = 1.10861919, grad/param norm = 1.6228e-01, time/batch = 0.3002s	
1456/2700 (epoch 26.963), train_loss = 1.10117009, grad/param norm = 1.6003e-01, time/batch = 0.3079s	
1457/2700 (epoch 26.981), train_loss = 1.05089677, grad/param norm = 1.7856e-01, time/batch = 0.3016s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1458/2700 (epoch 27.000), train_loss = 1.12655892, grad/param norm = 1.8252e-01, time/batch = 0.2789s	
1459/2700 (epoch 27.019), train_loss = 1.19883895, grad/param norm = 1.9138e-01, time/batch = 0.2665s	
1460/2700 (epoch 27.037), train_loss = 1.14029828, grad/param norm = 1.7941e-01, time/batch = 0.2859s	
1461/2700 (epoch 27.056), train_loss = 1.09036404, grad/param norm = 1.8635e-01, time/batch = 0.2875s	
1462/2700 (epoch 27.074), train_loss = 1.07846979, grad/param norm = 1.8166e-01, time/batch = 0.2934s	
1463/2700 (epoch 27.093), train_loss = 1.02694600, grad/param norm = 1.7015e-01, time/batch = 0.2837s	
1464/2700 (epoch 27.111), train_loss = 1.04067723, grad/param norm = 1.7976e-01, time/batch = 0.2959s	
1465/2700 (epoch 27.130), train_loss = 1.08401777, grad/param norm = 1.7680e-01, time/batch = 0.2967s	
1466/2700 (epoch 27.148), train_loss = 1.07338185, grad/param norm = 2.0677e-01, time/batch = 0.2992s	
1467/2700 (epoch 27.167), train_loss = 1.13288796, grad/param norm = 1.9924e-01, time/batch = 0.2986s	
1468/2700 (epoch 27.185), train_loss = 1.08741333, grad/param norm = 1.7824e-01, time/batch = 0.3095s	
1469/2700 (epoch 27.204), train_loss = 1.11249585, grad/param norm = 1.7509e-01, time/batch = 0.3018s	
1470/2700 (epoch 27.222), train_loss = 1.04655185, grad/param norm = 1.8220e-01, time/batch = 0.2186s	
1471/2700 (epoch 27.241), train_loss = 1.03090638, grad/param norm = 1.8835e-01, time/batch = 0.3175s	
1472/2700 (epoch 27.259), train_loss = 1.04569694, grad/param norm = 1.5572e-01, time/batch = 0.2872s	
1473/2700 (epoch 27.278), train_loss = 1.10427123, grad/param norm = 1.8220e-01, time/batch = 0.3018s	
1474/2700 (epoch 27.296), train_loss = 1.07480836, grad/param norm = 1.8131e-01, time/batch = 0.3012s	
1475/2700 (epoch 27.315), train_loss = 1.05103526, grad/param norm = 2.0203e-01, time/batch = 0.3016s	
1476/2700 (epoch 27.333), train_loss = 1.09048194, grad/param norm = 2.2495e-01, time/batch = 0.2885s	
1477/2700 (epoch 27.352), train_loss = 1.07276354, grad/param norm = 1.8160e-01, time/batch = 0.2853s	
1478/2700 (epoch 27.370), train_loss = 1.08303340, grad/param norm = 2.5040e-01, time/batch = 0.2811s	
1479/2700 (epoch 27.389), train_loss = 1.06685141, grad/param norm = 2.1044e-01, time/batch = 0.2782s	
1480/2700 (epoch 27.407), train_loss = 1.14482802, grad/param norm = 1.6158e-01, time/batch = 0.2936s	
1481/2700 (epoch 27.426), train_loss = 1.13267716, grad/param norm = 1.7241e-01, time/batch = 0.2603s	
1482/2700 (epoch 27.444), train_loss = 1.08097513, grad/param norm = 1.6189e-01, time/batch = 0.2505s	
1483/2700 (epoch 27.463), train_loss = 1.11311709, grad/param norm = 1.9317e-01, time/batch = 0.3034s	
1484/2700 (epoch 27.481), train_loss = 1.06069885, grad/param norm = 1.8731e-01, time/batch = 0.2908s	
1485/2700 (epoch 27.500), train_loss = 1.03082548, grad/param norm = 1.9963e-01, time/batch = 0.2963s	
1486/2700 (epoch 27.519), train_loss = 1.11157205, grad/param norm = 1.9589e-01, time/batch = 0.2919s	
1487/2700 (epoch 27.537), train_loss = 1.11769559, grad/param norm = 2.4566e-01, time/batch = 0.3097s	
1488/2700 (epoch 27.556), train_loss = 1.04902252, grad/param norm = 1.6902e-01, time/batch = 0.3248s	
1489/2700 (epoch 27.574), train_loss = 1.01589008, grad/param norm = 1.5729e-01, time/batch = 0.3311s	
1490/2700 (epoch 27.593), train_loss = 1.07847844, grad/param norm = 1.7757e-01, time/batch = 0.3251s	
1491/2700 (epoch 27.611), train_loss = 1.03736927, grad/param norm = 1.9183e-01, time/batch = 0.3204s	
1492/2700 (epoch 27.630), train_loss = 1.05559777, grad/param norm = 2.0150e-01, time/batch = 0.2775s	
1493/2700 (epoch 27.648), train_loss = 1.05158009, grad/param norm = 1.7240e-01, time/batch = 0.3131s	
1494/2700 (epoch 27.667), train_loss = 1.05938716, grad/param norm = 2.1029e-01, time/batch = 0.3035s	
1495/2700 (epoch 27.685), train_loss = 1.11287615, grad/param norm = 2.3993e-01, time/batch = 0.2895s	
1496/2700 (epoch 27.704), train_loss = 1.11088958, grad/param norm = 2.0726e-01, time/batch = 0.2930s	
1497/2700 (epoch 27.722), train_loss = 1.10653635, grad/param norm = 1.8163e-01, time/batch = 0.2974s	
1498/2700 (epoch 27.741), train_loss = 1.02908480, grad/param norm = 1.5394e-01, time/batch = 0.3062s	
1499/2700 (epoch 27.759), train_loss = 1.04286791, grad/param norm = 1.5305e-01, time/batch = 0.3162s	
1500/2700 (epoch 27.778), train_loss = 1.10220870, grad/param norm = 2.1771e-01, time/batch = 0.3245s	
1501/2700 (epoch 27.796), train_loss = 1.04724227, grad/param norm = 1.9212e-01, time/batch = 0.3167s	
1502/2700 (epoch 27.815), train_loss = 1.08897972, grad/param norm = 1.6475e-01, time/batch = 0.3070s	
1503/2700 (epoch 27.833), train_loss = 1.04680301, grad/param norm = 1.6250e-01, time/batch = 0.3080s	
1504/2700 (epoch 27.852), train_loss = 1.05734643, grad/param norm = 2.0436e-01, time/batch = 0.3216s	
1505/2700 (epoch 27.870), train_loss = 1.07679423, grad/param norm = 1.9464e-01, time/batch = 0.3152s	
1506/2700 (epoch 27.889), train_loss = 1.04164377, grad/param norm = 1.6337e-01, time/batch = 0.2937s	
1507/2700 (epoch 27.907), train_loss = 1.13056672, grad/param norm = 1.8247e-01, time/batch = 0.2943s	
1508/2700 (epoch 27.926), train_loss = 1.07810256, grad/param norm = 1.8735e-01, time/batch = 0.2911s	
1509/2700 (epoch 27.944), train_loss = 1.07295686, grad/param norm = 1.7249e-01, time/batch = 0.2996s	
1510/2700 (epoch 27.963), train_loss = 1.06277772, grad/param norm = 1.5745e-01, time/batch = 0.3135s	
1511/2700 (epoch 27.981), train_loss = 1.00620865, grad/param norm = 1.6176e-01, time/batch = 0.3091s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1512/2700 (epoch 28.000), train_loss = 1.08655452, grad/param norm = 1.9793e-01, time/batch = 0.3053s	
1513/2700 (epoch 28.019), train_loss = 1.16844452, grad/param norm = 1.9755e-01, time/batch = 0.3145s	
1514/2700 (epoch 28.037), train_loss = 1.10900962, grad/param norm = 2.1129e-01, time/batch = 0.2811s	
1515/2700 (epoch 28.056), train_loss = 1.06902380, grad/param norm = 2.0518e-01, time/batch = 0.2464s	
1516/2700 (epoch 28.074), train_loss = 1.05328742, grad/param norm = 2.1529e-01, time/batch = 0.3087s	
1517/2700 (epoch 28.093), train_loss = 1.00266875, grad/param norm = 1.8829e-01, time/batch = 0.3084s	
1518/2700 (epoch 28.111), train_loss = 0.99640954, grad/param norm = 1.7173e-01, time/batch = 0.3061s	
1519/2700 (epoch 28.130), train_loss = 1.08114560, grad/param norm = 2.8005e-01, time/batch = 0.3174s	
1520/2700 (epoch 28.148), train_loss = 1.05008346, grad/param norm = 2.1607e-01, time/batch = 0.3188s	
1521/2700 (epoch 28.167), train_loss = 1.08892509, grad/param norm = 1.6968e-01, time/batch = 0.3244s	
1522/2700 (epoch 28.185), train_loss = 1.04611218, grad/param norm = 1.6933e-01, time/batch = 0.3153s	
1523/2700 (epoch 28.204), train_loss = 1.07184058, grad/param norm = 1.7655e-01, time/batch = 0.3048s	
1524/2700 (epoch 28.222), train_loss = 1.00729779, grad/param norm = 1.7077e-01, time/batch = 0.3202s	
1525/2700 (epoch 28.241), train_loss = 0.98730242, grad/param norm = 1.6182e-01, time/batch = 0.3121s	
1526/2700 (epoch 28.259), train_loss = 1.01365286, grad/param norm = 1.7495e-01, time/batch = 0.2392s	
1527/2700 (epoch 28.278), train_loss = 1.06315173, grad/param norm = 1.7975e-01, time/batch = 0.3182s	
1528/2700 (epoch 28.296), train_loss = 1.03189915, grad/param norm = 1.7808e-01, time/batch = 0.3144s	
1529/2700 (epoch 28.315), train_loss = 1.02512305, grad/param norm = 2.2541e-01, time/batch = 0.3158s	
1530/2700 (epoch 28.333), train_loss = 1.05384903, grad/param norm = 2.2052e-01, time/batch = 0.3171s	
1531/2700 (epoch 28.352), train_loss = 1.04956145, grad/param norm = 2.1572e-01, time/batch = 0.3190s	
1532/2700 (epoch 28.370), train_loss = 1.03698231, grad/param norm = 2.1287e-01, time/batch = 0.3143s	
1533/2700 (epoch 28.389), train_loss = 1.02033122, grad/param norm = 1.8651e-01, time/batch = 0.2905s	
1534/2700 (epoch 28.407), train_loss = 1.11278232, grad/param norm = 1.9087e-01, time/batch = 0.3169s	
1535/2700 (epoch 28.426), train_loss = 1.10437799, grad/param norm = 2.0230e-01, time/batch = 0.3038s	
1536/2700 (epoch 28.444), train_loss = 1.04721491, grad/param norm = 1.6698e-01, time/batch = 0.2984s	
1537/2700 (epoch 28.463), train_loss = 1.06775223, grad/param norm = 1.7829e-01, time/batch = 0.2585s	
1538/2700 (epoch 28.481), train_loss = 1.01963060, grad/param norm = 1.7695e-01, time/batch = 0.3205s	
1539/2700 (epoch 28.500), train_loss = 0.98951528, grad/param norm = 1.9019e-01, time/batch = 0.3196s	
1540/2700 (epoch 28.519), train_loss = 1.07082420, grad/param norm = 2.1829e-01, time/batch = 0.3183s	
1541/2700 (epoch 28.537), train_loss = 1.08987823, grad/param norm = 2.5379e-01, time/batch = 0.3199s	
1542/2700 (epoch 28.556), train_loss = 1.02222376, grad/param norm = 2.0184e-01, time/batch = 0.2915s	
1543/2700 (epoch 28.574), train_loss = 0.98652887, grad/param norm = 1.6801e-01, time/batch = 0.3179s	
1544/2700 (epoch 28.593), train_loss = 1.03961649, grad/param norm = 1.7565e-01, time/batch = 0.3155s	
1545/2700 (epoch 28.611), train_loss = 1.00284715, grad/param norm = 1.8146e-01, time/batch = 0.3038s	
1546/2700 (epoch 28.630), train_loss = 1.01494323, grad/param norm = 1.9128e-01, time/batch = 0.2969s	
1547/2700 (epoch 28.648), train_loss = 1.02131409, grad/param norm = 1.8511e-01, time/batch = 0.2974s	
1548/2700 (epoch 28.667), train_loss = 1.01698460, grad/param norm = 1.8996e-01, time/batch = 0.2588s	
1549/2700 (epoch 28.685), train_loss = 1.04673934, grad/param norm = 1.7933e-01, time/batch = 0.3167s	
1550/2700 (epoch 28.704), train_loss = 1.06237207, grad/param norm = 1.9306e-01, time/batch = 0.3140s	
1551/2700 (epoch 28.722), train_loss = 1.07627414, grad/param norm = 2.1683e-01, time/batch = 0.3246s	
1552/2700 (epoch 28.741), train_loss = 0.99433375, grad/param norm = 1.7082e-01, time/batch = 0.3163s	
1553/2700 (epoch 28.759), train_loss = 1.01561267, grad/param norm = 1.7885e-01, time/batch = 0.3181s	
1554/2700 (epoch 28.778), train_loss = 1.06330649, grad/param norm = 2.2946e-01, time/batch = 0.3139s	
1555/2700 (epoch 28.796), train_loss = 1.01343388, grad/param norm = 2.1854e-01, time/batch = 0.3021s	
1556/2700 (epoch 28.815), train_loss = 1.05497418, grad/param norm = 1.6874e-01, time/batch = 0.2921s	
1557/2700 (epoch 28.833), train_loss = 1.00955625, grad/param norm = 1.6683e-01, time/batch = 0.2944s	
1558/2700 (epoch 28.852), train_loss = 1.01724835, grad/param norm = 2.0843e-01, time/batch = 0.2958s	
1559/2700 (epoch 28.870), train_loss = 1.03143533, grad/param norm = 1.7772e-01, time/batch = 0.2751s	
1560/2700 (epoch 28.889), train_loss = 1.00475094, grad/param norm = 1.6368e-01, time/batch = 0.3139s	
1561/2700 (epoch 28.907), train_loss = 1.08745988, grad/param norm = 1.8183e-01, time/batch = 0.3309s	
1562/2700 (epoch 28.926), train_loss = 1.04593120, grad/param norm = 2.0660e-01, time/batch = 0.3202s	
1563/2700 (epoch 28.944), train_loss = 1.05288572, grad/param norm = 2.0579e-01, time/batch = 0.3166s	
1564/2700 (epoch 28.963), train_loss = 1.04882029, grad/param norm = 2.1816e-01, time/batch = 0.3159s	
1565/2700 (epoch 28.981), train_loss = 0.98203530, grad/param norm = 1.7636e-01, time/batch = 0.3204s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
1566/2700 (epoch 29.000), train_loss = 1.04773590, grad/param norm = 2.0293e-01, time/batch = 0.3064s	
1567/2700 (epoch 29.019), train_loss = 1.12862283, grad/param norm = 1.8585e-01, time/batch = 0.3019s	
1568/2700 (epoch 29.037), train_loss = 1.08169875, grad/param norm = 2.2264e-01, time/batch = 0.2917s	
1569/2700 (epoch 29.056), train_loss = 1.02969707, grad/param norm = 1.9724e-01, time/batch = 0.2937s	
1570/2700 (epoch 29.074), train_loss = 1.01921325, grad/param norm = 2.1097e-01, time/batch = 0.2406s	
1571/2700 (epoch 29.093), train_loss = 0.97180130, grad/param norm = 1.9375e-01, time/batch = 0.3188s	
1572/2700 (epoch 29.111), train_loss = 0.97020137, grad/param norm = 1.9369e-01, time/batch = 0.3133s	
1573/2700 (epoch 29.130), train_loss = 1.03601988, grad/param norm = 2.4497e-01, time/batch = 0.3187s	
1574/2700 (epoch 29.148), train_loss = 1.00836390, grad/param norm = 1.8199e-01, time/batch = 0.3234s	
1575/2700 (epoch 29.167), train_loss = 1.05469316, grad/param norm = 1.8889e-01, time/batch = 0.3200s	
1576/2700 (epoch 29.185), train_loss = 1.03063168, grad/param norm = 2.1052e-01, time/batch = 0.3039s	
1577/2700 (epoch 29.204), train_loss = 1.04345404, grad/param norm = 2.0851e-01, time/batch = 0.2944s	
1578/2700 (epoch 29.222), train_loss = 0.98367947, grad/param norm = 1.9293e-01, time/batch = 0.2918s	
1579/2700 (epoch 29.241), train_loss = 0.95830216, grad/param norm = 1.9062e-01, time/batch = 0.2862s	
1580/2700 (epoch 29.259), train_loss = 0.97935434, grad/param norm = 1.7536e-01, time/batch = 0.3078s	
1581/2700 (epoch 29.278), train_loss = 1.04086491, grad/param norm = 2.3267e-01, time/batch = 0.2960s	
1582/2700 (epoch 29.296), train_loss = 1.00813774, grad/param norm = 1.9344e-01, time/batch = 0.3049s	
1583/2700 (epoch 29.315), train_loss = 0.97505134, grad/param norm = 1.6639e-01, time/batch = 0.3118s	
1584/2700 (epoch 29.333), train_loss = 1.00530631, grad/param norm = 1.9787e-01, time/batch = 0.2968s	
1585/2700 (epoch 29.352), train_loss = 1.01493110, grad/param norm = 2.4585e-01, time/batch = 0.3021s	
1586/2700 (epoch 29.370), train_loss = 1.00618720, grad/param norm = 2.3937e-01, time/batch = 0.2963s	
1587/2700 (epoch 29.389), train_loss = 0.99076322, grad/param norm = 2.0509e-01, time/batch = 0.2984s	
1588/2700 (epoch 29.407), train_loss = 1.07875645, grad/param norm = 1.7830e-01, time/batch = 0.2997s	
1589/2700 (epoch 29.426), train_loss = 1.06246657, grad/param norm = 1.8240e-01, time/batch = 0.3094s	
1590/2700 (epoch 29.444), train_loss = 1.01650548, grad/param norm = 1.8362e-01, time/batch = 0.3182s	
1591/2700 (epoch 29.463), train_loss = 1.04317943, grad/param norm = 2.2429e-01, time/batch = 0.3298s	
1592/2700 (epoch 29.481), train_loss = 0.99130830, grad/param norm = 2.0301e-01, time/batch = 0.3131s	
1593/2700 (epoch 29.500), train_loss = 0.96544848, grad/param norm = 2.2379e-01, time/batch = 0.3028s	
1594/2700 (epoch 29.519), train_loss = 1.03862483, grad/param norm = 2.2657e-01, time/batch = 0.2928s	
1595/2700 (epoch 29.537), train_loss = 1.03902796, grad/param norm = 2.0680e-01, time/batch = 0.2913s	
1596/2700 (epoch 29.556), train_loss = 0.98547561, grad/param norm = 2.2095e-01, time/batch = 0.2880s	
1597/2700 (epoch 29.574), train_loss = 0.96188808, grad/param norm = 2.1230e-01, time/batch = 0.2930s	
1598/2700 (epoch 29.593), train_loss = 1.00968226, grad/param norm = 1.7752e-01, time/batch = 0.3006s	
1599/2700 (epoch 29.611), train_loss = 0.95851136, grad/param norm = 1.6623e-01, time/batch = 0.3056s	
1600/2700 (epoch 29.630), train_loss = 0.97916581, grad/param norm = 1.7704e-01, time/batch = 0.3114s	
1601/2700 (epoch 29.648), train_loss = 0.98602409, grad/param norm = 1.9520e-01, time/batch = 0.3251s	
1602/2700 (epoch 29.667), train_loss = 0.99409675, grad/param norm = 2.0949e-01, time/batch = 0.3143s	
1603/2700 (epoch 29.685), train_loss = 1.00889567, grad/param norm = 1.9049e-01, time/batch = 0.3109s	
1604/2700 (epoch 29.704), train_loss = 1.01956298, grad/param norm = 1.7632e-01, time/batch = 0.3108s	
1605/2700 (epoch 29.722), train_loss = 1.03102682, grad/param norm = 1.9243e-01, time/batch = 0.2991s	
1606/2700 (epoch 29.741), train_loss = 0.97797272, grad/param norm = 2.1067e-01, time/batch = 0.2915s	
1607/2700 (epoch 29.759), train_loss = 0.98424965, grad/param norm = 1.7727e-01, time/batch = 0.2966s	
1608/2700 (epoch 29.778), train_loss = 1.01624060, grad/param norm = 1.7422e-01, time/batch = 0.3003s	
1609/2700 (epoch 29.796), train_loss = 0.97049396, grad/param norm = 1.9406e-01, time/batch = 0.3087s	
1610/2700 (epoch 29.815), train_loss = 1.03254051, grad/param norm = 2.1586e-01, time/batch = 0.3110s	
1611/2700 (epoch 29.833), train_loss = 0.98753096, grad/param norm = 2.0261e-01, time/batch = 0.3244s	
1612/2700 (epoch 29.852), train_loss = 0.97666711, grad/param norm = 1.8770e-01, time/batch = 0.3108s	
1613/2700 (epoch 29.870), train_loss = 1.00006456, grad/param norm = 1.9368e-01, time/batch = 0.3164s	
1614/2700 (epoch 29.889), train_loss = 0.98576955, grad/param norm = 2.2078e-01, time/batch = 0.3186s	
1615/2700 (epoch 29.907), train_loss = 1.06574646, grad/param norm = 2.2771e-01, time/batch = 0.2504s	
1616/2700 (epoch 29.926), train_loss = 1.01309791, grad/param norm = 2.1507e-01, time/batch = 0.3120s	
1617/2700 (epoch 29.944), train_loss = 1.00701725, grad/param norm = 1.7601e-01, time/batch = 0.3151s	
1618/2700 (epoch 29.963), train_loss = 1.00656482, grad/param norm = 1.8215e-01, time/batch = 0.3211s	
1619/2700 (epoch 29.981), train_loss = 0.95013690, grad/param norm = 1.8253e-01, time/batch = 0.3194s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
1620/2700 (epoch 30.000), train_loss = 1.00991375, grad/param norm = 1.9556e-01, time/batch = 0.3103s	
1621/2700 (epoch 30.019), train_loss = 1.09637149, grad/param norm = 1.9841e-01, time/batch = 0.3210s	
1622/2700 (epoch 30.037), train_loss = 1.02991993, grad/param norm = 1.8197e-01, time/batch = 0.3059s	
1623/2700 (epoch 30.056), train_loss = 0.99246927, grad/param norm = 1.9578e-01, time/batch = 0.3214s	
1624/2700 (epoch 30.074), train_loss = 1.00956646, grad/param norm = 2.9141e-01, time/batch = 0.3169s	
1625/2700 (epoch 30.093), train_loss = 0.96116738, grad/param norm = 2.3170e-01, time/batch = 0.2903s	
1626/2700 (epoch 30.111), train_loss = 0.94344133, grad/param norm = 1.9620e-01, time/batch = 0.2440s	
1627/2700 (epoch 30.130), train_loss = 0.99089134, grad/param norm = 2.1155e-01, time/batch = 0.3199s	
1628/2700 (epoch 30.148), train_loss = 0.98277311, grad/param norm = 2.1550e-01, time/batch = 0.3191s	
1629/2700 (epoch 30.167), train_loss = 1.02913585, grad/param norm = 2.1170e-01, time/batch = 0.3033s	
1630/2700 (epoch 30.185), train_loss = 0.99873383, grad/param norm = 1.9855e-01, time/batch = 0.2848s	
1631/2700 (epoch 30.204), train_loss = 0.99802454, grad/param norm = 1.7432e-01, time/batch = 0.3154s	
1632/2700 (epoch 30.222), train_loss = 0.94683891, grad/param norm = 2.1340e-01, time/batch = 0.3035s	
1633/2700 (epoch 30.241), train_loss = 0.94171994, grad/param norm = 2.0950e-01, time/batch = 0.2964s	
1634/2700 (epoch 30.259), train_loss = 0.95891878, grad/param norm = 2.0959e-01, time/batch = 0.2722s	
1635/2700 (epoch 30.278), train_loss = 0.99906614, grad/param norm = 1.8588e-01, time/batch = 0.2866s	
1636/2700 (epoch 30.296), train_loss = 0.96457832, grad/param norm = 1.9572e-01, time/batch = 0.2894s	
1637/2700 (epoch 30.315), train_loss = 0.95692032, grad/param norm = 2.2791e-01, time/batch = 0.2848s	
1638/2700 (epoch 30.333), train_loss = 0.97424592, grad/param norm = 2.0968e-01, time/batch = 0.3027s	
1639/2700 (epoch 30.352), train_loss = 0.97443576, grad/param norm = 2.1830e-01, time/batch = 0.2882s	
1640/2700 (epoch 30.370), train_loss = 0.97067999, grad/param norm = 2.2833e-01, time/batch = 0.2872s	
1641/2700 (epoch 30.389), train_loss = 0.95912602, grad/param norm = 2.3752e-01, time/batch = 0.3026s	
1642/2700 (epoch 30.407), train_loss = 1.04841538, grad/param norm = 2.1254e-01, time/batch = 0.2914s	
1643/2700 (epoch 30.426), train_loss = 1.03230961, grad/param norm = 2.1778e-01, time/batch = 0.2877s	
1644/2700 (epoch 30.444), train_loss = 0.98831325, grad/param norm = 2.0355e-01, time/batch = 0.2721s	
1645/2700 (epoch 30.463), train_loss = 1.00710206, grad/param norm = 1.9328e-01, time/batch = 0.2951s	
1646/2700 (epoch 30.481), train_loss = 0.96174897, grad/param norm = 2.2330e-01, time/batch = 0.2996s	
1647/2700 (epoch 30.500), train_loss = 0.93258912, grad/param norm = 2.2977e-01, time/batch = 0.3043s	
1648/2700 (epoch 30.519), train_loss = 1.00014758, grad/param norm = 2.1869e-01, time/batch = 0.3031s	
1649/2700 (epoch 30.537), train_loss = 1.00454002, grad/param norm = 2.3845e-01, time/batch = 0.2480s	
1650/2700 (epoch 30.556), train_loss = 0.94467726, grad/param norm = 1.9925e-01, time/batch = 0.2911s	
1651/2700 (epoch 30.574), train_loss = 0.93154799, grad/param norm = 2.1468e-01, time/batch = 0.3002s	
1652/2700 (epoch 30.593), train_loss = 0.98677526, grad/param norm = 1.9011e-01, time/batch = 0.3059s	
1653/2700 (epoch 30.611), train_loss = 0.93510331, grad/param norm = 1.9657e-01, time/batch = 0.2823s	
1654/2700 (epoch 30.630), train_loss = 0.95295927, grad/param norm = 1.8234e-01, time/batch = 0.3015s	
1655/2700 (epoch 30.648), train_loss = 0.95518095, grad/param norm = 2.0628e-01, time/batch = 0.3040s	
1656/2700 (epoch 30.667), train_loss = 0.95392162, grad/param norm = 2.1917e-01, time/batch = 0.3013s	
1657/2700 (epoch 30.685), train_loss = 0.97905934, grad/param norm = 1.9424e-01, time/batch = 0.2927s	
1658/2700 (epoch 30.704), train_loss = 0.98890721, grad/param norm = 2.0179e-01, time/batch = 0.2837s	
1659/2700 (epoch 30.722), train_loss = 1.00600785, grad/param norm = 1.9662e-01, time/batch = 0.2821s	
1660/2700 (epoch 30.741), train_loss = 0.93740376, grad/param norm = 1.8860e-01, time/batch = 0.2677s	
1661/2700 (epoch 30.759), train_loss = 0.93837294, grad/param norm = 1.5416e-01, time/batch = 0.3267s	
1662/2700 (epoch 30.778), train_loss = 0.97520237, grad/param norm = 1.6644e-01, time/batch = 0.3161s	
1663/2700 (epoch 30.796), train_loss = 0.92845923, grad/param norm = 1.8028e-01, time/batch = 0.3136s	
1664/2700 (epoch 30.815), train_loss = 0.99561063, grad/param norm = 2.2605e-01, time/batch = 0.3128s	
1665/2700 (epoch 30.833), train_loss = 0.96939511, grad/param norm = 2.2782e-01, time/batch = 0.3184s	
1666/2700 (epoch 30.852), train_loss = 0.95741136, grad/param norm = 2.4695e-01, time/batch = 0.3114s	
1667/2700 (epoch 30.870), train_loss = 0.98035565, grad/param norm = 2.1358e-01, time/batch = 0.2893s	
1668/2700 (epoch 30.889), train_loss = 0.94012604, grad/param norm = 1.9810e-01, time/batch = 0.2910s	
1669/2700 (epoch 30.907), train_loss = 1.02507786, grad/param norm = 2.0942e-01, time/batch = 0.2883s	
1670/2700 (epoch 30.926), train_loss = 0.98728569, grad/param norm = 2.4652e-01, time/batch = 0.2920s	
1671/2700 (epoch 30.944), train_loss = 0.99044796, grad/param norm = 2.4188e-01, time/batch = 0.2813s	
1672/2700 (epoch 30.963), train_loss = 0.97064942, grad/param norm = 1.7631e-01, time/batch = 0.3245s	
1673/2700 (epoch 30.981), train_loss = 0.91990866, grad/param norm = 1.9593e-01, time/batch = 0.3159s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
1674/2700 (epoch 31.000), train_loss = 0.97194340, grad/param norm = 1.8923e-01, time/batch = 0.3157s	
1675/2700 (epoch 31.019), train_loss = 1.07048793, grad/param norm = 2.1863e-01, time/batch = 0.3075s	
1676/2700 (epoch 31.037), train_loss = 1.00983178, grad/param norm = 2.1911e-01, time/batch = 0.2967s	
1677/2700 (epoch 31.056), train_loss = 0.95923290, grad/param norm = 1.9043e-01, time/batch = 0.2873s	
1678/2700 (epoch 31.074), train_loss = 0.93957276, grad/param norm = 1.8302e-01, time/batch = 0.2843s	
1679/2700 (epoch 31.093), train_loss = 0.92841783, grad/param norm = 2.4914e-01, time/batch = 0.2858s	
1680/2700 (epoch 31.111), train_loss = 0.91390905, grad/param norm = 2.0270e-01, time/batch = 0.2960s	
1681/2700 (epoch 31.130), train_loss = 0.97130556, grad/param norm = 2.6025e-01, time/batch = 0.2818s	
1682/2700 (epoch 31.148), train_loss = 0.94195003, grad/param norm = 1.8876e-01, time/batch = 0.2593s	
1683/2700 (epoch 31.167), train_loss = 0.98399951, grad/param norm = 1.8466e-01, time/batch = 0.1887s	
1684/2700 (epoch 31.185), train_loss = 0.95351597, grad/param norm = 1.8260e-01, time/batch = 0.2897s	
1685/2700 (epoch 31.204), train_loss = 0.97937601, grad/param norm = 2.3944e-01, time/batch = 0.2840s	
1686/2700 (epoch 31.222), train_loss = 0.92180688, grad/param norm = 2.0719e-01, time/batch = 0.3038s	
1687/2700 (epoch 31.241), train_loss = 0.90026351, grad/param norm = 1.8418e-01, time/batch = 0.3180s	
1688/2700 (epoch 31.259), train_loss = 0.92451552, grad/param norm = 2.0381e-01, time/batch = 0.3271s	
1689/2700 (epoch 31.278), train_loss = 0.96836104, grad/param norm = 2.1116e-01, time/batch = 0.3307s	
1690/2700 (epoch 31.296), train_loss = 0.93441238, grad/param norm = 1.9047e-01, time/batch = 0.3252s	
1691/2700 (epoch 31.315), train_loss = 0.91400596, grad/param norm = 1.9929e-01, time/batch = 0.3208s	
1692/2700 (epoch 31.333), train_loss = 0.94279481, grad/param norm = 2.1829e-01, time/batch = 0.3181s	
1693/2700 (epoch 31.352), train_loss = 0.94442479, grad/param norm = 2.4352e-01, time/batch = 0.2532s	
1694/2700 (epoch 31.370), train_loss = 0.94309372, grad/param norm = 2.3802e-01, time/batch = 0.2796s	
1695/2700 (epoch 31.389), train_loss = 0.93091978, grad/param norm = 2.5744e-01, time/batch = 0.2961s	
1696/2700 (epoch 31.407), train_loss = 1.02647677, grad/param norm = 2.0819e-01, time/batch = 0.2991s	
1697/2700 (epoch 31.426), train_loss = 0.99428984, grad/param norm = 2.0747e-01, time/batch = 0.3101s	
1698/2700 (epoch 31.444), train_loss = 0.95800367, grad/param norm = 1.9644e-01, time/batch = 0.3136s	
1699/2700 (epoch 31.463), train_loss = 0.96824258, grad/param norm = 2.0115e-01, time/batch = 0.3186s	
1700/2700 (epoch 31.481), train_loss = 0.91570292, grad/param norm = 1.8789e-01, time/batch = 0.3196s	
1701/2700 (epoch 31.500), train_loss = 0.88496378, grad/param norm = 2.0416e-01, time/batch = 0.3220s	
1702/2700 (epoch 31.519), train_loss = 0.97179423, grad/param norm = 2.2202e-01, time/batch = 0.3005s	
1703/2700 (epoch 31.537), train_loss = 0.96934334, grad/param norm = 2.3090e-01, time/batch = 0.3104s	
1704/2700 (epoch 31.556), train_loss = 0.92614145, grad/param norm = 2.2266e-01, time/batch = 0.3159s	
1705/2700 (epoch 31.574), train_loss = 0.89733335, grad/param norm = 2.0720e-01, time/batch = 0.2487s	
1706/2700 (epoch 31.593), train_loss = 0.94128165, grad/param norm = 1.7348e-01, time/batch = 0.3159s	
1707/2700 (epoch 31.611), train_loss = 0.90258153, grad/param norm = 1.8701e-01, time/batch = 0.3143s	
1708/2700 (epoch 31.630), train_loss = 0.92267430, grad/param norm = 2.0268e-01, time/batch = 0.3110s	
1709/2700 (epoch 31.648), train_loss = 0.92227326, grad/param norm = 2.0397e-01, time/batch = 0.3206s	
1710/2700 (epoch 31.667), train_loss = 0.92667513, grad/param norm = 2.3953e-01, time/batch = 0.3211s	
1711/2700 (epoch 31.685), train_loss = 0.96842791, grad/param norm = 2.5278e-01, time/batch = 0.3258s	
1712/2700 (epoch 31.704), train_loss = 0.97398178, grad/param norm = 2.4374e-01, time/batch = 0.3256s	
1713/2700 (epoch 31.722), train_loss = 0.98050071, grad/param norm = 2.1507e-01, time/batch = 0.3048s	
1714/2700 (epoch 31.741), train_loss = 0.90506503, grad/param norm = 1.8736e-01, time/batch = 0.3194s	
1715/2700 (epoch 31.759), train_loss = 0.91017204, grad/param norm = 1.8700e-01, time/batch = 0.3065s	
1716/2700 (epoch 31.778), train_loss = 0.94650999, grad/param norm = 1.8951e-01, time/batch = 0.2346s	
1717/2700 (epoch 31.796), train_loss = 0.89938615, grad/param norm = 1.9375e-01, time/batch = 0.3143s	
1718/2700 (epoch 31.815), train_loss = 0.95806673, grad/param norm = 2.0718e-01, time/batch = 0.3127s	
1719/2700 (epoch 31.833), train_loss = 0.91925212, grad/param norm = 1.9986e-01, time/batch = 0.3176s	
1720/2700 (epoch 31.852), train_loss = 0.92486835, grad/param norm = 2.2496e-01, time/batch = 0.3078s	
1721/2700 (epoch 31.870), train_loss = 0.95730340, grad/param norm = 2.3846e-01, time/batch = 0.2775s	
1722/2700 (epoch 31.889), train_loss = 0.90783197, grad/param norm = 1.8364e-01, time/batch = 0.3156s	
1723/2700 (epoch 31.907), train_loss = 0.98044889, grad/param norm = 1.8358e-01, time/batch = 0.2996s	
1724/2700 (epoch 31.926), train_loss = 0.92707533, grad/param norm = 1.9648e-01, time/batch = 0.2954s	
1725/2700 (epoch 31.944), train_loss = 0.93972505, grad/param norm = 2.1880e-01, time/batch = 0.2896s	
1726/2700 (epoch 31.963), train_loss = 0.94126222, grad/param norm = 1.9010e-01, time/batch = 0.2953s	
1727/2700 (epoch 31.981), train_loss = 0.88244733, grad/param norm = 1.6944e-01, time/batch = 0.2658s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
1728/2700 (epoch 32.000), train_loss = 0.93509557, grad/param norm = 1.8368e-01, time/batch = 0.3119s	
1729/2700 (epoch 32.019), train_loss = 1.03003401, grad/param norm = 2.0612e-01, time/batch = 0.3117s	
1730/2700 (epoch 32.037), train_loss = 0.95911664, grad/param norm = 1.7859e-01, time/batch = 0.2866s	
1731/2700 (epoch 32.056), train_loss = 0.92611461, grad/param norm = 1.9050e-01, time/batch = 0.3175s	
1732/2700 (epoch 32.074), train_loss = 0.92041914, grad/param norm = 2.5848e-01, time/batch = 0.3150s	
1733/2700 (epoch 32.093), train_loss = 0.88407901, grad/param norm = 1.8789e-01, time/batch = 0.3025s	
1734/2700 (epoch 32.111), train_loss = 0.86956277, grad/param norm = 1.7406e-01, time/batch = 0.2943s	
1735/2700 (epoch 32.130), train_loss = 0.93268064, grad/param norm = 2.5128e-01, time/batch = 0.2862s	
1736/2700 (epoch 32.148), train_loss = 0.92099352, grad/param norm = 2.1770e-01, time/batch = 0.2893s	
1737/2700 (epoch 32.167), train_loss = 0.95565129, grad/param norm = 1.9160e-01, time/batch = 0.2962s	
1738/2700 (epoch 32.185), train_loss = 0.92272286, grad/param norm = 1.8148e-01, time/batch = 0.2849s	
1739/2700 (epoch 32.204), train_loss = 0.93222622, grad/param norm = 1.9578e-01, time/batch = 0.3095s	
1740/2700 (epoch 32.222), train_loss = 0.88103237, grad/param norm = 1.9510e-01, time/batch = 0.2490s	
1741/2700 (epoch 32.241), train_loss = 0.87385844, grad/param norm = 2.1938e-01, time/batch = 0.3131s	
1742/2700 (epoch 32.259), train_loss = 0.89789455, grad/param norm = 2.1582e-01, time/batch = 0.3139s	
1743/2700 (epoch 32.278), train_loss = 0.95665877, grad/param norm = 2.9079e-01, time/batch = 0.2980s	
1744/2700 (epoch 32.296), train_loss = 0.91904609, grad/param norm = 2.0497e-01, time/batch = 0.2909s	
1745/2700 (epoch 32.315), train_loss = 0.89144764, grad/param norm = 2.0284e-01, time/batch = 0.2863s	
1746/2700 (epoch 32.333), train_loss = 0.90748982, grad/param norm = 2.1744e-01, time/batch = 0.2885s	
1747/2700 (epoch 32.352), train_loss = 0.89937289, grad/param norm = 2.0458e-01, time/batch = 0.2984s	
1748/2700 (epoch 32.370), train_loss = 0.90195679, grad/param norm = 2.3351e-01, time/batch = 0.3035s	
1749/2700 (epoch 32.389), train_loss = 0.92100609, grad/param norm = 2.9456e-01, time/batch = 0.2901s	
1750/2700 (epoch 32.407), train_loss = 1.02152463, grad/param norm = 2.8644e-01, time/batch = 0.2990s	
1751/2700 (epoch 32.426), train_loss = 0.98402211, grad/param norm = 2.3235e-01, time/batch = 0.3250s	
1752/2700 (epoch 32.444), train_loss = 0.92590781, grad/param norm = 1.9673e-01, time/batch = 0.3187s	
1753/2700 (epoch 32.463), train_loss = 0.93181292, grad/param norm = 1.9103e-01, time/batch = 0.3060s	
1754/2700 (epoch 32.481), train_loss = 0.88603151, grad/param norm = 1.9451e-01, time/batch = 0.3184s	
1755/2700 (epoch 32.500), train_loss = 0.85245535, grad/param norm = 1.9069e-01, time/batch = 0.3026s	
1756/2700 (epoch 32.519), train_loss = 0.92167461, grad/param norm = 2.0277e-01, time/batch = 0.2936s	
1757/2700 (epoch 32.537), train_loss = 0.93350505, grad/param norm = 2.3093e-01, time/batch = 0.2980s	
1758/2700 (epoch 32.556), train_loss = 0.89092962, grad/param norm = 2.3595e-01, time/batch = 0.2917s	
1759/2700 (epoch 32.574), train_loss = 0.87049695, grad/param norm = 1.9444e-01, time/batch = 0.3023s	
1760/2700 (epoch 32.593), train_loss = 0.91433275, grad/param norm = 2.0483e-01, time/batch = 0.2995s	
1761/2700 (epoch 32.611), train_loss = 0.88958449, grad/param norm = 2.5463e-01, time/batch = 0.3314s	
1762/2700 (epoch 32.630), train_loss = 0.90421613, grad/param norm = 2.0255e-01, time/batch = 0.3280s	
1763/2700 (epoch 32.648), train_loss = 0.90029479, grad/param norm = 2.4351e-01, time/batch = 0.3148s	
1764/2700 (epoch 32.667), train_loss = 0.91025520, grad/param norm = 2.6171e-01, time/batch = 0.3153s	
1765/2700 (epoch 32.685), train_loss = 0.92828104, grad/param norm = 2.4031e-01, time/batch = 0.3177s	
1766/2700 (epoch 32.704), train_loss = 0.92443483, grad/param norm = 1.9189e-01, time/batch = 0.3133s	
1767/2700 (epoch 32.722), train_loss = 0.94356679, grad/param norm = 2.1675e-01, time/batch = 0.3059s	
1768/2700 (epoch 32.741), train_loss = 0.88425016, grad/param norm = 2.1215e-01, time/batch = 0.2550s	
1769/2700 (epoch 32.759), train_loss = 0.88690811, grad/param norm = 1.9797e-01, time/batch = 0.2945s	
1770/2700 (epoch 32.778), train_loss = 0.91662855, grad/param norm = 1.9826e-01, time/batch = 0.2980s	
1771/2700 (epoch 32.796), train_loss = 0.88052112, grad/param norm = 2.3797e-01, time/batch = 0.2630s	
1772/2700 (epoch 32.815), train_loss = 0.92777350, grad/param norm = 2.1966e-01, time/batch = 0.3204s	
1773/2700 (epoch 32.833), train_loss = 0.90301420, grad/param norm = 2.2004e-01, time/batch = 0.3189s	
1774/2700 (epoch 32.852), train_loss = 0.88491214, grad/param norm = 2.2372e-01, time/batch = 0.2441s	
1775/2700 (epoch 32.870), train_loss = 0.90915266, grad/param norm = 1.9072e-01, time/batch = 0.2861s	
1776/2700 (epoch 32.889), train_loss = 0.87375266, grad/param norm = 2.0203e-01, time/batch = 0.2949s	
1777/2700 (epoch 32.907), train_loss = 0.95543601, grad/param norm = 2.1933e-01, time/batch = 0.3039s	
1778/2700 (epoch 32.926), train_loss = 0.90122226, grad/param norm = 2.0419e-01, time/batch = 0.3178s	
1779/2700 (epoch 32.944), train_loss = 0.89708119, grad/param norm = 1.7722e-01, time/batch = 0.3236s	
1780/2700 (epoch 32.963), train_loss = 0.89929476, grad/param norm = 1.7709e-01, time/batch = 0.3221s	
1781/2700 (epoch 32.981), train_loss = 0.84921570, grad/param norm = 1.8602e-01, time/batch = 0.3034s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
1782/2700 (epoch 33.000), train_loss = 0.90134972, grad/param norm = 1.9310e-01, time/batch = 0.2897s	
1783/2700 (epoch 33.019), train_loss = 0.99979752, grad/param norm = 2.0988e-01, time/batch = 0.3058s	
1784/2700 (epoch 33.037), train_loss = 0.92926576, grad/param norm = 2.0014e-01, time/batch = 0.2519s	
1785/2700 (epoch 33.056), train_loss = 0.90053648, grad/param norm = 2.0946e-01, time/batch = 0.2896s	
1786/2700 (epoch 33.074), train_loss = 0.87763383, grad/param norm = 1.9599e-01, time/batch = 0.2890s	
1787/2700 (epoch 33.093), train_loss = 0.86979862, grad/param norm = 2.7028e-01, time/batch = 0.2821s	
1788/2700 (epoch 33.111), train_loss = 0.86420641, grad/param norm = 2.3317e-01, time/batch = 0.3129s	
1789/2700 (epoch 33.130), train_loss = 0.90084770, grad/param norm = 2.3414e-01, time/batch = 0.3162s	
1790/2700 (epoch 33.148), train_loss = 0.88331174, grad/param norm = 1.8808e-01, time/batch = 0.3207s	
1791/2700 (epoch 33.167), train_loss = 0.92169418, grad/param norm = 1.9648e-01, time/batch = 0.3289s	
1792/2700 (epoch 33.185), train_loss = 0.89610470, grad/param norm = 1.8023e-01, time/batch = 0.3235s	
1793/2700 (epoch 33.204), train_loss = 0.89267673, grad/param norm = 2.0067e-01, time/batch = 0.3113s	
1794/2700 (epoch 33.222), train_loss = 0.84668373, grad/param norm = 1.9938e-01, time/batch = 0.2569s	
1795/2700 (epoch 33.241), train_loss = 0.83934907, grad/param norm = 1.9384e-01, time/batch = 0.2930s	
1796/2700 (epoch 33.259), train_loss = 0.86683044, grad/param norm = 2.2638e-01, time/batch = 0.2630s	
1797/2700 (epoch 33.278), train_loss = 0.90566648, grad/param norm = 2.0589e-01, time/batch = 0.3190s	
1798/2700 (epoch 33.296), train_loss = 0.90245334, grad/param norm = 2.6551e-01, time/batch = 0.3094s	
1799/2700 (epoch 33.315), train_loss = 0.87669964, grad/param norm = 2.4453e-01, time/batch = 0.3146s	
1800/2700 (epoch 33.333), train_loss = 0.87608800, grad/param norm = 2.2192e-01, time/batch = 0.3216s	
1801/2700 (epoch 33.352), train_loss = 0.87250502, grad/param norm = 2.2136e-01, time/batch = 0.3302s	
1802/2700 (epoch 33.370), train_loss = 0.86683826, grad/param norm = 2.2384e-01, time/batch = 0.3234s	
1803/2700 (epoch 33.389), train_loss = 0.86990168, grad/param norm = 2.3336e-01, time/batch = 0.3230s	
1804/2700 (epoch 33.407), train_loss = 0.96993414, grad/param norm = 2.4354e-01, time/batch = 0.3016s	
1805/2700 (epoch 33.426), train_loss = 0.93758655, grad/param norm = 2.2167e-01, time/batch = 0.2373s	
1806/2700 (epoch 33.444), train_loss = 0.90625754, grad/param norm = 2.2472e-01, time/batch = 0.3071s	
1807/2700 (epoch 33.463), train_loss = 0.91030009, grad/param norm = 2.1671e-01, time/batch = 0.3195s	
1808/2700 (epoch 33.481), train_loss = 0.85828764, grad/param norm = 2.0393e-01, time/batch = 0.3148s	
1809/2700 (epoch 33.500), train_loss = 0.81639360, grad/param norm = 1.9052e-01, time/batch = 0.3104s	
1810/2700 (epoch 33.519), train_loss = 0.90511561, grad/param norm = 2.3487e-01, time/batch = 0.3157s	
1811/2700 (epoch 33.537), train_loss = 0.88886324, grad/param norm = 2.0402e-01, time/batch = 0.3185s	
1812/2700 (epoch 33.556), train_loss = 0.84750887, grad/param norm = 1.9835e-01, time/batch = 0.3216s	
1813/2700 (epoch 33.574), train_loss = 0.83339144, grad/param norm = 2.0635e-01, time/batch = 0.3216s	
1814/2700 (epoch 33.593), train_loss = 0.88832716, grad/param norm = 2.0408e-01, time/batch = 0.3034s	
1815/2700 (epoch 33.611), train_loss = 0.84525181, grad/param norm = 2.2355e-01, time/batch = 0.3039s	
1816/2700 (epoch 33.630), train_loss = 0.87515422, grad/param norm = 2.0648e-01, time/batch = 0.2439s	
1817/2700 (epoch 33.648), train_loss = 0.87524751, grad/param norm = 2.4237e-01, time/batch = 0.3193s	
1818/2700 (epoch 33.667), train_loss = 0.85665801, grad/param norm = 2.0472e-01, time/batch = 0.3208s	
1819/2700 (epoch 33.685), train_loss = 0.88615763, grad/param norm = 2.2235e-01, time/batch = 0.3160s	
1820/2700 (epoch 33.704), train_loss = 0.91095325, grad/param norm = 2.7812e-01, time/batch = 0.3082s	
1821/2700 (epoch 33.722), train_loss = 0.92942528, grad/param norm = 2.3745e-01, time/batch = 0.3163s	
1822/2700 (epoch 33.741), train_loss = 0.85541644, grad/param norm = 1.9553e-01, time/batch = 0.3142s	
1823/2700 (epoch 33.759), train_loss = 0.85354053, grad/param norm = 1.8090e-01, time/batch = 0.3168s	
1824/2700 (epoch 33.778), train_loss = 0.88902674, grad/param norm = 2.0689e-01, time/batch = 0.2545s	
1825/2700 (epoch 33.796), train_loss = 0.86782058, grad/param norm = 2.6672e-01, time/batch = 0.2862s	
1826/2700 (epoch 33.815), train_loss = 0.90913209, grad/param norm = 2.4705e-01, time/batch = 0.2871s	
1827/2700 (epoch 33.833), train_loss = 0.88385382, grad/param norm = 2.4852e-01, time/batch = 0.2713s	
1828/2700 (epoch 33.852), train_loss = 0.86330236, grad/param norm = 2.3162e-01, time/batch = 0.3110s	
1829/2700 (epoch 33.870), train_loss = 0.89034838, grad/param norm = 2.2564e-01, time/batch = 0.2997s	
1830/2700 (epoch 33.889), train_loss = 0.84098672, grad/param norm = 1.7493e-01, time/batch = 0.2740s	
1831/2700 (epoch 33.907), train_loss = 0.91374946, grad/param norm = 1.9140e-01, time/batch = 0.3190s	
1832/2700 (epoch 33.926), train_loss = 0.87254300, grad/param norm = 2.2023e-01, time/batch = 0.2966s	
1833/2700 (epoch 33.944), train_loss = 0.87739997, grad/param norm = 2.1613e-01, time/batch = 0.2853s	
1834/2700 (epoch 33.963), train_loss = 0.88583706, grad/param norm = 2.2979e-01, time/batch = 0.2924s	
1835/2700 (epoch 33.981), train_loss = 0.82653274, grad/param norm = 1.8519e-01, time/batch = 0.2542s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
1836/2700 (epoch 34.000), train_loss = 0.86984083, grad/param norm = 1.8403e-01, time/batch = 0.3031s	
1837/2700 (epoch 34.019), train_loss = 0.96668700, grad/param norm = 2.0541e-01, time/batch = 0.3049s	
1838/2700 (epoch 34.037), train_loss = 0.90234656, grad/param norm = 2.2040e-01, time/batch = 0.2886s	
1839/2700 (epoch 34.056), train_loss = 0.88091441, grad/param norm = 2.2304e-01, time/batch = 0.2885s	
1840/2700 (epoch 34.074), train_loss = 0.84936370, grad/param norm = 2.1529e-01, time/batch = 0.2830s	
1841/2700 (epoch 34.093), train_loss = 0.83365472, grad/param norm = 2.2207e-01, time/batch = 0.3046s	
1842/2700 (epoch 34.111), train_loss = 0.82793940, grad/param norm = 2.0470e-01, time/batch = 0.2905s	
1843/2700 (epoch 34.130), train_loss = 0.86543594, grad/param norm = 2.2936e-01, time/batch = 0.2566s	
1844/2700 (epoch 34.148), train_loss = 0.85849328, grad/param norm = 2.1156e-01, time/batch = 0.2865s	
1845/2700 (epoch 34.167), train_loss = 0.89834635, grad/param norm = 2.1496e-01, time/batch = 0.2659s	
1846/2700 (epoch 34.185), train_loss = 0.87577731, grad/param norm = 2.3122e-01, time/batch = 0.3076s	
1847/2700 (epoch 34.204), train_loss = 0.87914742, grad/param norm = 2.4599e-01, time/batch = 0.3021s	
1848/2700 (epoch 34.222), train_loss = 0.81544202, grad/param norm = 1.9442e-01, time/batch = 0.3014s	
1849/2700 (epoch 34.241), train_loss = 0.80691714, grad/param norm = 1.7984e-01, time/batch = 0.3018s	
1850/2700 (epoch 34.259), train_loss = 0.83270553, grad/param norm = 2.0366e-01, time/batch = 0.2614s	
1851/2700 (epoch 34.278), train_loss = 0.86594558, grad/param norm = 2.0923e-01, time/batch = 0.2834s	
1852/2700 (epoch 34.296), train_loss = 0.84569478, grad/param norm = 1.8411e-01, time/batch = 0.2756s	
1853/2700 (epoch 34.315), train_loss = 0.83071809, grad/param norm = 2.1268e-01, time/batch = 0.2873s	
1854/2700 (epoch 34.333), train_loss = 0.86771407, grad/param norm = 2.4587e-01, time/batch = 0.2957s	
1855/2700 (epoch 34.352), train_loss = 0.84986610, grad/param norm = 2.3800e-01, time/batch = 0.2529s	
1856/2700 (epoch 34.370), train_loss = 0.85073405, grad/param norm = 2.3509e-01, time/batch = 0.3208s	
1857/2700 (epoch 34.389), train_loss = 0.83475675, grad/param norm = 2.1465e-01, time/batch = 0.3169s	
1858/2700 (epoch 34.407), train_loss = 0.92911191, grad/param norm = 2.2012e-01, time/batch = 0.3136s	
1859/2700 (epoch 34.426), train_loss = 0.92168574, grad/param norm = 2.7247e-01, time/batch = 0.2993s	
1860/2700 (epoch 34.444), train_loss = 0.88697317, grad/param norm = 2.2216e-01, time/batch = 0.2923s	
1861/2700 (epoch 34.463), train_loss = 0.87870342, grad/param norm = 2.1099e-01, time/batch = 0.2299s	
1862/2700 (epoch 34.481), train_loss = 0.83622090, grad/param norm = 2.4453e-01, time/batch = 0.2862s	
1863/2700 (epoch 34.500), train_loss = 0.79343334, grad/param norm = 2.1894e-01, time/batch = 0.3238s	
1864/2700 (epoch 34.519), train_loss = 0.85393855, grad/param norm = 1.7497e-01, time/batch = 0.3205s	
1865/2700 (epoch 34.537), train_loss = 0.85064571, grad/param norm = 2.0635e-01, time/batch = 0.2988s	
1866/2700 (epoch 34.556), train_loss = 0.83493971, grad/param norm = 2.8567e-01, time/batch = 0.3207s	
1867/2700 (epoch 34.574), train_loss = 0.81932269, grad/param norm = 2.1002e-01, time/batch = 0.3120s	
1868/2700 (epoch 34.593), train_loss = 0.84429253, grad/param norm = 1.7622e-01, time/batch = 0.3031s	
1869/2700 (epoch 34.611), train_loss = 0.81099504, grad/param norm = 1.9224e-01, time/batch = 0.2970s	
1870/2700 (epoch 34.630), train_loss = 0.85084595, grad/param norm = 2.4229e-01, time/batch = 0.2936s	
1871/2700 (epoch 34.648), train_loss = 0.84233829, grad/param norm = 2.2706e-01, time/batch = 0.2784s	
1872/2700 (epoch 34.667), train_loss = 0.82350294, grad/param norm = 2.1219e-01, time/batch = 0.2782s	
1873/2700 (epoch 34.685), train_loss = 0.86783496, grad/param norm = 2.3550e-01, time/batch = 0.3263s	
1874/2700 (epoch 34.704), train_loss = 0.87169094, grad/param norm = 2.1488e-01, time/batch = 0.3253s	
1875/2700 (epoch 34.722), train_loss = 0.89791674, grad/param norm = 2.3171e-01, time/batch = 0.3209s	
1876/2700 (epoch 34.741), train_loss = 0.84089990, grad/param norm = 2.3067e-01, time/batch = 0.2721s	
1877/2700 (epoch 34.759), train_loss = 0.83116424, grad/param norm = 2.2775e-01, time/batch = 0.2622s	
1878/2700 (epoch 34.778), train_loss = 0.86040403, grad/param norm = 2.0484e-01, time/batch = 0.2152s	
1879/2700 (epoch 34.796), train_loss = 0.81073050, grad/param norm = 1.7782e-01, time/batch = 0.2812s	
1880/2700 (epoch 34.815), train_loss = 0.86049652, grad/param norm = 2.1408e-01, time/batch = 0.2986s	
1881/2700 (epoch 34.833), train_loss = 0.84650016, grad/param norm = 2.4819e-01, time/batch = 0.2682s	
1882/2700 (epoch 34.852), train_loss = 0.84011969, grad/param norm = 2.2756e-01, time/batch = 0.3084s	
1883/2700 (epoch 34.870), train_loss = 0.86429721, grad/param norm = 2.4589e-01, time/batch = 0.2938s	
1884/2700 (epoch 34.889), train_loss = 0.82636952, grad/param norm = 2.0946e-01, time/batch = 0.3220s	
1885/2700 (epoch 34.907), train_loss = 0.88492785, grad/param norm = 2.0529e-01, time/batch = 0.3139s	
1886/2700 (epoch 34.926), train_loss = 0.83014030, grad/param norm = 1.7981e-01, time/batch = 0.3006s	
1887/2700 (epoch 34.944), train_loss = 0.83695965, grad/param norm = 1.8949e-01, time/batch = 0.2986s	
1888/2700 (epoch 34.963), train_loss = 0.84209990, grad/param norm = 1.8212e-01, time/batch = 0.2902s	
1889/2700 (epoch 34.981), train_loss = 0.80082985, grad/param norm = 1.9636e-01, time/batch = 0.2564s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
1890/2700 (epoch 35.000), train_loss = 0.84464023, grad/param norm = 2.2662e-01, time/batch = 0.3050s	
1891/2700 (epoch 35.019), train_loss = 0.94608047, grad/param norm = 2.2627e-01, time/batch = 0.3047s	
1892/2700 (epoch 35.037), train_loss = 0.88178121, grad/param norm = 2.2785e-01, time/batch = 0.3072s	
1893/2700 (epoch 35.056), train_loss = 0.84845089, grad/param norm = 1.8820e-01, time/batch = 0.3053s	
1894/2700 (epoch 35.074), train_loss = 0.81226632, grad/param norm = 1.9125e-01, time/batch = 0.2942s	
1895/2700 (epoch 35.093), train_loss = 0.82379887, grad/param norm = 3.0965e-01, time/batch = 0.2898s	
1896/2700 (epoch 35.111), train_loss = 0.80710720, grad/param norm = 2.2530e-01, time/batch = 0.2855s	
1897/2700 (epoch 35.130), train_loss = 0.82547857, grad/param norm = 2.0720e-01, time/batch = 0.2881s	
1898/2700 (epoch 35.148), train_loss = 0.83515506, grad/param norm = 2.3086e-01, time/batch = 0.2845s	
1899/2700 (epoch 35.167), train_loss = 0.86378033, grad/param norm = 1.8911e-01, time/batch = 0.2504s	
1900/2700 (epoch 35.185), train_loss = 0.84114587, grad/param norm = 1.9509e-01, time/batch = 0.2900s	
1901/2700 (epoch 35.204), train_loss = 0.83908146, grad/param norm = 2.4274e-01, time/batch = 0.3016s	
1902/2700 (epoch 35.222), train_loss = 0.82276754, grad/param norm = 3.0238e-01, time/batch = 0.3077s	
1903/2700 (epoch 35.241), train_loss = 0.81295592, grad/param norm = 2.7809e-01, time/batch = 0.3074s	
1904/2700 (epoch 35.259), train_loss = 0.81885420, grad/param norm = 2.2112e-01, time/batch = 0.3094s	
1905/2700 (epoch 35.278), train_loss = 0.86075521, grad/param norm = 2.7754e-01, time/batch = 0.3012s	
1906/2700 (epoch 35.296), train_loss = 0.82881268, grad/param norm = 2.2124e-01, time/batch = 0.2780s	
1907/2700 (epoch 35.315), train_loss = 0.79882878, grad/param norm = 1.9277e-01, time/batch = 0.2791s	
1908/2700 (epoch 35.333), train_loss = 0.81197326, grad/param norm = 1.9647e-01, time/batch = 0.2860s	
1909/2700 (epoch 35.352), train_loss = 0.79941129, grad/param norm = 2.0923e-01, time/batch = 0.2691s	
1910/2700 (epoch 35.370), train_loss = 0.80707005, grad/param norm = 2.3356e-01, time/batch = 0.3170s	
1911/2700 (epoch 35.389), train_loss = 0.79989184, grad/param norm = 2.0795e-01, time/batch = 0.2937s	
1912/2700 (epoch 35.407), train_loss = 0.90312122, grad/param norm = 2.4721e-01, time/batch = 0.3027s	
1913/2700 (epoch 35.426), train_loss = 0.87886140, grad/param norm = 2.2504e-01, time/batch = 0.3105s	
1914/2700 (epoch 35.444), train_loss = 0.84469637, grad/param norm = 2.1712e-01, time/batch = 0.3082s	
1915/2700 (epoch 35.463), train_loss = 0.85719761, grad/param norm = 2.5253e-01, time/batch = 0.2984s	
1916/2700 (epoch 35.481), train_loss = 0.81409804, grad/param norm = 2.4194e-01, time/batch = 0.2962s	
1917/2700 (epoch 35.500), train_loss = 0.76602630, grad/param norm = 2.2454e-01, time/batch = 0.2893s	
1918/2700 (epoch 35.519), train_loss = 0.83443435, grad/param norm = 2.1554e-01, time/batch = 0.2776s	
1919/2700 (epoch 35.537), train_loss = 0.82077553, grad/param norm = 2.0747e-01, time/batch = 0.2464s	
1920/2700 (epoch 35.556), train_loss = 0.79244892, grad/param norm = 2.2209e-01, time/batch = 0.2987s	
1921/2700 (epoch 35.574), train_loss = 0.78578578, grad/param norm = 2.4320e-01, time/batch = 0.3085s	
1922/2700 (epoch 35.593), train_loss = 0.84022362, grad/param norm = 2.2581e-01, time/batch = 0.3261s	
1923/2700 (epoch 35.611), train_loss = 0.78758729, grad/param norm = 2.1687e-01, time/batch = 0.3279s	
1924/2700 (epoch 35.630), train_loss = 0.80980430, grad/param norm = 1.9572e-01, time/batch = 0.3238s	
1925/2700 (epoch 35.648), train_loss = 0.79877093, grad/param norm = 2.0528e-01, time/batch = 0.3180s	
1926/2700 (epoch 35.667), train_loss = 0.79548776, grad/param norm = 2.3642e-01, time/batch = 0.3125s	
1927/2700 (epoch 35.685), train_loss = 0.84136540, grad/param norm = 2.5461e-01, time/batch = 0.3137s	
1928/2700 (epoch 35.704), train_loss = 0.84575211, grad/param norm = 2.1970e-01, time/batch = 0.1935s	
1929/2700 (epoch 35.722), train_loss = 0.86771261, grad/param norm = 2.5238e-01, time/batch = 0.3195s	
1930/2700 (epoch 35.741), train_loss = 0.81058592, grad/param norm = 2.0398e-01, time/batch = 0.2994s	
1931/2700 (epoch 35.759), train_loss = 0.78732915, grad/param norm = 1.8075e-01, time/batch = 0.3177s	
1932/2700 (epoch 35.778), train_loss = 0.82935694, grad/param norm = 2.2916e-01, time/batch = 0.3224s	
1933/2700 (epoch 35.796), train_loss = 0.79852335, grad/param norm = 2.3739e-01, time/batch = 0.3220s	
1934/2700 (epoch 35.815), train_loss = 0.83498551, grad/param norm = 2.2589e-01, time/batch = 0.3199s	
1935/2700 (epoch 35.833), train_loss = 0.81812677, grad/param norm = 2.3022e-01, time/batch = 0.3040s	
1936/2700 (epoch 35.852), train_loss = 0.79661456, grad/param norm = 2.1353e-01, time/batch = 0.2938s	
1937/2700 (epoch 35.870), train_loss = 0.82094984, grad/param norm = 2.1588e-01, time/batch = 0.2822s	
1938/2700 (epoch 35.889), train_loss = 0.80103289, grad/param norm = 2.5141e-01, time/batch = 0.2951s	
1939/2700 (epoch 35.907), train_loss = 0.88280945, grad/param norm = 2.7647e-01, time/batch = 0.2837s	
1940/2700 (epoch 35.926), train_loss = 0.81733901, grad/param norm = 2.2091e-01, time/batch = 0.2797s	
1941/2700 (epoch 35.944), train_loss = 0.80800475, grad/param norm = 1.8871e-01, time/batch = 0.3133s	
1942/2700 (epoch 35.963), train_loss = 0.81511215, grad/param norm = 1.9452e-01, time/batch = 0.3136s	
1943/2700 (epoch 35.981), train_loss = 0.76228030, grad/param norm = 1.7540e-01, time/batch = 0.3180s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
1944/2700 (epoch 36.000), train_loss = 0.80072931, grad/param norm = 1.7135e-01, time/batch = 0.3081s	
1945/2700 (epoch 36.019), train_loss = 0.90781228, grad/param norm = 2.2360e-01, time/batch = 0.2993s	
1946/2700 (epoch 36.037), train_loss = 0.86090672, grad/param norm = 2.7103e-01, time/batch = 0.2957s	
1947/2700 (epoch 36.056), train_loss = 0.84181880, grad/param norm = 2.4166e-01, time/batch = 0.2680s	
1948/2700 (epoch 36.074), train_loss = 0.78752864, grad/param norm = 1.9398e-01, time/batch = 0.2964s	
1949/2700 (epoch 36.093), train_loss = 0.78276572, grad/param norm = 2.3503e-01, time/batch = 0.3086s	
1950/2700 (epoch 36.111), train_loss = 0.77237337, grad/param norm = 1.9602e-01, time/batch = 0.2483s	
1951/2700 (epoch 36.130), train_loss = 0.81025965, grad/param norm = 2.4021e-01, time/batch = 0.3014s	
1952/2700 (epoch 36.148), train_loss = 0.82284132, grad/param norm = 2.5020e-01, time/batch = 0.3014s	
1953/2700 (epoch 36.167), train_loss = 0.84724796, grad/param norm = 2.2182e-01, time/batch = 0.2961s	
1954/2700 (epoch 36.185), train_loss = 0.82098352, grad/param norm = 2.2017e-01, time/batch = 0.2961s	
1955/2700 (epoch 36.204), train_loss = 0.80653349, grad/param norm = 2.0692e-01, time/batch = 0.2940s	
1956/2700 (epoch 36.222), train_loss = 0.75278739, grad/param norm = 1.8584e-01, time/batch = 0.2915s	
1957/2700 (epoch 36.241), train_loss = 0.75501529, grad/param norm = 1.8364e-01, time/batch = 0.3142s	
1958/2700 (epoch 36.259), train_loss = 0.79150018, grad/param norm = 2.4387e-01, time/batch = 0.3146s	
1959/2700 (epoch 36.278), train_loss = 0.82175863, grad/param norm = 2.2312e-01, time/batch = 0.3126s	
1960/2700 (epoch 36.296), train_loss = 0.81027079, grad/param norm = 2.5265e-01, time/batch = 0.3048s	
1961/2700 (epoch 36.315), train_loss = 0.79392238, grad/param norm = 2.5934e-01, time/batch = 0.3097s	
1962/2700 (epoch 36.333), train_loss = 0.79664807, grad/param norm = 2.0885e-01, time/batch = 0.3075s	
1963/2700 (epoch 36.352), train_loss = 0.78084505, grad/param norm = 2.1504e-01, time/batch = 0.2944s	
1964/2700 (epoch 36.370), train_loss = 0.78579518, grad/param norm = 2.3472e-01, time/batch = 0.2982s	
1965/2700 (epoch 36.389), train_loss = 0.77572335, grad/param norm = 2.4199e-01, time/batch = 0.2895s	
1966/2700 (epoch 36.407), train_loss = 0.85758211, grad/param norm = 2.0142e-01, time/batch = 0.3024s	
1967/2700 (epoch 36.426), train_loss = 0.84316576, grad/param norm = 2.3446e-01, time/batch = 0.3156s	
1968/2700 (epoch 36.444), train_loss = 0.82408310, grad/param norm = 2.1628e-01, time/batch = 0.3163s	
1969/2700 (epoch 36.463), train_loss = 0.81959191, grad/param norm = 2.1128e-01, time/batch = 0.3190s	
1970/2700 (epoch 36.481), train_loss = 0.78421929, grad/param norm = 2.3424e-01, time/batch = 0.3091s	
1971/2700 (epoch 36.500), train_loss = 0.74371595, grad/param norm = 2.3944e-01, time/batch = 0.3241s	
1972/2700 (epoch 36.519), train_loss = 0.81935550, grad/param norm = 2.7870e-01, time/batch = 0.3151s	
1973/2700 (epoch 36.537), train_loss = 0.80425735, grad/param norm = 2.3379e-01, time/batch = 0.3039s	
1974/2700 (epoch 36.556), train_loss = 0.76015095, grad/param norm = 2.1783e-01, time/batch = 0.2407s	
1975/2700 (epoch 36.574), train_loss = 0.75639026, grad/param norm = 2.0940e-01, time/batch = 0.2997s	
1976/2700 (epoch 36.593), train_loss = 0.79390774, grad/param norm = 2.0210e-01, time/batch = 0.3032s	
1977/2700 (epoch 36.611), train_loss = 0.76206534, grad/param norm = 2.3727e-01, time/batch = 0.3145s	
1978/2700 (epoch 36.630), train_loss = 0.78459296, grad/param norm = 1.8950e-01, time/batch = 0.3175s	
1979/2700 (epoch 36.648), train_loss = 0.77694862, grad/param norm = 2.1120e-01, time/batch = 0.3170s	
1980/2700 (epoch 36.667), train_loss = 0.75865117, grad/param norm = 2.0924e-01, time/batch = 0.3005s	
1981/2700 (epoch 36.685), train_loss = 0.80137453, grad/param norm = 2.2784e-01, time/batch = 0.3281s	
1982/2700 (epoch 36.704), train_loss = 0.82756040, grad/param norm = 2.4199e-01, time/batch = 0.3296s	
1983/2700 (epoch 36.722), train_loss = 0.82306936, grad/param norm = 2.0083e-01, time/batch = 0.3039s	
1984/2700 (epoch 36.741), train_loss = 0.77148955, grad/param norm = 1.9267e-01, time/batch = 0.3033s	
1985/2700 (epoch 36.759), train_loss = 0.76790101, grad/param norm = 2.1117e-01, time/batch = 0.2985s	
1986/2700 (epoch 36.778), train_loss = 0.79537006, grad/param norm = 2.1915e-01, time/batch = 0.2980s	
1987/2700 (epoch 36.796), train_loss = 0.77046207, grad/param norm = 2.1353e-01, time/batch = 0.2985s	
1988/2700 (epoch 36.815), train_loss = 0.80243673, grad/param norm = 2.2045e-01, time/batch = 0.3025s	
1989/2700 (epoch 36.833), train_loss = 0.78675439, grad/param norm = 2.2187e-01, time/batch = 0.3147s	
1990/2700 (epoch 36.852), train_loss = 0.77292658, grad/param norm = 2.1117e-01, time/batch = 0.3042s	
1991/2700 (epoch 36.870), train_loss = 0.79007607, grad/param norm = 2.0908e-01, time/batch = 0.3131s	
1992/2700 (epoch 36.889), train_loss = 0.76045462, grad/param norm = 1.8548e-01, time/batch = 0.3153s	
1993/2700 (epoch 36.907), train_loss = 0.82758980, grad/param norm = 2.0256e-01, time/batch = 0.3260s	
1994/2700 (epoch 36.926), train_loss = 0.79281602, grad/param norm = 2.5110e-01, time/batch = 0.3158s	
1995/2700 (epoch 36.944), train_loss = 0.79496112, grad/param norm = 2.3438e-01, time/batch = 0.3019s	
1996/2700 (epoch 36.963), train_loss = 0.79842834, grad/param norm = 2.1011e-01, time/batch = 0.2923s	
1997/2700 (epoch 36.981), train_loss = 0.74491947, grad/param norm = 1.9876e-01, time/batch = 0.2923s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
1998/2700 (epoch 37.000), train_loss = 0.79016104, grad/param norm = 2.2892e-01, time/batch = 0.3014s	
1999/2700 (epoch 37.019), train_loss = 0.88730903, grad/param norm = 2.2367e-01, time/batch = 0.3101s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch37.04_1.9835.t7	
2000/2700 (epoch 37.037), train_loss = 0.81040091, grad/param norm = 2.0263e-01, time/batch = 0.2993s	
2001/2700 (epoch 37.056), train_loss = 1.21561632, grad/param norm = 2.4906e-01, time/batch = 0.2810s	
2002/2700 (epoch 37.074), train_loss = 0.78388755, grad/param norm = 2.2275e-01, time/batch = 0.2884s	
2003/2700 (epoch 37.093), train_loss = 0.77050474, grad/param norm = 2.6074e-01, time/batch = 0.2698s	
2004/2700 (epoch 37.111), train_loss = 0.75678894, grad/param norm = 2.1645e-01, time/batch = 0.3009s	
2005/2700 (epoch 37.130), train_loss = 0.78016630, grad/param norm = 2.2011e-01, time/batch = 0.2890s	
2006/2700 (epoch 37.148), train_loss = 0.77587624, grad/param norm = 1.9962e-01, time/batch = 0.2879s	
2007/2700 (epoch 37.167), train_loss = 0.82045362, grad/param norm = 2.4208e-01, time/batch = 0.2952s	
2008/2700 (epoch 37.185), train_loss = 0.80417207, grad/param norm = 2.3207e-01, time/batch = 0.2448s	
2009/2700 (epoch 37.204), train_loss = 0.77962446, grad/param norm = 2.0744e-01, time/batch = 0.2835s	
2010/2700 (epoch 37.222), train_loss = 0.73096828, grad/param norm = 2.1869e-01, time/batch = 0.3194s	
2011/2700 (epoch 37.241), train_loss = 0.72930024, grad/param norm = 1.9146e-01, time/batch = 0.3124s	
2012/2700 (epoch 37.259), train_loss = 0.75259765, grad/param norm = 1.8996e-01, time/batch = 0.3157s	
2013/2700 (epoch 37.278), train_loss = 0.78527419, grad/param norm = 2.1899e-01, time/batch = 0.3150s	
2014/2700 (epoch 37.296), train_loss = 0.77127443, grad/param norm = 2.0676e-01, time/batch = 0.3003s	
2015/2700 (epoch 37.315), train_loss = 0.75561345, grad/param norm = 2.3800e-01, time/batch = 0.2945s	
2016/2700 (epoch 37.333), train_loss = 0.78024698, grad/param norm = 2.5747e-01, time/batch = 0.2872s	
2017/2700 (epoch 37.352), train_loss = 0.75522173, grad/param norm = 2.2163e-01, time/batch = 0.2885s	
2018/2700 (epoch 37.370), train_loss = 0.75649639, grad/param norm = 2.3333e-01, time/batch = 0.2345s	
2019/2700 (epoch 37.389), train_loss = 0.74700024, grad/param norm = 2.2731e-01, time/batch = 0.3124s	
2020/2700 (epoch 37.407), train_loss = 0.84031709, grad/param norm = 2.4239e-01, time/batch = 0.3142s	
2021/2700 (epoch 37.426), train_loss = 0.80912412, grad/param norm = 2.0033e-01, time/batch = 0.3120s	
2022/2700 (epoch 37.444), train_loss = 0.78100342, grad/param norm = 1.9237e-01, time/batch = 0.3154s	
2023/2700 (epoch 37.463), train_loss = 0.79648781, grad/param norm = 2.2347e-01, time/batch = 0.3193s	
2024/2700 (epoch 37.481), train_loss = 0.74863213, grad/param norm = 1.9938e-01, time/batch = 0.3243s	
2025/2700 (epoch 37.500), train_loss = 0.71455559, grad/param norm = 2.0724e-01, time/batch = 0.3186s	
2026/2700 (epoch 37.519), train_loss = 0.77656352, grad/param norm = 2.1120e-01, time/batch = 0.2582s	
2027/2700 (epoch 37.537), train_loss = 0.77180306, grad/param norm = 2.4393e-01, time/batch = 0.3168s	
2028/2700 (epoch 37.556), train_loss = 0.75210846, grad/param norm = 2.7996e-01, time/batch = 0.3219s	
2029/2700 (epoch 37.574), train_loss = 0.74343183, grad/param norm = 2.5603e-01, time/batch = 0.3195s	
2030/2700 (epoch 37.593), train_loss = 0.78781269, grad/param norm = 2.4086e-01, time/batch = 0.3123s	
2031/2700 (epoch 37.611), train_loss = 0.74182664, grad/param norm = 2.2621e-01, time/batch = 0.3150s	
2032/2700 (epoch 37.630), train_loss = 0.77054507, grad/param norm = 2.3672e-01, time/batch = 0.3221s	
2033/2700 (epoch 37.648), train_loss = 0.76070894, grad/param norm = 2.3085e-01, time/batch = 0.3193s	
2034/2700 (epoch 37.667), train_loss = 0.73870739, grad/param norm = 2.1692e-01, time/batch = 0.3196s	
2035/2700 (epoch 37.685), train_loss = 0.78597791, grad/param norm = 2.9785e-01, time/batch = 0.3214s	
2036/2700 (epoch 37.704), train_loss = 0.81380605, grad/param norm = 2.7429e-01, time/batch = 0.3043s	
2037/2700 (epoch 37.722), train_loss = 0.80839599, grad/param norm = 2.3127e-01, time/batch = 0.2457s	
2038/2700 (epoch 37.741), train_loss = 0.75538118, grad/param norm = 2.1350e-01, time/batch = 0.3243s	
2039/2700 (epoch 37.759), train_loss = 0.74076960, grad/param norm = 2.0778e-01, time/batch = 0.3153s	
2040/2700 (epoch 37.778), train_loss = 0.76300202, grad/param norm = 1.7221e-01, time/batch = 0.3140s	
2041/2700 (epoch 37.796), train_loss = 0.73789532, grad/param norm = 2.1172e-01, time/batch = 0.3199s	
2042/2700 (epoch 37.815), train_loss = 0.78667353, grad/param norm = 2.3355e-01, time/batch = 0.3221s	
2043/2700 (epoch 37.833), train_loss = 0.76441016, grad/param norm = 2.4002e-01, time/batch = 0.3198s	
2044/2700 (epoch 37.852), train_loss = 0.78200401, grad/param norm = 2.9569e-01, time/batch = 0.3200s	
2045/2700 (epoch 37.870), train_loss = 0.77955151, grad/param norm = 2.3544e-01, time/batch = 0.3147s	
2046/2700 (epoch 37.889), train_loss = 0.74288554, grad/param norm = 2.0543e-01, time/batch = 0.3024s	
2047/2700 (epoch 37.907), train_loss = 0.80881198, grad/param norm = 2.4306e-01, time/batch = 0.2958s	
2048/2700 (epoch 37.926), train_loss = 0.75744866, grad/param norm = 2.1264e-01, time/batch = 0.2641s	
2049/2700 (epoch 37.944), train_loss = 0.76445635, grad/param norm = 2.0645e-01, time/batch = 0.3090s	
2050/2700 (epoch 37.963), train_loss = 0.76474489, grad/param norm = 2.0793e-01, time/batch = 0.3085s	
2051/2700 (epoch 37.981), train_loss = 0.72559746, grad/param norm = 2.4001e-01, time/batch = 0.3171s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2052/2700 (epoch 38.000), train_loss = 0.75301311, grad/param norm = 2.0239e-01, time/batch = 0.3198s	
2053/2700 (epoch 38.019), train_loss = 0.85522494, grad/param norm = 2.0941e-01, time/batch = 0.3206s	
2054/2700 (epoch 38.037), train_loss = 0.79832548, grad/param norm = 2.6326e-01, time/batch = 0.3179s	
2055/2700 (epoch 38.056), train_loss = 0.79793642, grad/param norm = 2.0366e-01, time/batch = 0.3098s	
2056/2700 (epoch 38.074), train_loss = 0.73497629, grad/param norm = 1.9821e-01, time/batch = 0.3073s	
2057/2700 (epoch 38.093), train_loss = 0.72156716, grad/param norm = 1.9004e-01, time/batch = 0.2951s	
2058/2700 (epoch 38.111), train_loss = 0.73196863, grad/param norm = 2.5940e-01, time/batch = 0.2874s	
2059/2700 (epoch 38.130), train_loss = 0.76565477, grad/param norm = 2.6086e-01, time/batch = 0.2556s	
2060/2700 (epoch 38.148), train_loss = 0.76521740, grad/param norm = 2.4292e-01, time/batch = 0.3160s	
2061/2700 (epoch 38.167), train_loss = 0.78695993, grad/param norm = 1.9530e-01, time/batch = 0.3270s	
2062/2700 (epoch 38.185), train_loss = 0.75913478, grad/param norm = 1.8403e-01, time/batch = 0.3248s	
2063/2700 (epoch 38.204), train_loss = 0.74987884, grad/param norm = 2.2930e-01, time/batch = 0.3219s	
2064/2700 (epoch 38.222), train_loss = 0.71963119, grad/param norm = 2.5812e-01, time/batch = 0.2961s	
2065/2700 (epoch 38.241), train_loss = 0.71588587, grad/param norm = 2.2439e-01, time/batch = 0.3157s	
2066/2700 (epoch 38.259), train_loss = 0.73684852, grad/param norm = 2.1823e-01, time/batch = 0.3141s	
2067/2700 (epoch 38.278), train_loss = 0.75539401, grad/param norm = 2.3284e-01, time/batch = 0.3074s	
2068/2700 (epoch 38.296), train_loss = 0.74463462, grad/param norm = 2.1295e-01, time/batch = 0.2918s	
2069/2700 (epoch 38.315), train_loss = 0.72100141, grad/param norm = 2.0228e-01, time/batch = 0.2907s	
2070/2700 (epoch 38.333), train_loss = 0.73670736, grad/param norm = 2.1348e-01, time/batch = 0.2486s	
2071/2700 (epoch 38.352), train_loss = 0.72789865, grad/param norm = 2.1223e-01, time/batch = 0.3259s	
2072/2700 (epoch 38.370), train_loss = 0.73028099, grad/param norm = 2.2929e-01, time/batch = 0.3270s	
2073/2700 (epoch 38.389), train_loss = 0.72658709, grad/param norm = 2.6198e-01, time/batch = 0.3226s	
2074/2700 (epoch 38.407), train_loss = 0.80312710, grad/param norm = 2.0771e-01, time/batch = 0.3195s	
2075/2700 (epoch 38.426), train_loss = 0.78937982, grad/param norm = 2.4734e-01, time/batch = 0.3178s	
2076/2700 (epoch 38.444), train_loss = 0.76864186, grad/param norm = 2.2389e-01, time/batch = 0.3077s	
2077/2700 (epoch 38.463), train_loss = 0.76171504, grad/param norm = 1.9813e-01, time/batch = 0.2959s	
2078/2700 (epoch 38.481), train_loss = 0.72449347, grad/param norm = 2.1841e-01, time/batch = 0.2840s	
2079/2700 (epoch 38.500), train_loss = 0.67664502, grad/param norm = 1.9079e-01, time/batch = 0.2865s	
2080/2700 (epoch 38.519), train_loss = 0.75027324, grad/param norm = 2.3162e-01, time/batch = 0.2926s	
2081/2700 (epoch 38.537), train_loss = 0.74069067, grad/param norm = 2.3828e-01, time/batch = 0.2610s	
2082/2700 (epoch 38.556), train_loss = 0.71122717, grad/param norm = 2.1867e-01, time/batch = 0.3210s	
2083/2700 (epoch 38.574), train_loss = 0.71122682, grad/param norm = 2.4292e-01, time/batch = 0.2957s	
2084/2700 (epoch 38.593), train_loss = 0.75793494, grad/param norm = 2.3204e-01, time/batch = 0.3118s	
2085/2700 (epoch 38.611), train_loss = 0.72728992, grad/param norm = 2.5762e-01, time/batch = 0.2949s	
2086/2700 (epoch 38.630), train_loss = 0.76991696, grad/param norm = 3.1119e-01, time/batch = 0.2984s	
2087/2700 (epoch 38.648), train_loss = 0.73863721, grad/param norm = 2.1469e-01, time/batch = 0.2930s	
2088/2700 (epoch 38.667), train_loss = 0.70339901, grad/param norm = 1.9504e-01, time/batch = 0.3013s	
2089/2700 (epoch 38.685), train_loss = 0.74889630, grad/param norm = 2.2648e-01, time/batch = 0.2643s	
2090/2700 (epoch 38.704), train_loss = 0.76481324, grad/param norm = 2.1847e-01, time/batch = 0.3208s	
2091/2700 (epoch 38.722), train_loss = 0.78779319, grad/param norm = 2.4708e-01, time/batch = 0.3083s	
2092/2700 (epoch 38.741), train_loss = 0.74652199, grad/param norm = 2.6561e-01, time/batch = 0.2670s	
2093/2700 (epoch 38.759), train_loss = 0.71733118, grad/param norm = 2.0871e-01, time/batch = 0.2644s	
2094/2700 (epoch 38.778), train_loss = 0.74135931, grad/param norm = 2.1221e-01, time/batch = 0.2882s	
2095/2700 (epoch 38.796), train_loss = 0.70996590, grad/param norm = 2.0609e-01, time/batch = 0.2987s	
2096/2700 (epoch 38.815), train_loss = 0.74424903, grad/param norm = 2.0338e-01, time/batch = 0.3155s	
2097/2700 (epoch 38.833), train_loss = 0.72421745, grad/param norm = 2.0059e-01, time/batch = 0.3083s	
2098/2700 (epoch 38.852), train_loss = 0.71069082, grad/param norm = 1.9407e-01, time/batch = 0.3012s	
2099/2700 (epoch 38.870), train_loss = 0.74519808, grad/param norm = 2.1170e-01, time/batch = 0.2852s	
2100/2700 (epoch 38.889), train_loss = 0.72838238, grad/param norm = 2.8426e-01, time/batch = 0.3189s	
2101/2700 (epoch 38.907), train_loss = 0.78939216, grad/param norm = 2.4879e-01, time/batch = 0.3113s	
2102/2700 (epoch 38.926), train_loss = 0.73296076, grad/param norm = 2.1696e-01, time/batch = 0.3170s	
2103/2700 (epoch 38.944), train_loss = 0.72990688, grad/param norm = 2.1237e-01, time/batch = 0.3041s	
2104/2700 (epoch 38.963), train_loss = 0.73706046, grad/param norm = 1.9093e-01, time/batch = 0.2609s	
2105/2700 (epoch 38.981), train_loss = 0.69986253, grad/param norm = 2.3353e-01, time/batch = 0.3209s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2106/2700 (epoch 39.000), train_loss = 0.73727523, grad/param norm = 2.3336e-01, time/batch = 0.3234s	
2107/2700 (epoch 39.019), train_loss = 0.83986037, grad/param norm = 2.2066e-01, time/batch = 0.3191s	
2108/2700 (epoch 39.037), train_loss = 0.75571283, grad/param norm = 2.0666e-01, time/batch = 0.3150s	
2109/2700 (epoch 39.056), train_loss = 0.76701890, grad/param norm = 2.1589e-01, time/batch = 0.3045s	
2110/2700 (epoch 39.074), train_loss = 0.71613548, grad/param norm = 2.2272e-01, time/batch = 0.3243s	
2111/2700 (epoch 39.093), train_loss = 0.70652927, grad/param norm = 2.3453e-01, time/batch = 0.3265s	
2112/2700 (epoch 39.111), train_loss = 0.69739991, grad/param norm = 2.0912e-01, time/batch = 0.3241s	
2113/2700 (epoch 39.130), train_loss = 0.72786536, grad/param norm = 2.4029e-01, time/batch = 0.3132s	
2114/2700 (epoch 39.148), train_loss = 0.74473437, grad/param norm = 2.3816e-01, time/batch = 0.3184s	
2115/2700 (epoch 39.167), train_loss = 0.77341042, grad/param norm = 2.4226e-01, time/batch = 0.2524s	
2116/2700 (epoch 39.185), train_loss = 0.75603953, grad/param norm = 2.4166e-01, time/batch = 0.3137s	
2117/2700 (epoch 39.204), train_loss = 0.72353651, grad/param norm = 2.0558e-01, time/batch = 0.3169s	
2118/2700 (epoch 39.222), train_loss = 0.68326253, grad/param norm = 2.4490e-01, time/batch = 0.3188s	
2119/2700 (epoch 39.241), train_loss = 0.68350664, grad/param norm = 1.9150e-01, time/batch = 0.3168s	
2120/2700 (epoch 39.259), train_loss = 0.70789697, grad/param norm = 2.2281e-01, time/batch = 0.3187s	
2121/2700 (epoch 39.278), train_loss = 0.73876562, grad/param norm = 2.3391e-01, time/batch = 0.3268s	
2122/2700 (epoch 39.296), train_loss = 0.73619729, grad/param norm = 2.6925e-01, time/batch = 0.3285s	
2123/2700 (epoch 39.315), train_loss = 0.71107115, grad/param norm = 2.4241e-01, time/batch = 0.3215s	
2124/2700 (epoch 39.333), train_loss = 0.70974824, grad/param norm = 1.9396e-01, time/batch = 0.3106s	
2125/2700 (epoch 39.352), train_loss = 0.70366034, grad/param norm = 2.3280e-01, time/batch = 0.3016s	
2126/2700 (epoch 39.370), train_loss = 0.71222111, grad/param norm = 2.3833e-01, time/batch = 0.2334s	
2127/2700 (epoch 39.389), train_loss = 0.68629337, grad/param norm = 1.9498e-01, time/batch = 0.3162s	
2128/2700 (epoch 39.407), train_loss = 0.78354149, grad/param norm = 2.4196e-01, time/batch = 0.3291s	
2129/2700 (epoch 39.426), train_loss = 0.76821551, grad/param norm = 3.0225e-01, time/batch = 0.3158s	
2130/2700 (epoch 39.444), train_loss = 0.75962259, grad/param norm = 2.4450e-01, time/batch = 0.3231s	
2131/2700 (epoch 39.463), train_loss = 0.74993717, grad/param norm = 2.1921e-01, time/batch = 0.3295s	
2132/2700 (epoch 39.481), train_loss = 0.69474801, grad/param norm = 1.8570e-01, time/batch = 0.3207s	
2133/2700 (epoch 39.500), train_loss = 0.65543069, grad/param norm = 2.1360e-01, time/batch = 0.3077s	
2134/2700 (epoch 39.519), train_loss = 0.71509797, grad/param norm = 1.8627e-01, time/batch = 0.2986s	
2135/2700 (epoch 39.537), train_loss = 0.70596386, grad/param norm = 2.1699e-01, time/batch = 0.2838s	
2136/2700 (epoch 39.556), train_loss = 0.68310372, grad/param norm = 2.2798e-01, time/batch = 0.2832s	
2137/2700 (epoch 39.574), train_loss = 0.68169247, grad/param norm = 2.3815e-01, time/batch = 0.2739s	
2138/2700 (epoch 39.593), train_loss = 0.71930131, grad/param norm = 2.1053e-01, time/batch = 0.3124s	
2139/2700 (epoch 39.611), train_loss = 0.69014720, grad/param norm = 2.2219e-01, time/batch = 0.3197s	
2140/2700 (epoch 39.630), train_loss = 0.71412777, grad/param norm = 2.0540e-01, time/batch = 0.3133s	
2141/2700 (epoch 39.648), train_loss = 0.70949771, grad/param norm = 2.2254e-01, time/batch = 0.3251s	
2142/2700 (epoch 39.667), train_loss = 0.68845994, grad/param norm = 2.4074e-01, time/batch = 0.3209s	
2143/2700 (epoch 39.685), train_loss = 0.72743012, grad/param norm = 2.4012e-01, time/batch = 0.3124s	
2144/2700 (epoch 39.704), train_loss = 0.75201403, grad/param norm = 2.4718e-01, time/batch = 0.3161s	
2145/2700 (epoch 39.722), train_loss = 0.75727762, grad/param norm = 2.4373e-01, time/batch = 0.3005s	
2146/2700 (epoch 39.741), train_loss = 0.71366346, grad/param norm = 2.2810e-01, time/batch = 0.2889s	
2147/2700 (epoch 39.759), train_loss = 0.69562514, grad/param norm = 2.2361e-01, time/batch = 0.2778s	
2148/2700 (epoch 39.778), train_loss = 0.72957001, grad/param norm = 2.4048e-01, time/batch = 0.2602s	
2149/2700 (epoch 39.796), train_loss = 0.68075927, grad/param norm = 2.1464e-01, time/batch = 0.3179s	
2150/2700 (epoch 39.815), train_loss = 0.72403303, grad/param norm = 2.1522e-01, time/batch = 0.2569s	
2151/2700 (epoch 39.833), train_loss = 0.70095312, grad/param norm = 2.2349e-01, time/batch = 0.3038s	
2152/2700 (epoch 39.852), train_loss = 0.69676501, grad/param norm = 2.2467e-01, time/batch = 0.3028s	
2153/2700 (epoch 39.870), train_loss = 0.71088817, grad/param norm = 2.0951e-01, time/batch = 0.2907s	
2154/2700 (epoch 39.889), train_loss = 0.68632009, grad/param norm = 2.1877e-01, time/batch = 0.2775s	
2155/2700 (epoch 39.907), train_loss = 0.75928099, grad/param norm = 2.5577e-01, time/batch = 0.2766s	
2156/2700 (epoch 39.926), train_loss = 0.72047022, grad/param norm = 2.6403e-01, time/batch = 0.2904s	
2157/2700 (epoch 39.944), train_loss = 0.72922417, grad/param norm = 2.9119e-01, time/batch = 0.3010s	
2158/2700 (epoch 39.963), train_loss = 0.72476575, grad/param norm = 2.1291e-01, time/batch = 0.3009s	
2159/2700 (epoch 39.981), train_loss = 0.67124768, grad/param norm = 1.9868e-01, time/batch = 0.2938s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2160/2700 (epoch 40.000), train_loss = 0.70127963, grad/param norm = 2.0498e-01, time/batch = 0.2688s	
2161/2700 (epoch 40.019), train_loss = 0.80867137, grad/param norm = 2.2849e-01, time/batch = 0.3137s	
2162/2700 (epoch 40.037), train_loss = 0.73716330, grad/param norm = 2.5834e-01, time/batch = 0.3141s	
2163/2700 (epoch 40.056), train_loss = 0.74867252, grad/param norm = 2.3995e-01, time/batch = 0.2993s	
2164/2700 (epoch 40.074), train_loss = 0.70587256, grad/param norm = 2.2468e-01, time/batch = 0.2893s	
2165/2700 (epoch 40.093), train_loss = 0.68040690, grad/param norm = 2.0931e-01, time/batch = 0.2996s	
2166/2700 (epoch 40.111), train_loss = 0.68355031, grad/param norm = 2.4780e-01, time/batch = 0.2953s	
2167/2700 (epoch 40.130), train_loss = 0.70554291, grad/param norm = 2.2359e-01, time/batch = 0.3113s	
2168/2700 (epoch 40.148), train_loss = 0.70846615, grad/param norm = 2.2358e-01, time/batch = 0.3187s	
2169/2700 (epoch 40.167), train_loss = 0.74279295, grad/param norm = 2.7136e-01, time/batch = 0.3160s	
2170/2700 (epoch 40.185), train_loss = 0.73020143, grad/param norm = 2.2121e-01, time/batch = 0.2921s	
2171/2700 (epoch 40.204), train_loss = 0.71751423, grad/param norm = 2.6664e-01, time/batch = 0.3120s	
2172/2700 (epoch 40.222), train_loss = 0.65730325, grad/param norm = 2.2154e-01, time/batch = 0.3164s	
2173/2700 (epoch 40.241), train_loss = 0.68408411, grad/param norm = 2.6127e-01, time/batch = 0.3046s	
2174/2700 (epoch 40.259), train_loss = 0.70368433, grad/param norm = 2.5976e-01, time/batch = 0.2919s	
2175/2700 (epoch 40.278), train_loss = 0.70972798, grad/param norm = 2.2881e-01, time/batch = 0.2576s	
2176/2700 (epoch 40.296), train_loss = 0.72269784, grad/param norm = 2.8340e-01, time/batch = 0.3082s	
2177/2700 (epoch 40.315), train_loss = 0.68873917, grad/param norm = 2.2367e-01, time/batch = 0.3112s	
2178/2700 (epoch 40.333), train_loss = 0.69623236, grad/param norm = 2.6331e-01, time/batch = 0.3175s	
2179/2700 (epoch 40.352), train_loss = 0.68666908, grad/param norm = 2.3021e-01, time/batch = 0.3185s	
2180/2700 (epoch 40.370), train_loss = 0.68236060, grad/param norm = 2.1577e-01, time/batch = 0.3019s	
2181/2700 (epoch 40.389), train_loss = 0.66847408, grad/param norm = 2.2400e-01, time/batch = 0.3104s	
2182/2700 (epoch 40.407), train_loss = 0.75419129, grad/param norm = 2.3622e-01, time/batch = 0.3096s	
2183/2700 (epoch 40.426), train_loss = 0.73373630, grad/param norm = 2.1336e-01, time/batch = 0.2941s	
2184/2700 (epoch 40.444), train_loss = 0.71096794, grad/param norm = 2.0194e-01, time/batch = 0.2757s	
2185/2700 (epoch 40.463), train_loss = 0.73198856, grad/param norm = 2.6942e-01, time/batch = 0.2997s	
2186/2700 (epoch 40.481), train_loss = 0.68470659, grad/param norm = 2.5696e-01, time/batch = 0.3089s	
2187/2700 (epoch 40.500), train_loss = 0.64827783, grad/param norm = 2.2285e-01, time/batch = 0.3189s	
2188/2700 (epoch 40.519), train_loss = 0.69235837, grad/param norm = 2.0980e-01, time/batch = 0.3213s	
2189/2700 (epoch 40.537), train_loss = 0.68704423, grad/param norm = 2.2251e-01, time/batch = 0.3207s	
2190/2700 (epoch 40.556), train_loss = 0.64690525, grad/param norm = 1.9204e-01, time/batch = 0.3069s	
2191/2700 (epoch 40.574), train_loss = 0.65238408, grad/param norm = 2.1578e-01, time/batch = 0.3293s	
2192/2700 (epoch 40.593), train_loss = 0.69480084, grad/param norm = 2.1482e-01, time/batch = 0.3317s	
2193/2700 (epoch 40.611), train_loss = 0.67624707, grad/param norm = 2.3905e-01, time/batch = 0.2659s	
2194/2700 (epoch 40.630), train_loss = 0.69766434, grad/param norm = 2.2886e-01, time/batch = 0.2703s	
2195/2700 (epoch 40.648), train_loss = 0.68135343, grad/param norm = 2.1056e-01, time/batch = 0.2551s	
2196/2700 (epoch 40.667), train_loss = 0.66349582, grad/param norm = 2.1406e-01, time/batch = 0.3277s	
2197/2700 (epoch 40.685), train_loss = 0.69217017, grad/param norm = 2.1297e-01, time/batch = 0.3185s	
2198/2700 (epoch 40.704), train_loss = 0.70962802, grad/param norm = 1.9613e-01, time/batch = 0.3186s	
2199/2700 (epoch 40.722), train_loss = 0.71534794, grad/param norm = 1.9416e-01, time/batch = 0.3163s	
2200/2700 (epoch 40.741), train_loss = 0.68377013, grad/param norm = 2.2099e-01, time/batch = 0.3064s	
2201/2700 (epoch 40.759), train_loss = 0.66982204, grad/param norm = 2.3131e-01, time/batch = 0.3245s	
2202/2700 (epoch 40.778), train_loss = 0.70668018, grad/param norm = 2.5162e-01, time/batch = 0.3145s	
2203/2700 (epoch 40.796), train_loss = 0.67064809, grad/param norm = 2.4776e-01, time/batch = 0.3168s	
2204/2700 (epoch 40.815), train_loss = 0.70782562, grad/param norm = 2.4004e-01, time/batch = 0.3017s	
2205/2700 (epoch 40.833), train_loss = 0.69020368, grad/param norm = 2.5377e-01, time/batch = 0.2942s	
2206/2700 (epoch 40.852), train_loss = 0.67231456, grad/param norm = 2.2514e-01, time/batch = 0.2590s	
2207/2700 (epoch 40.870), train_loss = 0.69216545, grad/param norm = 2.1462e-01, time/batch = 0.3228s	
2208/2700 (epoch 40.889), train_loss = 0.66679111, grad/param norm = 2.0756e-01, time/batch = 0.3214s	
2209/2700 (epoch 40.907), train_loss = 0.73965526, grad/param norm = 2.8590e-01, time/batch = 0.3187s	
2210/2700 (epoch 40.926), train_loss = 0.70500111, grad/param norm = 3.1438e-01, time/batch = 0.3150s	
2211/2700 (epoch 40.944), train_loss = 0.70346776, grad/param norm = 2.6742e-01, time/batch = 0.3246s	
2212/2700 (epoch 40.963), train_loss = 0.69950717, grad/param norm = 2.2072e-01, time/batch = 0.3255s	
2213/2700 (epoch 40.981), train_loss = 0.64464528, grad/param norm = 1.8356e-01, time/batch = 0.3172s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2214/2700 (epoch 41.000), train_loss = 0.67495977, grad/param norm = 1.9671e-01, time/batch = 0.3075s	
2215/2700 (epoch 41.019), train_loss = 0.77431448, grad/param norm = 1.9061e-01, time/batch = 0.2900s	
2216/2700 (epoch 41.037), train_loss = 0.69470167, grad/param norm = 1.8927e-01, time/batch = 0.2822s	
2217/2700 (epoch 41.056), train_loss = 0.71293161, grad/param norm = 2.1334e-01, time/batch = 0.2588s	
2218/2700 (epoch 41.074), train_loss = 0.67075824, grad/param norm = 2.2002e-01, time/batch = 0.3222s	
2219/2700 (epoch 41.093), train_loss = 0.65378913, grad/param norm = 1.9001e-01, time/batch = 0.3241s	
2220/2700 (epoch 41.111), train_loss = 0.65703733, grad/param norm = 2.4136e-01, time/batch = 0.3086s	
2221/2700 (epoch 41.130), train_loss = 0.68596987, grad/param norm = 2.4964e-01, time/batch = 0.3301s	
2222/2700 (epoch 41.148), train_loss = 0.69654428, grad/param norm = 2.5083e-01, time/batch = 0.3224s	
2223/2700 (epoch 41.167), train_loss = 0.72046600, grad/param norm = 2.3621e-01, time/batch = 0.3129s	
2224/2700 (epoch 41.185), train_loss = 0.70934413, grad/param norm = 2.3748e-01, time/batch = 0.3126s	
2225/2700 (epoch 41.204), train_loss = 0.68517790, grad/param norm = 2.3809e-01, time/batch = 0.3026s	
2226/2700 (epoch 41.222), train_loss = 0.63370323, grad/param norm = 2.3250e-01, time/batch = 0.2878s	
2227/2700 (epoch 41.241), train_loss = 0.64541739, grad/param norm = 2.1021e-01, time/batch = 0.2946s	
2228/2700 (epoch 41.259), train_loss = 0.66249941, grad/param norm = 2.1014e-01, time/batch = 0.2642s	
2229/2700 (epoch 41.278), train_loss = 0.68405263, grad/param norm = 2.2343e-01, time/batch = 0.3193s	
2230/2700 (epoch 41.296), train_loss = 0.68253056, grad/param norm = 2.3484e-01, time/batch = 0.3101s	
2231/2700 (epoch 41.315), train_loss = 0.65571523, grad/param norm = 2.2521e-01, time/batch = 0.3125s	
2232/2700 (epoch 41.333), train_loss = 0.66271939, grad/param norm = 2.3426e-01, time/batch = 0.3170s	
2233/2700 (epoch 41.352), train_loss = 0.66207231, grad/param norm = 2.3975e-01, time/batch = 0.3131s	
2234/2700 (epoch 41.370), train_loss = 0.67566565, grad/param norm = 2.5962e-01, time/batch = 0.2965s	
2235/2700 (epoch 41.389), train_loss = 0.64791552, grad/param norm = 2.3816e-01, time/batch = 0.2960s	
2236/2700 (epoch 41.407), train_loss = 0.72740019, grad/param norm = 2.0922e-01, time/batch = 0.2908s	
2237/2700 (epoch 41.426), train_loss = 0.70863843, grad/param norm = 2.5334e-01, time/batch = 0.2915s	
2238/2700 (epoch 41.444), train_loss = 0.70139498, grad/param norm = 2.4188e-01, time/batch = 0.3059s	
2239/2700 (epoch 41.463), train_loss = 0.70135400, grad/param norm = 2.0691e-01, time/batch = 0.2993s	
2240/2700 (epoch 41.481), train_loss = 0.65736560, grad/param norm = 2.1351e-01, time/batch = 0.3204s	
2241/2700 (epoch 41.500), train_loss = 0.61079648, grad/param norm = 2.0555e-01, time/batch = 0.2983s	
2242/2700 (epoch 41.519), train_loss = 0.67914951, grad/param norm = 2.2988e-01, time/batch = 0.3049s	
2243/2700 (epoch 41.537), train_loss = 0.66487893, grad/param norm = 2.4461e-01, time/batch = 0.2979s	
2244/2700 (epoch 41.556), train_loss = 0.63993416, grad/param norm = 2.2758e-01, time/batch = 0.2905s	
2245/2700 (epoch 41.574), train_loss = 0.63641338, grad/param norm = 2.3792e-01, time/batch = 0.2859s	
2246/2700 (epoch 41.593), train_loss = 0.67712915, grad/param norm = 2.2211e-01, time/batch = 0.2853s	
2247/2700 (epoch 41.611), train_loss = 0.64583928, grad/param norm = 2.1948e-01, time/batch = 0.2831s	
2248/2700 (epoch 41.630), train_loss = 0.68509531, grad/param norm = 2.6170e-01, time/batch = 0.2957s	
2249/2700 (epoch 41.648), train_loss = 0.67739442, grad/param norm = 2.7136e-01, time/batch = 0.3016s	
2250/2700 (epoch 41.667), train_loss = 0.65474223, grad/param norm = 2.5803e-01, time/batch = 0.2948s	
2251/2700 (epoch 41.685), train_loss = 0.69317515, grad/param norm = 3.0878e-01, time/batch = 0.2809s	
2252/2700 (epoch 41.704), train_loss = 0.72483271, grad/param norm = 3.0769e-01, time/batch = 0.3048s	
2253/2700 (epoch 41.722), train_loss = 0.70623846, grad/param norm = 2.3242e-01, time/batch = 0.2948s	
2254/2700 (epoch 41.741), train_loss = 0.66462113, grad/param norm = 2.3826e-01, time/batch = 0.2821s	
2255/2700 (epoch 41.759), train_loss = 0.64857316, grad/param norm = 2.0754e-01, time/batch = 0.2827s	
2256/2700 (epoch 41.778), train_loss = 0.68192676, grad/param norm = 2.1983e-01, time/batch = 0.2781s	
2257/2700 (epoch 41.796), train_loss = 0.64171330, grad/param norm = 2.2797e-01, time/batch = 0.2918s	
2258/2700 (epoch 41.815), train_loss = 0.67539600, grad/param norm = 2.2971e-01, time/batch = 0.2943s	
2259/2700 (epoch 41.833), train_loss = 0.65619309, grad/param norm = 2.2422e-01, time/batch = 0.3000s	
2260/2700 (epoch 41.852), train_loss = 0.66768359, grad/param norm = 2.8947e-01, time/batch = 0.3020s	
2261/2700 (epoch 41.870), train_loss = 0.68194666, grad/param norm = 2.6199e-01, time/batch = 0.2604s	
2262/2700 (epoch 41.889), train_loss = 0.64791518, grad/param norm = 1.8733e-01, time/batch = 0.2894s	
2263/2700 (epoch 41.907), train_loss = 0.70245371, grad/param norm = 2.2934e-01, time/batch = 0.2887s	
2264/2700 (epoch 41.926), train_loss = 0.65983733, grad/param norm = 2.1936e-01, time/batch = 0.2809s	
2265/2700 (epoch 41.944), train_loss = 0.67735698, grad/param norm = 2.6571e-01, time/batch = 0.2815s	
2266/2700 (epoch 41.963), train_loss = 0.68055979, grad/param norm = 2.5109e-01, time/batch = 0.2996s	
2267/2700 (epoch 41.981), train_loss = 0.63207780, grad/param norm = 2.2382e-01, time/batch = 0.3029s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2268/2700 (epoch 42.000), train_loss = 0.65340598, grad/param norm = 1.9309e-01, time/batch = 0.2964s	
2269/2700 (epoch 42.019), train_loss = 0.75516569, grad/param norm = 1.9401e-01, time/batch = 0.3037s	
2270/2700 (epoch 42.037), train_loss = 0.67995525, grad/param norm = 2.2403e-01, time/batch = 0.3050s	
2271/2700 (epoch 42.056), train_loss = 0.68119820, grad/param norm = 2.0498e-01, time/batch = 0.2559s	
2272/2700 (epoch 42.074), train_loss = 0.64020993, grad/param norm = 1.8848e-01, time/batch = 0.3151s	
2273/2700 (epoch 42.093), train_loss = 0.63254491, grad/param norm = 2.0318e-01, time/batch = 0.2598s	
2274/2700 (epoch 42.111), train_loss = 0.63337077, grad/param norm = 2.3045e-01, time/batch = 0.3259s	
2275/2700 (epoch 42.130), train_loss = 0.64958160, grad/param norm = 1.9992e-01, time/batch = 0.3151s	
2276/2700 (epoch 42.148), train_loss = 0.66269625, grad/param norm = 2.2405e-01, time/batch = 0.3219s	
2277/2700 (epoch 42.167), train_loss = 0.69467524, grad/param norm = 2.4499e-01, time/batch = 0.3178s	
2278/2700 (epoch 42.185), train_loss = 0.67698359, grad/param norm = 2.0928e-01, time/batch = 0.3145s	
2279/2700 (epoch 42.204), train_loss = 0.64904381, grad/param norm = 2.1063e-01, time/batch = 0.3113s	
2280/2700 (epoch 42.222), train_loss = 0.61106046, grad/param norm = 2.5938e-01, time/batch = 0.3168s	
2281/2700 (epoch 42.241), train_loss = 0.62719455, grad/param norm = 2.1611e-01, time/batch = 0.2906s	
2282/2700 (epoch 42.259), train_loss = 0.64388697, grad/param norm = 2.2088e-01, time/batch = 0.3127s	
2283/2700 (epoch 42.278), train_loss = 0.67618066, grad/param norm = 2.8496e-01, time/batch = 0.3005s	
2284/2700 (epoch 42.296), train_loss = 0.66336413, grad/param norm = 2.2696e-01, time/batch = 0.2179s	
2285/2700 (epoch 42.315), train_loss = 0.64688215, grad/param norm = 2.7176e-01, time/batch = 0.3170s	
2286/2700 (epoch 42.333), train_loss = 0.65438713, grad/param norm = 2.6714e-01, time/batch = 0.3210s	
2287/2700 (epoch 42.352), train_loss = 0.65251446, grad/param norm = 2.4702e-01, time/batch = 0.3176s	
2288/2700 (epoch 42.370), train_loss = 0.64593265, grad/param norm = 2.3402e-01, time/batch = 0.3191s	
2289/2700 (epoch 42.389), train_loss = 0.63353502, grad/param norm = 2.6470e-01, time/batch = 0.3032s	
2290/2700 (epoch 42.407), train_loss = 0.72054381, grad/param norm = 2.6516e-01, time/batch = 0.2931s	
2291/2700 (epoch 42.426), train_loss = 0.67768236, grad/param norm = 1.9614e-01, time/batch = 0.3019s	
2292/2700 (epoch 42.444), train_loss = 0.67827412, grad/param norm = 2.6042e-01, time/batch = 0.3006s	
2293/2700 (epoch 42.463), train_loss = 0.69161644, grad/param norm = 2.5421e-01, time/batch = 0.3003s	
2294/2700 (epoch 42.481), train_loss = 0.64024747, grad/param norm = 2.1285e-01, time/batch = 0.2853s	
2295/2700 (epoch 42.500), train_loss = 0.59414332, grad/param norm = 2.2694e-01, time/batch = 0.2662s	
2296/2700 (epoch 42.519), train_loss = 0.64134839, grad/param norm = 1.7680e-01, time/batch = 0.3174s	
2297/2700 (epoch 42.537), train_loss = 0.62881688, grad/param norm = 1.9268e-01, time/batch = 0.3172s	
2298/2700 (epoch 42.556), train_loss = 0.60925484, grad/param norm = 2.3449e-01, time/batch = 0.3027s	
2299/2700 (epoch 42.574), train_loss = 0.61074943, grad/param norm = 2.1829e-01, time/batch = 0.2881s	
2300/2700 (epoch 42.593), train_loss = 0.64394510, grad/param norm = 2.2211e-01, time/batch = 0.2918s	
2301/2700 (epoch 42.611), train_loss = 0.62910519, grad/param norm = 2.4506e-01, time/batch = 0.2978s	
2302/2700 (epoch 42.630), train_loss = 0.65252652, grad/param norm = 2.2428e-01, time/batch = 0.2913s	
2303/2700 (epoch 42.648), train_loss = 0.65035055, grad/param norm = 2.5736e-01, time/batch = 0.2778s	
2304/2700 (epoch 42.667), train_loss = 0.63136635, grad/param norm = 2.5668e-01, time/batch = 0.2860s	
2305/2700 (epoch 42.685), train_loss = 0.65616167, grad/param norm = 2.4335e-01, time/batch = 0.2961s	
2306/2700 (epoch 42.704), train_loss = 0.68570472, grad/param norm = 2.8615e-01, time/batch = 0.2864s	
2307/2700 (epoch 42.722), train_loss = 0.70108861, grad/param norm = 2.8578e-01, time/batch = 0.3052s	
2308/2700 (epoch 42.741), train_loss = 0.65555326, grad/param norm = 2.3414e-01, time/batch = 0.3019s	
2309/2700 (epoch 42.759), train_loss = 0.62803577, grad/param norm = 2.2499e-01, time/batch = 0.2878s	
2310/2700 (epoch 42.778), train_loss = 0.66399450, grad/param norm = 2.2715e-01, time/batch = 0.2889s	
2311/2700 (epoch 42.796), train_loss = 0.63826102, grad/param norm = 2.8648e-01, time/batch = 0.2886s	
2312/2700 (epoch 42.815), train_loss = 0.67489456, grad/param norm = 2.9323e-01, time/batch = 0.2930s	
2313/2700 (epoch 42.833), train_loss = 0.64033122, grad/param norm = 2.1096e-01, time/batch = 0.2490s	
2314/2700 (epoch 42.852), train_loss = 0.62413334, grad/param norm = 2.0622e-01, time/batch = 0.2896s	
2315/2700 (epoch 42.870), train_loss = 0.65567871, grad/param norm = 2.3862e-01, time/batch = 0.3037s	
2316/2700 (epoch 42.889), train_loss = 0.63255585, grad/param norm = 2.4868e-01, time/batch = 0.2993s	
2317/2700 (epoch 42.907), train_loss = 0.68129206, grad/param norm = 2.1994e-01, time/batch = 0.2917s	
2318/2700 (epoch 42.926), train_loss = 0.62846501, grad/param norm = 1.9956e-01, time/batch = 0.3018s	
2319/2700 (epoch 42.944), train_loss = 0.63255411, grad/param norm = 2.1387e-01, time/batch = 0.2841s	
2320/2700 (epoch 42.963), train_loss = 0.64095385, grad/param norm = 1.9038e-01, time/batch = 0.2824s	
2321/2700 (epoch 42.981), train_loss = 0.60374514, grad/param norm = 2.1126e-01, time/batch = 0.3115s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
2322/2700 (epoch 43.000), train_loss = 0.63393148, grad/param norm = 2.1743e-01, time/batch = 0.2835s	
2323/2700 (epoch 43.019), train_loss = 0.73476902, grad/param norm = 2.1440e-01, time/batch = 0.2810s	
2324/2700 (epoch 43.037), train_loss = 0.65797350, grad/param norm = 2.2422e-01, time/batch = 0.2822s	
2325/2700 (epoch 43.056), train_loss = 0.66819987, grad/param norm = 2.3584e-01, time/batch = 0.2876s	
2326/2700 (epoch 43.074), train_loss = 0.62711244, grad/param norm = 2.2724e-01, time/batch = 0.2951s	
2327/2700 (epoch 43.093), train_loss = 0.61714894, grad/param norm = 2.0291e-01, time/batch = 0.3024s	
2328/2700 (epoch 43.111), train_loss = 0.61102902, grad/param norm = 2.1282e-01, time/batch = 0.2939s	
2329/2700 (epoch 43.130), train_loss = 0.63653056, grad/param norm = 2.5798e-01, time/batch = 0.2944s	
2330/2700 (epoch 43.148), train_loss = 0.65362661, grad/param norm = 2.4960e-01, time/batch = 0.2836s	
2331/2700 (epoch 43.167), train_loss = 0.67208062, grad/param norm = 2.2695e-01, time/batch = 0.3112s	
2332/2700 (epoch 43.185), train_loss = 0.66339974, grad/param norm = 2.5022e-01, time/batch = 0.2822s	
2333/2700 (epoch 43.204), train_loss = 0.63179677, grad/param norm = 2.3228e-01, time/batch = 0.2628s	
2334/2700 (epoch 43.222), train_loss = 0.59366519, grad/param norm = 2.5352e-01, time/batch = 0.2311s	
2335/2700 (epoch 43.241), train_loss = 0.60490482, grad/param norm = 2.1485e-01, time/batch = 0.1916s	
2336/2700 (epoch 43.259), train_loss = 0.62490115, grad/param norm = 2.1071e-01, time/batch = 0.2298s	
2337/2700 (epoch 43.278), train_loss = 0.63370062, grad/param norm = 2.1647e-01, time/batch = 0.2432s	
2338/2700 (epoch 43.296), train_loss = 0.66286483, grad/param norm = 3.1844e-01, time/batch = 0.2360s	
2339/2700 (epoch 43.315), train_loss = 0.61625294, grad/param norm = 2.1932e-01, time/batch = 0.2252s	
2340/2700 (epoch 43.333), train_loss = 0.62216109, grad/param norm = 2.5053e-01, time/batch = 0.1740s	
2341/2700 (epoch 43.352), train_loss = 0.62642356, grad/param norm = 2.6723e-01, time/batch = 0.2420s	
2342/2700 (epoch 43.370), train_loss = 0.64475978, grad/param norm = 3.0290e-01, time/batch = 0.2167s	
2343/2700 (epoch 43.389), train_loss = 0.61442653, grad/param norm = 2.4998e-01, time/batch = 0.2673s	
2344/2700 (epoch 43.407), train_loss = 0.68150041, grad/param norm = 2.1765e-01, time/batch = 0.2678s	
2345/2700 (epoch 43.426), train_loss = 0.66071017, grad/param norm = 2.5280e-01, time/batch = 0.2686s	
2346/2700 (epoch 43.444), train_loss = 0.65473024, grad/param norm = 2.2646e-01, time/batch = 0.2620s	
2347/2700 (epoch 43.463), train_loss = 0.66122450, grad/param norm = 2.3300e-01, time/batch = 0.2565s	
2348/2700 (epoch 43.481), train_loss = 0.61954589, grad/param norm = 2.1484e-01, time/batch = 0.2526s	
2349/2700 (epoch 43.500), train_loss = 0.58264395, grad/param norm = 2.3038e-01, time/batch = 0.2409s	
2350/2700 (epoch 43.519), train_loss = 0.62756228, grad/param norm = 2.0991e-01, time/batch = 0.2344s	
2351/2700 (epoch 43.537), train_loss = 0.61603902, grad/param norm = 2.1123e-01, time/batch = 0.1990s	
2352/2700 (epoch 43.556), train_loss = 0.58114893, grad/param norm = 2.0155e-01, time/batch = 0.2561s	
2353/2700 (epoch 43.574), train_loss = 0.59279438, grad/param norm = 2.4711e-01, time/batch = 0.2182s	
2354/2700 (epoch 43.593), train_loss = 0.63423449, grad/param norm = 2.4860e-01, time/batch = 0.2597s	
2355/2700 (epoch 43.611), train_loss = 0.61156152, grad/param norm = 2.5756e-01, time/batch = 0.2641s	
2356/2700 (epoch 43.630), train_loss = 0.63208950, grad/param norm = 2.1857e-01, time/batch = 0.2659s	
2357/2700 (epoch 43.648), train_loss = 0.61682992, grad/param norm = 2.0965e-01, time/batch = 0.2656s	
2358/2700 (epoch 43.667), train_loss = 0.59984727, grad/param norm = 2.0924e-01, time/batch = 0.2563s	
2359/2700 (epoch 43.685), train_loss = 0.62282881, grad/param norm = 2.2723e-01, time/batch = 0.2564s	
2360/2700 (epoch 43.704), train_loss = 0.64862169, grad/param norm = 2.1663e-01, time/batch = 0.2429s	
2361/2700 (epoch 43.722), train_loss = 0.65281200, grad/param norm = 2.2334e-01, time/batch = 0.2600s	
2362/2700 (epoch 43.741), train_loss = 0.61925485, grad/param norm = 2.2133e-01, time/batch = 0.2507s	
2363/2700 (epoch 43.759), train_loss = 0.61069824, grad/param norm = 2.3161e-01, time/batch = 0.2321s	
2364/2700 (epoch 43.778), train_loss = 0.64383024, grad/param norm = 2.3639e-01, time/batch = 0.2368s	
2365/2700 (epoch 43.796), train_loss = 0.59159229, grad/param norm = 1.9074e-01, time/batch = 0.2332s	
2366/2700 (epoch 43.815), train_loss = 0.62458572, grad/param norm = 2.0735e-01, time/batch = 0.2278s	
2367/2700 (epoch 43.833), train_loss = 0.61817472, grad/param norm = 2.4726e-01, time/batch = 0.2304s	
2368/2700 (epoch 43.852), train_loss = 0.60489600, grad/param norm = 2.0017e-01, time/batch = 0.2393s	
2369/2700 (epoch 43.870), train_loss = 0.62815065, grad/param norm = 2.3574e-01, time/batch = 0.1951s	
2370/2700 (epoch 43.889), train_loss = 0.61177073, grad/param norm = 2.2765e-01, time/batch = 0.2201s	
2371/2700 (epoch 43.907), train_loss = 0.66339284, grad/param norm = 2.4007e-01, time/batch = 0.2464s	
2372/2700 (epoch 43.926), train_loss = 0.61281474, grad/param norm = 2.2995e-01, time/batch = 0.2495s	
2373/2700 (epoch 43.944), train_loss = 0.61520148, grad/param norm = 2.2853e-01, time/batch = 0.2381s	
2374/2700 (epoch 43.963), train_loss = 0.62517808, grad/param norm = 2.1000e-01, time/batch = 0.2190s	
2375/2700 (epoch 43.981), train_loss = 0.58569996, grad/param norm = 2.0643e-01, time/batch = 0.2379s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
2376/2700 (epoch 44.000), train_loss = 0.60954908, grad/param norm = 2.1349e-01, time/batch = 0.2376s	
2377/2700 (epoch 44.019), train_loss = 0.70791998, grad/param norm = 2.0146e-01, time/batch = 0.2320s	
2378/2700 (epoch 44.037), train_loss = 0.62860654, grad/param norm = 2.0731e-01, time/batch = 0.2343s	
2379/2700 (epoch 44.056), train_loss = 0.64319575, grad/param norm = 2.1923e-01, time/batch = 0.2417s	
2380/2700 (epoch 44.074), train_loss = 0.59888416, grad/param norm = 1.9954e-01, time/batch = 0.2483s	
2381/2700 (epoch 44.093), train_loss = 0.59673104, grad/param norm = 2.1630e-01, time/batch = 0.2312s	
2382/2700 (epoch 44.111), train_loss = 0.60170664, grad/param norm = 2.4432e-01, time/batch = 0.2368s	
2383/2700 (epoch 44.130), train_loss = 0.61212164, grad/param norm = 2.1955e-01, time/batch = 0.2117s	
2384/2700 (epoch 44.148), train_loss = 0.61743143, grad/param norm = 1.9919e-01, time/batch = 0.2467s	
2385/2700 (epoch 44.167), train_loss = 0.65001166, grad/param norm = 2.3821e-01, time/batch = 0.1909s	
2386/2700 (epoch 44.185), train_loss = 0.63987249, grad/param norm = 2.3877e-01, time/batch = 0.2443s	
2387/2700 (epoch 44.204), train_loss = 0.61504988, grad/param norm = 2.4348e-01, time/batch = 0.2344s	
2388/2700 (epoch 44.222), train_loss = 0.57043114, grad/param norm = 2.4623e-01, time/batch = 0.2345s	
2389/2700 (epoch 44.241), train_loss = 0.58045326, grad/param norm = 1.9514e-01, time/batch = 0.2312s	
2390/2700 (epoch 44.259), train_loss = 0.60191216, grad/param norm = 2.3170e-01, time/batch = 0.2327s	
2391/2700 (epoch 44.278), train_loss = 0.62012057, grad/param norm = 2.1773e-01, time/batch = 0.2341s	
2392/2700 (epoch 44.296), train_loss = 0.63086157, grad/param norm = 2.8064e-01, time/batch = 0.2370s	
2393/2700 (epoch 44.315), train_loss = 0.60712027, grad/param norm = 2.6148e-01, time/batch = 0.2337s	
2394/2700 (epoch 44.333), train_loss = 0.60274025, grad/param norm = 2.2469e-01, time/batch = 0.2046s	
2395/2700 (epoch 44.352), train_loss = 0.59589919, grad/param norm = 2.0783e-01, time/batch = 0.2473s	
2396/2700 (epoch 44.370), train_loss = 0.60044506, grad/param norm = 2.3160e-01, time/batch = 0.1946s	
2397/2700 (epoch 44.389), train_loss = 0.58521375, grad/param norm = 2.3281e-01, time/batch = 0.2479s	
2398/2700 (epoch 44.407), train_loss = 0.68231301, grad/param norm = 3.2471e-01, time/batch = 0.2363s	
2399/2700 (epoch 44.426), train_loss = 0.65821254, grad/param norm = 2.9593e-01, time/batch = 0.2353s	
2400/2700 (epoch 44.444), train_loss = 0.63346499, grad/param norm = 2.2769e-01, time/batch = 0.2364s	
2401/2700 (epoch 44.463), train_loss = 0.64297466, grad/param norm = 2.4879e-01, time/batch = 0.2507s	
2402/2700 (epoch 44.481), train_loss = 0.62342387, grad/param norm = 3.0564e-01, time/batch = 0.2389s	
2403/2700 (epoch 44.500), train_loss = 0.56764317, grad/param norm = 2.4273e-01, time/batch = 0.2392s	
2404/2700 (epoch 44.519), train_loss = 0.61341889, grad/param norm = 2.1319e-01, time/batch = 0.2348s	
2405/2700 (epoch 44.537), train_loss = 0.59823964, grad/param norm = 2.3274e-01, time/batch = 0.1828s	
2406/2700 (epoch 44.556), train_loss = 0.56676478, grad/param norm = 2.0210e-01, time/batch = 0.2427s	
2407/2700 (epoch 44.574), train_loss = 0.56556220, grad/param norm = 2.1808e-01, time/batch = 0.1233s	
2408/2700 (epoch 44.593), train_loss = 0.60796675, grad/param norm = 2.2052e-01, time/batch = 0.2199s	
2409/2700 (epoch 44.611), train_loss = 0.58855302, grad/param norm = 2.2379e-01, time/batch = 0.1769s	
2410/2700 (epoch 44.630), train_loss = 0.62958014, grad/param norm = 2.7568e-01, time/batch = 0.1818s	
2411/2700 (epoch 44.648), train_loss = 0.60827767, grad/param norm = 2.2428e-01, time/batch = 0.2027s	
2412/2700 (epoch 44.667), train_loss = 0.58274486, grad/param norm = 2.3159e-01, time/batch = 0.2458s	
2413/2700 (epoch 44.685), train_loss = 0.60480884, grad/param norm = 2.2487e-01, time/batch = 0.2431s	
2414/2700 (epoch 44.704), train_loss = 0.62990129, grad/param norm = 2.2663e-01, time/batch = 0.2288s	
2415/2700 (epoch 44.722), train_loss = 0.63218829, grad/param norm = 2.0385e-01, time/batch = 0.1714s	
2416/2700 (epoch 44.741), train_loss = 0.59962293, grad/param norm = 2.0608e-01, time/batch = 0.1903s	
2417/2700 (epoch 44.759), train_loss = 0.57935632, grad/param norm = 2.0344e-01, time/batch = 0.2197s	
2418/2700 (epoch 44.778), train_loss = 0.61580714, grad/param norm = 2.0913e-01, time/batch = 0.1806s	
2419/2700 (epoch 44.796), train_loss = 0.58417207, grad/param norm = 2.3950e-01, time/batch = 0.1951s	
2420/2700 (epoch 44.815), train_loss = 0.61064675, grad/param norm = 2.2845e-01, time/batch = 0.1144s	
2421/2700 (epoch 44.833), train_loss = 0.58774297, grad/param norm = 1.9261e-01, time/batch = 0.2223s	
2422/2700 (epoch 44.852), train_loss = 0.58259463, grad/param norm = 2.0793e-01, time/batch = 0.2387s	
2423/2700 (epoch 44.870), train_loss = 0.61005303, grad/param norm = 2.1350e-01, time/batch = 0.2366s	
2424/2700 (epoch 44.889), train_loss = 0.58032232, grad/param norm = 1.8906e-01, time/batch = 0.1673s	
2425/2700 (epoch 44.907), train_loss = 0.63984765, grad/param norm = 2.6744e-01, time/batch = 0.1947s	
2426/2700 (epoch 44.926), train_loss = 0.59504797, grad/param norm = 2.3998e-01, time/batch = 0.2238s	
2427/2700 (epoch 44.944), train_loss = 0.59178032, grad/param norm = 1.9231e-01, time/batch = 0.2003s	
2428/2700 (epoch 44.963), train_loss = 0.61398171, grad/param norm = 2.5299e-01, time/batch = 0.1958s	
2429/2700 (epoch 44.981), train_loss = 0.56676940, grad/param norm = 2.1142e-01, time/batch = 0.1949s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
2430/2700 (epoch 45.000), train_loss = 0.58421082, grad/param norm = 1.9423e-01, time/batch = 0.1535s	
2431/2700 (epoch 45.019), train_loss = 0.69382254, grad/param norm = 2.2845e-01, time/batch = 0.2076s	
2432/2700 (epoch 45.037), train_loss = 0.62026437, grad/param norm = 2.5835e-01, time/batch = 0.2250s	
2433/2700 (epoch 45.056), train_loss = 0.63088225, grad/param norm = 2.2987e-01, time/batch = 0.1620s	
2434/2700 (epoch 45.074), train_loss = 0.59314715, grad/param norm = 2.2264e-01, time/batch = 0.1520s	
2435/2700 (epoch 45.093), train_loss = 0.57587909, grad/param norm = 2.0624e-01, time/batch = 0.1991s	
2436/2700 (epoch 45.111), train_loss = 0.57886229, grad/param norm = 2.3843e-01, time/batch = 0.1952s	
2437/2700 (epoch 45.130), train_loss = 0.59866946, grad/param norm = 2.6413e-01, time/batch = 0.1870s	
2438/2700 (epoch 45.148), train_loss = 0.60589226, grad/param norm = 2.4136e-01, time/batch = 0.1737s	
2439/2700 (epoch 45.167), train_loss = 0.63423100, grad/param norm = 2.5217e-01, time/batch = 0.2099s	
2440/2700 (epoch 45.185), train_loss = 0.62209470, grad/param norm = 2.4439e-01, time/batch = 0.2386s	
2441/2700 (epoch 45.204), train_loss = 0.59403299, grad/param norm = 2.5508e-01, time/batch = 0.2442s	
2442/2700 (epoch 45.222), train_loss = 0.55132948, grad/param norm = 2.5265e-01, time/batch = 0.2197s	
2443/2700 (epoch 45.241), train_loss = 0.58586594, grad/param norm = 2.7706e-01, time/batch = 0.1617s	
2444/2700 (epoch 45.259), train_loss = 0.59281145, grad/param norm = 2.3135e-01, time/batch = 0.2093s	
2445/2700 (epoch 45.278), train_loss = 0.60425704, grad/param norm = 2.2961e-01, time/batch = 0.2091s	
2446/2700 (epoch 45.296), train_loss = 0.61119288, grad/param norm = 2.2367e-01, time/batch = 0.1808s	
2447/2700 (epoch 45.315), train_loss = 0.58725540, grad/param norm = 2.6264e-01, time/batch = 0.1853s	
2448/2700 (epoch 45.333), train_loss = 0.58373721, grad/param norm = 2.5199e-01, time/batch = 0.2078s	
2449/2700 (epoch 45.352), train_loss = 0.58427773, grad/param norm = 2.4750e-01, time/batch = 0.1632s	
2450/2700 (epoch 45.370), train_loss = 0.59187907, grad/param norm = 2.3225e-01, time/batch = 0.2363s	
2451/2700 (epoch 45.389), train_loss = 0.56051866, grad/param norm = 2.1693e-01, time/batch = 0.2718s	
2452/2700 (epoch 45.407), train_loss = 0.64334237, grad/param norm = 2.2928e-01, time/batch = 0.2539s	
2453/2700 (epoch 45.426), train_loss = 0.63198615, grad/param norm = 2.8711e-01, time/batch = 0.2374s	
2454/2700 (epoch 45.444), train_loss = 0.63643486, grad/param norm = 3.3162e-01, time/batch = 0.1968s	
2455/2700 (epoch 45.463), train_loss = 0.63994274, grad/param norm = 2.8657e-01, time/batch = 0.1681s	
2456/2700 (epoch 45.481), train_loss = 0.58627687, grad/param norm = 2.1752e-01, time/batch = 0.2093s	
2457/2700 (epoch 45.500), train_loss = 0.54791273, grad/param norm = 2.2474e-01, time/batch = 0.1637s	
2458/2700 (epoch 45.519), train_loss = 0.59320260, grad/param norm = 2.2643e-01, time/batch = 0.1992s	
2459/2700 (epoch 45.537), train_loss = 0.57649777, grad/param norm = 2.1067e-01, time/batch = 0.1868s	
2460/2700 (epoch 45.556), train_loss = 0.54424282, grad/param norm = 2.0604e-01, time/batch = 0.1789s	
2461/2700 (epoch 45.574), train_loss = 0.54763642, grad/param norm = 2.1151e-01, time/batch = 0.2353s	
2462/2700 (epoch 45.593), train_loss = 0.58076252, grad/param norm = 2.1649e-01, time/batch = 0.2284s	
2463/2700 (epoch 45.611), train_loss = 0.56360214, grad/param norm = 2.0489e-01, time/batch = 0.1725s	
2464/2700 (epoch 45.630), train_loss = 0.59544460, grad/param norm = 2.1911e-01, time/batch = 0.2144s	
2465/2700 (epoch 45.648), train_loss = 0.58029014, grad/param norm = 2.0246e-01, time/batch = 0.1634s	
2466/2700 (epoch 45.667), train_loss = 0.55731982, grad/param norm = 1.9621e-01, time/batch = 0.2040s	
2467/2700 (epoch 45.685), train_loss = 0.57615538, grad/param norm = 2.1247e-01, time/batch = 0.2392s	
2468/2700 (epoch 45.704), train_loss = 0.61125405, grad/param norm = 2.4995e-01, time/batch = 0.2407s	
2469/2700 (epoch 45.722), train_loss = 0.61272626, grad/param norm = 2.4762e-01, time/batch = 0.2113s	
2470/2700 (epoch 45.741), train_loss = 0.58505398, grad/param norm = 2.1480e-01, time/batch = 0.1494s	
2471/2700 (epoch 45.759), train_loss = 0.56491975, grad/param norm = 2.0653e-01, time/batch = 0.2269s	
2472/2700 (epoch 45.778), train_loss = 0.60424995, grad/param norm = 2.2561e-01, time/batch = 0.2379s	
2473/2700 (epoch 45.796), train_loss = 0.55385283, grad/param norm = 1.9505e-01, time/batch = 0.2106s	
2474/2700 (epoch 45.815), train_loss = 0.57943490, grad/param norm = 2.1207e-01, time/batch = 0.1668s	
2475/2700 (epoch 45.833), train_loss = 0.57630206, grad/param norm = 2.3533e-01, time/batch = 0.2098s	
2476/2700 (epoch 45.852), train_loss = 0.56221573, grad/param norm = 1.9541e-01, time/batch = 0.1740s	
2477/2700 (epoch 45.870), train_loss = 0.58444142, grad/param norm = 1.9430e-01, time/batch = 0.1756s	
2478/2700 (epoch 45.889), train_loss = 0.56188179, grad/param norm = 1.8143e-01, time/batch = 0.2162s	
2479/2700 (epoch 45.907), train_loss = 0.60568314, grad/param norm = 1.9139e-01, time/batch = 0.1568s	
2480/2700 (epoch 45.926), train_loss = 0.56626139, grad/param norm = 2.0883e-01, time/batch = 0.2187s	
2481/2700 (epoch 45.944), train_loss = 0.57425492, grad/param norm = 2.4032e-01, time/batch = 0.1932s	
2482/2700 (epoch 45.963), train_loss = 0.58931306, grad/param norm = 2.4204e-01, time/batch = 0.1644s	
2483/2700 (epoch 45.981), train_loss = 0.54453765, grad/param norm = 2.0051e-01, time/batch = 0.2032s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
2484/2700 (epoch 46.000), train_loss = 0.56198225, grad/param norm = 1.9163e-01, time/batch = 0.1936s	
2485/2700 (epoch 46.019), train_loss = 0.67354314, grad/param norm = 2.2875e-01, time/batch = 0.1843s	
2486/2700 (epoch 46.037), train_loss = 0.60377344, grad/param norm = 2.3355e-01, time/batch = 0.2379s	
2487/2700 (epoch 46.056), train_loss = 0.60584723, grad/param norm = 2.3595e-01, time/batch = 0.2446s	
2488/2700 (epoch 46.074), train_loss = 0.56606177, grad/param norm = 2.1997e-01, time/batch = 0.1986s	
2489/2700 (epoch 46.093), train_loss = 0.55615967, grad/param norm = 2.0471e-01, time/batch = 0.1765s	
2490/2700 (epoch 46.111), train_loss = 0.55884046, grad/param norm = 2.2008e-01, time/batch = 0.2150s	
2491/2700 (epoch 46.130), train_loss = 0.58236460, grad/param norm = 2.5202e-01, time/batch = 0.2038s	
2492/2700 (epoch 46.148), train_loss = 0.58259009, grad/param norm = 2.4376e-01, time/batch = 0.1691s	
2493/2700 (epoch 46.167), train_loss = 0.61242081, grad/param norm = 2.5943e-01, time/batch = 0.2590s	
2494/2700 (epoch 46.185), train_loss = 0.60545014, grad/param norm = 2.4422e-01, time/batch = 0.2260s	
2495/2700 (epoch 46.204), train_loss = 0.56673774, grad/param norm = 2.0385e-01, time/batch = 0.2098s	
2496/2700 (epoch 46.222), train_loss = 0.53315824, grad/param norm = 2.4303e-01, time/batch = 0.2388s	
2497/2700 (epoch 46.241), train_loss = 0.54562972, grad/param norm = 2.0493e-01, time/batch = 0.2525s	
2498/2700 (epoch 46.259), train_loss = 0.56220256, grad/param norm = 2.0632e-01, time/batch = 0.2512s	
2499/2700 (epoch 46.278), train_loss = 0.58984709, grad/param norm = 2.6272e-01, time/batch = 0.2053s	
2500/2700 (epoch 46.296), train_loss = 0.59138746, grad/param norm = 2.4025e-01, time/batch = 0.2277s	
2501/2700 (epoch 46.315), train_loss = 0.55905372, grad/param norm = 2.2945e-01, time/batch = 0.2480s	
2502/2700 (epoch 46.333), train_loss = 0.56115222, grad/param norm = 2.2977e-01, time/batch = 0.2558s	
2503/2700 (epoch 46.352), train_loss = 0.56854294, grad/param norm = 2.6462e-01, time/batch = 0.2393s	
2504/2700 (epoch 46.370), train_loss = 0.56839435, grad/param norm = 2.3088e-01, time/batch = 0.1913s	
2505/2700 (epoch 46.389), train_loss = 0.54941629, grad/param norm = 2.3564e-01, time/batch = 0.2150s	
2506/2700 (epoch 46.407), train_loss = 0.61492805, grad/param norm = 1.9317e-01, time/batch = 0.2466s	
2507/2700 (epoch 46.426), train_loss = 0.59421833, grad/param norm = 2.2697e-01, time/batch = 0.2158s	
2508/2700 (epoch 46.444), train_loss = 0.59696505, grad/param norm = 2.3651e-01, time/batch = 0.2373s	
2509/2700 (epoch 46.463), train_loss = 0.60915445, grad/param norm = 2.5972e-01, time/batch = 0.2603s	
2510/2700 (epoch 46.481), train_loss = 0.58040040, grad/param norm = 2.7219e-01, time/batch = 0.2641s	
2511/2700 (epoch 46.500), train_loss = 0.52747067, grad/param norm = 2.3574e-01, time/batch = 0.2335s	
2512/2700 (epoch 46.519), train_loss = 0.56323939, grad/param norm = 1.9511e-01, time/batch = 0.2217s	
2513/2700 (epoch 46.537), train_loss = 0.54882155, grad/param norm = 2.1382e-01, time/batch = 0.1931s	
2514/2700 (epoch 46.556), train_loss = 0.53523550, grad/param norm = 2.3997e-01, time/batch = 0.2150s	
2515/2700 (epoch 46.574), train_loss = 0.54086356, grad/param norm = 2.4279e-01, time/batch = 0.2630s	
2516/2700 (epoch 46.593), train_loss = 0.57215643, grad/param norm = 2.3547e-01, time/batch = 0.2661s	
2517/2700 (epoch 46.611), train_loss = 0.55074711, grad/param norm = 2.3287e-01, time/batch = 0.2431s	
2518/2700 (epoch 46.630), train_loss = 0.57774611, grad/param norm = 2.4113e-01, time/batch = 0.1922s	
2519/2700 (epoch 46.648), train_loss = 0.56819025, grad/param norm = 2.2360e-01, time/batch = 0.2629s	
2520/2700 (epoch 46.667), train_loss = 0.53969691, grad/param norm = 1.9508e-01, time/batch = 0.2431s	
2521/2700 (epoch 46.685), train_loss = 0.56315330, grad/param norm = 2.3680e-01, time/batch = 0.2340s	
2522/2700 (epoch 46.704), train_loss = 0.58844205, grad/param norm = 2.2641e-01, time/batch = 0.1904s	
2523/2700 (epoch 46.722), train_loss = 0.58431612, grad/param norm = 2.1283e-01, time/batch = 0.2271s	
2524/2700 (epoch 46.741), train_loss = 0.56561958, grad/param norm = 2.4126e-01, time/batch = 0.1984s	
2525/2700 (epoch 46.759), train_loss = 0.56012805, grad/param norm = 2.5736e-01, time/batch = 0.2340s	
2526/2700 (epoch 46.778), train_loss = 0.58959977, grad/param norm = 2.6138e-01, time/batch = 0.2181s	
2527/2700 (epoch 46.796), train_loss = 0.54970704, grad/param norm = 2.3545e-01, time/batch = 0.2498s	
2528/2700 (epoch 46.815), train_loss = 0.57483682, grad/param norm = 2.3267e-01, time/batch = 0.2629s	
2529/2700 (epoch 46.833), train_loss = 0.55098664, grad/param norm = 1.9583e-01, time/batch = 0.2475s	
2530/2700 (epoch 46.852), train_loss = 0.54680555, grad/param norm = 2.2277e-01, time/batch = 0.2259s	
2531/2700 (epoch 46.870), train_loss = 0.56971568, grad/param norm = 2.2883e-01, time/batch = 0.1635s	
2532/2700 (epoch 46.889), train_loss = 0.54525414, grad/param norm = 2.0575e-01, time/batch = 0.2297s	
2533/2700 (epoch 46.907), train_loss = 0.59029846, grad/param norm = 2.2540e-01, time/batch = 0.1919s	
2534/2700 (epoch 46.926), train_loss = 0.55065367, grad/param norm = 1.9915e-01, time/batch = 0.1974s	
2535/2700 (epoch 46.944), train_loss = 0.55199535, grad/param norm = 2.1421e-01, time/batch = 0.2610s	
2536/2700 (epoch 46.963), train_loss = 0.57523388, grad/param norm = 2.4627e-01, time/batch = 0.2460s	
2537/2700 (epoch 46.981), train_loss = 0.53711442, grad/param norm = 2.4214e-01, time/batch = 0.2130s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
2538/2700 (epoch 47.000), train_loss = 0.54684351, grad/param norm = 2.1528e-01, time/batch = 0.2400s	
2539/2700 (epoch 47.019), train_loss = 0.65361098, grad/param norm = 2.1128e-01, time/batch = 0.2675s	
2540/2700 (epoch 47.037), train_loss = 0.57432348, grad/param norm = 2.3434e-01, time/batch = 0.2549s	
2541/2700 (epoch 47.056), train_loss = 0.58892015, grad/param norm = 2.6323e-01, time/batch = 0.2309s	
2542/2700 (epoch 47.074), train_loss = 0.55000987, grad/param norm = 2.1056e-01, time/batch = 0.1882s	
2543/2700 (epoch 47.093), train_loss = 0.54391526, grad/param norm = 2.2462e-01, time/batch = 0.2255s	
2544/2700 (epoch 47.111), train_loss = 0.53965171, grad/param norm = 2.1471e-01, time/batch = 0.1857s	
2545/2700 (epoch 47.130), train_loss = 0.56343898, grad/param norm = 2.7885e-01, time/batch = 0.1966s	
2546/2700 (epoch 47.148), train_loss = 0.57705014, grad/param norm = 2.6735e-01, time/batch = 0.2650s	
2547/2700 (epoch 47.167), train_loss = 0.60342269, grad/param norm = 2.7062e-01, time/batch = 0.2536s	
2548/2700 (epoch 47.185), train_loss = 0.59060319, grad/param norm = 2.4523e-01, time/batch = 0.2286s	
2549/2700 (epoch 47.204), train_loss = 0.54964814, grad/param norm = 2.1510e-01, time/batch = 0.2211s	
2550/2700 (epoch 47.222), train_loss = 0.50105503, grad/param norm = 2.0323e-01, time/batch = 0.2514s	
2551/2700 (epoch 47.241), train_loss = 0.53457823, grad/param norm = 2.3489e-01, time/batch = 0.2295s	
2552/2700 (epoch 47.259), train_loss = 0.55265116, grad/param norm = 2.4964e-01, time/batch = 0.2306s	
2553/2700 (epoch 47.278), train_loss = 0.56614776, grad/param norm = 2.2162e-01, time/batch = 0.2147s	
2554/2700 (epoch 47.296), train_loss = 0.57665772, grad/param norm = 2.7233e-01, time/batch = 0.1762s	
2555/2700 (epoch 47.315), train_loss = 0.54926556, grad/param norm = 2.5088e-01, time/batch = 0.2623s	
2556/2700 (epoch 47.333), train_loss = 0.54076426, grad/param norm = 2.2632e-01, time/batch = 0.2532s	
2557/2700 (epoch 47.352), train_loss = 0.54566206, grad/param norm = 2.1994e-01, time/batch = 0.2296s	
2558/2700 (epoch 47.370), train_loss = 0.55220802, grad/param norm = 2.3693e-01, time/batch = 0.1988s	
2559/2700 (epoch 47.389), train_loss = 0.52582263, grad/param norm = 2.1906e-01, time/batch = 0.2471s	
2560/2700 (epoch 47.407), train_loss = 0.59762897, grad/param norm = 2.2409e-01, time/batch = 0.2263s	
2561/2700 (epoch 47.426), train_loss = 0.56887380, grad/param norm = 1.9457e-01, time/batch = 0.2223s	
2562/2700 (epoch 47.444), train_loss = 0.57140758, grad/param norm = 2.1444e-01, time/batch = 0.2017s	
2563/2700 (epoch 47.463), train_loss = 0.58257711, grad/param norm = 2.3382e-01, time/batch = 0.2366s	
2564/2700 (epoch 47.481), train_loss = 0.56239440, grad/param norm = 2.4720e-01, time/batch = 0.2057s	
2565/2700 (epoch 47.500), train_loss = 0.51627312, grad/param norm = 2.5236e-01, time/batch = 0.2326s	
2566/2700 (epoch 47.519), train_loss = 0.55374980, grad/param norm = 2.1906e-01, time/batch = 0.2232s	
2567/2700 (epoch 47.537), train_loss = 0.53618004, grad/param norm = 2.0116e-01, time/batch = 0.2418s	
2568/2700 (epoch 47.556), train_loss = 0.50799256, grad/param norm = 1.9928e-01, time/batch = 0.2636s	
2569/2700 (epoch 47.574), train_loss = 0.51496357, grad/param norm = 2.1714e-01, time/batch = 0.2553s	
2570/2700 (epoch 47.593), train_loss = 0.55339915, grad/param norm = 2.6375e-01, time/batch = 0.2268s	
2571/2700 (epoch 47.611), train_loss = 0.53031697, grad/param norm = 2.3296e-01, time/batch = 0.1749s	
2572/2700 (epoch 47.630), train_loss = 0.56212400, grad/param norm = 2.2236e-01, time/batch = 0.2306s	
2573/2700 (epoch 47.648), train_loss = 0.55286237, grad/param norm = 2.5675e-01, time/batch = 0.2265s	
2574/2700 (epoch 47.667), train_loss = 0.52953900, grad/param norm = 1.9384e-01, time/batch = 0.1694s	
2575/2700 (epoch 47.685), train_loss = 0.53967173, grad/param norm = 2.2150e-01, time/batch = 0.2582s	
2576/2700 (epoch 47.704), train_loss = 0.57662400, grad/param norm = 2.6734e-01, time/batch = 0.2650s	
2577/2700 (epoch 47.722), train_loss = 0.58164320, grad/param norm = 2.7068e-01, time/batch = 0.2493s	
2578/2700 (epoch 47.741), train_loss = 0.55903531, grad/param norm = 2.5089e-01, time/batch = 0.2135s	
2579/2700 (epoch 47.759), train_loss = 0.54472704, grad/param norm = 2.9216e-01, time/batch = 0.2357s	
2580/2700 (epoch 47.778), train_loss = 0.57248589, grad/param norm = 2.2682e-01, time/batch = 0.2594s	
2581/2700 (epoch 47.796), train_loss = 0.52512293, grad/param norm = 2.2200e-01, time/batch = 0.2366s	
2582/2700 (epoch 47.815), train_loss = 0.56229303, grad/param norm = 2.3528e-01, time/batch = 0.2349s	
2583/2700 (epoch 47.833), train_loss = 0.53373557, grad/param norm = 2.2082e-01, time/batch = 0.2018s	
2584/2700 (epoch 47.852), train_loss = 0.52424325, grad/param norm = 2.0518e-01, time/batch = 0.1707s	
2585/2700 (epoch 47.870), train_loss = 0.55280606, grad/param norm = 2.1990e-01, time/batch = 0.2241s	
2586/2700 (epoch 47.889), train_loss = 0.53115161, grad/param norm = 2.1346e-01, time/batch = 0.2260s	
2587/2700 (epoch 47.907), train_loss = 0.56586565, grad/param norm = 2.0783e-01, time/batch = 0.2537s	
2588/2700 (epoch 47.926), train_loss = 0.54500028, grad/param norm = 2.5746e-01, time/batch = 0.2646s	
2589/2700 (epoch 47.944), train_loss = 0.53068457, grad/param norm = 2.0391e-01, time/batch = 0.2500s	
2590/2700 (epoch 47.963), train_loss = 0.55127957, grad/param norm = 1.9903e-01, time/batch = 0.2280s	
2591/2700 (epoch 47.981), train_loss = 0.51531586, grad/param norm = 2.3616e-01, time/batch = 0.2235s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
2592/2700 (epoch 48.000), train_loss = 0.53727764, grad/param norm = 2.3007e-01, time/batch = 0.1959s	
2593/2700 (epoch 48.019), train_loss = 0.63079134, grad/param norm = 2.2313e-01, time/batch = 0.2383s	
2594/2700 (epoch 48.037), train_loss = 0.55532145, grad/param norm = 2.2166e-01, time/batch = 0.2028s	
2595/2700 (epoch 48.056), train_loss = 0.57421800, grad/param norm = 2.5815e-01, time/batch = 0.2320s	
2596/2700 (epoch 48.074), train_loss = 0.53640230, grad/param norm = 2.1017e-01, time/batch = 0.2187s	
2597/2700 (epoch 48.093), train_loss = 0.52567630, grad/param norm = 2.1125e-01, time/batch = 0.2306s	
2598/2700 (epoch 48.111), train_loss = 0.52796466, grad/param norm = 2.3227e-01, time/batch = 0.2302s	
2599/2700 (epoch 48.130), train_loss = 0.54053037, grad/param norm = 2.4996e-01, time/batch = 0.2211s	
2600/2700 (epoch 48.148), train_loss = 0.55035720, grad/param norm = 2.2934e-01, time/batch = 0.2488s	
2601/2700 (epoch 48.167), train_loss = 0.57786381, grad/param norm = 2.6678e-01, time/batch = 0.2318s	
2602/2700 (epoch 48.185), train_loss = 0.57813949, grad/param norm = 2.8099e-01, time/batch = 0.2330s	
2603/2700 (epoch 48.204), train_loss = 0.53257953, grad/param norm = 2.0710e-01, time/batch = 0.2249s	
2604/2700 (epoch 48.222), train_loss = 0.49403718, grad/param norm = 2.2184e-01, time/batch = 0.1876s	
2605/2700 (epoch 48.241), train_loss = 0.50877280, grad/param norm = 1.7907e-01, time/batch = 0.2064s	
2606/2700 (epoch 48.259), train_loss = 0.52650476, grad/param norm = 2.0620e-01, time/batch = 0.1722s	
2607/2700 (epoch 48.278), train_loss = 0.55334889, grad/param norm = 2.6498e-01, time/batch = 0.1200s	
2608/2700 (epoch 48.296), train_loss = 0.55372623, grad/param norm = 2.4583e-01, time/batch = 0.1669s	
2609/2700 (epoch 48.315), train_loss = 0.53476051, grad/param norm = 2.7078e-01, time/batch = 0.1710s	
2610/2700 (epoch 48.333), train_loss = 0.52634100, grad/param norm = 2.3432e-01, time/batch = 0.1540s	
2611/2700 (epoch 48.352), train_loss = 0.52318650, grad/param norm = 2.1636e-01, time/batch = 0.1733s	
2612/2700 (epoch 48.370), train_loss = 0.52783191, grad/param norm = 1.9984e-01, time/batch = 0.1709s	
2613/2700 (epoch 48.389), train_loss = 0.50099486, grad/param norm = 1.9657e-01, time/batch = 0.1715s	
2614/2700 (epoch 48.407), train_loss = 0.58409148, grad/param norm = 2.5168e-01, time/batch = 0.1722s	
2615/2700 (epoch 48.426), train_loss = 0.55907501, grad/param norm = 2.2764e-01, time/batch = 0.1740s	
2616/2700 (epoch 48.444), train_loss = 0.55095298, grad/param norm = 2.2034e-01, time/batch = 0.1597s	
2617/2700 (epoch 48.463), train_loss = 0.56179472, grad/param norm = 2.1630e-01, time/batch = 0.1520s	
2618/2700 (epoch 48.481), train_loss = 0.53251071, grad/param norm = 2.1998e-01, time/batch = 0.1502s	
2619/2700 (epoch 48.500), train_loss = 0.48875002, grad/param norm = 1.9485e-01, time/batch = 0.1491s	
2620/2700 (epoch 48.519), train_loss = 0.53169557, grad/param norm = 2.2940e-01, time/batch = 0.1599s	
2621/2700 (epoch 48.537), train_loss = 0.51773701, grad/param norm = 2.1542e-01, time/batch = 0.1150s	
2622/2700 (epoch 48.556), train_loss = 0.48962265, grad/param norm = 1.8980e-01, time/batch = 0.1668s	
2623/2700 (epoch 48.574), train_loss = 0.49441949, grad/param norm = 2.1189e-01, time/batch = 0.1531s	
2624/2700 (epoch 48.593), train_loss = 0.53273413, grad/param norm = 2.3412e-01, time/batch = 0.1538s	
2625/2700 (epoch 48.611), train_loss = 0.51156974, grad/param norm = 2.1383e-01, time/batch = 0.1510s	
2626/2700 (epoch 48.630), train_loss = 0.54233796, grad/param norm = 2.3841e-01, time/batch = 0.1511s	
2627/2700 (epoch 48.648), train_loss = 0.53482822, grad/param norm = 2.2047e-01, time/batch = 0.1610s	
2628/2700 (epoch 48.667), train_loss = 0.51837522, grad/param norm = 2.5296e-01, time/batch = 0.1714s	
2629/2700 (epoch 48.685), train_loss = 0.53468589, grad/param norm = 2.5545e-01, time/batch = 0.1710s	
2630/2700 (epoch 48.704), train_loss = 0.54698701, grad/param norm = 2.0042e-01, time/batch = 0.1715s	
2631/2700 (epoch 48.722), train_loss = 0.55461874, grad/param norm = 2.4834e-01, time/batch = 0.1619s	
2632/2700 (epoch 48.741), train_loss = 0.53264260, grad/param norm = 2.3314e-01, time/batch = 0.1484s	
2633/2700 (epoch 48.759), train_loss = 0.52044686, grad/param norm = 2.1408e-01, time/batch = 0.1627s	
2634/2700 (epoch 48.778), train_loss = 0.55516254, grad/param norm = 2.4843e-01, time/batch = 0.1478s	
2635/2700 (epoch 48.796), train_loss = 0.51367614, grad/param norm = 2.2122e-01, time/batch = 0.1493s	
2636/2700 (epoch 48.815), train_loss = 0.53636304, grad/param norm = 2.2318e-01, time/batch = 0.1492s	
2637/2700 (epoch 48.833), train_loss = 0.52431883, grad/param norm = 2.3967e-01, time/batch = 0.1593s	
2638/2700 (epoch 48.852), train_loss = 0.51235058, grad/param norm = 2.0626e-01, time/batch = 0.1715s	
2639/2700 (epoch 48.870), train_loss = 0.54029522, grad/param norm = 2.1724e-01, time/batch = 0.1702s	
2640/2700 (epoch 48.889), train_loss = 0.52010227, grad/param norm = 2.3782e-01, time/batch = 0.1714s	
2641/2700 (epoch 48.907), train_loss = 0.55266347, grad/param norm = 2.1460e-01, time/batch = 0.1635s	
2642/2700 (epoch 48.926), train_loss = 0.51845873, grad/param norm = 2.2366e-01, time/batch = 0.1708s	
2643/2700 (epoch 48.944), train_loss = 0.52505502, grad/param norm = 2.4224e-01, time/batch = 0.1525s	
2644/2700 (epoch 48.963), train_loss = 0.53471830, grad/param norm = 2.2811e-01, time/batch = 0.1582s	
2645/2700 (epoch 48.981), train_loss = 0.49123653, grad/param norm = 1.9386e-01, time/batch = 0.1530s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
2646/2700 (epoch 49.000), train_loss = 0.50523672, grad/param norm = 1.8615e-01, time/batch = 0.1500s	
2647/2700 (epoch 49.019), train_loss = 0.61545018, grad/param norm = 2.2216e-01, time/batch = 0.1495s	
2648/2700 (epoch 49.037), train_loss = 0.53863174, grad/param norm = 2.3532e-01, time/batch = 0.1598s	
2649/2700 (epoch 49.056), train_loss = 0.55659385, grad/param norm = 2.4463e-01, time/batch = 0.1711s	
2650/2700 (epoch 49.074), train_loss = 0.52201488, grad/param norm = 2.3626e-01, time/batch = 0.1709s	
2651/2700 (epoch 49.093), train_loss = 0.51097523, grad/param norm = 2.2562e-01, time/batch = 0.1577s	
2652/2700 (epoch 49.111), train_loss = 0.50533195, grad/param norm = 2.1716e-01, time/batch = 0.1684s	
2653/2700 (epoch 49.130), train_loss = 0.52556722, grad/param norm = 2.2975e-01, time/batch = 0.1713s	
2654/2700 (epoch 49.148), train_loss = 0.52641740, grad/param norm = 1.9419e-01, time/batch = 0.1545s	
2655/2700 (epoch 49.167), train_loss = 0.55283231, grad/param norm = 2.2506e-01, time/batch = 0.1532s	
2656/2700 (epoch 49.185), train_loss = 0.54591518, grad/param norm = 2.3288e-01, time/batch = 0.1510s	
2657/2700 (epoch 49.204), train_loss = 0.52916840, grad/param norm = 2.7349e-01, time/batch = 0.1498s	
2658/2700 (epoch 49.222), train_loss = 0.48081622, grad/param norm = 2.4376e-01, time/batch = 0.1542s	
2659/2700 (epoch 49.241), train_loss = 0.49976672, grad/param norm = 2.2466e-01, time/batch = 0.1668s	
2660/2700 (epoch 49.259), train_loss = 0.51059314, grad/param norm = 1.9877e-01, time/batch = 0.1718s	
2661/2700 (epoch 49.278), train_loss = 0.52312215, grad/param norm = 1.8855e-01, time/batch = 0.1554s	
2662/2700 (epoch 49.296), train_loss = 0.54028254, grad/param norm = 2.5319e-01, time/batch = 0.1662s	
2663/2700 (epoch 49.315), train_loss = 0.50907817, grad/param norm = 2.1935e-01, time/batch = 0.1707s	
2664/2700 (epoch 49.333), train_loss = 0.50735274, grad/param norm = 2.2277e-01, time/batch = 0.1704s	
2665/2700 (epoch 49.352), train_loss = 0.51394797, grad/param norm = 2.2653e-01, time/batch = 0.1597s	
2666/2700 (epoch 49.370), train_loss = 0.51171968, grad/param norm = 2.0164e-01, time/batch = 0.1536s	
2667/2700 (epoch 49.389), train_loss = 0.48115655, grad/param norm = 1.8345e-01, time/batch = 0.1515s	
2668/2700 (epoch 49.407), train_loss = 0.55127891, grad/param norm = 1.9805e-01, time/batch = 0.1517s	
2669/2700 (epoch 49.426), train_loss = 0.53498725, grad/param norm = 2.4125e-01, time/batch = 0.1529s	
2670/2700 (epoch 49.444), train_loss = 0.54005339, grad/param norm = 2.5692e-01, time/batch = 0.1614s	
2671/2700 (epoch 49.463), train_loss = 0.54829870, grad/param norm = 2.3677e-01, time/batch = 0.1485s	
2672/2700 (epoch 49.481), train_loss = 0.52772567, grad/param norm = 2.3295e-01, time/batch = 0.1616s	
2673/2700 (epoch 49.500), train_loss = 0.47623773, grad/param norm = 2.1305e-01, time/batch = 0.1713s	
2674/2700 (epoch 49.519), train_loss = 0.51518299, grad/param norm = 1.9550e-01, time/batch = 0.1704s	
2675/2700 (epoch 49.537), train_loss = 0.49907323, grad/param norm = 2.1201e-01, time/batch = 0.1713s	
2676/2700 (epoch 49.556), train_loss = 0.47582195, grad/param norm = 2.2020e-01, time/batch = 0.1605s	
2677/2700 (epoch 49.574), train_loss = 0.47973660, grad/param norm = 1.9887e-01, time/batch = 0.1537s	
2678/2700 (epoch 49.593), train_loss = 0.50623229, grad/param norm = 2.0032e-01, time/batch = 0.1527s	
2679/2700 (epoch 49.611), train_loss = 0.49346858, grad/param norm = 2.2143e-01, time/batch = 0.1490s	
2680/2700 (epoch 49.630), train_loss = 0.53576663, grad/param norm = 2.5266e-01, time/batch = 0.1531s	
2681/2700 (epoch 49.648), train_loss = 0.51143921, grad/param norm = 1.9743e-01, time/batch = 0.1483s	
2682/2700 (epoch 49.667), train_loss = 0.49074436, grad/param norm = 1.9084e-01, time/batch = 0.1503s	
2683/2700 (epoch 49.685), train_loss = 0.50406394, grad/param norm = 2.1822e-01, time/batch = 0.1614s	
2684/2700 (epoch 49.704), train_loss = 0.53728480, grad/param norm = 2.5534e-01, time/batch = 0.1709s	
2685/2700 (epoch 49.722), train_loss = 0.53544077, grad/param norm = 2.2381e-01, time/batch = 0.1700s	
2686/2700 (epoch 49.741), train_loss = 0.51566958, grad/param norm = 2.0691e-01, time/batch = 0.1715s	
2687/2700 (epoch 49.759), train_loss = 0.49719178, grad/param norm = 2.1111e-01, time/batch = 0.1611s	
2688/2700 (epoch 49.778), train_loss = 0.53457529, grad/param norm = 2.1061e-01, time/batch = 0.1542s	
2689/2700 (epoch 49.796), train_loss = 0.48797508, grad/param norm = 2.0630e-01, time/batch = 0.1523s	
2690/2700 (epoch 49.815), train_loss = 0.51350064, grad/param norm = 1.8850e-01, time/batch = 0.1495s	
2691/2700 (epoch 49.833), train_loss = 0.49696301, grad/param norm = 2.1333e-01, time/batch = 0.1522s	
2692/2700 (epoch 49.852), train_loss = 0.51131576, grad/param norm = 2.7717e-01, time/batch = 0.1505s	
2693/2700 (epoch 49.870), train_loss = 0.53092728, grad/param norm = 2.3677e-01, time/batch = 0.1486s	
2694/2700 (epoch 49.889), train_loss = 0.49740367, grad/param norm = 2.0327e-01, time/batch = 0.1597s	
2695/2700 (epoch 49.907), train_loss = 0.53857148, grad/param norm = 2.6802e-01, time/batch = 0.1709s	
2696/2700 (epoch 49.926), train_loss = 0.51111598, grad/param norm = 2.4496e-01, time/batch = 0.1714s	
2697/2700 (epoch 49.944), train_loss = 0.50234190, grad/param norm = 2.0970e-01, time/batch = 0.1711s	
2698/2700 (epoch 49.963), train_loss = 0.52393602, grad/param norm = 2.2495e-01, time/batch = 0.1602s	
2699/2700 (epoch 49.981), train_loss = 0.47739507, grad/param norm = 2.1170e-01, time/batch = 0.1519s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch50.00_2.2961.t7	
2700/2700 (epoch 50.000), train_loss = 0.49150828, grad/param norm = 2.0058e-01, time/batch = 0.1519s	
