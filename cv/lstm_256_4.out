using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 54, val: 3, test: 0	
vocab size: 91	
creating an lstm with 4 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
setting forget gate biases to 1 in LSTM layer 3	
setting forget gate biases to 1 in LSTM layer 4	
number of parameters in the model: 1959771	
cloning rnn	
cloning criterion	
1/2700 (epoch 0.019), train_loss = 4.49576612, grad/param norm = 4.8652e-01, time/batch = 1.3357s	
2/2700 (epoch 0.037), train_loss = 3.57375350, grad/param norm = 9.9788e-01, time/batch = 0.5614s	
3/2700 (epoch 0.056), train_loss = 3.74453931, grad/param norm = 1.0106e+00, time/batch = 0.5639s	
4/2700 (epoch 0.074), train_loss = 3.35209419, grad/param norm = 4.5971e-01, time/batch = 0.5672s	
5/2700 (epoch 0.093), train_loss = 3.32550119, grad/param norm = 3.9034e-01, time/batch = 0.5370s	
6/2700 (epoch 0.111), train_loss = 3.29052191, grad/param norm = 3.2076e-01, time/batch = 0.5544s	
7/2700 (epoch 0.130), train_loss = 3.29755117, grad/param norm = 2.7389e-01, time/batch = 0.5468s	
8/2700 (epoch 0.148), train_loss = 3.25818343, grad/param norm = 3.3839e-01, time/batch = 0.5562s	
9/2700 (epoch 0.167), train_loss = 3.26849607, grad/param norm = 3.5934e-01, time/batch = 0.5498s	
10/2700 (epoch 0.185), train_loss = 3.25406257, grad/param norm = 3.2384e-01, time/batch = 0.5434s	
11/2700 (epoch 0.204), train_loss = 3.18247585, grad/param norm = 2.4286e-01, time/batch = 0.5702s	
12/2700 (epoch 0.222), train_loss = 3.15127503, grad/param norm = 2.3431e-01, time/batch = 0.5619s	
13/2700 (epoch 0.241), train_loss = 3.17357917, grad/param norm = 2.0190e-01, time/batch = 0.5632s	
14/2700 (epoch 0.259), train_loss = 3.20887147, grad/param norm = 1.9138e-01, time/batch = 0.5520s	
15/2700 (epoch 0.278), train_loss = 3.28076044, grad/param norm = 2.2439e-01, time/batch = 0.5414s	
16/2700 (epoch 0.296), train_loss = 3.28349977, grad/param norm = 2.0956e-01, time/batch = 0.5754s	
17/2700 (epoch 0.315), train_loss = 3.25740348, grad/param norm = 1.8360e-01, time/batch = 0.5654s	
18/2700 (epoch 0.333), train_loss = 3.33795202, grad/param norm = 1.8369e-01, time/batch = 0.5542s	
19/2700 (epoch 0.352), train_loss = 3.34226143, grad/param norm = 2.2025e-01, time/batch = 0.5394s	
20/2700 (epoch 0.370), train_loss = 3.28961643, grad/param norm = 2.2014e-01, time/batch = 0.5399s	
21/2700 (epoch 0.389), train_loss = 3.25568490, grad/param norm = 1.7540e-01, time/batch = 0.5592s	
22/2700 (epoch 0.407), train_loss = 3.27622074, grad/param norm = 1.5114e-01, time/batch = 0.5218s	
23/2700 (epoch 0.426), train_loss = 3.27951353, grad/param norm = 1.6820e-01, time/batch = 0.5634s	
24/2700 (epoch 0.444), train_loss = 3.20815231, grad/param norm = 1.4047e-01, time/batch = 0.5505s	
25/2700 (epoch 0.463), train_loss = 3.25104225, grad/param norm = 2.0010e-01, time/batch = 0.5341s	
26/2700 (epoch 0.481), train_loss = 3.32809042, grad/param norm = 2.1368e-01, time/batch = 0.5703s	
27/2700 (epoch 0.500), train_loss = 3.37375191, grad/param norm = 2.9681e-01, time/batch = 0.5731s	
28/2700 (epoch 0.519), train_loss = 3.33071920, grad/param norm = 3.1862e-01, time/batch = 0.5534s	
29/2700 (epoch 0.537), train_loss = 3.33384811, grad/param norm = 3.4924e-01, time/batch = 0.5382s	
30/2700 (epoch 0.556), train_loss = 3.27392360, grad/param norm = 3.1198e-01, time/batch = 0.5499s	
31/2700 (epoch 0.574), train_loss = 3.23669125, grad/param norm = 2.9073e-01, time/batch = 0.5789s	
32/2700 (epoch 0.593), train_loss = 3.23855613, grad/param norm = 3.2561e-01, time/batch = 0.5615s	
33/2700 (epoch 0.611), train_loss = 3.17470977, grad/param norm = 2.2089e-01, time/batch = 0.5384s	
34/2700 (epoch 0.630), train_loss = 3.21357637, grad/param norm = 2.0853e-01, time/batch = 0.5472s	
35/2700 (epoch 0.648), train_loss = 3.28410211, grad/param norm = 2.0131e-01, time/batch = 0.5894s	
36/2700 (epoch 0.667), train_loss = 3.21508170, grad/param norm = 1.6719e-01, time/batch = 0.5513s	
37/2700 (epoch 0.685), train_loss = 3.21230750, grad/param norm = 1.7180e-01, time/batch = 0.5501s	
38/2700 (epoch 0.704), train_loss = 3.18420155, grad/param norm = 2.2091e-01, time/batch = 0.5250s	
39/2700 (epoch 0.722), train_loss = 3.17559013, grad/param norm = 1.6571e-01, time/batch = 0.5589s	
40/2700 (epoch 0.741), train_loss = 3.30847111, grad/param norm = 2.0620e-01, time/batch = 0.5487s	
41/2700 (epoch 0.759), train_loss = 3.25810209, grad/param norm = 2.5098e-01, time/batch = 0.5638s	
42/2700 (epoch 0.778), train_loss = 3.24905644, grad/param norm = 2.2020e-01, time/batch = 0.5507s	
43/2700 (epoch 0.796), train_loss = 3.24255127, grad/param norm = 2.2234e-01, time/batch = 0.5423s	
44/2700 (epoch 0.815), train_loss = 3.19488887, grad/param norm = 1.8267e-01, time/batch = 0.5766s	
45/2700 (epoch 0.833), train_loss = 3.23206035, grad/param norm = 1.8034e-01, time/batch = 0.5471s	
46/2700 (epoch 0.852), train_loss = 3.22052814, grad/param norm = 2.0196e-01, time/batch = 0.5439s	
47/2700 (epoch 0.870), train_loss = 3.21411547, grad/param norm = 1.6378e-01, time/batch = 0.5222s	
48/2700 (epoch 0.889), train_loss = 3.25175769, grad/param norm = 1.8263e-01, time/batch = 0.5347s	
49/2700 (epoch 0.907), train_loss = 3.30501972, grad/param norm = 2.5241e-01, time/batch = 0.5633s	
50/2700 (epoch 0.926), train_loss = 3.25646893, grad/param norm = 2.7025e-01, time/batch = 0.5897s	
51/2700 (epoch 0.944), train_loss = 3.26426001, grad/param norm = 2.5607e-01, time/batch = 0.5495s	
52/2700 (epoch 0.963), train_loss = 3.34271694, grad/param norm = 2.5022e-01, time/batch = 0.5314s	
53/2700 (epoch 0.981), train_loss = 3.40074919, grad/param norm = 2.1401e-01, time/batch = 0.5563s	
54/2700 (epoch 1.000), train_loss = 3.30185506, grad/param norm = 2.3321e-01, time/batch = 0.5969s	
55/2700 (epoch 1.019), train_loss = 3.24291531, grad/param norm = 2.9055e-01, time/batch = 0.5242s	
56/2700 (epoch 1.037), train_loss = 3.25904709, grad/param norm = 2.6096e-01, time/batch = 0.5591s	
57/2700 (epoch 1.056), train_loss = 3.25906196, grad/param norm = 1.5359e-01, time/batch = 0.5373s	
58/2700 (epoch 1.074), train_loss = 3.28994869, grad/param norm = 1.7822e-01, time/batch = 0.5595s	
59/2700 (epoch 1.093), train_loss = 3.29510435, grad/param norm = 2.0923e-01, time/batch = 0.5904s	
60/2700 (epoch 1.111), train_loss = 3.26704237, grad/param norm = 1.8591e-01, time/batch = 0.5642s	
61/2700 (epoch 1.130), train_loss = 3.28077176, grad/param norm = 1.5132e-01, time/batch = 0.5486s	
62/2700 (epoch 1.148), train_loss = 3.24608755, grad/param norm = 2.0964e-01, time/batch = 0.5790s	
63/2700 (epoch 1.167), train_loss = 3.25660010, grad/param norm = 2.4425e-01, time/batch = 0.5320s	
64/2700 (epoch 1.185), train_loss = 3.23975518, grad/param norm = 1.6587e-01, time/batch = 0.5550s	
65/2700 (epoch 1.204), train_loss = 3.17578718, grad/param norm = 1.7717e-01, time/batch = 0.5400s	
66/2700 (epoch 1.222), train_loss = 3.15239671, grad/param norm = 2.6523e-01, time/batch = 0.5545s	
67/2700 (epoch 1.241), train_loss = 3.17033139, grad/param norm = 1.8565e-01, time/batch = 0.5944s	
68/2700 (epoch 1.259), train_loss = 3.20216285, grad/param norm = 1.3109e-01, time/batch = 0.5716s	
69/2700 (epoch 1.278), train_loss = 3.27771709, grad/param norm = 2.0036e-01, time/batch = 0.5467s	
70/2700 (epoch 1.296), train_loss = 3.28009115, grad/param norm = 2.1565e-01, time/batch = 0.5347s	
71/2700 (epoch 1.315), train_loss = 3.25569829, grad/param norm = 1.9034e-01, time/batch = 0.5366s	
72/2700 (epoch 1.333), train_loss = 3.33543869, grad/param norm = 1.8633e-01, time/batch = 0.5635s	
73/2700 (epoch 1.352), train_loss = 3.34108241, grad/param norm = 2.1176e-01, time/batch = 0.5417s	
74/2700 (epoch 1.370), train_loss = 3.28948740, grad/param norm = 2.5735e-01, time/batch = 0.5381s	
75/2700 (epoch 1.389), train_loss = 3.25885577, grad/param norm = 2.8860e-01, time/batch = 0.5767s	
76/2700 (epoch 1.407), train_loss = 3.28292662, grad/param norm = 3.1754e-01, time/batch = 0.5870s	
77/2700 (epoch 1.426), train_loss = 3.28416367, grad/param norm = 3.1100e-01, time/batch = 0.5598s	
78/2700 (epoch 1.444), train_loss = 3.21482682, grad/param norm = 3.0328e-01, time/batch = 0.5415s	
79/2700 (epoch 1.463), train_loss = 3.25217577, grad/param norm = 2.9257e-01, time/batch = 0.5269s	
80/2700 (epoch 1.481), train_loss = 3.32813130, grad/param norm = 2.4650e-01, time/batch = 0.5703s	
81/2700 (epoch 1.500), train_loss = 3.37182350, grad/param norm = 2.6732e-01, time/batch = 0.5480s	
82/2700 (epoch 1.519), train_loss = 3.32440926, grad/param norm = 2.3068e-01, time/batch = 0.5392s	
83/2700 (epoch 1.537), train_loss = 3.32650736, grad/param norm = 2.1904e-01, time/batch = 0.5593s	
84/2700 (epoch 1.556), train_loss = 3.26253376, grad/param norm = 1.6259e-01, time/batch = 0.6320s	
85/2700 (epoch 1.574), train_loss = 3.23168520, grad/param norm = 1.8191e-01, time/batch = 0.5685s	
86/2700 (epoch 1.593), train_loss = 3.23219051, grad/param norm = 2.3480e-01, time/batch = 0.5391s	
87/2700 (epoch 1.611), train_loss = 3.17160049, grad/param norm = 1.5776e-01, time/batch = 0.5362s	
88/2700 (epoch 1.630), train_loss = 3.21221132, grad/param norm = 1.7375e-01, time/batch = 0.5624s	
89/2700 (epoch 1.648), train_loss = 3.28189476, grad/param norm = 1.8130e-01, time/batch = 0.5674s	
90/2700 (epoch 1.667), train_loss = 3.21394046, grad/param norm = 1.4487e-01, time/batch = 0.5407s	
91/2700 (epoch 1.685), train_loss = 3.21173419, grad/param norm = 1.7991e-01, time/batch = 0.5923s	
92/2700 (epoch 1.704), train_loss = 3.18454327, grad/param norm = 2.3270e-01, time/batch = 0.5868s	
93/2700 (epoch 1.722), train_loss = 3.17507910, grad/param norm = 1.8385e-01, time/batch = 0.5525s	
94/2700 (epoch 1.741), train_loss = 3.31008641, grad/param norm = 2.5223e-01, time/batch = 0.5367s	
95/2700 (epoch 1.759), train_loss = 3.25768803, grad/param norm = 2.5786e-01, time/batch = 0.5367s	
96/2700 (epoch 1.778), train_loss = 3.24760980, grad/param norm = 2.0694e-01, time/batch = 0.5740s	
97/2700 (epoch 1.796), train_loss = 3.24078299, grad/param norm = 2.0169e-01, time/batch = 0.5535s	
98/2700 (epoch 1.815), train_loss = 3.19318800, grad/param norm = 1.5728e-01, time/batch = 0.5521s	
99/2700 (epoch 1.833), train_loss = 3.23116737, grad/param norm = 1.6902e-01, time/batch = 0.5401s	
100/2700 (epoch 1.852), train_loss = 3.21891694, grad/param norm = 1.8833e-01, time/batch = 0.5460s	
101/2700 (epoch 1.870), train_loss = 3.21272149, grad/param norm = 1.4318e-01, time/batch = 0.5605s	
102/2700 (epoch 1.889), train_loss = 3.25132654, grad/param norm = 1.6514e-01, time/batch = 0.5631s	
103/2700 (epoch 1.907), train_loss = 3.30411917, grad/param norm = 2.3269e-01, time/batch = 0.5335s	
104/2700 (epoch 1.926), train_loss = 3.25328091, grad/param norm = 2.2965e-01, time/batch = 0.5529s	
105/2700 (epoch 1.944), train_loss = 3.26201015, grad/param norm = 2.0880e-01, time/batch = 0.5474s	
106/2700 (epoch 1.963), train_loss = 3.34081436, grad/param norm = 1.9706e-01, time/batch = 0.5728s	
107/2700 (epoch 1.981), train_loss = 3.39990106, grad/param norm = 1.9153e-01, time/batch = 0.5391s	
108/2700 (epoch 2.000), train_loss = 3.30027225, grad/param norm = 2.0229e-01, time/batch = 0.5410s	
109/2700 (epoch 2.019), train_loss = 3.24074218, grad/param norm = 2.4678e-01, time/batch = 0.5454s	
110/2700 (epoch 2.037), train_loss = 3.25749969, grad/param norm = 2.1235e-01, time/batch = 0.5632s	
111/2700 (epoch 2.056), train_loss = 3.25872257, grad/param norm = 1.5023e-01, time/batch = 0.5650s	
112/2700 (epoch 2.074), train_loss = 3.29057371, grad/param norm = 2.1542e-01, time/batch = 0.5446s	
113/2700 (epoch 2.093), train_loss = 3.29639222, grad/param norm = 2.5192e-01, time/batch = 0.5332s	
114/2700 (epoch 2.111), train_loss = 3.26724266, grad/param norm = 2.1608e-01, time/batch = 0.5877s	
115/2700 (epoch 2.130), train_loss = 3.28071269, grad/param norm = 1.7213e-01, time/batch = 0.5691s	
116/2700 (epoch 2.148), train_loss = 3.24475477, grad/param norm = 1.8351e-01, time/batch = 0.5345s	
117/2700 (epoch 2.167), train_loss = 3.25526558, grad/param norm = 2.3966e-01, time/batch = 0.5339s	
118/2700 (epoch 2.185), train_loss = 3.23964767, grad/param norm = 1.6968e-01, time/batch = 0.5425s	
119/2700 (epoch 2.204), train_loss = 3.17609653, grad/param norm = 2.0272e-01, time/batch = 0.5728s	
120/2700 (epoch 2.222), train_loss = 3.15254046, grad/param norm = 2.7182e-01, time/batch = 0.5393s	
121/2700 (epoch 2.241), train_loss = 3.17101461, grad/param norm = 2.2097e-01, time/batch = 0.5451s	
122/2700 (epoch 2.259), train_loss = 3.20422296, grad/param norm = 2.1751e-01, time/batch = 0.5394s	
123/2700 (epoch 2.278), train_loss = 3.27794321, grad/param norm = 2.2598e-01, time/batch = 0.5624s	
124/2700 (epoch 2.296), train_loss = 3.28089783, grad/param norm = 2.4652e-01, time/batch = 0.5730s	
125/2700 (epoch 2.315), train_loss = 3.25727376, grad/param norm = 2.3952e-01, time/batch = 0.5581s	
126/2700 (epoch 2.333), train_loss = 3.33788597, grad/param norm = 2.2557e-01, time/batch = 0.5368s	
127/2700 (epoch 2.352), train_loss = 3.34251901, grad/param norm = 2.3576e-01, time/batch = 0.5429s	
128/2700 (epoch 2.370), train_loss = 3.28527469, grad/param norm = 1.8571e-01, time/batch = 0.5954s	
129/2700 (epoch 2.389), train_loss = 3.25218488, grad/param norm = 1.3665e-01, time/batch = 0.5576s	
130/2700 (epoch 2.407), train_loss = 3.27392175, grad/param norm = 1.4230e-01, time/batch = 0.5809s	
131/2700 (epoch 2.426), train_loss = 3.27709465, grad/param norm = 1.5855e-01, time/batch = 0.5621s	
132/2700 (epoch 2.444), train_loss = 3.20697213, grad/param norm = 1.3685e-01, time/batch = 0.5609s	
133/2700 (epoch 2.463), train_loss = 3.24854867, grad/param norm = 1.6887e-01, time/batch = 0.5538s	
134/2700 (epoch 2.481), train_loss = 3.32534287, grad/param norm = 1.6666e-01, time/batch = 0.5422s	
135/2700 (epoch 2.500), train_loss = 3.37070195, grad/param norm = 2.4635e-01, time/batch = 0.5397s	
136/2700 (epoch 2.519), train_loss = 3.32491904, grad/param norm = 2.3168e-01, time/batch = 0.5916s	
137/2700 (epoch 2.537), train_loss = 3.32759303, grad/param norm = 2.4980e-01, time/batch = 0.5619s	
138/2700 (epoch 2.556), train_loss = 3.26352945, grad/param norm = 1.9974e-01, time/batch = 0.5625s	
139/2700 (epoch 2.574), train_loss = 3.23155427, grad/param norm = 1.9059e-01, time/batch = 0.5430s	
140/2700 (epoch 2.593), train_loss = 3.23139863, grad/param norm = 2.3138e-01, time/batch = 0.5497s	
141/2700 (epoch 2.611), train_loss = 3.17105428, grad/param norm = 1.4846e-01, time/batch = 0.5629s	
142/2700 (epoch 2.630), train_loss = 3.21222861, grad/param norm = 1.7471e-01, time/batch = 0.5466s	
143/2700 (epoch 2.648), train_loss = 3.28122616, grad/param norm = 1.7650e-01, time/batch = 0.5387s	
144/2700 (epoch 2.667), train_loss = 3.21335159, grad/param norm = 1.4205e-01, time/batch = 0.5367s	
145/2700 (epoch 2.685), train_loss = 3.21081708, grad/param norm = 1.6143e-01, time/batch = 0.5895s	
146/2700 (epoch 2.704), train_loss = 3.18316350, grad/param norm = 2.0804e-01, time/batch = 0.5846s	
147/2700 (epoch 2.722), train_loss = 3.17375600, grad/param norm = 1.4710e-01, time/batch = 0.5564s	
148/2700 (epoch 2.741), train_loss = 3.30877191, grad/param norm = 2.1983e-01, time/batch = 0.5374s	
149/2700 (epoch 2.759), train_loss = 3.25691886, grad/param norm = 2.5073e-01, time/batch = 0.5573s	
150/2700 (epoch 2.778), train_loss = 3.24756453, grad/param norm = 2.0850e-01, time/batch = 0.5836s	
151/2700 (epoch 2.796), train_loss = 3.24057935, grad/param norm = 2.0011e-01, time/batch = 0.5335s	
152/2700 (epoch 2.815), train_loss = 3.19279359, grad/param norm = 1.4655e-01, time/batch = 0.5543s	
153/2700 (epoch 2.833), train_loss = 3.23056365, grad/param norm = 1.5489e-01, time/batch = 0.5854s	
154/2700 (epoch 2.852), train_loss = 3.21799719, grad/param norm = 1.7478e-01, time/batch = 0.5494s	
155/2700 (epoch 2.870), train_loss = 3.21215868, grad/param norm = 1.3798e-01, time/batch = 0.5617s	
156/2700 (epoch 2.889), train_loss = 3.25144890, grad/param norm = 1.7275e-01, time/batch = 0.5359s	
157/2700 (epoch 2.907), train_loss = 3.30444893, grad/param norm = 2.4718e-01, time/batch = 0.5454s	
158/2700 (epoch 2.926), train_loss = 3.25413142, grad/param norm = 2.5207e-01, time/batch = 0.5748s	
159/2700 (epoch 2.944), train_loss = 3.26194533, grad/param norm = 2.2084e-01, time/batch = 0.5701s	
160/2700 (epoch 2.963), train_loss = 3.34091131, grad/param norm = 2.0122e-01, time/batch = 0.5292s	
161/2700 (epoch 2.981), train_loss = 3.40016112, grad/param norm = 1.9301e-01, time/batch = 0.5671s	
162/2700 (epoch 3.000), train_loss = 3.29983596, grad/param norm = 2.0550e-01, time/batch = 0.5761s	
163/2700 (epoch 3.019), train_loss = 3.24052057, grad/param norm = 2.4362e-01, time/batch = 0.5596s	
164/2700 (epoch 3.037), train_loss = 3.25682179, grad/param norm = 1.9902e-01, time/batch = 0.5356s	
165/2700 (epoch 3.056), train_loss = 3.25863296, grad/param norm = 1.4614e-01, time/batch = 0.5371s	
166/2700 (epoch 3.074), train_loss = 3.28986866, grad/param norm = 2.1011e-01, time/batch = 0.5537s	
167/2700 (epoch 3.093), train_loss = 3.29486356, grad/param norm = 2.3348e-01, time/batch = 0.5786s	
168/2700 (epoch 3.111), train_loss = 3.26547946, grad/param norm = 1.8797e-01, time/batch = 0.5541s	
169/2700 (epoch 3.130), train_loss = 3.27965642, grad/param norm = 1.5134e-01, time/batch = 0.5156s	
170/2700 (epoch 3.148), train_loss = 3.24426231, grad/param norm = 1.7123e-01, time/batch = 0.5309s	
171/2700 (epoch 3.167), train_loss = 3.25376056, grad/param norm = 2.1726e-01, time/batch = 0.5921s	
172/2700 (epoch 3.185), train_loss = 3.23818767, grad/param norm = 1.3780e-01, time/batch = 0.5551s	
173/2700 (epoch 3.204), train_loss = 3.17437305, grad/param norm = 1.6259e-01, time/batch = 0.5431s	
174/2700 (epoch 3.222), train_loss = 3.15066323, grad/param norm = 2.3475e-01, time/batch = 0.5348s	
175/2700 (epoch 3.241), train_loss = 3.16883935, grad/param norm = 1.6971e-01, time/batch = 0.5390s	
176/2700 (epoch 3.259), train_loss = 3.20227203, grad/param norm = 1.6327e-01, time/batch = 0.5661s	
177/2700 (epoch 3.278), train_loss = 3.27637168, grad/param norm = 1.8827e-01, time/batch = 0.5372s	
178/2700 (epoch 3.296), train_loss = 3.27949347, grad/param norm = 2.2111e-01, time/batch = 0.5448s	
179/2700 (epoch 3.315), train_loss = 3.25633517, grad/param norm = 2.2881e-01, time/batch = 0.5465s	
180/2700 (epoch 3.333), train_loss = 3.33759278, grad/param norm = 2.3114e-01, time/batch = 0.5403s	
181/2700 (epoch 3.352), train_loss = 3.34314724, grad/param norm = 2.4448e-01, time/batch = 0.5826s	
182/2700 (epoch 3.370), train_loss = 3.28553125, grad/param norm = 1.9109e-01, time/batch = 0.5575s	
183/2700 (epoch 3.389), train_loss = 3.25216716, grad/param norm = 1.3828e-01, time/batch = 0.5530s	
184/2700 (epoch 3.407), train_loss = 3.27372453, grad/param norm = 1.4015e-01, time/batch = 0.5388s	
185/2700 (epoch 3.426), train_loss = 3.27667096, grad/param norm = 1.5545e-01, time/batch = 0.5445s	
186/2700 (epoch 3.444), train_loss = 3.20661336, grad/param norm = 1.2896e-01, time/batch = 0.5767s	
187/2700 (epoch 3.463), train_loss = 3.24787871, grad/param norm = 1.5797e-01, time/batch = 0.5537s	
188/2700 (epoch 3.481), train_loss = 3.32511600, grad/param norm = 1.5827e-01, time/batch = 0.5412s	
189/2700 (epoch 3.500), train_loss = 3.36946490, grad/param norm = 2.3250e-01, time/batch = 0.5405s	
190/2700 (epoch 3.519), train_loss = 3.32355766, grad/param norm = 2.0905e-01, time/batch = 0.5382s	
191/2700 (epoch 3.537), train_loss = 3.32653682, grad/param norm = 2.2831e-01, time/batch = 0.5856s	
192/2700 (epoch 3.556), train_loss = 3.26251135, grad/param norm = 1.8410e-01, time/batch = 0.5556s	
193/2700 (epoch 3.574), train_loss = 3.23144544, grad/param norm = 1.8126e-01, time/batch = 0.5349s	
194/2700 (epoch 3.593), train_loss = 3.23077145, grad/param norm = 2.1940e-01, time/batch = 0.5532s	
195/2700 (epoch 3.611), train_loss = 3.17069782, grad/param norm = 1.4140e-01, time/batch = 0.5552s	
196/2700 (epoch 3.630), train_loss = 3.21204898, grad/param norm = 1.6965e-01, time/batch = 0.5628s	
197/2700 (epoch 3.648), train_loss = 3.28042448, grad/param norm = 1.7163e-01, time/batch = 0.5338s	
198/2700 (epoch 3.667), train_loss = 3.21280378, grad/param norm = 1.3548e-01, time/batch = 0.5430s	
199/2700 (epoch 3.685), train_loss = 3.21032167, grad/param norm = 1.5326e-01, time/batch = 0.5491s	
200/2700 (epoch 3.704), train_loss = 3.18256660, grad/param norm = 1.9934e-01, time/batch = 0.5692s	
201/2700 (epoch 3.722), train_loss = 3.17330773, grad/param norm = 1.3820e-01, time/batch = 0.5527s	
202/2700 (epoch 3.741), train_loss = 3.30806338, grad/param norm = 2.0921e-01, time/batch = 0.5376s	
203/2700 (epoch 3.759), train_loss = 3.25611661, grad/param norm = 2.3876e-01, time/batch = 0.5333s	
204/2700 (epoch 3.778), train_loss = 3.24711483, grad/param norm = 1.9926e-01, time/batch = 0.5751s	
205/2700 (epoch 3.796), train_loss = 3.23998807, grad/param norm = 1.9117e-01, time/batch = 0.5826s	
206/2700 (epoch 3.815), train_loss = 3.19239970, grad/param norm = 1.3930e-01, time/batch = 0.5338s	
207/2700 (epoch 3.833), train_loss = 3.23017883, grad/param norm = 1.4839e-01, time/batch = 0.5331s	
208/2700 (epoch 3.852), train_loss = 3.21726665, grad/param norm = 1.6389e-01, time/batch = 0.5425s	
209/2700 (epoch 3.870), train_loss = 3.21143075, grad/param norm = 1.2918e-01, time/batch = 0.5815s	
210/2700 (epoch 3.889), train_loss = 3.25127794, grad/param norm = 1.6860e-01, time/batch = 0.5552s	
211/2700 (epoch 3.907), train_loss = 3.30402536, grad/param norm = 2.3937e-01, time/batch = 0.5416s	
212/2700 (epoch 3.926), train_loss = 3.25299576, grad/param norm = 2.3461e-01, time/batch = 0.5444s	
213/2700 (epoch 3.944), train_loss = 3.26120450, grad/param norm = 1.9922e-01, time/batch = 0.5628s	
214/2700 (epoch 3.963), train_loss = 3.34032049, grad/param norm = 1.8136e-01, time/batch = 0.5748s	
215/2700 (epoch 3.981), train_loss = 3.40024284, grad/param norm = 1.8490e-01, time/batch = 0.5540s	
216/2700 (epoch 4.000), train_loss = 3.29953827, grad/param norm = 1.9439e-01, time/batch = 0.5442s	
217/2700 (epoch 4.019), train_loss = 3.23832292, grad/param norm = 2.2052e-01, time/batch = 0.5407s	
218/2700 (epoch 4.037), train_loss = 3.25582931, grad/param norm = 1.7940e-01, time/batch = 0.5762s	
219/2700 (epoch 4.056), train_loss = 3.25874860, grad/param norm = 1.4801e-01, time/batch = 0.5672s	
220/2700 (epoch 4.074), train_loss = 3.28973662, grad/param norm = 2.1018e-01, time/batch = 0.5716s	
221/2700 (epoch 4.093), train_loss = 3.29454100, grad/param norm = 2.2866e-01, time/batch = 0.5649s	
222/2700 (epoch 4.111), train_loss = 3.26483661, grad/param norm = 1.8033e-01, time/batch = 0.5629s	
223/2700 (epoch 4.130), train_loss = 3.27955340, grad/param norm = 1.4987e-01, time/batch = 0.5491s	
224/2700 (epoch 4.148), train_loss = 3.24400461, grad/param norm = 1.6497e-01, time/batch = 0.5382s	
225/2700 (epoch 4.167), train_loss = 3.25275984, grad/param norm = 2.0706e-01, time/batch = 0.5424s	
226/2700 (epoch 4.185), train_loss = 3.23769553, grad/param norm = 1.2833e-01, time/batch = 0.5742s	
227/2700 (epoch 4.204), train_loss = 3.17436704, grad/param norm = 1.5770e-01, time/batch = 0.5482s	
228/2700 (epoch 4.222), train_loss = 3.15026010, grad/param norm = 2.2438e-01, time/batch = 0.5845s	
229/2700 (epoch 4.241), train_loss = 3.16862617, grad/param norm = 1.6078e-01, time/batch = 0.5482s	
230/2700 (epoch 4.259), train_loss = 3.20173653, grad/param norm = 1.5239e-01, time/batch = 0.5377s	
231/2700 (epoch 4.278), train_loss = 3.27570977, grad/param norm = 1.7217e-01, time/batch = 0.5685s	
232/2700 (epoch 4.296), train_loss = 3.27820189, grad/param norm = 1.9554e-01, time/batch = 0.5507s	
233/2700 (epoch 4.315), train_loss = 3.25499402, grad/param norm = 1.9998e-01, time/batch = 0.5385s	
234/2700 (epoch 4.333), train_loss = 3.33652407, grad/param norm = 2.0802e-01, time/batch = 0.5268s	
235/2700 (epoch 4.352), train_loss = 3.34165308, grad/param norm = 2.3552e-01, time/batch = 0.5707s	
236/2700 (epoch 4.370), train_loss = 3.28430016, grad/param norm = 1.9802e-01, time/batch = 0.5775s	
237/2700 (epoch 4.389), train_loss = 3.25656629, grad/param norm = 1.9552e-01, time/batch = 0.5725s	
238/2700 (epoch 4.407), train_loss = 3.28092587, grad/param norm = 2.2981e-01, time/batch = 0.5356s	
239/2700 (epoch 4.426), train_loss = 3.27698736, grad/param norm = 1.6337e-01, time/batch = 0.5385s	
240/2700 (epoch 4.444), train_loss = 3.20470634, grad/param norm = 1.1290e-01, time/batch = 0.5830s	
241/2700 (epoch 4.463), train_loss = 3.24527942, grad/param norm = 1.4288e-01, time/batch = 0.5374s	
242/2700 (epoch 4.481), train_loss = 3.32147608, grad/param norm = 1.4633e-01, time/batch = 0.5283s	
243/2700 (epoch 4.500), train_loss = 3.36091540, grad/param norm = 2.0443e-01, time/batch = 0.5580s	
244/2700 (epoch 4.519), train_loss = 3.31287027, grad/param norm = 1.7369e-01, time/batch = 0.6030s	
245/2700 (epoch 4.537), train_loss = 3.31496628, grad/param norm = 2.3090e-01, time/batch = 0.5449s	
246/2700 (epoch 4.556), train_loss = 3.28177844, grad/param norm = 3.6557e-01, time/batch = 0.5455s	
247/2700 (epoch 4.574), train_loss = 3.22812496, grad/param norm = 2.6439e-01, time/batch = 0.5382s	
248/2700 (epoch 4.593), train_loss = 3.21180196, grad/param norm = 1.8407e-01, time/batch = 0.5572s	
249/2700 (epoch 4.611), train_loss = 3.14222513, grad/param norm = 2.7635e-01, time/batch = 0.5911s	
250/2700 (epoch 4.630), train_loss = 3.23652590, grad/param norm = 4.2726e-01, time/batch = 0.5539s	
251/2700 (epoch 4.648), train_loss = 3.25579357, grad/param norm = 3.3177e-01, time/batch = 0.5698s	
252/2700 (epoch 4.667), train_loss = 3.13547326, grad/param norm = 1.4805e-01, time/batch = 0.5675s	
253/2700 (epoch 4.685), train_loss = 3.46194826, grad/param norm = 9.5081e-01, time/batch = 0.5458s	
254/2700 (epoch 4.704), train_loss = 3.32413888, grad/param norm = 7.7467e-01, time/batch = 0.5483s	
255/2700 (epoch 4.722), train_loss = 3.14649651, grad/param norm = 1.8538e-01, time/batch = 0.5444s	
256/2700 (epoch 4.741), train_loss = 3.24573011, grad/param norm = 1.5182e-01, time/batch = 0.5570s	
257/2700 (epoch 4.759), train_loss = 3.16523984, grad/param norm = 1.6984e-01, time/batch = 0.5844s	
258/2700 (epoch 4.778), train_loss = 3.16325235, grad/param norm = 1.9522e-01, time/batch = 0.5614s	
259/2700 (epoch 4.796), train_loss = 3.14826549, grad/param norm = 1.8256e-01, time/batch = 0.5195s	
260/2700 (epoch 4.815), train_loss = 3.08253958, grad/param norm = 2.2560e-01, time/batch = 0.5335s	
261/2700 (epoch 4.833), train_loss = 3.12712329, grad/param norm = 2.9724e-01, time/batch = 0.6073s	
262/2700 (epoch 4.852), train_loss = 3.16282488, grad/param norm = 4.5245e-01, time/batch = 0.5493s	
263/2700 (epoch 4.870), train_loss = 3.12027781, grad/param norm = 3.9274e-01, time/batch = 0.5402s	
264/2700 (epoch 4.889), train_loss = 3.11238262, grad/param norm = 2.6479e-01, time/batch = 0.5356s	
265/2700 (epoch 4.907), train_loss = 3.15518853, grad/param norm = 1.7973e-01, time/batch = 0.5434s	
266/2700 (epoch 4.926), train_loss = 3.08804829, grad/param norm = 2.1344e-01, time/batch = 0.5775s	
267/2700 (epoch 4.944), train_loss = 3.10685592, grad/param norm = 2.1267e-01, time/batch = 0.5177s	
268/2700 (epoch 4.963), train_loss = 3.18755259, grad/param norm = 3.6600e-01, time/batch = 0.5475s	
269/2700 (epoch 4.981), train_loss = 3.19986328, grad/param norm = 2.6116e-01, time/batch = 0.5390s	
270/2700 (epoch 5.000), train_loss = 3.23506993, grad/param norm = 7.7251e-01, time/batch = 0.5412s	
271/2700 (epoch 5.019), train_loss = 3.34993594, grad/param norm = 8.7994e-01, time/batch = 0.6148s	
272/2700 (epoch 5.037), train_loss = 3.13096605, grad/param norm = 2.3261e-01, time/batch = 0.5576s	
273/2700 (epoch 5.056), train_loss = 3.08967013, grad/param norm = 1.4634e-01, time/batch = 0.5388s	
274/2700 (epoch 5.074), train_loss = 3.11700957, grad/param norm = 1.2825e-01, time/batch = 0.5380s	
275/2700 (epoch 5.093), train_loss = 3.11593379, grad/param norm = 1.3898e-01, time/batch = 0.5438s	
276/2700 (epoch 5.111), train_loss = 3.07662401, grad/param norm = 1.3049e-01, time/batch = 0.5701s	
277/2700 (epoch 5.130), train_loss = 3.08485593, grad/param norm = 1.3587e-01, time/batch = 0.5537s	
278/2700 (epoch 5.148), train_loss = 3.02734750, grad/param norm = 2.1639e-01, time/batch = 0.5372s	
279/2700 (epoch 5.167), train_loss = 3.07850404, grad/param norm = 4.3400e-01, time/batch = 0.5405s	
280/2700 (epoch 5.185), train_loss = 3.06602978, grad/param norm = 5.1530e-01, time/batch = 0.5686s	
281/2700 (epoch 5.204), train_loss = 3.02939379, grad/param norm = 4.9353e-01, time/batch = 0.5467s	
282/2700 (epoch 5.222), train_loss = 2.92406801, grad/param norm = 2.8213e-01, time/batch = 0.5549s	
283/2700 (epoch 5.241), train_loss = 2.91436691, grad/param norm = 1.8314e-01, time/batch = 0.5235s	
284/2700 (epoch 5.259), train_loss = 2.92851150, grad/param norm = 1.4971e-01, time/batch = 0.5442s	
285/2700 (epoch 5.278), train_loss = 3.01278317, grad/param norm = 2.4174e-01, time/batch = 0.5373s	
286/2700 (epoch 5.296), train_loss = 3.02980992, grad/param norm = 2.7358e-01, time/batch = 0.5768s	
287/2700 (epoch 5.315), train_loss = 3.04645828, grad/param norm = 4.1723e-01, time/batch = 0.5471s	
288/2700 (epoch 5.333), train_loss = 3.13779911, grad/param norm = 4.4393e-01, time/batch = 0.5408s	
289/2700 (epoch 5.352), train_loss = 3.07850017, grad/param norm = 2.6854e-01, time/batch = 0.5394s	
290/2700 (epoch 5.370), train_loss = 3.02709741, grad/param norm = 3.6783e-01, time/batch = 0.5641s	
291/2700 (epoch 5.389), train_loss = 3.04439260, grad/param norm = 5.0038e-01, time/batch = 0.5632s	
292/2700 (epoch 5.407), train_loss = 3.08422740, grad/param norm = 4.2656e-01, time/batch = 0.5359s	
293/2700 (epoch 5.426), train_loss = 3.02161375, grad/param norm = 2.6913e-01, time/batch = 0.5337s	
294/2700 (epoch 5.444), train_loss = 2.89397605, grad/param norm = 2.7529e-01, time/batch = 0.5458s	
295/2700 (epoch 5.463), train_loss = 2.99007058, grad/param norm = 3.8459e-01, time/batch = 0.5767s	
296/2700 (epoch 5.481), train_loss = 3.09454672, grad/param norm = 4.4361e-01, time/batch = 0.5526s	
297/2700 (epoch 5.500), train_loss = 3.07134291, grad/param norm = 3.5332e-01, time/batch = 0.5380s	
298/2700 (epoch 5.519), train_loss = 3.01310958, grad/param norm = 3.0956e-01, time/batch = 0.5363s	
299/2700 (epoch 5.537), train_loss = 2.99803403, grad/param norm = 2.2105e-01, time/batch = 0.5424s	
300/2700 (epoch 5.556), train_loss = 2.97117664, grad/param norm = 3.1312e-01, time/batch = 0.5902s	
301/2700 (epoch 5.574), train_loss = 2.95921381, grad/param norm = 3.2616e-01, time/batch = 0.5547s	
302/2700 (epoch 5.593), train_loss = 2.87507371, grad/param norm = 2.2112e-01, time/batch = 0.5401s	
303/2700 (epoch 5.611), train_loss = 2.79523658, grad/param norm = 1.7518e-01, time/batch = 0.5381s	
304/2700 (epoch 5.630), train_loss = 2.84433331, grad/param norm = 2.4370e-01, time/batch = 0.5526s	
305/2700 (epoch 5.648), train_loss = 2.91805971, grad/param norm = 4.6508e-01, time/batch = 0.5789s	
306/2700 (epoch 5.667), train_loss = 2.98349044, grad/param norm = 5.1510e-01, time/batch = 0.5557s	
307/2700 (epoch 5.685), train_loss = 2.93109423, grad/param norm = 4.1184e-01, time/batch = 0.5367s	
308/2700 (epoch 5.704), train_loss = 2.92047477, grad/param norm = 4.6030e-01, time/batch = 0.5242s	
309/2700 (epoch 5.722), train_loss = 2.79899749, grad/param norm = 2.2943e-01, time/batch = 0.5648s	
310/2700 (epoch 5.741), train_loss = 2.97297218, grad/param norm = 2.0091e-01, time/batch = 0.5630s	
311/2700 (epoch 5.759), train_loss = 2.89190098, grad/param norm = 1.9354e-01, time/batch = 0.5473s	
312/2700 (epoch 5.778), train_loss = 2.87392690, grad/param norm = 1.9970e-01, time/batch = 0.5332s	
313/2700 (epoch 5.796), train_loss = 2.85715390, grad/param norm = 2.4932e-01, time/batch = 0.5358s	
314/2700 (epoch 5.815), train_loss = 2.83218788, grad/param norm = 2.3615e-01, time/batch = 0.5980s	
315/2700 (epoch 5.833), train_loss = 2.82516893, grad/param norm = 2.4778e-01, time/batch = 0.5691s	
316/2700 (epoch 5.852), train_loss = 2.84057272, grad/param norm = 2.4292e-01, time/batch = 0.5291s	
317/2700 (epoch 5.870), train_loss = 2.78966125, grad/param norm = 2.0216e-01, time/batch = 0.5383s	
318/2700 (epoch 5.889), train_loss = 2.83731638, grad/param norm = 1.8652e-01, time/batch = 0.5376s	
319/2700 (epoch 5.907), train_loss = 2.92393828, grad/param norm = 2.9855e-01, time/batch = 0.5747s	
320/2700 (epoch 5.926), train_loss = 2.92872523, grad/param norm = 3.7687e-01, time/batch = 0.5500s	
321/2700 (epoch 5.944), train_loss = 2.92041514, grad/param norm = 3.1492e-01, time/batch = 0.5456s	
322/2700 (epoch 5.963), train_loss = 3.02436901, grad/param norm = 2.7327e-01, time/batch = 0.5419s	
323/2700 (epoch 5.981), train_loss = 3.01543953, grad/param norm = 3.0167e-01, time/batch = 0.5831s	
324/2700 (epoch 6.000), train_loss = 3.02219672, grad/param norm = 5.8696e-01, time/batch = 0.5558s	
325/2700 (epoch 6.019), train_loss = 3.09937889, grad/param norm = 6.1971e-01, time/batch = 0.5304s	
326/2700 (epoch 6.037), train_loss = 2.94261914, grad/param norm = 3.5830e-01, time/batch = 0.5401s	
327/2700 (epoch 6.056), train_loss = 2.87002615, grad/param norm = 2.2999e-01, time/batch = 0.5568s	
328/2700 (epoch 6.074), train_loss = 2.88643878, grad/param norm = 1.8247e-01, time/batch = 0.5723s	
329/2700 (epoch 6.093), train_loss = 2.89482231, grad/param norm = 2.4041e-01, time/batch = 0.5702s	
330/2700 (epoch 6.111), train_loss = 2.88301851, grad/param norm = 2.8732e-01, time/batch = 0.5614s	
331/2700 (epoch 6.130), train_loss = 2.87742764, grad/param norm = 2.6516e-01, time/batch = 0.5550s	
332/2700 (epoch 6.148), train_loss = 2.83942521, grad/param norm = 2.3719e-01, time/batch = 0.5664s	
333/2700 (epoch 6.167), train_loss = 2.81719970, grad/param norm = 1.9905e-01, time/batch = 0.5211s	
334/2700 (epoch 6.185), train_loss = 2.78707395, grad/param norm = 1.3146e-01, time/batch = 0.5531s	
335/2700 (epoch 6.204), train_loss = 2.72790650, grad/param norm = 2.6337e-01, time/batch = 0.5421s	
336/2700 (epoch 6.222), train_loss = 2.70137493, grad/param norm = 2.7541e-01, time/batch = 0.5708s	
337/2700 (epoch 6.241), train_loss = 2.72104408, grad/param norm = 3.3620e-01, time/batch = 0.5527s	
338/2700 (epoch 6.259), train_loss = 2.79934255, grad/param norm = 3.5217e-01, time/batch = 0.5586s	
339/2700 (epoch 6.278), train_loss = 2.87828881, grad/param norm = 3.3323e-01, time/batch = 0.5436s	
340/2700 (epoch 6.296), train_loss = 2.83479492, grad/param norm = 2.4367e-01, time/batch = 0.5326s	
341/2700 (epoch 6.315), train_loss = 2.82238884, grad/param norm = 2.7289e-01, time/batch = 0.5367s	
342/2700 (epoch 6.333), train_loss = 2.93340278, grad/param norm = 2.7489e-01, time/batch = 0.5649s	
343/2700 (epoch 6.352), train_loss = 2.90050697, grad/param norm = 2.1860e-01, time/batch = 0.5531s	
344/2700 (epoch 6.370), train_loss = 2.80932922, grad/param norm = 1.9912e-01, time/batch = 0.5392s	
345/2700 (epoch 6.389), train_loss = 2.75130746, grad/param norm = 1.5663e-01, time/batch = 0.5677s	
346/2700 (epoch 6.407), train_loss = 2.79110392, grad/param norm = 2.2488e-01, time/batch = 0.5592s	
347/2700 (epoch 6.426), train_loss = 2.83257758, grad/param norm = 2.0132e-01, time/batch = 0.5494s	
348/2700 (epoch 6.444), train_loss = 2.72370191, grad/param norm = 2.5284e-01, time/batch = 0.5555s	
349/2700 (epoch 6.463), train_loss = 2.81994036, grad/param norm = 4.5230e-01, time/batch = 0.5239s	
350/2700 (epoch 6.481), train_loss = 3.04546659, grad/param norm = 4.8697e-01, time/batch = 0.5568s	
351/2700 (epoch 6.500), train_loss = 2.93690183, grad/param norm = 3.3543e-01, time/batch = 0.5635s	
352/2700 (epoch 6.519), train_loss = 2.88359086, grad/param norm = 3.3741e-01, time/batch = 0.5368s	
353/2700 (epoch 6.537), train_loss = 3.06805205, grad/param norm = 1.0333e+00, time/batch = 0.5415s	
354/2700 (epoch 6.556), train_loss = 3.13780800, grad/param norm = 5.2026e-01, time/batch = 0.5480s	
355/2700 (epoch 6.574), train_loss = 2.82286091, grad/param norm = 2.1563e-01, time/batch = 0.6159s	
356/2700 (epoch 6.593), train_loss = 2.76920808, grad/param norm = 2.1464e-01, time/batch = 0.5644s	
357/2700 (epoch 6.611), train_loss = 2.68262741, grad/param norm = 2.0116e-01, time/batch = 0.5388s	
358/2700 (epoch 6.630), train_loss = 2.72539419, grad/param norm = 1.9859e-01, time/batch = 0.5351s	
359/2700 (epoch 6.648), train_loss = 2.75347428, grad/param norm = 1.6085e-01, time/batch = 0.5442s	
360/2700 (epoch 6.667), train_loss = 2.69301976, grad/param norm = 1.5824e-01, time/batch = 0.5804s	
361/2700 (epoch 6.685), train_loss = 2.71424437, grad/param norm = 1.9716e-01, time/batch = 0.5409s	
362/2700 (epoch 6.704), train_loss = 2.70622318, grad/param norm = 3.1611e-01, time/batch = 0.5545s	
363/2700 (epoch 6.722), train_loss = 2.74215198, grad/param norm = 3.7116e-01, time/batch = 0.5956s	
364/2700 (epoch 6.741), train_loss = 2.90683750, grad/param norm = 3.0663e-01, time/batch = 0.5509s	
365/2700 (epoch 6.759), train_loss = 2.79342111, grad/param norm = 1.8538e-01, time/batch = 0.5456s	
366/2700 (epoch 6.778), train_loss = 2.75192971, grad/param norm = 1.4626e-01, time/batch = 0.5372s	
367/2700 (epoch 6.796), train_loss = 2.72150195, grad/param norm = 1.6638e-01, time/batch = 0.5189s	
368/2700 (epoch 6.815), train_loss = 2.69851359, grad/param norm = 1.4297e-01, time/batch = 0.5688s	
369/2700 (epoch 6.833), train_loss = 2.69802637, grad/param norm = 1.5488e-01, time/batch = 0.5754s	
370/2700 (epoch 6.852), train_loss = 2.72763635, grad/param norm = 2.4451e-01, time/batch = 0.5517s	
371/2700 (epoch 6.870), train_loss = 2.76042788, grad/param norm = 4.7123e-01, time/batch = 0.6045s	
372/2700 (epoch 6.889), train_loss = 2.91059126, grad/param norm = 5.6243e-01, time/batch = 0.5849s	
373/2700 (epoch 6.907), train_loss = 2.84431271, grad/param norm = 3.3621e-01, time/batch = 0.5411s	
374/2700 (epoch 6.926), train_loss = 2.76329102, grad/param norm = 2.6107e-01, time/batch = 0.5361s	
375/2700 (epoch 6.944), train_loss = 2.80996952, grad/param norm = 2.2186e-01, time/batch = 0.5254s	
376/2700 (epoch 6.963), train_loss = 2.86871771, grad/param norm = 2.9722e-01, time/batch = 0.5519s	
377/2700 (epoch 6.981), train_loss = 2.95533302, grad/param norm = 4.6848e-01, time/batch = 0.5794s	
378/2700 (epoch 7.000), train_loss = 3.78408855, grad/param norm = 1.6310e+00, time/batch = 0.5526s	
379/2700 (epoch 7.019), train_loss = 3.03314952, grad/param norm = 4.2781e-01, time/batch = 0.5406s	
380/2700 (epoch 7.037), train_loss = 2.91517262, grad/param norm = 3.8332e-01, time/batch = 0.5437s	
381/2700 (epoch 7.056), train_loss = 2.79276258, grad/param norm = 1.4494e-01, time/batch = 0.5862s	
382/2700 (epoch 7.074), train_loss = 2.81608758, grad/param norm = 1.6434e-01, time/batch = 0.5352s	
383/2700 (epoch 7.093), train_loss = 2.80619207, grad/param norm = 1.4662e-01, time/batch = 0.5562s	
384/2700 (epoch 7.111), train_loss = 2.76646896, grad/param norm = 1.6880e-01, time/batch = 0.5374s	
385/2700 (epoch 7.130), train_loss = 2.77418009, grad/param norm = 1.6607e-01, time/batch = 0.5436s	
386/2700 (epoch 7.148), train_loss = 2.73203195, grad/param norm = 2.3576e-01, time/batch = 0.5843s	
387/2700 (epoch 7.167), train_loss = 2.76385062, grad/param norm = 3.0396e-01, time/batch = 0.5621s	
388/2700 (epoch 7.185), train_loss = 2.75336557, grad/param norm = 3.6194e-01, time/batch = 0.5418s	
389/2700 (epoch 7.204), train_loss = 2.70116710, grad/param norm = 3.0150e-01, time/batch = 0.5438s	
390/2700 (epoch 7.222), train_loss = 2.65081552, grad/param norm = 3.0596e-01, time/batch = 0.6046s	
391/2700 (epoch 7.241), train_loss = 2.63735762, grad/param norm = 2.1754e-01, time/batch = 0.5461s	
392/2700 (epoch 7.259), train_loss = 2.66139416, grad/param norm = 1.9912e-01, time/batch = 0.5517s	
393/2700 (epoch 7.278), train_loss = 2.72063543, grad/param norm = 1.5011e-01, time/batch = 0.5382s	
394/2700 (epoch 7.296), train_loss = 2.69338082, grad/param norm = 1.4161e-01, time/batch = 0.5525s	
395/2700 (epoch 7.315), train_loss = 2.71827632, grad/param norm = 1.4709e-01, time/batch = 0.5861s	
396/2700 (epoch 7.333), train_loss = 2.75098164, grad/param norm = 2.0426e-01, time/batch = 0.5603s	
397/2700 (epoch 7.352), train_loss = 2.79748312, grad/param norm = 2.2456e-01, time/batch = 0.5400s	
398/2700 (epoch 7.370), train_loss = 2.73377063, grad/param norm = 2.5943e-01, time/batch = 0.5250s	
399/2700 (epoch 7.389), train_loss = 2.71019912, grad/param norm = 3.6488e-01, time/batch = 0.5695s	
400/2700 (epoch 7.407), train_loss = 2.74024417, grad/param norm = 3.3919e-01, time/batch = 0.5869s	
401/2700 (epoch 7.426), train_loss = 2.82448155, grad/param norm = 3.7634e-01, time/batch = 0.5351s	
402/2700 (epoch 7.444), train_loss = 2.70610075, grad/param norm = 3.4486e-01, time/batch = 0.5359s	
403/2700 (epoch 7.463), train_loss = 2.76029891, grad/param norm = 3.6039e-01, time/batch = 0.5371s	
404/2700 (epoch 7.481), train_loss = 2.80566664, grad/param norm = 3.5836e-01, time/batch = 0.5869s	
405/2700 (epoch 7.500), train_loss = 2.85095997, grad/param norm = 5.7777e-01, time/batch = 0.5531s	
406/2700 (epoch 7.519), train_loss = 2.96040762, grad/param norm = 4.3119e-01, time/batch = 0.5273s	
407/2700 (epoch 7.537), train_loss = 2.82068064, grad/param norm = 3.3216e-01, time/batch = 0.5399s	
408/2700 (epoch 7.556), train_loss = 2.73405360, grad/param norm = 1.8968e-01, time/batch = 0.5345s	
409/2700 (epoch 7.574), train_loss = 2.66204169, grad/param norm = 1.5268e-01, time/batch = 0.5851s	
410/2700 (epoch 7.593), train_loss = 2.64969982, grad/param norm = 1.6319e-01, time/batch = 0.5652s	
411/2700 (epoch 7.611), train_loss = 2.57752986, grad/param norm = 1.8506e-01, time/batch = 0.5375s	
412/2700 (epoch 7.630), train_loss = 2.66488570, grad/param norm = 2.7977e-01, time/batch = 0.5290s	
413/2700 (epoch 7.648), train_loss = 2.71009591, grad/param norm = 3.5890e-01, time/batch = 0.5762s	
414/2700 (epoch 7.667), train_loss = 2.69261005, grad/param norm = 3.6900e-01, time/batch = 0.5768s	
415/2700 (epoch 7.685), train_loss = 2.68315136, grad/param norm = 3.0975e-01, time/batch = 0.5323s	
416/2700 (epoch 7.704), train_loss = 2.64204323, grad/param norm = 2.2918e-01, time/batch = 0.5365s	
417/2700 (epoch 7.722), train_loss = 2.60330343, grad/param norm = 1.1827e-01, time/batch = 0.5529s	
418/2700 (epoch 7.741), train_loss = 2.73895268, grad/param norm = 1.2665e-01, time/batch = 0.5911s	
419/2700 (epoch 7.759), train_loss = 2.69621279, grad/param norm = 2.1852e-01, time/batch = 0.5556s	
420/2700 (epoch 7.778), train_loss = 2.72697248, grad/param norm = 2.9829e-01, time/batch = 0.5519s	
421/2700 (epoch 7.796), train_loss = 2.68875800, grad/param norm = 2.5815e-01, time/batch = 0.5593s	
422/2700 (epoch 7.815), train_loss = 2.65935554, grad/param norm = 1.9272e-01, time/batch = 0.5624s	
423/2700 (epoch 7.833), train_loss = 2.65595270, grad/param norm = 1.7509e-01, time/batch = 0.5260s	
424/2700 (epoch 7.852), train_loss = 2.65459693, grad/param norm = 1.8415e-01, time/batch = 0.5448s	
425/2700 (epoch 7.870), train_loss = 2.63203816, grad/param norm = 3.9231e-01, time/batch = 0.5462s	
426/2700 (epoch 7.889), train_loss = 2.74558856, grad/param norm = 4.0984e-01, time/batch = 0.5734s	
427/2700 (epoch 7.907), train_loss = 2.81994204, grad/param norm = 3.7457e-01, time/batch = 0.5749s	
428/2700 (epoch 7.926), train_loss = 2.70237014, grad/param norm = 2.7353e-01, time/batch = 0.5621s	
429/2700 (epoch 7.944), train_loss = 2.73130901, grad/param norm = 1.9914e-01, time/batch = 0.5473s	
430/2700 (epoch 7.963), train_loss = 2.79301620, grad/param norm = 2.5448e-01, time/batch = 0.5305s	
431/2700 (epoch 7.981), train_loss = 2.86854505, grad/param norm = 4.0289e-01, time/batch = 0.5405s	
432/2700 (epoch 8.000), train_loss = 3.03184031, grad/param norm = 1.0423e+00, time/batch = 0.5631s	
433/2700 (epoch 8.019), train_loss = 2.97442784, grad/param norm = 5.2668e-01, time/batch = 0.5418s	
434/2700 (epoch 8.037), train_loss = 2.80058603, grad/param norm = 3.1191e-01, time/batch = 0.5572s	
435/2700 (epoch 8.056), train_loss = 2.72301191, grad/param norm = 2.0099e-01, time/batch = 0.5764s	
436/2700 (epoch 8.074), train_loss = 2.73880258, grad/param norm = 1.4845e-01, time/batch = 0.5861s	
437/2700 (epoch 8.093), train_loss = 2.73316784, grad/param norm = 1.3382e-01, time/batch = 0.5420s	
438/2700 (epoch 8.111), train_loss = 2.69010718, grad/param norm = 1.7024e-01, time/batch = 0.5405s	
439/2700 (epoch 8.130), train_loss = 2.71606371, grad/param norm = 2.9944e-01, time/batch = 0.5175s	
440/2700 (epoch 8.148), train_loss = 2.70528720, grad/param norm = 3.5752e-01, time/batch = 0.5651s	
441/2700 (epoch 8.167), train_loss = 2.71988562, grad/param norm = 3.7549e-01, time/batch = 0.5548s	
442/2700 (epoch 8.185), train_loss = 2.69879726, grad/param norm = 3.3734e-01, time/batch = 0.5388s	
443/2700 (epoch 8.204), train_loss = 2.65679615, grad/param norm = 3.6965e-01, time/batch = 0.5566s	
444/2700 (epoch 8.222), train_loss = 2.61932142, grad/param norm = 3.2659e-01, time/batch = 0.5739s	
445/2700 (epoch 8.241), train_loss = 2.60133210, grad/param norm = 2.2450e-01, time/batch = 0.5657s	
446/2700 (epoch 8.259), train_loss = 2.60169642, grad/param norm = 1.5138e-01, time/batch = 0.5359s	
447/2700 (epoch 8.278), train_loss = 2.65291198, grad/param norm = 1.1298e-01, time/batch = 0.5325s	
448/2700 (epoch 8.296), train_loss = 2.62428171, grad/param norm = 1.1523e-01, time/batch = 0.5312s	
449/2700 (epoch 8.315), train_loss = 2.65740547, grad/param norm = 1.3117e-01, time/batch = 0.5304s	
450/2700 (epoch 8.333), train_loss = 2.67634038, grad/param norm = 1.8026e-01, time/batch = 0.5874s	
451/2700 (epoch 8.352), train_loss = 2.71307329, grad/param norm = 2.3823e-01, time/batch = 0.5472s	
452/2700 (epoch 8.370), train_loss = 2.70694790, grad/param norm = 4.3121e-01, time/batch = 0.5486s	
453/2700 (epoch 8.389), train_loss = 2.71175732, grad/param norm = 4.3673e-01, time/batch = 0.5723s	
454/2700 (epoch 8.407), train_loss = 2.66799340, grad/param norm = 2.2674e-01, time/batch = 0.5938s	
455/2700 (epoch 8.426), train_loss = 2.71429502, grad/param norm = 2.5612e-01, time/batch = 0.5369s	
456/2700 (epoch 8.444), train_loss = 2.60200487, grad/param norm = 2.3371e-01, time/batch = 0.5230s	
457/2700 (epoch 8.463), train_loss = 2.67060397, grad/param norm = 2.3911e-01, time/batch = 0.5269s	
458/2700 (epoch 8.481), train_loss = 2.70753260, grad/param norm = 3.0865e-01, time/batch = 0.5525s	
459/2700 (epoch 8.500), train_loss = 2.78721010, grad/param norm = 4.5347e-01, time/batch = 0.5763s	
460/2700 (epoch 8.519), train_loss = 2.83024395, grad/param norm = 5.1952e-01, time/batch = 0.5602s	
461/2700 (epoch 8.537), train_loss = 2.80092228, grad/param norm = 5.2684e-01, time/batch = 0.5450s	
462/2700 (epoch 8.556), train_loss = 2.77303188, grad/param norm = 3.8085e-01, time/batch = 0.5622s	
463/2700 (epoch 8.574), train_loss = 2.64692038, grad/param norm = 2.3603e-01, time/batch = 0.5760s	
464/2700 (epoch 8.593), train_loss = 2.60792548, grad/param norm = 1.6576e-01, time/batch = 0.5239s	
465/2700 (epoch 8.611), train_loss = 2.52822726, grad/param norm = 1.5179e-01, time/batch = 0.5620s	
466/2700 (epoch 8.630), train_loss = 2.57914406, grad/param norm = 1.7583e-01, time/batch = 0.5300s	
467/2700 (epoch 8.648), train_loss = 2.61320002, grad/param norm = 2.4292e-01, time/batch = 0.5584s	
468/2700 (epoch 8.667), train_loss = 2.59972507, grad/param norm = 3.3771e-01, time/batch = 0.5728s	
469/2700 (epoch 8.685), train_loss = 2.66354543, grad/param norm = 4.6912e-01, time/batch = 0.5498s	
470/2700 (epoch 8.704), train_loss = 2.68950681, grad/param norm = 3.7941e-01, time/batch = 0.5552s	
471/2700 (epoch 8.722), train_loss = 2.58429736, grad/param norm = 1.8304e-01, time/batch = 0.5706s	
472/2700 (epoch 8.741), train_loss = 2.68199569, grad/param norm = 1.6533e-01, time/batch = 0.5494s	
473/2700 (epoch 8.759), train_loss = 2.64806535, grad/param norm = 2.0982e-01, time/batch = 0.5649s	
474/2700 (epoch 8.778), train_loss = 2.65706841, grad/param norm = 2.4678e-01, time/batch = 0.5516s	
475/2700 (epoch 8.796), train_loss = 2.61952190, grad/param norm = 2.1953e-01, time/batch = 0.5444s	
476/2700 (epoch 8.815), train_loss = 2.60773805, grad/param norm = 1.7285e-01, time/batch = 0.5868s	
477/2700 (epoch 8.833), train_loss = 2.60246736, grad/param norm = 1.4750e-01, time/batch = 0.5603s	
478/2700 (epoch 8.852), train_loss = 2.59490239, grad/param norm = 1.4048e-01, time/batch = 0.5402s	
479/2700 (epoch 8.870), train_loss = 2.55826480, grad/param norm = 1.5526e-01, time/batch = 0.5511s	
480/2700 (epoch 8.889), train_loss = 2.58074805, grad/param norm = 2.3058e-01, time/batch = 0.5820s	
481/2700 (epoch 8.907), train_loss = 2.70555725, grad/param norm = 4.3841e-01, time/batch = 0.5492s	
482/2700 (epoch 8.926), train_loss = 2.72451782, grad/param norm = 5.2418e-01, time/batch = 0.5437s	
483/2700 (epoch 8.944), train_loss = 2.75691303, grad/param norm = 3.5784e-01, time/batch = 0.5371s	
484/2700 (epoch 8.963), train_loss = 2.73760946, grad/param norm = 2.9611e-01, time/batch = 0.5466s	
485/2700 (epoch 8.981), train_loss = 2.73366236, grad/param norm = 5.5462e-01, time/batch = 0.5843s	
486/2700 (epoch 9.000), train_loss = 2.88135193, grad/param norm = 4.0374e-01, time/batch = 0.5709s	
487/2700 (epoch 9.019), train_loss = 2.69034608, grad/param norm = 3.1800e-01, time/batch = 0.5372s	
488/2700 (epoch 9.037), train_loss = 2.67605255, grad/param norm = 2.2066e-01, time/batch = 0.5352s	
489/2700 (epoch 9.056), train_loss = 2.62998663, grad/param norm = 1.4409e-01, time/batch = 0.5646s	
490/2700 (epoch 9.074), train_loss = 2.62053898, grad/param norm = 1.7629e-01, time/batch = 0.5666s	
491/2700 (epoch 9.093), train_loss = 2.68166268, grad/param norm = 3.2927e-01, time/batch = 0.5336s	
492/2700 (epoch 9.111), train_loss = 2.68017695, grad/param norm = 3.1128e-01, time/batch = 0.5365s	
493/2700 (epoch 9.130), train_loss = 2.64227373, grad/param norm = 2.0789e-01, time/batch = 0.5384s	
494/2700 (epoch 9.148), train_loss = 2.59760577, grad/param norm = 1.8621e-01, time/batch = 0.5918s	
495/2700 (epoch 9.167), train_loss = 2.60780252, grad/param norm = 1.7807e-01, time/batch = 0.5649s	
496/2700 (epoch 9.185), train_loss = 2.57579412, grad/param norm = 1.8374e-01, time/batch = 0.5244s	
497/2700 (epoch 9.204), train_loss = 2.56408971, grad/param norm = 2.1642e-01, time/batch = 0.5457s	
498/2700 (epoch 9.222), train_loss = 2.54648548, grad/param norm = 3.5236e-01, time/batch = 0.5636s	
499/2700 (epoch 9.241), train_loss = 2.62458951, grad/param norm = 5.6428e-01, time/batch = 0.5836s	
500/2700 (epoch 9.259), train_loss = 2.73190670, grad/param norm = 5.5146e-01, time/batch = 0.5402s	
501/2700 (epoch 9.278), train_loss = 2.65403060, grad/param norm = 2.8255e-01, time/batch = 0.5382s	
502/2700 (epoch 9.296), train_loss = 2.57731895, grad/param norm = 1.9100e-01, time/batch = 0.5673s	
503/2700 (epoch 9.315), train_loss = 2.60578325, grad/param norm = 1.8101e-01, time/batch = 0.5678s	
504/2700 (epoch 9.333), train_loss = 2.62346110, grad/param norm = 2.0934e-01, time/batch = 0.5432s	
505/2700 (epoch 9.352), train_loss = 2.66539868, grad/param norm = 2.7276e-01, time/batch = 0.5383s	
506/2700 (epoch 9.370), train_loss = 2.66707116, grad/param norm = 4.8806e-01, time/batch = 0.5403s	
507/2700 (epoch 9.389), train_loss = 2.68736149, grad/param norm = 3.7504e-01, time/batch = 0.5978s	
508/2700 (epoch 9.407), train_loss = 2.62010522, grad/param norm = 2.1506e-01, time/batch = 0.5752s	
509/2700 (epoch 9.426), train_loss = 2.63568683, grad/param norm = 2.2537e-01, time/batch = 0.5574s	
510/2700 (epoch 9.444), train_loss = 2.53027327, grad/param norm = 2.4077e-01, time/batch = 0.5352s	
511/2700 (epoch 9.463), train_loss = 2.61411337, grad/param norm = 1.9897e-01, time/batch = 0.5718s	
512/2700 (epoch 9.481), train_loss = 2.59719026, grad/param norm = 1.6142e-01, time/batch = 0.5632s	
513/2700 (epoch 9.500), train_loss = 2.60250378, grad/param norm = 1.9458e-01, time/batch = 0.5187s	
514/2700 (epoch 9.519), train_loss = 2.59860834, grad/param norm = 2.4628e-01, time/batch = 0.5315s	
515/2700 (epoch 9.537), train_loss = 2.60943631, grad/param norm = 3.6730e-01, time/batch = 0.5535s	
516/2700 (epoch 9.556), train_loss = 2.66112557, grad/param norm = 4.9314e-01, time/batch = 0.5871s	
517/2700 (epoch 9.574), train_loss = 2.66176559, grad/param norm = 4.2960e-01, time/batch = 0.5677s	
518/2700 (epoch 9.593), train_loss = 2.62233218, grad/param norm = 2.9192e-01, time/batch = 0.5461s	
519/2700 (epoch 9.611), train_loss = 2.52578794, grad/param norm = 2.4236e-01, time/batch = 0.5387s	
520/2700 (epoch 9.630), train_loss = 2.55486992, grad/param norm = 2.5155e-01, time/batch = 0.5339s	
521/2700 (epoch 9.648), train_loss = 2.58283999, grad/param norm = 2.5965e-01, time/batch = 0.5320s	
522/2700 (epoch 9.667), train_loss = 2.52981286, grad/param norm = 2.4252e-01, time/batch = 0.5651s	
523/2700 (epoch 9.685), train_loss = 2.55469844, grad/param norm = 2.0186e-01, time/batch = 0.5408s	
524/2700 (epoch 9.704), train_loss = 2.54295102, grad/param norm = 1.6522e-01, time/batch = 0.5474s	
525/2700 (epoch 9.722), train_loss = 2.50595932, grad/param norm = 1.4053e-01, time/batch = 0.6147s	
526/2700 (epoch 9.741), train_loss = 2.61237566, grad/param norm = 2.0989e-01, time/batch = 0.5561s	
527/2700 (epoch 9.759), train_loss = 2.63595951, grad/param norm = 4.3422e-01, time/batch = 0.5462s	
528/2700 (epoch 9.778), train_loss = 2.75391798, grad/param norm = 7.2923e-01, time/batch = 0.5360s	
529/2700 (epoch 9.796), train_loss = 2.84137761, grad/param norm = 5.2983e-01, time/batch = 0.5271s	
530/2700 (epoch 9.815), train_loss = 2.66677894, grad/param norm = 3.3122e-01, time/batch = 0.5798s	
531/2700 (epoch 9.833), train_loss = 2.59206411, grad/param norm = 2.1534e-01, time/batch = 0.5391s	
532/2700 (epoch 9.852), train_loss = 2.55965725, grad/param norm = 1.7309e-01, time/batch = 0.5386s	
533/2700 (epoch 9.870), train_loss = 2.53024638, grad/param norm = 1.7608e-01, time/batch = 0.5512s	
534/2700 (epoch 9.889), train_loss = 2.52543173, grad/param norm = 2.4244e-01, time/batch = 0.5839s	
535/2700 (epoch 9.907), train_loss = 2.63071922, grad/param norm = 2.5911e-01, time/batch = 0.5680s	
536/2700 (epoch 9.926), train_loss = 2.59203878, grad/param norm = 2.7103e-01, time/batch = 0.5504s	
537/2700 (epoch 9.944), train_loss = 2.62980480, grad/param norm = 3.6266e-01, time/batch = 0.5252s	
538/2700 (epoch 9.963), train_loss = 2.71704867, grad/param norm = 6.6886e-01, time/batch = 0.5405s	
539/2700 (epoch 9.981), train_loss = 2.89818105, grad/param norm = 4.7186e-01, time/batch = 0.5445s	
decayed learning rate by a factor 0.97 to 0.00194	
540/2700 (epoch 10.000), train_loss = 2.68559785, grad/param norm = 2.5322e-01, time/batch = 0.5774s	
541/2700 (epoch 10.019), train_loss = 2.61468902, grad/param norm = 1.8117e-01, time/batch = 0.5491s	
542/2700 (epoch 10.037), train_loss = 2.58539293, grad/param norm = 1.3111e-01, time/batch = 0.5721s	
543/2700 (epoch 10.056), train_loss = 2.55768999, grad/param norm = 1.5107e-01, time/batch = 0.6071s	
544/2700 (epoch 10.074), train_loss = 2.54983640, grad/param norm = 1.8955e-01, time/batch = 0.5472s	
545/2700 (epoch 10.093), train_loss = 2.58937940, grad/param norm = 2.0770e-01, time/batch = 0.5231s	
546/2700 (epoch 10.111), train_loss = 2.57068177, grad/param norm = 2.1002e-01, time/batch = 0.5442s	
547/2700 (epoch 10.130), train_loss = 2.58869015, grad/param norm = 2.1044e-01, time/batch = 0.5251s	
548/2700 (epoch 10.148), train_loss = 2.57362669, grad/param norm = 2.4648e-01, time/batch = 0.5842s	
549/2700 (epoch 10.167), train_loss = 2.56910586, grad/param norm = 2.4010e-01, time/batch = 0.5543s	
550/2700 (epoch 10.185), train_loss = 2.51819584, grad/param norm = 2.9978e-01, time/batch = 0.5342s	
551/2700 (epoch 10.204), train_loss = 2.54822314, grad/param norm = 4.1727e-01, time/batch = 0.6351s	
552/2700 (epoch 10.222), train_loss = 2.54986867, grad/param norm = 4.2444e-01, time/batch = 0.5501s	
553/2700 (epoch 10.241), train_loss = 2.47117988, grad/param norm = 2.9362e-01, time/batch = 0.5393s	
554/2700 (epoch 10.259), train_loss = 2.48817565, grad/param norm = 2.4138e-01, time/batch = 0.5359s	
555/2700 (epoch 10.278), train_loss = 2.51756754, grad/param norm = 1.8073e-01, time/batch = 0.5190s	
556/2700 (epoch 10.296), train_loss = 2.49821748, grad/param norm = 1.5578e-01, time/batch = 0.5498s	
557/2700 (epoch 10.315), train_loss = 2.53763103, grad/param norm = 1.8067e-01, time/batch = 0.5861s	
558/2700 (epoch 10.333), train_loss = 2.56438813, grad/param norm = 2.4567e-01, time/batch = 0.5665s	
559/2700 (epoch 10.352), train_loss = 2.59298989, grad/param norm = 3.0966e-01, time/batch = 0.5379s	
560/2700 (epoch 10.370), train_loss = 2.61064945, grad/param norm = 3.1315e-01, time/batch = 0.5413s	
561/2700 (epoch 10.389), train_loss = 2.54521807, grad/param norm = 3.1310e-01, time/batch = 0.5809s	
562/2700 (epoch 10.407), train_loss = 2.59649122, grad/param norm = 2.9830e-01, time/batch = 0.5301s	
563/2700 (epoch 10.426), train_loss = 2.58476017, grad/param norm = 2.2109e-01, time/batch = 0.5633s	
564/2700 (epoch 10.444), train_loss = 2.47566405, grad/param norm = 2.0042e-01, time/batch = 0.5382s	
565/2700 (epoch 10.463), train_loss = 2.54503114, grad/param norm = 2.8036e-01, time/batch = 0.5387s	
566/2700 (epoch 10.481), train_loss = 2.68019312, grad/param norm = 6.4925e-01, time/batch = 0.5789s	
567/2700 (epoch 10.500), train_loss = 2.93541793, grad/param norm = 1.2560e+00, time/batch = 0.5659s	
568/2700 (epoch 10.519), train_loss = 2.99363005, grad/param norm = 4.9024e-01, time/batch = 0.5382s	
569/2700 (epoch 10.537), train_loss = 2.67041574, grad/param norm = 3.0378e-01, time/batch = 0.5410s	
570/2700 (epoch 10.556), train_loss = 2.58165591, grad/param norm = 1.6757e-01, time/batch = 0.6000s	
571/2700 (epoch 10.574), train_loss = 2.53220805, grad/param norm = 1.8650e-01, time/batch = 0.5685s	
572/2700 (epoch 10.593), train_loss = 2.52671785, grad/param norm = 2.0735e-01, time/batch = 0.5392s	
573/2700 (epoch 10.611), train_loss = 2.45241709, grad/param norm = 2.6618e-01, time/batch = 0.5368s	
574/2700 (epoch 10.630), train_loss = 2.52429716, grad/param norm = 2.8248e-01, time/batch = 0.5483s	
575/2700 (epoch 10.648), train_loss = 2.51681461, grad/param norm = 3.2279e-01, time/batch = 0.5870s	
576/2700 (epoch 10.667), train_loss = 2.48438656, grad/param norm = 2.8993e-01, time/batch = 0.5635s	
577/2700 (epoch 10.685), train_loss = 2.50619879, grad/param norm = 2.8368e-01, time/batch = 0.5392s	
578/2700 (epoch 10.704), train_loss = 2.52595198, grad/param norm = 2.7098e-01, time/batch = 0.5289s	
579/2700 (epoch 10.722), train_loss = 2.45871844, grad/param norm = 2.0609e-01, time/batch = 0.5793s	
580/2700 (epoch 10.741), train_loss = 2.56007370, grad/param norm = 2.1448e-01, time/batch = 0.5760s	
581/2700 (epoch 10.759), train_loss = 2.56903303, grad/param norm = 2.8761e-01, time/batch = 0.5397s	
582/2700 (epoch 10.778), train_loss = 2.59204298, grad/param norm = 3.5214e-01, time/batch = 0.5399s	
583/2700 (epoch 10.796), train_loss = 2.53872507, grad/param norm = 3.0461e-01, time/batch = 0.5693s	
584/2700 (epoch 10.815), train_loss = 2.52579035, grad/param norm = 2.2171e-01, time/batch = 0.5535s	
585/2700 (epoch 10.833), train_loss = 2.49711346, grad/param norm = 1.7379e-01, time/batch = 0.5498s	
586/2700 (epoch 10.852), train_loss = 2.48600555, grad/param norm = 1.5237e-01, time/batch = 0.5233s	
587/2700 (epoch 10.870), train_loss = 2.46093099, grad/param norm = 2.0491e-01, time/batch = 0.5416s	
588/2700 (epoch 10.889), train_loss = 2.49556264, grad/param norm = 2.8943e-01, time/batch = 0.5452s	
589/2700 (epoch 10.907), train_loss = 2.64335158, grad/param norm = 4.9220e-01, time/batch = 0.5834s	
590/2700 (epoch 10.926), train_loss = 2.67395003, grad/param norm = 3.8623e-01, time/batch = 0.5528s	
591/2700 (epoch 10.944), train_loss = 2.57047732, grad/param norm = 1.8025e-01, time/batch = 0.5531s	
592/2700 (epoch 10.963), train_loss = 2.57720439, grad/param norm = 1.4573e-01, time/batch = 0.5728s	
593/2700 (epoch 10.981), train_loss = 2.51882648, grad/param norm = 1.5195e-01, time/batch = 0.5585s	
decayed learning rate by a factor 0.97 to 0.0018818	
594/2700 (epoch 11.000), train_loss = 2.53757370, grad/param norm = 1.4767e-01, time/batch = 0.5363s	
595/2700 (epoch 11.019), train_loss = 2.52955607, grad/param norm = 1.8545e-01, time/batch = 0.5364s	
596/2700 (epoch 11.037), train_loss = 2.52673054, grad/param norm = 2.0506e-01, time/batch = 0.5371s	
597/2700 (epoch 11.056), train_loss = 2.51488760, grad/param norm = 2.7794e-01, time/batch = 0.5842s	
598/2700 (epoch 11.074), train_loss = 2.51674881, grad/param norm = 3.3548e-01, time/batch = 0.5454s	
599/2700 (epoch 11.093), train_loss = 2.57105621, grad/param norm = 3.6276e-01, time/batch = 0.5732s	
600/2700 (epoch 11.111), train_loss = 2.53242739, grad/param norm = 3.8785e-01, time/batch = 0.5382s	
601/2700 (epoch 11.130), train_loss = 2.55873631, grad/param norm = 3.6500e-01, time/batch = 0.5692s	
602/2700 (epoch 11.148), train_loss = 2.49448919, grad/param norm = 3.1691e-01, time/batch = 0.5564s	
603/2700 (epoch 11.167), train_loss = 2.52143693, grad/param norm = 2.8071e-01, time/batch = 0.5243s	
604/2700 (epoch 11.185), train_loss = 2.46386356, grad/param norm = 2.9246e-01, time/batch = 0.5380s	
605/2700 (epoch 11.204), train_loss = 2.49939898, grad/param norm = 3.0256e-01, time/batch = 0.5583s	
606/2700 (epoch 11.222), train_loss = 2.43389848, grad/param norm = 2.7648e-01, time/batch = 0.5884s	
607/2700 (epoch 11.241), train_loss = 2.42834068, grad/param norm = 3.3343e-01, time/batch = 0.5651s	
608/2700 (epoch 11.259), train_loss = 2.45668889, grad/param norm = 4.1780e-01, time/batch = 0.5631s	
609/2700 (epoch 11.278), train_loss = 2.55859794, grad/param norm = 3.9548e-01, time/batch = 0.5431s	
610/2700 (epoch 11.296), train_loss = 2.49926097, grad/param norm = 3.0987e-01, time/batch = 0.5671s	
611/2700 (epoch 11.315), train_loss = 2.50211822, grad/param norm = 1.9943e-01, time/batch = 0.5226s	
612/2700 (epoch 11.333), train_loss = 2.49370509, grad/param norm = 1.3636e-01, time/batch = 0.5354s	
613/2700 (epoch 11.352), train_loss = 2.50437777, grad/param norm = 1.4839e-01, time/batch = 0.5393s	
614/2700 (epoch 11.370), train_loss = 2.49846950, grad/param norm = 1.6126e-01, time/batch = 0.5762s	
615/2700 (epoch 11.389), train_loss = 2.46476490, grad/param norm = 2.8793e-01, time/batch = 0.5688s	
616/2700 (epoch 11.407), train_loss = 2.59327546, grad/param norm = 5.1386e-01, time/batch = 0.5602s	
617/2700 (epoch 11.426), train_loss = 2.63856182, grad/param norm = 5.0431e-01, time/batch = 0.5375s	
618/2700 (epoch 11.444), train_loss = 2.48613600, grad/param norm = 3.5092e-01, time/batch = 0.5462s	
619/2700 (epoch 11.463), train_loss = 2.51543723, grad/param norm = 3.1514e-01, time/batch = 0.5373s	
620/2700 (epoch 11.481), train_loss = 2.53156466, grad/param norm = 3.1268e-01, time/batch = 0.5619s	
621/2700 (epoch 11.500), train_loss = 2.52541704, grad/param norm = 3.7506e-01, time/batch = 0.5417s	
622/2700 (epoch 11.519), train_loss = 2.56713417, grad/param norm = 4.2047e-01, time/batch = 0.5533s	
623/2700 (epoch 11.537), train_loss = 2.56028041, grad/param norm = 5.0677e-01, time/batch = 0.5847s	
624/2700 (epoch 11.556), train_loss = 2.61141619, grad/param norm = 3.8634e-01, time/batch = 0.5544s	
625/2700 (epoch 11.574), train_loss = 2.48625568, grad/param norm = 2.0781e-01, time/batch = 0.5502s	
626/2700 (epoch 11.593), train_loss = 2.45439113, grad/param norm = 1.6112e-01, time/batch = 0.5341s	
627/2700 (epoch 11.611), train_loss = 2.36874220, grad/param norm = 1.5277e-01, time/batch = 0.5346s	
628/2700 (epoch 11.630), train_loss = 2.40585552, grad/param norm = 1.3131e-01, time/batch = 0.5651s	
629/2700 (epoch 11.648), train_loss = 2.43894854, grad/param norm = 1.4961e-01, time/batch = 0.5653s	
630/2700 (epoch 11.667), train_loss = 2.40059489, grad/param norm = 2.0717e-01, time/batch = 0.5441s	
631/2700 (epoch 11.685), train_loss = 2.44186727, grad/param norm = 3.2513e-01, time/batch = 0.5607s	
632/2700 (epoch 11.704), train_loss = 2.49871480, grad/param norm = 4.3610e-01, time/batch = 0.5833s	
633/2700 (epoch 11.722), train_loss = 2.48429375, grad/param norm = 4.5930e-01, time/batch = 0.5461s	
634/2700 (epoch 11.741), train_loss = 2.56026768, grad/param norm = 4.6630e-01, time/batch = 0.5454s	
635/2700 (epoch 11.759), train_loss = 2.57058868, grad/param norm = 4.7905e-01, time/batch = 0.5276s	
636/2700 (epoch 11.778), train_loss = 2.61303662, grad/param norm = 4.7556e-01, time/batch = 0.5593s	
637/2700 (epoch 11.796), train_loss = 2.54258487, grad/param norm = 4.3519e-01, time/batch = 0.5240s	
638/2700 (epoch 11.815), train_loss = 2.51375662, grad/param norm = 2.3890e-01, time/batch = 0.5713s	
639/2700 (epoch 11.833), train_loss = 2.44234650, grad/param norm = 1.4677e-01, time/batch = 0.5544s	
640/2700 (epoch 11.852), train_loss = 2.43120893, grad/param norm = 1.6530e-01, time/batch = 0.5399s	
641/2700 (epoch 11.870), train_loss = 2.41381585, grad/param norm = 2.3233e-01, time/batch = 0.5754s	
642/2700 (epoch 11.889), train_loss = 2.43510627, grad/param norm = 4.4157e-01, time/batch = 0.5636s	
643/2700 (epoch 11.907), train_loss = 2.62190473, grad/param norm = 4.3747e-01, time/batch = 0.5431s	
644/2700 (epoch 11.926), train_loss = 2.51656856, grad/param norm = 3.2014e-01, time/batch = 0.5305s	
645/2700 (epoch 11.944), train_loss = 2.51575767, grad/param norm = 2.5954e-01, time/batch = 0.5346s	
646/2700 (epoch 11.963), train_loss = 2.53772796, grad/param norm = 1.9704e-01, time/batch = 0.5564s	
647/2700 (epoch 11.981), train_loss = 2.47739758, grad/param norm = 2.2325e-01, time/batch = 0.5736s	
decayed learning rate by a factor 0.97 to 0.001825346	
648/2700 (epoch 12.000), train_loss = 2.54275051, grad/param norm = 2.9188e-01, time/batch = 0.5591s	
649/2700 (epoch 12.019), train_loss = 2.52428056, grad/param norm = 2.6777e-01, time/batch = 0.5402s	
650/2700 (epoch 12.037), train_loss = 2.49168848, grad/param norm = 2.0336e-01, time/batch = 0.5483s	
651/2700 (epoch 12.056), train_loss = 2.46136884, grad/param norm = 1.9464e-01, time/batch = 0.5750s	
652/2700 (epoch 12.074), train_loss = 2.41838496, grad/param norm = 1.7840e-01, time/batch = 0.5254s	
653/2700 (epoch 12.093), train_loss = 2.44897198, grad/param norm = 2.0797e-01, time/batch = 0.5629s	
654/2700 (epoch 12.111), train_loss = 2.43661162, grad/param norm = 2.9053e-01, time/batch = 0.5368s	
655/2700 (epoch 12.130), train_loss = 2.51621391, grad/param norm = 4.9652e-01, time/batch = 0.5484s	
656/2700 (epoch 12.148), train_loss = 2.58610656, grad/param norm = 5.7780e-01, time/batch = 0.5843s	
657/2700 (epoch 12.167), train_loss = 2.55484099, grad/param norm = 4.0671e-01, time/batch = 0.5689s	
658/2700 (epoch 12.185), train_loss = 2.43032611, grad/param norm = 2.8247e-01, time/batch = 0.5416s	
659/2700 (epoch 12.204), train_loss = 2.42048242, grad/param norm = 2.5400e-01, time/batch = 0.5476s	
660/2700 (epoch 12.222), train_loss = 2.38965300, grad/param norm = 2.8909e-01, time/batch = 0.6019s	
661/2700 (epoch 12.241), train_loss = 2.38275188, grad/param norm = 3.7118e-01, time/batch = 0.5509s	
662/2700 (epoch 12.259), train_loss = 2.45482119, grad/param norm = 3.3971e-01, time/batch = 0.5438s	
663/2700 (epoch 12.278), train_loss = 2.46002943, grad/param norm = 2.3056e-01, time/batch = 0.5506s	
664/2700 (epoch 12.296), train_loss = 2.40802046, grad/param norm = 1.5172e-01, time/batch = 0.5704s	
665/2700 (epoch 12.315), train_loss = 2.41823366, grad/param norm = 1.0998e-01, time/batch = 0.5675s	
666/2700 (epoch 12.333), train_loss = 2.42755344, grad/param norm = 1.2330e-01, time/batch = 0.5402s	
667/2700 (epoch 12.352), train_loss = 2.43060874, grad/param norm = 1.2927e-01, time/batch = 0.5377s	
668/2700 (epoch 12.370), train_loss = 2.42966718, grad/param norm = 1.7502e-01, time/batch = 0.5744s	
669/2700 (epoch 12.389), train_loss = 2.40021237, grad/param norm = 2.3019e-01, time/batch = 0.5665s	
670/2700 (epoch 12.407), train_loss = 2.45383087, grad/param norm = 3.7844e-01, time/batch = 0.5564s	
671/2700 (epoch 12.426), train_loss = 2.54004727, grad/param norm = 4.4777e-01, time/batch = 0.5514s	
672/2700 (epoch 12.444), train_loss = 2.44562060, grad/param norm = 4.6593e-01, time/batch = 0.5619s	
673/2700 (epoch 12.463), train_loss = 2.51329961, grad/param norm = 4.9118e-01, time/batch = 0.5508s	
674/2700 (epoch 12.481), train_loss = 2.48665122, grad/param norm = 3.5460e-01, time/batch = 0.5616s	
675/2700 (epoch 12.500), train_loss = 2.43829206, grad/param norm = 2.3139e-01, time/batch = 0.5402s	
676/2700 (epoch 12.519), train_loss = 2.44046575, grad/param norm = 2.1791e-01, time/batch = 0.5539s	
677/2700 (epoch 12.537), train_loss = 2.44534984, grad/param norm = 2.5896e-01, time/batch = 0.5674s	
678/2700 (epoch 12.556), train_loss = 2.46369000, grad/param norm = 2.3144e-01, time/batch = 0.5552s	
679/2700 (epoch 12.574), train_loss = 2.40130971, grad/param norm = 2.0583e-01, time/batch = 0.5557s	
680/2700 (epoch 12.593), train_loss = 2.43228582, grad/param norm = 3.6807e-01, time/batch = 0.5477s	
681/2700 (epoch 12.611), train_loss = 2.50115970, grad/param norm = 7.2637e-01, time/batch = 0.5683s	
682/2700 (epoch 12.630), train_loss = 2.59430270, grad/param norm = 4.9687e-01, time/batch = 0.5554s	
683/2700 (epoch 12.648), train_loss = 2.44486840, grad/param norm = 2.3238e-01, time/batch = 0.5463s	
684/2700 (epoch 12.667), train_loss = 2.37613576, grad/param norm = 1.6742e-01, time/batch = 0.5251s	
685/2700 (epoch 12.685), train_loss = 2.37078438, grad/param norm = 1.6975e-01, time/batch = 0.5627s	
686/2700 (epoch 12.704), train_loss = 2.40534908, grad/param norm = 2.0611e-01, time/batch = 0.5606s	
687/2700 (epoch 12.722), train_loss = 2.36539663, grad/param norm = 2.0080e-01, time/batch = 0.5534s	
688/2700 (epoch 12.741), train_loss = 2.43533579, grad/param norm = 2.3158e-01, time/batch = 0.5602s	
689/2700 (epoch 12.759), train_loss = 2.45340481, grad/param norm = 3.0218e-01, time/batch = 0.5353s	
690/2700 (epoch 12.778), train_loss = 2.47088850, grad/param norm = 3.6368e-01, time/batch = 0.5481s	
691/2700 (epoch 12.796), train_loss = 2.42331503, grad/param norm = 3.5768e-01, time/batch = 0.5459s	
692/2700 (epoch 12.815), train_loss = 2.44025692, grad/param norm = 3.6699e-01, time/batch = 0.5582s	
693/2700 (epoch 12.833), train_loss = 2.42403982, grad/param norm = 3.4724e-01, time/batch = 0.5297s	
694/2700 (epoch 12.852), train_loss = 2.41419285, grad/param norm = 3.0166e-01, time/batch = 0.5335s	
695/2700 (epoch 12.870), train_loss = 2.37874838, grad/param norm = 2.5504e-01, time/batch = 0.5803s	
696/2700 (epoch 12.889), train_loss = 2.36080265, grad/param norm = 2.3339e-01, time/batch = 0.5793s	
697/2700 (epoch 12.907), train_loss = 2.47806493, grad/param norm = 2.5392e-01, time/batch = 0.5736s	
698/2700 (epoch 12.926), train_loss = 2.42660279, grad/param norm = 2.4340e-01, time/batch = 0.5369s	
699/2700 (epoch 12.944), train_loss = 2.43253067, grad/param norm = 1.8868e-01, time/batch = 0.5452s	
700/2700 (epoch 12.963), train_loss = 2.45748554, grad/param norm = 1.8206e-01, time/batch = 0.5664s	
701/2700 (epoch 12.981), train_loss = 2.39437262, grad/param norm = 2.1971e-01, time/batch = 0.5233s	
decayed learning rate by a factor 0.97 to 0.00177058562	
702/2700 (epoch 13.000), train_loss = 2.44951961, grad/param norm = 2.5700e-01, time/batch = 0.5333s	
703/2700 (epoch 13.019), train_loss = 2.46547367, grad/param norm = 4.4556e-01, time/batch = 0.5444s	
704/2700 (epoch 13.037), train_loss = 2.54625392, grad/param norm = 4.7328e-01, time/batch = 0.5903s	
705/2700 (epoch 13.056), train_loss = 2.47118229, grad/param norm = 4.4198e-01, time/batch = 0.5728s	
706/2700 (epoch 13.074), train_loss = 2.46815964, grad/param norm = 5.1502e-01, time/batch = 0.5398s	
707/2700 (epoch 13.093), train_loss = 2.54797230, grad/param norm = 5.6701e-01, time/batch = 0.5360s	
708/2700 (epoch 13.111), train_loss = 2.57009915, grad/param norm = 8.3000e-01, time/batch = 0.5397s	
709/2700 (epoch 13.130), train_loss = 2.66396403, grad/param norm = 5.0426e-01, time/batch = 0.5352s	
710/2700 (epoch 13.148), train_loss = 2.46804330, grad/param norm = 3.0207e-01, time/batch = 0.5723s	
711/2700 (epoch 13.167), train_loss = 2.42667194, grad/param norm = 2.2588e-01, time/batch = 0.5404s	
712/2700 (epoch 13.185), train_loss = 2.34439478, grad/param norm = 1.5517e-01, time/batch = 0.5568s	
713/2700 (epoch 13.204), train_loss = 2.34418773, grad/param norm = 1.3248e-01, time/batch = 0.5921s	
714/2700 (epoch 13.222), train_loss = 2.28451690, grad/param norm = 1.2689e-01, time/batch = 0.5480s	
715/2700 (epoch 13.241), train_loss = 2.25021583, grad/param norm = 1.4279e-01, time/batch = 0.5612s	
716/2700 (epoch 13.259), train_loss = 2.28973842, grad/param norm = 2.3238e-01, time/batch = 0.5364s	
717/2700 (epoch 13.278), train_loss = 2.37935459, grad/param norm = 3.8469e-01, time/batch = 0.5318s	
718/2700 (epoch 13.296), train_loss = 2.40591920, grad/param norm = 4.5645e-01, time/batch = 0.5549s	
719/2700 (epoch 13.315), train_loss = 2.44912941, grad/param norm = 4.3743e-01, time/batch = 0.5642s	
720/2700 (epoch 13.333), train_loss = 2.44225567, grad/param norm = 3.3843e-01, time/batch = 0.5514s	
721/2700 (epoch 13.352), train_loss = 2.40475138, grad/param norm = 2.3233e-01, time/batch = 0.5833s	
722/2700 (epoch 13.370), train_loss = 2.38721985, grad/param norm = 1.6798e-01, time/batch = 0.5829s	
723/2700 (epoch 13.389), train_loss = 2.33621115, grad/param norm = 1.6597e-01, time/batch = 0.5425s	
724/2700 (epoch 13.407), train_loss = 2.37523588, grad/param norm = 1.8628e-01, time/batch = 0.5427s	
725/2700 (epoch 13.426), train_loss = 2.37501155, grad/param norm = 1.1394e-01, time/batch = 0.5219s	
726/2700 (epoch 13.444), train_loss = 2.27789796, grad/param norm = 9.9606e-02, time/batch = 0.5630s	
727/2700 (epoch 13.463), train_loss = 2.33908177, grad/param norm = 1.3648e-01, time/batch = 0.5496s	
728/2700 (epoch 13.481), train_loss = 2.36695754, grad/param norm = 2.0141e-01, time/batch = 0.5637s	
729/2700 (epoch 13.500), train_loss = 2.38781046, grad/param norm = 2.8043e-01, time/batch = 0.5366s	
730/2700 (epoch 13.519), train_loss = 2.43418188, grad/param norm = 4.6552e-01, time/batch = 0.5416s	
731/2700 (epoch 13.537), train_loss = 2.49498313, grad/param norm = 5.5351e-01, time/batch = 0.5985s	
732/2700 (epoch 13.556), train_loss = 2.42888852, grad/param norm = 3.9367e-01, time/batch = 0.5499s	
733/2700 (epoch 13.574), train_loss = 2.37263070, grad/param norm = 3.1902e-01, time/batch = 0.5441s	
734/2700 (epoch 13.593), train_loss = 2.35601654, grad/param norm = 2.9233e-01, time/batch = 0.5308s	
735/2700 (epoch 13.611), train_loss = 2.27951262, grad/param norm = 3.0751e-01, time/batch = 0.5239s	
736/2700 (epoch 13.630), train_loss = 2.33695920, grad/param norm = 3.3127e-01, time/batch = 0.5469s	
737/2700 (epoch 13.648), train_loss = 2.39091586, grad/param norm = 4.3012e-01, time/batch = 0.5901s	
738/2700 (epoch 13.667), train_loss = 2.41305612, grad/param norm = 3.8162e-01, time/batch = 0.5553s	
739/2700 (epoch 13.685), train_loss = 2.34456774, grad/param norm = 2.8821e-01, time/batch = 0.5373s	
740/2700 (epoch 13.704), train_loss = 2.34880380, grad/param norm = 2.5219e-01, time/batch = 0.5401s	
741/2700 (epoch 13.722), train_loss = 2.30160712, grad/param norm = 1.6984e-01, time/batch = 0.5837s	
742/2700 (epoch 13.741), train_loss = 2.35391410, grad/param norm = 1.4199e-01, time/batch = 0.5567s	
743/2700 (epoch 13.759), train_loss = 2.38225537, grad/param norm = 2.7606e-01, time/batch = 0.5547s	
744/2700 (epoch 13.778), train_loss = 2.45297263, grad/param norm = 4.9343e-01, time/batch = 0.5403s	
745/2700 (epoch 13.796), train_loss = 2.47599391, grad/param norm = 5.8776e-01, time/batch = 0.5553s	
746/2700 (epoch 13.815), train_loss = 2.46718000, grad/param norm = 4.8676e-01, time/batch = 0.5812s	
747/2700 (epoch 13.833), train_loss = 2.37483364, grad/param norm = 3.1237e-01, time/batch = 0.5555s	
748/2700 (epoch 13.852), train_loss = 2.35224100, grad/param norm = 2.1384e-01, time/batch = 0.5404s	
749/2700 (epoch 13.870), train_loss = 2.30950245, grad/param norm = 1.4517e-01, time/batch = 0.5413s	
750/2700 (epoch 13.889), train_loss = 2.27475998, grad/param norm = 1.0699e-01, time/batch = 0.6034s	
751/2700 (epoch 13.907), train_loss = 2.39243191, grad/param norm = 1.6131e-01, time/batch = 0.5591s	
752/2700 (epoch 13.926), train_loss = 2.33436885, grad/param norm = 1.9876e-01, time/batch = 0.5393s	
753/2700 (epoch 13.944), train_loss = 2.36843482, grad/param norm = 1.9892e-01, time/batch = 0.5361s	
754/2700 (epoch 13.963), train_loss = 2.40373836, grad/param norm = 2.5593e-01, time/batch = 0.5522s	
755/2700 (epoch 13.981), train_loss = 2.35291687, grad/param norm = 3.8026e-01, time/batch = 0.5843s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
756/2700 (epoch 14.000), train_loss = 2.45351676, grad/param norm = 4.6907e-01, time/batch = 0.5542s	
757/2700 (epoch 14.019), train_loss = 2.48612454, grad/param norm = 6.1818e-01, time/batch = 0.5385s	
758/2700 (epoch 14.037), train_loss = 2.53586856, grad/param norm = 4.1403e-01, time/batch = 0.5252s	
759/2700 (epoch 14.056), train_loss = 2.38647612, grad/param norm = 2.0956e-01, time/batch = 0.5726s	
760/2700 (epoch 14.074), train_loss = 2.32269762, grad/param norm = 1.9070e-01, time/batch = 0.5493s	
761/2700 (epoch 14.093), train_loss = 2.34761701, grad/param norm = 1.7497e-01, time/batch = 0.5463s	
762/2700 (epoch 14.111), train_loss = 2.29507053, grad/param norm = 1.4855e-01, time/batch = 0.5367s	
763/2700 (epoch 14.130), train_loss = 2.33008783, grad/param norm = 1.8442e-01, time/batch = 0.5273s	
764/2700 (epoch 14.148), train_loss = 2.30154643, grad/param norm = 2.3507e-01, time/batch = 0.5792s	
765/2700 (epoch 14.167), train_loss = 2.33718388, grad/param norm = 2.7923e-01, time/batch = 0.5684s	
766/2700 (epoch 14.185), train_loss = 2.29871499, grad/param norm = 3.6778e-01, time/batch = 0.5318s	
767/2700 (epoch 14.204), train_loss = 2.33764520, grad/param norm = 3.2838e-01, time/batch = 0.5390s	
768/2700 (epoch 14.222), train_loss = 2.24948214, grad/param norm = 2.4664e-01, time/batch = 0.5348s	
769/2700 (epoch 14.241), train_loss = 2.21855578, grad/param norm = 2.8238e-01, time/batch = 0.5662s	
770/2700 (epoch 14.259), train_loss = 2.27304292, grad/param norm = 3.0013e-01, time/batch = 0.5905s	
771/2700 (epoch 14.278), train_loss = 2.33138606, grad/param norm = 2.4180e-01, time/batch = 0.5389s	
772/2700 (epoch 14.296), train_loss = 2.29996823, grad/param norm = 1.9330e-01, time/batch = 0.5272s	
773/2700 (epoch 14.315), train_loss = 2.31974249, grad/param norm = 1.8576e-01, time/batch = 0.5902s	
774/2700 (epoch 14.333), train_loss = 2.34063876, grad/param norm = 1.7981e-01, time/batch = 0.5679s	
775/2700 (epoch 14.352), train_loss = 2.32861084, grad/param norm = 1.6069e-01, time/batch = 0.5359s	
776/2700 (epoch 14.370), train_loss = 2.33497921, grad/param norm = 2.1577e-01, time/batch = 0.5287s	
777/2700 (epoch 14.389), train_loss = 2.31908348, grad/param norm = 4.1157e-01, time/batch = 0.5542s	
778/2700 (epoch 14.407), train_loss = 2.42258400, grad/param norm = 5.0079e-01, time/batch = 0.5856s	
779/2700 (epoch 14.426), train_loss = 2.38441556, grad/param norm = 3.5108e-01, time/batch = 0.5586s	
780/2700 (epoch 14.444), train_loss = 2.26656274, grad/param norm = 2.7272e-01, time/batch = 0.5643s	
781/2700 (epoch 14.463), train_loss = 2.32887579, grad/param norm = 3.1827e-01, time/batch = 0.5558s	
782/2700 (epoch 14.481), train_loss = 2.36008375, grad/param norm = 3.1352e-01, time/batch = 0.5611s	
783/2700 (epoch 14.500), train_loss = 2.31647871, grad/param norm = 3.2100e-01, time/batch = 0.5319s	
784/2700 (epoch 14.519), train_loss = 2.34055664, grad/param norm = 3.3338e-01, time/batch = 0.5387s	
785/2700 (epoch 14.537), train_loss = 2.31925045, grad/param norm = 3.5469e-01, time/batch = 0.5468s	
786/2700 (epoch 14.556), train_loss = 2.33185572, grad/param norm = 3.4106e-01, time/batch = 0.5719s	
787/2700 (epoch 14.574), train_loss = 2.28056324, grad/param norm = 2.6701e-01, time/batch = 0.5937s	
788/2700 (epoch 14.593), train_loss = 2.27718617, grad/param norm = 2.4834e-01, time/batch = 0.5682s	
789/2700 (epoch 14.611), train_loss = 2.19102246, grad/param norm = 2.3649e-01, time/batch = 0.5369s	
790/2700 (epoch 14.630), train_loss = 2.23731813, grad/param norm = 2.0825e-01, time/batch = 0.5338s	
791/2700 (epoch 14.648), train_loss = 2.26128984, grad/param norm = 1.9062e-01, time/batch = 0.5382s	
792/2700 (epoch 14.667), train_loss = 2.24489133, grad/param norm = 1.8964e-01, time/batch = 0.5629s	
793/2700 (epoch 14.685), train_loss = 2.25248803, grad/param norm = 2.9306e-01, time/batch = 0.5402s	
794/2700 (epoch 14.704), train_loss = 2.35439166, grad/param norm = 4.6812e-01, time/batch = 0.5510s	
795/2700 (epoch 14.722), train_loss = 2.44621336, grad/param norm = 6.3867e-01, time/batch = 0.5737s	
796/2700 (epoch 14.741), train_loss = 2.53979925, grad/param norm = 6.6378e-01, time/batch = 0.5667s	
797/2700 (epoch 14.759), train_loss = 2.50253586, grad/param norm = 4.2689e-01, time/batch = 0.5307s	
798/2700 (epoch 14.778), train_loss = 2.37844490, grad/param norm = 2.0769e-01, time/batch = 0.5401s	
799/2700 (epoch 14.796), train_loss = 2.27590589, grad/param norm = 1.3451e-01, time/batch = 0.5180s	
800/2700 (epoch 14.815), train_loss = 2.29034216, grad/param norm = 1.1792e-01, time/batch = 0.5611s	
801/2700 (epoch 14.833), train_loss = 2.26219991, grad/param norm = 1.2257e-01, time/batch = 0.5600s	
802/2700 (epoch 14.852), train_loss = 2.26407934, grad/param norm = 1.2488e-01, time/batch = 0.5527s	
803/2700 (epoch 14.870), train_loss = 2.24855292, grad/param norm = 1.6696e-01, time/batch = 0.5460s	
804/2700 (epoch 14.889), train_loss = 2.25262073, grad/param norm = 2.7888e-01, time/batch = 0.5637s	
805/2700 (epoch 14.907), train_loss = 2.42148895, grad/param norm = 4.4959e-01, time/batch = 0.5729s	
806/2700 (epoch 14.926), train_loss = 2.40002513, grad/param norm = 5.1172e-01, time/batch = 0.5748s	
807/2700 (epoch 14.944), train_loss = 2.37983359, grad/param norm = 3.6813e-01, time/batch = 0.5291s	
808/2700 (epoch 14.963), train_loss = 2.36853045, grad/param norm = 2.7120e-01, time/batch = 0.5233s	
809/2700 (epoch 14.981), train_loss = 2.27741493, grad/param norm = 2.2316e-01, time/batch = 0.5414s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
810/2700 (epoch 15.000), train_loss = 2.31981723, grad/param norm = 1.9962e-01, time/batch = 0.4942s	
811/2700 (epoch 15.019), train_loss = 2.31076610, grad/param norm = 2.0190e-01, time/batch = 0.5385s	
812/2700 (epoch 15.037), train_loss = 2.30352120, grad/param norm = 1.9832e-01, time/batch = 0.5558s	
813/2700 (epoch 15.056), train_loss = 2.27847875, grad/param norm = 2.0676e-01, time/batch = 0.5469s	
814/2700 (epoch 15.074), train_loss = 2.24051375, grad/param norm = 2.5509e-01, time/batch = 0.5566s	
815/2700 (epoch 15.093), train_loss = 2.28621485, grad/param norm = 3.4883e-01, time/batch = 0.5820s	
816/2700 (epoch 15.111), train_loss = 2.28365018, grad/param norm = 4.2660e-01, time/batch = 0.4989s	
817/2700 (epoch 15.130), train_loss = 2.33801936, grad/param norm = 4.4067e-01, time/batch = 0.4247s	
818/2700 (epoch 15.148), train_loss = 2.30040828, grad/param norm = 3.6694e-01, time/batch = 0.5385s	
819/2700 (epoch 15.167), train_loss = 2.30910826, grad/param norm = 2.8858e-01, time/batch = 0.5601s	
820/2700 (epoch 15.185), train_loss = 2.22731637, grad/param norm = 2.5342e-01, time/batch = 0.5850s	
821/2700 (epoch 15.204), train_loss = 2.23361086, grad/param norm = 2.0321e-01, time/batch = 0.5490s	
822/2700 (epoch 15.222), train_loss = 2.16791379, grad/param norm = 2.0866e-01, time/batch = 0.5691s	
823/2700 (epoch 15.241), train_loss = 2.13805392, grad/param norm = 2.5678e-01, time/batch = 0.6051s	
824/2700 (epoch 15.259), train_loss = 2.20710253, grad/param norm = 3.0601e-01, time/batch = 0.5341s	
825/2700 (epoch 15.278), train_loss = 2.27696634, grad/param norm = 3.5312e-01, time/batch = 0.5163s	
826/2700 (epoch 15.296), train_loss = 2.31182981, grad/param norm = 3.7891e-01, time/batch = 0.5246s	
827/2700 (epoch 15.315), train_loss = 2.36012506, grad/param norm = 4.1610e-01, time/batch = 0.5341s	
828/2700 (epoch 15.333), train_loss = 2.35581623, grad/param norm = 3.1471e-01, time/batch = 0.5726s	
829/2700 (epoch 15.352), train_loss = 2.29290899, grad/param norm = 1.7284e-01, time/batch = 0.5852s	
830/2700 (epoch 15.370), train_loss = 2.28528805, grad/param norm = 1.5164e-01, time/batch = 0.5459s	
831/2700 (epoch 15.389), train_loss = 2.23436987, grad/param norm = 1.7341e-01, time/batch = 0.5560s	
832/2700 (epoch 15.407), train_loss = 2.28985707, grad/param norm = 2.3327e-01, time/batch = 0.5951s	
833/2700 (epoch 15.426), train_loss = 2.30451152, grad/param norm = 2.8713e-01, time/batch = 0.5594s	
834/2700 (epoch 15.444), train_loss = 2.22319135, grad/param norm = 4.1155e-01, time/batch = 0.5357s	
835/2700 (epoch 15.463), train_loss = 2.33632891, grad/param norm = 5.1240e-01, time/batch = 0.5264s	
836/2700 (epoch 15.481), train_loss = 2.34852207, grad/param norm = 4.0514e-01, time/batch = 0.5581s	
837/2700 (epoch 15.500), train_loss = 2.27467807, grad/param norm = 2.1930e-01, time/batch = 0.5748s	
838/2700 (epoch 15.519), train_loss = 2.25606053, grad/param norm = 1.4935e-01, time/batch = 0.5587s	
839/2700 (epoch 15.537), train_loss = 2.23584836, grad/param norm = 1.4494e-01, time/batch = 0.5493s	
840/2700 (epoch 15.556), train_loss = 2.22694828, grad/param norm = 1.4170e-01, time/batch = 0.5477s	
841/2700 (epoch 15.574), train_loss = 2.20344208, grad/param norm = 1.4931e-01, time/batch = 0.5858s	
842/2700 (epoch 15.593), train_loss = 2.22000731, grad/param norm = 1.8237e-01, time/batch = 0.5152s	
843/2700 (epoch 15.611), train_loss = 2.13897999, grad/param norm = 2.5084e-01, time/batch = 0.5511s	
844/2700 (epoch 15.630), train_loss = 2.20206525, grad/param norm = 3.0164e-01, time/batch = 0.5272s	
845/2700 (epoch 15.648), train_loss = 2.22926626, grad/param norm = 3.4162e-01, time/batch = 0.5446s	
846/2700 (epoch 15.667), train_loss = 2.27485222, grad/param norm = 3.8082e-01, time/batch = 0.5691s	
847/2700 (epoch 15.685), train_loss = 2.29682237, grad/param norm = 3.9260e-01, time/batch = 0.5523s	
848/2700 (epoch 15.704), train_loss = 2.29318039, grad/param norm = 2.7269e-01, time/batch = 0.5614s	
849/2700 (epoch 15.722), train_loss = 2.18372670, grad/param norm = 1.1425e-01, time/batch = 0.5457s	
850/2700 (epoch 15.741), train_loss = 2.23684198, grad/param norm = 9.9084e-02, time/batch = 0.5370s	
851/2700 (epoch 15.759), train_loss = 2.25395916, grad/param norm = 1.2845e-01, time/batch = 0.5536s	
852/2700 (epoch 15.778), train_loss = 2.27253013, grad/param norm = 2.0888e-01, time/batch = 0.5744s	
853/2700 (epoch 15.796), train_loss = 2.26993865, grad/param norm = 3.8293e-01, time/batch = 0.5259s	
854/2700 (epoch 15.815), train_loss = 2.37505767, grad/param norm = 5.3530e-01, time/batch = 0.5377s	
855/2700 (epoch 15.833), train_loss = 2.38132634, grad/param norm = 4.9842e-01, time/batch = 0.5683s	
856/2700 (epoch 15.852), train_loss = 2.31170709, grad/param norm = 3.5998e-01, time/batch = 0.5629s	
857/2700 (epoch 15.870), train_loss = 2.23374564, grad/param norm = 2.7747e-01, time/batch = 0.5506s	
858/2700 (epoch 15.889), train_loss = 2.19807905, grad/param norm = 2.4463e-01, time/batch = 0.5340s	
859/2700 (epoch 15.907), train_loss = 2.30727414, grad/param norm = 2.2180e-01, time/batch = 0.5476s	
860/2700 (epoch 15.926), train_loss = 2.24567579, grad/param norm = 2.1465e-01, time/batch = 0.5564s	
861/2700 (epoch 15.944), train_loss = 2.27917859, grad/param norm = 2.5069e-01, time/batch = 0.5530s	
862/2700 (epoch 15.963), train_loss = 2.30544749, grad/param norm = 2.7910e-01, time/batch = 0.5325s	
863/2700 (epoch 15.981), train_loss = 2.23067828, grad/param norm = 3.2322e-01, time/batch = 0.5340s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
864/2700 (epoch 16.000), train_loss = 2.29034061, grad/param norm = 3.6399e-01, time/batch = 0.5408s	
865/2700 (epoch 16.019), train_loss = 2.28213997, grad/param norm = 3.3977e-01, time/batch = 0.5851s	
866/2700 (epoch 16.037), train_loss = 2.27789551, grad/param norm = 3.2325e-01, time/batch = 0.5504s	
867/2700 (epoch 16.056), train_loss = 2.27038566, grad/param norm = 3.1405e-01, time/batch = 0.5342s	
868/2700 (epoch 16.074), train_loss = 2.20218107, grad/param norm = 2.6076e-01, time/batch = 0.5374s	
869/2700 (epoch 16.093), train_loss = 2.22471952, grad/param norm = 2.0979e-01, time/batch = 0.5415s	
870/2700 (epoch 16.111), train_loss = 2.19207058, grad/param norm = 2.2400e-01, time/batch = 0.5467s	
871/2700 (epoch 16.130), train_loss = 2.26199198, grad/param norm = 2.7167e-01, time/batch = 0.5497s	
872/2700 (epoch 16.148), train_loss = 2.23531589, grad/param norm = 2.8491e-01, time/batch = 0.5480s	
873/2700 (epoch 16.167), train_loss = 2.26448794, grad/param norm = 2.2880e-01, time/batch = 0.5437s	
874/2700 (epoch 16.185), train_loss = 2.18116928, grad/param norm = 1.8305e-01, time/batch = 0.5655s	
875/2700 (epoch 16.204), train_loss = 2.19652609, grad/param norm = 1.4930e-01, time/batch = 0.5324s	
876/2700 (epoch 16.222), train_loss = 2.10699522, grad/param norm = 1.5395e-01, time/batch = 0.5593s	
877/2700 (epoch 16.241), train_loss = 2.07173348, grad/param norm = 2.3759e-01, time/batch = 0.5548s	
878/2700 (epoch 16.259), train_loss = 2.15296923, grad/param norm = 3.8377e-01, time/batch = 0.5454s	
879/2700 (epoch 16.278), train_loss = 2.25191224, grad/param norm = 4.2094e-01, time/batch = 0.5489s	
880/2700 (epoch 16.296), train_loss = 2.22602600, grad/param norm = 3.2943e-01, time/batch = 0.5732s	
881/2700 (epoch 16.315), train_loss = 2.22262794, grad/param norm = 2.3296e-01, time/batch = 0.5350s	
882/2700 (epoch 16.333), train_loss = 2.22772137, grad/param norm = 2.1546e-01, time/batch = 0.5368s	
883/2700 (epoch 16.352), train_loss = 2.22483521, grad/param norm = 2.0164e-01, time/batch = 0.5493s	
884/2700 (epoch 16.370), train_loss = 2.23584388, grad/param norm = 1.6898e-01, time/batch = 0.5667s	
885/2700 (epoch 16.389), train_loss = 2.17151914, grad/param norm = 1.7146e-01, time/batch = 0.5751s	
886/2700 (epoch 16.407), train_loss = 2.22442060, grad/param norm = 2.0340e-01, time/batch = 0.5617s	
887/2700 (epoch 16.426), train_loss = 2.22861200, grad/param norm = 1.5537e-01, time/batch = 0.5434s	
888/2700 (epoch 16.444), train_loss = 2.14590153, grad/param norm = 1.7982e-01, time/batch = 0.5557s	
889/2700 (epoch 16.463), train_loss = 2.22628591, grad/param norm = 2.8060e-01, time/batch = 0.5862s	
890/2700 (epoch 16.481), train_loss = 2.26634284, grad/param norm = 4.0870e-01, time/batch = 0.5451s	
891/2700 (epoch 16.500), train_loss = 2.27979944, grad/param norm = 4.0218e-01, time/batch = 0.5704s	
892/2700 (epoch 16.519), train_loss = 2.23827745, grad/param norm = 3.2904e-01, time/batch = 0.5496s	
893/2700 (epoch 16.537), train_loss = 2.21995353, grad/param norm = 2.8187e-01, time/batch = 0.5628s	
894/2700 (epoch 16.556), train_loss = 2.18348455, grad/param norm = 2.4946e-01, time/batch = 0.5703s	
895/2700 (epoch 16.574), train_loss = 2.17496584, grad/param norm = 2.9760e-01, time/batch = 0.5365s	
896/2700 (epoch 16.593), train_loss = 2.20159192, grad/param norm = 3.5184e-01, time/batch = 0.5571s	
897/2700 (epoch 16.611), train_loss = 2.16701454, grad/param norm = 3.8501e-01, time/batch = 0.5845s	
898/2700 (epoch 16.630), train_loss = 2.21367395, grad/param norm = 3.3728e-01, time/batch = 0.5667s	
899/2700 (epoch 16.648), train_loss = 2.17660517, grad/param norm = 2.7845e-01, time/batch = 0.4658s	
900/2700 (epoch 16.667), train_loss = 2.17088612, grad/param norm = 2.8089e-01, time/batch = 0.4506s	
901/2700 (epoch 16.685), train_loss = 2.17262941, grad/param norm = 2.9270e-01, time/batch = 0.5432s	
902/2700 (epoch 16.704), train_loss = 2.19283129, grad/param norm = 2.6413e-01, time/batch = 0.5663s	
903/2700 (epoch 16.722), train_loss = 2.15391841, grad/param norm = 2.2855e-01, time/batch = 0.5661s	
904/2700 (epoch 16.741), train_loss = 2.20788601, grad/param norm = 2.3284e-01, time/batch = 0.5507s	
905/2700 (epoch 16.759), train_loss = 2.22142595, grad/param norm = 2.0390e-01, time/batch = 0.5597s	
906/2700 (epoch 16.778), train_loss = 2.21397840, grad/param norm = 1.5086e-01, time/batch = 0.5807s	
907/2700 (epoch 16.796), train_loss = 2.16075944, grad/param norm = 1.2215e-01, time/batch = 0.5534s	
908/2700 (epoch 16.815), train_loss = 2.18264412, grad/param norm = 1.5827e-01, time/batch = 0.5236s	
909/2700 (epoch 16.833), train_loss = 2.17402491, grad/param norm = 2.3103e-01, time/batch = 0.5257s	
910/2700 (epoch 16.852), train_loss = 2.18985311, grad/param norm = 2.6259e-01, time/batch = 0.5560s	
911/2700 (epoch 16.870), train_loss = 2.18852311, grad/param norm = 3.4412e-01, time/batch = 0.5597s	
912/2700 (epoch 16.889), train_loss = 2.21727387, grad/param norm = 3.8555e-01, time/batch = 0.5619s	
913/2700 (epoch 16.907), train_loss = 2.31659265, grad/param norm = 3.7092e-01, time/batch = 0.5444s	
914/2700 (epoch 16.926), train_loss = 2.22271399, grad/param norm = 3.1716e-01, time/batch = 0.5574s	
915/2700 (epoch 16.944), train_loss = 2.20955983, grad/param norm = 2.1412e-01, time/batch = 0.5795s	
916/2700 (epoch 16.963), train_loss = 2.23432878, grad/param norm = 1.6334e-01, time/batch = 0.5226s	
917/2700 (epoch 16.981), train_loss = 2.15587390, grad/param norm = 1.5454e-01, time/batch = 0.5585s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
918/2700 (epoch 17.000), train_loss = 2.20764267, grad/param norm = 1.6619e-01, time/batch = 0.5278s	
919/2700 (epoch 17.019), train_loss = 2.21703510, grad/param norm = 2.2797e-01, time/batch = 0.5545s	
920/2700 (epoch 17.037), train_loss = 2.24282267, grad/param norm = 2.1201e-01, time/batch = 0.5725s	
921/2700 (epoch 17.056), train_loss = 2.21031814, grad/param norm = 1.8461e-01, time/batch = 0.5559s	
922/2700 (epoch 17.074), train_loss = 2.15536309, grad/param norm = 1.8064e-01, time/batch = 0.5462s	
923/2700 (epoch 17.093), train_loss = 2.16624171, grad/param norm = 1.8269e-01, time/batch = 0.5453s	
924/2700 (epoch 17.111), train_loss = 2.13679638, grad/param norm = 2.7946e-01, time/batch = 0.5543s	
925/2700 (epoch 17.130), train_loss = 2.25490172, grad/param norm = 5.0944e-01, time/batch = 0.5604s	
926/2700 (epoch 17.148), train_loss = 2.27197425, grad/param norm = 4.8568e-01, time/batch = 0.5577s	
927/2700 (epoch 17.167), train_loss = 2.22036054, grad/param norm = 2.8139e-01, time/batch = 0.5254s	
928/2700 (epoch 17.185), train_loss = 2.11911932, grad/param norm = 1.7239e-01, time/batch = 0.5354s	
929/2700 (epoch 17.204), train_loss = 2.13008966, grad/param norm = 1.1934e-01, time/batch = 0.5755s	
930/2700 (epoch 17.222), train_loss = 2.06051844, grad/param norm = 1.1467e-01, time/batch = 0.5682s	
931/2700 (epoch 17.241), train_loss = 2.01603737, grad/param norm = 1.3423e-01, time/batch = 0.5484s	
932/2700 (epoch 17.259), train_loss = 2.08007071, grad/param norm = 1.6082e-01, time/batch = 0.5304s	
933/2700 (epoch 17.278), train_loss = 2.15405643, grad/param norm = 1.8484e-01, time/batch = 0.5668s	
934/2700 (epoch 17.296), train_loss = 2.14500769, grad/param norm = 1.4932e-01, time/batch = 0.5646s	
935/2700 (epoch 17.315), train_loss = 2.14088928, grad/param norm = 1.2673e-01, time/batch = 0.5608s	
936/2700 (epoch 17.333), train_loss = 2.15612022, grad/param norm = 1.4235e-01, time/batch = 0.5298s	
937/2700 (epoch 17.352), train_loss = 2.15212811, grad/param norm = 1.3434e-01, time/batch = 0.5476s	
938/2700 (epoch 17.370), train_loss = 2.16168192, grad/param norm = 1.3174e-01, time/batch = 0.5816s	
939/2700 (epoch 17.389), train_loss = 2.10937737, grad/param norm = 2.2413e-01, time/batch = 0.5624s	
940/2700 (epoch 17.407), train_loss = 2.19629009, grad/param norm = 3.5944e-01, time/batch = 0.5481s	
941/2700 (epoch 17.426), train_loss = 2.22810627, grad/param norm = 3.9854e-01, time/batch = 0.5679s	
942/2700 (epoch 17.444), train_loss = 2.16225125, grad/param norm = 3.6704e-01, time/batch = 0.5702s	
943/2700 (epoch 17.463), train_loss = 2.20540554, grad/param norm = 3.1194e-01, time/batch = 0.5461s	
944/2700 (epoch 17.481), train_loss = 2.18355337, grad/param norm = 2.3132e-01, time/batch = 0.5392s	
945/2700 (epoch 17.500), train_loss = 2.12837151, grad/param norm = 2.1001e-01, time/batch = 0.5353s	
946/2700 (epoch 17.519), train_loss = 2.14546823, grad/param norm = 2.8421e-01, time/batch = 0.5509s	
947/2700 (epoch 17.537), train_loss = 2.18826930, grad/param norm = 3.1203e-01, time/batch = 0.6033s	
948/2700 (epoch 17.556), train_loss = 2.14903587, grad/param norm = 2.8090e-01, time/batch = 0.5708s	
949/2700 (epoch 17.574), train_loss = 2.12189335, grad/param norm = 2.4570e-01, time/batch = 0.5387s	
950/2700 (epoch 17.593), train_loss = 2.11887373, grad/param norm = 2.2164e-01, time/batch = 0.5296s	
951/2700 (epoch 17.611), train_loss = 2.03654711, grad/param norm = 2.1248e-01, time/batch = 0.5772s	
952/2700 (epoch 17.630), train_loss = 2.08083342, grad/param norm = 2.2982e-01, time/batch = 0.5538s	
953/2700 (epoch 17.648), train_loss = 2.10659823, grad/param norm = 2.4488e-01, time/batch = 0.5398s	
954/2700 (epoch 17.667), train_loss = 2.10763832, grad/param norm = 2.3253e-01, time/batch = 0.5234s	
955/2700 (epoch 17.685), train_loss = 2.11162387, grad/param norm = 2.3118e-01, time/batch = 0.5589s	
956/2700 (epoch 17.704), train_loss = 2.13325638, grad/param norm = 2.3398e-01, time/batch = 0.5844s	
957/2700 (epoch 17.722), train_loss = 2.08124332, grad/param norm = 2.3167e-01, time/batch = 0.5323s	
958/2700 (epoch 17.741), train_loss = 2.13750950, grad/param norm = 2.4453e-01, time/batch = 0.5476s	
959/2700 (epoch 17.759), train_loss = 2.18118288, grad/param norm = 3.2462e-01, time/batch = 0.5352s	
960/2700 (epoch 17.778), train_loss = 2.23037137, grad/param norm = 4.2754e-01, time/batch = 0.5661s	
961/2700 (epoch 17.796), train_loss = 2.19443434, grad/param norm = 3.6672e-01, time/batch = 0.5513s	
962/2700 (epoch 17.815), train_loss = 2.19109421, grad/param norm = 3.3451e-01, time/batch = 0.5470s	
963/2700 (epoch 17.833), train_loss = 2.15909217, grad/param norm = 2.9287e-01, time/batch = 0.5045s	
964/2700 (epoch 17.852), train_loss = 2.14730515, grad/param norm = 2.1677e-01, time/batch = 0.5900s	
965/2700 (epoch 17.870), train_loss = 2.14143509, grad/param norm = 2.5917e-01, time/batch = 0.5252s	
966/2700 (epoch 17.889), train_loss = 2.17131164, grad/param norm = 2.8953e-01, time/batch = 0.5541s	
967/2700 (epoch 17.907), train_loss = 2.25608007, grad/param norm = 2.5816e-01, time/batch = 0.5664s	
968/2700 (epoch 17.926), train_loss = 2.15668259, grad/param norm = 2.0715e-01, time/batch = 0.5369s	
969/2700 (epoch 17.944), train_loss = 2.14016305, grad/param norm = 1.0258e-01, time/batch = 0.5624s	
970/2700 (epoch 17.963), train_loss = 2.16792252, grad/param norm = 8.0394e-02, time/batch = 0.5793s	
971/2700 (epoch 17.981), train_loss = 2.08815197, grad/param norm = 1.1325e-01, time/batch = 0.5503s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
972/2700 (epoch 18.000), train_loss = 2.13593478, grad/param norm = 1.6686e-01, time/batch = 0.5091s	
973/2700 (epoch 18.019), train_loss = 2.14182742, grad/param norm = 2.1099e-01, time/batch = 0.5781s	
974/2700 (epoch 18.037), train_loss = 2.16480819, grad/param norm = 2.6689e-01, time/batch = 0.5728s	
975/2700 (epoch 18.056), train_loss = 2.15931549, grad/param norm = 3.5162e-01, time/batch = 0.5742s	
976/2700 (epoch 18.074), train_loss = 2.13021652, grad/param norm = 3.6090e-01, time/batch = 0.5350s	
977/2700 (epoch 18.093), train_loss = 2.11728102, grad/param norm = 2.7437e-01, time/batch = 0.5467s	
978/2700 (epoch 18.111), train_loss = 2.05602347, grad/param norm = 2.3405e-01, time/batch = 0.5786s	
979/2700 (epoch 18.130), train_loss = 2.14261359, grad/param norm = 2.5678e-01, time/batch = 0.5628s	
980/2700 (epoch 18.148), train_loss = 2.10578871, grad/param norm = 2.8206e-01, time/batch = 0.5525s	
981/2700 (epoch 18.167), train_loss = 2.17710888, grad/param norm = 2.3763e-01, time/batch = 0.5553s	
982/2700 (epoch 18.185), train_loss = 2.07156300, grad/param norm = 1.5147e-01, time/batch = 0.5688s	
983/2700 (epoch 18.204), train_loss = 2.07576376, grad/param norm = 1.3411e-01, time/batch = 0.5632s	
984/2700 (epoch 18.222), train_loss = 2.00808465, grad/param norm = 1.4225e-01, time/batch = 0.5422s	
985/2700 (epoch 18.241), train_loss = 1.95763170, grad/param norm = 1.8656e-01, time/batch = 0.5467s	
986/2700 (epoch 18.259), train_loss = 2.02640842, grad/param norm = 2.4344e-01, time/batch = 0.5652s	
987/2700 (epoch 18.278), train_loss = 2.10735337, grad/param norm = 2.9919e-01, time/batch = 0.5528s	
988/2700 (epoch 18.296), train_loss = 2.13467877, grad/param norm = 3.9049e-01, time/batch = 0.5710s	
989/2700 (epoch 18.315), train_loss = 2.16575169, grad/param norm = 4.2490e-01, time/batch = 0.5348s	
990/2700 (epoch 18.333), train_loss = 2.18836066, grad/param norm = 4.0629e-01, time/batch = 0.4988s	
991/2700 (epoch 18.352), train_loss = 2.17002013, grad/param norm = 2.9224e-01, time/batch = 0.5899s	
992/2700 (epoch 18.370), train_loss = 2.12965313, grad/param norm = 1.9196e-01, time/batch = 0.5525s	
993/2700 (epoch 18.389), train_loss = 2.07300723, grad/param norm = 1.6221e-01, time/batch = 0.5391s	
994/2700 (epoch 18.407), train_loss = 2.14433771, grad/param norm = 2.3280e-01, time/batch = 0.5407s	
995/2700 (epoch 18.426), train_loss = 2.16927306, grad/param norm = 1.8376e-01, time/batch = 0.5600s	
996/2700 (epoch 18.444), train_loss = 2.04370250, grad/param norm = 1.3942e-01, time/batch = 0.5697s	
997/2700 (epoch 18.463), train_loss = 2.09709558, grad/param norm = 1.2197e-01, time/batch = 0.5673s	
998/2700 (epoch 18.481), train_loss = 2.09870523, grad/param norm = 1.2133e-01, time/batch = 0.5423s	
999/2700 (epoch 18.500), train_loss = 2.05633085, grad/param norm = 1.1950e-01, time/batch = 0.4949s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch18.52_2.1058.t7	
1000/2700 (epoch 18.519), train_loss = 2.05865548, grad/param norm = 1.3316e-01, time/batch = 0.5746s	
1001/2700 (epoch 18.537), train_loss = 2.17255154, grad/param norm = 1.9503e-01, time/batch = 0.5575s	
1002/2700 (epoch 18.556), train_loss = 2.07674597, grad/param norm = 2.7605e-01, time/batch = 0.5796s	
1003/2700 (epoch 18.574), train_loss = 2.11433515, grad/param norm = 3.9335e-01, time/batch = 0.5711s	
1004/2700 (epoch 18.593), train_loss = 2.14376230, grad/param norm = 4.2130e-01, time/batch = 0.5307s	
1005/2700 (epoch 18.611), train_loss = 2.06438281, grad/param norm = 3.6635e-01, time/batch = 0.5145s	
1006/2700 (epoch 18.630), train_loss = 2.07164145, grad/param norm = 2.7735e-01, time/batch = 0.5590s	
1007/2700 (epoch 18.648), train_loss = 2.06175391, grad/param norm = 2.1872e-01, time/batch = 0.5827s	
1008/2700 (epoch 18.667), train_loss = 2.05889237, grad/param norm = 2.0428e-01, time/batch = 0.5675s	
1009/2700 (epoch 18.685), train_loss = 2.06923260, grad/param norm = 1.7766e-01, time/batch = 0.5443s	
1010/2700 (epoch 18.704), train_loss = 2.07204953, grad/param norm = 1.4091e-01, time/batch = 0.5377s	
1011/2700 (epoch 18.722), train_loss = 2.03439702, grad/param norm = 1.4760e-01, time/batch = 0.6030s	
1012/2700 (epoch 18.741), train_loss = 2.07423183, grad/param norm = 1.4395e-01, time/batch = 0.5420s	
1013/2700 (epoch 18.759), train_loss = 2.10417080, grad/param norm = 1.6731e-01, time/batch = 0.5467s	
1014/2700 (epoch 18.778), train_loss = 2.12095522, grad/param norm = 1.9405e-01, time/batch = 0.5324s	
1015/2700 (epoch 18.796), train_loss = 2.05961274, grad/param norm = 1.8090e-01, time/batch = 0.5606s	
1016/2700 (epoch 18.815), train_loss = 2.08546117, grad/param norm = 2.0551e-01, time/batch = 0.5786s	
1017/2700 (epoch 18.833), train_loss = 2.06603827, grad/param norm = 2.3789e-01, time/batch = 0.5659s	
1018/2700 (epoch 18.852), train_loss = 2.07543778, grad/param norm = 2.0531e-01, time/batch = 0.5425s	
1019/2700 (epoch 18.870), train_loss = 2.06942569, grad/param norm = 2.4297e-01, time/batch = 0.5403s	
1020/2700 (epoch 18.889), train_loss = 2.06941784, grad/param norm = 2.4407e-01, time/batch = 0.5784s	
1021/2700 (epoch 18.907), train_loss = 2.17736147, grad/param norm = 2.4989e-01, time/batch = 0.5558s	
1022/2700 (epoch 18.926), train_loss = 2.10184921, grad/param norm = 2.5209e-01, time/batch = 0.5417s	
1023/2700 (epoch 18.944), train_loss = 2.09802770, grad/param norm = 2.0591e-01, time/batch = 0.5355s	
1024/2700 (epoch 18.963), train_loss = 2.13070375, grad/param norm = 2.0570e-01, time/batch = 0.5751s	
1025/2700 (epoch 18.981), train_loss = 2.06451896, grad/param norm = 2.7597e-01, time/batch = 0.5590s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1026/2700 (epoch 19.000), train_loss = 2.15938442, grad/param norm = 4.1148e-01, time/batch = 0.5547s	
1027/2700 (epoch 19.019), train_loss = 2.19014492, grad/param norm = 4.0134e-01, time/batch = 0.5368s	
1028/2700 (epoch 19.037), train_loss = 2.14842823, grad/param norm = 2.8982e-01, time/batch = 0.5391s	
1029/2700 (epoch 19.056), train_loss = 2.10139847, grad/param norm = 2.4982e-01, time/batch = 0.5824s	
1030/2700 (epoch 19.074), train_loss = 2.05943980, grad/param norm = 2.4110e-01, time/batch = 0.5692s	
1031/2700 (epoch 19.093), train_loss = 2.07164578, grad/param norm = 2.9400e-01, time/batch = 0.5427s	
1032/2700 (epoch 19.111), train_loss = 2.03625270, grad/param norm = 3.3592e-01, time/batch = 0.5567s	
1033/2700 (epoch 19.130), train_loss = 2.10090048, grad/param norm = 3.3005e-01, time/batch = 0.5752s	
1034/2700 (epoch 19.148), train_loss = 2.06731511, grad/param norm = 2.9109e-01, time/batch = 0.5557s	
1035/2700 (epoch 19.167), train_loss = 2.09823942, grad/param norm = 2.3397e-01, time/batch = 0.5457s	
1036/2700 (epoch 19.185), train_loss = 2.02448657, grad/param norm = 1.9857e-01, time/batch = 0.5314s	
1037/2700 (epoch 19.204), train_loss = 2.04574377, grad/param norm = 1.6735e-01, time/batch = 0.5765s	
1038/2700 (epoch 19.222), train_loss = 1.97311625, grad/param norm = 1.5259e-01, time/batch = 0.5501s	
1039/2700 (epoch 19.241), train_loss = 1.91350420, grad/param norm = 1.3177e-01, time/batch = 0.5633s	
1040/2700 (epoch 19.259), train_loss = 1.96950948, grad/param norm = 1.2880e-01, time/batch = 0.5517s	
1041/2700 (epoch 19.278), train_loss = 2.03332793, grad/param norm = 1.1362e-01, time/batch = 0.5598s	
1042/2700 (epoch 19.296), train_loss = 2.02534472, grad/param norm = 9.5117e-02, time/batch = 0.5664s	
1043/2700 (epoch 19.315), train_loss = 2.02520951, grad/param norm = 1.0394e-01, time/batch = 0.5421s	
1044/2700 (epoch 19.333), train_loss = 2.04480945, grad/param norm = 1.1565e-01, time/batch = 0.5276s	
1045/2700 (epoch 19.352), train_loss = 2.04555729, grad/param norm = 1.1028e-01, time/batch = 0.5585s	
1046/2700 (epoch 19.370), train_loss = 2.05780353, grad/param norm = 1.0948e-01, time/batch = 0.5895s	
1047/2700 (epoch 19.389), train_loss = 2.00459315, grad/param norm = 1.2921e-01, time/batch = 0.5545s	
1048/2700 (epoch 19.407), train_loss = 2.07553924, grad/param norm = 1.5302e-01, time/batch = 0.5638s	
1049/2700 (epoch 19.426), train_loss = 2.08375434, grad/param norm = 1.4612e-01, time/batch = 0.5381s	
1050/2700 (epoch 19.444), train_loss = 1.97963318, grad/param norm = 1.8453e-01, time/batch = 0.5498s	
1051/2700 (epoch 19.463), train_loss = 2.06546292, grad/param norm = 2.8029e-01, time/batch = 0.5695s	
1052/2700 (epoch 19.481), train_loss = 2.09896130, grad/param norm = 3.3437e-01, time/batch = 0.5264s	
1053/2700 (epoch 19.500), train_loss = 2.06428559, grad/param norm = 3.0200e-01, time/batch = 0.5397s	
1054/2700 (epoch 19.519), train_loss = 2.04888507, grad/param norm = 2.5841e-01, time/batch = 0.5517s	
1055/2700 (epoch 19.537), train_loss = 2.05193034, grad/param norm = 2.2582e-01, time/batch = 0.5661s	
1056/2700 (epoch 19.556), train_loss = 2.01527768, grad/param norm = 2.1774e-01, time/batch = 0.5451s	
1057/2700 (epoch 19.574), train_loss = 2.03039927, grad/param norm = 2.1999e-01, time/batch = 0.5468s	
1058/2700 (epoch 19.593), train_loss = 2.01236211, grad/param norm = 1.9639e-01, time/batch = 0.5434s	
1059/2700 (epoch 19.611), train_loss = 1.93896568, grad/param norm = 1.9788e-01, time/batch = 0.5404s	
1060/2700 (epoch 19.630), train_loss = 1.99916698, grad/param norm = 3.0988e-01, time/batch = 0.5850s	
1061/2700 (epoch 19.648), train_loss = 2.09067305, grad/param norm = 4.0266e-01, time/batch = 0.5327s	
1062/2700 (epoch 19.667), train_loss = 2.12974138, grad/param norm = 5.1186e-01, time/batch = 0.5413s	
1063/2700 (epoch 19.685), train_loss = 2.17214061, grad/param norm = 4.4361e-01, time/batch = 0.5617s	
1064/2700 (epoch 19.704), train_loss = 2.06737501, grad/param norm = 2.2409e-01, time/batch = 0.5928s	
1065/2700 (epoch 19.722), train_loss = 1.98855853, grad/param norm = 1.2168e-01, time/batch = 0.5598s	
1066/2700 (epoch 19.741), train_loss = 2.01511578, grad/param norm = 1.0976e-01, time/batch = 0.5330s	
1067/2700 (epoch 19.759), train_loss = 2.03218363, grad/param norm = 9.9370e-02, time/batch = 0.5380s	
1068/2700 (epoch 19.778), train_loss = 2.04928882, grad/param norm = 8.5865e-02, time/batch = 0.5540s	
1069/2700 (epoch 19.796), train_loss = 1.98906385, grad/param norm = 8.8596e-02, time/batch = 0.5427s	
1070/2700 (epoch 19.815), train_loss = 2.01685943, grad/param norm = 7.8271e-02, time/batch = 0.5626s	
1071/2700 (epoch 19.833), train_loss = 1.99130956, grad/param norm = 8.2556e-02, time/batch = 0.5481s	
1072/2700 (epoch 19.852), train_loss = 2.00069577, grad/param norm = 9.7468e-02, time/batch = 0.5840s	
1073/2700 (epoch 19.870), train_loss = 2.00588966, grad/param norm = 1.6697e-01, time/batch = 0.5668s	
1074/2700 (epoch 19.889), train_loss = 2.01148324, grad/param norm = 2.6898e-01, time/batch = 0.5570s	
1075/2700 (epoch 19.907), train_loss = 2.15685841, grad/param norm = 3.3671e-01, time/batch = 0.5331s	
1076/2700 (epoch 19.926), train_loss = 2.09650105, grad/param norm = 3.1401e-01, time/batch = 0.5367s	
1077/2700 (epoch 19.944), train_loss = 2.08981309, grad/param norm = 3.2367e-01, time/batch = 0.5523s	
1078/2700 (epoch 19.963), train_loss = 2.15078388, grad/param norm = 3.3668e-01, time/batch = 0.5363s	
1079/2700 (epoch 19.981), train_loss = 2.05992661, grad/param norm = 3.4147e-01, time/batch = 0.5676s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1080/2700 (epoch 20.000), train_loss = 2.10715376, grad/param norm = 2.8342e-01, time/batch = 0.5538s	
1081/2700 (epoch 20.019), train_loss = 2.06733054, grad/param norm = 1.8099e-01, time/batch = 0.5776s	
1082/2700 (epoch 20.037), train_loss = 2.06363857, grad/param norm = 1.2302e-01, time/batch = 0.5680s	
1083/2700 (epoch 20.056), train_loss = 2.02664322, grad/param norm = 1.2708e-01, time/batch = 0.5429s	
1084/2700 (epoch 20.074), train_loss = 1.98103965, grad/param norm = 1.1550e-01, time/batch = 0.5408s	
1085/2700 (epoch 20.093), train_loss = 1.98193262, grad/param norm = 1.2941e-01, time/batch = 0.5204s	
1086/2700 (epoch 20.111), train_loss = 1.93325125, grad/param norm = 1.5517e-01, time/batch = 0.5553s	
1087/2700 (epoch 20.130), train_loss = 2.00727481, grad/param norm = 1.6784e-01, time/batch = 0.5328s	
1088/2700 (epoch 20.148), train_loss = 1.97727650, grad/param norm = 2.0579e-01, time/batch = 0.5641s	
1089/2700 (epoch 20.167), train_loss = 2.03578294, grad/param norm = 2.2442e-01, time/batch = 0.5559s	
1090/2700 (epoch 20.185), train_loss = 1.96043555, grad/param norm = 2.1861e-01, time/batch = 0.5402s	
1091/2700 (epoch 20.204), train_loss = 1.99162270, grad/param norm = 1.9540e-01, time/batch = 0.6170s	
1092/2700 (epoch 20.222), train_loss = 1.92710815, grad/param norm = 1.8067e-01, time/batch = 0.5612s	
1093/2700 (epoch 20.241), train_loss = 1.86101019, grad/param norm = 1.8618e-01, time/batch = 0.5312s	
1094/2700 (epoch 20.259), train_loss = 1.93066101, grad/param norm = 1.9628e-01, time/batch = 0.5376s	
1095/2700 (epoch 20.278), train_loss = 1.98911464, grad/param norm = 1.8476e-01, time/batch = 0.5264s	
1096/2700 (epoch 20.296), train_loss = 1.97840526, grad/param norm = 1.3188e-01, time/batch = 0.5844s	
1097/2700 (epoch 20.315), train_loss = 1.97781073, grad/param norm = 1.3083e-01, time/batch = 0.5629s	
1098/2700 (epoch 20.333), train_loss = 1.99892612, grad/param norm = 2.1439e-01, time/batch = 0.5424s	
1099/2700 (epoch 20.352), train_loss = 2.03301472, grad/param norm = 3.0356e-01, time/batch = 0.5438s	
1100/2700 (epoch 20.370), train_loss = 2.06165504, grad/param norm = 3.4204e-01, time/batch = 0.5928s	
1101/2700 (epoch 20.389), train_loss = 2.01370888, grad/param norm = 3.0221e-01, time/batch = 0.5626s	
1102/2700 (epoch 20.407), train_loss = 2.03022804, grad/param norm = 2.3855e-01, time/batch = 0.5391s	
1103/2700 (epoch 20.426), train_loss = 2.03058348, grad/param norm = 1.2956e-01, time/batch = 0.5358s	
1104/2700 (epoch 20.444), train_loss = 1.93581692, grad/param norm = 1.2891e-01, time/batch = 0.5481s	
1105/2700 (epoch 20.463), train_loss = 2.02777908, grad/param norm = 1.5929e-01, time/batch = 0.5884s	
1106/2700 (epoch 20.481), train_loss = 2.02673923, grad/param norm = 1.5223e-01, time/batch = 0.5652s	
1107/2700 (epoch 20.500), train_loss = 1.97678492, grad/param norm = 1.4010e-01, time/batch = 0.5416s	
1108/2700 (epoch 20.519), train_loss = 1.98092207, grad/param norm = 1.3841e-01, time/batch = 0.5494s	
1109/2700 (epoch 20.537), train_loss = 2.01190654, grad/param norm = 1.3938e-01, time/batch = 0.6089s	
1110/2700 (epoch 20.556), train_loss = 1.95229188, grad/param norm = 1.3795e-01, time/batch = 0.5148s	
1111/2700 (epoch 20.574), train_loss = 1.96022985, grad/param norm = 1.4668e-01, time/batch = 0.5399s	
1112/2700 (epoch 20.593), train_loss = 1.96124040, grad/param norm = 1.6490e-01, time/batch = 0.5480s	
1113/2700 (epoch 20.611), train_loss = 1.89621525, grad/param norm = 1.8500e-01, time/batch = 0.5696s	
1114/2700 (epoch 20.630), train_loss = 1.94596214, grad/param norm = 2.0305e-01, time/batch = 0.5704s	
1115/2700 (epoch 20.648), train_loss = 1.97550671, grad/param norm = 2.0338e-01, time/batch = 0.5481s	
1116/2700 (epoch 20.667), train_loss = 1.96466087, grad/param norm = 1.9619e-01, time/batch = 0.5390s	
1117/2700 (epoch 20.685), train_loss = 1.96628264, grad/param norm = 1.9253e-01, time/batch = 0.5958s	
1118/2700 (epoch 20.704), train_loss = 1.96480555, grad/param norm = 1.3771e-01, time/batch = 0.5362s	
1119/2700 (epoch 20.722), train_loss = 1.92194356, grad/param norm = 1.0335e-01, time/batch = 0.5700s	
1120/2700 (epoch 20.741), train_loss = 1.95110014, grad/param norm = 1.6149e-01, time/batch = 0.5489s	
1121/2700 (epoch 20.759), train_loss = 2.00278795, grad/param norm = 2.2387e-01, time/batch = 0.5696s	
1122/2700 (epoch 20.778), train_loss = 2.05830904, grad/param norm = 3.1959e-01, time/batch = 0.5560s	
1123/2700 (epoch 20.796), train_loss = 2.03872670, grad/param norm = 3.3710e-01, time/batch = 0.5473s	
1124/2700 (epoch 20.815), train_loss = 2.02763921, grad/param norm = 2.9340e-01, time/batch = 0.5407s	
1125/2700 (epoch 20.833), train_loss = 2.00009551, grad/param norm = 2.7858e-01, time/batch = 0.5685s	
1126/2700 (epoch 20.852), train_loss = 2.00082196, grad/param norm = 3.0030e-01, time/batch = 0.5590s	
1127/2700 (epoch 20.870), train_loss = 2.01075751, grad/param norm = 3.1419e-01, time/batch = 0.5708s	
1128/2700 (epoch 20.889), train_loss = 1.98588506, grad/param norm = 2.6131e-01, time/batch = 0.5596s	
1129/2700 (epoch 20.907), train_loss = 2.06575906, grad/param norm = 1.8097e-01, time/batch = 0.5411s	
1130/2700 (epoch 20.926), train_loss = 1.99157478, grad/param norm = 1.4816e-01, time/batch = 0.5579s	
1131/2700 (epoch 20.944), train_loss = 1.99418329, grad/param norm = 1.4778e-01, time/batch = 0.5512s	
1132/2700 (epoch 20.963), train_loss = 2.02257833, grad/param norm = 1.3161e-01, time/batch = 0.5354s	
1133/2700 (epoch 20.981), train_loss = 1.94583082, grad/param norm = 1.4058e-01, time/batch = 0.5523s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1134/2700 (epoch 21.000), train_loss = 2.00335516, grad/param norm = 1.6908e-01, time/batch = 0.5767s	
1135/2700 (epoch 21.019), train_loss = 1.99959570, grad/param norm = 1.6747e-01, time/batch = 0.5684s	
1136/2700 (epoch 21.037), train_loss = 2.01558682, grad/param norm = 1.7489e-01, time/batch = 0.5575s	
1137/2700 (epoch 21.056), train_loss = 2.00361213, grad/param norm = 2.2794e-01, time/batch = 0.5341s	
1138/2700 (epoch 21.074), train_loss = 1.97605794, grad/param norm = 2.9106e-01, time/batch = 0.5583s	
1139/2700 (epoch 21.093), train_loss = 2.02793962, grad/param norm = 3.2115e-01, time/batch = 0.5708s	
1140/2700 (epoch 21.111), train_loss = 1.97828234, grad/param norm = 3.2060e-01, time/batch = 0.5617s	
1141/2700 (epoch 21.130), train_loss = 2.03027927, grad/param norm = 2.4720e-01, time/batch = 0.5666s	
1142/2700 (epoch 21.148), train_loss = 1.92911592, grad/param norm = 1.2611e-01, time/batch = 0.5677s	
1143/2700 (epoch 21.167), train_loss = 1.97294955, grad/param norm = 8.5329e-02, time/batch = 0.5740s	
1144/2700 (epoch 21.185), train_loss = 1.89190902, grad/param norm = 7.8771e-02, time/batch = 0.5531s	
1145/2700 (epoch 21.204), train_loss = 1.92783016, grad/param norm = 7.8499e-02, time/batch = 0.5443s	
1146/2700 (epoch 21.222), train_loss = 1.86121525, grad/param norm = 8.4916e-02, time/batch = 0.5610s	
1147/2700 (epoch 21.241), train_loss = 1.79738249, grad/param norm = 9.5619e-02, time/batch = 0.5774s	
1148/2700 (epoch 21.259), train_loss = 1.86125406, grad/param norm = 1.3801e-01, time/batch = 0.5587s	
1149/2700 (epoch 21.278), train_loss = 1.93874475, grad/param norm = 1.6580e-01, time/batch = 0.5338s	
1150/2700 (epoch 21.296), train_loss = 1.95452442, grad/param norm = 2.3016e-01, time/batch = 0.5272s	
1151/2700 (epoch 21.315), train_loss = 1.98135706, grad/param norm = 3.5612e-01, time/batch = 0.5996s	
1152/2700 (epoch 21.333), train_loss = 2.02648867, grad/param norm = 3.7424e-01, time/batch = 0.5590s	
1153/2700 (epoch 21.352), train_loss = 2.02252110, grad/param norm = 3.3658e-01, time/batch = 0.5457s	
1154/2700 (epoch 21.370), train_loss = 2.02828669, grad/param norm = 2.4397e-01, time/batch = 0.5396s	
1155/2700 (epoch 21.389), train_loss = 1.92973518, grad/param norm = 1.5881e-01, time/batch = 0.5724s	
1156/2700 (epoch 21.407), train_loss = 1.96718300, grad/param norm = 1.3094e-01, time/batch = 0.5689s	
1157/2700 (epoch 21.426), train_loss = 1.97991295, grad/param norm = 1.5122e-01, time/batch = 0.5490s	
1158/2700 (epoch 21.444), train_loss = 1.88765450, grad/param norm = 1.5884e-01, time/batch = 0.5169s	
1159/2700 (epoch 21.463), train_loss = 1.95972838, grad/param norm = 1.1302e-01, time/batch = 0.5499s	
1160/2700 (epoch 21.481), train_loss = 1.96650977, grad/param norm = 1.0419e-01, time/batch = 0.6059s	
1161/2700 (epoch 21.500), train_loss = 1.91405130, grad/param norm = 1.5209e-01, time/batch = 0.5547s	
1162/2700 (epoch 21.519), train_loss = 1.94106883, grad/param norm = 1.9043e-01, time/batch = 0.5488s	
1163/2700 (epoch 21.537), train_loss = 1.97027137, grad/param norm = 1.7613e-01, time/batch = 0.5719s	
1164/2700 (epoch 21.556), train_loss = 1.90623287, grad/param norm = 1.6895e-01, time/batch = 0.5858s	
1165/2700 (epoch 21.574), train_loss = 1.91192766, grad/param norm = 1.9922e-01, time/batch = 0.5396s	
1166/2700 (epoch 21.593), train_loss = 1.93657099, grad/param norm = 2.3835e-01, time/batch = 0.5259s	
1167/2700 (epoch 21.611), train_loss = 1.86303457, grad/param norm = 2.9164e-01, time/batch = 0.5326s	
1168/2700 (epoch 21.630), train_loss = 1.91189952, grad/param norm = 2.9512e-01, time/batch = 0.5481s	
1169/2700 (epoch 21.648), train_loss = 1.91610452, grad/param norm = 2.4869e-01, time/batch = 0.5809s	
1170/2700 (epoch 21.667), train_loss = 1.89670220, grad/param norm = 2.0832e-01, time/batch = 0.5668s	
1171/2700 (epoch 21.685), train_loss = 1.90406698, grad/param norm = 1.6893e-01, time/batch = 0.5527s	
1172/2700 (epoch 21.704), train_loss = 1.92373231, grad/param norm = 1.5821e-01, time/batch = 0.5862s	
1173/2700 (epoch 21.722), train_loss = 1.87760102, grad/param norm = 1.3949e-01, time/batch = 0.5613s	
1174/2700 (epoch 21.741), train_loss = 1.89913782, grad/param norm = 1.3825e-01, time/batch = 0.5234s	
1175/2700 (epoch 21.759), train_loss = 1.94404885, grad/param norm = 2.1460e-01, time/batch = 0.5430s	
1176/2700 (epoch 21.778), train_loss = 2.01581699, grad/param norm = 3.1189e-01, time/batch = 0.5114s	
1177/2700 (epoch 21.796), train_loss = 1.98578328, grad/param norm = 3.0892e-01, time/batch = 0.5993s	
1178/2700 (epoch 21.815), train_loss = 1.98844222, grad/param norm = 2.6925e-01, time/batch = 0.6032s	
1179/2700 (epoch 21.833), train_loss = 1.94031142, grad/param norm = 1.9839e-01, time/batch = 0.5281s	
1180/2700 (epoch 21.852), train_loss = 1.91632877, grad/param norm = 1.1640e-01, time/batch = 0.5458s	
1181/2700 (epoch 21.870), train_loss = 1.91496044, grad/param norm = 9.1400e-02, time/batch = 0.5840s	
1182/2700 (epoch 21.889), train_loss = 1.89900888, grad/param norm = 8.6388e-02, time/batch = 0.5557s	
1183/2700 (epoch 21.907), train_loss = 2.01597835, grad/param norm = 1.2568e-01, time/batch = 0.5337s	
1184/2700 (epoch 21.926), train_loss = 1.95768139, grad/param norm = 1.4858e-01, time/batch = 0.5389s	
1185/2700 (epoch 21.944), train_loss = 1.95959539, grad/param norm = 1.2576e-01, time/batch = 0.5189s	
1186/2700 (epoch 21.963), train_loss = 1.98180438, grad/param norm = 1.1063e-01, time/batch = 0.5771s	
1187/2700 (epoch 21.981), train_loss = 1.90053068, grad/param norm = 9.3221e-02, time/batch = 0.5907s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1188/2700 (epoch 22.000), train_loss = 1.95157827, grad/param norm = 9.7788e-02, time/batch = 0.5389s	
1189/2700 (epoch 22.019), train_loss = 1.95658508, grad/param norm = 1.4355e-01, time/batch = 0.5459s	
1190/2700 (epoch 22.037), train_loss = 1.97495434, grad/param norm = 2.0244e-01, time/batch = 0.5801s	
1191/2700 (epoch 22.056), train_loss = 1.95232275, grad/param norm = 2.5264e-01, time/batch = 0.5244s	
1192/2700 (epoch 22.074), train_loss = 1.94755309, grad/param norm = 3.0085e-01, time/batch = 0.5449s	
1193/2700 (epoch 22.093), train_loss = 1.95768555, grad/param norm = 3.6278e-01, time/batch = 0.5543s	
1194/2700 (epoch 22.111), train_loss = 1.89636795, grad/param norm = 3.1841e-01, time/batch = 0.5637s	
1195/2700 (epoch 22.130), train_loss = 1.93436736, grad/param norm = 2.2747e-01, time/batch = 0.5721s	
1196/2700 (epoch 22.148), train_loss = 1.87816407, grad/param norm = 1.6984e-01, time/batch = 0.5609s	
1197/2700 (epoch 22.167), train_loss = 1.93272912, grad/param norm = 1.3035e-01, time/batch = 0.5385s	
1198/2700 (epoch 22.185), train_loss = 1.84990844, grad/param norm = 9.9999e-02, time/batch = 0.5547s	
1199/2700 (epoch 22.204), train_loss = 1.88663839, grad/param norm = 9.8734e-02, time/batch = 0.5475s	
1200/2700 (epoch 22.222), train_loss = 1.82810442, grad/param norm = 1.1089e-01, time/batch = 0.5658s	
1201/2700 (epoch 22.241), train_loss = 1.76324771, grad/param norm = 1.2486e-01, time/batch = 0.5496s	
1202/2700 (epoch 22.259), train_loss = 1.83261440, grad/param norm = 1.4483e-01, time/batch = 0.5965s	
1203/2700 (epoch 22.278), train_loss = 1.89981414, grad/param norm = 1.4305e-01, time/batch = 0.5546s	
1204/2700 (epoch 22.296), train_loss = 1.89912846, grad/param norm = 1.6871e-01, time/batch = 0.5506s	
1205/2700 (epoch 22.315), train_loss = 1.90059171, grad/param norm = 2.2545e-01, time/batch = 0.5358s	
1206/2700 (epoch 22.333), train_loss = 1.92346620, grad/param norm = 2.0673e-01, time/batch = 0.5378s	
1207/2700 (epoch 22.352), train_loss = 1.91198187, grad/param norm = 1.5603e-01, time/batch = 0.5504s	
1208/2700 (epoch 22.370), train_loss = 1.93198940, grad/param norm = 1.6909e-01, time/batch = 0.5588s	
1209/2700 (epoch 22.389), train_loss = 1.90017264, grad/param norm = 1.9843e-01, time/batch = 0.5672s	
1210/2700 (epoch 22.407), train_loss = 1.95619070, grad/param norm = 2.1680e-01, time/batch = 0.5448s	
1211/2700 (epoch 22.426), train_loss = 1.96925336, grad/param norm = 2.1138e-01, time/batch = 0.6005s	
1212/2700 (epoch 22.444), train_loss = 1.85212869, grad/param norm = 1.9876e-01, time/batch = 0.5550s	
1213/2700 (epoch 22.463), train_loss = 1.92844070, grad/param norm = 1.8489e-01, time/batch = 0.5501s	
1214/2700 (epoch 22.481), train_loss = 1.92873353, grad/param norm = 1.5250e-01, time/batch = 0.5451s	
1215/2700 (epoch 22.500), train_loss = 1.86571265, grad/param norm = 1.2462e-01, time/batch = 0.5426s	
1216/2700 (epoch 22.519), train_loss = 1.88306919, grad/param norm = 1.0467e-01, time/batch = 0.5589s	
1217/2700 (epoch 22.537), train_loss = 1.91161280, grad/param norm = 1.2084e-01, time/batch = 0.5559s	
1218/2700 (epoch 22.556), train_loss = 1.84255373, grad/param norm = 1.3099e-01, time/batch = 0.5763s	
1219/2700 (epoch 22.574), train_loss = 1.86065642, grad/param norm = 1.7129e-01, time/batch = 0.5494s	
1220/2700 (epoch 22.593), train_loss = 1.88571769, grad/param norm = 2.2740e-01, time/batch = 0.5612s	
1221/2700 (epoch 22.611), train_loss = 1.81948648, grad/param norm = 2.6156e-01, time/batch = 0.5491s	
1222/2700 (epoch 22.630), train_loss = 1.85666916, grad/param norm = 2.4525e-01, time/batch = 0.5476s	
1223/2700 (epoch 22.648), train_loss = 1.86183090, grad/param norm = 1.9913e-01, time/batch = 0.5289s	
1224/2700 (epoch 22.667), train_loss = 1.85893906, grad/param norm = 1.9186e-01, time/batch = 0.5609s	
1225/2700 (epoch 22.685), train_loss = 1.87199278, grad/param norm = 2.0331e-01, time/batch = 0.5500s	
1226/2700 (epoch 22.704), train_loss = 1.88195978, grad/param norm = 1.5623e-01, time/batch = 0.5706s	
1227/2700 (epoch 22.722), train_loss = 1.83643717, grad/param norm = 1.1846e-01, time/batch = 0.5577s	
1228/2700 (epoch 22.741), train_loss = 1.85202946, grad/param norm = 1.4670e-01, time/batch = 0.5522s	
1229/2700 (epoch 22.759), train_loss = 1.89018167, grad/param norm = 1.6458e-01, time/batch = 0.5591s	
1230/2700 (epoch 22.778), train_loss = 1.93446982, grad/param norm = 1.5244e-01, time/batch = 0.5715s	
1231/2700 (epoch 22.796), train_loss = 1.86547439, grad/param norm = 1.5505e-01, time/batch = 0.5310s	
1232/2700 (epoch 22.815), train_loss = 1.90226001, grad/param norm = 1.6142e-01, time/batch = 0.5402s	
1233/2700 (epoch 22.833), train_loss = 1.88508300, grad/param norm = 1.8116e-01, time/batch = 0.5437s	
1234/2700 (epoch 22.852), train_loss = 1.89257330, grad/param norm = 2.3284e-01, time/batch = 0.6042s	
1235/2700 (epoch 22.870), train_loss = 1.93635731, grad/param norm = 2.4307e-01, time/batch = 0.5731s	
1236/2700 (epoch 22.889), train_loss = 1.92107551, grad/param norm = 2.3788e-01, time/batch = 0.5414s	
1237/2700 (epoch 22.907), train_loss = 2.02793162, grad/param norm = 2.0163e-01, time/batch = 0.5355s	
1238/2700 (epoch 22.926), train_loss = 1.94692790, grad/param norm = 1.8828e-01, time/batch = 0.5747s	
1239/2700 (epoch 22.944), train_loss = 1.94109177, grad/param norm = 1.4849e-01, time/batch = 0.5565s	
1240/2700 (epoch 22.963), train_loss = 1.93481796, grad/param norm = 1.1931e-01, time/batch = 0.5156s	
1241/2700 (epoch 22.981), train_loss = 1.85187550, grad/param norm = 1.1460e-01, time/batch = 0.5320s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1242/2700 (epoch 23.000), train_loss = 1.90946071, grad/param norm = 1.4589e-01, time/batch = 0.5902s	
1243/2700 (epoch 23.019), train_loss = 1.92134229, grad/param norm = 2.2484e-01, time/batch = 0.5861s	
1244/2700 (epoch 23.037), train_loss = 1.96096118, grad/param norm = 3.0151e-01, time/batch = 0.5540s	
1245/2700 (epoch 23.056), train_loss = 1.91985114, grad/param norm = 2.7474e-01, time/batch = 0.5450s	
1246/2700 (epoch 23.074), train_loss = 1.87443074, grad/param norm = 2.3123e-01, time/batch = 0.5705s	
1247/2700 (epoch 23.093), train_loss = 1.86784329, grad/param norm = 2.1034e-01, time/batch = 0.5715s	
1248/2700 (epoch 23.111), train_loss = 1.79680660, grad/param norm = 1.6025e-01, time/batch = 0.5189s	
1249/2700 (epoch 23.130), train_loss = 1.86856688, grad/param norm = 1.2492e-01, time/batch = 0.5422s	
1250/2700 (epoch 23.148), train_loss = 1.82351579, grad/param norm = 1.1168e-01, time/batch = 0.5403s	
1251/2700 (epoch 23.167), train_loss = 1.88875206, grad/param norm = 9.6934e-02, time/batch = 0.5815s	
1252/2700 (epoch 23.185), train_loss = 1.80433510, grad/param norm = 8.3069e-02, time/batch = 0.5564s	
1253/2700 (epoch 23.204), train_loss = 1.84107719, grad/param norm = 9.0995e-02, time/batch = 0.5481s	
1254/2700 (epoch 23.222), train_loss = 1.78714179, grad/param norm = 1.1307e-01, time/batch = 0.5432s	
1255/2700 (epoch 23.241), train_loss = 1.71968516, grad/param norm = 1.2644e-01, time/batch = 0.5669s	
1256/2700 (epoch 23.259), train_loss = 1.78165929, grad/param norm = 1.4299e-01, time/batch = 0.5328s	
1257/2700 (epoch 23.278), train_loss = 1.85145163, grad/param norm = 1.3153e-01, time/batch = 0.5592s	
1258/2700 (epoch 23.296), train_loss = 1.85406977, grad/param norm = 1.6514e-01, time/batch = 0.5467s	
1259/2700 (epoch 23.315), train_loss = 1.85994584, grad/param norm = 2.0695e-01, time/batch = 0.5427s	
1260/2700 (epoch 23.333), train_loss = 1.86843156, grad/param norm = 1.7272e-01, time/batch = 0.6056s	
1261/2700 (epoch 23.352), train_loss = 1.86340541, grad/param norm = 1.4449e-01, time/batch = 0.5725s	
1262/2700 (epoch 23.370), train_loss = 1.88342362, grad/param norm = 1.4645e-01, time/batch = 0.5428s	
1263/2700 (epoch 23.389), train_loss = 1.83061030, grad/param norm = 1.2935e-01, time/batch = 0.5593s	
1264/2700 (epoch 23.407), train_loss = 1.88779183, grad/param norm = 1.3560e-01, time/batch = 0.5457s	
1265/2700 (epoch 23.426), train_loss = 1.91244898, grad/param norm = 1.6610e-01, time/batch = 0.5516s	
1266/2700 (epoch 23.444), train_loss = 1.81691890, grad/param norm = 2.2422e-01, time/batch = 0.5472s	
1267/2700 (epoch 23.463), train_loss = 1.91839017, grad/param norm = 2.4543e-01, time/batch = 0.5427s	
1268/2700 (epoch 23.481), train_loss = 1.89996880, grad/param norm = 1.8995e-01, time/batch = 0.5803s	
1269/2700 (epoch 23.500), train_loss = 1.81604261, grad/param norm = 1.2954e-01, time/batch = 0.5943s	
1270/2700 (epoch 23.519), train_loss = 1.84482262, grad/param norm = 1.3205e-01, time/batch = 0.5697s	
1271/2700 (epoch 23.537), train_loss = 1.88767762, grad/param norm = 1.6417e-01, time/batch = 0.5682s	
1272/2700 (epoch 23.556), train_loss = 1.81025841, grad/param norm = 1.6490e-01, time/batch = 0.5392s	
1273/2700 (epoch 23.574), train_loss = 1.83252683, grad/param norm = 1.9809e-01, time/batch = 0.5622s	
1274/2700 (epoch 23.593), train_loss = 1.85116870, grad/param norm = 1.8928e-01, time/batch = 0.5389s	
1275/2700 (epoch 23.611), train_loss = 1.75334685, grad/param norm = 1.6661e-01, time/batch = 0.5406s	
1276/2700 (epoch 23.630), train_loss = 1.79303950, grad/param norm = 1.5776e-01, time/batch = 0.5928s	
1277/2700 (epoch 23.648), train_loss = 1.81697357, grad/param norm = 1.6080e-01, time/batch = 0.5834s	
1278/2700 (epoch 23.667), train_loss = 1.83823448, grad/param norm = 2.0252e-01, time/batch = 0.5642s	
1279/2700 (epoch 23.685), train_loss = 1.87317210, grad/param norm = 2.5010e-01, time/batch = 0.5376s	
1280/2700 (epoch 23.704), train_loss = 1.87577657, grad/param norm = 1.9728e-01, time/batch = 0.5348s	
1281/2700 (epoch 23.722), train_loss = 1.81703812, grad/param norm = 1.3032e-01, time/batch = 0.5652s	
1282/2700 (epoch 23.741), train_loss = 1.81499832, grad/param norm = 1.2926e-01, time/batch = 0.5556s	
1283/2700 (epoch 23.759), train_loss = 1.84738550, grad/param norm = 1.2590e-01, time/batch = 0.5324s	
1284/2700 (epoch 23.778), train_loss = 1.89531031, grad/param norm = 1.1749e-01, time/batch = 0.5480s	
1285/2700 (epoch 23.796), train_loss = 1.82176333, grad/param norm = 1.1269e-01, time/batch = 0.6280s	
1286/2700 (epoch 23.815), train_loss = 1.85182573, grad/param norm = 8.9123e-02, time/batch = 0.5789s	
1287/2700 (epoch 23.833), train_loss = 1.82218476, grad/param norm = 9.5749e-02, time/batch = 0.5359s	
1288/2700 (epoch 23.852), train_loss = 1.81627542, grad/param norm = 1.0607e-01, time/batch = 0.5290s	
1289/2700 (epoch 23.870), train_loss = 1.84196572, grad/param norm = 1.6094e-01, time/batch = 0.5713s	
1290/2700 (epoch 23.889), train_loss = 1.86641269, grad/param norm = 2.5562e-01, time/batch = 0.5630s	
1291/2700 (epoch 23.907), train_loss = 2.01228211, grad/param norm = 2.9822e-01, time/batch = 0.5490s	
1292/2700 (epoch 23.926), train_loss = 1.92398160, grad/param norm = 2.7108e-01, time/batch = 0.5516s	
1293/2700 (epoch 23.944), train_loss = 1.89658102, grad/param norm = 2.0971e-01, time/batch = 0.5999s	
1294/2700 (epoch 23.963), train_loss = 1.90102144, grad/param norm = 1.6627e-01, time/batch = 0.5574s	
1295/2700 (epoch 23.981), train_loss = 1.82947896, grad/param norm = 1.5639e-01, time/batch = 0.5389s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1296/2700 (epoch 24.000), train_loss = 1.89413623, grad/param norm = 1.3999e-01, time/batch = 0.5291s	
1297/2700 (epoch 24.019), train_loss = 1.89230793, grad/param norm = 1.4983e-01, time/batch = 0.5799s	
1298/2700 (epoch 24.037), train_loss = 1.88753170, grad/param norm = 1.1391e-01, time/batch = 0.5561s	
1299/2700 (epoch 24.056), train_loss = 1.84276537, grad/param norm = 1.1534e-01, time/batch = 0.5480s	
1300/2700 (epoch 24.074), train_loss = 1.80927587, grad/param norm = 1.1896e-01, time/batch = 0.5429s	
1301/2700 (epoch 24.093), train_loss = 1.79841444, grad/param norm = 1.0025e-01, time/batch = 0.5507s	
1302/2700 (epoch 24.111), train_loss = 1.74772751, grad/param norm = 1.0489e-01, time/batch = 0.6059s	
1303/2700 (epoch 24.130), train_loss = 1.82781061, grad/param norm = 1.1385e-01, time/batch = 0.5462s	
1304/2700 (epoch 24.148), train_loss = 1.77335354, grad/param norm = 1.0564e-01, time/batch = 0.5306s	
1305/2700 (epoch 24.167), train_loss = 1.85025405, grad/param norm = 1.1667e-01, time/batch = 0.5630s	
1306/2700 (epoch 24.185), train_loss = 1.77490451, grad/param norm = 1.4308e-01, time/batch = 0.5676s	
1307/2700 (epoch 24.204), train_loss = 1.82960065, grad/param norm = 2.1561e-01, time/batch = 0.5550s	
1308/2700 (epoch 24.222), train_loss = 1.79718421, grad/param norm = 2.5176e-01, time/batch = 0.5465s	
1309/2700 (epoch 24.241), train_loss = 1.72835364, grad/param norm = 2.7632e-01, time/batch = 0.5706s	
1310/2700 (epoch 24.259), train_loss = 1.79766215, grad/param norm = 2.8253e-01, time/batch = 0.5961s	
1311/2700 (epoch 24.278), train_loss = 1.83721382, grad/param norm = 2.1763e-01, time/batch = 0.5371s	
1312/2700 (epoch 24.296), train_loss = 1.82848558, grad/param norm = 2.0104e-01, time/batch = 0.5318s	
1313/2700 (epoch 24.315), train_loss = 1.81130611, grad/param norm = 1.5786e-01, time/batch = 0.5712s	
1314/2700 (epoch 24.333), train_loss = 1.80659942, grad/param norm = 8.8260e-02, time/batch = 0.5736s	
1315/2700 (epoch 24.352), train_loss = 1.81352241, grad/param norm = 9.6564e-02, time/batch = 0.5428s	
1316/2700 (epoch 24.370), train_loss = 1.83583063, grad/param norm = 1.2224e-01, time/batch = 0.5448s	
1317/2700 (epoch 24.389), train_loss = 1.78789174, grad/param norm = 1.2753e-01, time/batch = 0.5674s	
1318/2700 (epoch 24.407), train_loss = 1.83716250, grad/param norm = 1.3057e-01, time/batch = 0.5912s	
1319/2700 (epoch 24.426), train_loss = 1.85286979, grad/param norm = 1.0011e-01, time/batch = 0.5202s	
1320/2700 (epoch 24.444), train_loss = 1.75511858, grad/param norm = 9.8360e-02, time/batch = 0.5522s	
1321/2700 (epoch 24.463), train_loss = 1.84983897, grad/param norm = 1.4804e-01, time/batch = 0.5894s	
1322/2700 (epoch 24.481), train_loss = 1.86008400, grad/param norm = 2.0307e-01, time/batch = 0.5596s	
1323/2700 (epoch 24.500), train_loss = 1.81036911, grad/param norm = 2.9175e-01, time/batch = 0.5391s	
1324/2700 (epoch 24.519), train_loss = 1.86291829, grad/param norm = 3.2312e-01, time/batch = 0.5457s	
1325/2700 (epoch 24.537), train_loss = 1.88352827, grad/param norm = 2.4669e-01, time/batch = 0.5573s	
1326/2700 (epoch 24.556), train_loss = 1.79211940, grad/param norm = 2.0241e-01, time/batch = 0.5898s	
1327/2700 (epoch 24.574), train_loss = 1.81186173, grad/param norm = 2.0746e-01, time/batch = 0.5469s	
1328/2700 (epoch 24.593), train_loss = 1.82344752, grad/param norm = 1.8543e-01, time/batch = 0.5191s	
1329/2700 (epoch 24.611), train_loss = 1.71280886, grad/param norm = 1.4401e-01, time/batch = 0.5339s	
1330/2700 (epoch 24.630), train_loss = 1.74958576, grad/param norm = 1.2360e-01, time/batch = 0.5306s	
1331/2700 (epoch 24.648), train_loss = 1.75760766, grad/param norm = 1.3541e-01, time/batch = 0.5806s	
1332/2700 (epoch 24.667), train_loss = 1.75933318, grad/param norm = 1.4239e-01, time/batch = 0.5673s	
1333/2700 (epoch 24.685), train_loss = 1.77462510, grad/param norm = 1.3228e-01, time/batch = 0.5451s	
1334/2700 (epoch 24.704), train_loss = 1.80908699, grad/param norm = 1.5671e-01, time/batch = 0.5567s	
1335/2700 (epoch 24.722), train_loss = 1.77532903, grad/param norm = 1.6682e-01, time/batch = 0.5942s	
1336/2700 (epoch 24.741), train_loss = 1.79007030, grad/param norm = 1.7425e-01, time/batch = 0.5574s	
1337/2700 (epoch 24.759), train_loss = 1.84079754, grad/param norm = 2.4353e-01, time/batch = 0.5216s	
1338/2700 (epoch 24.778), train_loss = 1.91561058, grad/param norm = 2.7343e-01, time/batch = 0.5354s	
1339/2700 (epoch 24.796), train_loss = 1.81871259, grad/param norm = 2.2462e-01, time/batch = 0.5446s	
1340/2700 (epoch 24.815), train_loss = 1.83266920, grad/param norm = 1.9287e-01, time/batch = 0.5779s	
1341/2700 (epoch 24.833), train_loss = 1.79462001, grad/param norm = 1.6389e-01, time/batch = 0.5587s	
1342/2700 (epoch 24.852), train_loss = 1.78208776, grad/param norm = 1.3064e-01, time/batch = 0.5474s	
1343/2700 (epoch 24.870), train_loss = 1.81076601, grad/param norm = 1.3272e-01, time/batch = 0.5710s	
1344/2700 (epoch 24.889), train_loss = 1.80398936, grad/param norm = 1.2276e-01, time/batch = 0.5777s	
1345/2700 (epoch 24.907), train_loss = 1.90607797, grad/param norm = 1.2963e-01, time/batch = 0.5150s	
1346/2700 (epoch 24.926), train_loss = 1.84100781, grad/param norm = 1.3976e-01, time/batch = 0.5552s	
1347/2700 (epoch 24.944), train_loss = 1.84877269, grad/param norm = 1.9973e-01, time/batch = 0.5384s	
1348/2700 (epoch 24.963), train_loss = 1.88600997, grad/param norm = 2.3297e-01, time/batch = 0.5557s	
1349/2700 (epoch 24.981), train_loss = 1.81347139, grad/param norm = 2.1907e-01, time/batch = 0.5856s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1350/2700 (epoch 25.000), train_loss = 1.86081104, grad/param norm = 1.9309e-01, time/batch = 0.5657s	
1351/2700 (epoch 25.019), train_loss = 1.84870931, grad/param norm = 1.6894e-01, time/batch = 0.5518s	
1352/2700 (epoch 25.037), train_loss = 1.84548671, grad/param norm = 1.5185e-01, time/batch = 0.5811s	
1353/2700 (epoch 25.056), train_loss = 1.82020686, grad/param norm = 1.8836e-01, time/batch = 0.5293s	
1354/2700 (epoch 25.074), train_loss = 1.79286472, grad/param norm = 1.9911e-01, time/batch = 0.5611s	
1355/2700 (epoch 25.093), train_loss = 1.78096135, grad/param norm = 1.5838e-01, time/batch = 0.5366s	
1356/2700 (epoch 25.111), train_loss = 1.72035588, grad/param norm = 1.3139e-01, time/batch = 0.5371s	
1357/2700 (epoch 25.130), train_loss = 1.80779756, grad/param norm = 1.3539e-01, time/batch = 0.5729s	
1358/2700 (epoch 25.148), train_loss = 1.74047796, grad/param norm = 1.0773e-01, time/batch = 0.5845s	
1359/2700 (epoch 25.167), train_loss = 1.81240350, grad/param norm = 8.9732e-02, time/batch = 0.5725s	
1360/2700 (epoch 25.185), train_loss = 1.73496141, grad/param norm = 8.4031e-02, time/batch = 0.5530s	
1361/2700 (epoch 25.204), train_loss = 1.76536881, grad/param norm = 9.3409e-02, time/batch = 0.5361s	
1362/2700 (epoch 25.222), train_loss = 1.71922629, grad/param norm = 8.8575e-02, time/batch = 0.5661s	
1363/2700 (epoch 25.241), train_loss = 1.64298347, grad/param norm = 8.4848e-02, time/batch = 0.5524s	
1364/2700 (epoch 25.259), train_loss = 1.70883567, grad/param norm = 9.3879e-02, time/batch = 0.5459s	
1365/2700 (epoch 25.278), train_loss = 1.78060496, grad/param norm = 1.0462e-01, time/batch = 0.5815s	
1366/2700 (epoch 25.296), train_loss = 1.77446050, grad/param norm = 1.3138e-01, time/batch = 0.5612s	
1367/2700 (epoch 25.315), train_loss = 1.78214785, grad/param norm = 1.9313e-01, time/batch = 0.5532s	
1368/2700 (epoch 25.333), train_loss = 1.82682290, grad/param norm = 3.5071e-01, time/batch = 0.5476s	
1369/2700 (epoch 25.352), train_loss = 1.89802392, grad/param norm = 3.9968e-01, time/batch = 0.5414s	
1370/2700 (epoch 25.370), train_loss = 1.87164284, grad/param norm = 2.8668e-01, time/batch = 0.5693s	
1371/2700 (epoch 25.389), train_loss = 1.77443660, grad/param norm = 1.8226e-01, time/batch = 0.5497s	
1372/2700 (epoch 25.407), train_loss = 1.81186428, grad/param norm = 1.1542e-01, time/batch = 0.5343s	
1373/2700 (epoch 25.426), train_loss = 1.82356884, grad/param norm = 1.0180e-01, time/batch = 0.5423s	
1374/2700 (epoch 25.444), train_loss = 1.72604061, grad/param norm = 9.6494e-02, time/batch = 0.5998s	
1375/2700 (epoch 25.463), train_loss = 1.80833870, grad/param norm = 9.3110e-02, time/batch = 0.5726s	
1376/2700 (epoch 25.481), train_loss = 1.80653913, grad/param norm = 1.0336e-01, time/batch = 0.5457s	
1377/2700 (epoch 25.500), train_loss = 1.72848823, grad/param norm = 1.1934e-01, time/batch = 0.5263s	
1378/2700 (epoch 25.519), train_loss = 1.76511365, grad/param norm = 9.4564e-02, time/batch = 0.5448s	
1379/2700 (epoch 25.537), train_loss = 1.79495814, grad/param norm = 9.7789e-02, time/batch = 0.5524s	
1380/2700 (epoch 25.556), train_loss = 1.71545650, grad/param norm = 1.1843e-01, time/batch = 0.5834s	
1381/2700 (epoch 25.574), train_loss = 1.73203133, grad/param norm = 1.5273e-01, time/batch = 0.5226s	
1382/2700 (epoch 25.593), train_loss = 1.75636940, grad/param norm = 1.6086e-01, time/batch = 0.5770s	
1383/2700 (epoch 25.611), train_loss = 1.68456910, grad/param norm = 1.6370e-01, time/batch = 0.6085s	
1384/2700 (epoch 25.630), train_loss = 1.73628299, grad/param norm = 1.5627e-01, time/batch = 0.5338s	
1385/2700 (epoch 25.648), train_loss = 1.73851551, grad/param norm = 1.1966e-01, time/batch = 0.5185s	
1386/2700 (epoch 25.667), train_loss = 1.73412687, grad/param norm = 1.0774e-01, time/batch = 0.5534s	
1387/2700 (epoch 25.685), train_loss = 1.75347847, grad/param norm = 1.1953e-01, time/batch = 0.5403s	
1388/2700 (epoch 25.704), train_loss = 1.77707964, grad/param norm = 1.1964e-01, time/batch = 0.5708s	
1389/2700 (epoch 25.722), train_loss = 1.74274028, grad/param norm = 1.0951e-01, time/batch = 0.5634s	
1390/2700 (epoch 25.741), train_loss = 1.74734805, grad/param norm = 1.2039e-01, time/batch = 0.5342s	
1391/2700 (epoch 25.759), train_loss = 1.77297183, grad/param norm = 1.0774e-01, time/batch = 0.5786s	
1392/2700 (epoch 25.778), train_loss = 1.82111364, grad/param norm = 9.9598e-02, time/batch = 0.5563s	
1393/2700 (epoch 25.796), train_loss = 1.73783354, grad/param norm = 9.4212e-02, time/batch = 0.5378s	
1394/2700 (epoch 25.815), train_loss = 1.77542386, grad/param norm = 8.8738e-02, time/batch = 0.5185s	
1395/2700 (epoch 25.833), train_loss = 1.74632662, grad/param norm = 9.8237e-02, time/batch = 0.5313s	
1396/2700 (epoch 25.852), train_loss = 1.73904386, grad/param norm = 1.0627e-01, time/batch = 0.5584s	
1397/2700 (epoch 25.870), train_loss = 1.77585822, grad/param norm = 1.4369e-01, time/batch = 0.5842s	
1398/2700 (epoch 25.889), train_loss = 1.77468997, grad/param norm = 1.9769e-01, time/batch = 0.5739s	
1399/2700 (epoch 25.907), train_loss = 1.89875905, grad/param norm = 2.7826e-01, time/batch = 0.5105s	
1400/2700 (epoch 25.926), train_loss = 1.86444794, grad/param norm = 3.2467e-01, time/batch = 0.5486s	
1401/2700 (epoch 25.944), train_loss = 1.85243778, grad/param norm = 2.9594e-01, time/batch = 0.5815s	
1402/2700 (epoch 25.963), train_loss = 1.84332516, grad/param norm = 2.2405e-01, time/batch = 0.5203s	
1403/2700 (epoch 25.981), train_loss = 1.75880445, grad/param norm = 1.6756e-01, time/batch = 0.5546s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1404/2700 (epoch 26.000), train_loss = 1.81255051, grad/param norm = 1.3615e-01, time/batch = 0.5435s	
1405/2700 (epoch 26.019), train_loss = 1.81066949, grad/param norm = 1.1341e-01, time/batch = 0.5645s	
1406/2700 (epoch 26.037), train_loss = 1.79936803, grad/param norm = 8.0356e-02, time/batch = 0.5751s	
1407/2700 (epoch 26.056), train_loss = 1.75701907, grad/param norm = 8.5423e-02, time/batch = 0.5763s	
1408/2700 (epoch 26.074), train_loss = 1.73022928, grad/param norm = 7.8136e-02, time/batch = 0.5129s	
1409/2700 (epoch 26.093), train_loss = 1.71979934, grad/param norm = 8.3965e-02, time/batch = 0.5531s	
1410/2700 (epoch 26.111), train_loss = 1.66456881, grad/param norm = 9.7503e-02, time/batch = 0.5929s	
1411/2700 (epoch 26.130), train_loss = 1.74818182, grad/param norm = 1.1226e-01, time/batch = 0.5524s	
1412/2700 (epoch 26.148), train_loss = 1.70157482, grad/param norm = 1.2989e-01, time/batch = 0.5408s	
1413/2700 (epoch 26.167), train_loss = 1.78604981, grad/param norm = 1.4741e-01, time/batch = 0.5599s	
1414/2700 (epoch 26.185), train_loss = 1.71504995, grad/param norm = 1.5024e-01, time/batch = 0.5698s	
1415/2700 (epoch 26.204), train_loss = 1.75021697, grad/param norm = 1.6077e-01, time/batch = 0.5684s	
1416/2700 (epoch 26.222), train_loss = 1.71583118, grad/param norm = 1.6937e-01, time/batch = 0.5590s	
1417/2700 (epoch 26.241), train_loss = 1.63297767, grad/param norm = 1.8789e-01, time/batch = 0.4970s	
1418/2700 (epoch 26.259), train_loss = 1.70439909, grad/param norm = 1.7579e-01, time/batch = 0.5750s	
1419/2700 (epoch 26.278), train_loss = 1.75416088, grad/param norm = 1.5677e-01, time/batch = 0.5614s	
1420/2700 (epoch 26.296), train_loss = 1.74015995, grad/param norm = 1.5058e-01, time/batch = 0.5669s	
1421/2700 (epoch 26.315), train_loss = 1.73806649, grad/param norm = 1.6568e-01, time/batch = 0.5592s	
1422/2700 (epoch 26.333), train_loss = 1.75187050, grad/param norm = 2.3280e-01, time/batch = 0.5689s	
1423/2700 (epoch 26.352), train_loss = 1.78050087, grad/param norm = 2.3476e-01, time/batch = 0.5852s	
1424/2700 (epoch 26.370), train_loss = 1.78324563, grad/param norm = 1.7994e-01, time/batch = 0.5490s	
1425/2700 (epoch 26.389), train_loss = 1.71765634, grad/param norm = 1.2788e-01, time/batch = 0.5426s	
1426/2700 (epoch 26.407), train_loss = 1.76721290, grad/param norm = 9.2482e-02, time/batch = 0.5593s	
1427/2700 (epoch 26.426), train_loss = 1.79267523, grad/param norm = 1.0137e-01, time/batch = 0.5487s	
1428/2700 (epoch 26.444), train_loss = 1.69533570, grad/param norm = 9.9817e-02, time/batch = 0.5706s	
1429/2700 (epoch 26.463), train_loss = 1.78248691, grad/param norm = 9.3457e-02, time/batch = 0.5465s	
1430/2700 (epoch 26.481), train_loss = 1.77969753, grad/param norm = 1.1306e-01, time/batch = 0.5360s	
1431/2700 (epoch 26.500), train_loss = 1.71786667, grad/param norm = 1.4160e-01, time/batch = 0.5873s	
1432/2700 (epoch 26.519), train_loss = 1.75829472, grad/param norm = 1.3414e-01, time/batch = 0.5616s	
1433/2700 (epoch 26.537), train_loss = 1.77971360, grad/param norm = 1.1953e-01, time/batch = 0.5509s	
1434/2700 (epoch 26.556), train_loss = 1.69493350, grad/param norm = 1.5333e-01, time/batch = 0.5378s	
1435/2700 (epoch 26.574), train_loss = 1.71698711, grad/param norm = 1.6301e-01, time/batch = 0.5651s	
1436/2700 (epoch 26.593), train_loss = 1.72496787, grad/param norm = 1.6295e-01, time/batch = 0.5565s	
1437/2700 (epoch 26.611), train_loss = 1.64409767, grad/param norm = 1.4710e-01, time/batch = 0.5621s	
1438/2700 (epoch 26.630), train_loss = 1.68789413, grad/param norm = 1.2297e-01, time/batch = 0.5445s	
1439/2700 (epoch 26.648), train_loss = 1.69118561, grad/param norm = 1.0322e-01, time/batch = 0.5591s	
1440/2700 (epoch 26.667), train_loss = 1.68398824, grad/param norm = 8.9281e-02, time/batch = 0.5647s	
1441/2700 (epoch 26.685), train_loss = 1.70495923, grad/param norm = 1.0244e-01, time/batch = 0.5688s	
1442/2700 (epoch 26.704), train_loss = 1.73335546, grad/param norm = 9.2161e-02, time/batch = 0.5329s	
1443/2700 (epoch 26.722), train_loss = 1.69295742, grad/param norm = 7.4630e-02, time/batch = 0.5443s	
1444/2700 (epoch 26.741), train_loss = 1.69609051, grad/param norm = 1.0323e-01, time/batch = 0.5578s	
1445/2700 (epoch 26.759), train_loss = 1.73220222, grad/param norm = 1.4045e-01, time/batch = 0.5559s	
1446/2700 (epoch 26.778), train_loss = 1.79980869, grad/param norm = 1.8141e-01, time/batch = 0.5422s	
1447/2700 (epoch 26.796), train_loss = 1.74528086, grad/param norm = 2.2222e-01, time/batch = 0.5355s	
1448/2700 (epoch 26.815), train_loss = 1.78697459, grad/param norm = 2.3978e-01, time/batch = 0.5456s	
1449/2700 (epoch 26.833), train_loss = 1.77127928, grad/param norm = 2.5547e-01, time/batch = 0.5978s	
1450/2700 (epoch 26.852), train_loss = 1.75092168, grad/param norm = 2.3608e-01, time/batch = 0.5844s	
1451/2700 (epoch 26.870), train_loss = 1.76642180, grad/param norm = 1.8801e-01, time/batch = 0.5634s	
1452/2700 (epoch 26.889), train_loss = 1.73676699, grad/param norm = 1.4056e-01, time/batch = 0.5035s	
1453/2700 (epoch 26.907), train_loss = 1.84170258, grad/param norm = 1.3738e-01, time/batch = 0.5804s	
1454/2700 (epoch 26.926), train_loss = 1.79826228, grad/param norm = 1.8561e-01, time/batch = 0.5648s	
1455/2700 (epoch 26.944), train_loss = 1.79182981, grad/param norm = 1.8048e-01, time/batch = 0.5357s	
1456/2700 (epoch 26.963), train_loss = 1.80140083, grad/param norm = 1.9863e-01, time/batch = 0.5365s	
1457/2700 (epoch 26.981), train_loss = 1.74255367, grad/param norm = 2.2679e-01, time/batch = 0.6070s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1458/2700 (epoch 27.000), train_loss = 1.81974669, grad/param norm = 2.2866e-01, time/batch = 0.5679s	
1459/2700 (epoch 27.019), train_loss = 1.81997243, grad/param norm = 2.4808e-01, time/batch = 0.5451s	
1460/2700 (epoch 27.037), train_loss = 1.80257648, grad/param norm = 2.1088e-01, time/batch = 0.5382s	
1461/2700 (epoch 27.056), train_loss = 1.73510498, grad/param norm = 1.4426e-01, time/batch = 0.5618s	
1462/2700 (epoch 27.074), train_loss = 1.70416444, grad/param norm = 1.1415e-01, time/batch = 0.5697s	
1463/2700 (epoch 27.093), train_loss = 1.68987786, grad/param norm = 1.1049e-01, time/batch = 0.5445s	
1464/2700 (epoch 27.111), train_loss = 1.63146020, grad/param norm = 9.8418e-02, time/batch = 0.5422s	
1465/2700 (epoch 27.130), train_loss = 1.71040261, grad/param norm = 8.2238e-02, time/batch = 0.5847s	
1466/2700 (epoch 27.148), train_loss = 1.66288138, grad/param norm = 7.9154e-02, time/batch = 0.5593s	
1467/2700 (epoch 27.167), train_loss = 1.74342877, grad/param norm = 8.4901e-02, time/batch = 0.5170s	
1468/2700 (epoch 27.185), train_loss = 1.66836438, grad/param norm = 8.1015e-02, time/batch = 0.5566s	
1469/2700 (epoch 27.204), train_loss = 1.69962765, grad/param norm = 1.0052e-01, time/batch = 0.5392s	
1470/2700 (epoch 27.222), train_loss = 1.65715695, grad/param norm = 1.0831e-01, time/batch = 0.5375s	
1471/2700 (epoch 27.241), train_loss = 1.57782218, grad/param norm = 9.9250e-02, time/batch = 0.5703s	
1472/2700 (epoch 27.259), train_loss = 1.64959972, grad/param norm = 1.0971e-01, time/batch = 0.5502s	
1473/2700 (epoch 27.278), train_loss = 1.71024638, grad/param norm = 9.8661e-02, time/batch = 0.5407s	
1474/2700 (epoch 27.296), train_loss = 1.70498926, grad/param norm = 1.2115e-01, time/batch = 0.5782s	
1475/2700 (epoch 27.315), train_loss = 1.70137537, grad/param norm = 1.3381e-01, time/batch = 0.5699s	
1476/2700 (epoch 27.333), train_loss = 1.69306627, grad/param norm = 1.1520e-01, time/batch = 0.5699s	
1477/2700 (epoch 27.352), train_loss = 1.71585259, grad/param norm = 1.3099e-01, time/batch = 0.5460s	
1478/2700 (epoch 27.370), train_loss = 1.74122247, grad/param norm = 1.8138e-01, time/batch = 0.5396s	
1479/2700 (epoch 27.389), train_loss = 1.70347883, grad/param norm = 2.2271e-01, time/batch = 0.5599s	
1480/2700 (epoch 27.407), train_loss = 1.76885722, grad/param norm = 2.2429e-01, time/batch = 0.5744s	
1481/2700 (epoch 27.426), train_loss = 1.79410370, grad/param norm = 2.3900e-01, time/batch = 0.5482s	
1482/2700 (epoch 27.444), train_loss = 1.69391822, grad/param norm = 1.9795e-01, time/batch = 0.5812s	
1483/2700 (epoch 27.463), train_loss = 1.75066469, grad/param norm = 1.2270e-01, time/batch = 0.5433s	
1484/2700 (epoch 27.481), train_loss = 1.74223906, grad/param norm = 1.0599e-01, time/batch = 0.5582s	
1485/2700 (epoch 27.500), train_loss = 1.67385251, grad/param norm = 1.2310e-01, time/batch = 0.5475s	
1486/2700 (epoch 27.519), train_loss = 1.73122430, grad/param norm = 1.1291e-01, time/batch = 0.5442s	
1487/2700 (epoch 27.537), train_loss = 1.73781145, grad/param norm = 1.3069e-01, time/batch = 0.5729s	
1488/2700 (epoch 27.556), train_loss = 1.65209931, grad/param norm = 1.4098e-01, time/batch = 0.5554s	
1489/2700 (epoch 27.574), train_loss = 1.67902507, grad/param norm = 1.4794e-01, time/batch = 0.5624s	
1490/2700 (epoch 27.593), train_loss = 1.70566245, grad/param norm = 1.3216e-01, time/batch = 0.5424s	
1491/2700 (epoch 27.611), train_loss = 1.61357765, grad/param norm = 1.3136e-01, time/batch = 0.5768s	
1492/2700 (epoch 27.630), train_loss = 1.65805811, grad/param norm = 1.2551e-01, time/batch = 0.5607s	
1493/2700 (epoch 27.648), train_loss = 1.66237338, grad/param norm = 1.4702e-01, time/batch = 0.5656s	
1494/2700 (epoch 27.667), train_loss = 1.66992243, grad/param norm = 1.8035e-01, time/batch = 0.5337s	
1495/2700 (epoch 27.685), train_loss = 1.69259092, grad/param norm = 1.9778e-01, time/batch = 0.5509s	
1496/2700 (epoch 27.704), train_loss = 1.73095612, grad/param norm = 1.8437e-01, time/batch = 0.5787s	
1497/2700 (epoch 27.722), train_loss = 1.67176608, grad/param norm = 1.2391e-01, time/batch = 0.5599s	
1498/2700 (epoch 27.741), train_loss = 1.66716473, grad/param norm = 1.0190e-01, time/batch = 0.5462s	
1499/2700 (epoch 27.759), train_loss = 1.68690927, grad/param norm = 1.3101e-01, time/batch = 0.5269s	
1500/2700 (epoch 27.778), train_loss = 1.75302486, grad/param norm = 1.6326e-01, time/batch = 0.5612s	
1501/2700 (epoch 27.796), train_loss = 1.68714984, grad/param norm = 1.9690e-01, time/batch = 0.5661s	
1502/2700 (epoch 27.815), train_loss = 1.75115491, grad/param norm = 2.6791e-01, time/batch = 0.5617s	
1503/2700 (epoch 27.833), train_loss = 1.72019895, grad/param norm = 2.4535e-01, time/batch = 0.5439s	
1504/2700 (epoch 27.852), train_loss = 1.68838320, grad/param norm = 1.7453e-01, time/batch = 0.5642s	
1505/2700 (epoch 27.870), train_loss = 1.70620276, grad/param norm = 1.3940e-01, time/batch = 0.5864s	
1506/2700 (epoch 27.889), train_loss = 1.69318668, grad/param norm = 1.2941e-01, time/batch = 0.5438s	
1507/2700 (epoch 27.907), train_loss = 1.81199080, grad/param norm = 1.8081e-01, time/batch = 0.5323s	
1508/2700 (epoch 27.926), train_loss = 1.76266482, grad/param norm = 1.8919e-01, time/batch = 0.5389s	
1509/2700 (epoch 27.944), train_loss = 1.74040155, grad/param norm = 1.3296e-01, time/batch = 0.5456s	
1510/2700 (epoch 27.963), train_loss = 1.74790969, grad/param norm = 1.1712e-01, time/batch = 0.5706s	
1511/2700 (epoch 27.981), train_loss = 1.67738738, grad/param norm = 1.0017e-01, time/batch = 0.5563s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1512/2700 (epoch 28.000), train_loss = 1.75046261, grad/param norm = 9.2962e-02, time/batch = 0.5427s	
1513/2700 (epoch 28.019), train_loss = 1.75325329, grad/param norm = 9.8746e-02, time/batch = 0.5603s	
1514/2700 (epoch 28.037), train_loss = 1.73331995, grad/param norm = 8.7306e-02, time/batch = 0.5910s	
1515/2700 (epoch 28.056), train_loss = 1.69855172, grad/param norm = 1.0562e-01, time/batch = 0.5445s	
1516/2700 (epoch 28.074), train_loss = 1.68196826, grad/param norm = 1.2249e-01, time/batch = 0.5360s	
1517/2700 (epoch 28.093), train_loss = 1.66501775, grad/param norm = 1.0415e-01, time/batch = 0.5320s	
1518/2700 (epoch 28.111), train_loss = 1.61376460, grad/param norm = 1.0916e-01, time/batch = 0.5526s	
1519/2700 (epoch 28.130), train_loss = 1.69247999, grad/param norm = 1.1750e-01, time/batch = 0.5958s	
1520/2700 (epoch 28.148), train_loss = 1.63894699, grad/param norm = 1.0145e-01, time/batch = 0.5824s	
1521/2700 (epoch 28.167), train_loss = 1.71375553, grad/param norm = 1.0549e-01, time/batch = 0.5759s	
1522/2700 (epoch 28.185), train_loss = 1.64710818, grad/param norm = 1.1404e-01, time/batch = 0.5685s	
1523/2700 (epoch 28.204), train_loss = 1.68211596, grad/param norm = 1.4238e-01, time/batch = 0.5492s	
1524/2700 (epoch 28.222), train_loss = 1.64119548, grad/param norm = 1.5072e-01, time/batch = 0.5224s	
1525/2700 (epoch 28.241), train_loss = 1.56412022, grad/param norm = 1.4960e-01, time/batch = 0.5420s	
1526/2700 (epoch 28.259), train_loss = 1.63269724, grad/param norm = 1.5242e-01, time/batch = 0.6028s	
1527/2700 (epoch 28.278), train_loss = 1.68393433, grad/param norm = 1.1634e-01, time/batch = 0.5747s	
1528/2700 (epoch 28.296), train_loss = 1.67498294, grad/param norm = 1.3203e-01, time/batch = 0.5485s	
1529/2700 (epoch 28.315), train_loss = 1.66338729, grad/param norm = 1.3246e-01, time/batch = 0.5408s	
1530/2700 (epoch 28.333), train_loss = 1.65534892, grad/param norm = 1.0687e-01, time/batch = 0.5498s	
1531/2700 (epoch 28.352), train_loss = 1.68407917, grad/param norm = 1.0887e-01, time/batch = 0.5694s	
1532/2700 (epoch 28.370), train_loss = 1.70758047, grad/param norm = 1.4241e-01, time/batch = 0.5244s	
1533/2700 (epoch 28.389), train_loss = 1.66885382, grad/param norm = 1.7335e-01, time/batch = 0.5166s	
1534/2700 (epoch 28.407), train_loss = 1.73562640, grad/param norm = 1.7226e-01, time/batch = 0.5532s	
1535/2700 (epoch 28.426), train_loss = 1.76355495, grad/param norm = 1.9842e-01, time/batch = 0.5806s	
1536/2700 (epoch 28.444), train_loss = 1.66048118, grad/param norm = 1.4499e-01, time/batch = 0.5507s	
1537/2700 (epoch 28.463), train_loss = 1.71640951, grad/param norm = 8.7664e-02, time/batch = 0.5713s	
1538/2700 (epoch 28.481), train_loss = 1.71187954, grad/param norm = 1.0559e-01, time/batch = 0.5460s	
1539/2700 (epoch 28.500), train_loss = 1.63154318, grad/param norm = 1.2805e-01, time/batch = 0.5484s	
1540/2700 (epoch 28.519), train_loss = 1.68223708, grad/param norm = 1.1824e-01, time/batch = 0.5485s	
1541/2700 (epoch 28.537), train_loss = 1.70294551, grad/param norm = 1.1006e-01, time/batch = 0.5483s	
1542/2700 (epoch 28.556), train_loss = 1.61688039, grad/param norm = 1.1533e-01, time/batch = 0.5069s	
1543/2700 (epoch 28.574), train_loss = 1.63655864, grad/param norm = 1.2356e-01, time/batch = 0.5502s	
1544/2700 (epoch 28.593), train_loss = 1.66999568, grad/param norm = 1.5564e-01, time/batch = 0.6293s	
1545/2700 (epoch 28.611), train_loss = 1.59238802, grad/param norm = 1.9366e-01, time/batch = 0.5586s	
1546/2700 (epoch 28.630), train_loss = 1.64905262, grad/param norm = 2.2913e-01, time/batch = 0.5505s	
1547/2700 (epoch 28.648), train_loss = 1.66590070, grad/param norm = 2.4510e-01, time/batch = 0.5461s	
1548/2700 (epoch 28.667), train_loss = 1.65485864, grad/param norm = 1.9703e-01, time/batch = 0.5527s	
1549/2700 (epoch 28.685), train_loss = 1.65164416, grad/param norm = 1.4636e-01, time/batch = 0.5648s	
1550/2700 (epoch 28.704), train_loss = 1.68110924, grad/param norm = 1.0945e-01, time/batch = 0.5532s	
1551/2700 (epoch 28.722), train_loss = 1.63514652, grad/param norm = 7.0464e-02, time/batch = 0.5375s	
1552/2700 (epoch 28.741), train_loss = 1.63057077, grad/param norm = 7.9717e-02, time/batch = 0.6205s	
1553/2700 (epoch 28.759), train_loss = 1.64866388, grad/param norm = 7.3950e-02, time/batch = 0.5519s	
1554/2700 (epoch 28.778), train_loss = 1.70959864, grad/param norm = 8.9177e-02, time/batch = 0.5454s	
1555/2700 (epoch 28.796), train_loss = 1.63490565, grad/param norm = 9.0784e-02, time/batch = 0.5526s	
1556/2700 (epoch 28.815), train_loss = 1.68213341, grad/param norm = 8.6037e-02, time/batch = 0.5515s	
1557/2700 (epoch 28.833), train_loss = 1.66527081, grad/param norm = 1.1539e-01, time/batch = 0.5626s	
1558/2700 (epoch 28.852), train_loss = 1.66530038, grad/param norm = 1.9322e-01, time/batch = 0.5451s	
1559/2700 (epoch 28.870), train_loss = 1.73878393, grad/param norm = 2.5724e-01, time/batch = 0.5439s	
1560/2700 (epoch 28.889), train_loss = 1.71097970, grad/param norm = 2.2074e-01, time/batch = 0.5229s	
1561/2700 (epoch 28.907), train_loss = 1.78923543, grad/param norm = 1.5085e-01, time/batch = 0.5750s	
1562/2700 (epoch 28.926), train_loss = 1.71987083, grad/param norm = 1.2304e-01, time/batch = 0.5347s	
1563/2700 (epoch 28.944), train_loss = 1.70744816, grad/param norm = 1.2366e-01, time/batch = 0.5310s	
1564/2700 (epoch 28.963), train_loss = 1.71989546, grad/param norm = 1.2571e-01, time/batch = 0.5233s	
1565/2700 (epoch 28.981), train_loss = 1.65031812, grad/param norm = 1.1255e-01, time/batch = 0.5570s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
1566/2700 (epoch 29.000), train_loss = 1.72489956, grad/param norm = 1.1813e-01, time/batch = 0.5452s	
1567/2700 (epoch 29.019), train_loss = 1.72659022, grad/param norm = 9.9961e-02, time/batch = 0.5685s	
1568/2700 (epoch 29.037), train_loss = 1.70382637, grad/param norm = 8.9753e-02, time/batch = 0.5521s	
1569/2700 (epoch 29.056), train_loss = 1.67396858, grad/param norm = 1.1868e-01, time/batch = 0.5222s	
1570/2700 (epoch 29.074), train_loss = 1.65233953, grad/param norm = 1.0131e-01, time/batch = 0.5662s	
1571/2700 (epoch 29.093), train_loss = 1.63051842, grad/param norm = 1.0333e-01, time/batch = 0.5962s	
1572/2700 (epoch 29.111), train_loss = 1.57890983, grad/param norm = 1.2655e-01, time/batch = 0.5317s	
1573/2700 (epoch 29.130), train_loss = 1.66413043, grad/param norm = 1.3801e-01, time/batch = 0.5371s	
1574/2700 (epoch 29.148), train_loss = 1.62144253, grad/param norm = 1.3516e-01, time/batch = 0.5322s	
1575/2700 (epoch 29.167), train_loss = 1.69082016, grad/param norm = 1.2107e-01, time/batch = 0.5821s	
1576/2700 (epoch 29.185), train_loss = 1.61364742, grad/param norm = 9.7968e-02, time/batch = 0.5637s	
1577/2700 (epoch 29.204), train_loss = 1.64009640, grad/param norm = 9.0290e-02, time/batch = 0.5414s	
1578/2700 (epoch 29.222), train_loss = 1.60181899, grad/param norm = 1.0952e-01, time/batch = 0.5273s	
1579/2700 (epoch 29.241), train_loss = 1.53026575, grad/param norm = 1.5318e-01, time/batch = 0.5612s	
1580/2700 (epoch 29.259), train_loss = 1.61701380, grad/param norm = 1.6966e-01, time/batch = 0.5796s	
1581/2700 (epoch 29.278), train_loss = 1.67732179, grad/param norm = 1.7534e-01, time/batch = 0.5167s	
1582/2700 (epoch 29.296), train_loss = 1.65745391, grad/param norm = 1.7706e-01, time/batch = 0.5309s	
1583/2700 (epoch 29.315), train_loss = 1.65628756, grad/param norm = 2.0290e-01, time/batch = 0.5425s	
1584/2700 (epoch 29.333), train_loss = 1.66719194, grad/param norm = 2.7031e-01, time/batch = 0.5731s	
1585/2700 (epoch 29.352), train_loss = 1.70085399, grad/param norm = 2.7238e-01, time/batch = 0.5538s	
1586/2700 (epoch 29.370), train_loss = 1.70227956, grad/param norm = 1.8702e-01, time/batch = 0.5653s	
1587/2700 (epoch 29.389), train_loss = 1.62321508, grad/param norm = 1.2834e-01, time/batch = 0.4980s	
1588/2700 (epoch 29.407), train_loss = 1.68640586, grad/param norm = 1.1154e-01, time/batch = 0.5521s	
1589/2700 (epoch 29.426), train_loss = 1.70774807, grad/param norm = 1.0134e-01, time/batch = 0.5438s	
1590/2700 (epoch 29.444), train_loss = 1.60218211, grad/param norm = 8.4660e-02, time/batch = 0.5582s	
1591/2700 (epoch 29.463), train_loss = 1.69230614, grad/param norm = 1.1429e-01, time/batch = 0.5432s	
1592/2700 (epoch 29.481), train_loss = 1.69096579, grad/param norm = 1.4591e-01, time/batch = 0.5356s	
1593/2700 (epoch 29.500), train_loss = 1.62074431, grad/param norm = 1.4885e-01, time/batch = 0.5743s	
1594/2700 (epoch 29.519), train_loss = 1.66056134, grad/param norm = 1.1486e-01, time/batch = 0.5511s	
1595/2700 (epoch 29.537), train_loss = 1.67470748, grad/param norm = 1.0221e-01, time/batch = 0.5646s	
1596/2700 (epoch 29.556), train_loss = 1.58109259, grad/param norm = 1.1371e-01, time/batch = 0.5087s	
1597/2700 (epoch 29.574), train_loss = 1.60178344, grad/param norm = 1.0718e-01, time/batch = 0.5433s	
1598/2700 (epoch 29.593), train_loss = 1.62143306, grad/param norm = 9.6091e-02, time/batch = 0.5628s	
1599/2700 (epoch 29.611), train_loss = 1.53989237, grad/param norm = 8.6108e-02, time/batch = 0.5530s	
1600/2700 (epoch 29.630), train_loss = 1.59654721, grad/param norm = 1.1581e-01, time/batch = 0.5434s	
1601/2700 (epoch 29.648), train_loss = 1.61318050, grad/param norm = 1.3913e-01, time/batch = 0.5608s	
1602/2700 (epoch 29.667), train_loss = 1.60840615, grad/param norm = 1.6008e-01, time/batch = 0.5649s	
1603/2700 (epoch 29.685), train_loss = 1.64768816, grad/param norm = 2.1114e-01, time/batch = 0.5625s	
1604/2700 (epoch 29.704), train_loss = 1.67068738, grad/param norm = 1.9398e-01, time/batch = 0.5634s	
1605/2700 (epoch 29.722), train_loss = 1.62820830, grad/param norm = 1.4602e-01, time/batch = 0.4931s	
1606/2700 (epoch 29.741), train_loss = 1.60971151, grad/param norm = 1.3169e-01, time/batch = 0.5706s	
1607/2700 (epoch 29.759), train_loss = 1.62441164, grad/param norm = 9.6042e-02, time/batch = 0.5527s	
1608/2700 (epoch 29.778), train_loss = 1.67924402, grad/param norm = 8.7997e-02, time/batch = 0.5484s	
1609/2700 (epoch 29.796), train_loss = 1.60272727, grad/param norm = 8.8199e-02, time/batch = 0.5475s	
1610/2700 (epoch 29.815), train_loss = 1.64702840, grad/param norm = 7.3317e-02, time/batch = 0.5309s	
1611/2700 (epoch 29.833), train_loss = 1.62861358, grad/param norm = 9.4196e-02, time/batch = 0.5659s	
1612/2700 (epoch 29.852), train_loss = 1.62019558, grad/param norm = 1.1517e-01, time/batch = 0.5512s	
1613/2700 (epoch 29.870), train_loss = 1.65884084, grad/param norm = 1.3490e-01, time/batch = 0.5537s	
1614/2700 (epoch 29.889), train_loss = 1.64403580, grad/param norm = 1.1311e-01, time/batch = 0.4618s	
1615/2700 (epoch 29.907), train_loss = 1.73572985, grad/param norm = 9.7642e-02, time/batch = 0.5326s	
1616/2700 (epoch 29.926), train_loss = 1.68328723, grad/param norm = 9.9808e-02, time/batch = 0.5565s	
1617/2700 (epoch 29.944), train_loss = 1.68217613, grad/param norm = 1.1529e-01, time/batch = 0.5680s	
1618/2700 (epoch 29.963), train_loss = 1.70219700, grad/param norm = 1.3408e-01, time/batch = 0.5581s	
1619/2700 (epoch 29.981), train_loss = 1.65701175, grad/param norm = 1.6306e-01, time/batch = 0.5535s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
1620/2700 (epoch 30.000), train_loss = 1.73664683, grad/param norm = 1.6519e-01, time/batch = 0.5401s	
1621/2700 (epoch 30.019), train_loss = 1.73152992, grad/param norm = 1.5862e-01, time/batch = 0.5747s	
1622/2700 (epoch 30.037), train_loss = 1.69196934, grad/param norm = 1.5290e-01, time/batch = 0.5125s	
1623/2700 (epoch 30.056), train_loss = 1.64038500, grad/param norm = 1.3830e-01, time/batch = 0.5236s	
1624/2700 (epoch 30.074), train_loss = 1.62581633, grad/param norm = 1.4144e-01, time/batch = 0.5053s	
1625/2700 (epoch 30.093), train_loss = 1.60968446, grad/param norm = 1.6191e-01, time/batch = 0.4734s	
1626/2700 (epoch 30.111), train_loss = 1.55684742, grad/param norm = 1.4119e-01, time/batch = 0.5386s	
1627/2700 (epoch 30.130), train_loss = 1.63575478, grad/param norm = 1.1912e-01, time/batch = 0.5667s	
1628/2700 (epoch 30.148), train_loss = 1.58174461, grad/param norm = 9.0208e-02, time/batch = 0.5837s	
1629/2700 (epoch 30.167), train_loss = 1.65474154, grad/param norm = 8.2854e-02, time/batch = 0.5516s	
1630/2700 (epoch 30.185), train_loss = 1.58397704, grad/param norm = 8.0694e-02, time/batch = 0.5339s	
1631/2700 (epoch 30.204), train_loss = 1.61352401, grad/param norm = 1.0583e-01, time/batch = 0.4882s	
1632/2700 (epoch 30.222), train_loss = 1.57921992, grad/param norm = 1.2231e-01, time/batch = 0.4362s	
1633/2700 (epoch 30.241), train_loss = 1.50364494, grad/param norm = 1.3517e-01, time/batch = 0.5521s	
1634/2700 (epoch 30.259), train_loss = 1.58488082, grad/param norm = 1.5276e-01, time/batch = 0.5498s	
1635/2700 (epoch 30.278), train_loss = 1.64033903, grad/param norm = 1.4873e-01, time/batch = 0.5557s	
1636/2700 (epoch 30.296), train_loss = 1.63564390, grad/param norm = 1.9158e-01, time/batch = 0.5727s	
1637/2700 (epoch 30.315), train_loss = 1.63225917, grad/param norm = 2.2521e-01, time/batch = 0.5415s	
1638/2700 (epoch 30.333), train_loss = 1.62375545, grad/param norm = 1.8039e-01, time/batch = 0.5441s	
1639/2700 (epoch 30.352), train_loss = 1.64218676, grad/param norm = 1.4020e-01, time/batch = 0.5372s	
1640/2700 (epoch 30.370), train_loss = 1.64895414, grad/param norm = 1.4862e-01, time/batch = 0.5219s	
1641/2700 (epoch 30.389), train_loss = 1.59177691, grad/param norm = 1.2678e-01, time/batch = 0.5433s	
1642/2700 (epoch 30.407), train_loss = 1.65872146, grad/param norm = 1.1946e-01, time/batch = 0.5662s	
1643/2700 (epoch 30.426), train_loss = 1.69058308, grad/param norm = 1.3439e-01, time/batch = 0.5405s	
1644/2700 (epoch 30.444), train_loss = 1.58476595, grad/param norm = 1.2288e-01, time/batch = 0.5543s	
1645/2700 (epoch 30.463), train_loss = 1.67567295, grad/param norm = 1.1759e-01, time/batch = 0.5812s	
1646/2700 (epoch 30.481), train_loss = 1.66266024, grad/param norm = 1.1712e-01, time/batch = 0.5544s	
1647/2700 (epoch 30.500), train_loss = 1.57709457, grad/param norm = 9.7034e-02, time/batch = 0.5348s	
1648/2700 (epoch 30.519), train_loss = 1.62308307, grad/param norm = 8.2495e-02, time/batch = 0.5420s	
1649/2700 (epoch 30.537), train_loss = 1.64378227, grad/param norm = 1.4059e-01, time/batch = 0.5277s	
1650/2700 (epoch 30.556), train_loss = 1.55848596, grad/param norm = 1.8581e-01, time/batch = 0.5278s	
1651/2700 (epoch 30.574), train_loss = 1.59541340, grad/param norm = 2.0696e-01, time/batch = 0.5630s	
1652/2700 (epoch 30.593), train_loss = 1.61546443, grad/param norm = 1.7124e-01, time/batch = 0.5619s	
1653/2700 (epoch 30.611), train_loss = 1.52651104, grad/param norm = 1.3368e-01, time/batch = 0.5511s	
1654/2700 (epoch 30.630), train_loss = 1.57225883, grad/param norm = 1.3138e-01, time/batch = 0.5554s	
1655/2700 (epoch 30.648), train_loss = 1.57868752, grad/param norm = 1.1749e-01, time/batch = 0.6048s	
1656/2700 (epoch 30.667), train_loss = 1.57431117, grad/param norm = 1.1383e-01, time/batch = 0.5446s	
1657/2700 (epoch 30.685), train_loss = 1.59991969, grad/param norm = 1.3773e-01, time/batch = 0.4939s	
1658/2700 (epoch 30.704), train_loss = 1.62479686, grad/param norm = 1.0674e-01, time/batch = 0.5503s	
1659/2700 (epoch 30.722), train_loss = 1.58832488, grad/param norm = 8.3260e-02, time/batch = 0.5318s	
1660/2700 (epoch 30.741), train_loss = 1.57633956, grad/param norm = 8.4300e-02, time/batch = 0.5491s	
1661/2700 (epoch 30.759), train_loss = 1.59237742, grad/param norm = 9.4561e-02, time/batch = 0.5528s	
1662/2700 (epoch 30.778), train_loss = 1.65462143, grad/param norm = 1.3551e-01, time/batch = 0.5729s	
1663/2700 (epoch 30.796), train_loss = 1.58937653, grad/param norm = 1.7392e-01, time/batch = 0.5495s	
1664/2700 (epoch 30.815), train_loss = 1.65132037, grad/param norm = 2.3932e-01, time/batch = 0.5547s	
1665/2700 (epoch 30.833), train_loss = 1.63216877, grad/param norm = 2.3683e-01, time/batch = 0.5340s	
1666/2700 (epoch 30.852), train_loss = 1.61101021, grad/param norm = 1.7677e-01, time/batch = 0.5572s	
1667/2700 (epoch 30.870), train_loss = 1.62652861, grad/param norm = 1.3733e-01, time/batch = 0.5533s	
1668/2700 (epoch 30.889), train_loss = 1.61521295, grad/param norm = 1.1110e-01, time/batch = 0.5319s	
1669/2700 (epoch 30.907), train_loss = 1.71372279, grad/param norm = 1.3437e-01, time/batch = 0.5399s	
1670/2700 (epoch 30.926), train_loss = 1.66861553, grad/param norm = 1.3364e-01, time/batch = 0.5529s	
1671/2700 (epoch 30.944), train_loss = 1.65201566, grad/param norm = 1.1776e-01, time/batch = 0.5570s	
1672/2700 (epoch 30.963), train_loss = 1.65885600, grad/param norm = 1.2384e-01, time/batch = 0.5590s	
1673/2700 (epoch 30.981), train_loss = 1.59809454, grad/param norm = 1.1804e-01, time/batch = 0.5375s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
1674/2700 (epoch 31.000), train_loss = 1.67042254, grad/param norm = 1.1490e-01, time/batch = 0.5528s	
1675/2700 (epoch 31.019), train_loss = 1.68433362, grad/param norm = 1.2709e-01, time/batch = 0.5485s	
1676/2700 (epoch 31.037), train_loss = 1.65841404, grad/param norm = 1.4205e-01, time/batch = 0.5744s	
1677/2700 (epoch 31.056), train_loss = 1.61465504, grad/param norm = 1.1898e-01, time/batch = 0.5421s	
1678/2700 (epoch 31.074), train_loss = 1.59850859, grad/param norm = 1.0215e-01, time/batch = 0.5397s	
1679/2700 (epoch 31.093), train_loss = 1.57210063, grad/param norm = 9.1632e-02, time/batch = 0.5378s	
1680/2700 (epoch 31.111), train_loss = 1.52028131, grad/param norm = 8.1202e-02, time/batch = 0.5513s	
1681/2700 (epoch 31.130), train_loss = 1.60190485, grad/param norm = 8.9769e-02, time/batch = 0.5541s	
1682/2700 (epoch 31.148), train_loss = 1.56214485, grad/param norm = 1.0398e-01, time/batch = 0.5214s	
1683/2700 (epoch 31.167), train_loss = 1.63896133, grad/param norm = 1.2764e-01, time/batch = 0.5499s	
1684/2700 (epoch 31.185), train_loss = 1.57401178, grad/param norm = 1.3949e-01, time/batch = 0.5360s	
1685/2700 (epoch 31.204), train_loss = 1.59698785, grad/param norm = 1.3473e-01, time/batch = 0.5534s	
1686/2700 (epoch 31.222), train_loss = 1.55191915, grad/param norm = 1.1793e-01, time/batch = 0.5818s	
1687/2700 (epoch 31.241), train_loss = 1.47167005, grad/param norm = 1.0414e-01, time/batch = 0.5471s	
1688/2700 (epoch 31.259), train_loss = 1.54815710, grad/param norm = 1.0265e-01, time/batch = 0.5340s	
1689/2700 (epoch 31.278), train_loss = 1.60247088, grad/param norm = 8.8805e-02, time/batch = 0.5377s	
1690/2700 (epoch 31.296), train_loss = 1.59219930, grad/param norm = 9.4902e-02, time/batch = 0.5515s	
1691/2700 (epoch 31.315), train_loss = 1.57670568, grad/param norm = 9.4869e-02, time/batch = 0.5778s	
1692/2700 (epoch 31.333), train_loss = 1.56971396, grad/param norm = 1.0741e-01, time/batch = 0.5553s	
1693/2700 (epoch 31.352), train_loss = 1.60596756, grad/param norm = 1.4598e-01, time/batch = 0.5397s	
1694/2700 (epoch 31.370), train_loss = 1.62285085, grad/param norm = 1.6634e-01, time/batch = 0.5501s	
1695/2700 (epoch 31.389), train_loss = 1.59174103, grad/param norm = 1.9301e-01, time/batch = 0.5702s	
1696/2700 (epoch 31.407), train_loss = 1.68574831, grad/param norm = 2.2433e-01, time/batch = 0.5557s	
1697/2700 (epoch 31.426), train_loss = 1.68043661, grad/param norm = 1.5238e-01, time/batch = 0.5450s	
1698/2700 (epoch 31.444), train_loss = 1.56207135, grad/param norm = 1.2975e-01, time/batch = 0.5295s	
1699/2700 (epoch 31.463), train_loss = 1.65602233, grad/param norm = 1.5152e-01, time/batch = 0.5488s	
1700/2700 (epoch 31.481), train_loss = 1.64005007, grad/param norm = 1.6652e-01, time/batch = 0.5399s	
1701/2700 (epoch 31.500), train_loss = 1.57021613, grad/param norm = 1.8137e-01, time/batch = 0.5593s	
1702/2700 (epoch 31.519), train_loss = 1.61449690, grad/param norm = 1.3604e-01, time/batch = 0.5590s	
1703/2700 (epoch 31.537), train_loss = 1.61519674, grad/param norm = 9.9123e-02, time/batch = 0.5400s	
1704/2700 (epoch 31.556), train_loss = 1.52209197, grad/param norm = 1.0115e-01, time/batch = 0.5505s	
1705/2700 (epoch 31.574), train_loss = 1.55391789, grad/param norm = 1.4321e-01, time/batch = 0.5796s	
1706/2700 (epoch 31.593), train_loss = 1.60754722, grad/param norm = 1.7889e-01, time/batch = 0.5541s	
1707/2700 (epoch 31.611), train_loss = 1.51718597, grad/param norm = 1.8136e-01, time/batch = 0.5008s	
1708/2700 (epoch 31.630), train_loss = 1.55721838, grad/param norm = 1.4356e-01, time/batch = 0.5416s	
1709/2700 (epoch 31.648), train_loss = 1.56535877, grad/param norm = 1.2493e-01, time/batch = 0.5385s	
1710/2700 (epoch 31.667), train_loss = 1.55153659, grad/param norm = 1.0858e-01, time/batch = 0.5591s	
1711/2700 (epoch 31.685), train_loss = 1.56696758, grad/param norm = 1.0484e-01, time/batch = 0.5691s	
1712/2700 (epoch 31.704), train_loss = 1.59864509, grad/param norm = 9.6508e-02, time/batch = 0.5493s	
1713/2700 (epoch 31.722), train_loss = 1.56189605, grad/param norm = 7.7842e-02, time/batch = 0.5298s	
1714/2700 (epoch 31.741), train_loss = 1.54773484, grad/param norm = 8.1573e-02, time/batch = 0.5381s	
1715/2700 (epoch 31.759), train_loss = 1.56931456, grad/param norm = 1.3454e-01, time/batch = 0.5471s	
1716/2700 (epoch 31.778), train_loss = 1.63615161, grad/param norm = 1.7748e-01, time/batch = 0.5608s	
1717/2700 (epoch 31.796), train_loss = 1.57268276, grad/param norm = 1.9683e-01, time/batch = 0.5584s	
1718/2700 (epoch 31.815), train_loss = 1.62844420, grad/param norm = 2.0962e-01, time/batch = 0.5390s	
1719/2700 (epoch 31.833), train_loss = 1.59814900, grad/param norm = 1.5997e-01, time/batch = 0.5360s	
1720/2700 (epoch 31.852), train_loss = 1.56152678, grad/param norm = 9.7331e-02, time/batch = 0.5503s	
1721/2700 (epoch 31.870), train_loss = 1.59083234, grad/param norm = 9.3221e-02, time/batch = 0.5702s	
1722/2700 (epoch 31.889), train_loss = 1.58856653, grad/param norm = 1.1591e-01, time/batch = 0.5531s	
1723/2700 (epoch 31.907), train_loss = 1.69486818, grad/param norm = 1.3889e-01, time/batch = 0.4671s	
1724/2700 (epoch 31.926), train_loss = 1.64840837, grad/param norm = 1.4469e-01, time/batch = 0.5532s	
1725/2700 (epoch 31.944), train_loss = 1.62953247, grad/param norm = 1.6144e-01, time/batch = 0.5394s	
1726/2700 (epoch 31.963), train_loss = 1.64054979, grad/param norm = 1.8555e-01, time/batch = 0.5665s	
1727/2700 (epoch 31.981), train_loss = 1.59339013, grad/param norm = 2.0165e-01, time/batch = 0.5498s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
1728/2700 (epoch 32.000), train_loss = 1.66394235, grad/param norm = 2.0094e-01, time/batch = 0.5438s	
1729/2700 (epoch 32.019), train_loss = 1.65962692, grad/param norm = 1.5830e-01, time/batch = 0.5350s	
1730/2700 (epoch 32.037), train_loss = 1.62017449, grad/param norm = 1.2075e-01, time/batch = 0.5490s	
1731/2700 (epoch 32.056), train_loss = 1.58725170, grad/param norm = 1.4629e-01, time/batch = 0.5494s	
1732/2700 (epoch 32.074), train_loss = 1.57566975, grad/param norm = 1.3425e-01, time/batch = 0.4868s	
1733/2700 (epoch 32.093), train_loss = 1.54271709, grad/param norm = 9.5028e-02, time/batch = 0.5515s	
1734/2700 (epoch 32.111), train_loss = 1.50041744, grad/param norm = 1.0110e-01, time/batch = 0.5497s	
1735/2700 (epoch 32.130), train_loss = 1.59170102, grad/param norm = 1.3888e-01, time/batch = 0.5539s	
1736/2700 (epoch 32.148), train_loss = 1.54974859, grad/param norm = 1.2864e-01, time/batch = 0.5793s	
1737/2700 (epoch 32.167), train_loss = 1.61457845, grad/param norm = 1.2654e-01, time/batch = 0.5404s	
1738/2700 (epoch 32.185), train_loss = 1.54544422, grad/param norm = 1.0729e-01, time/batch = 0.5437s	
1739/2700 (epoch 32.204), train_loss = 1.55961031, grad/param norm = 9.0585e-02, time/batch = 0.5425s	
1740/2700 (epoch 32.222), train_loss = 1.52562683, grad/param norm = 8.5505e-02, time/batch = 0.5382s	
1741/2700 (epoch 32.241), train_loss = 1.44573640, grad/param norm = 8.3520e-02, time/batch = 0.5381s	
1742/2700 (epoch 32.259), train_loss = 1.51923658, grad/param norm = 7.7395e-02, time/batch = 0.5679s	
1743/2700 (epoch 32.278), train_loss = 1.57928050, grad/param norm = 9.9047e-02, time/batch = 0.5400s	
1744/2700 (epoch 32.296), train_loss = 1.56935396, grad/param norm = 1.1060e-01, time/batch = 0.5463s	
1745/2700 (epoch 32.315), train_loss = 1.55318368, grad/param norm = 1.5466e-01, time/batch = 0.5791s	
1746/2700 (epoch 32.333), train_loss = 1.57270608, grad/param norm = 2.3681e-01, time/batch = 0.5515s	
1747/2700 (epoch 32.352), train_loss = 1.60802739, grad/param norm = 2.4032e-01, time/batch = 0.5434s	
1748/2700 (epoch 32.370), train_loss = 1.60127916, grad/param norm = 1.5784e-01, time/batch = 0.5285s	
1749/2700 (epoch 32.389), train_loss = 1.53783255, grad/param norm = 9.8908e-02, time/batch = 0.5407s	
1750/2700 (epoch 32.407), train_loss = 1.60706553, grad/param norm = 9.0924e-02, time/batch = 0.5132s	
1751/2700 (epoch 32.426), train_loss = 1.63038257, grad/param norm = 9.6750e-02, time/batch = 0.5672s	
1752/2700 (epoch 32.444), train_loss = 1.52804554, grad/param norm = 9.6025e-02, time/batch = 0.5515s	
1753/2700 (epoch 32.463), train_loss = 1.62227569, grad/param norm = 9.4201e-02, time/batch = 0.5404s	
1754/2700 (epoch 32.481), train_loss = 1.60353163, grad/param norm = 1.0144e-01, time/batch = 0.5500s	
1755/2700 (epoch 32.500), train_loss = 1.52920773, grad/param norm = 1.1253e-01, time/batch = 0.5853s	
1756/2700 (epoch 32.519), train_loss = 1.58325184, grad/param norm = 1.2438e-01, time/batch = 0.5435s	
1757/2700 (epoch 32.537), train_loss = 1.60177880, grad/param norm = 1.7565e-01, time/batch = 0.4930s	
1758/2700 (epoch 32.556), train_loss = 1.50668177, grad/param norm = 1.7065e-01, time/batch = 0.5627s	
1759/2700 (epoch 32.574), train_loss = 1.52964610, grad/param norm = 1.5577e-01, time/batch = 0.5274s	
1760/2700 (epoch 32.593), train_loss = 1.55668098, grad/param norm = 1.2493e-01, time/batch = 0.5511s	
1761/2700 (epoch 32.611), train_loss = 1.47264817, grad/param norm = 1.0321e-01, time/batch = 0.5666s	
1762/2700 (epoch 32.630), train_loss = 1.52223381, grad/param norm = 1.3084e-01, time/batch = 0.5481s	
1763/2700 (epoch 32.648), train_loss = 1.53738752, grad/param norm = 1.2966e-01, time/batch = 0.5423s	
1764/2700 (epoch 32.667), train_loss = 1.53076753, grad/param norm = 1.3635e-01, time/batch = 0.5519s	
1765/2700 (epoch 32.685), train_loss = 1.55690304, grad/param norm = 1.5486e-01, time/batch = 0.5291s	
1766/2700 (epoch 32.704), train_loss = 1.57962695, grad/param norm = 1.2121e-01, time/batch = 0.5609s	
1767/2700 (epoch 32.722), train_loss = 1.54893301, grad/param norm = 9.9497e-02, time/batch = 0.5461s	
1768/2700 (epoch 32.741), train_loss = 1.53114053, grad/param norm = 1.0031e-01, time/batch = 0.5415s	
1769/2700 (epoch 32.759), train_loss = 1.54740222, grad/param norm = 1.1332e-01, time/batch = 0.5394s	
1770/2700 (epoch 32.778), train_loss = 1.60900076, grad/param norm = 1.3279e-01, time/batch = 0.5569s	
1771/2700 (epoch 32.796), train_loss = 1.53548254, grad/param norm = 1.2977e-01, time/batch = 0.5736s	
1772/2700 (epoch 32.815), train_loss = 1.58362960, grad/param norm = 1.0904e-01, time/batch = 0.5364s	
1773/2700 (epoch 32.833), train_loss = 1.56156556, grad/param norm = 1.1528e-01, time/batch = 0.5279s	
1774/2700 (epoch 32.852), train_loss = 1.55347665, grad/param norm = 1.6731e-01, time/batch = 0.5545s	
1775/2700 (epoch 32.870), train_loss = 1.59445437, grad/param norm = 1.8360e-01, time/batch = 0.5673s	
1776/2700 (epoch 32.889), train_loss = 1.56622095, grad/param norm = 1.4034e-01, time/batch = 0.5602s	
1777/2700 (epoch 32.907), train_loss = 1.65310461, grad/param norm = 1.0026e-01, time/batch = 0.5297s	
1778/2700 (epoch 32.926), train_loss = 1.60574731, grad/param norm = 9.6855e-02, time/batch = 0.5410s	
1779/2700 (epoch 32.944), train_loss = 1.59291246, grad/param norm = 9.3016e-02, time/batch = 0.5366s	
1780/2700 (epoch 32.963), train_loss = 1.59729122, grad/param norm = 1.0270e-01, time/batch = 0.5703s	
1781/2700 (epoch 32.981), train_loss = 1.54850371, grad/param norm = 1.0643e-01, time/batch = 0.5560s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
1782/2700 (epoch 33.000), train_loss = 1.62747342, grad/param norm = 1.3044e-01, time/batch = 0.5371s	
1783/2700 (epoch 33.019), train_loss = 1.64383038, grad/param norm = 1.6026e-01, time/batch = 0.5408s	
1784/2700 (epoch 33.037), train_loss = 1.61609265, grad/param norm = 1.8903e-01, time/batch = 0.5592s	
1785/2700 (epoch 33.056), train_loss = 1.57205871, grad/param norm = 1.6169e-01, time/batch = 0.5994s	
1786/2700 (epoch 33.074), train_loss = 1.55801017, grad/param norm = 1.3058e-01, time/batch = 0.5249s	
1787/2700 (epoch 33.093), train_loss = 1.52959040, grad/param norm = 1.3502e-01, time/batch = 0.5500s	
1788/2700 (epoch 33.111), train_loss = 1.48238845, grad/param norm = 1.3138e-01, time/batch = 0.5376s	
1789/2700 (epoch 33.130), train_loss = 1.56036845, grad/param norm = 1.2055e-01, time/batch = 0.5527s	
1790/2700 (epoch 33.148), train_loss = 1.51974858, grad/param norm = 1.0617e-01, time/batch = 0.5480s	
1791/2700 (epoch 33.167), train_loss = 1.57729247, grad/param norm = 8.8628e-02, time/batch = 0.5562s	
1792/2700 (epoch 33.185), train_loss = 1.51096691, grad/param norm = 8.1322e-02, time/batch = 0.5450s	
1793/2700 (epoch 33.204), train_loss = 1.53607861, grad/param norm = 1.0014e-01, time/batch = 0.5540s	
1794/2700 (epoch 33.222), train_loss = 1.50828229, grad/param norm = 1.3966e-01, time/batch = 0.5774s	
1795/2700 (epoch 33.241), train_loss = 1.44292626, grad/param norm = 1.6758e-01, time/batch = 0.5371s	
1796/2700 (epoch 33.259), train_loss = 1.51306374, grad/param norm = 1.3670e-01, time/batch = 0.4847s	
1797/2700 (epoch 33.278), train_loss = 1.56224633, grad/param norm = 1.2468e-01, time/batch = 0.4565s	
1798/2700 (epoch 33.296), train_loss = 1.54362278, grad/param norm = 1.0430e-01, time/batch = 0.5353s	
1799/2700 (epoch 33.315), train_loss = 1.51791839, grad/param norm = 1.1183e-01, time/batch = 0.5726s	
1800/2700 (epoch 33.333), train_loss = 1.51958476, grad/param norm = 1.4011e-01, time/batch = 0.5569s	
1801/2700 (epoch 33.352), train_loss = 1.55292258, grad/param norm = 1.3091e-01, time/batch = 0.5494s	
1802/2700 (epoch 33.370), train_loss = 1.55909177, grad/param norm = 1.0122e-01, time/batch = 0.5506s	
1803/2700 (epoch 33.389), train_loss = 1.51000236, grad/param norm = 1.0677e-01, time/batch = 0.5784s	
1804/2700 (epoch 33.407), train_loss = 1.57886049, grad/param norm = 1.0829e-01, time/batch = 0.5414s	
1805/2700 (epoch 33.426), train_loss = 1.61522382, grad/param norm = 1.4625e-01, time/batch = 0.5441s	
1806/2700 (epoch 33.444), train_loss = 1.52318846, grad/param norm = 1.7258e-01, time/batch = 0.5156s	
1807/2700 (epoch 33.463), train_loss = 1.61786690, grad/param norm = 1.5310e-01, time/batch = 0.5547s	
1808/2700 (epoch 33.481), train_loss = 1.58117575, grad/param norm = 1.2653e-01, time/batch = 0.5404s	
1809/2700 (epoch 33.500), train_loss = 1.49939263, grad/param norm = 1.2243e-01, time/batch = 0.5776s	
1810/2700 (epoch 33.519), train_loss = 1.57054962, grad/param norm = 1.3245e-01, time/batch = 0.5609s	
1811/2700 (epoch 33.537), train_loss = 1.58349829, grad/param norm = 1.5644e-01, time/batch = 0.5474s	
1812/2700 (epoch 33.556), train_loss = 1.47665671, grad/param norm = 1.1340e-01, time/batch = 0.5693s	
1813/2700 (epoch 33.574), train_loss = 1.49839207, grad/param norm = 9.8232e-02, time/batch = 0.5699s	
1814/2700 (epoch 33.593), train_loss = 1.53281803, grad/param norm = 9.4740e-02, time/batch = 0.5454s	
1815/2700 (epoch 33.611), train_loss = 1.44978741, grad/param norm = 1.0464e-01, time/batch = 0.5252s	
1816/2700 (epoch 33.630), train_loss = 1.49175728, grad/param norm = 9.6570e-02, time/batch = 0.5271s	
1817/2700 (epoch 33.648), train_loss = 1.50623795, grad/param norm = 8.9844e-02, time/batch = 0.5555s	
1818/2700 (epoch 33.667), train_loss = 1.50037045, grad/param norm = 1.0233e-01, time/batch = 0.5797s	
1819/2700 (epoch 33.685), train_loss = 1.52440767, grad/param norm = 1.3049e-01, time/batch = 0.5579s	
1820/2700 (epoch 33.704), train_loss = 1.56355476, grad/param norm = 1.5056e-01, time/batch = 0.5433s	
1821/2700 (epoch 33.722), train_loss = 1.53154161, grad/param norm = 1.4306e-01, time/batch = 0.5710s	
1822/2700 (epoch 33.741), train_loss = 1.51557367, grad/param norm = 1.5700e-01, time/batch = 0.5609s	
1823/2700 (epoch 33.759), train_loss = 1.53756487, grad/param norm = 2.1556e-01, time/batch = 0.5212s	
1824/2700 (epoch 33.778), train_loss = 1.60215851, grad/param norm = 2.3205e-01, time/batch = 0.5484s	
1825/2700 (epoch 33.796), train_loss = 1.52837932, grad/param norm = 1.9192e-01, time/batch = 0.5389s	
1826/2700 (epoch 33.815), train_loss = 1.57691739, grad/param norm = 1.6594e-01, time/batch = 0.5519s	
1827/2700 (epoch 33.833), train_loss = 1.55048735, grad/param norm = 1.2620e-01, time/batch = 0.5780s	
1828/2700 (epoch 33.852), train_loss = 1.51827506, grad/param norm = 1.0785e-01, time/batch = 0.5564s	
1829/2700 (epoch 33.870), train_loss = 1.54149875, grad/param norm = 9.0807e-02, time/batch = 0.5577s	
1830/2700 (epoch 33.889), train_loss = 1.53390442, grad/param norm = 1.0026e-01, time/batch = 0.5515s	
1831/2700 (epoch 33.907), train_loss = 1.63913945, grad/param norm = 1.4479e-01, time/batch = 0.5728s	
1832/2700 (epoch 33.926), train_loss = 1.59492307, grad/param norm = 1.3793e-01, time/batch = 0.5600s	
1833/2700 (epoch 33.944), train_loss = 1.57692913, grad/param norm = 1.1134e-01, time/batch = 0.5400s	
1834/2700 (epoch 33.963), train_loss = 1.56911649, grad/param norm = 1.1876e-01, time/batch = 0.5408s	
1835/2700 (epoch 33.981), train_loss = 1.51934004, grad/param norm = 1.3670e-01, time/batch = 0.5729s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
1836/2700 (epoch 34.000), train_loss = 1.59725988, grad/param norm = 1.4186e-01, time/batch = 0.5631s	
1837/2700 (epoch 34.019), train_loss = 1.61131575, grad/param norm = 1.4554e-01, time/batch = 0.5609s	
1838/2700 (epoch 34.037), train_loss = 1.57899002, grad/param norm = 1.4037e-01, time/batch = 0.5485s	
1839/2700 (epoch 34.056), train_loss = 1.53425702, grad/param norm = 1.1741e-01, time/batch = 0.5344s	
1840/2700 (epoch 34.074), train_loss = 1.53164203, grad/param norm = 1.0212e-01, time/batch = 0.5644s	
1841/2700 (epoch 34.093), train_loss = 1.50113904, grad/param norm = 9.5726e-02, time/batch = 0.5518s	
1842/2700 (epoch 34.111), train_loss = 1.45972723, grad/param norm = 1.0381e-01, time/batch = 0.5324s	
1843/2700 (epoch 34.130), train_loss = 1.54327298, grad/param norm = 1.4035e-01, time/batch = 0.5331s	
1844/2700 (epoch 34.148), train_loss = 1.50230964, grad/param norm = 1.3222e-01, time/batch = 0.5388s	
1845/2700 (epoch 34.167), train_loss = 1.56378331, grad/param norm = 1.3943e-01, time/batch = 0.5756s	
1846/2700 (epoch 34.185), train_loss = 1.49923915, grad/param norm = 1.3057e-01, time/batch = 0.5581s	
1847/2700 (epoch 34.204), train_loss = 1.51250950, grad/param norm = 1.1737e-01, time/batch = 0.5596s	
1848/2700 (epoch 34.222), train_loss = 1.48315984, grad/param norm = 1.1957e-01, time/batch = 0.5390s	
1849/2700 (epoch 34.241), train_loss = 1.41052920, grad/param norm = 1.1038e-01, time/batch = 0.5427s	
1850/2700 (epoch 34.259), train_loss = 1.48116883, grad/param norm = 1.1967e-01, time/batch = 0.5497s	
1851/2700 (epoch 34.278), train_loss = 1.53414876, grad/param norm = 1.1942e-01, time/batch = 0.5767s	
1852/2700 (epoch 34.296), train_loss = 1.53037615, grad/param norm = 1.5098e-01, time/batch = 0.5334s	
1853/2700 (epoch 34.315), train_loss = 1.51334265, grad/param norm = 1.6699e-01, time/batch = 0.5402s	
1854/2700 (epoch 34.333), train_loss = 1.50378671, grad/param norm = 1.4087e-01, time/batch = 0.5650s	
1855/2700 (epoch 34.352), train_loss = 1.53752215, grad/param norm = 1.3234e-01, time/batch = 0.5866s	
1856/2700 (epoch 34.370), train_loss = 1.54228989, grad/param norm = 1.6382e-01, time/batch = 0.5230s	
1857/2700 (epoch 34.389), train_loss = 1.50413138, grad/param norm = 1.8102e-01, time/batch = 0.5512s	
1858/2700 (epoch 34.407), train_loss = 1.57685733, grad/param norm = 1.9122e-01, time/batch = 0.5474s	
1859/2700 (epoch 34.426), train_loss = 1.59989305, grad/param norm = 1.6923e-01, time/batch = 0.5474s	
1860/2700 (epoch 34.444), train_loss = 1.48861216, grad/param norm = 1.3148e-01, time/batch = 0.5842s	
1861/2700 (epoch 34.463), train_loss = 1.57881504, grad/param norm = 9.7854e-02, time/batch = 0.5342s	
1862/2700 (epoch 34.481), train_loss = 1.55010207, grad/param norm = 9.2481e-02, time/batch = 0.5382s	
1863/2700 (epoch 34.500), train_loss = 1.47421941, grad/param norm = 9.5506e-02, time/batch = 0.5587s	
1864/2700 (epoch 34.519), train_loss = 1.53891893, grad/param norm = 8.9932e-02, time/batch = 0.5638s	
1865/2700 (epoch 34.537), train_loss = 1.54377304, grad/param norm = 9.8713e-02, time/batch = 0.5572s	
1866/2700 (epoch 34.556), train_loss = 1.44693805, grad/param norm = 1.0221e-01, time/batch = 0.5565s	
1867/2700 (epoch 34.574), train_loss = 1.48394007, grad/param norm = 1.5458e-01, time/batch = 0.5379s	
1868/2700 (epoch 34.593), train_loss = 1.53159916, grad/param norm = 1.6511e-01, time/batch = 0.5553s	
1869/2700 (epoch 34.611), train_loss = 1.43960216, grad/param norm = 1.3985e-01, time/batch = 0.5703s	
1870/2700 (epoch 34.630), train_loss = 1.47944844, grad/param norm = 1.1300e-01, time/batch = 0.5562s	
1871/2700 (epoch 34.648), train_loss = 1.49115360, grad/param norm = 9.5617e-02, time/batch = 0.5538s	
1872/2700 (epoch 34.667), train_loss = 1.47792102, grad/param norm = 8.7710e-02, time/batch = 0.5443s	
1873/2700 (epoch 34.685), train_loss = 1.49323758, grad/param norm = 9.3643e-02, time/batch = 0.5529s	
1874/2700 (epoch 34.704), train_loss = 1.52496420, grad/param norm = 8.2836e-02, time/batch = 0.5563s	
1875/2700 (epoch 34.722), train_loss = 1.49983806, grad/param norm = 1.0074e-01, time/batch = 0.5521s	
1876/2700 (epoch 34.741), train_loss = 1.48611169, grad/param norm = 1.3161e-01, time/batch = 0.5376s	
1877/2700 (epoch 34.759), train_loss = 1.51822703, grad/param norm = 1.7963e-01, time/batch = 0.5593s	
1878/2700 (epoch 34.778), train_loss = 1.59463154, grad/param norm = 2.1022e-01, time/batch = 0.5710s	
1879/2700 (epoch 34.796), train_loss = 1.52593563, grad/param norm = 2.1977e-01, time/batch = 0.5581s	
1880/2700 (epoch 34.815), train_loss = 1.55846618, grad/param norm = 1.9016e-01, time/batch = 0.5313s	
1881/2700 (epoch 34.833), train_loss = 1.53140651, grad/param norm = 1.7228e-01, time/batch = 0.5691s	
1882/2700 (epoch 34.852), train_loss = 1.50123840, grad/param norm = 1.7470e-01, time/batch = 0.5677s	
1883/2700 (epoch 34.870), train_loss = 1.53098438, grad/param norm = 1.3700e-01, time/batch = 0.5516s	
1884/2700 (epoch 34.889), train_loss = 1.50616585, grad/param norm = 8.7730e-02, time/batch = 0.5523s	
1885/2700 (epoch 34.907), train_loss = 1.60090199, grad/param norm = 1.0793e-01, time/batch = 0.5368s	
1886/2700 (epoch 34.926), train_loss = 1.55191630, grad/param norm = 1.0014e-01, time/batch = 0.5587s	
1887/2700 (epoch 34.944), train_loss = 1.54413410, grad/param norm = 9.3443e-02, time/batch = 0.5829s	
1888/2700 (epoch 34.963), train_loss = 1.54529494, grad/param norm = 1.0001e-01, time/batch = 0.5613s	
1889/2700 (epoch 34.981), train_loss = 1.49294108, grad/param norm = 9.9562e-02, time/batch = 0.5272s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
1890/2700 (epoch 35.000), train_loss = 1.57652507, grad/param norm = 1.1022e-01, time/batch = 0.5333s	
1891/2700 (epoch 35.019), train_loss = 1.58890963, grad/param norm = 1.1307e-01, time/batch = 0.5659s	
1892/2700 (epoch 35.037), train_loss = 1.54635587, grad/param norm = 9.8573e-02, time/batch = 0.5537s	
1893/2700 (epoch 35.056), train_loss = 1.50923853, grad/param norm = 1.4078e-01, time/batch = 0.5495s	
1894/2700 (epoch 35.074), train_loss = 1.51377669, grad/param norm = 1.4732e-01, time/batch = 0.5426s	
1895/2700 (epoch 35.093), train_loss = 1.47616369, grad/param norm = 1.1818e-01, time/batch = 0.5478s	
1896/2700 (epoch 35.111), train_loss = 1.43409867, grad/param norm = 1.0856e-01, time/batch = 0.5605s	
1897/2700 (epoch 35.130), train_loss = 1.51505898, grad/param norm = 1.2667e-01, time/batch = 0.5326s	
1898/2700 (epoch 35.148), train_loss = 1.47814446, grad/param norm = 1.2159e-01, time/batch = 0.5637s	
1899/2700 (epoch 35.167), train_loss = 1.53806621, grad/param norm = 1.2707e-01, time/batch = 0.5364s	
1900/2700 (epoch 35.185), train_loss = 1.47810211, grad/param norm = 1.2028e-01, time/batch = 0.5389s	
1901/2700 (epoch 35.204), train_loss = 1.49586134, grad/param norm = 1.0511e-01, time/batch = 0.5736s	
1902/2700 (epoch 35.222), train_loss = 1.46457771, grad/param norm = 9.4795e-02, time/batch = 0.5462s	
1903/2700 (epoch 35.241), train_loss = 1.38841022, grad/param norm = 8.7793e-02, time/batch = 0.5496s	
1904/2700 (epoch 35.259), train_loss = 1.45767043, grad/param norm = 8.4074e-02, time/batch = 0.5421s	
1905/2700 (epoch 35.278), train_loss = 1.50898998, grad/param norm = 8.3990e-02, time/batch = 0.5317s	
1906/2700 (epoch 35.296), train_loss = 1.49693819, grad/param norm = 8.1409e-02, time/batch = 0.5749s	
1907/2700 (epoch 35.315), train_loss = 1.47136159, grad/param norm = 9.5519e-02, time/batch = 0.5579s	
1908/2700 (epoch 35.333), train_loss = 1.46976172, grad/param norm = 1.2651e-01, time/batch = 0.5505s	
1909/2700 (epoch 35.352), train_loss = 1.50491804, grad/param norm = 1.4448e-01, time/batch = 0.5346s	
1910/2700 (epoch 35.370), train_loss = 1.50111675, grad/param norm = 1.1350e-01, time/batch = 0.5385s	
1911/2700 (epoch 35.389), train_loss = 1.45890825, grad/param norm = 1.1018e-01, time/batch = 0.5912s	
1912/2700 (epoch 35.407), train_loss = 1.54335758, grad/param norm = 1.4764e-01, time/batch = 0.5544s	
1913/2700 (epoch 35.426), train_loss = 1.57574545, grad/param norm = 1.5083e-01, time/batch = 0.5395s	
1914/2700 (epoch 35.444), train_loss = 1.48135479, grad/param norm = 1.5015e-01, time/batch = 0.5312s	
1915/2700 (epoch 35.463), train_loss = 1.57703917, grad/param norm = 1.8498e-01, time/batch = 0.5333s	
1916/2700 (epoch 35.481), train_loss = 1.55849487, grad/param norm = 1.9096e-01, time/batch = 0.5791s	
1917/2700 (epoch 35.500), train_loss = 1.48013735, grad/param norm = 1.8051e-01, time/batch = 0.5526s	
1918/2700 (epoch 35.519), train_loss = 1.52812280, grad/param norm = 1.3495e-01, time/batch = 0.5465s	
1919/2700 (epoch 35.537), train_loss = 1.51677895, grad/param norm = 9.7477e-02, time/batch = 0.5353s	
1920/2700 (epoch 35.556), train_loss = 1.42383964, grad/param norm = 1.1168e-01, time/batch = 0.5378s	
1921/2700 (epoch 35.574), train_loss = 1.44982066, grad/param norm = 1.2782e-01, time/batch = 0.5891s	
1922/2700 (epoch 35.593), train_loss = 1.49207610, grad/param norm = 1.3025e-01, time/batch = 0.5126s	
1923/2700 (epoch 35.611), train_loss = 1.41591865, grad/param norm = 1.2071e-01, time/batch = 0.5646s	
1924/2700 (epoch 35.630), train_loss = 1.44852840, grad/param norm = 9.1038e-02, time/batch = 0.5172s	
1925/2700 (epoch 35.648), train_loss = 1.46241356, grad/param norm = 8.0139e-02, time/batch = 0.5479s	
1926/2700 (epoch 35.667), train_loss = 1.45512772, grad/param norm = 9.2373e-02, time/batch = 0.5705s	
1927/2700 (epoch 35.685), train_loss = 1.47760538, grad/param norm = 1.0517e-01, time/batch = 0.5530s	
1928/2700 (epoch 35.704), train_loss = 1.50665214, grad/param norm = 8.9798e-02, time/batch = 0.5505s	
1929/2700 (epoch 35.722), train_loss = 1.48238643, grad/param norm = 9.0327e-02, time/batch = 0.5333s	
1930/2700 (epoch 35.741), train_loss = 1.45903718, grad/param norm = 9.4768e-02, time/batch = 0.5234s	
1931/2700 (epoch 35.759), train_loss = 1.46723514, grad/param norm = 8.4587e-02, time/batch = 0.5614s	
1932/2700 (epoch 35.778), train_loss = 1.53020025, grad/param norm = 8.9121e-02, time/batch = 0.5714s	
1933/2700 (epoch 35.796), train_loss = 1.45468418, grad/param norm = 1.0865e-01, time/batch = 0.5000s	
1934/2700 (epoch 35.815), train_loss = 1.51140898, grad/param norm = 1.2687e-01, time/batch = 0.5504s	
1935/2700 (epoch 35.833), train_loss = 1.50690230, grad/param norm = 1.7364e-01, time/batch = 0.5591s	
1936/2700 (epoch 35.852), train_loss = 1.49360962, grad/param norm = 1.9145e-01, time/batch = 0.5676s	
1937/2700 (epoch 35.870), train_loss = 1.51045744, grad/param norm = 1.4812e-01, time/batch = 0.5447s	
1938/2700 (epoch 35.889), train_loss = 1.48037178, grad/param norm = 8.7878e-02, time/batch = 0.5540s	
1939/2700 (epoch 35.907), train_loss = 1.57510199, grad/param norm = 1.0221e-01, time/batch = 0.5148s	
1940/2700 (epoch 35.926), train_loss = 1.52832670, grad/param norm = 9.7976e-02, time/batch = 0.5346s	
1941/2700 (epoch 35.944), train_loss = 1.52566244, grad/param norm = 1.1163e-01, time/batch = 0.5704s	
1942/2700 (epoch 35.963), train_loss = 1.52939406, grad/param norm = 1.2653e-01, time/batch = 0.5106s	
1943/2700 (epoch 35.981), train_loss = 1.47752136, grad/param norm = 1.2091e-01, time/batch = 0.5585s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
1944/2700 (epoch 36.000), train_loss = 1.55119076, grad/param norm = 1.0414e-01, time/batch = 0.5500s	
1945/2700 (epoch 36.019), train_loss = 1.56017943, grad/param norm = 9.0258e-02, time/batch = 0.5632s	
1946/2700 (epoch 36.037), train_loss = 1.52327993, grad/param norm = 9.1471e-02, time/batch = 0.5708s	
1947/2700 (epoch 36.056), train_loss = 1.48454549, grad/param norm = 1.0660e-01, time/batch = 0.4990s	
1948/2700 (epoch 36.074), train_loss = 1.48896470, grad/param norm = 1.0052e-01, time/batch = 0.5672s	
1949/2700 (epoch 36.093), train_loss = 1.45549796, grad/param norm = 9.6555e-02, time/batch = 0.5472s	
1950/2700 (epoch 36.111), train_loss = 1.41333107, grad/param norm = 9.7900e-02, time/batch = 0.5453s	
1951/2700 (epoch 36.130), train_loss = 1.49550153, grad/param norm = 1.1124e-01, time/batch = 0.5444s	
1952/2700 (epoch 36.148), train_loss = 1.45978488, grad/param norm = 1.2348e-01, time/batch = 0.5648s	
1953/2700 (epoch 36.167), train_loss = 1.51747782, grad/param norm = 1.5139e-01, time/batch = 0.5419s	
1954/2700 (epoch 36.185), train_loss = 1.47308291, grad/param norm = 1.8783e-01, time/batch = 0.5446s	
1955/2700 (epoch 36.204), train_loss = 1.50233701, grad/param norm = 2.1069e-01, time/batch = 0.5359s	
1956/2700 (epoch 36.222), train_loss = 1.48216793, grad/param norm = 2.3605e-01, time/batch = 0.5503s	
1957/2700 (epoch 36.241), train_loss = 1.39849205, grad/param norm = 2.0345e-01, time/batch = 0.5620s	
1958/2700 (epoch 36.259), train_loss = 1.44817642, grad/param norm = 1.1794e-01, time/batch = 0.5508s	
1959/2700 (epoch 36.278), train_loss = 1.49614145, grad/param norm = 1.0008e-01, time/batch = 0.5419s	
1960/2700 (epoch 36.296), train_loss = 1.47409826, grad/param norm = 8.0530e-02, time/batch = 0.5505s	
1961/2700 (epoch 36.315), train_loss = 1.44423537, grad/param norm = 8.7464e-02, time/batch = 0.5658s	
1962/2700 (epoch 36.333), train_loss = 1.45092059, grad/param norm = 1.1326e-01, time/batch = 0.5357s	
1963/2700 (epoch 36.352), train_loss = 1.48455044, grad/param norm = 1.1873e-01, time/batch = 0.5264s	
1964/2700 (epoch 36.370), train_loss = 1.50621176, grad/param norm = 1.7270e-01, time/batch = 0.5705s	
1965/2700 (epoch 36.389), train_loss = 1.46300762, grad/param norm = 1.9992e-01, time/batch = 0.5673s	
1966/2700 (epoch 36.407), train_loss = 1.53524956, grad/param norm = 1.5995e-01, time/batch = 0.5619s	
1967/2700 (epoch 36.426), train_loss = 1.56043147, grad/param norm = 1.5125e-01, time/batch = 0.5499s	
1968/2700 (epoch 36.444), train_loss = 1.44908858, grad/param norm = 9.5379e-02, time/batch = 0.5415s	
1969/2700 (epoch 36.463), train_loss = 1.53770626, grad/param norm = 9.5725e-02, time/batch = 0.5442s	
1970/2700 (epoch 36.481), train_loss = 1.51061653, grad/param norm = 9.4918e-02, time/batch = 0.5882s	
1971/2700 (epoch 36.500), train_loss = 1.43284512, grad/param norm = 9.6300e-02, time/batch = 0.5248s	
1972/2700 (epoch 36.519), train_loss = 1.49491891, grad/param norm = 9.1016e-02, time/batch = 0.5399s	
1973/2700 (epoch 36.537), train_loss = 1.49269852, grad/param norm = 1.0953e-01, time/batch = 0.5446s	
1974/2700 (epoch 36.556), train_loss = 1.39950157, grad/param norm = 9.4976e-02, time/batch = 0.5825s	
1975/2700 (epoch 36.574), train_loss = 1.42738296, grad/param norm = 9.3228e-02, time/batch = 0.5425s	
1976/2700 (epoch 36.593), train_loss = 1.46411501, grad/param norm = 9.1732e-02, time/batch = 0.5413s	
1977/2700 (epoch 36.611), train_loss = 1.39266369, grad/param norm = 1.0671e-01, time/batch = 0.5421s	
1978/2700 (epoch 36.630), train_loss = 1.43739155, grad/param norm = 1.6638e-01, time/batch = 0.5296s	
1979/2700 (epoch 36.648), train_loss = 1.46424010, grad/param norm = 1.8171e-01, time/batch = 0.5776s	
1980/2700 (epoch 36.667), train_loss = 1.45461553, grad/param norm = 1.7188e-01, time/batch = 0.5225s	
1981/2700 (epoch 36.685), train_loss = 1.46422737, grad/param norm = 1.5334e-01, time/batch = 0.5345s	
1982/2700 (epoch 36.704), train_loss = 1.48588369, grad/param norm = 1.1986e-01, time/batch = 0.5502s	
1983/2700 (epoch 36.722), train_loss = 1.46503716, grad/param norm = 1.2057e-01, time/batch = 0.5830s	
1984/2700 (epoch 36.741), train_loss = 1.43933145, grad/param norm = 1.0852e-01, time/batch = 0.5640s	
1985/2700 (epoch 36.759), train_loss = 1.45211724, grad/param norm = 9.9692e-02, time/batch = 0.5376s	
1986/2700 (epoch 36.778), train_loss = 1.51131094, grad/param norm = 1.0575e-01, time/batch = 0.5458s	
1987/2700 (epoch 36.796), train_loss = 1.44155617, grad/param norm = 1.2886e-01, time/batch = 0.5284s	
1988/2700 (epoch 36.815), train_loss = 1.50019156, grad/param norm = 1.3358e-01, time/batch = 0.5426s	
1989/2700 (epoch 36.833), train_loss = 1.48206500, grad/param norm = 1.2716e-01, time/batch = 0.5777s	
1990/2700 (epoch 36.852), train_loss = 1.44447264, grad/param norm = 9.8286e-02, time/batch = 0.5641s	
1991/2700 (epoch 36.870), train_loss = 1.47296153, grad/param norm = 8.1566e-02, time/batch = 0.5490s	
1992/2700 (epoch 36.889), train_loss = 1.46977329, grad/param norm = 1.3964e-01, time/batch = 0.5674s	
1993/2700 (epoch 36.907), train_loss = 1.57930283, grad/param norm = 2.0643e-01, time/batch = 0.5867s	
1994/2700 (epoch 36.926), train_loss = 1.52641212, grad/param norm = 1.8232e-01, time/batch = 0.5358s	
1995/2700 (epoch 36.944), train_loss = 1.51315231, grad/param norm = 1.5001e-01, time/batch = 0.5328s	
1996/2700 (epoch 36.963), train_loss = 1.50260952, grad/param norm = 1.3986e-01, time/batch = 0.5139s	
1997/2700 (epoch 36.981), train_loss = 1.45548659, grad/param norm = 1.4698e-01, time/batch = 0.5595s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
1998/2700 (epoch 37.000), train_loss = 1.53488703, grad/param norm = 1.4094e-01, time/batch = 0.5425s	
1999/2700 (epoch 37.019), train_loss = 1.54815023, grad/param norm = 1.2588e-01, time/batch = 0.5657s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch37.04_1.7255.t7	
2000/2700 (epoch 37.037), train_loss = 1.50133014, grad/param norm = 1.1084e-01, time/batch = 0.5631s	
2001/2700 (epoch 37.056), train_loss = 1.62213852, grad/param norm = 8.7709e-02, time/batch = 0.5532s	
2002/2700 (epoch 37.074), train_loss = 1.46123888, grad/param norm = 8.2239e-02, time/batch = 0.5450s	
2003/2700 (epoch 37.093), train_loss = 1.42955120, grad/param norm = 8.5369e-02, time/batch = 0.5256s	
2004/2700 (epoch 37.111), train_loss = 1.39582685, grad/param norm = 9.3390e-02, time/batch = 0.5351s	
2005/2700 (epoch 37.130), train_loss = 1.47383840, grad/param norm = 1.0219e-01, time/batch = 0.5664s	
2006/2700 (epoch 37.148), train_loss = 1.43993238, grad/param norm = 9.9400e-02, time/batch = 0.5689s	
2007/2700 (epoch 37.167), train_loss = 1.49326944, grad/param norm = 1.0873e-01, time/batch = 0.5711s	
2008/2700 (epoch 37.185), train_loss = 1.43467572, grad/param norm = 9.3361e-02, time/batch = 0.5491s	
2009/2700 (epoch 37.204), train_loss = 1.45038892, grad/param norm = 9.3294e-02, time/batch = 0.5488s	
2010/2700 (epoch 37.222), train_loss = 1.43087525, grad/param norm = 1.1114e-01, time/batch = 0.5847s	
2011/2700 (epoch 37.241), train_loss = 1.35169814, grad/param norm = 9.6837e-02, time/batch = 0.5285s	
2012/2700 (epoch 37.259), train_loss = 1.41329918, grad/param norm = 7.8331e-02, time/batch = 0.5256s	
2013/2700 (epoch 37.278), train_loss = 1.46817914, grad/param norm = 8.4778e-02, time/batch = 0.5379s	
2014/2700 (epoch 37.296), train_loss = 1.45246069, grad/param norm = 9.2766e-02, time/batch = 0.5707s	
2015/2700 (epoch 37.315), train_loss = 1.42907975, grad/param norm = 1.1915e-01, time/batch = 0.5603s	
2016/2700 (epoch 37.333), train_loss = 1.43889100, grad/param norm = 1.2898e-01, time/batch = 0.5604s	
2017/2700 (epoch 37.352), train_loss = 1.47239703, grad/param norm = 1.4597e-01, time/batch = 0.5460s	
2018/2700 (epoch 37.370), train_loss = 1.48292164, grad/param norm = 2.0694e-01, time/batch = 0.5513s	
2019/2700 (epoch 37.389), train_loss = 1.44469342, grad/param norm = 2.2684e-01, time/batch = 0.5498s	
2020/2700 (epoch 37.407), train_loss = 1.51361639, grad/param norm = 2.0074e-01, time/batch = 0.5582s	
2021/2700 (epoch 37.426), train_loss = 1.53415335, grad/param norm = 1.6524e-01, time/batch = 0.5287s	
2022/2700 (epoch 37.444), train_loss = 1.43108025, grad/param norm = 1.2720e-01, time/batch = 0.5380s	
2023/2700 (epoch 37.463), train_loss = 1.52006640, grad/param norm = 1.1065e-01, time/batch = 0.5711s	
2024/2700 (epoch 37.481), train_loss = 1.48421322, grad/param norm = 9.9251e-02, time/batch = 0.5638s	
2025/2700 (epoch 37.500), train_loss = 1.40717535, grad/param norm = 9.4109e-02, time/batch = 0.5575s	
2026/2700 (epoch 37.519), train_loss = 1.46975021, grad/param norm = 9.9075e-02, time/batch = 0.5486s	
2027/2700 (epoch 37.537), train_loss = 1.48276990, grad/param norm = 1.3623e-01, time/batch = 0.5377s	
2028/2700 (epoch 37.556), train_loss = 1.39483015, grad/param norm = 1.3578e-01, time/batch = 0.5563s	
2029/2700 (epoch 37.574), train_loss = 1.41928527, grad/param norm = 1.1567e-01, time/batch = 0.5481s	
2030/2700 (epoch 37.593), train_loss = 1.44999794, grad/param norm = 1.0316e-01, time/batch = 0.5563s	
2031/2700 (epoch 37.611), train_loss = 1.37500840, grad/param norm = 9.4008e-02, time/batch = 0.5408s	
2032/2700 (epoch 37.630), train_loss = 1.40613694, grad/param norm = 1.0737e-01, time/batch = 0.5856s	
2033/2700 (epoch 37.648), train_loss = 1.42511725, grad/param norm = 1.0704e-01, time/batch = 0.5564s	
2034/2700 (epoch 37.667), train_loss = 1.42108469, grad/param norm = 1.1200e-01, time/batch = 0.5627s	
2035/2700 (epoch 37.685), train_loss = 1.43317932, grad/param norm = 1.0134e-01, time/batch = 0.5261s	
2036/2700 (epoch 37.704), train_loss = 1.46168713, grad/param norm = 8.6421e-02, time/batch = 0.5422s	
2037/2700 (epoch 37.722), train_loss = 1.44023063, grad/param norm = 8.1721e-02, time/batch = 0.5388s	
2038/2700 (epoch 37.741), train_loss = 1.41318492, grad/param norm = 7.6503e-02, time/batch = 0.5926s	
2039/2700 (epoch 37.759), train_loss = 1.42447001, grad/param norm = 1.1548e-01, time/batch = 0.5478s	
2040/2700 (epoch 37.778), train_loss = 1.48474095, grad/param norm = 1.3925e-01, time/batch = 0.5377s	
2041/2700 (epoch 37.796), train_loss = 1.40740336, grad/param norm = 1.4085e-01, time/batch = 0.5945s	
2042/2700 (epoch 37.815), train_loss = 1.47189504, grad/param norm = 1.5740e-01, time/batch = 0.5512s	
2043/2700 (epoch 37.833), train_loss = 1.45158390, grad/param norm = 1.4753e-01, time/batch = 0.5423s	
2044/2700 (epoch 37.852), train_loss = 1.43440199, grad/param norm = 1.4612e-01, time/batch = 0.5182s	
2045/2700 (epoch 37.870), train_loss = 1.47350467, grad/param norm = 1.8052e-01, time/batch = 0.5285s	
2046/2700 (epoch 37.889), train_loss = 1.46294853, grad/param norm = 1.9158e-01, time/batch = 0.5520s	
2047/2700 (epoch 37.907), train_loss = 1.55486292, grad/param norm = 1.9850e-01, time/batch = 0.5749s	
2048/2700 (epoch 37.926), train_loss = 1.48842119, grad/param norm = 1.2131e-01, time/batch = 0.5616s	
2049/2700 (epoch 37.944), train_loss = 1.47687626, grad/param norm = 9.1768e-02, time/batch = 0.5400s	
2050/2700 (epoch 37.963), train_loss = 1.47338810, grad/param norm = 1.0953e-01, time/batch = 0.5404s	
2051/2700 (epoch 37.981), train_loss = 1.43214064, grad/param norm = 1.5074e-01, time/batch = 0.5957s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2052/2700 (epoch 38.000), train_loss = 1.51645805, grad/param norm = 1.6806e-01, time/batch = 0.5064s	
2053/2700 (epoch 38.019), train_loss = 1.52377646, grad/param norm = 1.2949e-01, time/batch = 0.5545s	
2054/2700 (epoch 38.037), train_loss = 1.47544322, grad/param norm = 1.0421e-01, time/batch = 0.5475s	
2055/2700 (epoch 38.056), train_loss = 1.45021018, grad/param norm = 1.5043e-01, time/batch = 0.5386s	
2056/2700 (epoch 38.074), train_loss = 1.45575534, grad/param norm = 1.5503e-01, time/batch = 0.5613s	
2057/2700 (epoch 38.093), train_loss = 1.41103687, grad/param norm = 8.9345e-02, time/batch = 0.5688s	
2058/2700 (epoch 38.111), train_loss = 1.37540975, grad/param norm = 8.7416e-02, time/batch = 0.5619s	
2059/2700 (epoch 38.130), train_loss = 1.45561135, grad/param norm = 1.1053e-01, time/batch = 0.5359s	
2060/2700 (epoch 38.148), train_loss = 1.41624170, grad/param norm = 9.2620e-02, time/batch = 0.5215s	
2061/2700 (epoch 38.167), train_loss = 1.46897496, grad/param norm = 1.0683e-01, time/batch = 0.5735s	
2062/2700 (epoch 38.185), train_loss = 1.41191281, grad/param norm = 1.0101e-01, time/batch = 0.5514s	
2063/2700 (epoch 38.204), train_loss = 1.42360402, grad/param norm = 9.2539e-02, time/batch = 0.5705s	
2064/2700 (epoch 38.222), train_loss = 1.40109053, grad/param norm = 9.7521e-02, time/batch = 0.5450s	
2065/2700 (epoch 38.241), train_loss = 1.33148493, grad/param norm = 1.0540e-01, time/batch = 0.5584s	
2066/2700 (epoch 38.259), train_loss = 1.40506528, grad/param norm = 1.2963e-01, time/batch = 0.5771s	
2067/2700 (epoch 38.278), train_loss = 1.45717409, grad/param norm = 1.2889e-01, time/batch = 0.5526s	
2068/2700 (epoch 38.296), train_loss = 1.44071733, grad/param norm = 1.3901e-01, time/batch = 0.5269s	
2069/2700 (epoch 38.315), train_loss = 1.40892936, grad/param norm = 1.4268e-01, time/batch = 0.5395s	
2070/2700 (epoch 38.333), train_loss = 1.40996404, grad/param norm = 1.2393e-01, time/batch = 0.5374s	
2071/2700 (epoch 38.352), train_loss = 1.43893217, grad/param norm = 1.4057e-01, time/batch = 0.5804s	
2072/2700 (epoch 38.370), train_loss = 1.46413230, grad/param norm = 1.8890e-01, time/batch = 0.5661s	
2073/2700 (epoch 38.389), train_loss = 1.41772894, grad/param norm = 1.5920e-01, time/batch = 0.5452s	
2074/2700 (epoch 38.407), train_loss = 1.48132820, grad/param norm = 1.0850e-01, time/batch = 0.5383s	
2075/2700 (epoch 38.426), train_loss = 1.52087826, grad/param norm = 1.3674e-01, time/batch = 0.5535s	
2076/2700 (epoch 38.444), train_loss = 1.42029852, grad/param norm = 1.2541e-01, time/batch = 0.5726s	
2077/2700 (epoch 38.463), train_loss = 1.50297102, grad/param norm = 1.3662e-01, time/batch = 0.5366s	
2078/2700 (epoch 38.481), train_loss = 1.46445745, grad/param norm = 1.3239e-01, time/batch = 0.5487s	
2079/2700 (epoch 38.500), train_loss = 1.39177725, grad/param norm = 1.2804e-01, time/batch = 0.5432s	
2080/2700 (epoch 38.519), train_loss = 1.44870485, grad/param norm = 1.0110e-01, time/batch = 0.5764s	
2081/2700 (epoch 38.537), train_loss = 1.45077913, grad/param norm = 1.0240e-01, time/batch = 0.5501s	
2082/2700 (epoch 38.556), train_loss = 1.36285275, grad/param norm = 1.4364e-01, time/batch = 0.5513s	
2083/2700 (epoch 38.574), train_loss = 1.39825430, grad/param norm = 1.7892e-01, time/batch = 0.5384s	
2084/2700 (epoch 38.593), train_loss = 1.44877913, grad/param norm = 1.7056e-01, time/batch = 0.5487s	
2085/2700 (epoch 38.611), train_loss = 1.35714582, grad/param norm = 1.3076e-01, time/batch = 0.5344s	
2086/2700 (epoch 38.630), train_loss = 1.38777705, grad/param norm = 9.5382e-02, time/batch = 0.5594s	
2087/2700 (epoch 38.648), train_loss = 1.41223968, grad/param norm = 1.0881e-01, time/batch = 0.5581s	
2088/2700 (epoch 38.667), train_loss = 1.40669269, grad/param norm = 1.2427e-01, time/batch = 0.5392s	
2089/2700 (epoch 38.685), train_loss = 1.42147940, grad/param norm = 1.4306e-01, time/batch = 0.5407s	
2090/2700 (epoch 38.704), train_loss = 1.45901328, grad/param norm = 1.6856e-01, time/batch = 0.5876s	
2091/2700 (epoch 38.722), train_loss = 1.43226925, grad/param norm = 1.3533e-01, time/batch = 0.5550s	
2092/2700 (epoch 38.741), train_loss = 1.40431632, grad/param norm = 1.2652e-01, time/batch = 0.5407s	
2093/2700 (epoch 38.759), train_loss = 1.41690150, grad/param norm = 1.6016e-01, time/batch = 0.5211s	
2094/2700 (epoch 38.778), train_loss = 1.47504451, grad/param norm = 1.6789e-01, time/batch = 0.5649s	
2095/2700 (epoch 38.796), train_loss = 1.39199067, grad/param norm = 1.2086e-01, time/batch = 0.5594s	
2096/2700 (epoch 38.815), train_loss = 1.44935278, grad/param norm = 1.0657e-01, time/batch = 0.5664s	
2097/2700 (epoch 38.833), train_loss = 1.43421554, grad/param norm = 1.1918e-01, time/batch = 0.5387s	
2098/2700 (epoch 38.852), train_loss = 1.41177018, grad/param norm = 1.3735e-01, time/batch = 0.5398s	
2099/2700 (epoch 38.870), train_loss = 1.43553395, grad/param norm = 1.0349e-01, time/batch = 0.5655s	
2100/2700 (epoch 38.889), train_loss = 1.41738970, grad/param norm = 8.6306e-02, time/batch = 0.5802s	
2101/2700 (epoch 38.907), train_loss = 1.50831129, grad/param norm = 1.0029e-01, time/batch = 0.5318s	
2102/2700 (epoch 38.926), train_loss = 1.47191284, grad/param norm = 1.6546e-01, time/batch = 0.5230s	
2103/2700 (epoch 38.944), train_loss = 1.48626305, grad/param norm = 2.4263e-01, time/batch = 0.5317s	
2104/2700 (epoch 38.963), train_loss = 1.48069690, grad/param norm = 2.3102e-01, time/batch = 0.5530s	
2105/2700 (epoch 38.981), train_loss = 1.42646759, grad/param norm = 1.8770e-01, time/batch = 0.5858s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2106/2700 (epoch 39.000), train_loss = 1.48846324, grad/param norm = 1.4943e-01, time/batch = 0.5670s	
2107/2700 (epoch 39.019), train_loss = 1.50837135, grad/param norm = 1.1630e-01, time/batch = 0.5378s	
2108/2700 (epoch 39.037), train_loss = 1.45535655, grad/param norm = 8.9920e-02, time/batch = 0.5418s	
2109/2700 (epoch 39.056), train_loss = 1.41331326, grad/param norm = 9.1153e-02, time/batch = 0.5642s	
2110/2700 (epoch 39.074), train_loss = 1.41870731, grad/param norm = 8.0521e-02, time/batch = 0.5303s	
2111/2700 (epoch 39.093), train_loss = 1.39105046, grad/param norm = 1.0387e-01, time/batch = 0.5444s	
2112/2700 (epoch 39.111), train_loss = 1.35694483, grad/param norm = 1.0174e-01, time/batch = 0.5383s	
2113/2700 (epoch 39.130), train_loss = 1.42863084, grad/param norm = 9.1637e-02, time/batch = 0.5387s	
2114/2700 (epoch 39.148), train_loss = 1.39309073, grad/param norm = 8.4245e-02, time/batch = 0.5716s	
2115/2700 (epoch 39.167), train_loss = 1.44064463, grad/param norm = 9.4833e-02, time/batch = 0.5803s	
2116/2700 (epoch 39.185), train_loss = 1.39305537, grad/param norm = 9.2523e-02, time/batch = 0.5471s	
2117/2700 (epoch 39.204), train_loss = 1.41056626, grad/param norm = 1.0538e-01, time/batch = 0.5381s	
2118/2700 (epoch 39.222), train_loss = 1.38837021, grad/param norm = 1.0546e-01, time/batch = 0.5512s	
2119/2700 (epoch 39.241), train_loss = 1.31204446, grad/param norm = 9.1258e-02, time/batch = 0.5904s	
2120/2700 (epoch 39.259), train_loss = 1.37996490, grad/param norm = 8.7765e-02, time/batch = 0.5505s	
2121/2700 (epoch 39.278), train_loss = 1.43486006, grad/param norm = 9.4055e-02, time/batch = 0.5420s	
2122/2700 (epoch 39.296), train_loss = 1.41303390, grad/param norm = 8.4630e-02, time/batch = 0.5671s	
2123/2700 (epoch 39.315), train_loss = 1.37782158, grad/param norm = 1.0896e-01, time/batch = 0.5817s	
2124/2700 (epoch 39.333), train_loss = 1.39878729, grad/param norm = 1.7443e-01, time/batch = 0.5553s	
2125/2700 (epoch 39.352), train_loss = 1.42451241, grad/param norm = 1.9472e-01, time/batch = 0.5397s	
2126/2700 (epoch 39.370), train_loss = 1.43401930, grad/param norm = 1.8047e-01, time/batch = 0.5316s	
2127/2700 (epoch 39.389), train_loss = 1.41494523, grad/param norm = 2.0855e-01, time/batch = 0.5730s	
2128/2700 (epoch 39.407), train_loss = 1.49362789, grad/param norm = 2.0382e-01, time/batch = 0.5854s	
2129/2700 (epoch 39.426), train_loss = 1.50235764, grad/param norm = 1.3597e-01, time/batch = 0.5409s	
2130/2700 (epoch 39.444), train_loss = 1.39307409, grad/param norm = 1.0812e-01, time/batch = 0.5469s	
2131/2700 (epoch 39.463), train_loss = 1.47830637, grad/param norm = 1.0576e-01, time/batch = 0.5761s	
2132/2700 (epoch 39.481), train_loss = 1.44135808, grad/param norm = 8.4358e-02, time/batch = 0.5581s	
2133/2700 (epoch 39.500), train_loss = 1.36753069, grad/param norm = 9.5065e-02, time/batch = 0.5497s	
2134/2700 (epoch 39.519), train_loss = 1.42882719, grad/param norm = 8.7878e-02, time/batch = 0.5346s	
2135/2700 (epoch 39.537), train_loss = 1.43153226, grad/param norm = 1.1413e-01, time/batch = 0.5558s	
2136/2700 (epoch 39.556), train_loss = 1.33532335, grad/param norm = 9.5457e-02, time/batch = 0.5488s	
2137/2700 (epoch 39.574), train_loss = 1.36472231, grad/param norm = 9.7156e-02, time/batch = 0.5653s	
2138/2700 (epoch 39.593), train_loss = 1.40609836, grad/param norm = 9.9692e-02, time/batch = 0.5398s	
2139/2700 (epoch 39.611), train_loss = 1.33715634, grad/param norm = 1.2655e-01, time/batch = 0.5361s	
2140/2700 (epoch 39.630), train_loss = 1.38137224, grad/param norm = 1.7758e-01, time/batch = 0.5357s	
2141/2700 (epoch 39.648), train_loss = 1.39599043, grad/param norm = 1.5399e-01, time/batch = 0.5653s	
2142/2700 (epoch 39.667), train_loss = 1.38450574, grad/param norm = 1.2570e-01, time/batch = 0.5550s	
2143/2700 (epoch 39.685), train_loss = 1.39777293, grad/param norm = 1.1660e-01, time/batch = 0.5411s	
2144/2700 (epoch 39.704), train_loss = 1.42688551, grad/param norm = 1.1549e-01, time/batch = 0.5425s	
2145/2700 (epoch 39.722), train_loss = 1.41568148, grad/param norm = 1.1604e-01, time/batch = 0.5515s	
2146/2700 (epoch 39.741), train_loss = 1.38359572, grad/param norm = 1.0743e-01, time/batch = 0.5793s	
2147/2700 (epoch 39.759), train_loss = 1.39433543, grad/param norm = 1.1445e-01, time/batch = 0.5415s	
2148/2700 (epoch 39.778), train_loss = 1.44908663, grad/param norm = 1.2062e-01, time/batch = 0.5473s	
2149/2700 (epoch 39.796), train_loss = 1.37624898, grad/param norm = 1.6995e-01, time/batch = 0.5348s	
2150/2700 (epoch 39.815), train_loss = 1.44327293, grad/param norm = 2.0352e-01, time/batch = 0.5381s	
2151/2700 (epoch 39.833), train_loss = 1.43604058, grad/param norm = 2.0446e-01, time/batch = 0.5351s	
2152/2700 (epoch 39.852), train_loss = 1.40215935, grad/param norm = 1.5269e-01, time/batch = 0.5614s	
2153/2700 (epoch 39.870), train_loss = 1.41018419, grad/param norm = 8.7845e-02, time/batch = 0.5663s	
2154/2700 (epoch 39.889), train_loss = 1.39765390, grad/param norm = 8.7094e-02, time/batch = 0.5460s	
2155/2700 (epoch 39.907), train_loss = 1.48786435, grad/param norm = 1.0086e-01, time/batch = 0.5638s	
2156/2700 (epoch 39.926), train_loss = 1.44582390, grad/param norm = 1.3063e-01, time/batch = 0.5707s	
2157/2700 (epoch 39.944), train_loss = 1.44675474, grad/param norm = 1.4980e-01, time/batch = 0.5469s	
2158/2700 (epoch 39.963), train_loss = 1.42671072, grad/param norm = 1.2017e-01, time/batch = 0.5377s	
2159/2700 (epoch 39.981), train_loss = 1.37678752, grad/param norm = 9.2500e-02, time/batch = 0.5228s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2160/2700 (epoch 40.000), train_loss = 1.45101133, grad/param norm = 8.8485e-02, time/batch = 0.5580s	
2161/2700 (epoch 40.019), train_loss = 1.47792959, grad/param norm = 9.2119e-02, time/batch = 0.5485s	
2162/2700 (epoch 40.037), train_loss = 1.43351112, grad/param norm = 9.7473e-02, time/batch = 0.5642s	
2163/2700 (epoch 40.056), train_loss = 1.39405073, grad/param norm = 1.0067e-01, time/batch = 0.5425s	
2164/2700 (epoch 40.074), train_loss = 1.40122160, grad/param norm = 9.7275e-02, time/batch = 0.5391s	
2165/2700 (epoch 40.093), train_loss = 1.37255455, grad/param norm = 1.1768e-01, time/batch = 0.5602s	
2166/2700 (epoch 40.111), train_loss = 1.34387508, grad/param norm = 1.2543e-01, time/batch = 0.5610s	
2167/2700 (epoch 40.130), train_loss = 1.41154120, grad/param norm = 1.0811e-01, time/batch = 0.5653s	
2168/2700 (epoch 40.148), train_loss = 1.38132368, grad/param norm = 1.1164e-01, time/batch = 0.5402s	
2169/2700 (epoch 40.167), train_loss = 1.42518756, grad/param norm = 1.2148e-01, time/batch = 0.5362s	
2170/2700 (epoch 40.185), train_loss = 1.37632303, grad/param norm = 1.0847e-01, time/batch = 0.5769s	
2171/2700 (epoch 40.204), train_loss = 1.39544523, grad/param norm = 1.1874e-01, time/batch = 0.5510s	
2172/2700 (epoch 40.222), train_loss = 1.36848595, grad/param norm = 1.0700e-01, time/batch = 0.5449s	
2173/2700 (epoch 40.241), train_loss = 1.28974999, grad/param norm = 8.6132e-02, time/batch = 0.5377s	
2174/2700 (epoch 40.259), train_loss = 1.36045866, grad/param norm = 8.5195e-02, time/batch = 0.5498s	
2175/2700 (epoch 40.278), train_loss = 1.41224984, grad/param norm = 8.8888e-02, time/batch = 0.5725s	
2176/2700 (epoch 40.296), train_loss = 1.39879234, grad/param norm = 9.8170e-02, time/batch = 0.4996s	
2177/2700 (epoch 40.315), train_loss = 1.36785834, grad/param norm = 1.1727e-01, time/batch = 0.5588s	
2178/2700 (epoch 40.333), train_loss = 1.37627370, grad/param norm = 1.4503e-01, time/batch = 0.5392s	
2179/2700 (epoch 40.352), train_loss = 1.39336386, grad/param norm = 1.2913e-01, time/batch = 0.5379s	
2180/2700 (epoch 40.370), train_loss = 1.41343866, grad/param norm = 1.3675e-01, time/batch = 0.5584s	
2181/2700 (epoch 40.389), train_loss = 1.37361862, grad/param norm = 1.3014e-01, time/batch = 0.5547s	
2182/2700 (epoch 40.407), train_loss = 1.43938768, grad/param norm = 1.0687e-01, time/batch = 0.5542s	
2183/2700 (epoch 40.426), train_loss = 1.47150629, grad/param norm = 1.1640e-01, time/batch = 0.5324s	
2184/2700 (epoch 40.444), train_loss = 1.37142205, grad/param norm = 9.9095e-02, time/batch = 0.5406s	
2185/2700 (epoch 40.463), train_loss = 1.45612324, grad/param norm = 1.0850e-01, time/batch = 0.5623s	
2186/2700 (epoch 40.481), train_loss = 1.42309046, grad/param norm = 1.0589e-01, time/batch = 0.5541s	
2187/2700 (epoch 40.500), train_loss = 1.34975032, grad/param norm = 1.0542e-01, time/batch = 0.5574s	
2188/2700 (epoch 40.519), train_loss = 1.40625377, grad/param norm = 8.0565e-02, time/batch = 0.5344s	
2189/2700 (epoch 40.537), train_loss = 1.41025222, grad/param norm = 9.1709e-02, time/batch = 0.5365s	
2190/2700 (epoch 40.556), train_loss = 1.32013651, grad/param norm = 1.3520e-01, time/batch = 0.5539s	
2191/2700 (epoch 40.574), train_loss = 1.35916831, grad/param norm = 1.8418e-01, time/batch = 0.5620s	
2192/2700 (epoch 40.593), train_loss = 1.41131417, grad/param norm = 1.8908e-01, time/batch = 0.5678s	
2193/2700 (epoch 40.611), train_loss = 1.32485849, grad/param norm = 1.5244e-01, time/batch = 0.4817s	
2194/2700 (epoch 40.630), train_loss = 1.35013506, grad/param norm = 1.2168e-01, time/batch = 0.5385s	
2195/2700 (epoch 40.648), train_loss = 1.37584362, grad/param norm = 1.4616e-01, time/batch = 0.5727s	
2196/2700 (epoch 40.667), train_loss = 1.37477743, grad/param norm = 1.6373e-01, time/batch = 0.5694s	
2197/2700 (epoch 40.685), train_loss = 1.39469933, grad/param norm = 1.8753e-01, time/batch = 0.5454s	
2198/2700 (epoch 40.704), train_loss = 1.42739662, grad/param norm = 1.9555e-01, time/batch = 0.5383s	
2199/2700 (epoch 40.722), train_loss = 1.40016866, grad/param norm = 1.3684e-01, time/batch = 0.5373s	
2200/2700 (epoch 40.741), train_loss = 1.36362719, grad/param norm = 1.1539e-01, time/batch = 0.5522s	
2201/2700 (epoch 40.759), train_loss = 1.37007638, grad/param norm = 1.3682e-01, time/batch = 0.5320s	
2202/2700 (epoch 40.778), train_loss = 1.41993227, grad/param norm = 1.0579e-01, time/batch = 0.5301s	
2203/2700 (epoch 40.796), train_loss = 1.34571161, grad/param norm = 1.0490e-01, time/batch = 0.5022s	
2204/2700 (epoch 40.815), train_loss = 1.40938864, grad/param norm = 1.0322e-01, time/batch = 0.4567s	
2205/2700 (epoch 40.833), train_loss = 1.39119598, grad/param norm = 1.0046e-01, time/batch = 0.4651s	
2206/2700 (epoch 40.852), train_loss = 1.36521629, grad/param norm = 9.0266e-02, time/batch = 0.4822s	
2207/2700 (epoch 40.870), train_loss = 1.39339317, grad/param norm = 1.0905e-01, time/batch = 0.4396s	
2208/2700 (epoch 40.889), train_loss = 1.38702507, grad/param norm = 1.3650e-01, time/batch = 0.4535s	
2209/2700 (epoch 40.907), train_loss = 1.47232519, grad/param norm = 1.3407e-01, time/batch = 0.4017s	
2210/2700 (epoch 40.926), train_loss = 1.41675809, grad/param norm = 9.7529e-02, time/batch = 0.3233s	
2211/2700 (epoch 40.944), train_loss = 1.41679098, grad/param norm = 1.0336e-01, time/batch = 0.1984s	
2212/2700 (epoch 40.963), train_loss = 1.40371682, grad/param norm = 1.1082e-01, time/batch = 0.2620s	
2213/2700 (epoch 40.981), train_loss = 1.36719832, grad/param norm = 1.4696e-01, time/batch = 0.2626s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2214/2700 (epoch 41.000), train_loss = 1.44627329, grad/param norm = 1.7143e-01, time/batch = 0.2700s	
2215/2700 (epoch 41.019), train_loss = 1.47947609, grad/param norm = 1.8096e-01, time/batch = 0.2706s	
2216/2700 (epoch 41.037), train_loss = 1.43215109, grad/param norm = 1.6966e-01, time/batch = 0.2740s	
2217/2700 (epoch 41.056), train_loss = 1.38248078, grad/param norm = 1.1831e-01, time/batch = 0.2678s	
2218/2700 (epoch 41.074), train_loss = 1.38134845, grad/param norm = 1.0924e-01, time/batch = 0.2651s	
2219/2700 (epoch 41.093), train_loss = 1.35679230, grad/param norm = 1.2866e-01, time/batch = 0.2637s	
2220/2700 (epoch 41.111), train_loss = 1.32452197, grad/param norm = 1.0180e-01, time/batch = 0.2510s	
2221/2700 (epoch 41.130), train_loss = 1.39403766, grad/param norm = 1.0934e-01, time/batch = 0.2718s	
2222/2700 (epoch 41.148), train_loss = 1.36018610, grad/param norm = 8.4282e-02, time/batch = 0.2728s	
2223/2700 (epoch 41.167), train_loss = 1.40085263, grad/param norm = 9.6182e-02, time/batch = 0.2682s	
2224/2700 (epoch 41.185), train_loss = 1.35882540, grad/param norm = 1.1309e-01, time/batch = 0.2656s	
2225/2700 (epoch 41.204), train_loss = 1.36922927, grad/param norm = 1.1802e-01, time/batch = 0.2646s	
2226/2700 (epoch 41.222), train_loss = 1.35022246, grad/param norm = 1.2642e-01, time/batch = 0.2621s	
2227/2700 (epoch 41.241), train_loss = 1.28645682, grad/param norm = 1.2154e-01, time/batch = 0.2627s	
2228/2700 (epoch 41.259), train_loss = 1.34975313, grad/param norm = 1.2675e-01, time/batch = 0.2625s	
2229/2700 (epoch 41.278), train_loss = 1.39718495, grad/param norm = 1.2020e-01, time/batch = 0.2435s	
2230/2700 (epoch 41.296), train_loss = 1.38561592, grad/param norm = 1.4068e-01, time/batch = 0.2625s	
2231/2700 (epoch 41.315), train_loss = 1.35998464, grad/param norm = 1.6067e-01, time/batch = 0.2717s	
2232/2700 (epoch 41.333), train_loss = 1.36103632, grad/param norm = 1.4751e-01, time/batch = 0.2745s	
2233/2700 (epoch 41.352), train_loss = 1.37956873, grad/param norm = 1.6463e-01, time/batch = 0.2668s	
2234/2700 (epoch 41.370), train_loss = 1.40294672, grad/param norm = 2.0820e-01, time/batch = 0.2646s	
2235/2700 (epoch 41.389), train_loss = 1.35287135, grad/param norm = 1.7030e-01, time/batch = 0.2633s	
2236/2700 (epoch 41.407), train_loss = 1.41841575, grad/param norm = 1.2591e-01, time/batch = 0.2621s	
2237/2700 (epoch 41.426), train_loss = 1.45383301, grad/param norm = 1.2857e-01, time/batch = 0.2625s	
2238/2700 (epoch 41.444), train_loss = 1.35792251, grad/param norm = 9.2751e-02, time/batch = 0.2425s	
2239/2700 (epoch 41.463), train_loss = 1.44183898, grad/param norm = 1.0240e-01, time/batch = 0.2619s	
2240/2700 (epoch 41.481), train_loss = 1.40570122, grad/param norm = 1.0976e-01, time/batch = 0.2628s	
2241/2700 (epoch 41.500), train_loss = 1.33192649, grad/param norm = 1.2467e-01, time/batch = 0.2731s	
2242/2700 (epoch 41.519), train_loss = 1.39649241, grad/param norm = 1.2107e-01, time/batch = 0.2733s	
2243/2700 (epoch 41.537), train_loss = 1.39945352, grad/param norm = 1.4093e-01, time/batch = 0.2660s	
2244/2700 (epoch 41.556), train_loss = 1.30068630, grad/param norm = 1.2040e-01, time/batch = 0.2648s	
2245/2700 (epoch 41.574), train_loss = 1.33147729, grad/param norm = 1.1769e-01, time/batch = 0.2629s	
2246/2700 (epoch 41.593), train_loss = 1.37993306, grad/param norm = 1.5337e-01, time/batch = 0.2625s	
2247/2700 (epoch 41.611), train_loss = 1.32256833, grad/param norm = 1.8068e-01, time/batch = 0.2465s	
2248/2700 (epoch 41.630), train_loss = 1.34893486, grad/param norm = 1.7755e-01, time/batch = 0.2621s	
2249/2700 (epoch 41.648), train_loss = 1.35549626, grad/param norm = 1.3215e-01, time/batch = 0.2625s	
2250/2700 (epoch 41.667), train_loss = 1.35001159, grad/param norm = 1.1270e-01, time/batch = 0.2616s	
2251/2700 (epoch 41.685), train_loss = 1.36072961, grad/param norm = 9.7714e-02, time/batch = 0.2701s	
2252/2700 (epoch 41.704), train_loss = 1.38508285, grad/param norm = 9.6518e-02, time/batch = 0.2693s	
2253/2700 (epoch 41.722), train_loss = 1.37471746, grad/param norm = 1.0267e-01, time/batch = 0.2659s	
2254/2700 (epoch 41.741), train_loss = 1.34053815, grad/param norm = 9.6239e-02, time/batch = 0.2640s	
2255/2700 (epoch 41.759), train_loss = 1.34172526, grad/param norm = 8.6393e-02, time/batch = 0.2623s	
2256/2700 (epoch 41.778), train_loss = 1.39519196, grad/param norm = 1.0072e-01, time/batch = 0.2482s	
2257/2700 (epoch 41.796), train_loss = 1.32804680, grad/param norm = 1.6589e-01, time/batch = 0.2627s	
2258/2700 (epoch 41.815), train_loss = 1.39487967, grad/param norm = 1.5777e-01, time/batch = 0.2617s	
2259/2700 (epoch 41.833), train_loss = 1.37775674, grad/param norm = 1.4724e-01, time/batch = 0.2616s	
2260/2700 (epoch 41.852), train_loss = 1.35443837, grad/param norm = 1.2732e-01, time/batch = 0.2623s	
2261/2700 (epoch 41.870), train_loss = 1.36965580, grad/param norm = 8.9682e-02, time/batch = 0.2738s	
2262/2700 (epoch 41.889), train_loss = 1.35758446, grad/param norm = 8.5241e-02, time/batch = 0.2668s	
2263/2700 (epoch 41.907), train_loss = 1.44226800, grad/param norm = 9.2076e-02, time/batch = 0.2649s	
2264/2700 (epoch 41.926), train_loss = 1.39921432, grad/param norm = 1.2890e-01, time/batch = 0.2640s	
2265/2700 (epoch 41.944), train_loss = 1.41009824, grad/param norm = 1.6053e-01, time/batch = 0.2493s	
2266/2700 (epoch 41.963), train_loss = 1.39817259, grad/param norm = 1.6938e-01, time/batch = 0.2633s	
2267/2700 (epoch 41.981), train_loss = 1.35542758, grad/param norm = 1.5634e-01, time/batch = 0.2632s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2268/2700 (epoch 42.000), train_loss = 1.42237374, grad/param norm = 1.5022e-01, time/batch = 0.2624s	
2269/2700 (epoch 42.019), train_loss = 1.44867293, grad/param norm = 1.3663e-01, time/batch = 0.2617s	
2270/2700 (epoch 42.037), train_loss = 1.39939535, grad/param norm = 1.3188e-01, time/batch = 0.2698s	
2271/2700 (epoch 42.056), train_loss = 1.37242718, grad/param norm = 1.7639e-01, time/batch = 0.2652s	
2272/2700 (epoch 42.074), train_loss = 1.37128694, grad/param norm = 1.5992e-01, time/batch = 0.2638s	
2273/2700 (epoch 42.093), train_loss = 1.33593362, grad/param norm = 1.0595e-01, time/batch = 0.2618s	
2274/2700 (epoch 42.111), train_loss = 1.30829234, grad/param norm = 1.1148e-01, time/batch = 0.2482s	
2275/2700 (epoch 42.130), train_loss = 1.38127241, grad/param norm = 1.5232e-01, time/batch = 0.2626s	
2276/2700 (epoch 42.148), train_loss = 1.34951720, grad/param norm = 1.3136e-01, time/batch = 0.2624s	
2277/2700 (epoch 42.167), train_loss = 1.38674788, grad/param norm = 1.3048e-01, time/batch = 0.2616s	
2278/2700 (epoch 42.185), train_loss = 1.33898991, grad/param norm = 1.1603e-01, time/batch = 0.2625s	
2279/2700 (epoch 42.204), train_loss = 1.35196949, grad/param norm = 1.1494e-01, time/batch = 0.2715s	
2280/2700 (epoch 42.222), train_loss = 1.32685099, grad/param norm = 1.0139e-01, time/batch = 0.2750s	
2281/2700 (epoch 42.241), train_loss = 1.25846623, grad/param norm = 8.9548e-02, time/batch = 0.2637s	
2282/2700 (epoch 42.259), train_loss = 1.32364226, grad/param norm = 9.3727e-02, time/batch = 0.2706s	
2283/2700 (epoch 42.278), train_loss = 1.37160472, grad/param norm = 8.3075e-02, time/batch = 0.2072s	
2284/2700 (epoch 42.296), train_loss = 1.35573365, grad/param norm = 7.6160e-02, time/batch = 0.2632s	
2285/2700 (epoch 42.315), train_loss = 1.31833898, grad/param norm = 1.0809e-01, time/batch = 0.2620s	
2286/2700 (epoch 42.333), train_loss = 1.33857266, grad/param norm = 1.5824e-01, time/batch = 0.2692s	
2287/2700 (epoch 42.352), train_loss = 1.35524279, grad/param norm = 1.7339e-01, time/batch = 0.2712s	
2288/2700 (epoch 42.370), train_loss = 1.37433168, grad/param norm = 1.4952e-01, time/batch = 0.2741s	
2289/2700 (epoch 42.389), train_loss = 1.32789928, grad/param norm = 1.4615e-01, time/batch = 0.2678s	
2290/2700 (epoch 42.407), train_loss = 1.41414029, grad/param norm = 1.6692e-01, time/batch = 0.2666s	
2291/2700 (epoch 42.426), train_loss = 1.44778588, grad/param norm = 1.7520e-01, time/batch = 0.2729s	
2292/2700 (epoch 42.444), train_loss = 1.34758360, grad/param norm = 1.3854e-01, time/batch = 0.1986s	
2293/2700 (epoch 42.463), train_loss = 1.41718632, grad/param norm = 1.0447e-01, time/batch = 0.2617s	
2294/2700 (epoch 42.481), train_loss = 1.37814725, grad/param norm = 8.1846e-02, time/batch = 0.2626s	
2295/2700 (epoch 42.500), train_loss = 1.30588302, grad/param norm = 8.4956e-02, time/batch = 0.2718s	
2296/2700 (epoch 42.519), train_loss = 1.37174727, grad/param norm = 9.1808e-02, time/batch = 0.2724s	
2297/2700 (epoch 42.537), train_loss = 1.38279645, grad/param norm = 1.1264e-01, time/batch = 0.2746s	
2298/2700 (epoch 42.556), train_loss = 1.28964053, grad/param norm = 1.1541e-01, time/batch = 0.2670s	
2299/2700 (epoch 42.574), train_loss = 1.31550229, grad/param norm = 1.1879e-01, time/batch = 0.2661s	
2300/2700 (epoch 42.593), train_loss = 1.35828635, grad/param norm = 1.2226e-01, time/batch = 0.2630s	
2301/2700 (epoch 42.611), train_loss = 1.28672624, grad/param norm = 1.0068e-01, time/batch = 0.2183s	
2302/2700 (epoch 42.630), train_loss = 1.30883464, grad/param norm = 8.5004e-02, time/batch = 0.2625s	
2303/2700 (epoch 42.648), train_loss = 1.32795751, grad/param norm = 8.4672e-02, time/batch = 0.2626s	
2304/2700 (epoch 42.667), train_loss = 1.32456570, grad/param norm = 9.5481e-02, time/batch = 0.2710s	
2305/2700 (epoch 42.685), train_loss = 1.34051750, grad/param norm = 1.0228e-01, time/batch = 0.2711s	
2306/2700 (epoch 42.704), train_loss = 1.36752481, grad/param norm = 1.2092e-01, time/batch = 0.2732s	
2307/2700 (epoch 42.722), train_loss = 1.35650285, grad/param norm = 1.0472e-01, time/batch = 0.2694s	
2308/2700 (epoch 42.741), train_loss = 1.32447025, grad/param norm = 1.2789e-01, time/batch = 0.2664s	
2309/2700 (epoch 42.759), train_loss = 1.33621805, grad/param norm = 1.8834e-01, time/batch = 0.2638s	
2310/2700 (epoch 42.778), train_loss = 1.39079329, grad/param norm = 1.9069e-01, time/batch = 0.2507s	
2311/2700 (epoch 42.796), train_loss = 1.31283672, grad/param norm = 1.6727e-01, time/batch = 0.2714s	
2312/2700 (epoch 42.815), train_loss = 1.38255939, grad/param norm = 1.7811e-01, time/batch = 0.2732s	
2313/2700 (epoch 42.833), train_loss = 1.36177859, grad/param norm = 1.6468e-01, time/batch = 0.2713s	
2314/2700 (epoch 42.852), train_loss = 1.33452160, grad/param norm = 1.4587e-01, time/batch = 0.2652s	
2315/2700 (epoch 42.870), train_loss = 1.36544541, grad/param norm = 1.8106e-01, time/batch = 0.2640s	
2316/2700 (epoch 42.889), train_loss = 1.35649592, grad/param norm = 1.8250e-01, time/batch = 0.2635s	
2317/2700 (epoch 42.907), train_loss = 1.43327998, grad/param norm = 1.4880e-01, time/batch = 0.2628s	
2318/2700 (epoch 42.926), train_loss = 1.37701045, grad/param norm = 1.0088e-01, time/batch = 0.2627s	
2319/2700 (epoch 42.944), train_loss = 1.37343363, grad/param norm = 8.9859e-02, time/batch = 0.2441s	
2320/2700 (epoch 42.963), train_loss = 1.36171772, grad/param norm = 1.1236e-01, time/batch = 0.2624s	
2321/2700 (epoch 42.981), train_loss = 1.33874082, grad/param norm = 1.6767e-01, time/batch = 0.2734s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
2322/2700 (epoch 43.000), train_loss = 1.40572548, grad/param norm = 1.5053e-01, time/batch = 0.2745s	
2323/2700 (epoch 43.019), train_loss = 1.43560378, grad/param norm = 1.2959e-01, time/batch = 0.2670s	
2324/2700 (epoch 43.037), train_loss = 1.37774912, grad/param norm = 1.0305e-01, time/batch = 0.2658s	
2325/2700 (epoch 43.056), train_loss = 1.33648039, grad/param norm = 9.5065e-02, time/batch = 0.2626s	
2326/2700 (epoch 43.074), train_loss = 1.34146965, grad/param norm = 9.5800e-02, time/batch = 0.2606s	
2327/2700 (epoch 43.093), train_loss = 1.31677297, grad/param norm = 1.2290e-01, time/batch = 0.2630s	
2328/2700 (epoch 43.111), train_loss = 1.29105414, grad/param norm = 1.0526e-01, time/batch = 0.2445s	
2329/2700 (epoch 43.130), train_loss = 1.35283908, grad/param norm = 9.5424e-02, time/batch = 0.2619s	
2330/2700 (epoch 43.148), train_loss = 1.32232343, grad/param norm = 8.5984e-02, time/batch = 0.2614s	
2331/2700 (epoch 43.167), train_loss = 1.36178852, grad/param norm = 1.0711e-01, time/batch = 0.2761s	
2332/2700 (epoch 43.185), train_loss = 1.32041513, grad/param norm = 1.0950e-01, time/batch = 0.2701s	
2333/2700 (epoch 43.204), train_loss = 1.33861318, grad/param norm = 1.3406e-01, time/batch = 0.2658s	
2334/2700 (epoch 43.222), train_loss = 1.31754778, grad/param norm = 1.5587e-01, time/batch = 0.2641s	
2335/2700 (epoch 43.241), train_loss = 1.25314975, grad/param norm = 1.5212e-01, time/batch = 0.2617s	
2336/2700 (epoch 43.259), train_loss = 1.31244366, grad/param norm = 1.2265e-01, time/batch = 0.2631s	
2337/2700 (epoch 43.278), train_loss = 1.36386815, grad/param norm = 1.3141e-01, time/batch = 0.2446s	
2338/2700 (epoch 43.296), train_loss = 1.34804692, grad/param norm = 1.3828e-01, time/batch = 0.2625s	
2339/2700 (epoch 43.315), train_loss = 1.31126389, grad/param norm = 1.7890e-01, time/batch = 0.2624s	
2340/2700 (epoch 43.333), train_loss = 1.32732990, grad/param norm = 1.9604e-01, time/batch = 0.2624s	
2341/2700 (epoch 43.352), train_loss = 1.32683794, grad/param norm = 1.3983e-01, time/batch = 0.2712s	
2342/2700 (epoch 43.370), train_loss = 1.33809181, grad/param norm = 9.9860e-02, time/batch = 0.2688s	
2343/2700 (epoch 43.389), train_loss = 1.29797547, grad/param norm = 1.0208e-01, time/batch = 0.2664s	
2344/2700 (epoch 43.407), train_loss = 1.37986855, grad/param norm = 1.2403e-01, time/batch = 0.2645s	
2345/2700 (epoch 43.426), train_loss = 1.41136019, grad/param norm = 1.0443e-01, time/batch = 0.2621s	
2346/2700 (epoch 43.444), train_loss = 1.32310471, grad/param norm = 9.8532e-02, time/batch = 0.2484s	
2347/2700 (epoch 43.463), train_loss = 1.40480424, grad/param norm = 1.1995e-01, time/batch = 0.2633s	
2348/2700 (epoch 43.481), train_loss = 1.37790091, grad/param norm = 1.5968e-01, time/batch = 0.2624s	
2349/2700 (epoch 43.500), train_loss = 1.31079568, grad/param norm = 1.5711e-01, time/batch = 0.2617s	
2350/2700 (epoch 43.519), train_loss = 1.36384130, grad/param norm = 1.3509e-01, time/batch = 0.2614s	
2351/2700 (epoch 43.537), train_loss = 1.37112809, grad/param norm = 1.3977e-01, time/batch = 0.2738s	
2352/2700 (epoch 43.556), train_loss = 1.26880901, grad/param norm = 1.0791e-01, time/batch = 0.2664s	
2353/2700 (epoch 43.574), train_loss = 1.28922030, grad/param norm = 8.9335e-02, time/batch = 0.2630s	
2354/2700 (epoch 43.593), train_loss = 1.33073892, grad/param norm = 8.5160e-02, time/batch = 0.2632s	
2355/2700 (epoch 43.611), train_loss = 1.26491990, grad/param norm = 1.0576e-01, time/batch = 0.2497s	
2356/2700 (epoch 43.630), train_loss = 1.29847632, grad/param norm = 1.3336e-01, time/batch = 0.2632s	
2357/2700 (epoch 43.648), train_loss = 1.31488726, grad/param norm = 1.1068e-01, time/batch = 0.2611s	
2358/2700 (epoch 43.667), train_loss = 1.30842555, grad/param norm = 9.3942e-02, time/batch = 0.2625s	
2359/2700 (epoch 43.685), train_loss = 1.32589598, grad/param norm = 1.1538e-01, time/batch = 0.2617s	
2360/2700 (epoch 43.704), train_loss = 1.35652056, grad/param norm = 1.3210e-01, time/batch = 0.2690s	
2361/2700 (epoch 43.722), train_loss = 1.35023150, grad/param norm = 1.4039e-01, time/batch = 0.2664s	
2362/2700 (epoch 43.741), train_loss = 1.31705211, grad/param norm = 1.4482e-01, time/batch = 0.2635s	
2363/2700 (epoch 43.759), train_loss = 1.32401557, grad/param norm = 1.5569e-01, time/batch = 0.2633s	
2364/2700 (epoch 43.778), train_loss = 1.38185577, grad/param norm = 1.7804e-01, time/batch = 0.2477s	
2365/2700 (epoch 43.796), train_loss = 1.30922993, grad/param norm = 2.2066e-01, time/batch = 0.2629s	
2366/2700 (epoch 43.815), train_loss = 1.36614754, grad/param norm = 1.9201e-01, time/batch = 0.2622s	
2367/2700 (epoch 43.833), train_loss = 1.34462304, grad/param norm = 1.5178e-01, time/batch = 0.2612s	
2368/2700 (epoch 43.852), train_loss = 1.31718611, grad/param norm = 1.2143e-01, time/batch = 0.2618s	
2369/2700 (epoch 43.870), train_loss = 1.33121835, grad/param norm = 8.9015e-02, time/batch = 0.2702s	
2370/2700 (epoch 43.889), train_loss = 1.32330100, grad/param norm = 9.2812e-02, time/batch = 0.2739s	
2371/2700 (epoch 43.907), train_loss = 1.41228108, grad/param norm = 1.3803e-01, time/batch = 0.2627s	
2372/2700 (epoch 43.926), train_loss = 1.37963058, grad/param norm = 2.0724e-01, time/batch = 0.2621s	
2373/2700 (epoch 43.944), train_loss = 1.37943338, grad/param norm = 2.0517e-01, time/batch = 0.2289s	
2374/2700 (epoch 43.963), train_loss = 1.34646897, grad/param norm = 1.5545e-01, time/batch = 0.2629s	
2375/2700 (epoch 43.981), train_loss = 1.30299058, grad/param norm = 1.2637e-01, time/batch = 0.2627s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
2376/2700 (epoch 44.000), train_loss = 1.37540416, grad/param norm = 1.2593e-01, time/batch = 0.2646s	
2377/2700 (epoch 44.019), train_loss = 1.41465617, grad/param norm = 1.3192e-01, time/batch = 0.2718s	
2378/2700 (epoch 44.037), train_loss = 1.36473715, grad/param norm = 1.2313e-01, time/batch = 0.2714s	
2379/2700 (epoch 44.056), train_loss = 1.32945802, grad/param norm = 1.5363e-01, time/batch = 0.2745s	
2380/2700 (epoch 44.074), train_loss = 1.32616842, grad/param norm = 1.2431e-01, time/batch = 0.2658s	
2381/2700 (epoch 44.093), train_loss = 1.29781906, grad/param norm = 9.7335e-02, time/batch = 0.2700s	
2382/2700 (epoch 44.111), train_loss = 1.27276734, grad/param norm = 8.9916e-02, time/batch = 0.2038s	
2383/2700 (epoch 44.130), train_loss = 1.33502725, grad/param norm = 1.0880e-01, time/batch = 0.2630s	
2384/2700 (epoch 44.148), train_loss = 1.31136659, grad/param norm = 1.0243e-01, time/batch = 0.2628s	
2385/2700 (epoch 44.167), train_loss = 1.34489272, grad/param norm = 1.0194e-01, time/batch = 0.2692s	
2386/2700 (epoch 44.185), train_loss = 1.30349184, grad/param norm = 1.0066e-01, time/batch = 0.2713s	
2387/2700 (epoch 44.204), train_loss = 1.31659453, grad/param norm = 1.1082e-01, time/batch = 0.2756s	
2388/2700 (epoch 44.222), train_loss = 1.28892707, grad/param norm = 1.0417e-01, time/batch = 0.2662s	
2389/2700 (epoch 44.241), train_loss = 1.22954723, grad/param norm = 1.0572e-01, time/batch = 0.2658s	
2390/2700 (epoch 44.259), train_loss = 1.29426118, grad/param norm = 1.2488e-01, time/batch = 0.2636s	
2391/2700 (epoch 44.278), train_loss = 1.34132041, grad/param norm = 1.2221e-01, time/batch = 0.2158s	
2392/2700 (epoch 44.296), train_loss = 1.32978649, grad/param norm = 1.3688e-01, time/batch = 0.2617s	
2393/2700 (epoch 44.315), train_loss = 1.28824528, grad/param norm = 1.4447e-01, time/batch = 0.2624s	
2394/2700 (epoch 44.333), train_loss = 1.29994945, grad/param norm = 1.4782e-01, time/batch = 0.2641s	
2395/2700 (epoch 44.352), train_loss = 1.32940764, grad/param norm = 1.9840e-01, time/batch = 0.2696s	
2396/2700 (epoch 44.370), train_loss = 1.35421238, grad/param norm = 2.3012e-01, time/batch = 0.2729s	
2397/2700 (epoch 44.389), train_loss = 1.29547798, grad/param norm = 1.5286e-01, time/batch = 0.2736s	
2398/2700 (epoch 44.407), train_loss = 1.36087947, grad/param norm = 1.2174e-01, time/batch = 0.2658s	
2399/2700 (epoch 44.426), train_loss = 1.38977619, grad/param norm = 1.2794e-01, time/batch = 0.2652s	
2400/2700 (epoch 44.444), train_loss = 1.30543265, grad/param norm = 1.0239e-01, time/batch = 0.2502s	
2401/2700 (epoch 44.463), train_loss = 1.38053615, grad/param norm = 1.0596e-01, time/batch = 0.2719s	
2402/2700 (epoch 44.481), train_loss = 1.34735170, grad/param norm = 1.3836e-01, time/batch = 0.2726s	
2403/2700 (epoch 44.500), train_loss = 1.28048371, grad/param norm = 1.4190e-01, time/batch = 0.2741s	
2404/2700 (epoch 44.519), train_loss = 1.34190447, grad/param norm = 1.0780e-01, time/batch = 0.2661s	
2405/2700 (epoch 44.537), train_loss = 1.34425612, grad/param norm = 1.0448e-01, time/batch = 0.2642s	
2406/2700 (epoch 44.556), train_loss = 1.24803415, grad/param norm = 1.1703e-01, time/batch = 0.2628s	
2407/2700 (epoch 44.574), train_loss = 1.29020919, grad/param norm = 1.4482e-01, time/batch = 0.2620s	
2408/2700 (epoch 44.593), train_loss = 1.33613780, grad/param norm = 1.2465e-01, time/batch = 0.2625s	
2409/2700 (epoch 44.611), train_loss = 1.25117740, grad/param norm = 9.8161e-02, time/batch = 0.2428s	
2410/2700 (epoch 44.630), train_loss = 1.27542074, grad/param norm = 9.2462e-02, time/batch = 0.2626s	
2411/2700 (epoch 44.648), train_loss = 1.29461135, grad/param norm = 9.7775e-02, time/batch = 0.2755s	
2412/2700 (epoch 44.667), train_loss = 1.29526978, grad/param norm = 1.2167e-01, time/batch = 0.2747s	
2413/2700 (epoch 44.685), train_loss = 1.31522388, grad/param norm = 1.5718e-01, time/batch = 0.2659s	
2414/2700 (epoch 44.704), train_loss = 1.34344500, grad/param norm = 1.7320e-01, time/batch = 0.2645s	
2415/2700 (epoch 44.722), train_loss = 1.32958399, grad/param norm = 1.2003e-01, time/batch = 0.2630s	
2416/2700 (epoch 44.741), train_loss = 1.29041522, grad/param norm = 1.2614e-01, time/batch = 0.2626s	
2417/2700 (epoch 44.759), train_loss = 1.29312840, grad/param norm = 1.6252e-01, time/batch = 0.2608s	
2418/2700 (epoch 44.778), train_loss = 1.34437567, grad/param norm = 1.3080e-01, time/batch = 0.2434s	
2419/2700 (epoch 44.796), train_loss = 1.26384895, grad/param norm = 1.1030e-01, time/batch = 0.2629s	
2420/2700 (epoch 44.815), train_loss = 1.32761220, grad/param norm = 1.2433e-01, time/batch = 0.2627s	
2421/2700 (epoch 44.833), train_loss = 1.31568337, grad/param norm = 1.2623e-01, time/batch = 0.2716s	
2422/2700 (epoch 44.852), train_loss = 1.29653286, grad/param norm = 1.3890e-01, time/batch = 0.2712s	
2423/2700 (epoch 44.870), train_loss = 1.32531967, grad/param norm = 1.8551e-01, time/batch = 0.2667s	
2424/2700 (epoch 44.889), train_loss = 1.31624701, grad/param norm = 1.7227e-01, time/batch = 0.2642s	
2425/2700 (epoch 44.907), train_loss = 1.38920841, grad/param norm = 1.3624e-01, time/batch = 0.2624s	
2426/2700 (epoch 44.926), train_loss = 1.33514763, grad/param norm = 9.4759e-02, time/batch = 0.2610s	
2427/2700 (epoch 44.944), train_loss = 1.33616893, grad/param norm = 1.0569e-01, time/batch = 0.2624s	
2428/2700 (epoch 44.963), train_loss = 1.32192640, grad/param norm = 1.4353e-01, time/batch = 0.2028s	
2429/2700 (epoch 44.981), train_loss = 1.30403123, grad/param norm = 2.1360e-01, time/batch = 0.1633s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
2430/2700 (epoch 45.000), train_loss = 1.37632352, grad/param norm = 1.9407e-01, time/batch = 0.1559s	
2431/2700 (epoch 45.019), train_loss = 1.40639889, grad/param norm = 1.4816e-01, time/batch = 0.1472s	
2432/2700 (epoch 45.037), train_loss = 1.34265434, grad/param norm = 1.1013e-01, time/batch = 0.1439s	
2433/2700 (epoch 45.056), train_loss = 1.30269627, grad/param norm = 9.5673e-02, time/batch = 0.1475s	
2434/2700 (epoch 45.074), train_loss = 1.30247615, grad/param norm = 9.9577e-02, time/batch = 0.1451s	
2435/2700 (epoch 45.093), train_loss = 1.28405822, grad/param norm = 1.3853e-01, time/batch = 0.1467s	
2436/2700 (epoch 45.111), train_loss = 1.26087397, grad/param norm = 1.1586e-01, time/batch = 0.1447s	
2437/2700 (epoch 45.130), train_loss = 1.31793076, grad/param norm = 1.0812e-01, time/batch = 0.1440s	
2438/2700 (epoch 45.148), train_loss = 1.29178057, grad/param norm = 9.5140e-02, time/batch = 0.1474s	
2439/2700 (epoch 45.167), train_loss = 1.32451332, grad/param norm = 1.0481e-01, time/batch = 0.1463s	
2440/2700 (epoch 45.185), train_loss = 1.28755910, grad/param norm = 1.0808e-01, time/batch = 0.1484s	
2441/2700 (epoch 45.204), train_loss = 1.29979144, grad/param norm = 1.1459e-01, time/batch = 0.1455s	
2442/2700 (epoch 45.222), train_loss = 1.27398861, grad/param norm = 1.2309e-01, time/batch = 0.1473s	
2443/2700 (epoch 45.241), train_loss = 1.21626539, grad/param norm = 1.2071e-01, time/batch = 0.1453s	
2444/2700 (epoch 45.259), train_loss = 1.27371250, grad/param norm = 1.0088e-01, time/batch = 0.1460s	
2445/2700 (epoch 45.278), train_loss = 1.32420873, grad/param norm = 1.0933e-01, time/batch = 0.1461s	
2446/2700 (epoch 45.296), train_loss = 1.30842155, grad/param norm = 1.0901e-01, time/batch = 0.1440s	
2447/2700 (epoch 45.315), train_loss = 1.26470431, grad/param norm = 1.4706e-01, time/batch = 0.1477s	
2448/2700 (epoch 45.333), train_loss = 1.29563359, grad/param norm = 1.7892e-01, time/batch = 0.1463s	
2449/2700 (epoch 45.352), train_loss = 1.29632181, grad/param norm = 1.5937e-01, time/batch = 0.1462s	
2450/2700 (epoch 45.370), train_loss = 1.30856697, grad/param norm = 1.2042e-01, time/batch = 0.1461s	
2451/2700 (epoch 45.389), train_loss = 1.27057679, grad/param norm = 1.3523e-01, time/batch = 0.1462s	
2452/2700 (epoch 45.407), train_loss = 1.35178829, grad/param norm = 1.5409e-01, time/batch = 0.1460s	
2453/2700 (epoch 45.426), train_loss = 1.37340137, grad/param norm = 1.2273e-01, time/batch = 0.1444s	
2454/2700 (epoch 45.444), train_loss = 1.29034927, grad/param norm = 1.1128e-01, time/batch = 0.1480s	
2455/2700 (epoch 45.463), train_loss = 1.36265332, grad/param norm = 9.9289e-02, time/batch = 0.1444s	
2456/2700 (epoch 45.481), train_loss = 1.32528340, grad/param norm = 9.0823e-02, time/batch = 0.1464s	
2457/2700 (epoch 45.500), train_loss = 1.25400938, grad/param norm = 9.6116e-02, time/batch = 0.1456s	
2458/2700 (epoch 45.519), train_loss = 1.32121673, grad/param norm = 1.0963e-01, time/batch = 0.1447s	
2459/2700 (epoch 45.537), train_loss = 1.33156068, grad/param norm = 1.5430e-01, time/batch = 0.1470s	
2460/2700 (epoch 45.556), train_loss = 1.25090396, grad/param norm = 2.1578e-01, time/batch = 0.1446s	
2461/2700 (epoch 45.574), train_loss = 1.27682528, grad/param norm = 1.9474e-01, time/batch = 0.1477s	
2462/2700 (epoch 45.593), train_loss = 1.31131823, grad/param norm = 1.4705e-01, time/batch = 0.1441s	
2463/2700 (epoch 45.611), train_loss = 1.23298926, grad/param norm = 1.0782e-01, time/batch = 0.1475s	
2464/2700 (epoch 45.630), train_loss = 1.25913153, grad/param norm = 9.5685e-02, time/batch = 0.1455s	
2465/2700 (epoch 45.648), train_loss = 1.28096174, grad/param norm = 1.1840e-01, time/batch = 0.1438s	
2466/2700 (epoch 45.667), train_loss = 1.27836196, grad/param norm = 1.2677e-01, time/batch = 0.1457s	
2467/2700 (epoch 45.685), train_loss = 1.29596590, grad/param norm = 1.3403e-01, time/batch = 0.1440s	
2468/2700 (epoch 45.704), train_loss = 1.31842956, grad/param norm = 1.2692e-01, time/batch = 0.1482s	
2469/2700 (epoch 45.722), train_loss = 1.31439014, grad/param norm = 9.8409e-02, time/batch = 0.1453s	
2470/2700 (epoch 45.741), train_loss = 1.27394719, grad/param norm = 1.0067e-01, time/batch = 0.1451s	
2471/2700 (epoch 45.759), train_loss = 1.27044444, grad/param norm = 9.9751e-02, time/batch = 0.1461s	
2472/2700 (epoch 45.778), train_loss = 1.32490651, grad/param norm = 1.3248e-01, time/batch = 0.1436s	
2473/2700 (epoch 45.796), train_loss = 1.25803025, grad/param norm = 1.9431e-01, time/batch = 0.1463s	
2474/2700 (epoch 45.815), train_loss = 1.32241213, grad/param norm = 1.7603e-01, time/batch = 0.1451s	
2475/2700 (epoch 45.833), train_loss = 1.30903763, grad/param norm = 1.5721e-01, time/batch = 0.1477s	
2476/2700 (epoch 45.852), train_loss = 1.27987914, grad/param norm = 1.2486e-01, time/batch = 0.1463s	
2477/2700 (epoch 45.870), train_loss = 1.29255896, grad/param norm = 9.2455e-02, time/batch = 0.1456s	
2478/2700 (epoch 45.889), train_loss = 1.28831487, grad/param norm = 1.0758e-01, time/batch = 0.1466s	
2479/2700 (epoch 45.907), train_loss = 1.37570734, grad/param norm = 1.5525e-01, time/batch = 0.1446s	
2480/2700 (epoch 45.926), train_loss = 1.34011540, grad/param norm = 2.0976e-01, time/batch = 0.1476s	
2481/2700 (epoch 45.944), train_loss = 1.33667075, grad/param norm = 1.9013e-01, time/batch = 0.1455s	
2482/2700 (epoch 45.963), train_loss = 1.30388667, grad/param norm = 1.4655e-01, time/batch = 0.1470s	
2483/2700 (epoch 45.981), train_loss = 1.27088729, grad/param norm = 1.3967e-01, time/batch = 0.1448s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
2484/2700 (epoch 46.000), train_loss = 1.34040925, grad/param norm = 1.3676e-01, time/batch = 0.1470s	
2485/2700 (epoch 46.019), train_loss = 1.38041304, grad/param norm = 1.3683e-01, time/batch = 0.1458s	
2486/2700 (epoch 46.037), train_loss = 1.32203844, grad/param norm = 1.2665e-01, time/batch = 0.1439s	
2487/2700 (epoch 46.056), train_loss = 1.29200224, grad/param norm = 1.6265e-01, time/batch = 0.1466s	
2488/2700 (epoch 46.074), train_loss = 1.28632474, grad/param norm = 1.3610e-01, time/batch = 0.1448s	
2489/2700 (epoch 46.093), train_loss = 1.26301088, grad/param norm = 9.8502e-02, time/batch = 0.1482s	
2490/2700 (epoch 46.111), train_loss = 1.24338542, grad/param norm = 1.0737e-01, time/batch = 0.1454s	
2491/2700 (epoch 46.130), train_loss = 1.30214976, grad/param norm = 1.3413e-01, time/batch = 0.1505s	
2492/2700 (epoch 46.148), train_loss = 1.27799489, grad/param norm = 1.0819e-01, time/batch = 0.1449s	
2493/2700 (epoch 46.167), train_loss = 1.30680366, grad/param norm = 1.0704e-01, time/batch = 0.1449s	
2494/2700 (epoch 46.185), train_loss = 1.27312545, grad/param norm = 1.1215e-01, time/batch = 0.1474s	
2495/2700 (epoch 46.204), train_loss = 1.28181429, grad/param norm = 1.1952e-01, time/batch = 0.1439s	
2496/2700 (epoch 46.222), train_loss = 1.25698877, grad/param norm = 1.2693e-01, time/batch = 0.1472s	
2497/2700 (epoch 46.241), train_loss = 1.20311452, grad/param norm = 1.3078e-01, time/batch = 0.1444s	
2498/2700 (epoch 46.259), train_loss = 1.25852332, grad/param norm = 1.2811e-01, time/batch = 0.1464s	
2499/2700 (epoch 46.278), train_loss = 1.30495619, grad/param norm = 1.1079e-01, time/batch = 0.1460s	
2500/2700 (epoch 46.296), train_loss = 1.29207605, grad/param norm = 1.1652e-01, time/batch = 0.1444s	
2501/2700 (epoch 46.315), train_loss = 1.24560811, grad/param norm = 1.2947e-01, time/batch = 0.1471s	
2502/2700 (epoch 46.333), train_loss = 1.26475733, grad/param norm = 1.3585e-01, time/batch = 0.1437s	
2503/2700 (epoch 46.352), train_loss = 1.27997366, grad/param norm = 1.7553e-01, time/batch = 0.1472s	
2504/2700 (epoch 46.370), train_loss = 1.30972828, grad/param norm = 2.1521e-01, time/batch = 0.1454s	
2505/2700 (epoch 46.389), train_loss = 1.25892164, grad/param norm = 1.4276e-01, time/batch = 0.1448s	
2506/2700 (epoch 46.407), train_loss = 1.32549897, grad/param norm = 1.1543e-01, time/batch = 0.1453s	
2507/2700 (epoch 46.426), train_loss = 1.35961171, grad/param norm = 1.4074e-01, time/batch = 0.1440s	
2508/2700 (epoch 46.444), train_loss = 1.28097618, grad/param norm = 1.1995e-01, time/batch = 0.1475s	
2509/2700 (epoch 46.463), train_loss = 1.35024431, grad/param norm = 1.1106e-01, time/batch = 0.1452s	
2510/2700 (epoch 46.481), train_loss = 1.31345366, grad/param norm = 1.2700e-01, time/batch = 0.1466s	
2511/2700 (epoch 46.500), train_loss = 1.24313625, grad/param norm = 1.0728e-01, time/batch = 0.1458s	
2512/2700 (epoch 46.519), train_loss = 1.30825597, grad/param norm = 1.0654e-01, time/batch = 0.1449s	
2513/2700 (epoch 46.537), train_loss = 1.31422942, grad/param norm = 1.1127e-01, time/batch = 0.1460s	
2514/2700 (epoch 46.556), train_loss = 1.21300376, grad/param norm = 1.0357e-01, time/batch = 0.1445s	
2515/2700 (epoch 46.574), train_loss = 1.23803514, grad/param norm = 9.3068e-02, time/batch = 0.1469s	
2516/2700 (epoch 46.593), train_loss = 1.28440995, grad/param norm = 1.1594e-01, time/batch = 0.1476s	
2517/2700 (epoch 46.611), train_loss = 1.22232104, grad/param norm = 1.4326e-01, time/batch = 0.1474s	
2518/2700 (epoch 46.630), train_loss = 1.25042818, grad/param norm = 1.5799e-01, time/batch = 0.1458s	
2519/2700 (epoch 46.648), train_loss = 1.26383171, grad/param norm = 1.2938e-01, time/batch = 0.1446s	
2520/2700 (epoch 46.667), train_loss = 1.26247225, grad/param norm = 1.3401e-01, time/batch = 0.1468s	
2521/2700 (epoch 46.685), train_loss = 1.28103813, grad/param norm = 1.4363e-01, time/batch = 0.1479s	
2522/2700 (epoch 46.704), train_loss = 1.30450077, grad/param norm = 1.5309e-01, time/batch = 0.1463s	
2523/2700 (epoch 46.722), train_loss = 1.30759000, grad/param norm = 1.6325e-01, time/batch = 0.1447s	
2524/2700 (epoch 46.741), train_loss = 1.26401953, grad/param norm = 1.4041e-01, time/batch = 0.1478s	
2525/2700 (epoch 46.759), train_loss = 1.25279185, grad/param norm = 1.2256e-01, time/batch = 0.1448s	
2526/2700 (epoch 46.778), train_loss = 1.31372513, grad/param norm = 1.4182e-01, time/batch = 0.1438s	
2527/2700 (epoch 46.796), train_loss = 1.23872227, grad/param norm = 1.6303e-01, time/batch = 0.1462s	
2528/2700 (epoch 46.815), train_loss = 1.30040065, grad/param norm = 1.1967e-01, time/batch = 0.1454s	
2529/2700 (epoch 46.833), train_loss = 1.28622389, grad/param norm = 1.0911e-01, time/batch = 0.1480s	
2530/2700 (epoch 46.852), train_loss = 1.26254769, grad/param norm = 1.0832e-01, time/batch = 0.1454s	
2531/2700 (epoch 46.870), train_loss = 1.28436321, grad/param norm = 1.4673e-01, time/batch = 0.1502s	
2532/2700 (epoch 46.889), train_loss = 1.28250113, grad/param norm = 1.5240e-01, time/batch = 0.1445s	
2533/2700 (epoch 46.907), train_loss = 1.35633251, grad/param norm = 1.1947e-01, time/batch = 0.1449s	
2534/2700 (epoch 46.926), train_loss = 1.30043724, grad/param norm = 9.7628e-02, time/batch = 0.1465s	
2535/2700 (epoch 46.944), train_loss = 1.30359902, grad/param norm = 1.0868e-01, time/batch = 0.1440s	
2536/2700 (epoch 46.963), train_loss = 1.28693541, grad/param norm = 1.6671e-01, time/batch = 0.1466s	
2537/2700 (epoch 46.981), train_loss = 1.27062040, grad/param norm = 2.3003e-01, time/batch = 0.1444s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
2538/2700 (epoch 47.000), train_loss = 1.33789937, grad/param norm = 1.8794e-01, time/batch = 0.1477s	
2539/2700 (epoch 47.019), train_loss = 1.37441898, grad/param norm = 1.4880e-01, time/batch = 0.1456s	
2540/2700 (epoch 47.037), train_loss = 1.30885761, grad/param norm = 1.2517e-01, time/batch = 0.1447s	
2541/2700 (epoch 47.056), train_loss = 1.27131083, grad/param norm = 1.0947e-01, time/batch = 0.1467s	
2542/2700 (epoch 47.074), train_loss = 1.26648361, grad/param norm = 1.1758e-01, time/batch = 0.1436s	
2543/2700 (epoch 47.093), train_loss = 1.25287116, grad/param norm = 1.5922e-01, time/batch = 0.1493s	
2544/2700 (epoch 47.111), train_loss = 1.22792394, grad/param norm = 1.1977e-01, time/batch = 0.1448s	
2545/2700 (epoch 47.130), train_loss = 1.27822092, grad/param norm = 9.5075e-02, time/batch = 0.1469s	
2546/2700 (epoch 47.148), train_loss = 1.26178113, grad/param norm = 1.1192e-01, time/batch = 0.1449s	
2547/2700 (epoch 47.167), train_loss = 1.29081836, grad/param norm = 1.2364e-01, time/batch = 0.1441s	
2548/2700 (epoch 47.185), train_loss = 1.25776116, grad/param norm = 1.2334e-01, time/batch = 0.1468s	
2549/2700 (epoch 47.204), train_loss = 1.26772160, grad/param norm = 1.1828e-01, time/batch = 0.1452s	
2550/2700 (epoch 47.222), train_loss = 1.23859857, grad/param norm = 1.1762e-01, time/batch = 0.1475s	
2551/2700 (epoch 47.241), train_loss = 1.18450646, grad/param norm = 1.2103e-01, time/batch = 0.1459s	
2552/2700 (epoch 47.259), train_loss = 1.24164646, grad/param norm = 1.0566e-01, time/batch = 0.1471s	
2553/2700 (epoch 47.278), train_loss = 1.28994662, grad/param norm = 1.1657e-01, time/batch = 0.1451s	
2554/2700 (epoch 47.296), train_loss = 1.27752282, grad/param norm = 1.2699e-01, time/batch = 0.1463s	
2555/2700 (epoch 47.315), train_loss = 1.23003165, grad/param norm = 1.7618e-01, time/batch = 0.1459s	
2556/2700 (epoch 47.333), train_loss = 1.26330348, grad/param norm = 2.0532e-01, time/batch = 0.1440s	
2557/2700 (epoch 47.352), train_loss = 1.26640139, grad/param norm = 1.6115e-01, time/batch = 0.1471s	
2558/2700 (epoch 47.370), train_loss = 1.27838332, grad/param norm = 1.4936e-01, time/batch = 0.1458s	
2559/2700 (epoch 47.389), train_loss = 1.23710737, grad/param norm = 1.5402e-01, time/batch = 0.1454s	
2560/2700 (epoch 47.407), train_loss = 1.30957907, grad/param norm = 1.4894e-01, time/batch = 0.1460s	
2561/2700 (epoch 47.426), train_loss = 1.33940075, grad/param norm = 1.3421e-01, time/batch = 0.1464s	
2562/2700 (epoch 47.444), train_loss = 1.25903873, grad/param norm = 1.2096e-01, time/batch = 0.1466s	
2563/2700 (epoch 47.463), train_loss = 1.32633349, grad/param norm = 1.0024e-01, time/batch = 0.1446s	
2564/2700 (epoch 47.481), train_loss = 1.29152025, grad/param norm = 1.0573e-01, time/batch = 0.1479s	
2565/2700 (epoch 47.500), train_loss = 1.22260872, grad/param norm = 1.0672e-01, time/batch = 0.1443s	
2566/2700 (epoch 47.519), train_loss = 1.28749713, grad/param norm = 1.0413e-01, time/batch = 0.1473s	
2567/2700 (epoch 47.537), train_loss = 1.29029803, grad/param norm = 1.1568e-01, time/batch = 0.1471s	
2568/2700 (epoch 47.556), train_loss = 1.20227107, grad/param norm = 1.4722e-01, time/batch = 0.1472s	
2569/2700 (epoch 47.574), train_loss = 1.23146900, grad/param norm = 1.3734e-01, time/batch = 0.1471s	
2570/2700 (epoch 47.593), train_loss = 1.27188633, grad/param norm = 1.0293e-01, time/batch = 0.1451s	
2571/2700 (epoch 47.611), train_loss = 1.20141280, grad/param norm = 1.0374e-01, time/batch = 0.1467s	
2572/2700 (epoch 47.630), train_loss = 1.23410879, grad/param norm = 1.1679e-01, time/batch = 0.1438s	
2573/2700 (epoch 47.648), train_loss = 1.25278596, grad/param norm = 1.3537e-01, time/batch = 0.1475s	
2574/2700 (epoch 47.667), train_loss = 1.24973099, grad/param norm = 1.4594e-01, time/batch = 0.1456s	
2575/2700 (epoch 47.685), train_loss = 1.26957464, grad/param norm = 1.7230e-01, time/batch = 0.1439s	
2576/2700 (epoch 47.704), train_loss = 1.29185845, grad/param norm = 1.7022e-01, time/batch = 0.1459s	
2577/2700 (epoch 47.722), train_loss = 1.28166824, grad/param norm = 1.1599e-01, time/batch = 0.1445s	
2578/2700 (epoch 47.741), train_loss = 1.24239085, grad/param norm = 1.3420e-01, time/batch = 0.1475s	
2579/2700 (epoch 47.759), train_loss = 1.23706713, grad/param norm = 1.5697e-01, time/batch = 0.1458s	
2580/2700 (epoch 47.778), train_loss = 1.28806975, grad/param norm = 1.2627e-01, time/batch = 0.1472s	
2581/2700 (epoch 47.796), train_loss = 1.21170642, grad/param norm = 1.2235e-01, time/batch = 0.1458s	
2582/2700 (epoch 47.815), train_loss = 1.28115557, grad/param norm = 1.6165e-01, time/batch = 0.1460s	
2583/2700 (epoch 47.833), train_loss = 1.27157293, grad/param norm = 1.5459e-01, time/batch = 0.1455s	
2584/2700 (epoch 47.852), train_loss = 1.24810742, grad/param norm = 1.5806e-01, time/batch = 0.1481s	
2585/2700 (epoch 47.870), train_loss = 1.26891635, grad/param norm = 1.7432e-01, time/batch = 0.1478s	
2586/2700 (epoch 47.889), train_loss = 1.25529384, grad/param norm = 1.3084e-01, time/batch = 0.1443s	
2587/2700 (epoch 47.907), train_loss = 1.33225251, grad/param norm = 1.1223e-01, time/batch = 0.1477s	
2588/2700 (epoch 47.926), train_loss = 1.28574198, grad/param norm = 1.1948e-01, time/batch = 0.1455s	
2589/2700 (epoch 47.944), train_loss = 1.28649357, grad/param norm = 1.1915e-01, time/batch = 0.1480s	
2590/2700 (epoch 47.963), train_loss = 1.26370313, grad/param norm = 1.0378e-01, time/batch = 0.1463s	
2591/2700 (epoch 47.981), train_loss = 1.22900573, grad/param norm = 1.1119e-01, time/batch = 0.1478s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
2592/2700 (epoch 48.000), train_loss = 1.30296827, grad/param norm = 1.2147e-01, time/batch = 0.1464s	
2593/2700 (epoch 48.019), train_loss = 1.34940143, grad/param norm = 1.2787e-01, time/batch = 0.1448s	
2594/2700 (epoch 48.037), train_loss = 1.29211571, grad/param norm = 1.2843e-01, time/batch = 0.1485s	
2595/2700 (epoch 48.056), train_loss = 1.26606350, grad/param norm = 1.7308e-01, time/batch = 0.1452s	
2596/2700 (epoch 48.074), train_loss = 1.24749789, grad/param norm = 1.3425e-01, time/batch = 0.1465s	
2597/2700 (epoch 48.093), train_loss = 1.22762030, grad/param norm = 1.0048e-01, time/batch = 0.1457s	
2598/2700 (epoch 48.111), train_loss = 1.21644944, grad/param norm = 1.3286e-01, time/batch = 0.1447s	
2599/2700 (epoch 48.130), train_loss = 1.27396119, grad/param norm = 1.6418e-01, time/batch = 0.1474s	
2600/2700 (epoch 48.148), train_loss = 1.24891124, grad/param norm = 1.2835e-01, time/batch = 0.1459s	
2601/2700 (epoch 48.167), train_loss = 1.27593344, grad/param norm = 1.2752e-01, time/batch = 0.1499s	
2602/2700 (epoch 48.185), train_loss = 1.24443973, grad/param norm = 1.3481e-01, time/batch = 0.1449s	
2603/2700 (epoch 48.204), train_loss = 1.24926687, grad/param norm = 1.3204e-01, time/batch = 0.1460s	
2604/2700 (epoch 48.222), train_loss = 1.22571161, grad/param norm = 1.4550e-01, time/batch = 0.1458s	
2605/2700 (epoch 48.241), train_loss = 1.17537312, grad/param norm = 1.3818e-01, time/batch = 0.1438s	
2606/2700 (epoch 48.259), train_loss = 1.22652233, grad/param norm = 1.3491e-01, time/batch = 0.1475s	
2607/2700 (epoch 48.278), train_loss = 1.27299807, grad/param norm = 1.2548e-01, time/batch = 0.1449s	
2608/2700 (epoch 48.296), train_loss = 1.26332994, grad/param norm = 1.3041e-01, time/batch = 0.1496s	
2609/2700 (epoch 48.315), train_loss = 1.21247625, grad/param norm = 1.3945e-01, time/batch = 0.1459s	
2610/2700 (epoch 48.333), train_loss = 1.23603417, grad/param norm = 1.5283e-01, time/batch = 0.1445s	
2611/2700 (epoch 48.352), train_loss = 1.25508765, grad/param norm = 1.9487e-01, time/batch = 0.1461s	
2612/2700 (epoch 48.370), train_loss = 1.26825345, grad/param norm = 1.9262e-01, time/batch = 0.1437s	
2613/2700 (epoch 48.389), train_loss = 1.21734482, grad/param norm = 1.1431e-01, time/batch = 0.1467s	
2614/2700 (epoch 48.407), train_loss = 1.28795600, grad/param norm = 1.1499e-01, time/batch = 0.1450s	
2615/2700 (epoch 48.426), train_loss = 1.32243365, grad/param norm = 1.3841e-01, time/batch = 0.1477s	
2616/2700 (epoch 48.444), train_loss = 1.24488530, grad/param norm = 1.0049e-01, time/batch = 0.1443s	
2617/2700 (epoch 48.463), train_loss = 1.31120851, grad/param norm = 1.0216e-01, time/batch = 0.1446s	
2618/2700 (epoch 48.481), train_loss = 1.27490851, grad/param norm = 1.2924e-01, time/batch = 0.1464s	
2619/2700 (epoch 48.500), train_loss = 1.20694853, grad/param norm = 1.0876e-01, time/batch = 0.1460s	
2620/2700 (epoch 48.519), train_loss = 1.27277969, grad/param norm = 1.0706e-01, time/batch = 0.1486s	
2621/2700 (epoch 48.537), train_loss = 1.27722834, grad/param norm = 1.3114e-01, time/batch = 0.1471s	
2622/2700 (epoch 48.556), train_loss = 1.18737232, grad/param norm = 1.2784e-01, time/batch = 0.1475s	
2623/2700 (epoch 48.574), train_loss = 1.21348388, grad/param norm = 1.3658e-01, time/batch = 0.1476s	
2624/2700 (epoch 48.593), train_loss = 1.26260574, grad/param norm = 1.8557e-01, time/batch = 0.1465s	
2625/2700 (epoch 48.611), train_loss = 1.20731551, grad/param norm = 1.8631e-01, time/batch = 0.1451s	
2626/2700 (epoch 48.630), train_loss = 1.22349973, grad/param norm = 1.4336e-01, time/batch = 0.1437s	
2627/2700 (epoch 48.648), train_loss = 1.22873407, grad/param norm = 1.0128e-01, time/batch = 0.1467s	
2628/2700 (epoch 48.667), train_loss = 1.22928859, grad/param norm = 1.0896e-01, time/batch = 0.1454s	
2629/2700 (epoch 48.685), train_loss = 1.24496998, grad/param norm = 1.1413e-01, time/batch = 0.1478s	
2630/2700 (epoch 48.704), train_loss = 1.26531048, grad/param norm = 1.2408e-01, time/batch = 0.1454s	
2631/2700 (epoch 48.722), train_loss = 1.27152424, grad/param norm = 1.3780e-01, time/batch = 0.1494s	
2632/2700 (epoch 48.741), train_loss = 1.22758453, grad/param norm = 1.2131e-01, time/batch = 0.1451s	
2633/2700 (epoch 48.759), train_loss = 1.21323777, grad/param norm = 1.0727e-01, time/batch = 0.1442s	
2634/2700 (epoch 48.778), train_loss = 1.27294041, grad/param norm = 1.3768e-01, time/batch = 0.1480s	
2635/2700 (epoch 48.796), train_loss = 1.20087949, grad/param norm = 1.6232e-01, time/batch = 0.1441s	
2636/2700 (epoch 48.815), train_loss = 1.26106265, grad/param norm = 1.2256e-01, time/batch = 0.1477s	
2637/2700 (epoch 48.833), train_loss = 1.25143340, grad/param norm = 1.2708e-01, time/batch = 0.1457s	
2638/2700 (epoch 48.852), train_loss = 1.23154092, grad/param norm = 1.2518e-01, time/batch = 0.1473s	
2639/2700 (epoch 48.870), train_loss = 1.24048740, grad/param norm = 1.0291e-01, time/batch = 0.1464s	
2640/2700 (epoch 48.889), train_loss = 1.24318859, grad/param norm = 1.4357e-01, time/batch = 0.1445s	
2641/2700 (epoch 48.907), train_loss = 1.33497217, grad/param norm = 2.1332e-01, time/batch = 0.1466s	
2642/2700 (epoch 48.926), train_loss = 1.30031609, grad/param norm = 2.4769e-01, time/batch = 0.1436s	
2643/2700 (epoch 48.944), train_loss = 1.27940683, grad/param norm = 1.8281e-01, time/batch = 0.1476s	
2644/2700 (epoch 48.963), train_loss = 1.24239926, grad/param norm = 1.2804e-01, time/batch = 0.1450s	
2645/2700 (epoch 48.981), train_loss = 1.21059540, grad/param norm = 1.2881e-01, time/batch = 0.1458s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
2646/2700 (epoch 49.000), train_loss = 1.28967201, grad/param norm = 1.5369e-01, time/batch = 0.1449s	
2647/2700 (epoch 49.019), train_loss = 1.33617301, grad/param norm = 1.4355e-01, time/batch = 0.1439s	
2648/2700 (epoch 49.037), train_loss = 1.27024831, grad/param norm = 1.1169e-01, time/batch = 0.1474s	
2649/2700 (epoch 49.056), train_loss = 1.23665749, grad/param norm = 1.2585e-01, time/batch = 0.1455s	
2650/2700 (epoch 49.074), train_loss = 1.22511029, grad/param norm = 9.6826e-02, time/batch = 0.1484s	
2651/2700 (epoch 49.093), train_loss = 1.21508148, grad/param norm = 1.1299e-01, time/batch = 0.1497s	
2652/2700 (epoch 49.111), train_loss = 1.19504363, grad/param norm = 1.0021e-01, time/batch = 0.1491s	
2653/2700 (epoch 49.130), train_loss = 1.24571367, grad/param norm = 9.9940e-02, time/batch = 0.1453s	
2654/2700 (epoch 49.148), train_loss = 1.22902053, grad/param norm = 9.5180e-02, time/batch = 0.1453s	
2655/2700 (epoch 49.167), train_loss = 1.25473080, grad/param norm = 1.1130e-01, time/batch = 0.1464s	
2656/2700 (epoch 49.185), train_loss = 1.22902013, grad/param norm = 1.4015e-01, time/batch = 0.1440s	
2657/2700 (epoch 49.204), train_loss = 1.24132343, grad/param norm = 1.3894e-01, time/batch = 0.1475s	
2658/2700 (epoch 49.222), train_loss = 1.20651332, grad/param norm = 1.3198e-01, time/batch = 0.1458s	
2659/2700 (epoch 49.241), train_loss = 1.15855164, grad/param norm = 1.4372e-01, time/batch = 0.1470s	
2660/2700 (epoch 49.259), train_loss = 1.21391062, grad/param norm = 1.2896e-01, time/batch = 0.1463s	
2661/2700 (epoch 49.278), train_loss = 1.26268322, grad/param norm = 1.4192e-01, time/batch = 0.1474s	
2662/2700 (epoch 49.296), train_loss = 1.24843609, grad/param norm = 1.4068e-01, time/batch = 0.1462s	
2663/2700 (epoch 49.315), train_loss = 1.19684928, grad/param norm = 1.8303e-01, time/batch = 0.1444s	
2664/2700 (epoch 49.333), train_loss = 1.23464151, grad/param norm = 1.8747e-01, time/batch = 0.1483s	
2665/2700 (epoch 49.352), train_loss = 1.22528128, grad/param norm = 1.3236e-01, time/batch = 0.1444s	
2666/2700 (epoch 49.370), train_loss = 1.23426041, grad/param norm = 1.1482e-01, time/batch = 0.1464s	
2667/2700 (epoch 49.389), train_loss = 1.20014019, grad/param norm = 1.3921e-01, time/batch = 0.1461s	
2668/2700 (epoch 49.407), train_loss = 1.27823009, grad/param norm = 1.4562e-01, time/batch = 0.1450s	
2669/2700 (epoch 49.426), train_loss = 1.30368191, grad/param norm = 1.2614e-01, time/batch = 0.1484s	
2670/2700 (epoch 49.444), train_loss = 1.22826055, grad/param norm = 1.0684e-01, time/batch = 0.1472s	
2671/2700 (epoch 49.463), train_loss = 1.28915334, grad/param norm = 9.0401e-02, time/batch = 0.1509s	
2672/2700 (epoch 49.481), train_loss = 1.25362433, grad/param norm = 9.5136e-02, time/batch = 0.1454s	
2673/2700 (epoch 49.500), train_loss = 1.18745157, grad/param norm = 9.6275e-02, time/batch = 0.1475s	
2674/2700 (epoch 49.519), train_loss = 1.25490373, grad/param norm = 1.0241e-01, time/batch = 0.1495s	
2675/2700 (epoch 49.537), train_loss = 1.25879025, grad/param norm = 1.1881e-01, time/batch = 0.1452s	
2676/2700 (epoch 49.556), train_loss = 1.17294776, grad/param norm = 1.5472e-01, time/batch = 0.1465s	
2677/2700 (epoch 49.574), train_loss = 1.19444272, grad/param norm = 1.2704e-01, time/batch = 0.1446s	
2678/2700 (epoch 49.593), train_loss = 1.23373908, grad/param norm = 1.0690e-01, time/batch = 0.1486s	
2679/2700 (epoch 49.611), train_loss = 1.17116230, grad/param norm = 1.1031e-01, time/batch = 0.1462s	
2680/2700 (epoch 49.630), train_loss = 1.20062115, grad/param norm = 1.3653e-01, time/batch = 0.1471s	
2681/2700 (epoch 49.648), train_loss = 1.22677434, grad/param norm = 1.8867e-01, time/batch = 0.1499s	
2682/2700 (epoch 49.667), train_loss = 1.22559532, grad/param norm = 1.8280e-01, time/batch = 0.1439s	
2683/2700 (epoch 49.685), train_loss = 1.23755003, grad/param norm = 1.7561e-01, time/batch = 0.1464s	
2684/2700 (epoch 49.704), train_loss = 1.25562891, grad/param norm = 1.5625e-01, time/batch = 0.1459s	
2685/2700 (epoch 49.722), train_loss = 1.25064887, grad/param norm = 1.1033e-01, time/batch = 0.1484s	
2686/2700 (epoch 49.741), train_loss = 1.21232330, grad/param norm = 1.2964e-01, time/batch = 0.1473s	
2687/2700 (epoch 49.759), train_loss = 1.19929778, grad/param norm = 1.3399e-01, time/batch = 0.1455s	
2688/2700 (epoch 49.778), train_loss = 1.25349338, grad/param norm = 1.0337e-01, time/batch = 0.1462s	
2689/2700 (epoch 49.796), train_loss = 1.18080067, grad/param norm = 1.1397e-01, time/batch = 0.1446s	
2690/2700 (epoch 49.815), train_loss = 1.25003999, grad/param norm = 1.4660e-01, time/batch = 0.1496s	
2691/2700 (epoch 49.833), train_loss = 1.23846481, grad/param norm = 1.3025e-01, time/batch = 0.1458s	
2692/2700 (epoch 49.852), train_loss = 1.21184452, grad/param norm = 1.1087e-01, time/batch = 0.1473s	
2693/2700 (epoch 49.870), train_loss = 1.22800532, grad/param norm = 1.2919e-01, time/batch = 0.1449s	
2694/2700 (epoch 49.889), train_loss = 1.22564049, grad/param norm = 1.3173e-01, time/batch = 0.1458s	
2695/2700 (epoch 49.907), train_loss = 1.30224310, grad/param norm = 1.1503e-01, time/batch = 0.1451s	
2696/2700 (epoch 49.926), train_loss = 1.24908879, grad/param norm = 1.0265e-01, time/batch = 0.1438s	
2697/2700 (epoch 49.944), train_loss = 1.25218121, grad/param norm = 1.2758e-01, time/batch = 0.1469s	
2698/2700 (epoch 49.963), train_loss = 1.23398207, grad/param norm = 1.8554e-01, time/batch = 0.1470s	
2699/2700 (epoch 49.981), train_loss = 1.21381923, grad/param norm = 2.3696e-01, time/batch = 0.1479s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch50.00_1.7301.t7	
2700/2700 (epoch 50.000), train_loss = 1.28510502, grad/param norm = 1.9739e-01, time/batch = 0.1456s	
