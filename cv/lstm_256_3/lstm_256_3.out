using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 54, val: 3, test: 0	
vocab size: 91	
creating an lstm with 3 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
setting forget gate biases to 1 in LSTM layer 3	
number of parameters in the model: 1433435	
cloning rnn	
cloning criterion	
1/2700 (epoch 0.019), train_loss = 4.52432585, grad/param norm = 5.8972e-01, time/batch = 0.9080s	
2/2700 (epoch 0.037), train_loss = 3.44859976, grad/param norm = 7.7503e-01, time/batch = 0.4049s	
3/2700 (epoch 0.056), train_loss = 3.93772739, grad/param norm = 1.6475e+00, time/batch = 0.4496s	
4/2700 (epoch 0.074), train_loss = 3.42197731, grad/param norm = 8.7719e-01, time/batch = 0.4681s	
5/2700 (epoch 0.093), train_loss = 3.31802895, grad/param norm = 3.4347e-01, time/batch = 0.5085s	
6/2700 (epoch 0.111), train_loss = 3.28297890, grad/param norm = 3.3852e-01, time/batch = 0.5097s	
7/2700 (epoch 0.130), train_loss = 3.30424506, grad/param norm = 3.2696e-01, time/batch = 0.5102s	
8/2700 (epoch 0.148), train_loss = 3.26579628, grad/param norm = 4.1735e-01, time/batch = 0.4986s	
9/2700 (epoch 0.167), train_loss = 3.27541937, grad/param norm = 4.7390e-01, time/batch = 0.5131s	
10/2700 (epoch 0.185), train_loss = 3.25271266, grad/param norm = 3.6536e-01, time/batch = 0.4670s	
11/2700 (epoch 0.204), train_loss = 3.18694789, grad/param norm = 3.4376e-01, time/batch = 0.4888s	
12/2700 (epoch 0.222), train_loss = 3.15848598, grad/param norm = 4.1161e-01, time/batch = 0.4726s	
13/2700 (epoch 0.241), train_loss = 3.17793118, grad/param norm = 3.8237e-01, time/batch = 0.4864s	
14/2700 (epoch 0.259), train_loss = 3.21669435, grad/param norm = 4.2100e-01, time/batch = 0.4601s	
15/2700 (epoch 0.278), train_loss = 3.28564273, grad/param norm = 4.3467e-01, time/batch = 0.5093s	
16/2700 (epoch 0.296), train_loss = 3.28443163, grad/param norm = 3.4172e-01, time/batch = 0.5057s	
17/2700 (epoch 0.315), train_loss = 3.25742138, grad/param norm = 2.4166e-01, time/batch = 0.4973s	
18/2700 (epoch 0.333), train_loss = 3.33681433, grad/param norm = 2.2201e-01, time/batch = 0.5076s	
19/2700 (epoch 0.352), train_loss = 3.34237036, grad/param norm = 2.5211e-01, time/batch = 0.4880s	
20/2700 (epoch 0.370), train_loss = 3.29031530, grad/param norm = 2.8824e-01, time/batch = 0.4750s	
21/2700 (epoch 0.389), train_loss = 3.25509353, grad/param norm = 2.3256e-01, time/batch = 0.4742s	
22/2700 (epoch 0.407), train_loss = 3.27629558, grad/param norm = 2.1091e-01, time/batch = 0.4913s	
23/2700 (epoch 0.426), train_loss = 3.27998894, grad/param norm = 2.1727e-01, time/batch = 0.4731s	
24/2700 (epoch 0.444), train_loss = 3.20966094, grad/param norm = 2.2713e-01, time/batch = 0.5033s	
25/2700 (epoch 0.463), train_loss = 3.24994753, grad/param norm = 2.6593e-01, time/batch = 0.5105s	
26/2700 (epoch 0.481), train_loss = 3.33084980, grad/param norm = 3.1062e-01, time/batch = 0.5024s	
27/2700 (epoch 0.500), train_loss = 3.37467356, grad/param norm = 3.6826e-01, time/batch = 0.4957s	
28/2700 (epoch 0.519), train_loss = 3.33155092, grad/param norm = 3.5995e-01, time/batch = 0.4963s	
29/2700 (epoch 0.537), train_loss = 3.33072911, grad/param norm = 3.4008e-01, time/batch = 0.4921s	
30/2700 (epoch 0.556), train_loss = 3.26677983, grad/param norm = 2.6657e-01, time/batch = 0.4768s	
31/2700 (epoch 0.574), train_loss = 3.23096296, grad/param norm = 2.1671e-01, time/batch = 0.4748s	
32/2700 (epoch 0.593), train_loss = 3.23174188, grad/param norm = 2.7255e-01, time/batch = 0.5056s	
33/2700 (epoch 0.611), train_loss = 3.17176392, grad/param norm = 1.8882e-01, time/batch = 0.4732s	
34/2700 (epoch 0.630), train_loss = 3.21322206, grad/param norm = 2.1129e-01, time/batch = 0.4952s	
35/2700 (epoch 0.648), train_loss = 3.28688623, grad/param norm = 2.4827e-01, time/batch = 0.5212s	
36/2700 (epoch 0.667), train_loss = 3.21564620, grad/param norm = 1.9167e-01, time/batch = 0.4623s	
37/2700 (epoch 0.685), train_loss = 3.21318040, grad/param norm = 2.2525e-01, time/batch = 0.5143s	
38/2700 (epoch 0.704), train_loss = 3.18847926, grad/param norm = 3.1825e-01, time/batch = 0.4959s	
39/2700 (epoch 0.722), train_loss = 3.17782910, grad/param norm = 2.8421e-01, time/batch = 0.4778s	
40/2700 (epoch 0.741), train_loss = 3.31327810, grad/param norm = 3.7135e-01, time/batch = 0.4795s	
41/2700 (epoch 0.759), train_loss = 3.26181721, grad/param norm = 3.6920e-01, time/batch = 0.4840s	
42/2700 (epoch 0.778), train_loss = 3.25065826, grad/param norm = 2.7271e-01, time/batch = 0.4790s	
43/2700 (epoch 0.796), train_loss = 3.24125950, grad/param norm = 2.3608e-01, time/batch = 0.4880s	
44/2700 (epoch 0.815), train_loss = 3.19484760, grad/param norm = 1.9961e-01, time/batch = 0.5013s	
45/2700 (epoch 0.833), train_loss = 3.23341473, grad/param norm = 2.1770e-01, time/batch = 0.4831s	
46/2700 (epoch 0.852), train_loss = 3.22068697, grad/param norm = 2.3138e-01, time/batch = 0.5166s	
47/2700 (epoch 0.870), train_loss = 3.21440526, grad/param norm = 1.9019e-01, time/batch = 0.4961s	
48/2700 (epoch 0.889), train_loss = 3.25329306, grad/param norm = 2.4029e-01, time/batch = 0.5092s	
49/2700 (epoch 0.907), train_loss = 3.30761839, grad/param norm = 3.3204e-01, time/batch = 0.4904s	
50/2700 (epoch 0.926), train_loss = 3.25773022, grad/param norm = 3.3189e-01, time/batch = 0.4773s	
51/2700 (epoch 0.944), train_loss = 3.26252055, grad/param norm = 2.6659e-01, time/batch = 0.4764s	
52/2700 (epoch 0.963), train_loss = 3.34124099, grad/param norm = 2.5264e-01, time/batch = 0.4706s	
53/2700 (epoch 0.981), train_loss = 3.40009324, grad/param norm = 2.4453e-01, time/batch = 0.4740s	
54/2700 (epoch 1.000), train_loss = 3.30269917, grad/param norm = 2.5789e-01, time/batch = 0.4531s	
55/2700 (epoch 1.019), train_loss = 3.23946471, grad/param norm = 2.7844e-01, time/batch = 0.5069s	
56/2700 (epoch 1.037), train_loss = 3.25665661, grad/param norm = 2.4682e-01, time/batch = 0.5215s	
57/2700 (epoch 1.056), train_loss = 3.26030346, grad/param norm = 1.9675e-01, time/batch = 0.5194s	
58/2700 (epoch 1.074), train_loss = 3.29129624, grad/param norm = 2.5330e-01, time/batch = 0.4991s	
59/2700 (epoch 1.093), train_loss = 3.29755275, grad/param norm = 2.9983e-01, time/batch = 0.4757s	
60/2700 (epoch 1.111), train_loss = 3.26846989, grad/param norm = 2.6287e-01, time/batch = 0.4720s	
61/2700 (epoch 1.130), train_loss = 3.28233472, grad/param norm = 2.1418e-01, time/batch = 0.4868s	
62/2700 (epoch 1.148), train_loss = 3.24473978, grad/param norm = 2.1171e-01, time/batch = 0.4881s	
63/2700 (epoch 1.167), train_loss = 3.25476137, grad/param norm = 2.7282e-01, time/batch = 0.4574s	
64/2700 (epoch 1.185), train_loss = 3.24017256, grad/param norm = 1.9859e-01, time/batch = 0.4940s	
65/2700 (epoch 1.204), train_loss = 3.17546102, grad/param norm = 2.2067e-01, time/batch = 0.5079s	
66/2700 (epoch 1.222), train_loss = 3.15198112, grad/param norm = 3.1352e-01, time/batch = 0.5225s	
67/2700 (epoch 1.241), train_loss = 3.17049645, grad/param norm = 2.4701e-01, time/batch = 0.5169s	
68/2700 (epoch 1.259), train_loss = 3.20424636, grad/param norm = 2.3883e-01, time/batch = 0.5124s	
69/2700 (epoch 1.278), train_loss = 3.27820697, grad/param norm = 2.8061e-01, time/batch = 0.5088s	
70/2700 (epoch 1.296), train_loss = 3.28311914, grad/param norm = 3.2770e-01, time/batch = 0.4147s	
71/2700 (epoch 1.315), train_loss = 3.26066255, grad/param norm = 3.3719e-01, time/batch = 0.4776s	
72/2700 (epoch 1.333), train_loss = 3.34114136, grad/param norm = 3.4737e-01, time/batch = 0.4786s	
73/2700 (epoch 1.352), train_loss = 3.34671791, grad/param norm = 3.4323e-01, time/batch = 0.5129s	
74/2700 (epoch 1.370), train_loss = 3.28570241, grad/param norm = 2.6404e-01, time/batch = 0.4845s	
75/2700 (epoch 1.389), train_loss = 3.25248802, grad/param norm = 1.8633e-01, time/batch = 0.5236s	
76/2700 (epoch 1.407), train_loss = 3.27524315, grad/param norm = 1.9089e-01, time/batch = 0.5145s	
77/2700 (epoch 1.426), train_loss = 3.27886578, grad/param norm = 2.1765e-01, time/batch = 0.5032s	
78/2700 (epoch 1.444), train_loss = 3.20614958, grad/param norm = 1.6970e-01, time/batch = 0.4827s	
79/2700 (epoch 1.463), train_loss = 3.24654459, grad/param norm = 1.8853e-01, time/batch = 0.4831s	
80/2700 (epoch 1.481), train_loss = 3.32343050, grad/param norm = 2.0512e-01, time/batch = 0.4830s	
81/2700 (epoch 1.500), train_loss = 3.37221208, grad/param norm = 2.9567e-01, time/batch = 0.4158s	
82/2700 (epoch 1.519), train_loss = 3.32781483, grad/param norm = 2.9433e-01, time/batch = 0.4920s	
83/2700 (epoch 1.537), train_loss = 3.32463886, grad/param norm = 2.4997e-01, time/batch = 0.4867s	
84/2700 (epoch 1.556), train_loss = 3.25835901, grad/param norm = 2.0748e-01, time/batch = 0.5138s	
85/2700 (epoch 1.574), train_loss = 3.23230251, grad/param norm = 2.9980e-01, time/batch = 0.5201s	
86/2700 (epoch 1.593), train_loss = 3.23749145, grad/param norm = 4.1071e-01, time/batch = 0.5118s	
87/2700 (epoch 1.611), train_loss = 3.18029407, grad/param norm = 3.6230e-01, time/batch = 0.5039s	
88/2700 (epoch 1.630), train_loss = 3.21437894, grad/param norm = 3.2263e-01, time/batch = 0.4817s	
89/2700 (epoch 1.648), train_loss = 3.28113474, grad/param norm = 2.9988e-01, time/batch = 0.4789s	
90/2700 (epoch 1.667), train_loss = 3.20800995, grad/param norm = 1.9616e-01, time/batch = 0.4707s	
91/2700 (epoch 1.685), train_loss = 3.20364342, grad/param norm = 2.2743e-01, time/batch = 0.4796s	
92/2700 (epoch 1.704), train_loss = 3.17393496, grad/param norm = 2.7127e-01, time/batch = 0.4193s	
93/2700 (epoch 1.722), train_loss = 3.16250933, grad/param norm = 2.2884e-01, time/batch = 0.5086s	
94/2700 (epoch 1.741), train_loss = 3.30871304, grad/param norm = 3.8724e-01, time/batch = 0.5216s	
95/2700 (epoch 1.759), train_loss = 3.28292768, grad/param norm = 4.9870e-01, time/batch = 0.5228s	
96/2700 (epoch 1.778), train_loss = 3.26704541, grad/param norm = 4.8686e-01, time/batch = 0.5159s	
97/2700 (epoch 1.796), train_loss = 3.23409209, grad/param norm = 2.9115e-01, time/batch = 0.5010s	
98/2700 (epoch 1.815), train_loss = 3.17142831, grad/param norm = 1.5808e-01, time/batch = 0.4764s	
99/2700 (epoch 1.833), train_loss = 3.20240367, grad/param norm = 1.7416e-01, time/batch = 0.4695s	
100/2700 (epoch 1.852), train_loss = 3.18433531, grad/param norm = 1.7346e-01, time/batch = 0.4807s	
101/2700 (epoch 1.870), train_loss = 3.16804301, grad/param norm = 1.2685e-01, time/batch = 0.4656s	
102/2700 (epoch 1.889), train_loss = 3.19512116, grad/param norm = 1.7736e-01, time/batch = 0.4772s	
103/2700 (epoch 1.907), train_loss = 3.26271876, grad/param norm = 3.5945e-01, time/batch = 0.4738s	
104/2700 (epoch 1.926), train_loss = 3.28122004, grad/param norm = 7.0503e-01, time/batch = 0.5290s	
105/2700 (epoch 1.944), train_loss = 3.25599442, grad/param norm = 4.7553e-01, time/batch = 0.5099s	
106/2700 (epoch 1.963), train_loss = 3.28763918, grad/param norm = 2.3010e-01, time/batch = 0.4903s	
107/2700 (epoch 1.981), train_loss = 3.32229810, grad/param norm = 2.4258e-01, time/batch = 0.4749s	
108/2700 (epoch 2.000), train_loss = 3.21380588, grad/param norm = 1.9224e-01, time/batch = 0.4682s	
109/2700 (epoch 2.019), train_loss = 3.13462479, grad/param norm = 2.1451e-01, time/batch = 0.4851s	
110/2700 (epoch 2.037), train_loss = 3.14161940, grad/param norm = 2.3809e-01, time/batch = 0.4943s	
111/2700 (epoch 2.056), train_loss = 3.16683832, grad/param norm = 4.3837e-01, time/batch = 0.5303s	
112/2700 (epoch 2.074), train_loss = 3.33207998, grad/param norm = 6.3203e-01, time/batch = 0.5117s	
113/2700 (epoch 2.093), train_loss = 3.28117049, grad/param norm = 6.2666e-01, time/batch = 0.5088s	
114/2700 (epoch 2.111), train_loss = 3.18812133, grad/param norm = 3.7004e-01, time/batch = 0.4998s	
115/2700 (epoch 2.130), train_loss = 3.16733693, grad/param norm = 1.9285e-01, time/batch = 0.4885s	
116/2700 (epoch 2.148), train_loss = 3.10047238, grad/param norm = 1.7493e-01, time/batch = 0.4979s	
117/2700 (epoch 2.167), train_loss = 3.09719381, grad/param norm = 1.9473e-01, time/batch = 0.4789s	
118/2700 (epoch 2.185), train_loss = 3.07426687, grad/param norm = 1.6279e-01, time/batch = 0.4803s	
119/2700 (epoch 2.204), train_loss = 3.02617099, grad/param norm = 2.8762e-01, time/batch = 0.4702s	
120/2700 (epoch 2.222), train_loss = 3.00352635, grad/param norm = 4.9888e-01, time/batch = 0.4871s	
121/2700 (epoch 2.241), train_loss = 3.03707205, grad/param norm = 5.3467e-01, time/batch = 0.4770s	
122/2700 (epoch 2.259), train_loss = 3.04459491, grad/param norm = 4.9746e-01, time/batch = 0.5125s	
123/2700 (epoch 2.278), train_loss = 3.14443103, grad/param norm = 4.7622e-01, time/batch = 0.5188s	
124/2700 (epoch 2.296), train_loss = 3.13300327, grad/param norm = 4.2324e-01, time/batch = 0.5167s	
125/2700 (epoch 2.315), train_loss = 3.08835515, grad/param norm = 2.8295e-01, time/batch = 0.4882s	
126/2700 (epoch 2.333), train_loss = 3.12174695, grad/param norm = 2.1872e-01, time/batch = 0.5074s	
127/2700 (epoch 2.352), train_loss = 3.12476431, grad/param norm = 2.0616e-01, time/batch = 0.4818s	
128/2700 (epoch 2.370), train_loss = 3.03453884, grad/param norm = 2.1851e-01, time/batch = 0.4703s	
129/2700 (epoch 2.389), train_loss = 3.01309493, grad/param norm = 2.8682e-01, time/batch = 0.4763s	
130/2700 (epoch 2.407), train_loss = 3.10363402, grad/param norm = 6.6389e-01, time/batch = 0.4901s	
131/2700 (epoch 2.426), train_loss = 3.18319699, grad/param norm = 6.0545e-01, time/batch = 0.4861s	
132/2700 (epoch 2.444), train_loss = 3.00760252, grad/param norm = 3.8247e-01, time/batch = 0.4976s	
133/2700 (epoch 2.463), train_loss = 3.06638464, grad/param norm = 4.9846e-01, time/batch = 0.5261s	
134/2700 (epoch 2.481), train_loss = 3.10489370, grad/param norm = 3.5794e-01, time/batch = 0.5155s	
135/2700 (epoch 2.500), train_loss = 3.10869362, grad/param norm = 2.5590e-01, time/batch = 0.4959s	
136/2700 (epoch 2.519), train_loss = 3.03472192, grad/param norm = 2.4705e-01, time/batch = 0.4546s	
137/2700 (epoch 2.537), train_loss = 3.05806508, grad/param norm = 2.9435e-01, time/batch = 0.4694s	
138/2700 (epoch 2.556), train_loss = 3.00838962, grad/param norm = 3.7563e-01, time/batch = 0.4813s	
139/2700 (epoch 2.574), train_loss = 2.99662534, grad/param norm = 5.1606e-01, time/batch = 0.4814s	
140/2700 (epoch 2.593), train_loss = 3.02153650, grad/param norm = 5.5698e-01, time/batch = 0.4944s	
141/2700 (epoch 2.611), train_loss = 2.92525525, grad/param norm = 6.5152e-01, time/batch = 0.5035s	
142/2700 (epoch 2.630), train_loss = 2.98672793, grad/param norm = 5.7126e-01, time/batch = 0.4972s	
143/2700 (epoch 2.648), train_loss = 2.95848405, grad/param norm = 2.8069e-01, time/batch = 0.5209s	
144/2700 (epoch 2.667), train_loss = 2.88067420, grad/param norm = 2.5950e-01, time/batch = 0.5191s	
145/2700 (epoch 2.685), train_loss = 2.88515692, grad/param norm = 2.7366e-01, time/batch = 0.4404s	
146/2700 (epoch 2.704), train_loss = 2.84268347, grad/param norm = 2.7805e-01, time/batch = 0.5020s	
147/2700 (epoch 2.722), train_loss = 2.79858290, grad/param norm = 2.4547e-01, time/batch = 0.4983s	
148/2700 (epoch 2.741), train_loss = 2.98375126, grad/param norm = 2.5511e-01, time/batch = 0.4095s	
149/2700 (epoch 2.759), train_loss = 2.92088726, grad/param norm = 3.6566e-01, time/batch = 0.5097s	
150/2700 (epoch 2.778), train_loss = 2.93100355, grad/param norm = 4.9077e-01, time/batch = 0.5067s	
151/2700 (epoch 2.796), train_loss = 2.90219450, grad/param norm = 4.6958e-01, time/batch = 0.5161s	
152/2700 (epoch 2.815), train_loss = 2.87378215, grad/param norm = 4.5735e-01, time/batch = 0.5185s	
153/2700 (epoch 2.833), train_loss = 2.91509202, grad/param norm = 6.3707e-01, time/batch = 0.5209s	
154/2700 (epoch 2.852), train_loss = 2.98517276, grad/param norm = 5.2959e-01, time/batch = 0.4478s	
155/2700 (epoch 2.870), train_loss = 2.84725815, grad/param norm = 2.9613e-01, time/batch = 0.5071s	
156/2700 (epoch 2.889), train_loss = 2.86697164, grad/param norm = 2.4297e-01, time/batch = 0.4934s	
157/2700 (epoch 2.907), train_loss = 2.92567126, grad/param norm = 1.9241e-01, time/batch = 0.4731s	
158/2700 (epoch 2.926), train_loss = 2.83794558, grad/param norm = 1.9933e-01, time/batch = 0.4806s	
159/2700 (epoch 2.944), train_loss = 2.87442378, grad/param norm = 2.2012e-01, time/batch = 0.4707s	
160/2700 (epoch 2.963), train_loss = 2.93875930, grad/param norm = 1.9661e-01, time/batch = 0.5069s	
161/2700 (epoch 2.981), train_loss = 2.96757735, grad/param norm = 3.4851e-01, time/batch = 0.5103s	
162/2700 (epoch 3.000), train_loss = 4.31351546, grad/param norm = 1.9674e+00, time/batch = 0.5201s	
163/2700 (epoch 3.019), train_loss = 2.89981877, grad/param norm = 4.2211e-01, time/batch = 0.4723s	
164/2700 (epoch 3.037), train_loss = 2.88443873, grad/param norm = 2.7239e-01, time/batch = 0.5132s	
165/2700 (epoch 3.056), train_loss = 2.84228720, grad/param norm = 2.2472e-01, time/batch = 0.5146s	
166/2700 (epoch 3.074), train_loss = 2.87698115, grad/param norm = 2.0743e-01, time/batch = 0.4831s	
167/2700 (epoch 3.093), train_loss = 2.87468837, grad/param norm = 1.9727e-01, time/batch = 0.4738s	
168/2700 (epoch 3.111), train_loss = 2.82550388, grad/param norm = 1.9516e-01, time/batch = 0.4784s	
169/2700 (epoch 3.130), train_loss = 2.85358884, grad/param norm = 2.5651e-01, time/batch = 0.4836s	
170/2700 (epoch 3.148), train_loss = 2.80889938, grad/param norm = 2.8206e-01, time/batch = 0.4822s	
171/2700 (epoch 3.167), train_loss = 2.82177656, grad/param norm = 3.1247e-01, time/batch = 0.5201s	
172/2700 (epoch 3.185), train_loss = 2.80399440, grad/param norm = 3.1706e-01, time/batch = 0.4742s	
173/2700 (epoch 3.204), train_loss = 2.74545471, grad/param norm = 3.9650e-01, time/batch = 0.5070s	
174/2700 (epoch 3.222), train_loss = 2.73273032, grad/param norm = 4.2054e-01, time/batch = 0.4869s	
175/2700 (epoch 3.241), train_loss = 2.72381806, grad/param norm = 4.1926e-01, time/batch = 0.4736s	
176/2700 (epoch 3.259), train_loss = 2.75154466, grad/param norm = 3.5207e-01, time/batch = 0.4698s	
177/2700 (epoch 3.278), train_loss = 2.82258766, grad/param norm = 2.6499e-01, time/batch = 0.4917s	
178/2700 (epoch 3.296), train_loss = 2.78426717, grad/param norm = 1.9970e-01, time/batch = 0.4911s	
179/2700 (epoch 3.315), train_loss = 2.79795217, grad/param norm = 1.6004e-01, time/batch = 0.5096s	
180/2700 (epoch 3.333), train_loss = 2.81792440, grad/param norm = 1.9093e-01, time/batch = 0.5104s	
181/2700 (epoch 3.352), train_loss = 2.95221836, grad/param norm = 4.6974e-01, time/batch = 0.4588s	
182/2700 (epoch 3.370), train_loss = 2.94588416, grad/param norm = 6.7774e-01, time/batch = 0.5191s	
183/2700 (epoch 3.389), train_loss = 2.90597472, grad/param norm = 5.5560e-01, time/batch = 0.4773s	
184/2700 (epoch 3.407), train_loss = 2.86081610, grad/param norm = 4.3322e-01, time/batch = 0.4904s	
185/2700 (epoch 3.426), train_loss = 2.84765990, grad/param norm = 2.7483e-01, time/batch = 0.4650s	
186/2700 (epoch 3.444), train_loss = 2.70195922, grad/param norm = 1.4910e-01, time/batch = 0.4716s	
187/2700 (epoch 3.463), train_loss = 2.77561755, grad/param norm = 1.2569e-01, time/batch = 0.5019s	
188/2700 (epoch 3.481), train_loss = 2.81738791, grad/param norm = 1.2352e-01, time/batch = 0.5077s	
189/2700 (epoch 3.500), train_loss = 2.85052739, grad/param norm = 1.3522e-01, time/batch = 0.5070s	
190/2700 (epoch 3.519), train_loss = 2.80432951, grad/param norm = 1.3394e-01, time/batch = 0.4937s	
191/2700 (epoch 3.537), train_loss = 2.80818829, grad/param norm = 1.6899e-01, time/batch = 0.5094s	
192/2700 (epoch 3.556), train_loss = 2.76862967, grad/param norm = 2.1133e-01, time/batch = 0.4747s	
193/2700 (epoch 3.574), train_loss = 2.74453825, grad/param norm = 3.7135e-01, time/batch = 0.5043s	
194/2700 (epoch 3.593), train_loss = 2.75883752, grad/param norm = 5.1787e-01, time/batch = 0.4727s	
195/2700 (epoch 3.611), train_loss = 2.71642965, grad/param norm = 4.6511e-01, time/batch = 0.4597s	
196/2700 (epoch 3.630), train_loss = 2.75911420, grad/param norm = 4.7671e-01, time/batch = 0.4741s	
197/2700 (epoch 3.648), train_loss = 2.83084793, grad/param norm = 4.7852e-01, time/batch = 0.4831s	
198/2700 (epoch 3.667), train_loss = 2.72092474, grad/param norm = 3.7910e-01, time/batch = 0.5133s	
199/2700 (epoch 3.685), train_loss = 2.74628645, grad/param norm = 4.0675e-01, time/batch = 0.4991s	
200/2700 (epoch 3.704), train_loss = 2.70632602, grad/param norm = 3.3845e-01, time/batch = 0.5090s	
201/2700 (epoch 3.722), train_loss = 2.66406416, grad/param norm = 2.4746e-01, time/batch = 0.4887s	
202/2700 (epoch 3.741), train_loss = 2.82670214, grad/param norm = 2.0598e-01, time/batch = 0.5292s	
203/2700 (epoch 3.759), train_loss = 2.75414341, grad/param norm = 1.7551e-01, time/batch = 0.5062s	
204/2700 (epoch 3.778), train_loss = 2.74875828, grad/param norm = 1.9930e-01, time/batch = 0.4955s	
205/2700 (epoch 3.796), train_loss = 2.72978892, grad/param norm = 2.3962e-01, time/batch = 0.4736s	
206/2700 (epoch 3.815), train_loss = 2.71052622, grad/param norm = 3.2152e-01, time/batch = 0.4788s	
207/2700 (epoch 3.833), train_loss = 2.74145711, grad/param norm = 3.9278e-01, time/batch = 0.4801s	
208/2700 (epoch 3.852), train_loss = 2.76982293, grad/param norm = 4.0472e-01, time/batch = 0.4768s	
209/2700 (epoch 3.870), train_loss = 2.71197250, grad/param norm = 3.1937e-01, time/batch = 0.5010s	
210/2700 (epoch 3.889), train_loss = 2.73828633, grad/param norm = 2.7081e-01, time/batch = 0.5032s	
211/2700 (epoch 3.907), train_loss = 2.82199162, grad/param norm = 2.9306e-01, time/batch = 0.4964s	
212/2700 (epoch 3.926), train_loss = 2.77111474, grad/param norm = 3.4023e-01, time/batch = 0.5116s	
213/2700 (epoch 3.944), train_loss = 2.80888775, grad/param norm = 3.5171e-01, time/batch = 0.5202s	
214/2700 (epoch 3.963), train_loss = 2.83163430, grad/param norm = 3.1075e-01, time/batch = 0.5091s	
215/2700 (epoch 3.981), train_loss = 2.82281902, grad/param norm = 3.6555e-01, time/batch = 0.5146s	
216/2700 (epoch 4.000), train_loss = 3.43460091, grad/param norm = 9.3897e-01, time/batch = 0.4982s	
217/2700 (epoch 4.019), train_loss = 2.83209369, grad/param norm = 7.6323e-01, time/batch = 0.4748s	
218/2700 (epoch 4.037), train_loss = 2.81535282, grad/param norm = 4.6931e-01, time/batch = 0.4807s	
219/2700 (epoch 4.056), train_loss = 2.85985401, grad/param norm = 4.9994e-01, time/batch = 0.4722s	
220/2700 (epoch 4.074), train_loss = 2.83408463, grad/param norm = 4.9390e-01, time/batch = 0.4862s	
221/2700 (epoch 4.093), train_loss = 2.84332456, grad/param norm = 3.5445e-01, time/batch = 0.4762s	
222/2700 (epoch 4.111), train_loss = 2.74451212, grad/param norm = 2.1206e-01, time/batch = 0.5159s	
223/2700 (epoch 4.130), train_loss = 2.74713806, grad/param norm = 1.5358e-01, time/batch = 0.5214s	
224/2700 (epoch 4.148), train_loss = 2.69387074, grad/param norm = 1.8428e-01, time/batch = 0.5233s	
225/2700 (epoch 4.167), train_loss = 2.71548233, grad/param norm = 1.9227e-01, time/batch = 0.4938s	
226/2700 (epoch 4.185), train_loss = 2.67857737, grad/param norm = 1.6614e-01, time/batch = 0.5005s	
227/2700 (epoch 4.204), train_loss = 2.63250329, grad/param norm = 1.9427e-01, time/batch = 0.4805s	
228/2700 (epoch 4.222), train_loss = 2.60263723, grad/param norm = 2.5883e-01, time/batch = 0.4682s	
229/2700 (epoch 4.241), train_loss = 2.61971596, grad/param norm = 2.6282e-01, time/batch = 0.4817s	
230/2700 (epoch 4.259), train_loss = 2.65835392, grad/param norm = 2.9393e-01, time/batch = 0.4843s	
231/2700 (epoch 4.278), train_loss = 2.73695097, grad/param norm = 3.0933e-01, time/batch = 0.4730s	
232/2700 (epoch 4.296), train_loss = 2.72580091, grad/param norm = 3.3009e-01, time/batch = 0.4985s	
233/2700 (epoch 4.315), train_loss = 2.74201126, grad/param norm = 2.7563e-01, time/batch = 0.5218s	
234/2700 (epoch 4.333), train_loss = 2.73172494, grad/param norm = 2.8824e-01, time/batch = 0.5213s	
235/2700 (epoch 4.352), train_loss = 2.77551795, grad/param norm = 3.1955e-01, time/batch = 0.5070s	
236/2700 (epoch 4.370), train_loss = 2.76935328, grad/param norm = 6.4436e-01, time/batch = 0.4563s	
237/2700 (epoch 4.389), train_loss = 2.79174741, grad/param norm = 4.1152e-01, time/batch = 0.4603s	
238/2700 (epoch 4.407), train_loss = 2.79267353, grad/param norm = 5.4784e-01, time/batch = 0.4832s	
239/2700 (epoch 4.426), train_loss = 2.81971758, grad/param norm = 4.5704e-01, time/batch = 0.4801s	
240/2700 (epoch 4.444), train_loss = 2.63524670, grad/param norm = 2.6394e-01, time/batch = 0.4972s	
241/2700 (epoch 4.463), train_loss = 2.71335577, grad/param norm = 2.3948e-01, time/batch = 0.4888s	
242/2700 (epoch 4.481), train_loss = 2.73473322, grad/param norm = 2.6474e-01, time/batch = 0.5285s	
243/2700 (epoch 4.500), train_loss = 2.77223142, grad/param norm = 2.7756e-01, time/batch = 0.5210s	
244/2700 (epoch 4.519), train_loss = 2.74906696, grad/param norm = 3.3387e-01, time/batch = 0.5171s	
245/2700 (epoch 4.537), train_loss = 2.74112504, grad/param norm = 3.9481e-01, time/batch = 0.4462s	
246/2700 (epoch 4.556), train_loss = 2.74943624, grad/param norm = 4.5004e-01, time/batch = 0.5036s	
247/2700 (epoch 4.574), train_loss = 2.68196773, grad/param norm = 3.6109e-01, time/batch = 0.5004s	
248/2700 (epoch 4.593), train_loss = 2.64301566, grad/param norm = 2.4911e-01, time/batch = 0.3968s	
249/2700 (epoch 4.611), train_loss = 2.56498628, grad/param norm = 1.6654e-01, time/batch = 0.5087s	
250/2700 (epoch 4.630), train_loss = 2.59681540, grad/param norm = 1.4115e-01, time/batch = 0.5073s	
251/2700 (epoch 4.648), train_loss = 2.63658974, grad/param norm = 1.8536e-01, time/batch = 0.5104s	
252/2700 (epoch 4.667), train_loss = 2.57712073, grad/param norm = 2.3034e-01, time/batch = 0.5248s	
253/2700 (epoch 4.685), train_loss = 2.63212370, grad/param norm = 3.0441e-01, time/batch = 0.5205s	
254/2700 (epoch 4.704), train_loss = 2.63200595, grad/param norm = 3.6252e-01, time/batch = 0.4552s	
255/2700 (epoch 4.722), train_loss = 2.62199733, grad/param norm = 3.3978e-01, time/batch = 0.5032s	
256/2700 (epoch 4.741), train_loss = 2.77203149, grad/param norm = 3.8555e-01, time/batch = 0.4934s	
257/2700 (epoch 4.759), train_loss = 2.74285185, grad/param norm = 4.4983e-01, time/batch = 0.4679s	
258/2700 (epoch 4.778), train_loss = 2.74351054, grad/param norm = 4.3026e-01, time/batch = 0.4849s	
259/2700 (epoch 4.796), train_loss = 2.69274354, grad/param norm = 3.1316e-01, time/batch = 0.4622s	
260/2700 (epoch 4.815), train_loss = 2.61704946, grad/param norm = 1.8296e-01, time/batch = 0.5079s	
261/2700 (epoch 4.833), train_loss = 2.60837509, grad/param norm = 1.5246e-01, time/batch = 0.5167s	
262/2700 (epoch 4.852), train_loss = 2.62915020, grad/param norm = 1.6276e-01, time/batch = 0.5224s	
263/2700 (epoch 4.870), train_loss = 2.59920942, grad/param norm = 2.5180e-01, time/batch = 0.4780s	
264/2700 (epoch 4.889), train_loss = 2.66613250, grad/param norm = 4.3540e-01, time/batch = 0.5098s	
265/2700 (epoch 4.907), train_loss = 2.77725305, grad/param norm = 4.5364e-01, time/batch = 0.5290s	
266/2700 (epoch 4.926), train_loss = 2.67860388, grad/param norm = 3.3627e-01, time/batch = 0.5062s	
267/2700 (epoch 4.944), train_loss = 2.67238133, grad/param norm = 2.5417e-01, time/batch = 0.4781s	
268/2700 (epoch 4.963), train_loss = 2.71219489, grad/param norm = 2.0666e-01, time/batch = 0.4819s	
269/2700 (epoch 4.981), train_loss = 2.70289507, grad/param norm = 3.4137e-01, time/batch = 0.4782s	
270/2700 (epoch 5.000), train_loss = 2.79574266, grad/param norm = 4.9596e-01, time/batch = 0.4696s	
271/2700 (epoch 5.019), train_loss = 2.78076231, grad/param norm = 4.9360e-01, time/batch = 0.5180s	
272/2700 (epoch 5.037), train_loss = 2.74333050, grad/param norm = 3.5759e-01, time/batch = 0.4793s	
273/2700 (epoch 5.056), train_loss = 2.66482304, grad/param norm = 2.6552e-01, time/batch = 0.5112s	
274/2700 (epoch 5.074), train_loss = 2.65672227, grad/param norm = 2.8003e-01, time/batch = 0.5308s	
275/2700 (epoch 5.093), train_loss = 2.68330674, grad/param norm = 3.1376e-01, time/batch = 0.4985s	
276/2700 (epoch 5.111), train_loss = 2.64265031, grad/param norm = 3.1538e-01, time/batch = 0.4896s	
277/2700 (epoch 5.130), train_loss = 2.66617666, grad/param norm = 3.6087e-01, time/batch = 0.4746s	
278/2700 (epoch 5.148), train_loss = 2.63950628, grad/param norm = 4.1236e-01, time/batch = 0.4810s	
279/2700 (epoch 5.167), train_loss = 2.66386942, grad/param norm = 3.4437e-01, time/batch = 0.4746s	
280/2700 (epoch 5.185), train_loss = 2.58351677, grad/param norm = 2.3708e-01, time/batch = 0.4983s	
281/2700 (epoch 5.204), train_loss = 2.54795144, grad/param norm = 2.5400e-01, time/batch = 0.4224s	
282/2700 (epoch 5.222), train_loss = 2.52477162, grad/param norm = 2.7483e-01, time/batch = 0.5121s	
283/2700 (epoch 5.241), train_loss = 2.51213516, grad/param norm = 2.0904e-01, time/batch = 0.5002s	
284/2700 (epoch 5.259), train_loss = 2.53251346, grad/param norm = 1.8723e-01, time/batch = 0.4647s	
285/2700 (epoch 5.278), train_loss = 2.59283330, grad/param norm = 1.9460e-01, time/batch = 0.4710s	
286/2700 (epoch 5.296), train_loss = 2.58336612, grad/param norm = 2.0609e-01, time/batch = 0.4896s	
287/2700 (epoch 5.315), train_loss = 2.62712461, grad/param norm = 2.4172e-01, time/batch = 0.5006s	
288/2700 (epoch 5.333), train_loss = 2.65357219, grad/param norm = 3.3053e-01, time/batch = 0.5106s	
289/2700 (epoch 5.352), train_loss = 2.69045813, grad/param norm = 3.9789e-01, time/batch = 0.5089s	
290/2700 (epoch 5.370), train_loss = 2.67495306, grad/param norm = 4.5501e-01, time/batch = 0.4927s	
291/2700 (epoch 5.389), train_loss = 2.63068286, grad/param norm = 4.3227e-01, time/batch = 0.5162s	
292/2700 (epoch 5.407), train_loss = 2.68527961, grad/param norm = 4.4304e-01, time/batch = 0.4762s	
293/2700 (epoch 5.426), train_loss = 2.62757559, grad/param norm = 2.8838e-01, time/batch = 0.5102s	
294/2700 (epoch 5.444), train_loss = 2.51287009, grad/param norm = 2.9485e-01, time/batch = 0.4710s	
295/2700 (epoch 5.463), train_loss = 2.58801141, grad/param norm = 3.1307e-01, time/batch = 0.4636s	
296/2700 (epoch 5.481), train_loss = 2.63595310, grad/param norm = 3.1286e-01, time/batch = 0.4659s	
297/2700 (epoch 5.500), train_loss = 2.62713093, grad/param norm = 2.5905e-01, time/batch = 0.4918s	
298/2700 (epoch 5.519), train_loss = 2.60344259, grad/param norm = 2.5948e-01, time/batch = 0.5074s	
299/2700 (epoch 5.537), train_loss = 2.56259951, grad/param norm = 2.1045e-01, time/batch = 0.4941s	
300/2700 (epoch 5.556), train_loss = 2.53453888, grad/param norm = 1.3306e-01, time/batch = 0.5053s	
301/2700 (epoch 5.574), train_loss = 2.48528253, grad/param norm = 1.3364e-01, time/batch = 0.4970s	
302/2700 (epoch 5.593), train_loss = 2.49487384, grad/param norm = 1.7990e-01, time/batch = 0.5195s	
303/2700 (epoch 5.611), train_loss = 2.46367374, grad/param norm = 2.1572e-01, time/batch = 0.5120s	
304/2700 (epoch 5.630), train_loss = 2.52887189, grad/param norm = 3.1330e-01, time/batch = 0.5235s	
305/2700 (epoch 5.648), train_loss = 2.61346712, grad/param norm = 3.0646e-01, time/batch = 0.4748s	
306/2700 (epoch 5.667), train_loss = 2.48109360, grad/param norm = 2.8221e-01, time/batch = 0.4725s	
307/2700 (epoch 5.685), train_loss = 2.53628174, grad/param norm = 4.4745e-01, time/batch = 0.4826s	
308/2700 (epoch 5.704), train_loss = 2.58401694, grad/param norm = 5.0946e-01, time/batch = 0.4676s	
309/2700 (epoch 5.722), train_loss = 2.56865309, grad/param norm = 5.6328e-01, time/batch = 0.4996s	
310/2700 (epoch 5.741), train_loss = 2.68225965, grad/param norm = 3.7388e-01, time/batch = 0.5023s	
311/2700 (epoch 5.759), train_loss = 2.54854152, grad/param norm = 1.7451e-01, time/batch = 0.4987s	
312/2700 (epoch 5.778), train_loss = 2.54115038, grad/param norm = 1.8003e-01, time/batch = 0.5076s	
313/2700 (epoch 5.796), train_loss = 2.51348664, grad/param norm = 2.6073e-01, time/batch = 0.5243s	
314/2700 (epoch 5.815), train_loss = 2.57018390, grad/param norm = 4.3657e-01, time/batch = 0.4952s	
315/2700 (epoch 5.833), train_loss = 2.63706644, grad/param norm = 5.2763e-01, time/batch = 0.4760s	
316/2700 (epoch 5.852), train_loss = 2.59641597, grad/param norm = 3.8895e-01, time/batch = 0.4773s	
317/2700 (epoch 5.870), train_loss = 2.55309636, grad/param norm = 4.6187e-01, time/batch = 0.4813s	
318/2700 (epoch 5.889), train_loss = 2.56735759, grad/param norm = 3.7143e-01, time/batch = 0.4746s	
319/2700 (epoch 5.907), train_loss = 2.58707513, grad/param norm = 1.7865e-01, time/batch = 0.4763s	
320/2700 (epoch 5.926), train_loss = 2.49466301, grad/param norm = 1.6579e-01, time/batch = 0.5032s	
321/2700 (epoch 5.944), train_loss = 2.50044244, grad/param norm = 1.3890e-01, time/batch = 0.4783s	
322/2700 (epoch 5.963), train_loss = 2.55577632, grad/param norm = 1.5996e-01, time/batch = 0.5253s	
323/2700 (epoch 5.981), train_loss = 2.50885841, grad/param norm = 2.2799e-01, time/batch = 0.5095s	
324/2700 (epoch 6.000), train_loss = 2.56307217, grad/param norm = 2.8756e-01, time/batch = 0.5174s	
325/2700 (epoch 6.019), train_loss = 2.54957467, grad/param norm = 2.9496e-01, time/batch = 0.5000s	
326/2700 (epoch 6.037), train_loss = 2.55194630, grad/param norm = 2.2831e-01, time/batch = 0.5109s	
327/2700 (epoch 6.056), train_loss = 2.50869331, grad/param norm = 2.4373e-01, time/batch = 0.4315s	
328/2700 (epoch 6.074), train_loss = 2.51229727, grad/param norm = 2.9203e-01, time/batch = 0.4809s	
329/2700 (epoch 6.093), train_loss = 2.53530580, grad/param norm = 2.5709e-01, time/batch = 0.4727s	
330/2700 (epoch 6.111), train_loss = 2.47533521, grad/param norm = 1.9163e-01, time/batch = 0.4914s	
331/2700 (epoch 6.130), train_loss = 2.48440913, grad/param norm = 1.9150e-01, time/batch = 0.4759s	
332/2700 (epoch 6.148), train_loss = 2.46317319, grad/param norm = 2.5991e-01, time/batch = 0.4914s	
333/2700 (epoch 6.167), train_loss = 2.50403855, grad/param norm = 2.9509e-01, time/batch = 0.5054s	
334/2700 (epoch 6.185), train_loss = 2.46014395, grad/param norm = 3.4671e-01, time/batch = 0.5145s	
335/2700 (epoch 6.204), train_loss = 2.44051138, grad/param norm = 4.0614e-01, time/batch = 0.5236s	
336/2700 (epoch 6.222), train_loss = 2.46149933, grad/param norm = 5.3296e-01, time/batch = 0.4371s	
337/2700 (epoch 6.241), train_loss = 2.50074157, grad/param norm = 4.6770e-01, time/batch = 0.4785s	
338/2700 (epoch 6.259), train_loss = 2.44436450, grad/param norm = 2.6617e-01, time/batch = 0.4726s	
339/2700 (epoch 6.278), train_loss = 2.46619034, grad/param norm = 1.8214e-01, time/batch = 0.4800s	
340/2700 (epoch 6.296), train_loss = 2.42963783, grad/param norm = 1.3935e-01, time/batch = 0.4870s	
341/2700 (epoch 6.315), train_loss = 2.46660485, grad/param norm = 1.9794e-01, time/batch = 0.4920s	
342/2700 (epoch 6.333), train_loss = 2.47757472, grad/param norm = 2.6645e-01, time/batch = 0.4982s	
343/2700 (epoch 6.352), train_loss = 2.52340947, grad/param norm = 3.4054e-01, time/batch = 0.5020s	
344/2700 (epoch 6.370), train_loss = 2.52202403, grad/param norm = 3.9251e-01, time/batch = 0.5178s	
345/2700 (epoch 6.389), train_loss = 2.50728703, grad/param norm = 2.8380e-01, time/batch = 0.4796s	
346/2700 (epoch 6.407), train_loss = 2.48485799, grad/param norm = 3.2504e-01, time/batch = 0.5132s	
347/2700 (epoch 6.426), train_loss = 2.50557799, grad/param norm = 2.9334e-01, time/batch = 0.5031s	
348/2700 (epoch 6.444), train_loss = 2.40817956, grad/param norm = 2.4999e-01, time/batch = 0.4777s	
349/2700 (epoch 6.463), train_loss = 2.44379019, grad/param norm = 2.2784e-01, time/batch = 0.4776s	
350/2700 (epoch 6.481), train_loss = 2.48792439, grad/param norm = 2.4470e-01, time/batch = 0.4787s	
351/2700 (epoch 6.500), train_loss = 2.47723646, grad/param norm = 2.5432e-01, time/batch = 0.4904s	
352/2700 (epoch 6.519), train_loss = 2.43718789, grad/param norm = 2.3233e-01, time/batch = 0.4833s	
353/2700 (epoch 6.537), train_loss = 2.42203384, grad/param norm = 1.9735e-01, time/batch = 0.4808s	
354/2700 (epoch 6.556), train_loss = 2.40438901, grad/param norm = 2.0503e-01, time/batch = 0.4772s	
355/2700 (epoch 6.574), train_loss = 2.38432107, grad/param norm = 2.9710e-01, time/batch = 0.5177s	
356/2700 (epoch 6.593), train_loss = 2.43781043, grad/param norm = 3.9823e-01, time/batch = 0.5188s	
357/2700 (epoch 6.611), train_loss = 2.40234504, grad/param norm = 4.0605e-01, time/batch = 0.5035s	
358/2700 (epoch 6.630), train_loss = 2.43365232, grad/param norm = 3.7274e-01, time/batch = 0.4897s	
359/2700 (epoch 6.648), train_loss = 2.46861511, grad/param norm = 4.1310e-01, time/batch = 0.4918s	
360/2700 (epoch 6.667), train_loss = 2.46224789, grad/param norm = 4.3079e-01, time/batch = 0.4795s	
361/2700 (epoch 6.685), train_loss = 2.42863842, grad/param norm = 3.8322e-01, time/batch = 0.4733s	
362/2700 (epoch 6.704), train_loss = 2.40030079, grad/param norm = 2.6599e-01, time/batch = 0.4977s	
363/2700 (epoch 6.722), train_loss = 2.35564456, grad/param norm = 1.8944e-01, time/batch = 0.4371s	
364/2700 (epoch 6.741), train_loss = 2.44332175, grad/param norm = 1.4725e-01, time/batch = 0.5021s	
365/2700 (epoch 6.759), train_loss = 2.41830187, grad/param norm = 1.4908e-01, time/batch = 0.5164s	
366/2700 (epoch 6.778), train_loss = 2.41629192, grad/param norm = 1.7597e-01, time/batch = 0.5187s	
367/2700 (epoch 6.796), train_loss = 2.36693497, grad/param norm = 2.0567e-01, time/batch = 0.4998s	
368/2700 (epoch 6.815), train_loss = 2.38397862, grad/param norm = 2.3481e-01, time/batch = 0.4995s	
369/2700 (epoch 6.833), train_loss = 2.36255782, grad/param norm = 2.6499e-01, time/batch = 0.4994s	
370/2700 (epoch 6.852), train_loss = 2.39709869, grad/param norm = 2.4630e-01, time/batch = 0.4085s	
371/2700 (epoch 6.870), train_loss = 2.35222276, grad/param norm = 2.2724e-01, time/batch = 0.4873s	
372/2700 (epoch 6.889), train_loss = 2.35279003, grad/param norm = 2.0068e-01, time/batch = 0.4953s	
373/2700 (epoch 6.907), train_loss = 2.45350273, grad/param norm = 1.7437e-01, time/batch = 0.5050s	
374/2700 (epoch 6.926), train_loss = 2.36536234, grad/param norm = 1.7485e-01, time/batch = 0.5112s	
375/2700 (epoch 6.944), train_loss = 2.37426006, grad/param norm = 1.5969e-01, time/batch = 0.5240s	
376/2700 (epoch 6.963), train_loss = 2.42854609, grad/param norm = 1.8510e-01, time/batch = 0.5093s	
377/2700 (epoch 6.981), train_loss = 2.40613173, grad/param norm = 2.7925e-01, time/batch = 0.4987s	
378/2700 (epoch 7.000), train_loss = 2.47870328, grad/param norm = 3.5796e-01, time/batch = 0.4914s	
379/2700 (epoch 7.019), train_loss = 2.49866543, grad/param norm = 3.6140e-01, time/batch = 0.4735s	
380/2700 (epoch 7.037), train_loss = 2.44824534, grad/param norm = 3.0418e-01, time/batch = 0.4743s	
381/2700 (epoch 7.056), train_loss = 2.41167037, grad/param norm = 3.2303e-01, time/batch = 0.4042s	
382/2700 (epoch 7.074), train_loss = 2.40342108, grad/param norm = 3.5377e-01, time/batch = 0.4993s	
383/2700 (epoch 7.093), train_loss = 2.43010567, grad/param norm = 3.1813e-01, time/batch = 0.5054s	
384/2700 (epoch 7.111), train_loss = 2.37585609, grad/param norm = 2.8816e-01, time/batch = 0.5173s	
385/2700 (epoch 7.130), train_loss = 2.40275191, grad/param norm = 2.9117e-01, time/batch = 0.5217s	
386/2700 (epoch 7.148), train_loss = 2.38050292, grad/param norm = 3.8885e-01, time/batch = 0.5083s	
387/2700 (epoch 7.167), train_loss = 2.45801658, grad/param norm = 3.7130e-01, time/batch = 0.4957s	
388/2700 (epoch 7.185), train_loss = 2.34041874, grad/param norm = 2.4823e-01, time/batch = 0.4848s	
389/2700 (epoch 7.204), train_loss = 2.31968776, grad/param norm = 1.8207e-01, time/batch = 0.4880s	
390/2700 (epoch 7.222), train_loss = 2.28041325, grad/param norm = 2.0860e-01, time/batch = 0.4748s	
391/2700 (epoch 7.241), train_loss = 2.26610989, grad/param norm = 1.9049e-01, time/batch = 0.4828s	
392/2700 (epoch 7.259), train_loss = 2.25858576, grad/param norm = 1.6480e-01, time/batch = 0.4144s	
393/2700 (epoch 7.278), train_loss = 2.34620888, grad/param norm = 1.7512e-01, time/batch = 0.5074s	
394/2700 (epoch 7.296), train_loss = 2.33153918, grad/param norm = 1.8977e-01, time/batch = 0.5198s	
395/2700 (epoch 7.315), train_loss = 2.36461840, grad/param norm = 1.8978e-01, time/batch = 0.5221s	
396/2700 (epoch 7.333), train_loss = 2.34331845, grad/param norm = 1.8331e-01, time/batch = 0.5116s	
397/2700 (epoch 7.352), train_loss = 2.38602447, grad/param norm = 2.6891e-01, time/batch = 0.5142s	
398/2700 (epoch 7.370), train_loss = 2.39800052, grad/param norm = 3.3692e-01, time/batch = 0.5126s	
399/2700 (epoch 7.389), train_loss = 2.37404607, grad/param norm = 3.3972e-01, time/batch = 0.4766s	
400/2700 (epoch 7.407), train_loss = 2.36761589, grad/param norm = 2.9851e-01, time/batch = 0.4818s	
401/2700 (epoch 7.426), train_loss = 2.37690983, grad/param norm = 2.3305e-01, time/batch = 0.4605s	
402/2700 (epoch 7.444), train_loss = 2.27059827, grad/param norm = 1.8165e-01, time/batch = 0.4709s	
403/2700 (epoch 7.463), train_loss = 2.31303107, grad/param norm = 2.2680e-01, time/batch = 0.4539s	
404/2700 (epoch 7.481), train_loss = 2.37881349, grad/param norm = 2.7381e-01, time/batch = 0.5187s	
405/2700 (epoch 7.500), train_loss = 2.39983603, grad/param norm = 2.9655e-01, time/batch = 0.5308s	
406/2700 (epoch 7.519), train_loss = 2.34377604, grad/param norm = 2.7243e-01, time/batch = 0.5026s	
407/2700 (epoch 7.537), train_loss = 2.35323166, grad/param norm = 2.4166e-01, time/batch = 0.4785s	
408/2700 (epoch 7.556), train_loss = 2.30692697, grad/param norm = 2.0866e-01, time/batch = 0.4828s	
409/2700 (epoch 7.574), train_loss = 2.27743031, grad/param norm = 2.4733e-01, time/batch = 0.4140s	
410/2700 (epoch 7.593), train_loss = 2.29756186, grad/param norm = 3.1642e-01, time/batch = 0.4780s	
411/2700 (epoch 7.611), train_loss = 2.26418634, grad/param norm = 3.7021e-01, time/batch = 0.4797s	
412/2700 (epoch 7.630), train_loss = 2.32077721, grad/param norm = 3.2656e-01, time/batch = 0.4811s	
413/2700 (epoch 7.648), train_loss = 2.30547321, grad/param norm = 2.3557e-01, time/batch = 0.5102s	
414/2700 (epoch 7.667), train_loss = 2.23153242, grad/param norm = 1.5051e-01, time/batch = 0.4776s	
415/2700 (epoch 7.685), train_loss = 2.23494839, grad/param norm = 1.5067e-01, time/batch = 0.5455s	
416/2700 (epoch 7.704), train_loss = 2.24838152, grad/param norm = 1.4932e-01, time/batch = 0.5049s	
417/2700 (epoch 7.722), train_loss = 2.22088169, grad/param norm = 1.6357e-01, time/batch = 0.4601s	
418/2700 (epoch 7.741), train_loss = 2.32047853, grad/param norm = 2.2050e-01, time/batch = 0.4224s	
419/2700 (epoch 7.759), train_loss = 2.35745429, grad/param norm = 3.3613e-01, time/batch = 0.4790s	
420/2700 (epoch 7.778), train_loss = 2.38986069, grad/param norm = 4.1385e-01, time/batch = 0.5128s	
421/2700 (epoch 7.796), train_loss = 2.32093505, grad/param norm = 3.2350e-01, time/batch = 0.4860s	
422/2700 (epoch 7.815), train_loss = 2.28506606, grad/param norm = 2.1285e-01, time/batch = 0.5000s	
423/2700 (epoch 7.833), train_loss = 2.25445512, grad/param norm = 2.0217e-01, time/batch = 0.5128s	
424/2700 (epoch 7.852), train_loss = 2.26888086, grad/param norm = 1.8335e-01, time/batch = 0.5224s	
425/2700 (epoch 7.870), train_loss = 2.26009876, grad/param norm = 1.9511e-01, time/batch = 0.5104s	
426/2700 (epoch 7.889), train_loss = 2.26284855, grad/param norm = 2.3066e-01, time/batch = 0.4973s	
427/2700 (epoch 7.907), train_loss = 2.39582247, grad/param norm = 2.5794e-01, time/batch = 0.3938s	
428/2700 (epoch 7.926), train_loss = 2.32925246, grad/param norm = 3.0151e-01, time/batch = 0.4698s	
429/2700 (epoch 7.944), train_loss = 2.32989773, grad/param norm = 2.8902e-01, time/batch = 0.4788s	
430/2700 (epoch 7.963), train_loss = 2.33761359, grad/param norm = 2.4346e-01, time/batch = 0.5110s	
431/2700 (epoch 7.981), train_loss = 2.26583565, grad/param norm = 1.7964e-01, time/batch = 0.4814s	
432/2700 (epoch 8.000), train_loss = 2.30188508, grad/param norm = 1.7318e-01, time/batch = 0.5000s	
433/2700 (epoch 8.019), train_loss = 2.30651663, grad/param norm = 2.0263e-01, time/batch = 0.5200s	
434/2700 (epoch 8.037), train_loss = 2.32892699, grad/param norm = 2.6229e-01, time/batch = 0.5279s	
435/2700 (epoch 8.056), train_loss = 2.36253483, grad/param norm = 3.2459e-01, time/batch = 0.5278s	
436/2700 (epoch 8.074), train_loss = 2.31656920, grad/param norm = 2.8673e-01, time/batch = 0.4282s	
437/2700 (epoch 8.093), train_loss = 2.29879603, grad/param norm = 2.1849e-01, time/batch = 0.4614s	
438/2700 (epoch 8.111), train_loss = 2.25175152, grad/param norm = 2.0075e-01, time/batch = 0.4677s	
439/2700 (epoch 8.130), train_loss = 2.27082507, grad/param norm = 2.1610e-01, time/batch = 0.4792s	
440/2700 (epoch 8.148), train_loss = 2.24905870, grad/param norm = 2.9046e-01, time/batch = 0.5118s	
441/2700 (epoch 8.167), train_loss = 2.31725361, grad/param norm = 2.7117e-01, time/batch = 0.4798s	
442/2700 (epoch 8.185), train_loss = 2.21068998, grad/param norm = 1.9190e-01, time/batch = 0.5008s	
443/2700 (epoch 8.204), train_loss = 2.20384475, grad/param norm = 1.8204e-01, time/batch = 0.5108s	
444/2700 (epoch 8.222), train_loss = 2.15878251, grad/param norm = 2.1051e-01, time/batch = 0.5173s	
445/2700 (epoch 8.241), train_loss = 2.12991731, grad/param norm = 2.3066e-01, time/batch = 0.4840s	
446/2700 (epoch 8.259), train_loss = 2.15357776, grad/param norm = 2.2209e-01, time/batch = 0.5164s	
447/2700 (epoch 8.278), train_loss = 2.23380227, grad/param norm = 2.0064e-01, time/batch = 0.5174s	
448/2700 (epoch 8.296), train_loss = 2.21490033, grad/param norm = 1.8673e-01, time/batch = 0.4413s	
449/2700 (epoch 8.315), train_loss = 2.24024951, grad/param norm = 2.1362e-01, time/batch = 0.4707s	
450/2700 (epoch 8.333), train_loss = 2.25440604, grad/param norm = 2.3719e-01, time/batch = 0.4824s	
451/2700 (epoch 8.352), train_loss = 2.26169879, grad/param norm = 2.2252e-01, time/batch = 0.4777s	
452/2700 (epoch 8.370), train_loss = 2.24694824, grad/param norm = 1.7503e-01, time/batch = 0.4873s	
453/2700 (epoch 8.389), train_loss = 2.21717968, grad/param norm = 1.6788e-01, time/batch = 0.5090s	
454/2700 (epoch 8.407), train_loss = 2.23320226, grad/param norm = 1.7343e-01, time/batch = 0.4813s	
455/2700 (epoch 8.426), train_loss = 2.23759807, grad/param norm = 1.5424e-01, time/batch = 0.5213s	
456/2700 (epoch 8.444), train_loss = 2.16108609, grad/param norm = 1.8115e-01, time/batch = 0.5088s	
457/2700 (epoch 8.463), train_loss = 2.24350841, grad/param norm = 2.4165e-01, time/batch = 0.4982s	
458/2700 (epoch 8.481), train_loss = 2.27746465, grad/param norm = 2.5175e-01, time/batch = 0.4877s	
459/2700 (epoch 8.500), train_loss = 2.27371931, grad/param norm = 2.6846e-01, time/batch = 0.4026s	
460/2700 (epoch 8.519), train_loss = 2.24067572, grad/param norm = 3.3442e-01, time/batch = 0.4889s	
461/2700 (epoch 8.537), train_loss = 2.27574311, grad/param norm = 3.6368e-01, time/batch = 0.4802s	
462/2700 (epoch 8.556), train_loss = 2.25425115, grad/param norm = 3.2910e-01, time/batch = 0.4946s	
463/2700 (epoch 8.574), train_loss = 2.23554823, grad/param norm = 3.2161e-01, time/batch = 0.5009s	
464/2700 (epoch 8.593), train_loss = 2.23301032, grad/param norm = 2.9446e-01, time/batch = 0.5183s	
465/2700 (epoch 8.611), train_loss = 2.14607272, grad/param norm = 2.4386e-01, time/batch = 0.4866s	
466/2700 (epoch 8.630), train_loss = 2.17021977, grad/param norm = 2.3371e-01, time/batch = 0.5210s	
467/2700 (epoch 8.648), train_loss = 2.18245346, grad/param norm = 2.1373e-01, time/batch = 0.4945s	
468/2700 (epoch 8.667), train_loss = 2.15195392, grad/param norm = 2.0782e-01, time/batch = 0.4699s	
469/2700 (epoch 8.685), train_loss = 2.15863941, grad/param norm = 2.2544e-01, time/batch = 0.4750s	
470/2700 (epoch 8.704), train_loss = 2.17410647, grad/param norm = 2.0980e-01, time/batch = 0.4164s	
471/2700 (epoch 8.722), train_loss = 2.13707261, grad/param norm = 1.8265e-01, time/batch = 0.5109s	
472/2700 (epoch 8.741), train_loss = 2.19721073, grad/param norm = 1.6798e-01, time/batch = 0.4922s	
473/2700 (epoch 8.759), train_loss = 2.21452344, grad/param norm = 1.6117e-01, time/batch = 0.5085s	
474/2700 (epoch 8.778), train_loss = 2.22176116, grad/param norm = 1.9178e-01, time/batch = 0.4991s	
475/2700 (epoch 8.796), train_loss = 2.19751806, grad/param norm = 2.5011e-01, time/batch = 0.5122s	
476/2700 (epoch 8.815), train_loss = 2.22462796, grad/param norm = 2.5956e-01, time/batch = 0.5240s	
477/2700 (epoch 8.833), train_loss = 2.19278359, grad/param norm = 2.5672e-01, time/batch = 0.4635s	
478/2700 (epoch 8.852), train_loss = 2.18100819, grad/param norm = 2.2172e-01, time/batch = 0.4843s	
479/2700 (epoch 8.870), train_loss = 2.15461396, grad/param norm = 2.1685e-01, time/batch = 0.5015s	
480/2700 (epoch 8.889), train_loss = 2.14538991, grad/param norm = 2.0662e-01, time/batch = 0.4919s	
481/2700 (epoch 8.907), train_loss = 2.25489334, grad/param norm = 1.7238e-01, time/batch = 0.4459s	
482/2700 (epoch 8.926), train_loss = 2.18266644, grad/param norm = 1.5769e-01, time/batch = 0.5098s	
483/2700 (epoch 8.944), train_loss = 2.18694203, grad/param norm = 1.6663e-01, time/batch = 0.5041s	
484/2700 (epoch 8.963), train_loss = 2.22240226, grad/param norm = 1.7563e-01, time/batch = 0.5183s	
485/2700 (epoch 8.981), train_loss = 2.18096676, grad/param norm = 1.8565e-01, time/batch = 0.5121s	
486/2700 (epoch 9.000), train_loss = 2.20749068, grad/param norm = 1.6905e-01, time/batch = 0.4988s	
487/2700 (epoch 9.019), train_loss = 2.21341242, grad/param norm = 2.0973e-01, time/batch = 0.4888s	
488/2700 (epoch 9.037), train_loss = 2.23762589, grad/param norm = 2.7513e-01, time/batch = 0.4695s	
489/2700 (epoch 9.056), train_loss = 2.23754724, grad/param norm = 3.4822e-01, time/batch = 0.4789s	
490/2700 (epoch 9.074), train_loss = 2.19418162, grad/param norm = 2.9243e-01, time/batch = 0.4835s	
491/2700 (epoch 9.093), train_loss = 2.19476979, grad/param norm = 2.6460e-01, time/batch = 0.4790s	
492/2700 (epoch 9.111), train_loss = 2.17450752, grad/param norm = 3.0501e-01, time/batch = 0.4542s	
493/2700 (epoch 9.130), train_loss = 2.20532720, grad/param norm = 2.6099e-01, time/batch = 0.5108s	
494/2700 (epoch 9.148), train_loss = 2.13215449, grad/param norm = 2.3798e-01, time/batch = 0.5209s	
495/2700 (epoch 9.167), train_loss = 2.18833241, grad/param norm = 2.0147e-01, time/batch = 0.5069s	
496/2700 (epoch 9.185), train_loss = 2.10924984, grad/param norm = 1.6621e-01, time/batch = 0.5009s	
497/2700 (epoch 9.204), train_loss = 2.12220172, grad/param norm = 1.7782e-01, time/batch = 0.4665s	
498/2700 (epoch 9.222), train_loss = 2.06764212, grad/param norm = 2.0064e-01, time/batch = 0.4615s	
499/2700 (epoch 9.241), train_loss = 2.03193700, grad/param norm = 1.9012e-01, time/batch = 0.4728s	
500/2700 (epoch 9.259), train_loss = 2.04796734, grad/param norm = 1.6020e-01, time/batch = 0.4415s	
501/2700 (epoch 9.278), train_loss = 2.12226660, grad/param norm = 1.4806e-01, time/batch = 0.4780s	
502/2700 (epoch 9.296), train_loss = 2.09599518, grad/param norm = 1.2625e-01, time/batch = 0.4978s	
503/2700 (epoch 9.315), train_loss = 2.11689031, grad/param norm = 1.5430e-01, time/batch = 0.4929s	
504/2700 (epoch 9.333), train_loss = 2.15808390, grad/param norm = 2.2989e-01, time/batch = 0.5081s	
505/2700 (epoch 9.352), train_loss = 2.18340727, grad/param norm = 2.8543e-01, time/batch = 0.5156s	
506/2700 (epoch 9.370), train_loss = 2.20754060, grad/param norm = 2.4213e-01, time/batch = 0.4832s	
507/2700 (epoch 9.389), train_loss = 2.16311979, grad/param norm = 2.3041e-01, time/batch = 0.4941s	
508/2700 (epoch 9.407), train_loss = 2.17392343, grad/param norm = 2.7148e-01, time/batch = 0.4623s	
509/2700 (epoch 9.426), train_loss = 2.19593746, grad/param norm = 2.7832e-01, time/batch = 0.4142s	
510/2700 (epoch 9.444), train_loss = 2.07330305, grad/param norm = 2.1887e-01, time/batch = 0.5053s	
511/2700 (epoch 9.463), train_loss = 2.12762413, grad/param norm = 2.3567e-01, time/batch = 0.5044s	
512/2700 (epoch 9.481), train_loss = 2.14515238, grad/param norm = 2.2499e-01, time/batch = 0.5134s	
513/2700 (epoch 9.500), train_loss = 2.12588269, grad/param norm = 1.9403e-01, time/batch = 0.5068s	
514/2700 (epoch 9.519), train_loss = 2.09635647, grad/param norm = 1.7219e-01, time/batch = 0.4957s	
515/2700 (epoch 9.537), train_loss = 2.11276711, grad/param norm = 1.6438e-01, time/batch = 0.5087s	
516/2700 (epoch 9.556), train_loss = 2.07617029, grad/param norm = 1.5478e-01, time/batch = 0.4873s	
517/2700 (epoch 9.574), train_loss = 2.08681431, grad/param norm = 1.6454e-01, time/batch = 0.4685s	
518/2700 (epoch 9.593), train_loss = 2.08338083, grad/param norm = 1.8913e-01, time/batch = 0.4677s	
519/2700 (epoch 9.611), train_loss = 2.03404845, grad/param norm = 2.5432e-01, time/batch = 0.4863s	
520/2700 (epoch 9.630), train_loss = 2.09249809, grad/param norm = 2.6503e-01, time/batch = 0.5056s	
521/2700 (epoch 9.648), train_loss = 2.10070453, grad/param norm = 2.1577e-01, time/batch = 0.5087s	
522/2700 (epoch 9.667), train_loss = 2.07113629, grad/param norm = 1.9546e-01, time/batch = 0.5110s	
523/2700 (epoch 9.685), train_loss = 2.06234402, grad/param norm = 1.9596e-01, time/batch = 0.5058s	
524/2700 (epoch 9.704), train_loss = 2.07729824, grad/param norm = 1.6986e-01, time/batch = 0.5062s	
525/2700 (epoch 9.722), train_loss = 2.01914974, grad/param norm = 1.3190e-01, time/batch = 0.5021s	
526/2700 (epoch 9.741), train_loss = 2.08414357, grad/param norm = 1.3585e-01, time/batch = 0.4734s	
527/2700 (epoch 9.759), train_loss = 2.10741235, grad/param norm = 1.6438e-01, time/batch = 0.4865s	
528/2700 (epoch 9.778), train_loss = 2.12733132, grad/param norm = 2.4322e-01, time/batch = 0.4811s	
529/2700 (epoch 9.796), train_loss = 2.11273669, grad/param norm = 2.8362e-01, time/batch = 0.5148s	
530/2700 (epoch 9.815), train_loss = 2.13739287, grad/param norm = 2.7921e-01, time/batch = 0.5178s	
531/2700 (epoch 9.833), train_loss = 2.09034490, grad/param norm = 2.0849e-01, time/batch = 0.5021s	
532/2700 (epoch 9.852), train_loss = 2.07555775, grad/param norm = 1.6181e-01, time/batch = 0.5105s	
533/2700 (epoch 9.870), train_loss = 2.07008996, grad/param norm = 1.8431e-01, time/batch = 0.5064s	
534/2700 (epoch 9.889), train_loss = 2.07106884, grad/param norm = 2.1324e-01, time/batch = 0.5123s	
535/2700 (epoch 9.907), train_loss = 2.19282302, grad/param norm = 2.2047e-01, time/batch = 0.5234s	
536/2700 (epoch 9.926), train_loss = 2.11893058, grad/param norm = 2.0717e-01, time/batch = 0.4666s	
537/2700 (epoch 9.944), train_loss = 2.11767237, grad/param norm = 2.2844e-01, time/batch = 0.4319s	
538/2700 (epoch 9.963), train_loss = 2.17464768, grad/param norm = 2.6867e-01, time/batch = 0.4637s	
539/2700 (epoch 9.981), train_loss = 2.14289678, grad/param norm = 2.7458e-01, time/batch = 0.4985s	
decayed learning rate by a factor 0.97 to 0.00194	
540/2700 (epoch 10.000), train_loss = 2.17974607, grad/param norm = 3.2046e-01, time/batch = 0.5193s	
541/2700 (epoch 10.019), train_loss = 2.20250386, grad/param norm = 2.7095e-01, time/batch = 0.4984s	
542/2700 (epoch 10.037), train_loss = 2.16450251, grad/param norm = 2.6728e-01, time/batch = 0.5131s	
543/2700 (epoch 10.056), train_loss = 2.13865000, grad/param norm = 2.5445e-01, time/batch = 0.5099s	
544/2700 (epoch 10.074), train_loss = 2.04710276, grad/param norm = 2.0697e-01, time/batch = 0.5194s	
545/2700 (epoch 10.093), train_loss = 2.06275594, grad/param norm = 1.7709e-01, time/batch = 0.4740s	
546/2700 (epoch 10.111), train_loss = 2.01705992, grad/param norm = 1.6297e-01, time/batch = 0.5106s	
547/2700 (epoch 10.130), train_loss = 2.05945511, grad/param norm = 1.6530e-01, time/batch = 0.4686s	
548/2700 (epoch 10.148), train_loss = 1.99621842, grad/param norm = 1.4314e-01, time/batch = 0.3996s	
549/2700 (epoch 10.167), train_loss = 2.06317388, grad/param norm = 1.2877e-01, time/batch = 0.4883s	
550/2700 (epoch 10.185), train_loss = 1.99880906, grad/param norm = 1.0944e-01, time/batch = 0.5100s	
551/2700 (epoch 10.204), train_loss = 2.01391643, grad/param norm = 1.0600e-01, time/batch = 0.5017s	
552/2700 (epoch 10.222), train_loss = 1.95507523, grad/param norm = 1.2658e-01, time/batch = 0.5134s	
553/2700 (epoch 10.241), train_loss = 1.90258849, grad/param norm = 1.1526e-01, time/batch = 0.5136s	
554/2700 (epoch 10.259), train_loss = 1.93871410, grad/param norm = 1.2692e-01, time/batch = 0.4953s	
555/2700 (epoch 10.278), train_loss = 2.03285630, grad/param norm = 1.6829e-01, time/batch = 0.5194s	
556/2700 (epoch 10.296), train_loss = 2.02759204, grad/param norm = 1.7556e-01, time/batch = 0.4912s	
557/2700 (epoch 10.315), train_loss = 2.04282298, grad/param norm = 1.6682e-01, time/batch = 0.4800s	
558/2700 (epoch 10.333), train_loss = 2.04288993, grad/param norm = 1.4550e-01, time/batch = 0.4548s	
559/2700 (epoch 10.352), train_loss = 2.03053325, grad/param norm = 1.3797e-01, time/batch = 0.4091s	
560/2700 (epoch 10.370), train_loss = 2.06226355, grad/param norm = 1.5936e-01, time/batch = 0.5212s	
561/2700 (epoch 10.389), train_loss = 2.04374827, grad/param norm = 1.7810e-01, time/batch = 0.5095s	
562/2700 (epoch 10.407), train_loss = 2.06883162, grad/param norm = 1.8649e-01, time/batch = 0.5103s	
563/2700 (epoch 10.426), train_loss = 2.07867890, grad/param norm = 1.6986e-01, time/batch = 0.4966s	
564/2700 (epoch 10.444), train_loss = 1.95932997, grad/param norm = 1.3825e-01, time/batch = 0.5103s	
565/2700 (epoch 10.463), train_loss = 2.02531537, grad/param norm = 1.5629e-01, time/batch = 0.4876s	
566/2700 (epoch 10.481), train_loss = 2.03977699, grad/param norm = 1.7426e-01, time/batch = 0.5324s	
567/2700 (epoch 10.500), train_loss = 2.05019255, grad/param norm = 2.4997e-01, time/batch = 0.4902s	
568/2700 (epoch 10.519), train_loss = 2.08838999, grad/param norm = 2.8933e-01, time/batch = 0.4855s	
569/2700 (epoch 10.537), train_loss = 2.08737666, grad/param norm = 3.3098e-01, time/batch = 0.4696s	
570/2700 (epoch 10.556), train_loss = 2.05907422, grad/param norm = 2.7914e-01, time/batch = 0.4604s	
571/2700 (epoch 10.574), train_loss = 2.05357189, grad/param norm = 2.6062e-01, time/batch = 0.5015s	
572/2700 (epoch 10.593), train_loss = 2.05038414, grad/param norm = 2.7569e-01, time/batch = 0.5055s	
573/2700 (epoch 10.611), train_loss = 1.94311729, grad/param norm = 2.2893e-01, time/batch = 0.5114s	
574/2700 (epoch 10.630), train_loss = 1.97565021, grad/param norm = 1.9038e-01, time/batch = 0.4737s	
575/2700 (epoch 10.648), train_loss = 2.00086483, grad/param norm = 1.7914e-01, time/batch = 0.5223s	
576/2700 (epoch 10.667), train_loss = 1.97683491, grad/param norm = 1.7162e-01, time/batch = 0.4990s	
577/2700 (epoch 10.685), train_loss = 1.98194365, grad/param norm = 1.8870e-01, time/batch = 0.4810s	
578/2700 (epoch 10.704), train_loss = 2.00222639, grad/param norm = 1.7340e-01, time/batch = 0.4709s	
579/2700 (epoch 10.722), train_loss = 1.93629436, grad/param norm = 1.3349e-01, time/batch = 0.4742s	
580/2700 (epoch 10.741), train_loss = 1.98990697, grad/param norm = 1.2724e-01, time/batch = 0.4881s	
581/2700 (epoch 10.759), train_loss = 2.02284883, grad/param norm = 1.3523e-01, time/batch = 0.4422s	
582/2700 (epoch 10.778), train_loss = 2.03081028, grad/param norm = 1.5513e-01, time/batch = 0.5111s	
583/2700 (epoch 10.796), train_loss = 1.97840808, grad/param norm = 1.7985e-01, time/batch = 0.4935s	
584/2700 (epoch 10.815), train_loss = 2.01946784, grad/param norm = 1.8454e-01, time/batch = 0.5211s	
585/2700 (epoch 10.833), train_loss = 1.99168833, grad/param norm = 1.9728e-01, time/batch = 0.5238s	
586/2700 (epoch 10.852), train_loss = 1.99893270, grad/param norm = 1.9741e-01, time/batch = 0.5327s	
587/2700 (epoch 10.870), train_loss = 1.98845603, grad/param norm = 1.7365e-01, time/batch = 0.4811s	
588/2700 (epoch 10.889), train_loss = 1.97002611, grad/param norm = 1.5974e-01, time/batch = 0.4693s	
589/2700 (epoch 10.907), train_loss = 2.09041392, grad/param norm = 1.7171e-01, time/batch = 0.4762s	
590/2700 (epoch 10.926), train_loss = 2.02934234, grad/param norm = 2.1037e-01, time/batch = 0.4719s	
591/2700 (epoch 10.944), train_loss = 2.02074804, grad/param norm = 2.0937e-01, time/batch = 0.4826s	
592/2700 (epoch 10.963), train_loss = 2.05520598, grad/param norm = 2.0337e-01, time/batch = 0.4343s	
593/2700 (epoch 10.981), train_loss = 2.01033449, grad/param norm = 1.9566e-01, time/batch = 0.5141s	
decayed learning rate by a factor 0.97 to 0.0018818	
594/2700 (epoch 11.000), train_loss = 2.02141644, grad/param norm = 1.5406e-01, time/batch = 0.5190s	
595/2700 (epoch 11.019), train_loss = 2.03071861, grad/param norm = 1.5388e-01, time/batch = 0.5074s	
596/2700 (epoch 11.037), train_loss = 2.02270210, grad/param norm = 1.4641e-01, time/batch = 0.4995s	
597/2700 (epoch 11.056), train_loss = 1.98361161, grad/param norm = 1.6363e-01, time/batch = 0.4901s	
598/2700 (epoch 11.074), train_loss = 1.93119642, grad/param norm = 1.5006e-01, time/batch = 0.4700s	
599/2700 (epoch 11.093), train_loss = 1.95293455, grad/param norm = 1.3137e-01, time/batch = 0.4800s	
600/2700 (epoch 11.111), train_loss = 1.92507521, grad/param norm = 1.4507e-01, time/batch = 0.4776s	
601/2700 (epoch 11.130), train_loss = 1.96362686, grad/param norm = 1.4411e-01, time/batch = 0.4744s	
602/2700 (epoch 11.148), train_loss = 1.90199980, grad/param norm = 1.4762e-01, time/batch = 0.4759s	
603/2700 (epoch 11.167), train_loss = 1.99956549, grad/param norm = 1.8975e-01, time/batch = 0.4798s	
604/2700 (epoch 11.185), train_loss = 1.94390536, grad/param norm = 2.0495e-01, time/batch = 0.5193s	
605/2700 (epoch 11.204), train_loss = 1.97430238, grad/param norm = 2.0105e-01, time/batch = 0.5008s	
606/2700 (epoch 11.222), train_loss = 1.90119699, grad/param norm = 1.8969e-01, time/batch = 0.5092s	
607/2700 (epoch 11.241), train_loss = 1.84796863, grad/param norm = 1.9282e-01, time/batch = 0.4715s	
608/2700 (epoch 11.259), train_loss = 1.90892081, grad/param norm = 2.0850e-01, time/batch = 0.4841s	
609/2700 (epoch 11.278), train_loss = 1.98134498, grad/param norm = 2.0886e-01, time/batch = 0.4626s	
610/2700 (epoch 11.296), train_loss = 1.97517998, grad/param norm = 1.9069e-01, time/batch = 0.4823s	
611/2700 (epoch 11.315), train_loss = 1.97166061, grad/param norm = 1.9571e-01, time/batch = 0.4765s	
612/2700 (epoch 11.333), train_loss = 1.97429039, grad/param norm = 1.6578e-01, time/batch = 0.4893s	
613/2700 (epoch 11.352), train_loss = 1.94741730, grad/param norm = 1.3764e-01, time/batch = 0.5044s	
614/2700 (epoch 11.370), train_loss = 1.97722614, grad/param norm = 1.3393e-01, time/batch = 0.4960s	
615/2700 (epoch 11.389), train_loss = 1.94597616, grad/param norm = 1.3120e-01, time/batch = 0.5431s	
616/2700 (epoch 11.407), train_loss = 1.96087173, grad/param norm = 1.2125e-01, time/batch = 0.4804s	
617/2700 (epoch 11.426), train_loss = 1.96874240, grad/param norm = 1.2015e-01, time/batch = 0.4619s	
618/2700 (epoch 11.444), train_loss = 1.86647280, grad/param norm = 1.0564e-01, time/batch = 0.4233s	
619/2700 (epoch 11.463), train_loss = 1.94163904, grad/param norm = 1.2501e-01, time/batch = 0.4714s	
620/2700 (epoch 11.481), train_loss = 1.94246611, grad/param norm = 1.3942e-01, time/batch = 0.5051s	
621/2700 (epoch 11.500), train_loss = 1.93608944, grad/param norm = 1.4158e-01, time/batch = 0.4809s	
622/2700 (epoch 11.519), train_loss = 1.94189449, grad/param norm = 1.7382e-01, time/batch = 0.4987s	
623/2700 (epoch 11.537), train_loss = 1.98193347, grad/param norm = 2.1289e-01, time/batch = 0.5124s	
624/2700 (epoch 11.556), train_loss = 1.94691509, grad/param norm = 2.5392e-01, time/batch = 0.5125s	
625/2700 (epoch 11.574), train_loss = 1.97650885, grad/param norm = 2.3137e-01, time/batch = 0.5157s	
626/2700 (epoch 11.593), train_loss = 1.93567700, grad/param norm = 1.9537e-01, time/batch = 0.4949s	
627/2700 (epoch 11.611), train_loss = 1.85099691, grad/param norm = 2.0247e-01, time/batch = 0.4084s	
628/2700 (epoch 11.630), train_loss = 1.89836169, grad/param norm = 1.7857e-01, time/batch = 0.4769s	
629/2700 (epoch 11.648), train_loss = 1.90757378, grad/param norm = 1.2972e-01, time/batch = 0.4656s	
630/2700 (epoch 11.667), train_loss = 1.88138684, grad/param norm = 1.1806e-01, time/batch = 0.5017s	
631/2700 (epoch 11.685), train_loss = 1.89098792, grad/param norm = 1.2891e-01, time/batch = 0.4808s	
632/2700 (epoch 11.704), train_loss = 1.91110430, grad/param norm = 1.3390e-01, time/batch = 0.4944s	
633/2700 (epoch 11.722), train_loss = 1.85452634, grad/param norm = 1.1115e-01, time/batch = 0.5182s	
634/2700 (epoch 11.741), train_loss = 1.90574226, grad/param norm = 1.2749e-01, time/batch = 0.5100s	
635/2700 (epoch 11.759), train_loss = 1.97039583, grad/param norm = 2.1905e-01, time/batch = 0.5207s	
636/2700 (epoch 11.778), train_loss = 2.04083223, grad/param norm = 3.2485e-01, time/batch = 0.4475s	
637/2700 (epoch 11.796), train_loss = 2.00642665, grad/param norm = 2.6378e-01, time/batch = 0.4910s	
638/2700 (epoch 11.815), train_loss = 1.96635094, grad/param norm = 1.9228e-01, time/batch = 0.4756s	
639/2700 (epoch 11.833), train_loss = 1.91805111, grad/param norm = 1.4717e-01, time/batch = 0.4763s	
640/2700 (epoch 11.852), train_loss = 1.89267354, grad/param norm = 1.2949e-01, time/batch = 0.4949s	
641/2700 (epoch 11.870), train_loss = 1.89842628, grad/param norm = 1.4347e-01, time/batch = 0.4808s	
642/2700 (epoch 11.889), train_loss = 1.88959411, grad/param norm = 1.4928e-01, time/batch = 0.5032s	
643/2700 (epoch 11.907), train_loss = 2.00977358, grad/param norm = 1.7028e-01, time/batch = 0.5122s	
644/2700 (epoch 11.926), train_loss = 1.95243690, grad/param norm = 1.7855e-01, time/batch = 0.5269s	
645/2700 (epoch 11.944), train_loss = 1.93479747, grad/param norm = 1.6537e-01, time/batch = 0.4815s	
646/2700 (epoch 11.963), train_loss = 1.95843980, grad/param norm = 1.4158e-01, time/batch = 0.5047s	
647/2700 (epoch 11.981), train_loss = 1.91359261, grad/param norm = 1.1286e-01, time/batch = 0.5191s	
decayed learning rate by a factor 0.97 to 0.001825346	
648/2700 (epoch 12.000), train_loss = 1.93213587, grad/param norm = 1.0311e-01, time/batch = 0.4527s	
649/2700 (epoch 12.019), train_loss = 1.95071974, grad/param norm = 1.2775e-01, time/batch = 0.4833s	
650/2700 (epoch 12.037), train_loss = 1.94765893, grad/param norm = 1.2909e-01, time/batch = 0.4812s	
651/2700 (epoch 12.056), train_loss = 1.91373507, grad/param norm = 1.5312e-01, time/batch = 0.4837s	
652/2700 (epoch 12.074), train_loss = 1.86316725, grad/param norm = 1.4337e-01, time/batch = 0.4960s	
653/2700 (epoch 12.093), train_loss = 1.87626824, grad/param norm = 1.2853e-01, time/batch = 0.4997s	
654/2700 (epoch 12.111), train_loss = 1.85459733, grad/param norm = 1.3925e-01, time/batch = 0.4821s	
655/2700 (epoch 12.130), train_loss = 1.89923586, grad/param norm = 1.6718e-01, time/batch = 0.5174s	
656/2700 (epoch 12.148), train_loss = 1.85391579, grad/param norm = 2.2191e-01, time/batch = 0.5168s	
657/2700 (epoch 12.167), train_loss = 1.97052999, grad/param norm = 2.2122e-01, time/batch = 0.4988s	
658/2700 (epoch 12.185), train_loss = 1.88046605, grad/param norm = 1.8463e-01, time/batch = 0.5041s	
659/2700 (epoch 12.204), train_loss = 1.89546381, grad/param norm = 1.3963e-01, time/batch = 0.4230s	
660/2700 (epoch 12.222), train_loss = 1.81266059, grad/param norm = 1.1176e-01, time/batch = 0.4890s	
661/2700 (epoch 12.241), train_loss = 1.74669616, grad/param norm = 1.1089e-01, time/batch = 0.4793s	
662/2700 (epoch 12.259), train_loss = 1.80081972, grad/param norm = 1.1625e-01, time/batch = 0.5184s	
663/2700 (epoch 12.278), train_loss = 1.86719340, grad/param norm = 1.1837e-01, time/batch = 0.4752s	
664/2700 (epoch 12.296), train_loss = 1.86059644, grad/param norm = 1.2654e-01, time/batch = 0.5171s	
665/2700 (epoch 12.315), train_loss = 1.88590670, grad/param norm = 1.4563e-01, time/batch = 0.5223s	
666/2700 (epoch 12.333), train_loss = 1.89054957, grad/param norm = 1.5459e-01, time/batch = 0.5030s	
667/2700 (epoch 12.352), train_loss = 1.88938422, grad/param norm = 1.5404e-01, time/batch = 0.4900s	
668/2700 (epoch 12.370), train_loss = 1.92068154, grad/param norm = 1.7938e-01, time/batch = 0.5130s	
669/2700 (epoch 12.389), train_loss = 1.90570251, grad/param norm = 2.0561e-01, time/batch = 0.4795s	
670/2700 (epoch 12.407), train_loss = 1.93155903, grad/param norm = 2.1406e-01, time/batch = 0.4268s	
671/2700 (epoch 12.426), train_loss = 1.92441068, grad/param norm = 1.6615e-01, time/batch = 0.4825s	
672/2700 (epoch 12.444), train_loss = 1.82379042, grad/param norm = 1.6680e-01, time/batch = 0.5203s	
673/2700 (epoch 12.463), train_loss = 1.90437607, grad/param norm = 1.5924e-01, time/batch = 0.5026s	
674/2700 (epoch 12.481), train_loss = 1.87822096, grad/param norm = 1.2981e-01, time/batch = 0.5197s	
675/2700 (epoch 12.500), train_loss = 1.86110115, grad/param norm = 1.3070e-01, time/batch = 0.5194s	
676/2700 (epoch 12.519), train_loss = 1.86617885, grad/param norm = 1.3120e-01, time/batch = 0.5158s	
677/2700 (epoch 12.537), train_loss = 1.87049461, grad/param norm = 1.2307e-01, time/batch = 0.5023s	
678/2700 (epoch 12.556), train_loss = 1.82124506, grad/param norm = 1.2052e-01, time/batch = 0.4886s	
679/2700 (epoch 12.574), train_loss = 1.84289637, grad/param norm = 1.2139e-01, time/batch = 0.4804s	
680/2700 (epoch 12.593), train_loss = 1.84267105, grad/param norm = 1.3381e-01, time/batch = 0.4834s	
681/2700 (epoch 12.611), train_loss = 1.76116044, grad/param norm = 1.4232e-01, time/batch = 0.4373s	
682/2700 (epoch 12.630), train_loss = 1.81257904, grad/param norm = 1.6341e-01, time/batch = 0.5081s	
683/2700 (epoch 12.648), train_loss = 1.86072055, grad/param norm = 1.9589e-01, time/batch = 0.4927s	
684/2700 (epoch 12.667), train_loss = 1.85554493, grad/param norm = 2.1476e-01, time/batch = 0.5232s	
685/2700 (epoch 12.685), train_loss = 1.87326315, grad/param norm = 2.0804e-01, time/batch = 0.5066s	
686/2700 (epoch 12.704), train_loss = 1.87765431, grad/param norm = 1.8209e-01, time/batch = 0.5053s	
687/2700 (epoch 12.722), train_loss = 1.81262204, grad/param norm = 1.5235e-01, time/batch = 0.4811s	
688/2700 (epoch 12.741), train_loss = 1.85337227, grad/param norm = 1.5648e-01, time/batch = 0.4805s	
689/2700 (epoch 12.759), train_loss = 1.91473027, grad/param norm = 2.1417e-01, time/batch = 0.4806s	
690/2700 (epoch 12.778), train_loss = 1.94353971, grad/param norm = 2.2138e-01, time/batch = 0.4659s	
691/2700 (epoch 12.796), train_loss = 1.86062024, grad/param norm = 1.8810e-01, time/batch = 0.4725s	
692/2700 (epoch 12.815), train_loss = 1.88244259, grad/param norm = 1.5269e-01, time/batch = 0.4473s	
693/2700 (epoch 12.833), train_loss = 1.84658667, grad/param norm = 1.3466e-01, time/batch = 0.5197s	
694/2700 (epoch 12.852), train_loss = 1.82848498, grad/param norm = 1.2035e-01, time/batch = 0.5106s	
695/2700 (epoch 12.870), train_loss = 1.84178548, grad/param norm = 1.2092e-01, time/batch = 0.4927s	
696/2700 (epoch 12.889), train_loss = 1.83111876, grad/param norm = 1.3184e-01, time/batch = 0.4800s	
697/2700 (epoch 12.907), train_loss = 1.94579745, grad/param norm = 1.5136e-01, time/batch = 0.4753s	
698/2700 (epoch 12.926), train_loss = 1.89290950, grad/param norm = 1.8651e-01, time/batch = 0.4772s	
699/2700 (epoch 12.944), train_loss = 1.87991985, grad/param norm = 1.7254e-01, time/batch = 0.4799s	
700/2700 (epoch 12.963), train_loss = 1.89495671, grad/param norm = 1.4903e-01, time/batch = 0.4933s	
701/2700 (epoch 12.981), train_loss = 1.85836603, grad/param norm = 1.5605e-01, time/batch = 0.4784s	
decayed learning rate by a factor 0.97 to 0.00177058562	
702/2700 (epoch 13.000), train_loss = 1.87850944, grad/param norm = 1.3534e-01, time/batch = 0.4946s	
703/2700 (epoch 13.019), train_loss = 1.89354780, grad/param norm = 1.3816e-01, time/batch = 0.4829s	
704/2700 (epoch 13.037), train_loss = 1.89032216, grad/param norm = 1.3465e-01, time/batch = 0.5113s	
705/2700 (epoch 13.056), train_loss = 1.84673776, grad/param norm = 1.5452e-01, time/batch = 0.4873s	
706/2700 (epoch 13.074), train_loss = 1.79436309, grad/param norm = 1.3103e-01, time/batch = 0.4561s	
707/2700 (epoch 13.093), train_loss = 1.80024541, grad/param norm = 1.1723e-01, time/batch = 0.4602s	
708/2700 (epoch 13.111), train_loss = 1.78194949, grad/param norm = 1.2528e-01, time/batch = 0.4874s	
709/2700 (epoch 13.130), train_loss = 1.82316916, grad/param norm = 1.2792e-01, time/batch = 0.4594s	
710/2700 (epoch 13.148), train_loss = 1.75969949, grad/param norm = 1.1463e-01, time/batch = 0.5113s	
711/2700 (epoch 13.167), train_loss = 1.86192557, grad/param norm = 1.2414e-01, time/batch = 0.4940s	
712/2700 (epoch 13.185), train_loss = 1.79582051, grad/param norm = 1.4174e-01, time/batch = 0.5081s	
713/2700 (epoch 13.204), train_loss = 1.83209419, grad/param norm = 1.3976e-01, time/batch = 0.5127s	
714/2700 (epoch 13.222), train_loss = 1.75916437, grad/param norm = 1.2525e-01, time/batch = 0.5031s	
715/2700 (epoch 13.241), train_loss = 1.68934466, grad/param norm = 1.4083e-01, time/batch = 0.4971s	
716/2700 (epoch 13.259), train_loss = 1.76513729, grad/param norm = 1.5539e-01, time/batch = 0.4803s	
717/2700 (epoch 13.278), train_loss = 1.82485742, grad/param norm = 1.5492e-01, time/batch = 0.4576s	
718/2700 (epoch 13.296), train_loss = 1.80343702, grad/param norm = 1.3043e-01, time/batch = 0.4165s	
719/2700 (epoch 13.315), train_loss = 1.81153884, grad/param norm = 1.1341e-01, time/batch = 0.4887s	
720/2700 (epoch 13.333), train_loss = 1.80748358, grad/param norm = 1.2934e-01, time/batch = 0.5218s	
721/2700 (epoch 13.352), train_loss = 1.80920032, grad/param norm = 1.2883e-01, time/batch = 0.4935s	
722/2700 (epoch 13.370), train_loss = 1.83626964, grad/param norm = 1.3368e-01, time/batch = 0.5116s	
723/2700 (epoch 13.389), train_loss = 1.82043295, grad/param norm = 1.4367e-01, time/batch = 0.5107s	
724/2700 (epoch 13.407), train_loss = 1.84932684, grad/param norm = 1.4496e-01, time/batch = 0.5231s	
725/2700 (epoch 13.426), train_loss = 1.85960354, grad/param norm = 1.4469e-01, time/batch = 0.5167s	
726/2700 (epoch 13.444), train_loss = 1.75804961, grad/param norm = 1.3960e-01, time/batch = 0.4962s	
727/2700 (epoch 13.463), train_loss = 1.84110933, grad/param norm = 1.4449e-01, time/batch = 0.3837s	
728/2700 (epoch 13.481), train_loss = 1.82702414, grad/param norm = 1.3147e-01, time/batch = 0.4749s	
729/2700 (epoch 13.500), train_loss = 1.80633265, grad/param norm = 1.3348e-01, time/batch = 0.4807s	
730/2700 (epoch 13.519), train_loss = 1.81953811, grad/param norm = 1.3348e-01, time/batch = 0.5133s	
731/2700 (epoch 13.537), train_loss = 1.82364736, grad/param norm = 1.4043e-01, time/batch = 0.4885s	
732/2700 (epoch 13.556), train_loss = 1.76543978, grad/param norm = 1.3314e-01, time/batch = 0.5061s	
733/2700 (epoch 13.574), train_loss = 1.80359493, grad/param norm = 1.6128e-01, time/batch = 0.5166s	
734/2700 (epoch 13.593), train_loss = 1.80833503, grad/param norm = 1.9031e-01, time/batch = 0.5282s	
735/2700 (epoch 13.611), train_loss = 1.71810138, grad/param norm = 1.8151e-01, time/batch = 0.5156s	
736/2700 (epoch 13.630), train_loss = 1.74701220, grad/param norm = 1.4805e-01, time/batch = 0.4276s	
737/2700 (epoch 13.648), train_loss = 1.76380489, grad/param norm = 1.2757e-01, time/batch = 0.4291s	
738/2700 (epoch 13.667), train_loss = 1.75027199, grad/param norm = 1.1791e-01, time/batch = 0.4805s	
739/2700 (epoch 13.685), train_loss = 1.77406462, grad/param norm = 1.3248e-01, time/batch = 0.5052s	
740/2700 (epoch 13.704), train_loss = 1.79337177, grad/param norm = 1.4243e-01, time/batch = 0.5189s	
741/2700 (epoch 13.722), train_loss = 1.74952089, grad/param norm = 1.3716e-01, time/batch = 0.4937s	
742/2700 (epoch 13.741), train_loss = 1.79065809, grad/param norm = 1.6111e-01, time/batch = 0.5195s	
743/2700 (epoch 13.759), train_loss = 1.84535757, grad/param norm = 2.0629e-01, time/batch = 0.5214s	
744/2700 (epoch 13.778), train_loss = 1.87143033, grad/param norm = 2.1317e-01, time/batch = 0.5204s	
745/2700 (epoch 13.796), train_loss = 1.79783282, grad/param norm = 1.6690e-01, time/batch = 0.4562s	
746/2700 (epoch 13.815), train_loss = 1.81183634, grad/param norm = 1.4042e-01, time/batch = 0.4992s	
747/2700 (epoch 13.833), train_loss = 1.78101599, grad/param norm = 1.2713e-01, time/batch = 0.4792s	
748/2700 (epoch 13.852), train_loss = 1.76302874, grad/param norm = 1.1674e-01, time/batch = 0.4144s	
749/2700 (epoch 13.870), train_loss = 1.77658168, grad/param norm = 1.1513e-01, time/batch = 0.5213s	
750/2700 (epoch 13.889), train_loss = 1.77549793, grad/param norm = 1.3257e-01, time/batch = 0.5084s	
751/2700 (epoch 13.907), train_loss = 1.87805153, grad/param norm = 1.3899e-01, time/batch = 0.5110s	
752/2700 (epoch 13.926), train_loss = 1.82592465, grad/param norm = 1.4490e-01, time/batch = 0.5111s	
753/2700 (epoch 13.944), train_loss = 1.80710283, grad/param norm = 1.5139e-01, time/batch = 0.5185s	
754/2700 (epoch 13.963), train_loss = 1.83766095, grad/param norm = 1.5003e-01, time/batch = 0.4814s	
755/2700 (epoch 13.981), train_loss = 1.80498966, grad/param norm = 1.6239e-01, time/batch = 0.5111s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
756/2700 (epoch 14.000), train_loss = 1.83462682, grad/param norm = 1.6105e-01, time/batch = 0.4963s	
757/2700 (epoch 14.019), train_loss = 1.85843423, grad/param norm = 1.6744e-01, time/batch = 0.4782s	
758/2700 (epoch 14.037), train_loss = 1.84015114, grad/param norm = 1.4002e-01, time/batch = 0.4892s	
759/2700 (epoch 14.056), train_loss = 1.78322205, grad/param norm = 1.4609e-01, time/batch = 0.4483s	
760/2700 (epoch 14.074), train_loss = 1.73811045, grad/param norm = 1.1642e-01, time/batch = 0.5111s	
761/2700 (epoch 14.093), train_loss = 1.72826313, grad/param norm = 8.8695e-02, time/batch = 0.5090s	
762/2700 (epoch 14.111), train_loss = 1.70692581, grad/param norm = 9.7648e-02, time/batch = 0.5175s	
763/2700 (epoch 14.130), train_loss = 1.75297681, grad/param norm = 1.1669e-01, time/batch = 0.4819s	
764/2700 (epoch 14.148), train_loss = 1.70761921, grad/param norm = 1.3218e-01, time/batch = 0.5132s	
765/2700 (epoch 14.167), train_loss = 1.81836213, grad/param norm = 1.3988e-01, time/batch = 0.5035s	
766/2700 (epoch 14.185), train_loss = 1.73289721, grad/param norm = 1.2993e-01, time/batch = 0.4997s	
767/2700 (epoch 14.204), train_loss = 1.75921574, grad/param norm = 1.0980e-01, time/batch = 0.4847s	
768/2700 (epoch 14.222), train_loss = 1.70989385, grad/param norm = 1.2130e-01, time/batch = 0.4714s	
769/2700 (epoch 14.241), train_loss = 1.63996286, grad/param norm = 1.2077e-01, time/batch = 0.4770s	
770/2700 (epoch 14.259), train_loss = 1.69773797, grad/param norm = 1.1478e-01, time/batch = 0.4667s	
771/2700 (epoch 14.278), train_loss = 1.76129544, grad/param norm = 1.1265e-01, time/batch = 0.4973s	
772/2700 (epoch 14.296), train_loss = 1.74967868, grad/param norm = 1.2534e-01, time/batch = 0.4943s	
773/2700 (epoch 14.315), train_loss = 1.77097190, grad/param norm = 1.5672e-01, time/batch = 0.5057s	
774/2700 (epoch 14.333), train_loss = 1.77256318, grad/param norm = 1.9265e-01, time/batch = 0.5183s	
775/2700 (epoch 14.352), train_loss = 1.80446399, grad/param norm = 2.0663e-01, time/batch = 0.5100s	
776/2700 (epoch 14.370), train_loss = 1.79761024, grad/param norm = 1.7118e-01, time/batch = 0.5061s	
777/2700 (epoch 14.389), train_loss = 1.74936128, grad/param norm = 1.2323e-01, time/batch = 0.4952s	
778/2700 (epoch 14.407), train_loss = 1.78136032, grad/param norm = 1.0958e-01, time/batch = 0.4767s	
779/2700 (epoch 14.426), train_loss = 1.79528900, grad/param norm = 1.4527e-01, time/batch = 0.4758s	
780/2700 (epoch 14.444), train_loss = 1.70852210, grad/param norm = 1.5427e-01, time/batch = 0.4812s	
781/2700 (epoch 14.463), train_loss = 1.78207115, grad/param norm = 1.2363e-01, time/batch = 0.4476s	
782/2700 (epoch 14.481), train_loss = 1.75459713, grad/param norm = 8.4537e-02, time/batch = 0.5114s	
783/2700 (epoch 14.500), train_loss = 1.72484820, grad/param norm = 9.1000e-02, time/batch = 0.4796s	
784/2700 (epoch 14.519), train_loss = 1.74953628, grad/param norm = 1.0105e-01, time/batch = 0.5199s	
785/2700 (epoch 14.537), train_loss = 1.76099072, grad/param norm = 1.2561e-01, time/batch = 0.5046s	
786/2700 (epoch 14.556), train_loss = 1.70883147, grad/param norm = 1.4806e-01, time/batch = 0.4996s	
787/2700 (epoch 14.574), train_loss = 1.74996687, grad/param norm = 1.5617e-01, time/batch = 0.4688s	
788/2700 (epoch 14.593), train_loss = 1.73432132, grad/param norm = 1.3639e-01, time/batch = 0.4694s	
789/2700 (epoch 14.611), train_loss = 1.62573748, grad/param norm = 1.0437e-01, time/batch = 0.4835s	
790/2700 (epoch 14.630), train_loss = 1.66390627, grad/param norm = 9.5811e-02, time/batch = 0.4739s	
791/2700 (epoch 14.648), train_loss = 1.69621204, grad/param norm = 9.4231e-02, time/batch = 0.4766s	
792/2700 (epoch 14.667), train_loss = 1.68961362, grad/param norm = 9.6763e-02, time/batch = 0.4528s	
793/2700 (epoch 14.685), train_loss = 1.72427647, grad/param norm = 1.2347e-01, time/batch = 0.5175s	
794/2700 (epoch 14.704), train_loss = 1.73913680, grad/param norm = 1.4452e-01, time/batch = 0.5094s	
795/2700 (epoch 14.722), train_loss = 1.69933026, grad/param norm = 1.3822e-01, time/batch = 0.5113s	
796/2700 (epoch 14.741), train_loss = 1.72852774, grad/param norm = 1.5250e-01, time/batch = 0.4566s	
797/2700 (epoch 14.759), train_loss = 1.77704470, grad/param norm = 1.5841e-01, time/batch = 0.4802s	
798/2700 (epoch 14.778), train_loss = 1.78685789, grad/param norm = 1.3242e-01, time/batch = 0.4700s	
799/2700 (epoch 14.796), train_loss = 1.71444764, grad/param norm = 1.3459e-01, time/batch = 0.4928s	
800/2700 (epoch 14.815), train_loss = 1.75693195, grad/param norm = 1.4385e-01, time/batch = 0.4966s	
801/2700 (epoch 14.833), train_loss = 1.74383699, grad/param norm = 1.6640e-01, time/batch = 0.4786s	
802/2700 (epoch 14.852), train_loss = 1.74557664, grad/param norm = 2.0162e-01, time/batch = 0.5056s	
803/2700 (epoch 14.870), train_loss = 1.77160852, grad/param norm = 2.0978e-01, time/batch = 0.4929s	
804/2700 (epoch 14.889), train_loss = 1.74202370, grad/param norm = 1.6883e-01, time/batch = 0.5348s	
805/2700 (epoch 14.907), train_loss = 1.83207575, grad/param norm = 1.4575e-01, time/batch = 0.4967s	
806/2700 (epoch 14.926), train_loss = 1.76791991, grad/param norm = 1.4032e-01, time/batch = 0.4542s	
807/2700 (epoch 14.944), train_loss = 1.74937993, grad/param norm = 1.2695e-01, time/batch = 0.4722s	
808/2700 (epoch 14.963), train_loss = 1.76932373, grad/param norm = 1.1982e-01, time/batch = 0.4776s	
809/2700 (epoch 14.981), train_loss = 1.73754921, grad/param norm = 1.2348e-01, time/batch = 0.4687s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
810/2700 (epoch 15.000), train_loss = 1.76963280, grad/param norm = 1.1426e-01, time/batch = 0.5090s	
811/2700 (epoch 15.019), train_loss = 1.78983640, grad/param norm = 1.1517e-01, time/batch = 0.4948s	
812/2700 (epoch 15.037), train_loss = 1.77641393, grad/param norm = 1.0967e-01, time/batch = 0.5108s	
813/2700 (epoch 15.056), train_loss = 1.72893909, grad/param norm = 1.3370e-01, time/batch = 0.5291s	
814/2700 (epoch 15.074), train_loss = 1.68911455, grad/param norm = 1.1718e-01, time/batch = 0.5060s	
815/2700 (epoch 15.093), train_loss = 1.68198362, grad/param norm = 1.2098e-01, time/batch = 0.5146s	
816/2700 (epoch 15.111), train_loss = 1.67435858, grad/param norm = 1.5492e-01, time/batch = 0.4883s	
817/2700 (epoch 15.130), train_loss = 1.72201127, grad/param norm = 1.5956e-01, time/batch = 0.4663s	
818/2700 (epoch 15.148), train_loss = 1.67733286, grad/param norm = 1.6807e-01, time/batch = 0.4345s	
819/2700 (epoch 15.167), train_loss = 1.77934724, grad/param norm = 1.7577e-01, time/batch = 0.4648s	
820/2700 (epoch 15.185), train_loss = 1.68911179, grad/param norm = 1.5393e-01, time/batch = 0.4982s	
821/2700 (epoch 15.204), train_loss = 1.71009451, grad/param norm = 1.1334e-01, time/batch = 0.4786s	
822/2700 (epoch 15.222), train_loss = 1.64697799, grad/param norm = 1.0532e-01, time/batch = 0.4975s	
823/2700 (epoch 15.241), train_loss = 1.57883393, grad/param norm = 1.1020e-01, time/batch = 0.5161s	
824/2700 (epoch 15.259), train_loss = 1.64252086, grad/param norm = 1.1868e-01, time/batch = 0.5159s	
825/2700 (epoch 15.278), train_loss = 1.71824370, grad/param norm = 1.2202e-01, time/batch = 0.5170s	
826/2700 (epoch 15.296), train_loss = 1.70596701, grad/param norm = 1.2041e-01, time/batch = 0.4948s	
827/2700 (epoch 15.315), train_loss = 1.70953439, grad/param norm = 1.3625e-01, time/batch = 0.4143s	
828/2700 (epoch 15.333), train_loss = 1.70936334, grad/param norm = 1.4785e-01, time/batch = 0.4791s	
829/2700 (epoch 15.352), train_loss = 1.71696115, grad/param norm = 1.4575e-01, time/batch = 0.4846s	
830/2700 (epoch 15.370), train_loss = 1.74025109, grad/param norm = 1.4870e-01, time/batch = 0.4939s	
831/2700 (epoch 15.389), train_loss = 1.70445364, grad/param norm = 1.4543e-01, time/batch = 0.4775s	
832/2700 (epoch 15.407), train_loss = 1.74019403, grad/param norm = 1.2153e-01, time/batch = 0.4941s	
833/2700 (epoch 15.426), train_loss = 1.74461514, grad/param norm = 1.3185e-01, time/batch = 0.5146s	
834/2700 (epoch 15.444), train_loss = 1.65577577, grad/param norm = 1.3485e-01, time/batch = 0.5171s	
835/2700 (epoch 15.463), train_loss = 1.73210896, grad/param norm = 1.1622e-01, time/batch = 0.5236s	
836/2700 (epoch 15.481), train_loss = 1.70809769, grad/param norm = 1.1204e-01, time/batch = 0.4412s	
837/2700 (epoch 15.500), train_loss = 1.68011740, grad/param norm = 1.3501e-01, time/batch = 0.4729s	
838/2700 (epoch 15.519), train_loss = 1.71105283, grad/param norm = 1.3863e-01, time/batch = 0.4685s	
839/2700 (epoch 15.537), train_loss = 1.71194914, grad/param norm = 1.2414e-01, time/batch = 0.4761s	
840/2700 (epoch 15.556), train_loss = 1.64282923, grad/param norm = 1.1382e-01, time/batch = 0.5022s	
841/2700 (epoch 15.574), train_loss = 1.67736837, grad/param norm = 1.2098e-01, time/batch = 0.4772s	
842/2700 (epoch 15.593), train_loss = 1.67012494, grad/param norm = 1.1950e-01, time/batch = 0.5001s	
843/2700 (epoch 15.611), train_loss = 1.57694459, grad/param norm = 1.0601e-01, time/batch = 0.5093s	
844/2700 (epoch 15.630), train_loss = 1.62678334, grad/param norm = 1.2493e-01, time/batch = 0.5136s	
845/2700 (epoch 15.648), train_loss = 1.65899572, grad/param norm = 1.1942e-01, time/batch = 0.4849s	
846/2700 (epoch 15.667), train_loss = 1.65466407, grad/param norm = 1.2626e-01, time/batch = 0.5118s	
847/2700 (epoch 15.685), train_loss = 1.68872139, grad/param norm = 1.4463e-01, time/batch = 0.4949s	
848/2700 (epoch 15.704), train_loss = 1.69806300, grad/param norm = 1.4224e-01, time/batch = 0.4342s	
849/2700 (epoch 15.722), train_loss = 1.64882087, grad/param norm = 1.0765e-01, time/batch = 0.4634s	
850/2700 (epoch 15.741), train_loss = 1.66306232, grad/param norm = 1.1058e-01, time/batch = 0.4977s	
851/2700 (epoch 15.759), train_loss = 1.70671683, grad/param norm = 1.4545e-01, time/batch = 0.4788s	
852/2700 (epoch 15.778), train_loss = 1.74969637, grad/param norm = 1.6803e-01, time/batch = 0.4947s	
853/2700 (epoch 15.796), train_loss = 1.68603109, grad/param norm = 1.7941e-01, time/batch = 0.5100s	
854/2700 (epoch 15.815), train_loss = 1.72330428, grad/param norm = 1.5646e-01, time/batch = 0.4970s	
855/2700 (epoch 15.833), train_loss = 1.69886324, grad/param norm = 1.3584e-01, time/batch = 0.5279s	
856/2700 (epoch 15.852), train_loss = 1.65909394, grad/param norm = 1.2030e-01, time/batch = 0.4870s	
857/2700 (epoch 15.870), train_loss = 1.67426294, grad/param norm = 1.1375e-01, time/batch = 0.5024s	
858/2700 (epoch 15.889), train_loss = 1.66459869, grad/param norm = 1.1233e-01, time/batch = 0.4971s	
859/2700 (epoch 15.907), train_loss = 1.76904131, grad/param norm = 1.2102e-01, time/batch = 0.4060s	
860/2700 (epoch 15.926), train_loss = 1.71958612, grad/param norm = 1.2822e-01, time/batch = 0.4946s	
861/2700 (epoch 15.944), train_loss = 1.70388773, grad/param norm = 1.2811e-01, time/batch = 0.4790s	
862/2700 (epoch 15.963), train_loss = 1.72716152, grad/param norm = 1.2737e-01, time/batch = 0.4924s	
863/2700 (epoch 15.981), train_loss = 1.69069479, grad/param norm = 1.4544e-01, time/batch = 0.4919s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
864/2700 (epoch 16.000), train_loss = 1.73140416, grad/param norm = 1.4989e-01, time/batch = 0.5130s	
865/2700 (epoch 16.019), train_loss = 1.75896617, grad/param norm = 1.5280e-01, time/batch = 0.4813s	
866/2700 (epoch 16.037), train_loss = 1.73933294, grad/param norm = 1.4157e-01, time/batch = 0.5092s	
867/2700 (epoch 16.056), train_loss = 1.68272523, grad/param norm = 1.4867e-01, time/batch = 0.5003s	
868/2700 (epoch 16.074), train_loss = 1.64591345, grad/param norm = 1.1806e-01, time/batch = 0.4602s	
869/2700 (epoch 16.093), train_loss = 1.62579846, grad/param norm = 9.3376e-02, time/batch = 0.4795s	
870/2700 (epoch 16.111), train_loss = 1.60761806, grad/param norm = 1.0171e-01, time/batch = 0.4322s	
871/2700 (epoch 16.130), train_loss = 1.65992491, grad/param norm = 1.1543e-01, time/batch = 0.5090s	
872/2700 (epoch 16.148), train_loss = 1.61299001, grad/param norm = 1.2175e-01, time/batch = 0.4962s	
873/2700 (epoch 16.167), train_loss = 1.70761195, grad/param norm = 1.1094e-01, time/batch = 0.5127s	
874/2700 (epoch 16.185), train_loss = 1.62113207, grad/param norm = 9.6224e-02, time/batch = 0.4900s	
875/2700 (epoch 16.204), train_loss = 1.65275022, grad/param norm = 9.5010e-02, time/batch = 0.5247s	
876/2700 (epoch 16.222), train_loss = 1.60844294, grad/param norm = 1.1779e-01, time/batch = 0.5024s	
877/2700 (epoch 16.241), train_loss = 1.54437017, grad/param norm = 1.2609e-01, time/batch = 0.4988s	
878/2700 (epoch 16.259), train_loss = 1.59654768, grad/param norm = 1.3382e-01, time/batch = 0.5034s	
879/2700 (epoch 16.278), train_loss = 1.67044719, grad/param norm = 1.2259e-01, time/batch = 0.4685s	
880/2700 (epoch 16.296), train_loss = 1.65427569, grad/param norm = 1.3076e-01, time/batch = 0.4794s	
881/2700 (epoch 16.315), train_loss = 1.65417574, grad/param norm = 1.5623e-01, time/batch = 0.4347s	
882/2700 (epoch 16.333), train_loss = 1.64882908, grad/param norm = 1.4352e-01, time/batch = 0.5110s	
883/2700 (epoch 16.352), train_loss = 1.65272391, grad/param norm = 1.4036e-01, time/batch = 0.4959s	
884/2700 (epoch 16.370), train_loss = 1.67372946, grad/param norm = 1.4170e-01, time/batch = 0.5219s	
885/2700 (epoch 16.389), train_loss = 1.64483446, grad/param norm = 1.2490e-01, time/batch = 0.5154s	
886/2700 (epoch 16.407), train_loss = 1.68226207, grad/param norm = 9.6372e-02, time/batch = 0.4962s	
887/2700 (epoch 16.426), train_loss = 1.68956037, grad/param norm = 1.0629e-01, time/batch = 0.4795s	
888/2700 (epoch 16.444), train_loss = 1.61362827, grad/param norm = 1.3004e-01, time/batch = 0.4536s	
889/2700 (epoch 16.463), train_loss = 1.69484260, grad/param norm = 1.3102e-01, time/batch = 0.4599s	
890/2700 (epoch 16.481), train_loss = 1.66939221, grad/param norm = 1.2900e-01, time/batch = 0.4864s	
891/2700 (epoch 16.500), train_loss = 1.63663708, grad/param norm = 1.2043e-01, time/batch = 0.4761s	
892/2700 (epoch 16.519), train_loss = 1.66480511, grad/param norm = 1.1973e-01, time/batch = 0.4455s	
893/2700 (epoch 16.537), train_loss = 1.67515966, grad/param norm = 1.4492e-01, time/batch = 0.5057s	
894/2700 (epoch 16.556), train_loss = 1.60881859, grad/param norm = 1.6197e-01, time/batch = 0.5066s	
895/2700 (epoch 16.574), train_loss = 1.65097825, grad/param norm = 1.7161e-01, time/batch = 0.5117s	
896/2700 (epoch 16.593), train_loss = 1.65213207, grad/param norm = 1.8787e-01, time/batch = 0.5030s	
897/2700 (epoch 16.611), train_loss = 1.55535156, grad/param norm = 1.5826e-01, time/batch = 0.4675s	
898/2700 (epoch 16.630), train_loss = 1.58116081, grad/param norm = 1.2915e-01, time/batch = 0.5122s	
899/2700 (epoch 16.648), train_loss = 1.61096594, grad/param norm = 1.1673e-01, time/batch = 0.4597s	
900/2700 (epoch 16.667), train_loss = 1.60192893, grad/param norm = 1.1063e-01, time/batch = 0.4381s	
901/2700 (epoch 16.685), train_loss = 1.64181619, grad/param norm = 1.3003e-01, time/batch = 0.4878s	
902/2700 (epoch 16.704), train_loss = 1.65229379, grad/param norm = 1.3857e-01, time/batch = 0.4588s	
903/2700 (epoch 16.722), train_loss = 1.60860499, grad/param norm = 1.2069e-01, time/batch = 0.4233s	
904/2700 (epoch 16.741), train_loss = 1.61793452, grad/param norm = 1.1762e-01, time/batch = 0.5006s	
905/2700 (epoch 16.759), train_loss = 1.64059326, grad/param norm = 1.3248e-01, time/batch = 0.5129s	
906/2700 (epoch 16.778), train_loss = 1.69051134, grad/param norm = 1.3571e-01, time/batch = 0.4876s	
907/2700 (epoch 16.796), train_loss = 1.61894517, grad/param norm = 1.3508e-01, time/batch = 0.4687s	
908/2700 (epoch 16.815), train_loss = 1.65554141, grad/param norm = 1.1322e-01, time/batch = 0.4769s	
909/2700 (epoch 16.833), train_loss = 1.63024103, grad/param norm = 1.0352e-01, time/batch = 0.5065s	
910/2700 (epoch 16.852), train_loss = 1.59796787, grad/param norm = 1.0308e-01, time/batch = 0.4297s	
911/2700 (epoch 16.870), train_loss = 1.62473146, grad/param norm = 1.1399e-01, time/batch = 0.4793s	
912/2700 (epoch 16.889), train_loss = 1.62890448, grad/param norm = 1.3072e-01, time/batch = 0.4905s	
913/2700 (epoch 16.907), train_loss = 1.72638568, grad/param norm = 1.2883e-01, time/batch = 0.5085s	
914/2700 (epoch 16.926), train_loss = 1.67208987, grad/param norm = 1.2952e-01, time/batch = 0.4857s	
915/2700 (epoch 16.944), train_loss = 1.66056780, grad/param norm = 1.3877e-01, time/batch = 0.5177s	
916/2700 (epoch 16.963), train_loss = 1.67851530, grad/param norm = 1.2510e-01, time/batch = 0.5008s	
917/2700 (epoch 16.981), train_loss = 1.63852361, grad/param norm = 1.1827e-01, time/batch = 0.5048s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
918/2700 (epoch 17.000), train_loss = 1.66708915, grad/param norm = 1.0511e-01, time/batch = 0.4656s	
919/2700 (epoch 17.019), train_loss = 1.70101776, grad/param norm = 1.0943e-01, time/batch = 0.4580s	
920/2700 (epoch 17.037), train_loss = 1.67593590, grad/param norm = 1.1122e-01, time/batch = 0.4430s	
921/2700 (epoch 17.056), train_loss = 1.63747838, grad/param norm = 1.4545e-01, time/batch = 0.4801s	
922/2700 (epoch 17.074), train_loss = 1.60945494, grad/param norm = 1.3374e-01, time/batch = 0.5070s	
923/2700 (epoch 17.093), train_loss = 1.58689019, grad/param norm = 1.1854e-01, time/batch = 0.5081s	
924/2700 (epoch 17.111), train_loss = 1.57275156, grad/param norm = 1.2861e-01, time/batch = 0.5073s	
925/2700 (epoch 17.130), train_loss = 1.63304797, grad/param norm = 1.4374e-01, time/batch = 0.4957s	
926/2700 (epoch 17.148), train_loss = 1.56801945, grad/param norm = 1.2897e-01, time/batch = 0.4792s	
927/2700 (epoch 17.167), train_loss = 1.65469901, grad/param norm = 9.9522e-02, time/batch = 0.4871s	
928/2700 (epoch 17.185), train_loss = 1.57446241, grad/param norm = 9.5459e-02, time/batch = 0.5014s	
929/2700 (epoch 17.204), train_loss = 1.61816683, grad/param norm = 1.1581e-01, time/batch = 0.4534s	
930/2700 (epoch 17.222), train_loss = 1.56994042, grad/param norm = 1.2968e-01, time/batch = 0.5185s	
931/2700 (epoch 17.241), train_loss = 1.49994959, grad/param norm = 1.1884e-01, time/batch = 0.5076s	
932/2700 (epoch 17.259), train_loss = 1.55181545, grad/param norm = 1.2397e-01, time/batch = 0.5100s	
933/2700 (epoch 17.278), train_loss = 1.62726853, grad/param norm = 1.2380e-01, time/batch = 0.5093s	
934/2700 (epoch 17.296), train_loss = 1.61085307, grad/param norm = 1.1943e-01, time/batch = 0.5095s	
935/2700 (epoch 17.315), train_loss = 1.60520642, grad/param norm = 1.3061e-01, time/batch = 0.5080s	
936/2700 (epoch 17.333), train_loss = 1.60902398, grad/param norm = 1.6678e-01, time/batch = 0.5117s	
937/2700 (epoch 17.352), train_loss = 1.61801755, grad/param norm = 1.4809e-01, time/batch = 0.4785s	
938/2700 (epoch 17.370), train_loss = 1.62707139, grad/param norm = 1.4884e-01, time/batch = 0.4345s	
939/2700 (epoch 17.389), train_loss = 1.61158705, grad/param norm = 1.4612e-01, time/batch = 0.4792s	
940/2700 (epoch 17.407), train_loss = 1.66514049, grad/param norm = 1.3596e-01, time/batch = 0.4980s	
941/2700 (epoch 17.426), train_loss = 1.65975167, grad/param norm = 1.3700e-01, time/batch = 0.5030s	
942/2700 (epoch 17.444), train_loss = 1.55867423, grad/param norm = 1.2573e-01, time/batch = 0.5191s	
943/2700 (epoch 17.463), train_loss = 1.64092314, grad/param norm = 1.1948e-01, time/batch = 0.5065s	
944/2700 (epoch 17.481), train_loss = 1.62905961, grad/param norm = 1.2745e-01, time/batch = 0.5054s	
945/2700 (epoch 17.500), train_loss = 1.59959550, grad/param norm = 1.2137e-01, time/batch = 0.5056s	
946/2700 (epoch 17.519), train_loss = 1.61967409, grad/param norm = 1.1024e-01, time/batch = 0.5100s	
947/2700 (epoch 17.537), train_loss = 1.62003310, grad/param norm = 1.2595e-01, time/batch = 0.4900s	
948/2700 (epoch 17.556), train_loss = 1.55159709, grad/param norm = 1.2301e-01, time/batch = 0.4399s	
949/2700 (epoch 17.574), train_loss = 1.58598419, grad/param norm = 1.2339e-01, time/batch = 0.5032s	
950/2700 (epoch 17.593), train_loss = 1.58538344, grad/param norm = 1.2376e-01, time/batch = 0.4882s	
951/2700 (epoch 17.611), train_loss = 1.48586362, grad/param norm = 9.6814e-02, time/batch = 0.4863s	
952/2700 (epoch 17.630), train_loss = 1.52367500, grad/param norm = 1.0303e-01, time/batch = 0.5187s	
953/2700 (epoch 17.648), train_loss = 1.56073400, grad/param norm = 1.1227e-01, time/batch = 0.5076s	
954/2700 (epoch 17.667), train_loss = 1.55787084, grad/param norm = 1.1294e-01, time/batch = 0.5041s	
955/2700 (epoch 17.685), train_loss = 1.60140240, grad/param norm = 1.2889e-01, time/batch = 0.5061s	
956/2700 (epoch 17.704), train_loss = 1.60548859, grad/param norm = 1.2913e-01, time/batch = 0.4959s	
957/2700 (epoch 17.722), train_loss = 1.56030790, grad/param norm = 1.0531e-01, time/batch = 0.5106s	
958/2700 (epoch 17.741), train_loss = 1.56644440, grad/param norm = 1.0590e-01, time/batch = 0.4810s	
959/2700 (epoch 17.759), train_loss = 1.58030271, grad/param norm = 1.0337e-01, time/batch = 0.4356s	
960/2700 (epoch 17.778), train_loss = 1.62279545, grad/param norm = 9.3984e-02, time/batch = 0.4946s	
961/2700 (epoch 17.796), train_loss = 1.55308154, grad/param norm = 1.0198e-01, time/batch = 0.4656s	
962/2700 (epoch 17.815), train_loss = 1.60290833, grad/param norm = 1.3174e-01, time/batch = 0.5160s	
963/2700 (epoch 17.833), train_loss = 1.59442051, grad/param norm = 1.3860e-01, time/batch = 0.5145s	
964/2700 (epoch 17.852), train_loss = 1.55804219, grad/param norm = 1.2899e-01, time/batch = 0.5090s	
965/2700 (epoch 17.870), train_loss = 1.58727889, grad/param norm = 1.2617e-01, time/batch = 0.4900s	
966/2700 (epoch 17.889), train_loss = 1.59529914, grad/param norm = 1.5809e-01, time/batch = 0.5128s	
967/2700 (epoch 17.907), train_loss = 1.71365139, grad/param norm = 1.9601e-01, time/batch = 0.5025s	
968/2700 (epoch 17.926), train_loss = 1.66620285, grad/param norm = 2.2212e-01, time/batch = 0.4941s	
969/2700 (epoch 17.944), train_loss = 1.64473385, grad/param norm = 1.6704e-01, time/batch = 0.4750s	
970/2700 (epoch 17.963), train_loss = 1.63395902, grad/param norm = 1.3489e-01, time/batch = 0.4411s	
971/2700 (epoch 17.981), train_loss = 1.59725493, grad/param norm = 1.3137e-01, time/batch = 0.5273s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
972/2700 (epoch 18.000), train_loss = 1.63421020, grad/param norm = 1.2218e-01, time/batch = 0.5023s	
973/2700 (epoch 18.019), train_loss = 1.66867622, grad/param norm = 1.2390e-01, time/batch = 0.5159s	
974/2700 (epoch 18.037), train_loss = 1.62653008, grad/param norm = 1.0843e-01, time/batch = 0.4992s	
975/2700 (epoch 18.056), train_loss = 1.58688991, grad/param norm = 1.2114e-01, time/batch = 0.5067s	
976/2700 (epoch 18.074), train_loss = 1.56382969, grad/param norm = 1.1444e-01, time/batch = 0.5028s	
977/2700 (epoch 18.093), train_loss = 1.54405025, grad/param norm = 1.1744e-01, time/batch = 0.5070s	
978/2700 (epoch 18.111), train_loss = 1.53161466, grad/param norm = 1.2256e-01, time/batch = 0.5040s	
979/2700 (epoch 18.130), train_loss = 1.58173362, grad/param norm = 1.1766e-01, time/batch = 0.4829s	
980/2700 (epoch 18.148), train_loss = 1.51457441, grad/param norm = 1.0672e-01, time/batch = 0.4802s	
981/2700 (epoch 18.167), train_loss = 1.61363166, grad/param norm = 1.1781e-01, time/batch = 0.4118s	
982/2700 (epoch 18.185), train_loss = 1.54458691, grad/param norm = 1.3103e-01, time/batch = 0.5077s	
983/2700 (epoch 18.204), train_loss = 1.58263857, grad/param norm = 1.3120e-01, time/batch = 0.5221s	
984/2700 (epoch 18.222), train_loss = 1.52730831, grad/param norm = 1.2969e-01, time/batch = 0.4709s	
985/2700 (epoch 18.241), train_loss = 1.46643444, grad/param norm = 1.3518e-01, time/batch = 0.5065s	
986/2700 (epoch 18.259), train_loss = 1.52575395, grad/param norm = 1.4243e-01, time/batch = 0.5214s	
987/2700 (epoch 18.278), train_loss = 1.59025769, grad/param norm = 1.3652e-01, time/batch = 0.4989s	
988/2700 (epoch 18.296), train_loss = 1.56492337, grad/param norm = 1.1852e-01, time/batch = 0.4844s	
989/2700 (epoch 18.315), train_loss = 1.55441633, grad/param norm = 1.2278e-01, time/batch = 0.4797s	
990/2700 (epoch 18.333), train_loss = 1.54873362, grad/param norm = 1.3191e-01, time/batch = 0.4776s	
991/2700 (epoch 18.352), train_loss = 1.55719385, grad/param norm = 1.2244e-01, time/batch = 0.4661s	
992/2700 (epoch 18.370), train_loss = 1.57369462, grad/param norm = 1.3593e-01, time/batch = 0.4438s	
993/2700 (epoch 18.389), train_loss = 1.55947333, grad/param norm = 1.2387e-01, time/batch = 0.4727s	
994/2700 (epoch 18.407), train_loss = 1.60347845, grad/param norm = 1.1163e-01, time/batch = 0.5050s	
995/2700 (epoch 18.426), train_loss = 1.59561264, grad/param norm = 1.0789e-01, time/batch = 0.4821s	
996/2700 (epoch 18.444), train_loss = 1.50102067, grad/param norm = 9.6756e-02, time/batch = 0.4797s	
997/2700 (epoch 18.463), train_loss = 1.59410525, grad/param norm = 1.0775e-01, time/batch = 0.4747s	
998/2700 (epoch 18.481), train_loss = 1.58447636, grad/param norm = 1.3172e-01, time/batch = 0.4902s	
999/2700 (epoch 18.500), train_loss = 1.55608432, grad/param norm = 1.2830e-01, time/batch = 0.5031s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch18.52_1.7663.t7	
1000/2700 (epoch 18.519), train_loss = 1.57983135, grad/param norm = 1.1625e-01, time/batch = 0.5086s	
1001/2700 (epoch 18.537), train_loss = 1.71262932, grad/param norm = 1.3744e-01, time/batch = 0.4786s	
1002/2700 (epoch 18.556), train_loss = 1.52005282, grad/param norm = 1.3064e-01, time/batch = 0.5165s	
1003/2700 (epoch 18.574), train_loss = 1.54855270, grad/param norm = 1.3822e-01, time/batch = 0.5122s	
1004/2700 (epoch 18.593), train_loss = 1.55892987, grad/param norm = 1.3842e-01, time/batch = 0.5066s	
1005/2700 (epoch 18.611), train_loss = 1.45670423, grad/param norm = 1.1145e-01, time/batch = 0.5036s	
1006/2700 (epoch 18.630), train_loss = 1.48659096, grad/param norm = 1.1418e-01, time/batch = 0.4811s	
1007/2700 (epoch 18.648), train_loss = 1.51976235, grad/param norm = 1.2075e-01, time/batch = 0.4761s	
1008/2700 (epoch 18.667), train_loss = 1.51566319, grad/param norm = 1.2031e-01, time/batch = 0.4837s	
1009/2700 (epoch 18.685), train_loss = 1.55251373, grad/param norm = 1.3420e-01, time/batch = 0.4508s	
1010/2700 (epoch 18.704), train_loss = 1.56310240, grad/param norm = 1.3230e-01, time/batch = 0.5063s	
1011/2700 (epoch 18.722), train_loss = 1.52290393, grad/param norm = 1.0700e-01, time/batch = 0.5143s	
1012/2700 (epoch 18.741), train_loss = 1.52628528, grad/param norm = 1.2603e-01, time/batch = 0.5095s	
1013/2700 (epoch 18.759), train_loss = 1.54985672, grad/param norm = 1.3750e-01, time/batch = 0.5092s	
1014/2700 (epoch 18.778), train_loss = 1.60086368, grad/param norm = 1.5062e-01, time/batch = 0.5082s	
1015/2700 (epoch 18.796), train_loss = 1.53160599, grad/param norm = 1.5024e-01, time/batch = 0.5014s	
1016/2700 (epoch 18.815), train_loss = 1.57024944, grad/param norm = 1.4559e-01, time/batch = 0.4824s	
1017/2700 (epoch 18.833), train_loss = 1.54383698, grad/param norm = 1.1257e-01, time/batch = 0.4751s	
1018/2700 (epoch 18.852), train_loss = 1.51943482, grad/param norm = 1.3276e-01, time/batch = 0.4736s	
1019/2700 (epoch 18.870), train_loss = 1.55611832, grad/param norm = 1.4680e-01, time/batch = 0.4916s	
1020/2700 (epoch 18.889), train_loss = 1.54622165, grad/param norm = 1.3920e-01, time/batch = 0.5050s	
1021/2700 (epoch 18.907), train_loss = 1.64584878, grad/param norm = 1.3906e-01, time/batch = 0.5173s	
1022/2700 (epoch 18.926), train_loss = 1.60161276, grad/param norm = 1.5696e-01, time/batch = 0.5205s	
1023/2700 (epoch 18.944), train_loss = 1.58416843, grad/param norm = 1.5431e-01, time/batch = 0.4928s	
1024/2700 (epoch 18.963), train_loss = 1.60454226, grad/param norm = 1.4010e-01, time/batch = 0.5051s	
1025/2700 (epoch 18.981), train_loss = 1.55840844, grad/param norm = 1.3597e-01, time/batch = 0.5001s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1026/2700 (epoch 19.000), train_loss = 1.59253118, grad/param norm = 1.3234e-01, time/batch = 0.4828s	
1027/2700 (epoch 19.019), train_loss = 1.62585332, grad/param norm = 1.2531e-01, time/batch = 0.4568s	
1028/2700 (epoch 19.037), train_loss = 1.58472427, grad/param norm = 1.1663e-01, time/batch = 0.4743s	
1029/2700 (epoch 19.056), train_loss = 1.54303780, grad/param norm = 1.3257e-01, time/batch = 0.4744s	
1030/2700 (epoch 19.074), train_loss = 1.51867518, grad/param norm = 1.0698e-01, time/batch = 0.5086s	
1031/2700 (epoch 19.093), train_loss = 1.49439148, grad/param norm = 9.4259e-02, time/batch = 0.4995s	
1032/2700 (epoch 19.111), train_loss = 1.47602431, grad/param norm = 1.0149e-01, time/batch = 0.5190s	
1033/2700 (epoch 19.130), train_loss = 1.53233712, grad/param norm = 1.0441e-01, time/batch = 0.5056s	
1034/2700 (epoch 19.148), train_loss = 1.47911955, grad/param norm = 1.2336e-01, time/batch = 0.4928s	
1035/2700 (epoch 19.167), train_loss = 1.57876774, grad/param norm = 1.4829e-01, time/batch = 0.4951s	
1036/2700 (epoch 19.185), train_loss = 1.50691067, grad/param norm = 1.3151e-01, time/batch = 0.4707s	
1037/2700 (epoch 19.204), train_loss = 1.53318881, grad/param norm = 1.2068e-01, time/batch = 0.4790s	
1038/2700 (epoch 19.222), train_loss = 1.49264410, grad/param norm = 1.3519e-01, time/batch = 0.4631s	
1039/2700 (epoch 19.241), train_loss = 1.43060088, grad/param norm = 1.3314e-01, time/batch = 0.4958s	
1040/2700 (epoch 19.259), train_loss = 1.46968248, grad/param norm = 1.2158e-01, time/batch = 0.5141s	
1041/2700 (epoch 19.278), train_loss = 1.53016534, grad/param norm = 1.0317e-01, time/batch = 0.5268s	
1042/2700 (epoch 19.296), train_loss = 1.51970433, grad/param norm = 1.0932e-01, time/batch = 0.5099s	
1043/2700 (epoch 19.315), train_loss = 1.50217179, grad/param norm = 1.1095e-01, time/batch = 0.5057s	
1044/2700 (epoch 19.333), train_loss = 1.49396798, grad/param norm = 1.1082e-01, time/batch = 0.5016s	
1045/2700 (epoch 19.352), train_loss = 1.51114728, grad/param norm = 1.3662e-01, time/batch = 0.4952s	
1046/2700 (epoch 19.370), train_loss = 1.52845400, grad/param norm = 1.4102e-01, time/batch = 0.4325s	
1047/2700 (epoch 19.389), train_loss = 1.52235824, grad/param norm = 1.4566e-01, time/batch = 0.4757s	
1048/2700 (epoch 19.407), train_loss = 1.58114758, grad/param norm = 1.5750e-01, time/batch = 0.5043s	
1049/2700 (epoch 19.426), train_loss = 1.57628483, grad/param norm = 1.4619e-01, time/batch = 0.5089s	
1050/2700 (epoch 19.444), train_loss = 1.47842698, grad/param norm = 1.2808e-01, time/batch = 0.5212s	
1051/2700 (epoch 19.463), train_loss = 1.56248089, grad/param norm = 1.1909e-01, time/batch = 0.5137s	
1052/2700 (epoch 19.481), train_loss = 1.52739448, grad/param norm = 1.1665e-01, time/batch = 0.5027s	
1053/2700 (epoch 19.500), train_loss = 1.49399558, grad/param norm = 1.1167e-01, time/batch = 0.4991s	
1054/2700 (epoch 19.519), train_loss = 1.53308488, grad/param norm = 1.1269e-01, time/batch = 0.4872s	
1055/2700 (epoch 19.537), train_loss = 1.53844574, grad/param norm = 1.1531e-01, time/batch = 0.4685s	
1056/2700 (epoch 19.556), train_loss = 1.45990663, grad/param norm = 1.1391e-01, time/batch = 0.4730s	
1057/2700 (epoch 19.574), train_loss = 1.48999561, grad/param norm = 1.1313e-01, time/batch = 0.4589s	
1058/2700 (epoch 19.593), train_loss = 1.50352657, grad/param norm = 1.1149e-01, time/batch = 0.5114s	
1059/2700 (epoch 19.611), train_loss = 1.41927824, grad/param norm = 1.1260e-01, time/batch = 0.5077s	
1060/2700 (epoch 19.630), train_loss = 1.46803384, grad/param norm = 1.6226e-01, time/batch = 0.5168s	
1061/2700 (epoch 19.648), train_loss = 1.50382915, grad/param norm = 1.4567e-01, time/batch = 0.5164s	
1062/2700 (epoch 19.667), train_loss = 1.47995363, grad/param norm = 1.1360e-01, time/batch = 0.5001s	
1063/2700 (epoch 19.685), train_loss = 1.51583916, grad/param norm = 1.1972e-01, time/batch = 0.4808s	
1064/2700 (epoch 19.704), train_loss = 1.52688981, grad/param norm = 1.3158e-01, time/batch = 0.3970s	
1065/2700 (epoch 19.722), train_loss = 1.48715004, grad/param norm = 1.1807e-01, time/batch = 0.4685s	
1066/2700 (epoch 19.741), train_loss = 1.48629238, grad/param norm = 1.3434e-01, time/batch = 0.4777s	
1067/2700 (epoch 19.759), train_loss = 1.50830789, grad/param norm = 1.5436e-01, time/batch = 0.5124s	
1068/2700 (epoch 19.778), train_loss = 1.55358916, grad/param norm = 1.3208e-01, time/batch = 0.4965s	
1069/2700 (epoch 19.796), train_loss = 1.47252101, grad/param norm = 1.1404e-01, time/batch = 0.5051s	
1070/2700 (epoch 19.815), train_loss = 1.51018769, grad/param norm = 1.1606e-01, time/batch = 0.5075s	
1071/2700 (epoch 19.833), train_loss = 1.51524110, grad/param norm = 1.5991e-01, time/batch = 0.5250s	
1072/2700 (epoch 19.852), train_loss = 1.50583886, grad/param norm = 1.9959e-01, time/batch = 0.5094s	
1073/2700 (epoch 19.870), train_loss = 1.53313145, grad/param norm = 1.7757e-01, time/batch = 0.4191s	
1074/2700 (epoch 19.889), train_loss = 1.50028252, grad/param norm = 1.2622e-01, time/batch = 0.4768s	
1075/2700 (epoch 19.907), train_loss = 1.59395014, grad/param norm = 1.2553e-01, time/batch = 0.4843s	
1076/2700 (epoch 19.926), train_loss = 1.55595423, grad/param norm = 1.3338e-01, time/batch = 0.4821s	
1077/2700 (epoch 19.944), train_loss = 1.53518013, grad/param norm = 1.3911e-01, time/batch = 0.5113s	
1078/2700 (epoch 19.963), train_loss = 1.54766456, grad/param norm = 1.2233e-01, time/batch = 0.5101s	
1079/2700 (epoch 19.981), train_loss = 1.50498634, grad/param norm = 1.1431e-01, time/batch = 0.4946s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1080/2700 (epoch 20.000), train_loss = 1.53934694, grad/param norm = 1.1425e-01, time/batch = 0.5110s	
1081/2700 (epoch 20.019), train_loss = 1.58556932, grad/param norm = 1.2066e-01, time/batch = 0.5195s	
1082/2700 (epoch 20.037), train_loss = 1.53834450, grad/param norm = 1.1906e-01, time/batch = 0.4408s	
1083/2700 (epoch 20.056), train_loss = 1.49728521, grad/param norm = 1.1971e-01, time/batch = 0.4904s	
1084/2700 (epoch 20.074), train_loss = 1.47250894, grad/param norm = 9.7642e-02, time/batch = 0.4884s	
1085/2700 (epoch 20.093), train_loss = 1.45514289, grad/param norm = 9.9509e-02, time/batch = 0.4727s	
1086/2700 (epoch 20.111), train_loss = 1.43470877, grad/param norm = 1.0991e-01, time/batch = 0.5011s	
1087/2700 (epoch 20.130), train_loss = 1.49504122, grad/param norm = 1.1592e-01, time/batch = 0.5061s	
1088/2700 (epoch 20.148), train_loss = 1.44250241, grad/param norm = 1.2294e-01, time/batch = 0.5110s	
1089/2700 (epoch 20.167), train_loss = 1.52516204, grad/param norm = 1.1387e-01, time/batch = 0.5082s	
1090/2700 (epoch 20.185), train_loss = 1.45173096, grad/param norm = 1.0189e-01, time/batch = 0.4940s	
1091/2700 (epoch 20.204), train_loss = 1.48526148, grad/param norm = 1.0531e-01, time/batch = 0.4624s	
1092/2700 (epoch 20.222), train_loss = 1.44746102, grad/param norm = 1.2409e-01, time/batch = 0.4878s	
1093/2700 (epoch 20.241), train_loss = 1.38484646, grad/param norm = 1.1229e-01, time/batch = 0.4771s	
1094/2700 (epoch 20.259), train_loss = 1.43391652, grad/param norm = 1.4555e-01, time/batch = 0.4726s	
1095/2700 (epoch 20.278), train_loss = 1.51338351, grad/param norm = 1.4313e-01, time/batch = 0.5036s	
1096/2700 (epoch 20.296), train_loss = 1.49014437, grad/param norm = 1.3547e-01, time/batch = 0.5204s	
1097/2700 (epoch 20.315), train_loss = 1.47432586, grad/param norm = 1.3250e-01, time/batch = 0.5074s	
1098/2700 (epoch 20.333), train_loss = 1.46223722, grad/param norm = 1.4720e-01, time/batch = 0.5031s	
1099/2700 (epoch 20.352), train_loss = 1.47995886, grad/param norm = 1.4119e-01, time/batch = 0.5068s	
1100/2700 (epoch 20.370), train_loss = 1.47839440, grad/param norm = 1.4244e-01, time/batch = 0.4956s	
1101/2700 (epoch 20.389), train_loss = 1.46942629, grad/param norm = 1.3247e-01, time/batch = 0.5077s	
1102/2700 (epoch 20.407), train_loss = 1.52935208, grad/param norm = 1.2244e-01, time/batch = 0.4795s	
1103/2700 (epoch 20.426), train_loss = 1.52498648, grad/param norm = 1.3051e-01, time/batch = 0.4568s	
1104/2700 (epoch 20.444), train_loss = 1.43053104, grad/param norm = 1.3540e-01, time/batch = 0.4651s	
1105/2700 (epoch 20.463), train_loss = 1.52705927, grad/param norm = 1.4313e-01, time/batch = 0.4873s	
1106/2700 (epoch 20.481), train_loss = 1.49297208, grad/param norm = 1.3617e-01, time/batch = 0.5216s	
1107/2700 (epoch 20.500), train_loss = 1.45721963, grad/param norm = 1.2527e-01, time/batch = 0.5082s	
1108/2700 (epoch 20.519), train_loss = 1.50222966, grad/param norm = 1.3004e-01, time/batch = 0.5060s	
1109/2700 (epoch 20.537), train_loss = 1.50287787, grad/param norm = 1.2589e-01, time/batch = 0.4958s	
1110/2700 (epoch 20.556), train_loss = 1.42574099, grad/param norm = 1.2687e-01, time/batch = 0.5110s	
1111/2700 (epoch 20.574), train_loss = 1.45477196, grad/param norm = 1.2593e-01, time/batch = 0.4908s	
1112/2700 (epoch 20.593), train_loss = 1.46831652, grad/param norm = 1.3986e-01, time/batch = 0.5178s	
1113/2700 (epoch 20.611), train_loss = 1.38592186, grad/param norm = 1.2847e-01, time/batch = 0.4128s	
1114/2700 (epoch 20.630), train_loss = 1.41427807, grad/param norm = 1.2660e-01, time/batch = 0.4085s	
1115/2700 (epoch 20.648), train_loss = 1.44463138, grad/param norm = 1.2203e-01, time/batch = 0.3707s	
1116/2700 (epoch 20.667), train_loss = 1.43804445, grad/param norm = 1.1366e-01, time/batch = 0.5158s	
1117/2700 (epoch 20.685), train_loss = 1.48087259, grad/param norm = 1.3244e-01, time/batch = 0.5080s	
1118/2700 (epoch 20.704), train_loss = 1.48613849, grad/param norm = 1.3988e-01, time/batch = 0.5038s	
1119/2700 (epoch 20.722), train_loss = 1.44723321, grad/param norm = 1.3664e-01, time/batch = 0.4208s	
1120/2700 (epoch 20.741), train_loss = 1.44701689, grad/param norm = 1.4470e-01, time/batch = 0.4687s	
1121/2700 (epoch 20.759), train_loss = 1.45869875, grad/param norm = 1.3109e-01, time/batch = 0.4787s	
1122/2700 (epoch 20.778), train_loss = 1.51603037, grad/param norm = 1.3097e-01, time/batch = 0.4806s	
1123/2700 (epoch 20.796), train_loss = 1.44150358, grad/param norm = 1.3832e-01, time/batch = 0.4919s	
1124/2700 (epoch 20.815), train_loss = 1.48589027, grad/param norm = 1.2797e-01, time/batch = 0.5140s	
1125/2700 (epoch 20.833), train_loss = 1.46195525, grad/param norm = 1.2790e-01, time/batch = 0.5132s	
1126/2700 (epoch 20.852), train_loss = 1.44039457, grad/param norm = 1.3086e-01, time/batch = 0.5113s	
1127/2700 (epoch 20.870), train_loss = 1.46609538, grad/param norm = 1.2546e-01, time/batch = 0.5165s	
1128/2700 (epoch 20.889), train_loss = 1.45399319, grad/param norm = 1.2347e-01, time/batch = 0.4141s	
1129/2700 (epoch 20.907), train_loss = 1.54536204, grad/param norm = 1.3628e-01, time/batch = 0.4617s	
1130/2700 (epoch 20.926), train_loss = 1.50666646, grad/param norm = 1.4272e-01, time/batch = 0.4767s	
1131/2700 (epoch 20.944), train_loss = 1.48534449, grad/param norm = 1.4720e-01, time/batch = 0.4820s	
1132/2700 (epoch 20.963), train_loss = 1.50176108, grad/param norm = 1.4141e-01, time/batch = 0.4749s	
1133/2700 (epoch 20.981), train_loss = 1.47303222, grad/param norm = 1.3151e-01, time/batch = 0.5250s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1134/2700 (epoch 21.000), train_loss = 1.50111934, grad/param norm = 1.1656e-01, time/batch = 0.5261s	
1135/2700 (epoch 21.019), train_loss = 1.55104459, grad/param norm = 1.2262e-01, time/batch = 0.5136s	
1136/2700 (epoch 21.037), train_loss = 1.49700583, grad/param norm = 1.1811e-01, time/batch = 0.5172s	
1137/2700 (epoch 21.056), train_loss = 1.45815512, grad/param norm = 1.2191e-01, time/batch = 0.4322s	
1138/2700 (epoch 21.074), train_loss = 1.44012329, grad/param norm = 1.1204e-01, time/batch = 0.4633s	
1139/2700 (epoch 21.093), train_loss = 1.41841365, grad/param norm = 1.0894e-01, time/batch = 0.4704s	
1140/2700 (epoch 21.111), train_loss = 1.39383583, grad/param norm = 9.9797e-02, time/batch = 0.4936s	
1141/2700 (epoch 21.130), train_loss = 1.45504970, grad/param norm = 1.1313e-01, time/batch = 0.4779s	
1142/2700 (epoch 21.148), train_loss = 1.40369515, grad/param norm = 1.1758e-01, time/batch = 0.4797s	
1143/2700 (epoch 21.167), train_loss = 1.48398041, grad/param norm = 1.2399e-01, time/batch = 0.5113s	
1144/2700 (epoch 21.185), train_loss = 1.41632165, grad/param norm = 1.2085e-01, time/batch = 0.5166s	
1145/2700 (epoch 21.204), train_loss = 1.46112963, grad/param norm = 1.5837e-01, time/batch = 0.5209s	
1146/2700 (epoch 21.222), train_loss = 1.42956601, grad/param norm = 1.7168e-01, time/batch = 0.4635s	
1147/2700 (epoch 21.241), train_loss = 1.36168272, grad/param norm = 1.4074e-01, time/batch = 0.5046s	
1148/2700 (epoch 21.259), train_loss = 1.38877751, grad/param norm = 1.2947e-01, time/batch = 0.4958s	
1149/2700 (epoch 21.278), train_loss = 1.45828993, grad/param norm = 1.3122e-01, time/batch = 0.4130s	
1150/2700 (epoch 21.296), train_loss = 1.44017073, grad/param norm = 1.2225e-01, time/batch = 0.5017s	
1151/2700 (epoch 21.315), train_loss = 1.42329723, grad/param norm = 1.3364e-01, time/batch = 0.4794s	
1152/2700 (epoch 21.333), train_loss = 1.42356894, grad/param norm = 1.3945e-01, time/batch = 0.5053s	
1153/2700 (epoch 21.352), train_loss = 1.43453374, grad/param norm = 1.4631e-01, time/batch = 0.5413s	
1154/2700 (epoch 21.370), train_loss = 1.44589334, grad/param norm = 1.3813e-01, time/batch = 0.5207s	
1155/2700 (epoch 21.389), train_loss = 1.43652109, grad/param norm = 1.4319e-01, time/batch = 0.4660s	
1156/2700 (epoch 21.407), train_loss = 1.50151200, grad/param norm = 1.4891e-01, time/batch = 0.5025s	
1157/2700 (epoch 21.426), train_loss = 1.49138328, grad/param norm = 1.4361e-01, time/batch = 0.4914s	
1158/2700 (epoch 21.444), train_loss = 1.38885933, grad/param norm = 1.0803e-01, time/batch = 0.4758s	
1159/2700 (epoch 21.463), train_loss = 1.47292824, grad/param norm = 1.1089e-01, time/batch = 0.4870s	
1160/2700 (epoch 21.481), train_loss = 1.43659109, grad/param norm = 1.1175e-01, time/batch = 0.4431s	
1161/2700 (epoch 21.500), train_loss = 1.41889107, grad/param norm = 1.3442e-01, time/batch = 0.4912s	
1162/2700 (epoch 21.519), train_loss = 1.45924716, grad/param norm = 1.4458e-01, time/batch = 0.5110s	
1163/2700 (epoch 21.537), train_loss = 1.47436900, grad/param norm = 1.5704e-01, time/batch = 0.5166s	
1164/2700 (epoch 21.556), train_loss = 1.39099682, grad/param norm = 1.5366e-01, time/batch = 0.4768s	
1165/2700 (epoch 21.574), train_loss = 1.41823835, grad/param norm = 1.4387e-01, time/batch = 0.5138s	
1166/2700 (epoch 21.593), train_loss = 1.43592656, grad/param norm = 1.4560e-01, time/batch = 0.5078s	
1167/2700 (epoch 21.611), train_loss = 1.33926381, grad/param norm = 1.1642e-01, time/batch = 0.4809s	
1168/2700 (epoch 21.630), train_loss = 1.35887598, grad/param norm = 1.0534e-01, time/batch = 0.4655s	
1169/2700 (epoch 21.648), train_loss = 1.40295929, grad/param norm = 1.1665e-01, time/batch = 0.4763s	
1170/2700 (epoch 21.667), train_loss = 1.40090829, grad/param norm = 1.2087e-01, time/batch = 0.4799s	
1171/2700 (epoch 21.685), train_loss = 1.43999946, grad/param norm = 1.3467e-01, time/batch = 0.4507s	
1172/2700 (epoch 21.704), train_loss = 1.44018812, grad/param norm = 1.2109e-01, time/batch = 0.5240s	
1173/2700 (epoch 21.722), train_loss = 1.39805328, grad/param norm = 1.1041e-01, time/batch = 0.4888s	
1174/2700 (epoch 21.741), train_loss = 1.39415815, grad/param norm = 1.1916e-01, time/batch = 0.5174s	
1175/2700 (epoch 21.759), train_loss = 1.42283305, grad/param norm = 1.6912e-01, time/batch = 0.4952s	
1176/2700 (epoch 21.778), train_loss = 1.49531011, grad/param norm = 2.0402e-01, time/batch = 0.4971s	
1177/2700 (epoch 21.796), train_loss = 1.41119334, grad/param norm = 1.6462e-01, time/batch = 0.4698s	
1178/2700 (epoch 21.815), train_loss = 1.44030116, grad/param norm = 1.3845e-01, time/batch = 0.4558s	
1179/2700 (epoch 21.833), train_loss = 1.41515455, grad/param norm = 1.0735e-01, time/batch = 0.4903s	
1180/2700 (epoch 21.852), train_loss = 1.38817481, grad/param norm = 1.2800e-01, time/batch = 0.4854s	
1181/2700 (epoch 21.870), train_loss = 1.41822809, grad/param norm = 1.1184e-01, time/batch = 0.4800s	
1182/2700 (epoch 21.889), train_loss = 1.41036831, grad/param norm = 1.2245e-01, time/batch = 0.4396s	
1183/2700 (epoch 21.907), train_loss = 1.51709566, grad/param norm = 1.5410e-01, time/batch = 0.5115s	
1184/2700 (epoch 21.926), train_loss = 1.47212449, grad/param norm = 1.5069e-01, time/batch = 0.4823s	
1185/2700 (epoch 21.944), train_loss = 1.44050483, grad/param norm = 1.2340e-01, time/batch = 0.5067s	
1186/2700 (epoch 21.963), train_loss = 1.45033857, grad/param norm = 1.2441e-01, time/batch = 0.4771s	
1187/2700 (epoch 21.981), train_loss = 1.42983759, grad/param norm = 1.4007e-01, time/batch = 0.4714s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1188/2700 (epoch 22.000), train_loss = 1.47774431, grad/param norm = 1.6560e-01, time/batch = 0.4640s	
1189/2700 (epoch 22.019), train_loss = 1.52397165, grad/param norm = 1.5041e-01, time/batch = 0.4816s	
1190/2700 (epoch 22.037), train_loss = 1.45278657, grad/param norm = 1.1982e-01, time/batch = 0.5197s	
1191/2700 (epoch 22.056), train_loss = 1.42577616, grad/param norm = 1.4096e-01, time/batch = 0.4759s	
1192/2700 (epoch 22.074), train_loss = 1.41308095, grad/param norm = 1.2957e-01, time/batch = 0.5074s	
1193/2700 (epoch 22.093), train_loss = 1.37788829, grad/param norm = 1.0256e-01, time/batch = 0.4816s	
1194/2700 (epoch 22.111), train_loss = 1.35729600, grad/param norm = 1.0429e-01, time/batch = 0.5107s	
1195/2700 (epoch 22.130), train_loss = 1.41267351, grad/param norm = 1.2089e-01, time/batch = 0.4882s	
1196/2700 (epoch 22.148), train_loss = 1.36171818, grad/param norm = 1.1220e-01, time/batch = 0.4741s	
1197/2700 (epoch 22.167), train_loss = 1.44587552, grad/param norm = 1.3631e-01, time/batch = 0.4683s	
1198/2700 (epoch 22.185), train_loss = 1.38975760, grad/param norm = 1.5399e-01, time/batch = 0.4700s	
1199/2700 (epoch 22.204), train_loss = 1.42536016, grad/param norm = 1.4997e-01, time/batch = 0.4960s	
1200/2700 (epoch 22.222), train_loss = 1.36830255, grad/param norm = 1.2465e-01, time/batch = 0.5207s	
1201/2700 (epoch 22.241), train_loss = 1.31122604, grad/param norm = 1.1596e-01, time/batch = 0.4839s	
1202/2700 (epoch 22.259), train_loss = 1.34730724, grad/param norm = 1.3549e-01, time/batch = 0.4848s	
1203/2700 (epoch 22.278), train_loss = 1.42922715, grad/param norm = 1.3122e-01, time/batch = 0.5118s	
1204/2700 (epoch 22.296), train_loss = 1.40122677, grad/param norm = 1.3418e-01, time/batch = 0.4970s	
1205/2700 (epoch 22.315), train_loss = 1.37999194, grad/param norm = 1.2161e-01, time/batch = 0.5047s	
1206/2700 (epoch 22.333), train_loss = 1.36980772, grad/param norm = 1.2903e-01, time/batch = 0.4819s	
1207/2700 (epoch 22.352), train_loss = 1.37663293, grad/param norm = 1.1941e-01, time/batch = 0.4634s	
1208/2700 (epoch 22.370), train_loss = 1.39184163, grad/param norm = 1.2975e-01, time/batch = 0.4703s	
1209/2700 (epoch 22.389), train_loss = 1.39312300, grad/param norm = 1.2485e-01, time/batch = 0.4830s	
1210/2700 (epoch 22.407), train_loss = 1.45119518, grad/param norm = 1.1463e-01, time/batch = 0.4662s	
1211/2700 (epoch 22.426), train_loss = 1.44031799, grad/param norm = 1.2312e-01, time/batch = 0.4811s	
1212/2700 (epoch 22.444), train_loss = 1.35295892, grad/param norm = 1.1821e-01, time/batch = 0.5081s	
1213/2700 (epoch 22.463), train_loss = 1.43680776, grad/param norm = 1.2745e-01, time/batch = 0.5101s	
1214/2700 (epoch 22.481), train_loss = 1.39298609, grad/param norm = 1.1366e-01, time/batch = 0.5080s	
1215/2700 (epoch 22.500), train_loss = 1.36882987, grad/param norm = 1.1776e-01, time/batch = 0.5080s	
1216/2700 (epoch 22.519), train_loss = 1.42310476, grad/param norm = 1.3851e-01, time/batch = 0.5249s	
1217/2700 (epoch 22.537), train_loss = 1.43813118, grad/param norm = 1.3461e-01, time/batch = 0.4757s	
1218/2700 (epoch 22.556), train_loss = 1.35131880, grad/param norm = 1.3242e-01, time/batch = 0.4748s	
1219/2700 (epoch 22.574), train_loss = 1.36904017, grad/param norm = 1.3389e-01, time/batch = 0.4380s	
1220/2700 (epoch 22.593), train_loss = 1.39254877, grad/param norm = 1.2746e-01, time/batch = 0.4961s	
1221/2700 (epoch 22.611), train_loss = 1.30829259, grad/param norm = 1.4762e-01, time/batch = 0.4828s	
1222/2700 (epoch 22.630), train_loss = 1.35022899, grad/param norm = 1.8068e-01, time/batch = 0.4992s	
1223/2700 (epoch 22.648), train_loss = 1.38885024, grad/param norm = 1.6297e-01, time/batch = 0.5128s	
1224/2700 (epoch 22.667), train_loss = 1.38160559, grad/param norm = 1.4970e-01, time/batch = 0.5243s	
1225/2700 (epoch 22.685), train_loss = 1.40510962, grad/param norm = 1.3798e-01, time/batch = 0.5197s	
1226/2700 (epoch 22.704), train_loss = 1.40913033, grad/param norm = 1.4518e-01, time/batch = 0.4953s	
1227/2700 (epoch 22.722), train_loss = 1.37278960, grad/param norm = 1.3873e-01, time/batch = 0.4830s	
1228/2700 (epoch 22.741), train_loss = 1.35715040, grad/param norm = 1.3096e-01, time/batch = 0.4043s	
1229/2700 (epoch 22.759), train_loss = 1.38138934, grad/param norm = 1.4265e-01, time/batch = 0.4786s	
1230/2700 (epoch 22.778), train_loss = 1.44958822, grad/param norm = 1.8107e-01, time/batch = 0.5038s	
1231/2700 (epoch 22.796), train_loss = 1.35962572, grad/param norm = 1.3728e-01, time/batch = 0.4850s	
1232/2700 (epoch 22.815), train_loss = 1.39008509, grad/param norm = 1.0684e-01, time/batch = 0.5007s	
1233/2700 (epoch 22.833), train_loss = 1.38066850, grad/param norm = 1.4010e-01, time/batch = 0.5306s	
1234/2700 (epoch 22.852), train_loss = 1.37608619, grad/param norm = 1.9114e-01, time/batch = 0.5168s	
1235/2700 (epoch 22.870), train_loss = 1.39020208, grad/param norm = 1.4771e-01, time/batch = 0.5228s	
1236/2700 (epoch 22.889), train_loss = 1.37494788, grad/param norm = 1.2181e-01, time/batch = 0.4969s	
1237/2700 (epoch 22.907), train_loss = 1.45728132, grad/param norm = 1.1487e-01, time/batch = 0.4115s	
1238/2700 (epoch 22.926), train_loss = 1.41383255, grad/param norm = 1.1875e-01, time/batch = 0.4213s	
1239/2700 (epoch 22.944), train_loss = 1.41184086, grad/param norm = 1.9028e-01, time/batch = 0.5137s	
1240/2700 (epoch 22.963), train_loss = 1.43911732, grad/param norm = 1.6930e-01, time/batch = 0.5148s	
1241/2700 (epoch 22.981), train_loss = 1.40708776, grad/param norm = 1.5289e-01, time/batch = 0.4927s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1242/2700 (epoch 23.000), train_loss = 1.42038285, grad/param norm = 1.1971e-01, time/batch = 0.5326s	
1243/2700 (epoch 23.019), train_loss = 1.47020469, grad/param norm = 1.2430e-01, time/batch = 0.5187s	
1244/2700 (epoch 23.037), train_loss = 1.42385972, grad/param norm = 1.3943e-01, time/batch = 0.5205s	
1245/2700 (epoch 23.056), train_loss = 1.38116406, grad/param norm = 1.4273e-01, time/batch = 0.4987s	
1246/2700 (epoch 23.074), train_loss = 1.36286322, grad/param norm = 1.1729e-01, time/batch = 0.4367s	
1247/2700 (epoch 23.093), train_loss = 1.34241383, grad/param norm = 1.1417e-01, time/batch = 0.4942s	
1248/2700 (epoch 23.111), train_loss = 1.32403111, grad/param norm = 1.1916e-01, time/batch = 0.4802s	
1249/2700 (epoch 23.130), train_loss = 1.37245853, grad/param norm = 1.1828e-01, time/batch = 0.4485s	
1250/2700 (epoch 23.148), train_loss = 1.33112078, grad/param norm = 1.2910e-01, time/batch = 0.5086s	
1251/2700 (epoch 23.167), train_loss = 1.40303765, grad/param norm = 1.3249e-01, time/batch = 0.5105s	
1252/2700 (epoch 23.185), train_loss = 1.33852106, grad/param norm = 1.1748e-01, time/batch = 0.5163s	
1253/2700 (epoch 23.204), train_loss = 1.37276932, grad/param norm = 1.1866e-01, time/batch = 0.5208s	
1254/2700 (epoch 23.222), train_loss = 1.33036014, grad/param norm = 1.3230e-01, time/batch = 0.5099s	
1255/2700 (epoch 23.241), train_loss = 1.28950473, grad/param norm = 1.5720e-01, time/batch = 0.4418s	
1256/2700 (epoch 23.259), train_loss = 1.31894801, grad/param norm = 1.5270e-01, time/batch = 0.4946s	
1257/2700 (epoch 23.278), train_loss = 1.38584291, grad/param norm = 1.2910e-01, time/batch = 0.4769s	
1258/2700 (epoch 23.296), train_loss = 1.35413600, grad/param norm = 1.1295e-01, time/batch = 0.4766s	
1259/2700 (epoch 23.315), train_loss = 1.33473513, grad/param norm = 1.2777e-01, time/batch = 0.4819s	
1260/2700 (epoch 23.333), train_loss = 1.33836382, grad/param norm = 1.3037e-01, time/batch = 0.4849s	
1261/2700 (epoch 23.352), train_loss = 1.33597496, grad/param norm = 1.3211e-01, time/batch = 0.5121s	
1262/2700 (epoch 23.370), train_loss = 1.35022042, grad/param norm = 1.2798e-01, time/batch = 0.5267s	
1263/2700 (epoch 23.389), train_loss = 1.34762370, grad/param norm = 1.3504e-01, time/batch = 0.5152s	
1264/2700 (epoch 23.407), train_loss = 1.41374386, grad/param norm = 1.2640e-01, time/batch = 0.4471s	
1265/2700 (epoch 23.426), train_loss = 1.39601473, grad/param norm = 1.2125e-01, time/batch = 0.5004s	
1266/2700 (epoch 23.444), train_loss = 1.31239852, grad/param norm = 1.1292e-01, time/batch = 0.4812s	
1267/2700 (epoch 23.463), train_loss = 1.40372538, grad/param norm = 1.4923e-01, time/batch = 0.4646s	
1268/2700 (epoch 23.481), train_loss = 1.36847588, grad/param norm = 1.4591e-01, time/batch = 0.4869s	
1269/2700 (epoch 23.500), train_loss = 1.33600219, grad/param norm = 1.3977e-01, time/batch = 0.4891s	
1270/2700 (epoch 23.519), train_loss = 1.38103971, grad/param norm = 1.4404e-01, time/batch = 0.5093s	
1271/2700 (epoch 23.537), train_loss = 1.41034202, grad/param norm = 1.8266e-01, time/batch = 0.4735s	
1272/2700 (epoch 23.556), train_loss = 1.32208992, grad/param norm = 1.4180e-01, time/batch = 0.5195s	
1273/2700 (epoch 23.574), train_loss = 1.33325294, grad/param norm = 1.4145e-01, time/batch = 0.4443s	
1274/2700 (epoch 23.593), train_loss = 1.37174876, grad/param norm = 1.4548e-01, time/batch = 0.4855s	
1275/2700 (epoch 23.611), train_loss = 1.27166856, grad/param norm = 1.2834e-01, time/batch = 0.4727s	
1276/2700 (epoch 23.630), train_loss = 1.30143852, grad/param norm = 1.2966e-01, time/batch = 0.4941s	
1277/2700 (epoch 23.648), train_loss = 1.33878317, grad/param norm = 1.4280e-01, time/batch = 0.5021s	
1278/2700 (epoch 23.667), train_loss = 1.33445945, grad/param norm = 1.3390e-01, time/batch = 0.5115s	
1279/2700 (epoch 23.685), train_loss = 1.36057941, grad/param norm = 1.4098e-01, time/batch = 0.5093s	
1280/2700 (epoch 23.704), train_loss = 1.37610216, grad/param norm = 1.6110e-01, time/batch = 0.5115s	
1281/2700 (epoch 23.722), train_loss = 1.32997644, grad/param norm = 1.3809e-01, time/batch = 0.5299s	
1282/2700 (epoch 23.741), train_loss = 1.31603796, grad/param norm = 1.3013e-01, time/batch = 0.4579s	
1283/2700 (epoch 23.759), train_loss = 1.33847914, grad/param norm = 1.5726e-01, time/batch = 0.5147s	
1284/2700 (epoch 23.778), train_loss = 1.39073959, grad/param norm = 1.3538e-01, time/batch = 0.4857s	
1285/2700 (epoch 23.796), train_loss = 1.31473159, grad/param norm = 1.3716e-01, time/batch = 0.4844s	
1286/2700 (epoch 23.815), train_loss = 1.36180693, grad/param norm = 1.6491e-01, time/batch = 0.4826s	
1287/2700 (epoch 23.833), train_loss = 1.35354379, grad/param norm = 1.7216e-01, time/batch = 0.4826s	
1288/2700 (epoch 23.852), train_loss = 1.32316191, grad/param norm = 1.6049e-01, time/batch = 0.5004s	
1289/2700 (epoch 23.870), train_loss = 1.34486350, grad/param norm = 1.3509e-01, time/batch = 0.5072s	
1290/2700 (epoch 23.889), train_loss = 1.34677592, grad/param norm = 1.4963e-01, time/batch = 0.5261s	
1291/2700 (epoch 23.907), train_loss = 1.43647619, grad/param norm = 1.5565e-01, time/batch = 0.4892s	
1292/2700 (epoch 23.926), train_loss = 1.37545220, grad/param norm = 1.2381e-01, time/batch = 0.5147s	
1293/2700 (epoch 23.944), train_loss = 1.34017890, grad/param norm = 1.1231e-01, time/batch = 0.5034s	
1294/2700 (epoch 23.963), train_loss = 1.36541305, grad/param norm = 1.3042e-01, time/batch = 0.4846s	
1295/2700 (epoch 23.981), train_loss = 1.34517264, grad/param norm = 1.2037e-01, time/batch = 0.4860s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1296/2700 (epoch 24.000), train_loss = 1.38032426, grad/param norm = 1.3538e-01, time/batch = 0.4804s	
1297/2700 (epoch 24.019), train_loss = 1.43728874, grad/param norm = 1.2809e-01, time/batch = 0.4827s	
1298/2700 (epoch 24.037), train_loss = 1.37292889, grad/param norm = 1.1987e-01, time/batch = 0.5001s	
1299/2700 (epoch 24.056), train_loss = 1.33681841, grad/param norm = 1.1647e-01, time/batch = 0.5174s	
1300/2700 (epoch 24.074), train_loss = 1.32490619, grad/param norm = 1.2177e-01, time/batch = 0.4787s	
1301/2700 (epoch 24.093), train_loss = 1.30755158, grad/param norm = 1.2007e-01, time/batch = 0.5147s	
1302/2700 (epoch 24.111), train_loss = 1.28627594, grad/param norm = 1.2477e-01, time/batch = 0.5078s	
1303/2700 (epoch 24.130), train_loss = 1.33505720, grad/param norm = 1.4392e-01, time/batch = 0.5064s	
1304/2700 (epoch 24.148), train_loss = 1.29266522, grad/param norm = 1.3107e-01, time/batch = 0.4987s	
1305/2700 (epoch 24.167), train_loss = 1.36418539, grad/param norm = 1.2690e-01, time/batch = 0.4216s	
1306/2700 (epoch 24.185), train_loss = 1.30750641, grad/param norm = 1.4757e-01, time/batch = 0.4925s	
1307/2700 (epoch 24.204), train_loss = 1.34431384, grad/param norm = 1.4604e-01, time/batch = 0.5113s	
1308/2700 (epoch 24.222), train_loss = 1.28451805, grad/param norm = 1.2429e-01, time/batch = 0.5045s	
1309/2700 (epoch 24.241), train_loss = 1.23677044, grad/param norm = 1.1000e-01, time/batch = 0.4870s	
1310/2700 (epoch 24.259), train_loss = 1.26869021, grad/param norm = 1.3011e-01, time/batch = 0.5159s	
1311/2700 (epoch 24.278), train_loss = 1.35061169, grad/param norm = 1.4323e-01, time/batch = 0.4862s	
1312/2700 (epoch 24.296), train_loss = 1.32459677, grad/param norm = 1.4394e-01, time/batch = 0.4925s	
1313/2700 (epoch 24.315), train_loss = 1.29636417, grad/param norm = 1.3465e-01, time/batch = 0.4730s	
1314/2700 (epoch 24.333), train_loss = 1.29207495, grad/param norm = 1.3195e-01, time/batch = 0.4526s	
1315/2700 (epoch 24.352), train_loss = 1.30666606, grad/param norm = 1.4682e-01, time/batch = 0.5009s	
1316/2700 (epoch 24.370), train_loss = 1.30756070, grad/param norm = 1.4073e-01, time/batch = 0.4661s	
1317/2700 (epoch 24.389), train_loss = 1.31815035, grad/param norm = 1.5970e-01, time/batch = 0.5093s	
1318/2700 (epoch 24.407), train_loss = 1.38752765, grad/param norm = 1.6217e-01, time/batch = 0.4941s	
1319/2700 (epoch 24.426), train_loss = 1.38134838, grad/param norm = 1.5624e-01, time/batch = 0.5092s	
1320/2700 (epoch 24.444), train_loss = 1.29613427, grad/param norm = 1.4697e-01, time/batch = 0.4977s	
1321/2700 (epoch 24.463), train_loss = 1.35936509, grad/param norm = 1.4091e-01, time/batch = 0.5132s	
1322/2700 (epoch 24.481), train_loss = 1.31300035, grad/param norm = 1.1754e-01, time/batch = 0.4905s	
1323/2700 (epoch 24.500), train_loss = 1.30004714, grad/param norm = 1.4764e-01, time/batch = 0.4960s	
1324/2700 (epoch 24.519), train_loss = 1.34167120, grad/param norm = 1.4744e-01, time/batch = 0.4720s	
1325/2700 (epoch 24.537), train_loss = 1.34544461, grad/param norm = 1.2879e-01, time/batch = 0.4910s	
1326/2700 (epoch 24.556), train_loss = 1.26500340, grad/param norm = 1.3148e-01, time/batch = 0.4809s	
1327/2700 (epoch 24.574), train_loss = 1.29351275, grad/param norm = 1.4290e-01, time/batch = 0.4696s	
1328/2700 (epoch 24.593), train_loss = 1.32068204, grad/param norm = 1.3386e-01, time/batch = 0.5093s	
1329/2700 (epoch 24.611), train_loss = 1.23199776, grad/param norm = 1.2847e-01, time/batch = 0.5023s	
1330/2700 (epoch 24.630), train_loss = 1.26412640, grad/param norm = 1.2964e-01, time/batch = 0.5108s	
1331/2700 (epoch 24.648), train_loss = 1.29109027, grad/param norm = 1.2381e-01, time/batch = 0.5180s	
1332/2700 (epoch 24.667), train_loss = 1.29271520, grad/param norm = 1.3035e-01, time/batch = 0.4790s	
1333/2700 (epoch 24.685), train_loss = 1.32616126, grad/param norm = 1.3033e-01, time/batch = 0.5007s	
1334/2700 (epoch 24.704), train_loss = 1.33852202, grad/param norm = 1.5172e-01, time/batch = 0.4727s	
1335/2700 (epoch 24.722), train_loss = 1.30783091, grad/param norm = 1.6234e-01, time/batch = 0.4846s	
1336/2700 (epoch 24.741), train_loss = 1.30876909, grad/param norm = 1.8534e-01, time/batch = 0.4798s	
1337/2700 (epoch 24.759), train_loss = 1.32321537, grad/param norm = 2.0002e-01, time/batch = 0.5107s	
1338/2700 (epoch 24.778), train_loss = 1.36801256, grad/param norm = 1.8869e-01, time/batch = 0.4876s	
1339/2700 (epoch 24.796), train_loss = 1.28146260, grad/param norm = 1.4410e-01, time/batch = 0.5149s	
1340/2700 (epoch 24.815), train_loss = 1.32505466, grad/param norm = 1.4242e-01, time/batch = 0.4957s	
1341/2700 (epoch 24.833), train_loss = 1.30062582, grad/param norm = 1.2222e-01, time/batch = 0.4724s	
1342/2700 (epoch 24.852), train_loss = 1.27075583, grad/param norm = 1.2902e-01, time/batch = 0.4596s	
1343/2700 (epoch 24.870), train_loss = 1.31472891, grad/param norm = 1.6216e-01, time/batch = 0.4655s	
1344/2700 (epoch 24.889), train_loss = 1.32012712, grad/param norm = 1.8338e-01, time/batch = 0.4916s	
1345/2700 (epoch 24.907), train_loss = 1.40072162, grad/param norm = 1.7735e-01, time/batch = 0.4945s	
1346/2700 (epoch 24.926), train_loss = 1.33756361, grad/param norm = 1.3710e-01, time/batch = 0.5110s	
1347/2700 (epoch 24.944), train_loss = 1.31827181, grad/param norm = 1.6776e-01, time/batch = 0.5035s	
1348/2700 (epoch 24.963), train_loss = 1.33148626, grad/param norm = 1.4003e-01, time/batch = 0.5087s	
1349/2700 (epoch 24.981), train_loss = 1.30474882, grad/param norm = 1.1948e-01, time/batch = 0.4975s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1350/2700 (epoch 25.000), train_loss = 1.32652973, grad/param norm = 1.2112e-01, time/batch = 0.4981s	
1351/2700 (epoch 25.019), train_loss = 1.40071189, grad/param norm = 1.3893e-01, time/batch = 0.4555s	
1352/2700 (epoch 25.037), train_loss = 1.33428718, grad/param norm = 1.2664e-01, time/batch = 0.4645s	
1353/2700 (epoch 25.056), train_loss = 1.29471663, grad/param norm = 1.2358e-01, time/batch = 0.4929s	
1354/2700 (epoch 25.074), train_loss = 1.27801801, grad/param norm = 1.1175e-01, time/batch = 0.5093s	
1355/2700 (epoch 25.093), train_loss = 1.26348248, grad/param norm = 1.0602e-01, time/batch = 0.4752s	
1356/2700 (epoch 25.111), train_loss = 1.24712182, grad/param norm = 1.1618e-01, time/batch = 0.5062s	
1357/2700 (epoch 25.130), train_loss = 1.28828279, grad/param norm = 1.2847e-01, time/batch = 0.5053s	
1358/2700 (epoch 25.148), train_loss = 1.26066573, grad/param norm = 1.2463e-01, time/batch = 0.5087s	
1359/2700 (epoch 25.167), train_loss = 1.32944086, grad/param norm = 1.4862e-01, time/batch = 0.5094s	
1360/2700 (epoch 25.185), train_loss = 1.26976503, grad/param norm = 1.2962e-01, time/batch = 0.4850s	
1361/2700 (epoch 25.204), train_loss = 1.30813400, grad/param norm = 1.5127e-01, time/batch = 0.4308s	
1362/2700 (epoch 25.222), train_loss = 1.26801011, grad/param norm = 1.5371e-01, time/batch = 0.4764s	
1363/2700 (epoch 25.241), train_loss = 1.23557666, grad/param norm = 1.9437e-01, time/batch = 0.5132s	
1364/2700 (epoch 25.259), train_loss = 1.24523645, grad/param norm = 1.5703e-01, time/batch = 0.4775s	
1365/2700 (epoch 25.278), train_loss = 1.30931628, grad/param norm = 1.2779e-01, time/batch = 0.5167s	
1366/2700 (epoch 25.296), train_loss = 1.28406034, grad/param norm = 1.4504e-01, time/batch = 0.5057s	
1367/2700 (epoch 25.315), train_loss = 1.26106415, grad/param norm = 1.4185e-01, time/batch = 0.5090s	
1368/2700 (epoch 25.333), train_loss = 1.25552171, grad/param norm = 1.5193e-01, time/batch = 0.5072s	
1369/2700 (epoch 25.352), train_loss = 1.25799769, grad/param norm = 1.4719e-01, time/batch = 0.5019s	
1370/2700 (epoch 25.370), train_loss = 1.26259791, grad/param norm = 1.4311e-01, time/batch = 0.4790s	
1371/2700 (epoch 25.389), train_loss = 1.27776599, grad/param norm = 1.5158e-01, time/batch = 0.4697s	
1372/2700 (epoch 25.407), train_loss = 1.33511099, grad/param norm = 1.3964e-01, time/batch = 0.4345s	
1373/2700 (epoch 25.426), train_loss = 1.31465438, grad/param norm = 1.4122e-01, time/batch = 0.4723s	
1374/2700 (epoch 25.444), train_loss = 1.24378766, grad/param norm = 1.3622e-01, time/batch = 0.5168s	
1375/2700 (epoch 25.463), train_loss = 1.31780777, grad/param norm = 1.4389e-01, time/batch = 0.5210s	
1376/2700 (epoch 25.481), train_loss = 1.28923842, grad/param norm = 1.4807e-01, time/batch = 0.5309s	
1377/2700 (epoch 25.500), train_loss = 1.25506611, grad/param norm = 1.4661e-01, time/batch = 0.5054s	
1378/2700 (epoch 25.519), train_loss = 1.29056430, grad/param norm = 1.2590e-01, time/batch = 0.4939s	
1379/2700 (epoch 25.537), train_loss = 1.31409944, grad/param norm = 1.5961e-01, time/batch = 0.4781s	
1380/2700 (epoch 25.556), train_loss = 1.23773846, grad/param norm = 1.4319e-01, time/batch = 0.4794s	
1381/2700 (epoch 25.574), train_loss = 1.24271455, grad/param norm = 1.3232e-01, time/batch = 0.4776s	
1382/2700 (epoch 25.593), train_loss = 1.28537918, grad/param norm = 1.4098e-01, time/batch = 0.4268s	
1383/2700 (epoch 25.611), train_loss = 1.19607247, grad/param norm = 1.2978e-01, time/batch = 0.4703s	
1384/2700 (epoch 25.630), train_loss = 1.22161879, grad/param norm = 1.3204e-01, time/batch = 0.5197s	
1385/2700 (epoch 25.648), train_loss = 1.26736325, grad/param norm = 1.6619e-01, time/batch = 0.5119s	
1386/2700 (epoch 25.667), train_loss = 1.26544900, grad/param norm = 1.4702e-01, time/batch = 0.5094s	
1387/2700 (epoch 25.685), train_loss = 1.28465578, grad/param norm = 1.3672e-01, time/batch = 0.4707s	
1388/2700 (epoch 25.704), train_loss = 1.28970717, grad/param norm = 1.2832e-01, time/batch = 0.4735s	
1389/2700 (epoch 25.722), train_loss = 1.25148615, grad/param norm = 1.4325e-01, time/batch = 0.4793s	
1390/2700 (epoch 25.741), train_loss = 1.25234560, grad/param norm = 1.3919e-01, time/batch = 0.4946s	
1391/2700 (epoch 25.759), train_loss = 1.27100269, grad/param norm = 1.5874e-01, time/batch = 0.4620s	
1392/2700 (epoch 25.778), train_loss = 1.34065061, grad/param norm = 1.7571e-01, time/batch = 0.5091s	
1393/2700 (epoch 25.796), train_loss = 1.26139416, grad/param norm = 1.8175e-01, time/batch = 0.4900s	
1394/2700 (epoch 25.815), train_loss = 1.30814281, grad/param norm = 1.9097e-01, time/batch = 0.5111s	
1395/2700 (epoch 25.833), train_loss = 1.28383359, grad/param norm = 1.6830e-01, time/batch = 0.4891s	
1396/2700 (epoch 25.852), train_loss = 1.24076229, grad/param norm = 1.4139e-01, time/batch = 0.4697s	
1397/2700 (epoch 25.870), train_loss = 1.26944690, grad/param norm = 1.4341e-01, time/batch = 0.4618s	
1398/2700 (epoch 25.889), train_loss = 1.26191590, grad/param norm = 1.3068e-01, time/batch = 0.4768s	
1399/2700 (epoch 25.907), train_loss = 1.34854769, grad/param norm = 1.3946e-01, time/batch = 0.4955s	
1400/2700 (epoch 25.926), train_loss = 1.30853056, grad/param norm = 1.6389e-01, time/batch = 0.4954s	
1401/2700 (epoch 25.944), train_loss = 1.28916720, grad/param norm = 1.9811e-01, time/batch = 0.5017s	
1402/2700 (epoch 25.963), train_loss = 1.30302088, grad/param norm = 1.6830e-01, time/batch = 0.4920s	
1403/2700 (epoch 25.981), train_loss = 1.28092453, grad/param norm = 1.7055e-01, time/batch = 0.5317s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1404/2700 (epoch 26.000), train_loss = 1.29790685, grad/param norm = 1.5006e-01, time/batch = 0.5175s	
1405/2700 (epoch 26.019), train_loss = 1.35994052, grad/param norm = 1.3589e-01, time/batch = 0.5009s	
1406/2700 (epoch 26.037), train_loss = 1.29782050, grad/param norm = 1.3140e-01, time/batch = 0.5021s	
1407/2700 (epoch 26.056), train_loss = 1.26833419, grad/param norm = 1.5180e-01, time/batch = 0.4690s	
1408/2700 (epoch 26.074), train_loss = 1.25238487, grad/param norm = 1.5135e-01, time/batch = 0.4815s	
1409/2700 (epoch 26.093), train_loss = 1.23209721, grad/param norm = 1.2029e-01, time/batch = 0.4721s	
1410/2700 (epoch 26.111), train_loss = 1.20244554, grad/param norm = 1.0528e-01, time/batch = 0.5060s	
1411/2700 (epoch 26.130), train_loss = 1.24645080, grad/param norm = 1.1596e-01, time/batch = 0.5040s	
1412/2700 (epoch 26.148), train_loss = 1.21889857, grad/param norm = 1.2152e-01, time/batch = 0.5298s	
1413/2700 (epoch 26.167), train_loss = 1.28135134, grad/param norm = 1.2133e-01, time/batch = 0.5176s	
1414/2700 (epoch 26.185), train_loss = 1.22495960, grad/param norm = 1.2783e-01, time/batch = 0.5183s	
1415/2700 (epoch 26.204), train_loss = 1.26249535, grad/param norm = 1.4064e-01, time/batch = 0.5052s	
1416/2700 (epoch 26.222), train_loss = 1.21667487, grad/param norm = 1.5006e-01, time/batch = 0.5037s	
1417/2700 (epoch 26.241), train_loss = 1.17580729, grad/param norm = 1.5952e-01, time/batch = 0.4099s	
1418/2700 (epoch 26.259), train_loss = 1.19161761, grad/param norm = 1.4469e-01, time/batch = 0.4861s	
1419/2700 (epoch 26.278), train_loss = 1.27786682, grad/param norm = 1.3581e-01, time/batch = 0.5109s	
1420/2700 (epoch 26.296), train_loss = 1.25255827, grad/param norm = 1.4758e-01, time/batch = 0.5082s	
1421/2700 (epoch 26.315), train_loss = 1.21298393, grad/param norm = 1.2427e-01, time/batch = 0.5146s	
1422/2700 (epoch 26.333), train_loss = 1.21014280, grad/param norm = 1.3088e-01, time/batch = 0.5233s	
1423/2700 (epoch 26.352), train_loss = 1.21095425, grad/param norm = 1.3340e-01, time/batch = 0.5023s	
1424/2700 (epoch 26.370), train_loss = 1.22245417, grad/param norm = 1.5270e-01, time/batch = 0.4933s	
1425/2700 (epoch 26.389), train_loss = 1.23864537, grad/param norm = 1.6044e-01, time/batch = 0.4733s	
1426/2700 (epoch 26.407), train_loss = 1.30775386, grad/param norm = 1.5717e-01, time/batch = 0.4798s	
1427/2700 (epoch 26.426), train_loss = 1.27790106, grad/param norm = 1.4883e-01, time/batch = 0.4652s	
1428/2700 (epoch 26.444), train_loss = 1.21972027, grad/param norm = 1.4979e-01, time/batch = 0.4686s	
1429/2700 (epoch 26.463), train_loss = 1.27698487, grad/param norm = 1.5808e-01, time/batch = 0.5114s	
1430/2700 (epoch 26.481), train_loss = 1.24705205, grad/param norm = 1.6934e-01, time/batch = 0.5122s	
1431/2700 (epoch 26.500), train_loss = 1.22352110, grad/param norm = 1.5881e-01, time/batch = 0.5241s	
1432/2700 (epoch 26.519), train_loss = 1.26623905, grad/param norm = 1.6111e-01, time/batch = 0.5012s	
1433/2700 (epoch 26.537), train_loss = 1.28118093, grad/param norm = 1.6060e-01, time/batch = 0.5347s	
1434/2700 (epoch 26.556), train_loss = 1.19410173, grad/param norm = 1.3379e-01, time/batch = 0.4903s	
1435/2700 (epoch 26.574), train_loss = 1.20868183, grad/param norm = 1.4404e-01, time/batch = 0.4746s	
1436/2700 (epoch 26.593), train_loss = 1.25698561, grad/param norm = 1.6819e-01, time/batch = 0.4711s	
1437/2700 (epoch 26.611), train_loss = 1.16677415, grad/param norm = 1.4177e-01, time/batch = 0.4810s	
1438/2700 (epoch 26.630), train_loss = 1.18882728, grad/param norm = 1.3372e-01, time/batch = 0.4810s	
1439/2700 (epoch 26.648), train_loss = 1.21115135, grad/param norm = 1.2561e-01, time/batch = 0.4796s	
1440/2700 (epoch 26.667), train_loss = 1.21505817, grad/param norm = 1.2880e-01, time/batch = 0.5206s	
1441/2700 (epoch 26.685), train_loss = 1.25296196, grad/param norm = 1.4803e-01, time/batch = 0.5001s	
1442/2700 (epoch 26.704), train_loss = 1.26362195, grad/param norm = 1.6221e-01, time/batch = 0.4805s	
1443/2700 (epoch 26.722), train_loss = 1.21729797, grad/param norm = 1.5207e-01, time/batch = 0.4875s	
1444/2700 (epoch 26.741), train_loss = 1.20775866, grad/param norm = 1.5102e-01, time/batch = 0.4778s	
1445/2700 (epoch 26.759), train_loss = 1.22709511, grad/param norm = 1.6586e-01, time/batch = 0.4672s	
1446/2700 (epoch 26.778), train_loss = 1.28350431, grad/param norm = 1.7499e-01, time/batch = 0.4924s	
1447/2700 (epoch 26.796), train_loss = 1.21180324, grad/param norm = 1.4196e-01, time/batch = 0.5040s	
1448/2700 (epoch 26.815), train_loss = 1.25428182, grad/param norm = 1.3909e-01, time/batch = 0.5114s	
1449/2700 (epoch 26.833), train_loss = 1.23680494, grad/param norm = 1.4582e-01, time/batch = 0.5107s	
1450/2700 (epoch 26.852), train_loss = 1.21022595, grad/param norm = 1.6794e-01, time/batch = 0.5073s	
1451/2700 (epoch 26.870), train_loss = 1.24159684, grad/param norm = 1.4982e-01, time/batch = 0.5033s	
1452/2700 (epoch 26.889), train_loss = 1.23111451, grad/param norm = 1.6225e-01, time/batch = 0.4976s	
1453/2700 (epoch 26.907), train_loss = 1.30862106, grad/param norm = 1.4293e-01, time/batch = 0.4528s	
1454/2700 (epoch 26.926), train_loss = 1.26959977, grad/param norm = 1.6244e-01, time/batch = 0.4689s	
1455/2700 (epoch 26.944), train_loss = 1.24090980, grad/param norm = 1.6935e-01, time/batch = 0.4900s	
1456/2700 (epoch 26.963), train_loss = 1.25154799, grad/param norm = 1.5156e-01, time/batch = 0.5001s	
1457/2700 (epoch 26.981), train_loss = 1.23421182, grad/param norm = 1.4054e-01, time/batch = 0.5063s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1458/2700 (epoch 27.000), train_loss = 1.26457499, grad/param norm = 1.5803e-01, time/batch = 0.5082s	
1459/2700 (epoch 27.019), train_loss = 1.34182703, grad/param norm = 1.7026e-01, time/batch = 0.5149s	
1460/2700 (epoch 27.037), train_loss = 1.26166331, grad/param norm = 1.4806e-01, time/batch = 0.5250s	
1461/2700 (epoch 27.056), train_loss = 1.21855236, grad/param norm = 1.1916e-01, time/batch = 0.5448s	
1462/2700 (epoch 27.074), train_loss = 1.20252992, grad/param norm = 1.2338e-01, time/batch = 0.4521s	
1463/2700 (epoch 27.093), train_loss = 1.20070271, grad/param norm = 1.3934e-01, time/batch = 0.4665s	
1464/2700 (epoch 27.111), train_loss = 1.18376607, grad/param norm = 1.4316e-01, time/batch = 0.4909s	
1465/2700 (epoch 27.130), train_loss = 1.21519749, grad/param norm = 1.4145e-01, time/batch = 0.5030s	
1466/2700 (epoch 27.148), train_loss = 1.19695078, grad/param norm = 1.7270e-01, time/batch = 0.5069s	
1467/2700 (epoch 27.167), train_loss = 1.24921162, grad/param norm = 1.5332e-01, time/batch = 0.5085s	
1468/2700 (epoch 27.185), train_loss = 1.18810279, grad/param norm = 1.1950e-01, time/batch = 0.5201s	
1469/2700 (epoch 27.204), train_loss = 1.21370294, grad/param norm = 1.2534e-01, time/batch = 0.5219s	
1470/2700 (epoch 27.222), train_loss = 1.17783824, grad/param norm = 1.4059e-01, time/batch = 0.5276s	
1471/2700 (epoch 27.241), train_loss = 1.15148038, grad/param norm = 1.5806e-01, time/batch = 0.5051s	
1472/2700 (epoch 27.259), train_loss = 1.15491073, grad/param norm = 1.5750e-01, time/batch = 0.4843s	
1473/2700 (epoch 27.278), train_loss = 1.25434162, grad/param norm = 1.8012e-01, time/batch = 0.4103s	
1474/2700 (epoch 27.296), train_loss = 1.22191781, grad/param norm = 1.6089e-01, time/batch = 0.5024s	
1475/2700 (epoch 27.315), train_loss = 1.19380755, grad/param norm = 1.7289e-01, time/batch = 0.5069s	
1476/2700 (epoch 27.333), train_loss = 1.19598302, grad/param norm = 1.6099e-01, time/batch = 0.5219s	
1477/2700 (epoch 27.352), train_loss = 1.19416393, grad/param norm = 1.7210e-01, time/batch = 0.5215s	
1478/2700 (epoch 27.370), train_loss = 1.18274357, grad/param norm = 1.4653e-01, time/batch = 0.5019s	
1479/2700 (epoch 27.389), train_loss = 1.20155838, grad/param norm = 1.5764e-01, time/batch = 0.4994s	
1480/2700 (epoch 27.407), train_loss = 1.27147571, grad/param norm = 1.5435e-01, time/batch = 0.4653s	
1481/2700 (epoch 27.426), train_loss = 1.25612070, grad/param norm = 1.6716e-01, time/batch = 0.4913s	
1482/2700 (epoch 27.444), train_loss = 1.19480363, grad/param norm = 1.5603e-01, time/batch = 0.4539s	
1483/2700 (epoch 27.463), train_loss = 1.22963321, grad/param norm = 1.3279e-01, time/batch = 0.4699s	
1484/2700 (epoch 27.481), train_loss = 1.19286993, grad/param norm = 1.4327e-01, time/batch = 0.4557s	
1485/2700 (epoch 27.500), train_loss = 1.18255294, grad/param norm = 1.5436e-01, time/batch = 0.5113s	
1486/2700 (epoch 27.519), train_loss = 1.21929883, grad/param norm = 1.4084e-01, time/batch = 0.5086s	
1487/2700 (epoch 27.537), train_loss = 1.23309571, grad/param norm = 1.5560e-01, time/batch = 0.5160s	
1488/2700 (epoch 27.556), train_loss = 1.15838651, grad/param norm = 1.6096e-01, time/batch = 0.5135s	
1489/2700 (epoch 27.574), train_loss = 1.17487644, grad/param norm = 1.6869e-01, time/batch = 0.4910s	
1490/2700 (epoch 27.593), train_loss = 1.21251433, grad/param norm = 1.5331e-01, time/batch = 0.4664s	
1491/2700 (epoch 27.611), train_loss = 1.13328845, grad/param norm = 1.5322e-01, time/batch = 0.3953s	
1492/2700 (epoch 27.630), train_loss = 1.16522127, grad/param norm = 1.6836e-01, time/batch = 0.4760s	
1493/2700 (epoch 27.648), train_loss = 1.19125544, grad/param norm = 1.6748e-01, time/batch = 0.4955s	
1494/2700 (epoch 27.667), train_loss = 1.19110024, grad/param norm = 1.6677e-01, time/batch = 0.5050s	
1495/2700 (epoch 27.685), train_loss = 1.21848191, grad/param norm = 1.5785e-01, time/batch = 0.4949s	
1496/2700 (epoch 27.704), train_loss = 1.22515682, grad/param norm = 1.6197e-01, time/batch = 0.5087s	
1497/2700 (epoch 27.722), train_loss = 1.17768533, grad/param norm = 1.5508e-01, time/batch = 0.5094s	
1498/2700 (epoch 27.741), train_loss = 1.17901996, grad/param norm = 1.6649e-01, time/batch = 0.5020s	
1499/2700 (epoch 27.759), train_loss = 1.19735795, grad/param norm = 1.9540e-01, time/batch = 0.4684s	
1500/2700 (epoch 27.778), train_loss = 1.24445528, grad/param norm = 1.6055e-01, time/batch = 0.4381s	
1501/2700 (epoch 27.796), train_loss = 1.18570454, grad/param norm = 1.8811e-01, time/batch = 0.4667s	
1502/2700 (epoch 27.815), train_loss = 1.22254032, grad/param norm = 1.6153e-01, time/batch = 0.4872s	
1503/2700 (epoch 27.833), train_loss = 1.19440139, grad/param norm = 1.4018e-01, time/batch = 0.5201s	
1504/2700 (epoch 27.852), train_loss = 1.16067971, grad/param norm = 1.4785e-01, time/batch = 0.5184s	
1505/2700 (epoch 27.870), train_loss = 1.19122196, grad/param norm = 1.3830e-01, time/batch = 0.5074s	
1506/2700 (epoch 27.889), train_loss = 1.18530568, grad/param norm = 1.3862e-01, time/batch = 0.4948s	
1507/2700 (epoch 27.907), train_loss = 1.26753494, grad/param norm = 1.6992e-01, time/batch = 0.4830s	
1508/2700 (epoch 27.926), train_loss = 1.23932270, grad/param norm = 1.8080e-01, time/batch = 0.4745s	
1509/2700 (epoch 27.944), train_loss = 1.20378512, grad/param norm = 1.5916e-01, time/batch = 0.4569s	
1510/2700 (epoch 27.963), train_loss = 1.22449809, grad/param norm = 1.8066e-01, time/batch = 0.4950s	
1511/2700 (epoch 27.981), train_loss = 1.20917460, grad/param norm = 1.7235e-01, time/batch = 0.4789s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1512/2700 (epoch 28.000), train_loss = 1.22734774, grad/param norm = 1.5084e-01, time/batch = 0.5094s	
1513/2700 (epoch 28.019), train_loss = 1.30646583, grad/param norm = 1.6383e-01, time/batch = 0.5224s	
1514/2700 (epoch 28.037), train_loss = 1.22022680, grad/param norm = 1.3357e-01, time/batch = 0.5093s	
1515/2700 (epoch 28.056), train_loss = 1.18662275, grad/param norm = 1.3796e-01, time/batch = 0.5138s	
1516/2700 (epoch 28.074), train_loss = 1.16614058, grad/param norm = 1.2962e-01, time/batch = 0.5065s	
1517/2700 (epoch 28.093), train_loss = 1.15252833, grad/param norm = 1.2016e-01, time/batch = 0.4980s	
1518/2700 (epoch 28.111), train_loss = 1.13180029, grad/param norm = 1.2205e-01, time/batch = 0.4120s	
1519/2700 (epoch 28.130), train_loss = 1.17242435, grad/param norm = 1.3871e-01, time/batch = 0.4913s	
1520/2700 (epoch 28.148), train_loss = 1.14441358, grad/param norm = 1.2669e-01, time/batch = 0.5113s	
1521/2700 (epoch 28.167), train_loss = 1.21015150, grad/param norm = 1.4239e-01, time/batch = 0.5123s	
1522/2700 (epoch 28.185), train_loss = 1.16513767, grad/param norm = 1.6988e-01, time/batch = 0.5192s	
1523/2700 (epoch 28.204), train_loss = 1.18920000, grad/param norm = 1.6206e-01, time/batch = 0.5136s	
1524/2700 (epoch 28.222), train_loss = 1.13348613, grad/param norm = 1.2996e-01, time/batch = 0.5094s	
1525/2700 (epoch 28.241), train_loss = 1.09378455, grad/param norm = 1.1569e-01, time/batch = 0.5066s	
1526/2700 (epoch 28.259), train_loss = 1.11332584, grad/param norm = 1.3861e-01, time/batch = 0.5083s	
1527/2700 (epoch 28.278), train_loss = 1.20400956, grad/param norm = 1.5188e-01, time/batch = 0.4766s	
1528/2700 (epoch 28.296), train_loss = 1.17311266, grad/param norm = 1.6394e-01, time/batch = 0.4805s	
1529/2700 (epoch 28.315), train_loss = 1.16582660, grad/param norm = 1.8540e-01, time/batch = 0.4168s	
1530/2700 (epoch 28.333), train_loss = 1.15573829, grad/param norm = 1.7353e-01, time/batch = 0.5179s	
1531/2700 (epoch 28.352), train_loss = 1.13971028, grad/param norm = 1.3073e-01, time/batch = 0.5155s	
1532/2700 (epoch 28.370), train_loss = 1.14691530, grad/param norm = 1.5675e-01, time/batch = 0.5122s	
1533/2700 (epoch 28.389), train_loss = 1.16653603, grad/param norm = 1.5409e-01, time/batch = 0.4996s	
1534/2700 (epoch 28.407), train_loss = 1.23078774, grad/param norm = 1.6224e-01, time/batch = 0.5002s	
1535/2700 (epoch 28.426), train_loss = 1.20354139, grad/param norm = 1.5349e-01, time/batch = 0.4889s	
1536/2700 (epoch 28.444), train_loss = 1.13972783, grad/param norm = 1.3891e-01, time/batch = 0.4662s	
1537/2700 (epoch 28.463), train_loss = 1.18955027, grad/param norm = 1.4016e-01, time/batch = 0.4818s	
1538/2700 (epoch 28.481), train_loss = 1.15560244, grad/param norm = 1.4384e-01, time/batch = 0.4743s	
1539/2700 (epoch 28.500), train_loss = 1.14020510, grad/param norm = 1.4214e-01, time/batch = 0.4893s	
1540/2700 (epoch 28.519), train_loss = 1.19357052, grad/param norm = 1.8685e-01, time/batch = 0.4862s	
1541/2700 (epoch 28.537), train_loss = 1.22289560, grad/param norm = 1.9914e-01, time/batch = 0.5110s	
1542/2700 (epoch 28.556), train_loss = 1.13599171, grad/param norm = 1.7664e-01, time/batch = 0.5109s	
1543/2700 (epoch 28.574), train_loss = 1.15145314, grad/param norm = 1.6874e-01, time/batch = 0.4950s	
1544/2700 (epoch 28.593), train_loss = 1.19329569, grad/param norm = 1.8094e-01, time/batch = 0.4540s	
1545/2700 (epoch 28.611), train_loss = 1.09941699, grad/param norm = 1.4158e-01, time/batch = 0.4724s	
1546/2700 (epoch 28.630), train_loss = 1.12010664, grad/param norm = 1.4551e-01, time/batch = 0.4563s	
1547/2700 (epoch 28.648), train_loss = 1.14431557, grad/param norm = 1.5601e-01, time/batch = 0.4874s	
1548/2700 (epoch 28.667), train_loss = 1.14727805, grad/param norm = 1.4627e-01, time/batch = 0.5104s	
1549/2700 (epoch 28.685), train_loss = 1.17727627, grad/param norm = 1.5641e-01, time/batch = 0.5084s	
1550/2700 (epoch 28.704), train_loss = 1.18422184, grad/param norm = 1.5202e-01, time/batch = 0.5159s	
1551/2700 (epoch 28.722), train_loss = 1.15306948, grad/param norm = 1.9463e-01, time/batch = 0.5073s	
1552/2700 (epoch 28.741), train_loss = 1.16008118, grad/param norm = 1.9052e-01, time/batch = 0.4992s	
1553/2700 (epoch 28.759), train_loss = 1.15370637, grad/param norm = 1.6907e-01, time/batch = 0.4629s	
1554/2700 (epoch 28.778), train_loss = 1.20921411, grad/param norm = 1.7506e-01, time/batch = 0.4633s	
1555/2700 (epoch 28.796), train_loss = 1.15077938, grad/param norm = 1.9847e-01, time/batch = 0.4030s	
1556/2700 (epoch 28.815), train_loss = 1.17215611, grad/param norm = 1.2892e-01, time/batch = 0.4873s	
1557/2700 (epoch 28.833), train_loss = 1.15847668, grad/param norm = 1.4851e-01, time/batch = 0.5177s	
1558/2700 (epoch 28.852), train_loss = 1.12424827, grad/param norm = 1.4691e-01, time/batch = 0.5199s	
1559/2700 (epoch 28.870), train_loss = 1.15536570, grad/param norm = 1.3797e-01, time/batch = 0.5056s	
1560/2700 (epoch 28.889), train_loss = 1.14953245, grad/param norm = 1.5239e-01, time/batch = 0.5064s	
1561/2700 (epoch 28.907), train_loss = 1.22256815, grad/param norm = 1.5908e-01, time/batch = 0.5094s	
1562/2700 (epoch 28.926), train_loss = 1.17873795, grad/param norm = 1.4518e-01, time/batch = 0.5124s	
1563/2700 (epoch 28.944), train_loss = 1.15626860, grad/param norm = 1.5390e-01, time/batch = 0.4816s	
1564/2700 (epoch 28.963), train_loss = 1.18336279, grad/param norm = 2.1420e-01, time/batch = 0.4041s	
1565/2700 (epoch 28.981), train_loss = 1.16079741, grad/param norm = 1.6829e-01, time/batch = 0.4833s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
1566/2700 (epoch 29.000), train_loss = 1.18693588, grad/param norm = 1.6933e-01, time/batch = 0.4898s	
1567/2700 (epoch 29.019), train_loss = 1.26938899, grad/param norm = 1.6302e-01, time/batch = 0.5169s	
1568/2700 (epoch 29.037), train_loss = 1.18297540, grad/param norm = 1.4401e-01, time/batch = 0.5126s	
1569/2700 (epoch 29.056), train_loss = 1.15688788, grad/param norm = 1.4651e-01, time/batch = 0.5055s	
1570/2700 (epoch 29.074), train_loss = 1.14196111, grad/param norm = 1.4987e-01, time/batch = 0.5080s	
1571/2700 (epoch 29.093), train_loss = 1.12245556, grad/param norm = 1.2459e-01, time/batch = 0.5198s	
1572/2700 (epoch 29.111), train_loss = 1.09411743, grad/param norm = 1.1581e-01, time/batch = 0.5196s	
1573/2700 (epoch 29.130), train_loss = 1.13716470, grad/param norm = 1.3292e-01, time/batch = 0.4291s	
1574/2700 (epoch 29.148), train_loss = 1.11797412, grad/param norm = 1.4918e-01, time/batch = 0.4161s	
1575/2700 (epoch 29.167), train_loss = 1.16696808, grad/param norm = 1.2708e-01, time/batch = 0.4931s	
1576/2700 (epoch 29.185), train_loss = 1.11863286, grad/param norm = 1.3817e-01, time/batch = 0.5206s	
1577/2700 (epoch 29.204), train_loss = 1.14453775, grad/param norm = 1.4847e-01, time/batch = 0.5193s	
1578/2700 (epoch 29.222), train_loss = 1.10680086, grad/param norm = 1.7779e-01, time/batch = 0.5045s	
1579/2700 (epoch 29.241), train_loss = 1.07727331, grad/param norm = 1.7294e-01, time/batch = 0.5064s	
1580/2700 (epoch 29.259), train_loss = 1.07803277, grad/param norm = 1.4866e-01, time/batch = 0.5077s	
1581/2700 (epoch 29.278), train_loss = 1.15584188, grad/param norm = 1.2962e-01, time/batch = 0.5203s	
1582/2700 (epoch 29.296), train_loss = 1.12418690, grad/param norm = 1.4997e-01, time/batch = 0.4709s	
1583/2700 (epoch 29.315), train_loss = 1.11554417, grad/param norm = 1.8468e-01, time/batch = 0.4874s	
1584/2700 (epoch 29.333), train_loss = 1.11711233, grad/param norm = 1.9250e-01, time/batch = 0.4680s	
1585/2700 (epoch 29.352), train_loss = 1.11491537, grad/param norm = 1.7326e-01, time/batch = 0.4289s	
1586/2700 (epoch 29.370), train_loss = 1.10159268, grad/param norm = 1.4380e-01, time/batch = 0.5227s	
1587/2700 (epoch 29.389), train_loss = 1.12612952, grad/param norm = 1.5854e-01, time/batch = 0.5078s	
1588/2700 (epoch 29.407), train_loss = 1.19922134, grad/param norm = 1.5830e-01, time/batch = 0.5130s	
1589/2700 (epoch 29.426), train_loss = 1.17651580, grad/param norm = 1.7400e-01, time/batch = 0.5010s	
1590/2700 (epoch 29.444), train_loss = 1.12148992, grad/param norm = 1.6120e-01, time/batch = 0.4861s	
1591/2700 (epoch 29.463), train_loss = 1.14563978, grad/param norm = 1.3270e-01, time/batch = 0.4706s	
1592/2700 (epoch 29.481), train_loss = 1.11091687, grad/param norm = 1.3214e-01, time/batch = 0.4780s	
1593/2700 (epoch 29.500), train_loss = 1.10796530, grad/param norm = 1.6876e-01, time/batch = 0.4734s	
1594/2700 (epoch 29.519), train_loss = 1.16506614, grad/param norm = 1.8286e-01, time/batch = 0.4830s	
1595/2700 (epoch 29.537), train_loss = 1.16954408, grad/param norm = 1.7498e-01, time/batch = 0.5120s	
1596/2700 (epoch 29.556), train_loss = 1.08449302, grad/param norm = 1.3992e-01, time/batch = 0.5084s	
1597/2700 (epoch 29.574), train_loss = 1.10990822, grad/param norm = 1.7700e-01, time/batch = 0.4965s	
1598/2700 (epoch 29.593), train_loss = 1.16182391, grad/param norm = 1.7437e-01, time/batch = 0.4983s	
1599/2700 (epoch 29.611), train_loss = 1.06860433, grad/param norm = 1.6070e-01, time/batch = 0.4856s	
1600/2700 (epoch 29.630), train_loss = 1.09842469, grad/param norm = 1.4929e-01, time/batch = 0.4659s	
1601/2700 (epoch 29.648), train_loss = 1.10872925, grad/param norm = 1.4936e-01, time/batch = 0.4835s	
1602/2700 (epoch 29.667), train_loss = 1.11573123, grad/param norm = 1.5537e-01, time/batch = 0.4508s	
1603/2700 (epoch 29.685), train_loss = 1.13459843, grad/param norm = 1.4634e-01, time/batch = 0.4745s	
1604/2700 (epoch 29.704), train_loss = 1.14437351, grad/param norm = 1.5962e-01, time/batch = 0.5137s	
1605/2700 (epoch 29.722), train_loss = 1.10505656, grad/param norm = 1.7285e-01, time/batch = 0.5217s	
1606/2700 (epoch 29.741), train_loss = 1.10872716, grad/param norm = 1.5113e-01, time/batch = 0.5141s	
1607/2700 (epoch 29.759), train_loss = 1.10380841, grad/param norm = 1.4142e-01, time/batch = 0.4919s	
1608/2700 (epoch 29.778), train_loss = 1.16458424, grad/param norm = 1.6237e-01, time/batch = 0.4974s	
1609/2700 (epoch 29.796), train_loss = 1.11058388, grad/param norm = 1.8039e-01, time/batch = 0.4592s	
1610/2700 (epoch 29.815), train_loss = 1.15879655, grad/param norm = 1.9194e-01, time/batch = 0.4816s	
1611/2700 (epoch 29.833), train_loss = 1.14226615, grad/param norm = 1.8771e-01, time/batch = 0.4610s	
1612/2700 (epoch 29.852), train_loss = 1.09426822, grad/param norm = 1.6899e-01, time/batch = 0.4789s	
1613/2700 (epoch 29.870), train_loss = 1.13269649, grad/param norm = 1.7570e-01, time/batch = 0.4759s	
1614/2700 (epoch 29.889), train_loss = 1.12116696, grad/param norm = 1.7721e-01, time/batch = 0.4983s	
1615/2700 (epoch 29.907), train_loss = 1.18377112, grad/param norm = 1.5496e-01, time/batch = 0.5188s	
1616/2700 (epoch 29.926), train_loss = 1.14034703, grad/param norm = 1.5382e-01, time/batch = 0.5209s	
1617/2700 (epoch 29.944), train_loss = 1.11885704, grad/param norm = 1.5105e-01, time/batch = 0.5079s	
1618/2700 (epoch 29.963), train_loss = 1.14738262, grad/param norm = 1.7592e-01, time/batch = 0.5065s	
1619/2700 (epoch 29.981), train_loss = 1.13190258, grad/param norm = 1.8998e-01, time/batch = 0.4079s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
1620/2700 (epoch 30.000), train_loss = 1.14414831, grad/param norm = 1.5653e-01, time/batch = 0.4756s	
1621/2700 (epoch 30.019), train_loss = 1.22124444, grad/param norm = 1.3763e-01, time/batch = 0.4771s	
1622/2700 (epoch 30.037), train_loss = 1.14271876, grad/param norm = 1.4178e-01, time/batch = 0.5022s	
1623/2700 (epoch 30.056), train_loss = 1.11652776, grad/param norm = 1.5712e-01, time/batch = 0.5086s	
1624/2700 (epoch 30.074), train_loss = 1.09529872, grad/param norm = 1.3719e-01, time/batch = 0.5154s	
1625/2700 (epoch 30.093), train_loss = 1.08883155, grad/param norm = 1.3730e-01, time/batch = 0.5230s	
1626/2700 (epoch 30.111), train_loss = 1.07493579, grad/param norm = 1.5109e-01, time/batch = 0.5226s	
1627/2700 (epoch 30.130), train_loss = 1.11260400, grad/param norm = 1.5965e-01, time/batch = 0.4972s	
1628/2700 (epoch 30.148), train_loss = 1.09454577, grad/param norm = 1.5161e-01, time/batch = 0.4251s	
1629/2700 (epoch 30.167), train_loss = 1.14307692, grad/param norm = 1.5476e-01, time/batch = 0.4601s	
1630/2700 (epoch 30.185), train_loss = 1.08459961, grad/param norm = 1.2936e-01, time/batch = 0.4456s	
1631/2700 (epoch 30.204), train_loss = 1.11801077, grad/param norm = 1.5407e-01, time/batch = 0.4986s	
1632/2700 (epoch 30.222), train_loss = 1.08541731, grad/param norm = 1.7680e-01, time/batch = 0.5114s	
1633/2700 (epoch 30.241), train_loss = 1.05400923, grad/param norm = 1.7433e-01, time/batch = 0.5233s	
1634/2700 (epoch 30.259), train_loss = 1.07095213, grad/param norm = 2.0501e-01, time/batch = 0.5222s	
1635/2700 (epoch 30.278), train_loss = 1.12538052, grad/param norm = 1.5326e-01, time/batch = 0.5092s	
1636/2700 (epoch 30.296), train_loss = 1.08622232, grad/param norm = 1.4950e-01, time/batch = 0.4913s	
1637/2700 (epoch 30.315), train_loss = 1.07142642, grad/param norm = 1.6774e-01, time/batch = 0.4246s	
1638/2700 (epoch 30.333), train_loss = 1.07209461, grad/param norm = 1.6460e-01, time/batch = 0.4772s	
1639/2700 (epoch 30.352), train_loss = 1.07622618, grad/param norm = 1.9412e-01, time/batch = 0.4708s	
1640/2700 (epoch 30.370), train_loss = 1.07582108, grad/param norm = 1.9955e-01, time/batch = 0.4905s	
1641/2700 (epoch 30.389), train_loss = 1.09710912, grad/param norm = 1.8865e-01, time/batch = 0.4559s	
1642/2700 (epoch 30.407), train_loss = 1.16700768, grad/param norm = 1.8771e-01, time/batch = 0.5072s	
1643/2700 (epoch 30.426), train_loss = 1.12888266, grad/param norm = 1.6421e-01, time/batch = 0.5177s	
1644/2700 (epoch 30.444), train_loss = 1.07125661, grad/param norm = 1.3662e-01, time/batch = 0.5198s	
1645/2700 (epoch 30.463), train_loss = 1.11615155, grad/param norm = 1.4408e-01, time/batch = 0.5131s	
1646/2700 (epoch 30.481), train_loss = 1.07809061, grad/param norm = 1.4722e-01, time/batch = 0.4177s	
1647/2700 (epoch 30.500), train_loss = 1.05885041, grad/param norm = 1.3331e-01, time/batch = 0.5000s	
1648/2700 (epoch 30.519), train_loss = 1.10512630, grad/param norm = 1.4261e-01, time/batch = 0.4743s	
1649/2700 (epoch 30.537), train_loss = 1.11836754, grad/param norm = 1.4697e-01, time/batch = 0.4754s	
1650/2700 (epoch 30.556), train_loss = 1.04571521, grad/param norm = 1.6337e-01, time/batch = 0.4955s	
1651/2700 (epoch 30.574), train_loss = 1.07552147, grad/param norm = 1.6762e-01, time/batch = 0.4809s	
1652/2700 (epoch 30.593), train_loss = 1.10350887, grad/param norm = 1.6112e-01, time/batch = 0.4787s	
1653/2700 (epoch 30.611), train_loss = 1.02329198, grad/param norm = 1.4591e-01, time/batch = 0.5194s	
1654/2700 (epoch 30.630), train_loss = 1.05796349, grad/param norm = 1.5356e-01, time/batch = 0.5066s	
1655/2700 (epoch 30.648), train_loss = 1.08163237, grad/param norm = 1.6843e-01, time/batch = 0.4339s	
1656/2700 (epoch 30.667), train_loss = 1.08385554, grad/param norm = 1.8183e-01, time/batch = 0.4700s	
1657/2700 (epoch 30.685), train_loss = 1.10862286, grad/param norm = 1.5280e-01, time/batch = 0.4758s	
1658/2700 (epoch 30.704), train_loss = 1.11657670, grad/param norm = 1.7304e-01, time/batch = 0.5007s	
1659/2700 (epoch 30.722), train_loss = 1.08341539, grad/param norm = 2.0745e-01, time/batch = 0.5109s	
1660/2700 (epoch 30.741), train_loss = 1.08379093, grad/param norm = 1.8783e-01, time/batch = 0.5081s	
1661/2700 (epoch 30.759), train_loss = 1.07047102, grad/param norm = 1.6742e-01, time/batch = 0.5011s	
1662/2700 (epoch 30.778), train_loss = 1.13162221, grad/param norm = 1.9003e-01, time/batch = 0.5155s	
1663/2700 (epoch 30.796), train_loss = 1.09514200, grad/param norm = 2.2506e-01, time/batch = 0.5092s	
1664/2700 (epoch 30.815), train_loss = 1.11877936, grad/param norm = 1.6055e-01, time/batch = 0.4476s	
1665/2700 (epoch 30.833), train_loss = 1.09555495, grad/param norm = 1.5488e-01, time/batch = 0.4873s	
1666/2700 (epoch 30.852), train_loss = 1.05668102, grad/param norm = 1.5802e-01, time/batch = 0.4858s	
1667/2700 (epoch 30.870), train_loss = 1.09797099, grad/param norm = 1.7415e-01, time/batch = 0.4796s	
1668/2700 (epoch 30.889), train_loss = 1.08355439, grad/param norm = 1.6088e-01, time/batch = 0.4861s	
1669/2700 (epoch 30.907), train_loss = 1.14406418, grad/param norm = 1.9638e-01, time/batch = 0.5006s	
1670/2700 (epoch 30.926), train_loss = 1.12297944, grad/param norm = 2.0790e-01, time/batch = 0.5125s	
1671/2700 (epoch 30.944), train_loss = 1.09810282, grad/param norm = 1.7321e-01, time/batch = 0.5154s	
1672/2700 (epoch 30.963), train_loss = 1.10354305, grad/param norm = 1.5776e-01, time/batch = 0.5178s	
1673/2700 (epoch 30.981), train_loss = 1.08528131, grad/param norm = 1.8487e-01, time/batch = 0.4815s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
1674/2700 (epoch 31.000), train_loss = 1.11430117, grad/param norm = 1.7837e-01, time/batch = 0.5088s	
1675/2700 (epoch 31.019), train_loss = 1.21447698, grad/param norm = 1.8877e-01, time/batch = 0.5142s	
1676/2700 (epoch 31.037), train_loss = 1.10800672, grad/param norm = 1.6552e-01, time/batch = 0.4744s	
1677/2700 (epoch 31.056), train_loss = 1.07664978, grad/param norm = 1.4258e-01, time/batch = 0.4847s	
1678/2700 (epoch 31.074), train_loss = 1.05670488, grad/param norm = 1.3373e-01, time/batch = 0.4786s	
1679/2700 (epoch 31.093), train_loss = 1.05041280, grad/param norm = 1.3202e-01, time/batch = 0.4837s	
1680/2700 (epoch 31.111), train_loss = 1.03389304, grad/param norm = 1.3942e-01, time/batch = 0.5046s	
1681/2700 (epoch 31.130), train_loss = 1.07137172, grad/param norm = 1.5087e-01, time/batch = 0.5445s	
1682/2700 (epoch 31.148), train_loss = 1.05345806, grad/param norm = 1.5559e-01, time/batch = 0.4740s	
1683/2700 (epoch 31.167), train_loss = 1.11262734, grad/param norm = 1.5989e-01, time/batch = 0.5170s	
1684/2700 (epoch 31.185), train_loss = 1.06524976, grad/param norm = 1.7602e-01, time/batch = 0.5096s	
1685/2700 (epoch 31.204), train_loss = 1.08389714, grad/param norm = 1.6064e-01, time/batch = 0.4843s	
1686/2700 (epoch 31.222), train_loss = 1.02566156, grad/param norm = 1.4827e-01, time/batch = 0.4819s	
1687/2700 (epoch 31.241), train_loss = 1.00715204, grad/param norm = 1.4072e-01, time/batch = 0.4749s	
1688/2700 (epoch 31.259), train_loss = 1.02622259, grad/param norm = 1.7238e-01, time/batch = 0.4818s	
1689/2700 (epoch 31.278), train_loss = 1.09399759, grad/param norm = 1.5981e-01, time/batch = 0.4797s	
1690/2700 (epoch 31.296), train_loss = 1.06086102, grad/param norm = 1.8136e-01, time/batch = 0.4984s	
1691/2700 (epoch 31.315), train_loss = 1.04324414, grad/param norm = 1.7495e-01, time/batch = 0.4697s	
1692/2700 (epoch 31.333), train_loss = 1.03970408, grad/param norm = 1.7976e-01, time/batch = 0.5126s	
1693/2700 (epoch 31.352), train_loss = 1.02964601, grad/param norm = 1.5537e-01, time/batch = 0.5118s	
1694/2700 (epoch 31.370), train_loss = 1.02556062, grad/param norm = 1.6859e-01, time/batch = 0.5166s	
1695/2700 (epoch 31.389), train_loss = 1.06583432, grad/param norm = 2.1280e-01, time/batch = 0.5095s	
1696/2700 (epoch 31.407), train_loss = 1.12915420, grad/param norm = 1.8812e-01, time/batch = 0.4952s	
1697/2700 (epoch 31.426), train_loss = 1.09975916, grad/param norm = 1.9430e-01, time/batch = 0.4065s	
1698/2700 (epoch 31.444), train_loss = 1.05948544, grad/param norm = 1.7984e-01, time/batch = 0.5094s	
1699/2700 (epoch 31.463), train_loss = 1.08638632, grad/param norm = 1.7259e-01, time/batch = 0.5081s	
1700/2700 (epoch 31.481), train_loss = 1.04552228, grad/param norm = 1.5220e-01, time/batch = 0.4961s	
1701/2700 (epoch 31.500), train_loss = 1.04215223, grad/param norm = 1.7636e-01, time/batch = 0.5227s	
1702/2700 (epoch 31.519), train_loss = 1.08331659, grad/param norm = 1.6817e-01, time/batch = 0.4860s	
1703/2700 (epoch 31.537), train_loss = 1.08523727, grad/param norm = 1.6823e-01, time/batch = 0.5092s	
1704/2700 (epoch 31.556), train_loss = 1.00561179, grad/param norm = 1.5304e-01, time/batch = 0.4739s	
1705/2700 (epoch 31.574), train_loss = 1.03627684, grad/param norm = 1.7799e-01, time/batch = 0.4652s	
1706/2700 (epoch 31.593), train_loss = 1.07535284, grad/param norm = 1.7163e-01, time/batch = 0.4917s	
1707/2700 (epoch 31.611), train_loss = 0.99266291, grad/param norm = 1.4876e-01, time/batch = 0.4816s	
1708/2700 (epoch 31.630), train_loss = 1.02534013, grad/param norm = 1.5932e-01, time/batch = 0.4826s	
1709/2700 (epoch 31.648), train_loss = 1.03555752, grad/param norm = 1.5246e-01, time/batch = 0.4923s	
1710/2700 (epoch 31.667), train_loss = 1.03999433, grad/param norm = 1.4786e-01, time/batch = 0.5121s	
1711/2700 (epoch 31.685), train_loss = 1.06765921, grad/param norm = 1.6540e-01, time/batch = 0.4961s	
1712/2700 (epoch 31.704), train_loss = 1.07784759, grad/param norm = 1.6703e-01, time/batch = 0.5101s	
1713/2700 (epoch 31.722), train_loss = 1.03214057, grad/param norm = 1.6337e-01, time/batch = 0.5001s	
1714/2700 (epoch 31.741), train_loss = 1.05526665, grad/param norm = 1.8588e-01, time/batch = 0.4786s	
1715/2700 (epoch 31.759), train_loss = 1.03677154, grad/param norm = 1.7837e-01, time/batch = 0.4821s	
1716/2700 (epoch 31.778), train_loss = 1.10664328, grad/param norm = 1.8931e-01, time/batch = 0.4626s	
1717/2700 (epoch 31.796), train_loss = 1.03996703, grad/param norm = 1.7898e-01, time/batch = 0.4822s	
1718/2700 (epoch 31.815), train_loss = 1.07612664, grad/param norm = 1.5789e-01, time/batch = 0.4859s	
1719/2700 (epoch 31.833), train_loss = 1.06579349, grad/param norm = 1.8437e-01, time/batch = 0.4946s	
1720/2700 (epoch 31.852), train_loss = 1.02136462, grad/param norm = 1.4898e-01, time/batch = 0.5027s	
1721/2700 (epoch 31.870), train_loss = 1.05740479, grad/param norm = 1.4993e-01, time/batch = 0.5200s	
1722/2700 (epoch 31.889), train_loss = 1.04394645, grad/param norm = 1.6300e-01, time/batch = 0.5132s	
1723/2700 (epoch 31.907), train_loss = 1.10309426, grad/param norm = 1.5898e-01, time/batch = 0.5288s	
1724/2700 (epoch 31.926), train_loss = 1.07293150, grad/param norm = 1.8413e-01, time/batch = 0.4619s	
1725/2700 (epoch 31.944), train_loss = 1.07426743, grad/param norm = 2.4805e-01, time/batch = 0.4988s	
1726/2700 (epoch 31.963), train_loss = 1.08694428, grad/param norm = 2.1020e-01, time/batch = 0.4790s	
1727/2700 (epoch 31.981), train_loss = 1.04747229, grad/param norm = 1.7550e-01, time/batch = 0.4698s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
1728/2700 (epoch 32.000), train_loss = 1.07861336, grad/param norm = 2.0474e-01, time/batch = 0.5012s	
1729/2700 (epoch 32.019), train_loss = 1.16748412, grad/param norm = 1.6700e-01, time/batch = 0.5063s	
1730/2700 (epoch 32.037), train_loss = 1.06892664, grad/param norm = 1.5205e-01, time/batch = 0.4945s	
1731/2700 (epoch 32.056), train_loss = 1.05576129, grad/param norm = 1.6957e-01, time/batch = 0.5041s	
1732/2700 (epoch 32.074), train_loss = 1.03480106, grad/param norm = 1.7135e-01, time/batch = 0.5001s	
1733/2700 (epoch 32.093), train_loss = 1.02580434, grad/param norm = 1.5239e-01, time/batch = 0.4688s	
1734/2700 (epoch 32.111), train_loss = 1.00103806, grad/param norm = 1.3391e-01, time/batch = 0.4706s	
1735/2700 (epoch 32.130), train_loss = 1.03598433, grad/param norm = 1.5048e-01, time/batch = 0.4797s	
1736/2700 (epoch 32.148), train_loss = 1.01902725, grad/param norm = 1.3642e-01, time/batch = 0.4836s	
1737/2700 (epoch 32.167), train_loss = 1.06335670, grad/param norm = 1.4187e-01, time/batch = 0.5106s	
1738/2700 (epoch 32.185), train_loss = 1.02347553, grad/param norm = 1.6137e-01, time/batch = 0.5048s	
1739/2700 (epoch 32.204), train_loss = 1.05003979, grad/param norm = 1.5518e-01, time/batch = 0.5119s	
1740/2700 (epoch 32.222), train_loss = 1.00323676, grad/param norm = 1.6681e-01, time/batch = 0.5200s	
1741/2700 (epoch 32.241), train_loss = 0.98294197, grad/param norm = 1.7520e-01, time/batch = 0.5018s	
1742/2700 (epoch 32.259), train_loss = 1.00173223, grad/param norm = 1.7335e-01, time/batch = 0.4778s	
1743/2700 (epoch 32.278), train_loss = 1.04879521, grad/param norm = 1.3917e-01, time/batch = 0.4574s	
1744/2700 (epoch 32.296), train_loss = 1.02089163, grad/param norm = 1.7203e-01, time/batch = 0.4644s	
1745/2700 (epoch 32.315), train_loss = 1.00860316, grad/param norm = 1.9348e-01, time/batch = 0.4750s	
1746/2700 (epoch 32.333), train_loss = 1.01282236, grad/param norm = 1.9104e-01, time/batch = 0.4624s	
1747/2700 (epoch 32.352), train_loss = 1.00175457, grad/param norm = 1.6817e-01, time/batch = 0.4957s	
1748/2700 (epoch 32.370), train_loss = 0.98914173, grad/param norm = 1.5015e-01, time/batch = 0.5110s	
1749/2700 (epoch 32.389), train_loss = 1.01470809, grad/param norm = 1.5837e-01, time/batch = 0.5052s	
1750/2700 (epoch 32.407), train_loss = 1.08170909, grad/param norm = 1.6006e-01, time/batch = 0.5074s	
1751/2700 (epoch 32.426), train_loss = 1.05300390, grad/param norm = 1.8131e-01, time/batch = 0.5196s	
1752/2700 (epoch 32.444), train_loss = 1.01720550, grad/param norm = 1.6276e-01, time/batch = 0.5086s	
1753/2700 (epoch 32.463), train_loss = 1.03772143, grad/param norm = 1.5369e-01, time/batch = 0.5076s	
1754/2700 (epoch 32.481), train_loss = 1.01370080, grad/param norm = 1.6900e-01, time/batch = 0.4599s	
1755/2700 (epoch 32.500), train_loss = 1.00728018, grad/param norm = 1.6638e-01, time/batch = 0.4512s	
1756/2700 (epoch 32.519), train_loss = 1.05856939, grad/param norm = 1.8302e-01, time/batch = 0.4780s	
1757/2700 (epoch 32.537), train_loss = 1.05830296, grad/param norm = 1.7625e-01, time/batch = 0.5039s	
1758/2700 (epoch 32.556), train_loss = 0.98262545, grad/param norm = 1.8534e-01, time/batch = 0.5095s	
1759/2700 (epoch 32.574), train_loss = 1.00719214, grad/param norm = 1.8044e-01, time/batch = 0.5068s	
1760/2700 (epoch 32.593), train_loss = 1.04543947, grad/param norm = 1.8934e-01, time/batch = 0.5102s	
1761/2700 (epoch 32.611), train_loss = 0.98417747, grad/param norm = 2.3481e-01, time/batch = 0.5182s	
1762/2700 (epoch 32.630), train_loss = 1.01189921, grad/param norm = 2.0044e-01, time/batch = 0.5084s	
1763/2700 (epoch 32.648), train_loss = 1.01038168, grad/param norm = 1.6669e-01, time/batch = 0.4887s	
1764/2700 (epoch 32.667), train_loss = 1.00811423, grad/param norm = 1.6643e-01, time/batch = 0.3433s	
1765/2700 (epoch 32.685), train_loss = 1.03444030, grad/param norm = 1.5149e-01, time/batch = 0.4745s	
1766/2700 (epoch 32.704), train_loss = 1.04053011, grad/param norm = 1.4996e-01, time/batch = 0.5089s	
1767/2700 (epoch 32.722), train_loss = 0.99780615, grad/param norm = 1.5408e-01, time/batch = 0.5208s	
1768/2700 (epoch 32.741), train_loss = 1.01147391, grad/param norm = 1.8584e-01, time/batch = 0.5013s	
1769/2700 (epoch 32.759), train_loss = 1.00353664, grad/param norm = 1.8096e-01, time/batch = 0.5056s	
1770/2700 (epoch 32.778), train_loss = 1.06010939, grad/param norm = 1.8058e-01, time/batch = 0.5070s	
1771/2700 (epoch 32.796), train_loss = 0.99708506, grad/param norm = 1.6175e-01, time/batch = 0.5099s	
1772/2700 (epoch 32.815), train_loss = 1.05023872, grad/param norm = 2.0349e-01, time/batch = 0.5181s	
1773/2700 (epoch 32.833), train_loss = 1.04306054, grad/param norm = 1.8495e-01, time/batch = 0.4584s	
1774/2700 (epoch 32.852), train_loss = 0.98586050, grad/param norm = 1.5267e-01, time/batch = 0.4811s	
1775/2700 (epoch 32.870), train_loss = 1.01736143, grad/param norm = 1.4225e-01, time/batch = 0.4296s	
1776/2700 (epoch 32.889), train_loss = 1.00668545, grad/param norm = 1.5631e-01, time/batch = 0.5066s	
1777/2700 (epoch 32.907), train_loss = 1.08107707, grad/param norm = 2.0606e-01, time/batch = 0.5209s	
1778/2700 (epoch 32.926), train_loss = 1.05417697, grad/param norm = 2.2246e-01, time/batch = 0.5101s	
1779/2700 (epoch 32.944), train_loss = 1.03469421, grad/param norm = 1.8334e-01, time/batch = 0.5045s	
1780/2700 (epoch 32.963), train_loss = 1.04218651, grad/param norm = 1.7059e-01, time/batch = 0.5076s	
1781/2700 (epoch 32.981), train_loss = 1.00828296, grad/param norm = 1.6701e-01, time/batch = 0.5168s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
1782/2700 (epoch 33.000), train_loss = 1.02603938, grad/param norm = 1.6428e-01, time/batch = 0.4742s	
1783/2700 (epoch 33.019), train_loss = 1.13482350, grad/param norm = 1.7469e-01, time/batch = 0.5147s	
1784/2700 (epoch 33.037), train_loss = 1.03387992, grad/param norm = 1.6135e-01, time/batch = 0.4934s	
1785/2700 (epoch 33.056), train_loss = 1.01221089, grad/param norm = 1.6183e-01, time/batch = 0.4692s	
1786/2700 (epoch 33.074), train_loss = 0.99739391, grad/param norm = 1.5240e-01, time/batch = 0.4148s	
1787/2700 (epoch 33.093), train_loss = 0.98422746, grad/param norm = 1.3530e-01, time/batch = 0.5207s	
1788/2700 (epoch 33.111), train_loss = 0.96499741, grad/param norm = 1.3965e-01, time/batch = 0.5084s	
1789/2700 (epoch 33.130), train_loss = 1.00429323, grad/param norm = 1.7388e-01, time/batch = 0.5038s	
1790/2700 (epoch 33.148), train_loss = 0.98354515, grad/param norm = 1.6346e-01, time/batch = 0.5070s	
1791/2700 (epoch 33.167), train_loss = 1.04450425, grad/param norm = 1.8856e-01, time/batch = 0.4928s	
1792/2700 (epoch 33.185), train_loss = 0.98898990, grad/param norm = 1.6996e-01, time/batch = 0.5115s	
1793/2700 (epoch 33.204), train_loss = 1.00583113, grad/param norm = 1.3883e-01, time/batch = 0.4585s	
1794/2700 (epoch 33.222), train_loss = 0.96151288, grad/param norm = 1.7116e-01, time/batch = 0.4783s	
1795/2700 (epoch 33.241), train_loss = 0.93879647, grad/param norm = 1.4418e-01, time/batch = 0.4752s	
1796/2700 (epoch 33.259), train_loss = 0.95240520, grad/param norm = 1.5383e-01, time/batch = 0.4704s	
1797/2700 (epoch 33.278), train_loss = 1.02277707, grad/param norm = 1.6783e-01, time/batch = 0.4759s	
1798/2700 (epoch 33.296), train_loss = 0.98278689, grad/param norm = 1.6042e-01, time/batch = 0.5077s	
1799/2700 (epoch 33.315), train_loss = 0.97526740, grad/param norm = 1.7449e-01, time/batch = 0.5036s	
1800/2700 (epoch 33.333), train_loss = 0.97373482, grad/param norm = 1.8137e-01, time/batch = 0.5050s	
1801/2700 (epoch 33.352), train_loss = 0.97541123, grad/param norm = 1.8843e-01, time/batch = 0.5096s	
1802/2700 (epoch 33.370), train_loss = 0.96700829, grad/param norm = 2.0015e-01, time/batch = 0.4541s	
1803/2700 (epoch 33.389), train_loss = 0.98913500, grad/param norm = 1.7276e-01, time/batch = 0.5014s	
1804/2700 (epoch 33.407), train_loss = 1.05691529, grad/param norm = 1.7637e-01, time/batch = 0.4779s	
1805/2700 (epoch 33.426), train_loss = 1.01852657, grad/param norm = 1.6227e-01, time/batch = 0.4848s	
1806/2700 (epoch 33.444), train_loss = 0.97598748, grad/param norm = 1.5353e-01, time/batch = 0.4756s	
1807/2700 (epoch 33.463), train_loss = 1.01393927, grad/param norm = 1.7223e-01, time/batch = 0.4886s	
1808/2700 (epoch 33.481), train_loss = 0.98284803, grad/param norm = 1.8302e-01, time/batch = 0.4941s	
1809/2700 (epoch 33.500), train_loss = 0.98500610, grad/param norm = 2.0681e-01, time/batch = 0.5036s	
1810/2700 (epoch 33.519), train_loss = 1.03036457, grad/param norm = 2.1171e-01, time/batch = 0.4491s	
1811/2700 (epoch 33.537), train_loss = 1.03118274, grad/param norm = 1.8756e-01, time/batch = 0.5093s	
1812/2700 (epoch 33.556), train_loss = 0.93754280, grad/param norm = 1.6112e-01, time/batch = 0.4598s	
1813/2700 (epoch 33.574), train_loss = 0.96926391, grad/param norm = 1.7747e-01, time/batch = 0.4205s	
1814/2700 (epoch 33.593), train_loss = 1.01486725, grad/param norm = 1.5999e-01, time/batch = 0.4772s	
1815/2700 (epoch 33.611), train_loss = 0.92511624, grad/param norm = 1.5235e-01, time/batch = 0.4807s	
1816/2700 (epoch 33.630), train_loss = 0.96563164, grad/param norm = 1.6232e-01, time/batch = 0.4724s	
1817/2700 (epoch 33.648), train_loss = 0.97420884, grad/param norm = 1.7796e-01, time/batch = 0.4939s	
1818/2700 (epoch 33.667), train_loss = 0.97633990, grad/param norm = 1.7009e-01, time/batch = 0.5088s	
1819/2700 (epoch 33.685), train_loss = 1.00706529, grad/param norm = 1.8112e-01, time/batch = 0.4675s	
1820/2700 (epoch 33.704), train_loss = 1.01095069, grad/param norm = 1.8235e-01, time/batch = 0.4213s	
1821/2700 (epoch 33.722), train_loss = 0.97741317, grad/param norm = 2.1512e-01, time/batch = 0.5148s	
1822/2700 (epoch 33.741), train_loss = 0.98799110, grad/param norm = 1.8531e-01, time/batch = 0.5059s	
1823/2700 (epoch 33.759), train_loss = 0.96722078, grad/param norm = 1.9988e-01, time/batch = 0.5095s	
1824/2700 (epoch 33.778), train_loss = 1.02726541, grad/param norm = 1.8782e-01, time/batch = 0.5131s	
1825/2700 (epoch 33.796), train_loss = 0.97858170, grad/param norm = 2.0651e-01, time/batch = 0.4784s	
1826/2700 (epoch 33.815), train_loss = 1.01646720, grad/param norm = 1.7347e-01, time/batch = 0.4619s	
1827/2700 (epoch 33.833), train_loss = 0.99286451, grad/param norm = 1.5501e-01, time/batch = 0.4711s	
1828/2700 (epoch 33.852), train_loss = 0.96222158, grad/param norm = 1.8696e-01, time/batch = 0.4738s	
1829/2700 (epoch 33.870), train_loss = 0.99716070, grad/param norm = 1.7915e-01, time/batch = 0.5017s	
1830/2700 (epoch 33.889), train_loss = 0.97412157, grad/param norm = 1.5638e-01, time/batch = 0.4660s	
1831/2700 (epoch 33.907), train_loss = 1.03284126, grad/param norm = 1.6889e-01, time/batch = 0.5055s	
1832/2700 (epoch 33.926), train_loss = 0.99468145, grad/param norm = 1.5736e-01, time/batch = 0.5129s	
1833/2700 (epoch 33.944), train_loss = 1.00114573, grad/param norm = 1.8809e-01, time/batch = 0.5120s	
1834/2700 (epoch 33.963), train_loss = 1.01432340, grad/param norm = 1.8598e-01, time/batch = 0.5187s	
1835/2700 (epoch 33.981), train_loss = 0.98855955, grad/param norm = 2.0448e-01, time/batch = 0.4989s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
1836/2700 (epoch 34.000), train_loss = 1.00468565, grad/param norm = 1.6519e-01, time/batch = 0.4763s	
1837/2700 (epoch 34.019), train_loss = 1.09995419, grad/param norm = 1.6947e-01, time/batch = 0.4638s	
1838/2700 (epoch 34.037), train_loss = 0.99952358, grad/param norm = 1.5163e-01, time/batch = 0.4803s	
1839/2700 (epoch 34.056), train_loss = 0.97778174, grad/param norm = 1.6075e-01, time/batch = 0.4353s	
1840/2700 (epoch 34.074), train_loss = 0.96840898, grad/param norm = 1.6914e-01, time/batch = 0.4944s	
1841/2700 (epoch 34.093), train_loss = 0.95945367, grad/param norm = 1.6729e-01, time/batch = 0.4722s	
1842/2700 (epoch 34.111), train_loss = 0.93364520, grad/param norm = 1.5694e-01, time/batch = 0.5092s	
1843/2700 (epoch 34.130), train_loss = 0.97392989, grad/param norm = 1.6331e-01, time/batch = 0.5062s	
1844/2700 (epoch 34.148), train_loss = 0.95479897, grad/param norm = 1.8436e-01, time/batch = 0.5086s	
1845/2700 (epoch 34.167), train_loss = 1.00765841, grad/param norm = 1.8944e-01, time/batch = 0.5120s	
1846/2700 (epoch 34.185), train_loss = 0.97688657, grad/param norm = 2.1718e-01, time/batch = 0.4881s	
1847/2700 (epoch 34.204), train_loss = 1.00840613, grad/param norm = 2.3809e-01, time/batch = 0.4706s	
1848/2700 (epoch 34.222), train_loss = 0.95370569, grad/param norm = 2.2939e-01, time/batch = 0.4240s	
1849/2700 (epoch 34.241), train_loss = 0.92168834, grad/param norm = 1.8666e-01, time/batch = 0.4767s	
1850/2700 (epoch 34.259), train_loss = 0.93038844, grad/param norm = 1.6846e-01, time/batch = 0.4991s	
1851/2700 (epoch 34.278), train_loss = 0.98326029, grad/param norm = 1.5020e-01, time/batch = 0.5052s	
1852/2700 (epoch 34.296), train_loss = 0.94879135, grad/param norm = 1.5381e-01, time/batch = 0.5063s	
1853/2700 (epoch 34.315), train_loss = 0.94670835, grad/param norm = 2.0502e-01, time/batch = 0.5060s	
1854/2700 (epoch 34.333), train_loss = 0.94389721, grad/param norm = 1.7700e-01, time/batch = 0.5116s	
1855/2700 (epoch 34.352), train_loss = 0.92838417, grad/param norm = 1.6839e-01, time/batch = 0.5127s	
1856/2700 (epoch 34.370), train_loss = 0.92802670, grad/param norm = 1.8492e-01, time/batch = 0.4913s	
1857/2700 (epoch 34.389), train_loss = 0.95901998, grad/param norm = 1.8370e-01, time/batch = 0.4593s	
1858/2700 (epoch 34.407), train_loss = 1.03672008, grad/param norm = 2.0118e-01, time/batch = 0.4846s	
1859/2700 (epoch 34.426), train_loss = 0.99612765, grad/param norm = 1.9896e-01, time/batch = 0.4603s	
1860/2700 (epoch 34.444), train_loss = 0.95317061, grad/param norm = 1.7156e-01, time/batch = 0.4888s	
1861/2700 (epoch 34.463), train_loss = 0.97253239, grad/param norm = 1.7921e-01, time/batch = 0.4839s	
1862/2700 (epoch 34.481), train_loss = 0.95916781, grad/param norm = 1.9594e-01, time/batch = 0.5173s	
1863/2700 (epoch 34.500), train_loss = 0.95552946, grad/param norm = 2.0403e-01, time/batch = 0.5010s	
1864/2700 (epoch 34.519), train_loss = 0.99523586, grad/param norm = 2.0170e-01, time/batch = 0.5058s	
1865/2700 (epoch 34.537), train_loss = 0.99956672, grad/param norm = 2.0153e-01, time/batch = 0.5077s	
1866/2700 (epoch 34.556), train_loss = 0.92285870, grad/param norm = 1.6881e-01, time/batch = 0.4982s	
1867/2700 (epoch 34.574), train_loss = 0.94464882, grad/param norm = 1.8275e-01, time/batch = 0.4858s	
1868/2700 (epoch 34.593), train_loss = 0.98203434, grad/param norm = 1.6475e-01, time/batch = 0.4716s	
1869/2700 (epoch 34.611), train_loss = 0.90081590, grad/param norm = 1.5515e-01, time/batch = 0.4740s	
1870/2700 (epoch 34.630), train_loss = 0.92660473, grad/param norm = 1.5400e-01, time/batch = 0.4726s	
1871/2700 (epoch 34.648), train_loss = 0.93639042, grad/param norm = 1.5787e-01, time/batch = 0.4869s	
1872/2700 (epoch 34.667), train_loss = 0.93096000, grad/param norm = 1.4095e-01, time/batch = 0.5012s	
1873/2700 (epoch 34.685), train_loss = 0.96769930, grad/param norm = 1.6109e-01, time/batch = 0.5227s	
1874/2700 (epoch 34.704), train_loss = 0.98317393, grad/param norm = 2.0852e-01, time/batch = 0.5006s	
1875/2700 (epoch 34.722), train_loss = 0.94580637, grad/param norm = 1.8943e-01, time/batch = 0.5029s	
1876/2700 (epoch 34.741), train_loss = 0.95233102, grad/param norm = 1.8407e-01, time/batch = 0.4830s	
1877/2700 (epoch 34.759), train_loss = 0.92932264, grad/param norm = 1.9131e-01, time/batch = 0.4858s	
1878/2700 (epoch 34.778), train_loss = 0.99434228, grad/param norm = 1.9216e-01, time/batch = 0.4779s	
1879/2700 (epoch 34.796), train_loss = 0.92961131, grad/param norm = 1.8441e-01, time/batch = 0.4795s	
1880/2700 (epoch 34.815), train_loss = 0.97128094, grad/param norm = 1.7692e-01, time/batch = 0.4815s	
1881/2700 (epoch 34.833), train_loss = 0.96691590, grad/param norm = 1.8299e-01, time/batch = 0.4736s	
1882/2700 (epoch 34.852), train_loss = 0.91893620, grad/param norm = 1.6115e-01, time/batch = 0.4842s	
1883/2700 (epoch 34.870), train_loss = 0.95736025, grad/param norm = 1.6436e-01, time/batch = 0.5038s	
1884/2700 (epoch 34.889), train_loss = 0.94239118, grad/param norm = 1.7350e-01, time/batch = 0.5235s	
1885/2700 (epoch 34.907), train_loss = 1.00789135, grad/param norm = 1.7814e-01, time/batch = 0.4620s	
1886/2700 (epoch 34.926), train_loss = 0.96264531, grad/param norm = 2.1378e-01, time/batch = 0.5063s	
1887/2700 (epoch 34.944), train_loss = 0.97077453, grad/param norm = 2.0850e-01, time/batch = 0.4976s	
1888/2700 (epoch 34.963), train_loss = 0.97600536, grad/param norm = 1.9321e-01, time/batch = 0.4794s	
1889/2700 (epoch 34.981), train_loss = 0.94511396, grad/param norm = 1.6810e-01, time/batch = 0.4806s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
1890/2700 (epoch 35.000), train_loss = 0.96856814, grad/param norm = 2.0291e-01, time/batch = 0.4817s	
1891/2700 (epoch 35.019), train_loss = 1.08181074, grad/param norm = 1.7062e-01, time/batch = 0.4746s	
1892/2700 (epoch 35.037), train_loss = 0.97368401, grad/param norm = 1.6417e-01, time/batch = 0.4834s	
1893/2700 (epoch 35.056), train_loss = 0.95419704, grad/param norm = 1.6361e-01, time/batch = 0.5144s	
1894/2700 (epoch 35.074), train_loss = 0.93190792, grad/param norm = 1.6323e-01, time/batch = 0.4797s	
1895/2700 (epoch 35.093), train_loss = 0.92936192, grad/param norm = 1.5093e-01, time/batch = 0.5185s	
1896/2700 (epoch 35.111), train_loss = 0.90680348, grad/param norm = 1.6812e-01, time/batch = 0.4747s	
1897/2700 (epoch 35.130), train_loss = 0.94228704, grad/param norm = 1.7808e-01, time/batch = 0.4990s	
1898/2700 (epoch 35.148), train_loss = 0.91736904, grad/param norm = 1.5907e-01, time/batch = 0.4846s	
1899/2700 (epoch 35.167), train_loss = 0.97480733, grad/param norm = 1.8742e-01, time/batch = 0.4802s	
1900/2700 (epoch 35.185), train_loss = 0.92996597, grad/param norm = 1.8418e-01, time/batch = 0.4774s	
1901/2700 (epoch 35.204), train_loss = 0.94943556, grad/param norm = 1.5331e-01, time/batch = 0.4763s	
1902/2700 (epoch 35.222), train_loss = 0.90225362, grad/param norm = 1.8052e-01, time/batch = 0.4831s	
1903/2700 (epoch 35.241), train_loss = 0.88078917, grad/param norm = 1.7310e-01, time/batch = 0.4688s	
1904/2700 (epoch 35.259), train_loss = 0.90604112, grad/param norm = 2.1185e-01, time/batch = 0.5107s	
1905/2700 (epoch 35.278), train_loss = 0.96373863, grad/param norm = 1.8906e-01, time/batch = 0.4927s	
1906/2700 (epoch 35.296), train_loss = 0.91558436, grad/param norm = 1.6770e-01, time/batch = 0.5219s	
1907/2700 (epoch 35.315), train_loss = 0.89620507, grad/param norm = 1.7087e-01, time/batch = 0.5087s	
1908/2700 (epoch 35.333), train_loss = 0.90221240, grad/param norm = 1.8380e-01, time/batch = 0.4966s	
1909/2700 (epoch 35.352), train_loss = 0.90410573, grad/param norm = 1.7699e-01, time/batch = 0.4788s	
1910/2700 (epoch 35.370), train_loss = 0.89546225, grad/param norm = 1.9425e-01, time/batch = 0.4748s	
1911/2700 (epoch 35.389), train_loss = 0.92861259, grad/param norm = 2.0058e-01, time/batch = 0.4846s	
1912/2700 (epoch 35.407), train_loss = 0.99881186, grad/param norm = 2.1118e-01, time/batch = 0.4634s	
1913/2700 (epoch 35.426), train_loss = 0.95949764, grad/param norm = 1.7661e-01, time/batch = 0.4807s	
1914/2700 (epoch 35.444), train_loss = 0.92519397, grad/param norm = 1.6233e-01, time/batch = 0.4679s	
1915/2700 (epoch 35.463), train_loss = 0.94166650, grad/param norm = 1.5057e-01, time/batch = 0.4975s	
1916/2700 (epoch 35.481), train_loss = 0.90909391, grad/param norm = 1.5127e-01, time/batch = 0.5127s	
1917/2700 (epoch 35.500), train_loss = 0.90827739, grad/param norm = 1.6104e-01, time/batch = 0.5190s	
1918/2700 (epoch 35.519), train_loss = 0.95611791, grad/param norm = 1.8580e-01, time/batch = 0.5097s	
1919/2700 (epoch 35.537), train_loss = 0.96709540, grad/param norm = 1.9700e-01, time/batch = 0.5043s	
1920/2700 (epoch 35.556), train_loss = 0.87688901, grad/param norm = 1.6979e-01, time/batch = 0.4847s	
1921/2700 (epoch 35.574), train_loss = 0.89878560, grad/param norm = 1.5263e-01, time/batch = 0.4988s	
1922/2700 (epoch 35.593), train_loss = 0.94061420, grad/param norm = 1.6177e-01, time/batch = 0.5105s	
1923/2700 (epoch 35.611), train_loss = 0.87243221, grad/param norm = 1.7440e-01, time/batch = 0.4669s	
1924/2700 (epoch 35.630), train_loss = 0.89660605, grad/param norm = 1.4745e-01, time/batch = 0.4836s	
1925/2700 (epoch 35.648), train_loss = 0.90422915, grad/param norm = 1.6118e-01, time/batch = 0.4849s	
1926/2700 (epoch 35.667), train_loss = 0.91021775, grad/param norm = 1.5196e-01, time/batch = 0.4695s	
1927/2700 (epoch 35.685), train_loss = 0.94003687, grad/param norm = 1.6292e-01, time/batch = 0.4835s	
1928/2700 (epoch 35.704), train_loss = 0.94783684, grad/param norm = 1.7342e-01, time/batch = 0.5132s	
1929/2700 (epoch 35.722), train_loss = 0.90871077, grad/param norm = 1.8108e-01, time/batch = 0.5112s	
1930/2700 (epoch 35.741), train_loss = 0.92432137, grad/param norm = 1.9410e-01, time/batch = 0.5035s	
1931/2700 (epoch 35.759), train_loss = 0.90805713, grad/param norm = 1.9173e-01, time/batch = 0.5124s	
1932/2700 (epoch 35.778), train_loss = 0.98114997, grad/param norm = 2.3439e-01, time/batch = 0.4660s	
1933/2700 (epoch 35.796), train_loss = 0.91423176, grad/param norm = 2.0712e-01, time/batch = 0.5106s	
1934/2700 (epoch 35.815), train_loss = 0.94998906, grad/param norm = 2.0679e-01, time/batch = 0.5132s	
1935/2700 (epoch 35.833), train_loss = 0.95222506, grad/param norm = 2.2088e-01, time/batch = 0.4904s	
1936/2700 (epoch 35.852), train_loss = 0.91649927, grad/param norm = 2.6047e-01, time/batch = 0.4600s	
1937/2700 (epoch 35.870), train_loss = 0.94350242, grad/param norm = 1.9856e-01, time/batch = 0.4639s	
1938/2700 (epoch 35.889), train_loss = 0.91562926, grad/param norm = 1.6932e-01, time/batch = 0.4875s	
1939/2700 (epoch 35.907), train_loss = 0.97012443, grad/param norm = 1.8444e-01, time/batch = 0.5040s	
1940/2700 (epoch 35.926), train_loss = 0.93426206, grad/param norm = 1.7447e-01, time/batch = 0.4594s	
1941/2700 (epoch 35.944), train_loss = 0.93252167, grad/param norm = 1.9308e-01, time/batch = 0.4988s	
1942/2700 (epoch 35.963), train_loss = 0.93926496, grad/param norm = 1.6341e-01, time/batch = 0.5113s	
1943/2700 (epoch 35.981), train_loss = 0.90760624, grad/param norm = 1.9100e-01, time/batch = 0.5152s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
1944/2700 (epoch 36.000), train_loss = 0.92764269, grad/param norm = 1.7144e-01, time/batch = 0.5298s	
1945/2700 (epoch 36.019), train_loss = 1.03194522, grad/param norm = 1.6553e-01, time/batch = 0.5027s	
1946/2700 (epoch 36.037), train_loss = 0.94254983, grad/param norm = 1.7021e-01, time/batch = 0.4821s	
1947/2700 (epoch 36.056), train_loss = 0.91960190, grad/param norm = 1.8449e-01, time/batch = 0.4668s	
1948/2700 (epoch 36.074), train_loss = 0.90821604, grad/param norm = 1.6606e-01, time/batch = 0.4842s	
1949/2700 (epoch 36.093), train_loss = 0.89878174, grad/param norm = 1.5121e-01, time/batch = 0.4406s	
1950/2700 (epoch 36.111), train_loss = 0.87250188, grad/param norm = 1.5398e-01, time/batch = 0.4918s	
1951/2700 (epoch 36.130), train_loss = 0.91144360, grad/param norm = 1.6637e-01, time/batch = 0.4674s	
1952/2700 (epoch 36.148), train_loss = 0.89549330, grad/param norm = 1.9710e-01, time/batch = 0.5119s	
1953/2700 (epoch 36.167), train_loss = 0.94460992, grad/param norm = 1.8785e-01, time/batch = 0.5216s	
1954/2700 (epoch 36.185), train_loss = 0.89874162, grad/param norm = 1.7324e-01, time/batch = 0.5266s	
1955/2700 (epoch 36.204), train_loss = 0.92874521, grad/param norm = 2.0781e-01, time/batch = 0.5171s	
1956/2700 (epoch 36.222), train_loss = 0.88180819, grad/param norm = 1.9251e-01, time/batch = 0.5014s	
1957/2700 (epoch 36.241), train_loss = 0.85229276, grad/param norm = 1.7879e-01, time/batch = 0.4806s	
1958/2700 (epoch 36.259), train_loss = 0.86723796, grad/param norm = 1.7550e-01, time/batch = 0.4149s	
1959/2700 (epoch 36.278), train_loss = 0.91227503, grad/param norm = 1.5850e-01, time/batch = 0.4831s	
1960/2700 (epoch 36.296), train_loss = 0.89200883, grad/param norm = 1.9240e-01, time/batch = 0.4874s	
1961/2700 (epoch 36.315), train_loss = 0.88355730, grad/param norm = 2.2535e-01, time/batch = 0.4802s	
1962/2700 (epoch 36.333), train_loss = 0.88431101, grad/param norm = 2.0827e-01, time/batch = 0.4664s	
1963/2700 (epoch 36.352), train_loss = 0.86868281, grad/param norm = 1.8973e-01, time/batch = 0.5123s	
1964/2700 (epoch 36.370), train_loss = 0.86876939, grad/param norm = 2.0627e-01, time/batch = 0.5134s	
1965/2700 (epoch 36.389), train_loss = 0.88787021, grad/param norm = 1.8677e-01, time/batch = 0.5223s	
1966/2700 (epoch 36.407), train_loss = 0.96530558, grad/param norm = 2.0055e-01, time/batch = 0.5100s	
1967/2700 (epoch 36.426), train_loss = 0.92516090, grad/param norm = 1.9218e-01, time/batch = 0.4500s	
1968/2700 (epoch 36.444), train_loss = 0.89949398, grad/param norm = 1.8919e-01, time/batch = 0.4907s	
1969/2700 (epoch 36.463), train_loss = 0.91506087, grad/param norm = 1.9514e-01, time/batch = 0.4722s	
1970/2700 (epoch 36.481), train_loss = 0.89856771, grad/param norm = 1.9738e-01, time/batch = 0.4683s	
1971/2700 (epoch 36.500), train_loss = 0.89693493, grad/param norm = 1.8887e-01, time/batch = 0.4863s	
1972/2700 (epoch 36.519), train_loss = 0.93017696, grad/param norm = 1.8170e-01, time/batch = 0.4801s	
1973/2700 (epoch 36.537), train_loss = 0.92812590, grad/param norm = 1.8845e-01, time/batch = 0.4732s	
1974/2700 (epoch 36.556), train_loss = 0.85089966, grad/param norm = 1.5517e-01, time/batch = 0.5134s	
1975/2700 (epoch 36.574), train_loss = 0.87912184, grad/param norm = 2.0442e-01, time/batch = 0.5199s	
1976/2700 (epoch 36.593), train_loss = 0.92313836, grad/param norm = 1.8153e-01, time/batch = 0.4846s	
1977/2700 (epoch 36.611), train_loss = 0.84103955, grad/param norm = 1.7024e-01, time/batch = 0.5214s	
1978/2700 (epoch 36.630), train_loss = 0.87919909, grad/param norm = 1.8916e-01, time/batch = 0.4808s	
1979/2700 (epoch 36.648), train_loss = 0.88414067, grad/param norm = 1.8744e-01, time/batch = 0.4696s	
1980/2700 (epoch 36.667), train_loss = 0.88724922, grad/param norm = 1.7406e-01, time/batch = 0.4640s	
1981/2700 (epoch 36.685), train_loss = 0.90987142, grad/param norm = 1.7175e-01, time/batch = 0.4600s	
1982/2700 (epoch 36.704), train_loss = 0.91688499, grad/param norm = 1.7190e-01, time/batch = 0.4837s	
1983/2700 (epoch 36.722), train_loss = 0.87437686, grad/param norm = 1.6966e-01, time/batch = 0.4828s	
1984/2700 (epoch 36.741), train_loss = 0.88836371, grad/param norm = 1.6458e-01, time/batch = 0.4895s	
1985/2700 (epoch 36.759), train_loss = 0.86900373, grad/param norm = 2.1601e-01, time/batch = 0.4966s	
1986/2700 (epoch 36.778), train_loss = 0.93495077, grad/param norm = 2.0097e-01, time/batch = 0.5117s	
1987/2700 (epoch 36.796), train_loss = 0.88702752, grad/param norm = 2.1252e-01, time/batch = 0.4993s	
1988/2700 (epoch 36.815), train_loss = 0.91820536, grad/param norm = 2.2701e-01, time/batch = 0.5023s	
1989/2700 (epoch 36.833), train_loss = 0.90637904, grad/param norm = 1.7852e-01, time/batch = 0.4977s	
1990/2700 (epoch 36.852), train_loss = 0.86374626, grad/param norm = 1.7228e-01, time/batch = 0.4617s	
1991/2700 (epoch 36.870), train_loss = 0.91000877, grad/param norm = 2.0251e-01, time/batch = 0.4568s	
1992/2700 (epoch 36.889), train_loss = 0.89018841, grad/param norm = 1.9453e-01, time/batch = 0.4883s	
1993/2700 (epoch 36.907), train_loss = 0.94119713, grad/param norm = 1.9308e-01, time/batch = 0.4813s	
1994/2700 (epoch 36.926), train_loss = 0.89555772, grad/param norm = 1.9391e-01, time/batch = 0.4869s	
1995/2700 (epoch 36.944), train_loss = 0.88757090, grad/param norm = 1.6740e-01, time/batch = 0.4946s	
1996/2700 (epoch 36.963), train_loss = 0.91004695, grad/param norm = 1.9050e-01, time/batch = 0.5061s	
1997/2700 (epoch 36.981), train_loss = 0.88198036, grad/param norm = 1.8287e-01, time/batch = 0.5099s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
1998/2700 (epoch 37.000), train_loss = 0.89503759, grad/param norm = 1.8200e-01, time/batch = 0.5014s	
1999/2700 (epoch 37.019), train_loss = 1.01045881, grad/param norm = 1.6941e-01, time/batch = 0.4805s	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch37.04_1.8881.t7	
2000/2700 (epoch 37.037), train_loss = 0.90516255, grad/param norm = 1.7362e-01, time/batch = 0.4681s	
2001/2700 (epoch 37.056), train_loss = 1.28787348, grad/param norm = 2.0101e-01, time/batch = 0.4687s	
2002/2700 (epoch 37.074), train_loss = 0.88487222, grad/param norm = 1.6850e-01, time/batch = 0.4818s	
2003/2700 (epoch 37.093), train_loss = 0.87001722, grad/param norm = 1.5070e-01, time/batch = 0.4739s	
2004/2700 (epoch 37.111), train_loss = 0.84610832, grad/param norm = 1.5928e-01, time/batch = 0.4733s	
2005/2700 (epoch 37.130), train_loss = 0.88266226, grad/param norm = 1.7515e-01, time/batch = 0.5218s	
2006/2700 (epoch 37.148), train_loss = 0.85944180, grad/param norm = 1.5978e-01, time/batch = 0.5100s	
2007/2700 (epoch 37.167), train_loss = 0.91601322, grad/param norm = 1.7951e-01, time/batch = 0.4899s	
2008/2700 (epoch 37.185), train_loss = 0.87529380, grad/param norm = 2.0286e-01, time/batch = 0.4520s	
2009/2700 (epoch 37.204), train_loss = 0.89927323, grad/param norm = 1.6975e-01, time/batch = 0.4598s	
2010/2700 (epoch 37.222), train_loss = 0.83727829, grad/param norm = 1.6964e-01, time/batch = 0.4724s	
2011/2700 (epoch 37.241), train_loss = 0.82981005, grad/param norm = 1.8837e-01, time/batch = 0.4582s	
2012/2700 (epoch 37.259), train_loss = 0.85098389, grad/param norm = 1.9027e-01, time/batch = 0.4900s	
2013/2700 (epoch 37.278), train_loss = 0.88912176, grad/param norm = 1.7959e-01, time/batch = 0.5119s	
2014/2700 (epoch 37.296), train_loss = 0.85149985, grad/param norm = 1.5177e-01, time/batch = 0.5110s	
2015/2700 (epoch 37.315), train_loss = 0.82696791, grad/param norm = 1.6676e-01, time/batch = 0.4936s	
2016/2700 (epoch 37.333), train_loss = 0.83810164, grad/param norm = 1.6683e-01, time/batch = 0.5147s	
2017/2700 (epoch 37.352), train_loss = 0.83077248, grad/param norm = 1.6558e-01, time/batch = 0.4839s	
2018/2700 (epoch 37.370), train_loss = 0.83890313, grad/param norm = 2.2147e-01, time/batch = 0.4966s	
2019/2700 (epoch 37.389), train_loss = 0.86138867, grad/param norm = 2.0499e-01, time/batch = 0.4679s	
2020/2700 (epoch 37.407), train_loss = 0.94521140, grad/param norm = 2.4385e-01, time/batch = 0.4317s	
2021/2700 (epoch 37.426), train_loss = 0.90054513, grad/param norm = 2.3553e-01, time/batch = 0.4718s	
2022/2700 (epoch 37.444), train_loss = 0.87458454, grad/param norm = 1.9572e-01, time/batch = 0.5001s	
2023/2700 (epoch 37.463), train_loss = 0.88153114, grad/param norm = 1.8156e-01, time/batch = 0.5106s	
2024/2700 (epoch 37.481), train_loss = 0.85889469, grad/param norm = 1.8627e-01, time/batch = 0.5090s	
2025/2700 (epoch 37.500), train_loss = 0.85533830, grad/param norm = 1.7241e-01, time/batch = 0.5108s	
2026/2700 (epoch 37.519), train_loss = 0.89850793, grad/param norm = 2.0607e-01, time/batch = 0.4973s	
2027/2700 (epoch 37.537), train_loss = 0.90349965, grad/param norm = 1.9356e-01, time/batch = 0.4995s	
2028/2700 (epoch 37.556), train_loss = 0.82455139, grad/param norm = 1.7249e-01, time/batch = 0.4763s	
2029/2700 (epoch 37.574), train_loss = 0.83565520, grad/param norm = 1.5537e-01, time/batch = 0.4482s	
2030/2700 (epoch 37.593), train_loss = 0.88116931, grad/param norm = 1.6053e-01, time/batch = 0.4717s	
2031/2700 (epoch 37.611), train_loss = 0.81805703, grad/param norm = 1.6435e-01, time/batch = 0.4737s	
2032/2700 (epoch 37.630), train_loss = 0.84210229, grad/param norm = 1.6033e-01, time/batch = 0.5058s	
2033/2700 (epoch 37.648), train_loss = 0.84678955, grad/param norm = 1.7406e-01, time/batch = 0.5148s	
2034/2700 (epoch 37.667), train_loss = 0.85667665, grad/param norm = 1.8305e-01, time/batch = 0.5088s	
2035/2700 (epoch 37.685), train_loss = 0.88313034, grad/param norm = 1.8059e-01, time/batch = 0.5095s	
2036/2700 (epoch 37.704), train_loss = 0.88254058, grad/param norm = 1.7725e-01, time/batch = 0.5086s	
2037/2700 (epoch 37.722), train_loss = 0.84835087, grad/param norm = 1.7296e-01, time/batch = 0.5083s	
2038/2700 (epoch 37.741), train_loss = 0.86179444, grad/param norm = 1.9109e-01, time/batch = 0.4311s	
2039/2700 (epoch 37.759), train_loss = 0.83351042, grad/param norm = 1.7006e-01, time/batch = 0.4915s	
2040/2700 (epoch 37.778), train_loss = 0.89661076, grad/param norm = 1.7145e-01, time/batch = 0.4858s	
2041/2700 (epoch 37.796), train_loss = 0.84809972, grad/param norm = 1.9732e-01, time/batch = 0.4963s	
2042/2700 (epoch 37.815), train_loss = 0.87935403, grad/param norm = 1.9995e-01, time/batch = 0.5203s	
2043/2700 (epoch 37.833), train_loss = 0.88938369, grad/param norm = 2.2846e-01, time/batch = 0.5119s	
2044/2700 (epoch 37.852), train_loss = 0.84696152, grad/param norm = 1.9805e-01, time/batch = 0.5074s	
2045/2700 (epoch 37.870), train_loss = 0.87545539, grad/param norm = 1.6563e-01, time/batch = 0.5083s	
2046/2700 (epoch 37.889), train_loss = 0.85275218, grad/param norm = 1.7661e-01, time/batch = 0.5085s	
2047/2700 (epoch 37.907), train_loss = 0.91255863, grad/param norm = 1.8564e-01, time/batch = 0.5000s	
2048/2700 (epoch 37.926), train_loss = 0.87496186, grad/param norm = 2.0960e-01, time/batch = 0.4919s	
2049/2700 (epoch 37.944), train_loss = 0.88331199, grad/param norm = 2.2268e-01, time/batch = 0.4006s	
2050/2700 (epoch 37.963), train_loss = 0.89390896, grad/param norm = 2.3334e-01, time/batch = 0.5017s	
2051/2700 (epoch 37.981), train_loss = 0.85169649, grad/param norm = 1.8364e-01, time/batch = 0.4699s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2052/2700 (epoch 38.000), train_loss = 0.86426782, grad/param norm = 1.6975e-01, time/batch = 0.5079s	
2053/2700 (epoch 38.019), train_loss = 0.97331233, grad/param norm = 1.6984e-01, time/batch = 0.5207s	
2054/2700 (epoch 38.037), train_loss = 0.87870356, grad/param norm = 1.5890e-01, time/batch = 0.5071s	
2055/2700 (epoch 38.056), train_loss = 0.87432325, grad/param norm = 1.7942e-01, time/batch = 0.5004s	
2056/2700 (epoch 38.074), train_loss = 0.84658531, grad/param norm = 1.6617e-01, time/batch = 0.4929s	
2057/2700 (epoch 38.093), train_loss = 0.84401639, grad/param norm = 1.7058e-01, time/batch = 0.5076s	
2058/2700 (epoch 38.111), train_loss = 0.81766785, grad/param norm = 1.7022e-01, time/batch = 0.4839s	
2059/2700 (epoch 38.130), train_loss = 0.84662049, grad/param norm = 1.6412e-01, time/batch = 0.4820s	
2060/2700 (epoch 38.148), train_loss = 0.82721582, grad/param norm = 1.6788e-01, time/batch = 0.4544s	
2061/2700 (epoch 38.167), train_loss = 0.87519043, grad/param norm = 1.6218e-01, time/batch = 0.4867s	
2062/2700 (epoch 38.185), train_loss = 0.82621368, grad/param norm = 1.4436e-01, time/batch = 0.5132s	
2063/2700 (epoch 38.204), train_loss = 0.86417383, grad/param norm = 1.7963e-01, time/batch = 0.5189s	
2064/2700 (epoch 38.222), train_loss = 0.81547853, grad/param norm = 1.7661e-01, time/batch = 0.5158s	
2065/2700 (epoch 38.241), train_loss = 0.79205335, grad/param norm = 1.8152e-01, time/batch = 0.5057s	
2066/2700 (epoch 38.259), train_loss = 0.80853052, grad/param norm = 1.8116e-01, time/batch = 0.4968s	
2067/2700 (epoch 38.278), train_loss = 0.87302880, grad/param norm = 2.0329e-01, time/batch = 0.5003s	
2068/2700 (epoch 38.296), train_loss = 0.84084188, grad/param norm = 1.9927e-01, time/batch = 0.4882s	
2069/2700 (epoch 38.315), train_loss = 0.81072674, grad/param norm = 1.8746e-01, time/batch = 0.4799s	
2070/2700 (epoch 38.333), train_loss = 0.81218008, grad/param norm = 1.9468e-01, time/batch = 0.4835s	
2071/2700 (epoch 38.352), train_loss = 0.81249981, grad/param norm = 1.7614e-01, time/batch = 0.4288s	
2072/2700 (epoch 38.370), train_loss = 0.79908188, grad/param norm = 1.8802e-01, time/batch = 0.5150s	
2073/2700 (epoch 38.389), train_loss = 0.83539886, grad/param norm = 2.0849e-01, time/batch = 0.5190s	
2074/2700 (epoch 38.407), train_loss = 0.90857890, grad/param norm = 2.1345e-01, time/batch = 0.5111s	
2075/2700 (epoch 38.426), train_loss = 0.86438815, grad/param norm = 1.9234e-01, time/batch = 0.4458s	
2076/2700 (epoch 38.444), train_loss = 0.84347623, grad/param norm = 1.9893e-01, time/batch = 0.5017s	
2077/2700 (epoch 38.463), train_loss = 0.85354041, grad/param norm = 1.7978e-01, time/batch = 0.4767s	
2078/2700 (epoch 38.481), train_loss = 0.82967314, grad/param norm = 1.8096e-01, time/batch = 0.4763s	
2079/2700 (epoch 38.500), train_loss = 0.82961456, grad/param norm = 1.8733e-01, time/batch = 0.4819s	
2080/2700 (epoch 38.519), train_loss = 0.85604671, grad/param norm = 1.6725e-01, time/batch = 0.4886s	
2081/2700 (epoch 38.537), train_loss = 0.85550407, grad/param norm = 1.6088e-01, time/batch = 0.4825s	
2082/2700 (epoch 38.556), train_loss = 0.78536561, grad/param norm = 1.6072e-01, time/batch = 0.4678s	
2083/2700 (epoch 38.574), train_loss = 0.80195184, grad/param norm = 1.7196e-01, time/batch = 0.5240s	
2084/2700 (epoch 38.593), train_loss = 0.84837609, grad/param norm = 1.5180e-01, time/batch = 0.4548s	
2085/2700 (epoch 38.611), train_loss = 0.78145442, grad/param norm = 1.7156e-01, time/batch = 0.4888s	
2086/2700 (epoch 38.630), train_loss = 0.82063328, grad/param norm = 1.9051e-01, time/batch = 0.4700s	
2087/2700 (epoch 38.648), train_loss = 0.81533454, grad/param norm = 1.7303e-01, time/batch = 0.4752s	
2088/2700 (epoch 38.667), train_loss = 0.82971909, grad/param norm = 1.8025e-01, time/batch = 0.4812s	
2089/2700 (epoch 38.685), train_loss = 0.85349464, grad/param norm = 1.8407e-01, time/batch = 0.5041s	
2090/2700 (epoch 38.704), train_loss = 0.86073193, grad/param norm = 2.0262e-01, time/batch = 0.5116s	
2091/2700 (epoch 38.722), train_loss = 0.82571880, grad/param norm = 1.8481e-01, time/batch = 0.4949s	
2092/2700 (epoch 38.741), train_loss = 0.83148318, grad/param norm = 1.6642e-01, time/batch = 0.5151s	
2093/2700 (epoch 38.759), train_loss = 0.81623817, grad/param norm = 2.1050e-01, time/batch = 0.4862s	
2094/2700 (epoch 38.778), train_loss = 0.88509464, grad/param norm = 2.2605e-01, time/batch = 0.5195s	
2095/2700 (epoch 38.796), train_loss = 0.82068094, grad/param norm = 2.0920e-01, time/batch = 0.5002s	
2096/2700 (epoch 38.815), train_loss = 0.86196135, grad/param norm = 2.1472e-01, time/batch = 0.4797s	
2097/2700 (epoch 38.833), train_loss = 0.85418549, grad/param norm = 2.0164e-01, time/batch = 0.4740s	
2098/2700 (epoch 38.852), train_loss = 0.80924852, grad/param norm = 1.7842e-01, time/batch = 0.4791s	
2099/2700 (epoch 38.870), train_loss = 0.84911502, grad/param norm = 1.7732e-01, time/batch = 0.4908s	
2100/2700 (epoch 38.889), train_loss = 0.82959167, grad/param norm = 1.8827e-01, time/batch = 0.5036s	
2101/2700 (epoch 38.907), train_loss = 0.87759155, grad/param norm = 1.8907e-01, time/batch = 0.4910s	
2102/2700 (epoch 38.926), train_loss = 0.83845722, grad/param norm = 1.8271e-01, time/batch = 0.5098s	
2103/2700 (epoch 38.944), train_loss = 0.83669719, grad/param norm = 1.7585e-01, time/batch = 0.5055s	
2104/2700 (epoch 38.963), train_loss = 0.84707139, grad/param norm = 1.7108e-01, time/batch = 0.5051s	
2105/2700 (epoch 38.981), train_loss = 0.81322775, grad/param norm = 1.7204e-01, time/batch = 0.5093s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2106/2700 (epoch 39.000), train_loss = 0.83978877, grad/param norm = 2.0437e-01, time/batch = 0.4939s	
2107/2700 (epoch 39.019), train_loss = 0.95411884, grad/param norm = 1.9078e-01, time/batch = 0.4770s	
2108/2700 (epoch 39.037), train_loss = 0.84781644, grad/param norm = 1.6428e-01, time/batch = 0.4770s	
2109/2700 (epoch 39.056), train_loss = 0.84073599, grad/param norm = 1.6889e-01, time/batch = 0.4801s	
2110/2700 (epoch 39.074), train_loss = 0.82028743, grad/param norm = 1.8412e-01, time/batch = 0.4903s	
2111/2700 (epoch 39.093), train_loss = 0.82260334, grad/param norm = 1.6355e-01, time/batch = 0.4673s	
2112/2700 (epoch 39.111), train_loss = 0.79200158, grad/param norm = 1.6137e-01, time/batch = 0.5071s	
2113/2700 (epoch 39.130), train_loss = 0.83126244, grad/param norm = 1.9079e-01, time/batch = 0.4943s	
2114/2700 (epoch 39.148), train_loss = 0.81053733, grad/param norm = 1.8987e-01, time/batch = 0.5244s	
2115/2700 (epoch 39.167), train_loss = 0.84356571, grad/param norm = 1.6974e-01, time/batch = 0.5141s	
2116/2700 (epoch 39.185), train_loss = 0.81478101, grad/param norm = 1.8965e-01, time/batch = 0.5023s	
2117/2700 (epoch 39.204), train_loss = 0.83671800, grad/param norm = 1.7523e-01, time/batch = 0.4845s	
2118/2700 (epoch 39.222), train_loss = 0.78082389, grad/param norm = 1.7457e-01, time/batch = 0.4751s	
2119/2700 (epoch 39.241), train_loss = 0.76713714, grad/param norm = 1.8221e-01, time/batch = 0.4812s	
2120/2700 (epoch 39.259), train_loss = 0.78347439, grad/param norm = 1.8205e-01, time/batch = 0.4717s	
2121/2700 (epoch 39.278), train_loss = 0.82976224, grad/param norm = 1.9208e-01, time/batch = 0.4852s	
2122/2700 (epoch 39.296), train_loss = 0.80242534, grad/param norm = 1.6987e-01, time/batch = 0.4592s	
2123/2700 (epoch 39.315), train_loss = 0.78100190, grad/param norm = 2.0574e-01, time/batch = 0.4887s	
2124/2700 (epoch 39.333), train_loss = 0.79775860, grad/param norm = 2.2126e-01, time/batch = 0.5112s	
2125/2700 (epoch 39.352), train_loss = 0.77914285, grad/param norm = 1.7928e-01, time/batch = 0.5248s	
2126/2700 (epoch 39.370), train_loss = 0.77490959, grad/param norm = 1.8799e-01, time/batch = 0.5116s	
2127/2700 (epoch 39.389), train_loss = 0.80254711, grad/param norm = 1.9898e-01, time/batch = 0.5038s	
2128/2700 (epoch 39.407), train_loss = 0.87621467, grad/param norm = 1.8694e-01, time/batch = 0.4909s	
2129/2700 (epoch 39.426), train_loss = 0.82802687, grad/param norm = 1.9228e-01, time/batch = 0.4874s	
2130/2700 (epoch 39.444), train_loss = 0.80961775, grad/param norm = 1.6390e-01, time/batch = 0.4658s	
2131/2700 (epoch 39.463), train_loss = 0.81716034, grad/param norm = 1.6961e-01, time/batch = 0.4797s	
2132/2700 (epoch 39.481), train_loss = 0.80314729, grad/param norm = 1.8756e-01, time/batch = 0.4823s	
2133/2700 (epoch 39.500), train_loss = 0.79212261, grad/param norm = 1.5594e-01, time/batch = 0.4837s	
2134/2700 (epoch 39.519), train_loss = 0.83114800, grad/param norm = 1.7790e-01, time/batch = 0.4715s	
2135/2700 (epoch 39.537), train_loss = 0.83131066, grad/param norm = 1.9666e-01, time/batch = 0.5043s	
2136/2700 (epoch 39.556), train_loss = 0.75542548, grad/param norm = 1.4780e-01, time/batch = 0.5084s	
2137/2700 (epoch 39.574), train_loss = 0.77972182, grad/param norm = 1.8610e-01, time/batch = 0.5119s	
2138/2700 (epoch 39.593), train_loss = 0.83382851, grad/param norm = 2.0850e-01, time/batch = 0.5136s	
2139/2700 (epoch 39.611), train_loss = 0.76667038, grad/param norm = 1.9179e-01, time/batch = 0.4481s	
2140/2700 (epoch 39.630), train_loss = 0.80014909, grad/param norm = 2.1902e-01, time/batch = 0.4780s	
2141/2700 (epoch 39.648), train_loss = 0.80542232, grad/param norm = 2.2439e-01, time/batch = 0.5033s	
2142/2700 (epoch 39.667), train_loss = 0.79887636, grad/param norm = 1.8228e-01, time/batch = 0.4856s	
2143/2700 (epoch 39.685), train_loss = 0.82556908, grad/param norm = 1.8598e-01, time/batch = 0.4794s	
2144/2700 (epoch 39.704), train_loss = 0.82498329, grad/param norm = 1.7604e-01, time/batch = 0.4832s	
2145/2700 (epoch 39.722), train_loss = 0.79072163, grad/param norm = 1.7294e-01, time/batch = 0.4754s	
2146/2700 (epoch 39.741), train_loss = 0.80569060, grad/param norm = 2.0233e-01, time/batch = 0.5039s	
2147/2700 (epoch 39.759), train_loss = 0.78433863, grad/param norm = 2.2018e-01, time/batch = 0.5141s	
2148/2700 (epoch 39.778), train_loss = 0.84707575, grad/param norm = 2.1226e-01, time/batch = 0.4712s	
2149/2700 (epoch 39.796), train_loss = 0.81823305, grad/param norm = 2.4036e-01, time/batch = 0.5093s	
2150/2700 (epoch 39.815), train_loss = 0.83743133, grad/param norm = 2.3080e-01, time/batch = 0.5058s	
2151/2700 (epoch 39.833), train_loss = 0.82670871, grad/param norm = 1.9264e-01, time/batch = 0.5116s	
2152/2700 (epoch 39.852), train_loss = 0.78931208, grad/param norm = 2.0299e-01, time/batch = 0.5108s	
2153/2700 (epoch 39.870), train_loss = 0.82357611, grad/param norm = 1.7421e-01, time/batch = 0.5045s	
2154/2700 (epoch 39.889), train_loss = 0.78941127, grad/param norm = 1.5809e-01, time/batch = 0.4698s	
2155/2700 (epoch 39.907), train_loss = 0.84395394, grad/param norm = 1.8877e-01, time/batch = 0.4762s	
2156/2700 (epoch 39.926), train_loss = 0.81082072, grad/param norm = 2.0745e-01, time/batch = 0.4729s	
2157/2700 (epoch 39.944), train_loss = 0.80825737, grad/param norm = 1.9545e-01, time/batch = 0.4388s	
2158/2700 (epoch 39.963), train_loss = 0.81736875, grad/param norm = 1.8751e-01, time/batch = 0.5060s	
2159/2700 (epoch 39.981), train_loss = 0.78440437, grad/param norm = 1.8860e-01, time/batch = 0.5090s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2160/2700 (epoch 40.000), train_loss = 0.79845788, grad/param norm = 1.7151e-01, time/batch = 0.5087s	
2161/2700 (epoch 40.019), train_loss = 0.92647491, grad/param norm = 1.9090e-01, time/batch = 0.5112s	
2162/2700 (epoch 40.037), train_loss = 0.83074240, grad/param norm = 1.8853e-01, time/batch = 0.5114s	
2163/2700 (epoch 40.056), train_loss = 0.81614544, grad/param norm = 1.7923e-01, time/batch = 0.5144s	
2164/2700 (epoch 40.074), train_loss = 0.78984359, grad/param norm = 1.8350e-01, time/batch = 0.5158s	
2165/2700 (epoch 40.093), train_loss = 0.78641963, grad/param norm = 1.8021e-01, time/batch = 0.4796s	
2166/2700 (epoch 40.111), train_loss = 0.76015583, grad/param norm = 1.6131e-01, time/batch = 0.4252s	
2167/2700 (epoch 40.130), train_loss = 0.79702860, grad/param norm = 1.8288e-01, time/batch = 0.4790s	
2168/2700 (epoch 40.148), train_loss = 0.77626338, grad/param norm = 1.5097e-01, time/batch = 0.4850s	
2169/2700 (epoch 40.167), train_loss = 0.81288823, grad/param norm = 1.6841e-01, time/batch = 0.5067s	
2170/2700 (epoch 40.185), train_loss = 0.76946481, grad/param norm = 1.5138e-01, time/batch = 0.5099s	
2171/2700 (epoch 40.204), train_loss = 0.80815298, grad/param norm = 1.7414e-01, time/batch = 0.5123s	
2172/2700 (epoch 40.222), train_loss = 0.75675239, grad/param norm = 1.9149e-01, time/batch = 0.5130s	
2173/2700 (epoch 40.241), train_loss = 0.74511590, grad/param norm = 2.0423e-01, time/batch = 0.5266s	
2174/2700 (epoch 40.259), train_loss = 0.76221526, grad/param norm = 2.0595e-01, time/batch = 0.5209s	
2175/2700 (epoch 40.278), train_loss = 0.81655087, grad/param norm = 1.8784e-01, time/batch = 0.4539s	
2176/2700 (epoch 40.296), train_loss = 0.78167596, grad/param norm = 1.8953e-01, time/batch = 0.5017s	
2177/2700 (epoch 40.315), train_loss = 0.75739254, grad/param norm = 2.0607e-01, time/batch = 0.4854s	
2178/2700 (epoch 40.333), train_loss = 0.75856522, grad/param norm = 1.8372e-01, time/batch = 0.4732s	
2179/2700 (epoch 40.352), train_loss = 0.75361635, grad/param norm = 1.6545e-01, time/batch = 0.4778s	
2180/2700 (epoch 40.370), train_loss = 0.73876519, grad/param norm = 1.6213e-01, time/batch = 0.4803s	
2181/2700 (epoch 40.389), train_loss = 0.76601545, grad/param norm = 1.7275e-01, time/batch = 0.4518s	
2182/2700 (epoch 40.407), train_loss = 0.83364246, grad/param norm = 1.8315e-01, time/batch = 0.5170s	
2183/2700 (epoch 40.426), train_loss = 0.79357309, grad/param norm = 1.7085e-01, time/batch = 0.5264s	
2184/2700 (epoch 40.444), train_loss = 0.77689798, grad/param norm = 1.6547e-01, time/batch = 0.4826s	
2185/2700 (epoch 40.463), train_loss = 0.79421216, grad/param norm = 1.7607e-01, time/batch = 0.5138s	
2186/2700 (epoch 40.481), train_loss = 0.75877265, grad/param norm = 1.4773e-01, time/batch = 0.4997s	
2187/2700 (epoch 40.500), train_loss = 0.76790904, grad/param norm = 1.7176e-01, time/batch = 0.4850s	
2188/2700 (epoch 40.519), train_loss = 0.80210746, grad/param norm = 1.7800e-01, time/batch = 0.4617s	
2189/2700 (epoch 40.537), train_loss = 0.80194669, grad/param norm = 1.6320e-01, time/batch = 0.4725s	
2190/2700 (epoch 40.556), train_loss = 0.72910548, grad/param norm = 1.8241e-01, time/batch = 0.4836s	
2191/2700 (epoch 40.574), train_loss = 0.75111201, grad/param norm = 1.9246e-01, time/batch = 0.4837s	
2192/2700 (epoch 40.593), train_loss = 0.79781139, grad/param norm = 1.8299e-01, time/batch = 0.4678s	
2193/2700 (epoch 40.611), train_loss = 0.74341565, grad/param norm = 2.0703e-01, time/batch = 0.4990s	
2194/2700 (epoch 40.630), train_loss = 0.77331209, grad/param norm = 1.7605e-01, time/batch = 0.5215s	
2195/2700 (epoch 40.648), train_loss = 0.77416398, grad/param norm = 2.0628e-01, time/batch = 0.5005s	
2196/2700 (epoch 40.667), train_loss = 0.78322092, grad/param norm = 1.9998e-01, time/batch = 0.5117s	
2197/2700 (epoch 40.685), train_loss = 0.79694234, grad/param norm = 1.8304e-01, time/batch = 0.4680s	
2198/2700 (epoch 40.704), train_loss = 0.79928359, grad/param norm = 1.9800e-01, time/batch = 0.4585s	
2199/2700 (epoch 40.722), train_loss = 0.77116204, grad/param norm = 1.9398e-01, time/batch = 0.4740s	
2200/2700 (epoch 40.741), train_loss = 0.78020399, grad/param norm = 1.9560e-01, time/batch = 0.4893s	
2201/2700 (epoch 40.759), train_loss = 0.74787158, grad/param norm = 2.0335e-01, time/batch = 0.4824s	
2202/2700 (epoch 40.778), train_loss = 0.81369502, grad/param norm = 1.9617e-01, time/batch = 0.4710s	
2203/2700 (epoch 40.796), train_loss = 0.76067412, grad/param norm = 2.1103e-01, time/batch = 0.4881s	
2204/2700 (epoch 40.815), train_loss = 0.80234382, grad/param norm = 2.0588e-01, time/batch = 0.4830s	
2205/2700 (epoch 40.833), train_loss = 0.80562015, grad/param norm = 2.3035e-01, time/batch = 0.5234s	
2206/2700 (epoch 40.852), train_loss = 0.76463402, grad/param norm = 2.0302e-01, time/batch = 0.5010s	
2207/2700 (epoch 40.870), train_loss = 0.80185825, grad/param norm = 1.9947e-01, time/batch = 0.4748s	
2208/2700 (epoch 40.889), train_loss = 0.77607582, grad/param norm = 1.9473e-01, time/batch = 0.4610s	
2209/2700 (epoch 40.907), train_loss = 0.81253261, grad/param norm = 1.8237e-01, time/batch = 0.4815s	
2210/2700 (epoch 40.926), train_loss = 0.78386577, grad/param norm = 1.9587e-01, time/batch = 0.4781s	
2211/2700 (epoch 40.944), train_loss = 0.79021084, grad/param norm = 2.1797e-01, time/batch = 0.4694s	
2212/2700 (epoch 40.963), train_loss = 0.79440446, grad/param norm = 1.9238e-01, time/batch = 0.4853s	
2213/2700 (epoch 40.981), train_loss = 0.76688160, grad/param norm = 1.9562e-01, time/batch = 0.5000s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2214/2700 (epoch 41.000), train_loss = 0.79442695, grad/param norm = 2.2698e-01, time/batch = 0.4901s	
2215/2700 (epoch 41.019), train_loss = 0.89675211, grad/param norm = 1.7086e-01, time/batch = 0.5298s	
2216/2700 (epoch 41.037), train_loss = 0.79561723, grad/param norm = 1.6647e-01, time/batch = 0.5058s	
2217/2700 (epoch 41.056), train_loss = 0.78642377, grad/param norm = 1.7138e-01, time/batch = 0.4646s	
2218/2700 (epoch 41.074), train_loss = 0.76101573, grad/param norm = 1.7121e-01, time/batch = 0.4592s	
2219/2700 (epoch 41.093), train_loss = 0.75859185, grad/param norm = 1.6224e-01, time/batch = 0.4672s	
2220/2700 (epoch 41.111), train_loss = 0.73405393, grad/param norm = 1.5375e-01, time/batch = 0.4834s	
2221/2700 (epoch 41.130), train_loss = 0.76988408, grad/param norm = 1.6099e-01, time/batch = 0.4541s	
2222/2700 (epoch 41.148), train_loss = 0.75069704, grad/param norm = 1.8646e-01, time/batch = 0.5007s	
2223/2700 (epoch 41.167), train_loss = 0.79375958, grad/param norm = 1.7982e-01, time/batch = 0.5103s	
2224/2700 (epoch 41.185), train_loss = 0.74828133, grad/param norm = 1.7864e-01, time/batch = 0.5077s	
2225/2700 (epoch 41.204), train_loss = 0.78517021, grad/param norm = 1.8910e-01, time/batch = 0.5092s	
2226/2700 (epoch 41.222), train_loss = 0.72854467, grad/param norm = 1.8547e-01, time/batch = 0.4325s	
2227/2700 (epoch 41.241), train_loss = 0.71643882, grad/param norm = 1.7491e-01, time/batch = 0.4105s	
2228/2700 (epoch 41.259), train_loss = 0.72160904, grad/param norm = 1.8372e-01, time/batch = 0.4481s	
2229/2700 (epoch 41.278), train_loss = 0.78538981, grad/param norm = 2.2135e-01, time/batch = 0.4743s	
2230/2700 (epoch 41.296), train_loss = 0.75787432, grad/param norm = 2.0976e-01, time/batch = 0.4411s	
2231/2700 (epoch 41.315), train_loss = 0.73453566, grad/param norm = 2.1394e-01, time/batch = 0.4890s	
2232/2700 (epoch 41.333), train_loss = 0.75285118, grad/param norm = 2.6635e-01, time/batch = 0.5225s	
2233/2700 (epoch 41.352), train_loss = 0.75429864, grad/param norm = 2.4757e-01, time/batch = 0.5172s	
2234/2700 (epoch 41.370), train_loss = 0.73450437, grad/param norm = 2.3075e-01, time/batch = 0.5101s	
2235/2700 (epoch 41.389), train_loss = 0.74428238, grad/param norm = 1.7597e-01, time/batch = 0.5064s	
2236/2700 (epoch 41.407), train_loss = 0.80494463, grad/param norm = 1.7921e-01, time/batch = 0.5088s	
2237/2700 (epoch 41.426), train_loss = 0.76693651, grad/param norm = 1.8077e-01, time/batch = 0.5039s	
2238/2700 (epoch 41.444), train_loss = 0.74787670, grad/param norm = 1.6529e-01, time/batch = 0.4864s	
2239/2700 (epoch 41.463), train_loss = 0.76527805, grad/param norm = 1.8524e-01, time/batch = 0.4178s	
2240/2700 (epoch 41.481), train_loss = 0.74316127, grad/param norm = 1.8062e-01, time/batch = 0.5069s	
2241/2700 (epoch 41.500), train_loss = 0.74145114, grad/param norm = 1.9535e-01, time/batch = 0.5003s	
2242/2700 (epoch 41.519), train_loss = 0.77166594, grad/param norm = 1.7407e-01, time/batch = 0.5220s	
2243/2700 (epoch 41.537), train_loss = 0.76973317, grad/param norm = 1.6597e-01, time/batch = 0.5094s	
2244/2700 (epoch 41.556), train_loss = 0.70347157, grad/param norm = 1.6302e-01, time/batch = 0.5087s	
2245/2700 (epoch 41.574), train_loss = 0.71985798, grad/param norm = 1.7511e-01, time/batch = 0.5070s	
2246/2700 (epoch 41.593), train_loss = 0.77090183, grad/param norm = 1.7837e-01, time/batch = 0.5092s	
2247/2700 (epoch 41.611), train_loss = 0.70619047, grad/param norm = 1.7263e-01, time/batch = 0.5052s	
2248/2700 (epoch 41.630), train_loss = 0.74173722, grad/param norm = 1.8365e-01, time/batch = 0.4600s	
2249/2700 (epoch 41.648), train_loss = 0.73534021, grad/param norm = 1.7162e-01, time/batch = 0.4750s	
2250/2700 (epoch 41.667), train_loss = 0.74112059, grad/param norm = 1.7568e-01, time/batch = 0.4407s	
2251/2700 (epoch 41.685), train_loss = 0.76737472, grad/param norm = 1.8328e-01, time/batch = 0.4989s	
2252/2700 (epoch 41.704), train_loss = 0.77349716, grad/param norm = 1.9987e-01, time/batch = 0.5227s	
2253/2700 (epoch 41.722), train_loss = 0.73904588, grad/param norm = 1.9026e-01, time/batch = 0.5122s	
2254/2700 (epoch 41.741), train_loss = 0.75105930, grad/param norm = 1.6892e-01, time/batch = 0.5047s	
2255/2700 (epoch 41.759), train_loss = 0.71810626, grad/param norm = 1.7529e-01, time/batch = 0.5068s	
2256/2700 (epoch 41.778), train_loss = 0.79257829, grad/param norm = 2.3248e-01, time/batch = 0.5063s	
2257/2700 (epoch 41.796), train_loss = 0.73473549, grad/param norm = 1.9740e-01, time/batch = 0.4855s	
2258/2700 (epoch 41.815), train_loss = 0.76088112, grad/param norm = 1.9371e-01, time/batch = 0.4817s	
2259/2700 (epoch 41.833), train_loss = 0.76376408, grad/param norm = 1.9748e-01, time/batch = 0.4620s	
2260/2700 (epoch 41.852), train_loss = 0.73710006, grad/param norm = 2.3003e-01, time/batch = 0.4811s	
2261/2700 (epoch 41.870), train_loss = 0.77262180, grad/param norm = 1.8099e-01, time/batch = 0.4285s	
2262/2700 (epoch 41.889), train_loss = 0.74281894, grad/param norm = 1.8112e-01, time/batch = 0.5252s	
2263/2700 (epoch 41.907), train_loss = 0.79124554, grad/param norm = 1.9777e-01, time/batch = 0.5126s	
2264/2700 (epoch 41.926), train_loss = 0.75283467, grad/param norm = 2.0978e-01, time/batch = 0.5088s	
2265/2700 (epoch 41.944), train_loss = 0.76220223, grad/param norm = 2.0717e-01, time/batch = 0.4879s	
2266/2700 (epoch 41.963), train_loss = 0.78084253, grad/param norm = 2.4333e-01, time/batch = 0.4741s	
2267/2700 (epoch 41.981), train_loss = 0.74727946, grad/param norm = 2.1425e-01, time/batch = 0.4801s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2268/2700 (epoch 42.000), train_loss = 0.75693033, grad/param norm = 1.9881e-01, time/batch = 0.4741s	
2269/2700 (epoch 42.019), train_loss = 0.88006277, grad/param norm = 2.0596e-01, time/batch = 0.4900s	
2270/2700 (epoch 42.037), train_loss = 0.77626883, grad/param norm = 1.7911e-01, time/batch = 0.5055s	
2271/2700 (epoch 42.056), train_loss = 0.75466161, grad/param norm = 1.6131e-01, time/batch = 0.5065s	
2272/2700 (epoch 42.074), train_loss = 0.73184836, grad/param norm = 1.7166e-01, time/batch = 0.4963s	
2273/2700 (epoch 42.093), train_loss = 0.73394732, grad/param norm = 1.7372e-01, time/batch = 0.5105s	
2274/2700 (epoch 42.111), train_loss = 0.70826016, grad/param norm = 1.6834e-01, time/batch = 0.4899s	
2275/2700 (epoch 42.130), train_loss = 0.73972533, grad/param norm = 1.6521e-01, time/batch = 0.4689s	
2276/2700 (epoch 42.148), train_loss = 0.72183987, grad/param norm = 1.6481e-01, time/batch = 0.4098s	
2277/2700 (epoch 42.167), train_loss = 0.75932236, grad/param norm = 1.5754e-01, time/batch = 0.4681s	
2278/2700 (epoch 42.185), train_loss = 0.71709748, grad/param norm = 1.7140e-01, time/batch = 0.4954s	
2279/2700 (epoch 42.204), train_loss = 0.74849450, grad/param norm = 1.6850e-01, time/batch = 0.5164s	
2280/2700 (epoch 42.222), train_loss = 0.70940962, grad/param norm = 2.3197e-01, time/batch = 0.5083s	
2281/2700 (epoch 42.241), train_loss = 0.70140898, grad/param norm = 2.1442e-01, time/batch = 0.5089s	
2282/2700 (epoch 42.259), train_loss = 0.70918228, grad/param norm = 2.2428e-01, time/batch = 0.5241s	
2283/2700 (epoch 42.278), train_loss = 0.76735837, grad/param norm = 2.1163e-01, time/batch = 0.5169s	
2284/2700 (epoch 42.296), train_loss = 0.73188170, grad/param norm = 2.0762e-01, time/batch = 0.5020s	
2285/2700 (epoch 42.315), train_loss = 0.71250245, grad/param norm = 2.3364e-01, time/batch = 0.4381s	
2286/2700 (epoch 42.333), train_loss = 0.72493550, grad/param norm = 2.2849e-01, time/batch = 0.4823s	
2287/2700 (epoch 42.352), train_loss = 0.70380063, grad/param norm = 2.0186e-01, time/batch = 0.4803s	
2288/2700 (epoch 42.370), train_loss = 0.69727359, grad/param norm = 1.8607e-01, time/batch = 0.4847s	
2289/2700 (epoch 42.389), train_loss = 0.71883315, grad/param norm = 1.9483e-01, time/batch = 0.4869s	
2290/2700 (epoch 42.407), train_loss = 0.78043395, grad/param norm = 1.8877e-01, time/batch = 0.5052s	
2291/2700 (epoch 42.426), train_loss = 0.73755335, grad/param norm = 1.7746e-01, time/batch = 0.5007s	
2292/2700 (epoch 42.444), train_loss = 0.72268845, grad/param norm = 1.7741e-01, time/batch = 0.5058s	
2293/2700 (epoch 42.463), train_loss = 0.73832941, grad/param norm = 1.8043e-01, time/batch = 0.5157s	
2294/2700 (epoch 42.481), train_loss = 0.71976723, grad/param norm = 1.8644e-01, time/batch = 0.4740s	
2295/2700 (epoch 42.500), train_loss = 0.71716068, grad/param norm = 1.7181e-01, time/batch = 0.5084s	
2296/2700 (epoch 42.519), train_loss = 0.75250291, grad/param norm = 2.1042e-01, time/batch = 0.4946s	
2297/2700 (epoch 42.537), train_loss = 0.75873935, grad/param norm = 2.1068e-01, time/batch = 0.4851s	
2298/2700 (epoch 42.556), train_loss = 0.67691635, grad/param norm = 1.6313e-01, time/batch = 0.4854s	
2299/2700 (epoch 42.574), train_loss = 0.69931007, grad/param norm = 1.7579e-01, time/batch = 0.4810s	
2300/2700 (epoch 42.593), train_loss = 0.74274771, grad/param norm = 1.7629e-01, time/batch = 0.4873s	
2301/2700 (epoch 42.611), train_loss = 0.68835854, grad/param norm = 1.7881e-01, time/batch = 0.4743s	
2302/2700 (epoch 42.630), train_loss = 0.71441032, grad/param norm = 1.9279e-01, time/batch = 0.4910s	
2303/2700 (epoch 42.648), train_loss = 0.70884724, grad/param norm = 1.7257e-01, time/batch = 0.4904s	
2304/2700 (epoch 42.667), train_loss = 0.71641629, grad/param norm = 1.9093e-01, time/batch = 0.5150s	
2305/2700 (epoch 42.685), train_loss = 0.74241654, grad/param norm = 1.9230e-01, time/batch = 0.5135s	
2306/2700 (epoch 42.704), train_loss = 0.74190749, grad/param norm = 1.7939e-01, time/batch = 0.4983s	
2307/2700 (epoch 42.722), train_loss = 0.70181485, grad/param norm = 1.5904e-01, time/batch = 0.4764s	
2308/2700 (epoch 42.741), train_loss = 0.72264525, grad/param norm = 1.8569e-01, time/batch = 0.4668s	
2309/2700 (epoch 42.759), train_loss = 0.69759507, grad/param norm = 1.9092e-01, time/batch = 0.4866s	
2310/2700 (epoch 42.778), train_loss = 0.76649151, grad/param norm = 2.3642e-01, time/batch = 0.4807s	
2311/2700 (epoch 42.796), train_loss = 0.70508068, grad/param norm = 1.8750e-01, time/batch = 0.4770s	
2312/2700 (epoch 42.815), train_loss = 0.73200786, grad/param norm = 2.0049e-01, time/batch = 0.4903s	
2313/2700 (epoch 42.833), train_loss = 0.73373533, grad/param norm = 1.8270e-01, time/batch = 0.5131s	
2314/2700 (epoch 42.852), train_loss = 0.70330916, grad/param norm = 1.8448e-01, time/batch = 0.5037s	
2315/2700 (epoch 42.870), train_loss = 0.75334150, grad/param norm = 2.2319e-01, time/batch = 0.5238s	
2316/2700 (epoch 42.889), train_loss = 0.72218253, grad/param norm = 2.0581e-01, time/batch = 0.5015s	
2317/2700 (epoch 42.907), train_loss = 0.77064196, grad/param norm = 1.9984e-01, time/batch = 0.4849s	
2318/2700 (epoch 42.926), train_loss = 0.72974810, grad/param norm = 1.8356e-01, time/batch = 0.4760s	
2319/2700 (epoch 42.944), train_loss = 0.71969536, grad/param norm = 1.9144e-01, time/batch = 0.4793s	
2320/2700 (epoch 42.963), train_loss = 0.73702299, grad/param norm = 1.8790e-01, time/batch = 0.4823s	
2321/2700 (epoch 42.981), train_loss = 0.71863318, grad/param norm = 2.1311e-01, time/batch = 0.4623s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
2322/2700 (epoch 43.000), train_loss = 0.74068251, grad/param norm = 2.1571e-01, time/batch = 0.4793s	
2323/2700 (epoch 43.019), train_loss = 0.85224775, grad/param norm = 2.1421e-01, time/batch = 0.4792s	
2324/2700 (epoch 43.037), train_loss = 0.74810969, grad/param norm = 1.7843e-01, time/batch = 0.5256s	
2325/2700 (epoch 43.056), train_loss = 0.72569985, grad/param norm = 1.6988e-01, time/batch = 0.5133s	
2326/2700 (epoch 43.074), train_loss = 0.70651943, grad/param norm = 1.6453e-01, time/batch = 0.5193s	
2327/2700 (epoch 43.093), train_loss = 0.70396662, grad/param norm = 1.6419e-01, time/batch = 0.4962s	
2328/2700 (epoch 43.111), train_loss = 0.67941431, grad/param norm = 1.5047e-01, time/batch = 0.4813s	
2329/2700 (epoch 43.130), train_loss = 0.70903599, grad/param norm = 1.5490e-01, time/batch = 0.4702s	
2330/2700 (epoch 43.148), train_loss = 0.69460711, grad/param norm = 1.6417e-01, time/batch = 0.4745s	
2331/2700 (epoch 43.167), train_loss = 0.74054159, grad/param norm = 1.9650e-01, time/batch = 0.4828s	
2332/2700 (epoch 43.185), train_loss = 0.68562491, grad/param norm = 1.5661e-01, time/batch = 0.4605s	
2333/2700 (epoch 43.204), train_loss = 0.72466455, grad/param norm = 1.8084e-01, time/batch = 0.4880s	
2334/2700 (epoch 43.222), train_loss = 0.67356850, grad/param norm = 1.7211e-01, time/batch = 0.5110s	
2335/2700 (epoch 43.241), train_loss = 0.66046000, grad/param norm = 1.6997e-01, time/batch = 0.5211s	
2336/2700 (epoch 43.259), train_loss = 0.67294853, grad/param norm = 1.8927e-01, time/batch = 0.5220s	
2337/2700 (epoch 43.278), train_loss = 0.73793925, grad/param norm = 2.0784e-01, time/batch = 0.5053s	
2338/2700 (epoch 43.296), train_loss = 0.70739645, grad/param norm = 1.9465e-01, time/batch = 0.4887s	
2339/2700 (epoch 43.315), train_loss = 0.68379741, grad/param norm = 2.2402e-01, time/batch = 0.4630s	
2340/2700 (epoch 43.333), train_loss = 0.70545291, grad/param norm = 2.7098e-01, time/batch = 0.4227s	
2341/2700 (epoch 43.352), train_loss = 0.69331064, grad/param norm = 2.3249e-01, time/batch = 0.4679s	
2342/2700 (epoch 43.370), train_loss = 0.67820236, grad/param norm = 2.0495e-01, time/batch = 0.4819s	
2343/2700 (epoch 43.389), train_loss = 0.69553376, grad/param norm = 1.9103e-01, time/batch = 0.4852s	
2344/2700 (epoch 43.407), train_loss = 0.75001439, grad/param norm = 1.8352e-01, time/batch = 0.5047s	
2345/2700 (epoch 43.426), train_loss = 0.71367592, grad/param norm = 1.7146e-01, time/batch = 0.5182s	
2346/2700 (epoch 43.444), train_loss = 0.69406534, grad/param norm = 1.7572e-01, time/batch = 0.5235s	
2347/2700 (epoch 43.463), train_loss = 0.71549073, grad/param norm = 1.7833e-01, time/batch = 0.5228s	
2348/2700 (epoch 43.481), train_loss = 0.68546132, grad/param norm = 1.7013e-01, time/batch = 0.5011s	
2349/2700 (epoch 43.500), train_loss = 0.68751411, grad/param norm = 1.6941e-01, time/batch = 0.4398s	
2350/2700 (epoch 43.519), train_loss = 0.71747374, grad/param norm = 1.7730e-01, time/batch = 0.4589s	
2351/2700 (epoch 43.537), train_loss = 0.71712654, grad/param norm = 1.6404e-01, time/batch = 0.4782s	
2352/2700 (epoch 43.556), train_loss = 0.66109966, grad/param norm = 1.8643e-01, time/batch = 0.4766s	
2353/2700 (epoch 43.574), train_loss = 0.67453482, grad/param norm = 2.0221e-01, time/batch = 0.4805s	
2354/2700 (epoch 43.593), train_loss = 0.71884242, grad/param norm = 1.7196e-01, time/batch = 0.4977s	
2355/2700 (epoch 43.611), train_loss = 0.66040944, grad/param norm = 1.6866e-01, time/batch = 0.5089s	
2356/2700 (epoch 43.630), train_loss = 0.68688114, grad/param norm = 1.5484e-01, time/batch = 0.5157s	
2357/2700 (epoch 43.648), train_loss = 0.68857884, grad/param norm = 1.8598e-01, time/batch = 0.5278s	
2358/2700 (epoch 43.667), train_loss = 0.69043542, grad/param norm = 1.7826e-01, time/batch = 0.4707s	
2359/2700 (epoch 43.685), train_loss = 0.71670885, grad/param norm = 1.8927e-01, time/batch = 0.5075s	
2360/2700 (epoch 43.704), train_loss = 0.71892740, grad/param norm = 2.1699e-01, time/batch = 0.4837s	
2361/2700 (epoch 43.722), train_loss = 0.69120022, grad/param norm = 1.9831e-01, time/batch = 0.4348s	
2362/2700 (epoch 43.741), train_loss = 0.70326913, grad/param norm = 1.8528e-01, time/batch = 0.4827s	
2363/2700 (epoch 43.759), train_loss = 0.66462992, grad/param norm = 1.7795e-01, time/batch = 0.5017s	
2364/2700 (epoch 43.778), train_loss = 0.72954813, grad/param norm = 1.6545e-01, time/batch = 0.5078s	
2365/2700 (epoch 43.796), train_loss = 0.69128535, grad/param norm = 2.5213e-01, time/batch = 0.5126s	
2366/2700 (epoch 43.815), train_loss = 0.72843997, grad/param norm = 2.2971e-01, time/batch = 0.5228s	
2367/2700 (epoch 43.833), train_loss = 0.71957219, grad/param norm = 2.1533e-01, time/batch = 0.4662s	
2368/2700 (epoch 43.852), train_loss = 0.67942439, grad/param norm = 2.0174e-01, time/batch = 0.5134s	
2369/2700 (epoch 43.870), train_loss = 0.72017149, grad/param norm = 1.7863e-01, time/batch = 0.5010s	
2370/2700 (epoch 43.889), train_loss = 0.68179969, grad/param norm = 1.5736e-01, time/batch = 0.4561s	
2371/2700 (epoch 43.907), train_loss = 0.73258807, grad/param norm = 2.1242e-01, time/batch = 0.4705s	
2372/2700 (epoch 43.926), train_loss = 0.70945587, grad/param norm = 2.0127e-01, time/batch = 0.4360s	
2373/2700 (epoch 43.944), train_loss = 0.70688014, grad/param norm = 1.9953e-01, time/batch = 0.5106s	
2374/2700 (epoch 43.963), train_loss = 0.71252072, grad/param norm = 2.0589e-01, time/batch = 0.5107s	
2375/2700 (epoch 43.981), train_loss = 0.68951202, grad/param norm = 2.0068e-01, time/batch = 0.5128s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
2376/2700 (epoch 44.000), train_loss = 0.71468075, grad/param norm = 2.1769e-01, time/batch = 0.4953s	
2377/2700 (epoch 44.019), train_loss = 0.82743525, grad/param norm = 1.8140e-01, time/batch = 0.5290s	
2378/2700 (epoch 44.037), train_loss = 0.72571088, grad/param norm = 2.1723e-01, time/batch = 0.4604s	
2379/2700 (epoch 44.056), train_loss = 0.71522914, grad/param norm = 2.1115e-01, time/batch = 0.4672s	
2380/2700 (epoch 44.074), train_loss = 0.68927296, grad/param norm = 2.1906e-01, time/batch = 0.4711s	
2381/2700 (epoch 44.093), train_loss = 0.69374692, grad/param norm = 1.7668e-01, time/batch = 0.4624s	
2382/2700 (epoch 44.111), train_loss = 0.66661036, grad/param norm = 1.7483e-01, time/batch = 0.4788s	
2383/2700 (epoch 44.130), train_loss = 0.69582354, grad/param norm = 1.7979e-01, time/batch = 0.4757s	
2384/2700 (epoch 44.148), train_loss = 0.67909279, grad/param norm = 1.7413e-01, time/batch = 0.5064s	
2385/2700 (epoch 44.167), train_loss = 0.71593768, grad/param norm = 1.9457e-01, time/batch = 0.4915s	
2386/2700 (epoch 44.185), train_loss = 0.68717717, grad/param norm = 2.1224e-01, time/batch = 0.5075s	
2387/2700 (epoch 44.204), train_loss = 0.70138494, grad/param norm = 1.7697e-01, time/batch = 0.5052s	
2388/2700 (epoch 44.222), train_loss = 0.65394363, grad/param norm = 1.9568e-01, time/batch = 0.4874s	
2389/2700 (epoch 44.241), train_loss = 0.64631431, grad/param norm = 1.9316e-01, time/batch = 0.4856s	
2390/2700 (epoch 44.259), train_loss = 0.65025259, grad/param norm = 1.8448e-01, time/batch = 0.4736s	
2391/2700 (epoch 44.278), train_loss = 0.70293036, grad/param norm = 1.8558e-01, time/batch = 0.4627s	
2392/2700 (epoch 44.296), train_loss = 0.68417431, grad/param norm = 1.9914e-01, time/batch = 0.4739s	
2393/2700 (epoch 44.315), train_loss = 0.65401428, grad/param norm = 1.9169e-01, time/batch = 0.5035s	
2394/2700 (epoch 44.333), train_loss = 0.66601051, grad/param norm = 1.9576e-01, time/batch = 0.5072s	
2395/2700 (epoch 44.352), train_loss = 0.64895787, grad/param norm = 1.8362e-01, time/batch = 0.4767s	
2396/2700 (epoch 44.370), train_loss = 0.64872697, grad/param norm = 1.7754e-01, time/batch = 0.5048s	
2397/2700 (epoch 44.389), train_loss = 0.67058334, grad/param norm = 1.7640e-01, time/batch = 0.5020s	
2398/2700 (epoch 44.407), train_loss = 0.72584477, grad/param norm = 1.7905e-01, time/batch = 0.4825s	
2399/2700 (epoch 44.426), train_loss = 0.68903192, grad/param norm = 1.8212e-01, time/batch = 0.4815s	
2400/2700 (epoch 44.444), train_loss = 0.66763256, grad/param norm = 1.6218e-01, time/batch = 0.4801s	
2401/2700 (epoch 44.463), train_loss = 0.69060431, grad/param norm = 1.7738e-01, time/batch = 0.4644s	
2402/2700 (epoch 44.481), train_loss = 0.66957065, grad/param norm = 1.8137e-01, time/batch = 0.4809s	
2403/2700 (epoch 44.500), train_loss = 0.67013962, grad/param norm = 2.1471e-01, time/batch = 0.5130s	
2404/2700 (epoch 44.519), train_loss = 0.69300547, grad/param norm = 1.8548e-01, time/batch = 0.4848s	
2405/2700 (epoch 44.537), train_loss = 0.69474266, grad/param norm = 2.0423e-01, time/batch = 0.5069s	
2406/2700 (epoch 44.556), train_loss = 0.63700914, grad/param norm = 1.8457e-01, time/batch = 0.5027s	
2407/2700 (epoch 44.574), train_loss = 0.64740661, grad/param norm = 1.8901e-01, time/batch = 0.4992s	
2408/2700 (epoch 44.593), train_loss = 0.69841666, grad/param norm = 1.8606e-01, time/batch = 0.4807s	
2409/2700 (epoch 44.611), train_loss = 0.64602092, grad/param norm = 2.0734e-01, time/batch = 0.4798s	
2410/2700 (epoch 44.630), train_loss = 0.67419492, grad/param norm = 1.8735e-01, time/batch = 0.4817s	
2411/2700 (epoch 44.648), train_loss = 0.65997807, grad/param norm = 1.7383e-01, time/batch = 0.4797s	
2412/2700 (epoch 44.667), train_loss = 0.66744073, grad/param norm = 1.8497e-01, time/batch = 0.4812s	
2413/2700 (epoch 44.685), train_loss = 0.69181624, grad/param norm = 1.7900e-01, time/batch = 0.4601s	
2414/2700 (epoch 44.704), train_loss = 0.69411206, grad/param norm = 1.9856e-01, time/batch = 0.5165s	
2415/2700 (epoch 44.722), train_loss = 0.66220582, grad/param norm = 1.8911e-01, time/batch = 0.5246s	
2416/2700 (epoch 44.741), train_loss = 0.68127358, grad/param norm = 1.8295e-01, time/batch = 0.5055s	
2417/2700 (epoch 44.759), train_loss = 0.65066594, grad/param norm = 2.0693e-01, time/batch = 0.4884s	
2418/2700 (epoch 44.778), train_loss = 0.71456474, grad/param norm = 2.2409e-01, time/batch = 0.4788s	
2419/2700 (epoch 44.796), train_loss = 0.65793806, grad/param norm = 1.9703e-01, time/batch = 0.4772s	
2420/2700 (epoch 44.815), train_loss = 0.67985615, grad/param norm = 1.8842e-01, time/batch = 0.4824s	
2421/2700 (epoch 44.833), train_loss = 0.69378040, grad/param norm = 2.3745e-01, time/batch = 0.4832s	
2422/2700 (epoch 44.852), train_loss = 0.65755132, grad/param norm = 1.8423e-01, time/batch = 0.4609s	
2423/2700 (epoch 44.870), train_loss = 0.70065490, grad/param norm = 2.2169e-01, time/batch = 0.4907s	
2424/2700 (epoch 44.889), train_loss = 0.68041815, grad/param norm = 2.0743e-01, time/batch = 0.4873s	
2425/2700 (epoch 44.907), train_loss = 0.71172978, grad/param norm = 1.9970e-01, time/batch = 0.5145s	
2426/2700 (epoch 44.926), train_loss = 0.68154174, grad/param norm = 2.1204e-01, time/batch = 0.5210s	
2427/2700 (epoch 44.944), train_loss = 0.68256515, grad/param norm = 1.9483e-01, time/batch = 0.5033s	
2428/2700 (epoch 44.963), train_loss = 0.68189992, grad/param norm = 1.7731e-01, time/batch = 0.4907s	
2429/2700 (epoch 44.981), train_loss = 0.66200393, grad/param norm = 1.9047e-01, time/batch = 0.4768s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
2430/2700 (epoch 45.000), train_loss = 0.68305038, grad/param norm = 2.0029e-01, time/batch = 0.4819s	
2431/2700 (epoch 45.019), train_loss = 0.80059973, grad/param norm = 2.0695e-01, time/batch = 0.4785s	
2432/2700 (epoch 45.037), train_loss = 0.69941808, grad/param norm = 1.8511e-01, time/batch = 0.4819s	
2433/2700 (epoch 45.056), train_loss = 0.67950038, grad/param norm = 1.9021e-01, time/batch = 0.4540s	
2434/2700 (epoch 45.074), train_loss = 0.66300991, grad/param norm = 1.9068e-01, time/batch = 0.4818s	
2435/2700 (epoch 45.093), train_loss = 0.66320070, grad/param norm = 1.7995e-01, time/batch = 0.4956s	
2436/2700 (epoch 45.111), train_loss = 0.63421038, grad/param norm = 1.5962e-01, time/batch = 0.5102s	
2437/2700 (epoch 45.130), train_loss = 0.66625415, grad/param norm = 1.6784e-01, time/batch = 0.5215s	
2438/2700 (epoch 45.148), train_loss = 0.65420286, grad/param norm = 1.6756e-01, time/batch = 0.5051s	
2439/2700 (epoch 45.167), train_loss = 0.68374786, grad/param norm = 1.6007e-01, time/batch = 0.4972s	
2440/2700 (epoch 45.185), train_loss = 0.63642150, grad/param norm = 1.6549e-01, time/batch = 0.4961s	
2441/2700 (epoch 45.204), train_loss = 0.67914664, grad/param norm = 2.0549e-01, time/batch = 0.5071s	
2442/2700 (epoch 45.222), train_loss = 0.62189742, grad/param norm = 1.8236e-01, time/batch = 0.4665s	
2443/2700 (epoch 45.241), train_loss = 0.62582283, grad/param norm = 1.9649e-01, time/batch = 0.4927s	
2444/2700 (epoch 45.259), train_loss = 0.62089763, grad/param norm = 1.6245e-01, time/batch = 0.4801s	
2445/2700 (epoch 45.278), train_loss = 0.67695192, grad/param norm = 1.6995e-01, time/batch = 0.4776s	
2446/2700 (epoch 45.296), train_loss = 0.65185999, grad/param norm = 1.8735e-01, time/batch = 0.4701s	
2447/2700 (epoch 45.315), train_loss = 0.62949405, grad/param norm = 1.8954e-01, time/batch = 0.4970s	
2448/2700 (epoch 45.333), train_loss = 0.64106659, grad/param norm = 2.0960e-01, time/batch = 0.5192s	
2449/2700 (epoch 45.352), train_loss = 0.62661806, grad/param norm = 1.9869e-01, time/batch = 0.5115s	
2450/2700 (epoch 45.370), train_loss = 0.63042003, grad/param norm = 1.9878e-01, time/batch = 0.4808s	
2451/2700 (epoch 45.389), train_loss = 0.65050946, grad/param norm = 2.0452e-01, time/batch = 0.4990s	
2452/2700 (epoch 45.407), train_loss = 0.70424481, grad/param norm = 2.1537e-01, time/batch = 0.4606s	
2453/2700 (epoch 45.426), train_loss = 0.67422106, grad/param norm = 2.1641e-01, time/batch = 0.4130s	
2454/2700 (epoch 45.444), train_loss = 0.64508721, grad/param norm = 1.8736e-01, time/batch = 0.3965s	
2455/2700 (epoch 45.463), train_loss = 0.66668569, grad/param norm = 1.8408e-01, time/batch = 0.4196s	
2456/2700 (epoch 45.481), train_loss = 0.64607383, grad/param norm = 1.8371e-01, time/batch = 0.3925s	
2457/2700 (epoch 45.500), train_loss = 0.64923008, grad/param norm = 1.7437e-01, time/batch = 0.3775s	
2458/2700 (epoch 45.519), train_loss = 0.67882133, grad/param norm = 2.2614e-01, time/batch = 0.3995s	
2459/2700 (epoch 45.537), train_loss = 0.68843013, grad/param norm = 2.2268e-01, time/batch = 0.3419s	
2460/2700 (epoch 45.556), train_loss = 0.62406641, grad/param norm = 2.2755e-01, time/batch = 0.2293s	
2461/2700 (epoch 45.574), train_loss = 0.63661111, grad/param norm = 2.0921e-01, time/batch = 0.2468s	
2462/2700 (epoch 45.593), train_loss = 0.68319191, grad/param norm = 2.1569e-01, time/batch = 0.2465s	
2463/2700 (epoch 45.611), train_loss = 0.62540813, grad/param norm = 2.0345e-01, time/batch = 0.2458s	
2464/2700 (epoch 45.630), train_loss = 0.65331673, grad/param norm = 1.8239e-01, time/batch = 0.2485s	
2465/2700 (epoch 45.648), train_loss = 0.65579354, grad/param norm = 2.1161e-01, time/batch = 0.2504s	
2466/2700 (epoch 45.667), train_loss = 0.63852073, grad/param norm = 1.6046e-01, time/batch = 0.2399s	
2467/2700 (epoch 45.685), train_loss = 0.66488314, grad/param norm = 1.6543e-01, time/batch = 0.2239s	
2468/2700 (epoch 45.704), train_loss = 0.67012040, grad/param norm = 1.8945e-01, time/batch = 0.2198s	
2469/2700 (epoch 45.722), train_loss = 0.64278765, grad/param norm = 1.9297e-01, time/batch = 0.2184s	
2470/2700 (epoch 45.741), train_loss = 0.65596279, grad/param norm = 1.7569e-01, time/batch = 0.2294s	
2471/2700 (epoch 45.759), train_loss = 0.62044764, grad/param norm = 1.7699e-01, time/batch = 0.1797s	
2472/2700 (epoch 45.778), train_loss = 0.69121960, grad/param norm = 2.2287e-01, time/batch = 0.2499s	
2473/2700 (epoch 45.796), train_loss = 0.64290766, grad/param norm = 2.1901e-01, time/batch = 0.2440s	
2474/2700 (epoch 45.815), train_loss = 0.67356832, grad/param norm = 2.2326e-01, time/batch = 0.2253s	
2475/2700 (epoch 45.833), train_loss = 0.66491703, grad/param norm = 1.9415e-01, time/batch = 0.2243s	
2476/2700 (epoch 45.852), train_loss = 0.63134759, grad/param norm = 2.1736e-01, time/batch = 0.2216s	
2477/2700 (epoch 45.870), train_loss = 0.68261819, grad/param norm = 2.2117e-01, time/batch = 0.2216s	
2478/2700 (epoch 45.889), train_loss = 0.64673093, grad/param norm = 1.8977e-01, time/batch = 0.2397s	
2479/2700 (epoch 45.907), train_loss = 0.68534043, grad/param norm = 1.9078e-01, time/batch = 0.2454s	
2480/2700 (epoch 45.926), train_loss = 0.65831140, grad/param norm = 2.0530e-01, time/batch = 0.2453s	
2481/2700 (epoch 45.944), train_loss = 0.65872709, grad/param norm = 2.0200e-01, time/batch = 0.2348s	
2482/2700 (epoch 45.963), train_loss = 0.66330876, grad/param norm = 1.9793e-01, time/batch = 0.2195s	
2483/2700 (epoch 45.981), train_loss = 0.64156387, grad/param norm = 2.1058e-01, time/batch = 0.2506s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
2484/2700 (epoch 46.000), train_loss = 0.65370726, grad/param norm = 1.8436e-01, time/batch = 0.2335s	
2485/2700 (epoch 46.019), train_loss = 0.76931627, grad/param norm = 1.8866e-01, time/batch = 0.2245s	
2486/2700 (epoch 46.037), train_loss = 0.67192963, grad/param norm = 1.6627e-01, time/batch = 0.2215s	
2487/2700 (epoch 46.056), train_loss = 0.65208398, grad/param norm = 1.6318e-01, time/batch = 0.2180s	
2488/2700 (epoch 46.074), train_loss = 0.62539768, grad/param norm = 1.7891e-01, time/batch = 0.2334s	
2489/2700 (epoch 46.093), train_loss = 0.63907053, grad/param norm = 1.7932e-01, time/batch = 0.2463s	
2490/2700 (epoch 46.111), train_loss = 0.61710880, grad/param norm = 1.7570e-01, time/batch = 0.2454s	
2491/2700 (epoch 46.130), train_loss = 0.64154837, grad/param norm = 1.7152e-01, time/batch = 0.2287s	
2492/2700 (epoch 46.148), train_loss = 0.62884937, grad/param norm = 1.7515e-01, time/batch = 0.2445s	
2493/2700 (epoch 46.167), train_loss = 0.66704028, grad/param norm = 1.8606e-01, time/batch = 0.2223s	
2494/2700 (epoch 46.185), train_loss = 0.61833761, grad/param norm = 1.6056e-01, time/batch = 0.2494s	
2495/2700 (epoch 46.204), train_loss = 0.65399956, grad/param norm = 1.8224e-01, time/batch = 0.2307s	
2496/2700 (epoch 46.222), train_loss = 0.60999504, grad/param norm = 2.3826e-01, time/batch = 0.2217s	
2497/2700 (epoch 46.241), train_loss = 0.60687661, grad/param norm = 2.1368e-01, time/batch = 0.2195s	
2498/2700 (epoch 46.259), train_loss = 0.61702670, grad/param norm = 2.1930e-01, time/batch = 0.2200s	
2499/2700 (epoch 46.278), train_loss = 0.66498742, grad/param norm = 2.0217e-01, time/batch = 0.2372s	
2500/2700 (epoch 46.296), train_loss = 0.62892326, grad/param norm = 1.7208e-01, time/batch = 0.2454s	
2501/2700 (epoch 46.315), train_loss = 0.60687414, grad/param norm = 1.8389e-01, time/batch = 0.2278s	
2502/2700 (epoch 46.333), train_loss = 0.61648291, grad/param norm = 2.0624e-01, time/batch = 0.2416s	
2503/2700 (epoch 46.352), train_loss = 0.60483421, grad/param norm = 1.8728e-01, time/batch = 0.2454s	
2504/2700 (epoch 46.370), train_loss = 0.60454070, grad/param norm = 1.7537e-01, time/batch = 0.2276s	
2505/2700 (epoch 46.389), train_loss = 0.62247865, grad/param norm = 1.8617e-01, time/batch = 0.2443s	
2506/2700 (epoch 46.407), train_loss = 0.68104414, grad/param norm = 1.9433e-01, time/batch = 0.2272s	
2507/2700 (epoch 46.426), train_loss = 0.65049748, grad/param norm = 2.2679e-01, time/batch = 0.2229s	
2508/2700 (epoch 46.444), train_loss = 0.64484013, grad/param norm = 2.2329e-01, time/batch = 0.2186s	
2509/2700 (epoch 46.463), train_loss = 0.64623283, grad/param norm = 2.0464e-01, time/batch = 0.2259s	
2510/2700 (epoch 46.481), train_loss = 0.63008233, grad/param norm = 2.0629e-01, time/batch = 0.2410s	
2511/2700 (epoch 46.500), train_loss = 0.62570627, grad/param norm = 1.7471e-01, time/batch = 0.2187s	
2512/2700 (epoch 46.519), train_loss = 0.64668376, grad/param norm = 1.6218e-01, time/batch = 0.2352s	
2513/2700 (epoch 46.537), train_loss = 0.64406012, grad/param norm = 1.7668e-01, time/batch = 0.2474s	
2514/2700 (epoch 46.556), train_loss = 0.59657848, grad/param norm = 1.8691e-01, time/batch = 0.2453s	
2515/2700 (epoch 46.574), train_loss = 0.60360576, grad/param norm = 1.9205e-01, time/batch = 0.2280s	
2516/2700 (epoch 46.593), train_loss = 0.65009298, grad/param norm = 1.7213e-01, time/batch = 0.2378s	
2517/2700 (epoch 46.611), train_loss = 0.59446187, grad/param norm = 1.7274e-01, time/batch = 0.2226s	
2518/2700 (epoch 46.630), train_loss = 0.62805754, grad/param norm = 2.0270e-01, time/batch = 0.2214s	
2519/2700 (epoch 46.648), train_loss = 0.63130976, grad/param norm = 2.1220e-01, time/batch = 0.2211s	
2520/2700 (epoch 46.667), train_loss = 0.62307113, grad/param norm = 2.0341e-01, time/batch = 0.2283s	
2521/2700 (epoch 46.685), train_loss = 0.65468138, grad/param norm = 2.1567e-01, time/batch = 0.2193s	
2522/2700 (epoch 46.704), train_loss = 0.64896772, grad/param norm = 1.9485e-01, time/batch = 0.2313s	
2523/2700 (epoch 46.722), train_loss = 0.61600878, grad/param norm = 1.8689e-01, time/batch = 0.2453s	
2524/2700 (epoch 46.741), train_loss = 0.62849606, grad/param norm = 1.6531e-01, time/batch = 0.2453s	
2525/2700 (epoch 46.759), train_loss = 0.60322123, grad/param norm = 2.1223e-01, time/batch = 0.2465s	
2526/2700 (epoch 46.778), train_loss = 0.66743425, grad/param norm = 2.1927e-01, time/batch = 0.2377s	
2527/2700 (epoch 46.796), train_loss = 0.63034460, grad/param norm = 2.4235e-01, time/batch = 0.1955s	
2528/2700 (epoch 46.815), train_loss = 0.63832839, grad/param norm = 1.8976e-01, time/batch = 0.2226s	
2529/2700 (epoch 46.833), train_loss = 0.64104073, grad/param norm = 1.9317e-01, time/batch = 0.2262s	
2530/2700 (epoch 46.852), train_loss = 0.60953388, grad/param norm = 1.8764e-01, time/batch = 0.2450s	
2531/2700 (epoch 46.870), train_loss = 0.64553475, grad/param norm = 1.6920e-01, time/batch = 0.2227s	
2532/2700 (epoch 46.889), train_loss = 0.61782619, grad/param norm = 1.8311e-01, time/batch = 0.2372s	
2533/2700 (epoch 46.907), train_loss = 0.66235591, grad/param norm = 2.0281e-01, time/batch = 0.2452s	
2534/2700 (epoch 46.926), train_loss = 0.62800426, grad/param norm = 1.7164e-01, time/batch = 0.2464s	
2535/2700 (epoch 46.944), train_loss = 0.62175587, grad/param norm = 1.6869e-01, time/batch = 0.2462s	
2536/2700 (epoch 46.963), train_loss = 0.63444143, grad/param norm = 1.8545e-01, time/batch = 0.2487s	
2537/2700 (epoch 46.981), train_loss = 0.60624369, grad/param norm = 1.6602e-01, time/batch = 0.2501s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
2538/2700 (epoch 47.000), train_loss = 0.63847696, grad/param norm = 2.4164e-01, time/batch = 0.1340s	
2539/2700 (epoch 47.019), train_loss = 0.75560912, grad/param norm = 2.1099e-01, time/batch = 0.2468s	
2540/2700 (epoch 47.037), train_loss = 0.65622320, grad/param norm = 2.0194e-01, time/batch = 0.2492s	
2541/2700 (epoch 47.056), train_loss = 0.63095908, grad/param norm = 1.8829e-01, time/batch = 0.2472s	
2542/2700 (epoch 47.074), train_loss = 0.60935876, grad/param norm = 2.0324e-01, time/batch = 0.2459s	
2543/2700 (epoch 47.093), train_loss = 0.62156477, grad/param norm = 1.8264e-01, time/batch = 0.2463s	
2544/2700 (epoch 47.111), train_loss = 0.59056392, grad/param norm = 1.6576e-01, time/batch = 0.2471s	
2545/2700 (epoch 47.130), train_loss = 0.62165460, grad/param norm = 1.6265e-01, time/batch = 0.2496s	
2546/2700 (epoch 47.148), train_loss = 0.61226402, grad/param norm = 1.7559e-01, time/batch = 0.2449s	
2547/2700 (epoch 47.167), train_loss = 0.64225334, grad/param norm = 1.8065e-01, time/batch = 0.2251s	
2548/2700 (epoch 47.185), train_loss = 0.60077205, grad/param norm = 1.9746e-01, time/batch = 0.2234s	
2549/2700 (epoch 47.204), train_loss = 0.62864381, grad/param norm = 1.9267e-01, time/batch = 0.1683s	
2550/2700 (epoch 47.222), train_loss = 0.58213306, grad/param norm = 1.9351e-01, time/batch = 0.2491s	
2551/2700 (epoch 47.241), train_loss = 0.58951073, grad/param norm = 2.3992e-01, time/batch = 0.2472s	
2552/2700 (epoch 47.259), train_loss = 0.59270590, grad/param norm = 2.0975e-01, time/batch = 0.2463s	
2553/2700 (epoch 47.278), train_loss = 0.64171615, grad/param norm = 2.0018e-01, time/batch = 0.2456s	
2554/2700 (epoch 47.296), train_loss = 0.61602670, grad/param norm = 2.0373e-01, time/batch = 0.2472s	
2555/2700 (epoch 47.315), train_loss = 0.58312171, grad/param norm = 1.7640e-01, time/batch = 0.2508s	
2556/2700 (epoch 47.333), train_loss = 0.59348254, grad/param norm = 1.8006e-01, time/batch = 0.2384s	
2557/2700 (epoch 47.352), train_loss = 0.58342597, grad/param norm = 1.7831e-01, time/batch = 0.2241s	
2558/2700 (epoch 47.370), train_loss = 0.58300454, grad/param norm = 1.7721e-01, time/batch = 0.2207s	
2559/2700 (epoch 47.389), train_loss = 0.59875770, grad/param norm = 1.9237e-01, time/batch = 0.2218s	
2560/2700 (epoch 47.407), train_loss = 0.65104088, grad/param norm = 1.7576e-01, time/batch = 0.1938s	
2561/2700 (epoch 47.426), train_loss = 0.60944973, grad/param norm = 1.5659e-01, time/batch = 0.2437s	
2562/2700 (epoch 47.444), train_loss = 0.60177874, grad/param norm = 1.8048e-01, time/batch = 0.2453s	
2563/2700 (epoch 47.463), train_loss = 0.62244594, grad/param norm = 1.9857e-01, time/batch = 0.2454s	
2564/2700 (epoch 47.481), train_loss = 0.60315380, grad/param norm = 1.9374e-01, time/batch = 0.2470s	
2565/2700 (epoch 47.500), train_loss = 0.61017367, grad/param norm = 2.0209e-01, time/batch = 0.2498s	
2566/2700 (epoch 47.519), train_loss = 0.63177950, grad/param norm = 1.9445e-01, time/batch = 0.2442s	
2567/2700 (epoch 47.537), train_loss = 0.62674038, grad/param norm = 1.8415e-01, time/batch = 0.2264s	
2568/2700 (epoch 47.556), train_loss = 0.57194530, grad/param norm = 1.7512e-01, time/batch = 0.2233s	
2569/2700 (epoch 47.574), train_loss = 0.57879019, grad/param norm = 1.8076e-01, time/batch = 0.2224s	
2570/2700 (epoch 47.593), train_loss = 0.62622684, grad/param norm = 1.8314e-01, time/batch = 0.2220s	
2571/2700 (epoch 47.611), train_loss = 0.57175740, grad/param norm = 1.6776e-01, time/batch = 0.1742s	
2572/2700 (epoch 47.630), train_loss = 0.60246252, grad/param norm = 1.6842e-01, time/batch = 0.2498s	
2573/2700 (epoch 47.648), train_loss = 0.59942105, grad/param norm = 1.8574e-01, time/batch = 0.2469s	
2574/2700 (epoch 47.667), train_loss = 0.59651452, grad/param norm = 1.9541e-01, time/batch = 0.2280s	
2575/2700 (epoch 47.685), train_loss = 0.62748618, grad/param norm = 2.0421e-01, time/batch = 0.2238s	
2576/2700 (epoch 47.704), train_loss = 0.63033343, grad/param norm = 2.2776e-01, time/batch = 0.2215s	
2577/2700 (epoch 47.722), train_loss = 0.60876311, grad/param norm = 2.0697e-01, time/batch = 0.2215s	
2578/2700 (epoch 47.741), train_loss = 0.61202385, grad/param norm = 1.8556e-01, time/batch = 0.2352s	
2579/2700 (epoch 47.759), train_loss = 0.57746665, grad/param norm = 1.8510e-01, time/batch = 0.2456s	
2580/2700 (epoch 47.778), train_loss = 0.64249208, grad/param norm = 2.1393e-01, time/batch = 0.2453s	
2581/2700 (epoch 47.796), train_loss = 0.58173930, grad/param norm = 1.8078e-01, time/batch = 0.2330s	
2582/2700 (epoch 47.815), train_loss = 0.62908410, grad/param norm = 2.3404e-01, time/batch = 0.2192s	
2583/2700 (epoch 47.833), train_loss = 0.63874821, grad/param norm = 2.4972e-01, time/batch = 0.2513s	
2584/2700 (epoch 47.852), train_loss = 0.59074134, grad/param norm = 1.7695e-01, time/batch = 0.2337s	
2585/2700 (epoch 47.870), train_loss = 0.62810641, grad/param norm = 1.9218e-01, time/batch = 0.2247s	
2586/2700 (epoch 47.889), train_loss = 0.59703446, grad/param norm = 1.6767e-01, time/batch = 0.2228s	
2587/2700 (epoch 47.907), train_loss = 0.63013122, grad/param norm = 1.8383e-01, time/batch = 0.2213s	
2588/2700 (epoch 47.926), train_loss = 0.60789122, grad/param norm = 1.7734e-01, time/batch = 0.2322s	
2589/2700 (epoch 47.944), train_loss = 0.60210996, grad/param norm = 1.9215e-01, time/batch = 0.2467s	
2590/2700 (epoch 47.963), train_loss = 0.60589898, grad/param norm = 1.6002e-01, time/batch = 0.2467s	
2591/2700 (epoch 47.981), train_loss = 0.58811483, grad/param norm = 1.7649e-01, time/batch = 0.2276s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
2592/2700 (epoch 48.000), train_loss = 0.61140724, grad/param norm = 1.8838e-01, time/batch = 0.2456s	
2593/2700 (epoch 48.019), train_loss = 0.71888328, grad/param norm = 1.8643e-01, time/batch = 0.2213s	
2594/2700 (epoch 48.037), train_loss = 0.62423806, grad/param norm = 1.5829e-01, time/batch = 0.2432s	
2595/2700 (epoch 48.056), train_loss = 0.60045929, grad/param norm = 1.6809e-01, time/batch = 0.2257s	
2596/2700 (epoch 48.074), train_loss = 0.58250961, grad/param norm = 1.8714e-01, time/batch = 0.2212s	
2597/2700 (epoch 48.093), train_loss = 0.59532863, grad/param norm = 1.8274e-01, time/batch = 0.2187s	
2598/2700 (epoch 48.111), train_loss = 0.58058075, grad/param norm = 1.8942e-01, time/batch = 0.2269s	
2599/2700 (epoch 48.130), train_loss = 0.60141853, grad/param norm = 1.7829e-01, time/batch = 0.2446s	
2600/2700 (epoch 48.148), train_loss = 0.59341087, grad/param norm = 1.8203e-01, time/batch = 0.2464s	
2601/2700 (epoch 48.167), train_loss = 0.62143622, grad/param norm = 1.7299e-01, time/batch = 0.2263s	
2602/2700 (epoch 48.185), train_loss = 0.57876464, grad/param norm = 1.7696e-01, time/batch = 0.2434s	
2603/2700 (epoch 48.204), train_loss = 0.60748680, grad/param norm = 1.7871e-01, time/batch = 0.2455s	
2604/2700 (epoch 48.222), train_loss = 0.55923033, grad/param norm = 2.2641e-01, time/batch = 0.2265s	
2605/2700 (epoch 48.241), train_loss = 0.56426522, grad/param norm = 1.9967e-01, time/batch = 0.2442s	
2606/2700 (epoch 48.259), train_loss = 0.56703975, grad/param norm = 2.0595e-01, time/batch = 0.2269s	
2607/2700 (epoch 48.278), train_loss = 0.61851205, grad/param norm = 1.8709e-01, time/batch = 0.2221s	
2608/2700 (epoch 48.296), train_loss = 0.58410508, grad/param norm = 1.8374e-01, time/batch = 0.2191s	
2609/2700 (epoch 48.315), train_loss = 0.56356623, grad/param norm = 1.7893e-01, time/batch = 0.2241s	
2610/2700 (epoch 48.333), train_loss = 0.56500907, grad/param norm = 1.6525e-01, time/batch = 0.2421s	
2611/2700 (epoch 48.352), train_loss = 0.55053016, grad/param norm = 1.4761e-01, time/batch = 0.2205s	
2612/2700 (epoch 48.370), train_loss = 0.55527603, grad/param norm = 1.5598e-01, time/batch = 0.2371s	
2613/2700 (epoch 48.389), train_loss = 0.57455476, grad/param norm = 1.5974e-01, time/batch = 0.2453s	
2614/2700 (epoch 48.407), train_loss = 0.62416146, grad/param norm = 1.8013e-01, time/batch = 0.2464s	
2615/2700 (epoch 48.426), train_loss = 0.59673567, grad/param norm = 1.8315e-01, time/batch = 0.2298s	
2616/2700 (epoch 48.444), train_loss = 0.58036664, grad/param norm = 1.8319e-01, time/batch = 0.2315s	
2617/2700 (epoch 48.463), train_loss = 0.59649732, grad/param norm = 1.6966e-01, time/batch = 0.2222s	
2618/2700 (epoch 48.481), train_loss = 0.58203807, grad/param norm = 2.1238e-01, time/batch = 0.2235s	
2619/2700 (epoch 48.500), train_loss = 0.58752909, grad/param norm = 2.0030e-01, time/batch = 0.2201s	
2620/2700 (epoch 48.519), train_loss = 0.60980130, grad/param norm = 2.0431e-01, time/batch = 0.2347s	
2621/2700 (epoch 48.537), train_loss = 0.61011462, grad/param norm = 2.0961e-01, time/batch = 0.2191s	
2622/2700 (epoch 48.556), train_loss = 0.55763427, grad/param norm = 1.8744e-01, time/batch = 0.2340s	
2623/2700 (epoch 48.574), train_loss = 0.56042052, grad/param norm = 1.8247e-01, time/batch = 0.2465s	
2624/2700 (epoch 48.593), train_loss = 0.61528912, grad/param norm = 1.9369e-01, time/batch = 0.2453s	
2625/2700 (epoch 48.611), train_loss = 0.56452606, grad/param norm = 2.2631e-01, time/batch = 0.2476s	
2626/2700 (epoch 48.630), train_loss = 0.59299437, grad/param norm = 2.0134e-01, time/batch = 0.2356s	
2627/2700 (epoch 48.648), train_loss = 0.58180056, grad/param norm = 1.8739e-01, time/batch = 0.1953s	
2628/2700 (epoch 48.667), train_loss = 0.58301238, grad/param norm = 2.0721e-01, time/batch = 0.2223s	
2629/2700 (epoch 48.685), train_loss = 0.61396776, grad/param norm = 2.0513e-01, time/batch = 0.2277s	
2630/2700 (epoch 48.704), train_loss = 0.60228112, grad/param norm = 1.8136e-01, time/batch = 0.2453s	
2631/2700 (epoch 48.722), train_loss = 0.57215180, grad/param norm = 1.9219e-01, time/batch = 0.2202s	
2632/2700 (epoch 48.741), train_loss = 0.59261504, grad/param norm = 1.7271e-01, time/batch = 0.2366s	
2633/2700 (epoch 48.759), train_loss = 0.55490115, grad/param norm = 1.8901e-01, time/batch = 0.2467s	
2634/2700 (epoch 48.778), train_loss = 0.61677965, grad/param norm = 2.0358e-01, time/batch = 0.2465s	
2635/2700 (epoch 48.796), train_loss = 0.57354231, grad/param norm = 2.2891e-01, time/batch = 0.2476s	
2636/2700 (epoch 48.815), train_loss = 0.59280351, grad/param norm = 1.9792e-01, time/batch = 0.2475s	
2637/2700 (epoch 48.833), train_loss = 0.59064272, grad/param norm = 1.8483e-01, time/batch = 0.2468s	
2638/2700 (epoch 48.852), train_loss = 0.56589744, grad/param norm = 2.0411e-01, time/batch = 0.1417s	
2639/2700 (epoch 48.870), train_loss = 0.61050797, grad/param norm = 1.9072e-01, time/batch = 0.2462s	
2640/2700 (epoch 48.889), train_loss = 0.57425095, grad/param norm = 1.7737e-01, time/batch = 0.2478s	
2641/2700 (epoch 48.907), train_loss = 0.61571737, grad/param norm = 2.0403e-01, time/batch = 0.2408s	
2642/2700 (epoch 48.926), train_loss = 0.59366399, grad/param norm = 2.1260e-01, time/batch = 0.2456s	
2643/2700 (epoch 48.944), train_loss = 0.58379876, grad/param norm = 1.7835e-01, time/batch = 0.2451s	
2644/2700 (epoch 48.963), train_loss = 0.58526655, grad/param norm = 1.6487e-01, time/batch = 0.2472s	
2645/2700 (epoch 48.981), train_loss = 0.56051728, grad/param norm = 1.6027e-01, time/batch = 0.2494s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
2646/2700 (epoch 49.000), train_loss = 0.58393296, grad/param norm = 1.8799e-01, time/batch = 0.2484s	
2647/2700 (epoch 49.019), train_loss = 0.69964498, grad/param norm = 1.9994e-01, time/batch = 0.2308s	
2648/2700 (epoch 49.037), train_loss = 0.60467560, grad/param norm = 1.8373e-01, time/batch = 0.2229s	
2649/2700 (epoch 49.056), train_loss = 0.58621157, grad/param norm = 1.6807e-01, time/batch = 0.1628s	
2650/2700 (epoch 49.074), train_loss = 0.55708009, grad/param norm = 1.7710e-01, time/batch = 0.2493s	
2651/2700 (epoch 49.093), train_loss = 0.57427572, grad/param norm = 1.7081e-01, time/batch = 0.2470s	
2652/2700 (epoch 49.111), train_loss = 0.55429741, grad/param norm = 1.8489e-01, time/batch = 0.2452s	
2653/2700 (epoch 49.130), train_loss = 0.58038996, grad/param norm = 1.7477e-01, time/batch = 0.2459s	
2654/2700 (epoch 49.148), train_loss = 0.57403423, grad/param norm = 1.7396e-01, time/batch = 0.2478s	
2655/2700 (epoch 49.167), train_loss = 0.60270472, grad/param norm = 1.8404e-01, time/batch = 0.2497s	
2656/2700 (epoch 49.185), train_loss = 0.55324749, grad/param norm = 1.6118e-01, time/batch = 0.2421s	
2657/2700 (epoch 49.204), train_loss = 0.58639992, grad/param norm = 1.8967e-01, time/batch = 0.2246s	
2658/2700 (epoch 49.222), train_loss = 0.53833866, grad/param norm = 2.0536e-01, time/batch = 0.2214s	
2659/2700 (epoch 49.241), train_loss = 0.54443750, grad/param norm = 2.0740e-01, time/batch = 0.2223s	
2660/2700 (epoch 49.259), train_loss = 0.54935806, grad/param norm = 2.0944e-01, time/batch = 0.1913s	
2661/2700 (epoch 49.278), train_loss = 0.60563989, grad/param norm = 2.0395e-01, time/batch = 0.2452s	
2662/2700 (epoch 49.296), train_loss = 0.57585800, grad/param norm = 2.1165e-01, time/batch = 0.2453s	
2663/2700 (epoch 49.315), train_loss = 0.54237834, grad/param norm = 1.8712e-01, time/batch = 0.2452s	
2664/2700 (epoch 49.333), train_loss = 0.55179494, grad/param norm = 1.6565e-01, time/batch = 0.2475s	
2665/2700 (epoch 49.352), train_loss = 0.53905357, grad/param norm = 1.9338e-01, time/batch = 0.2493s	
2666/2700 (epoch 49.370), train_loss = 0.54019510, grad/param norm = 1.7151e-01, time/batch = 0.2488s	
2667/2700 (epoch 49.389), train_loss = 0.55033658, grad/param norm = 1.5527e-01, time/batch = 0.2296s	
2668/2700 (epoch 49.407), train_loss = 0.60743515, grad/param norm = 2.0011e-01, time/batch = 0.2246s	
2669/2700 (epoch 49.426), train_loss = 0.56932248, grad/param norm = 1.7322e-01, time/batch = 0.2222s	
2670/2700 (epoch 49.444), train_loss = 0.55926933, grad/param norm = 1.8541e-01, time/batch = 0.2172s	
2671/2700 (epoch 49.463), train_loss = 0.57641784, grad/param norm = 1.8493e-01, time/batch = 0.1675s	
2672/2700 (epoch 49.481), train_loss = 0.56481705, grad/param norm = 1.9092e-01, time/batch = 0.2487s	
2673/2700 (epoch 49.500), train_loss = 0.56481837, grad/param norm = 2.1368e-01, time/batch = 0.2488s	
2674/2700 (epoch 49.519), train_loss = 0.59359279, grad/param norm = 1.8478e-01, time/batch = 0.2301s	
2675/2700 (epoch 49.537), train_loss = 0.58014441, grad/param norm = 1.8455e-01, time/batch = 0.2249s	
2676/2700 (epoch 49.556), train_loss = 0.53840789, grad/param norm = 1.9370e-01, time/batch = 0.2211s	
2677/2700 (epoch 49.574), train_loss = 0.54072075, grad/param norm = 2.0058e-01, time/batch = 0.2175s	
2678/2700 (epoch 49.593), train_loss = 0.58666416, grad/param norm = 1.8866e-01, time/batch = 0.2355s	
2679/2700 (epoch 49.611), train_loss = 0.53748044, grad/param norm = 1.8126e-01, time/batch = 0.2461s	
2680/2700 (epoch 49.630), train_loss = 0.56898485, grad/param norm = 1.9216e-01, time/batch = 0.2453s	
2681/2700 (epoch 49.648), train_loss = 0.57248020, grad/param norm = 2.0537e-01, time/batch = 0.2292s	
2682/2700 (epoch 49.667), train_loss = 0.55240723, grad/param norm = 1.6627e-01, time/batch = 0.2175s	
2683/2700 (epoch 49.685), train_loss = 0.58270026, grad/param norm = 1.8703e-01, time/batch = 0.2479s	
2684/2700 (epoch 49.704), train_loss = 0.58136779, grad/param norm = 2.1440e-01, time/batch = 0.2321s	
2685/2700 (epoch 49.722), train_loss = 0.55872278, grad/param norm = 1.8544e-01, time/batch = 0.2229s	
2686/2700 (epoch 49.741), train_loss = 0.56931632, grad/param norm = 1.7755e-01, time/batch = 0.2191s	
2687/2700 (epoch 49.759), train_loss = 0.53323988, grad/param norm = 1.7269e-01, time/batch = 0.2202s	
2688/2700 (epoch 49.778), train_loss = 0.59393698, grad/param norm = 2.0301e-01, time/batch = 0.2372s	
2689/2700 (epoch 49.796), train_loss = 0.55003369, grad/param norm = 1.9303e-01, time/batch = 0.2464s	
2690/2700 (epoch 49.815), train_loss = 0.57599408, grad/param norm = 1.9953e-01, time/batch = 0.2463s	
2691/2700 (epoch 49.833), train_loss = 0.58000100, grad/param norm = 2.1511e-01, time/batch = 0.2331s	
2692/2700 (epoch 49.852), train_loss = 0.54523986, grad/param norm = 1.8161e-01, time/batch = 0.2454s	
2693/2700 (epoch 49.870), train_loss = 0.58754914, grad/param norm = 1.8275e-01, time/batch = 0.2243s	
2694/2700 (epoch 49.889), train_loss = 0.55266355, grad/param norm = 1.6823e-01, time/batch = 0.2464s	
2695/2700 (epoch 49.907), train_loss = 0.58675393, grad/param norm = 1.9028e-01, time/batch = 0.2292s	
2696/2700 (epoch 49.926), train_loss = 0.57076677, grad/param norm = 1.9054e-01, time/batch = 0.2225s	
2697/2700 (epoch 49.944), train_loss = 0.56616925, grad/param norm = 2.0411e-01, time/batch = 0.2188s	
2698/2700 (epoch 49.963), train_loss = 0.57897663, grad/param norm = 2.1898e-01, time/batch = 0.2219s	
2699/2700 (epoch 49.981), train_loss = 0.55266177, grad/param norm = 2.1619e-01, time/batch = 0.2407s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/3...	
2/3...	
3/3...	
saving checkpoint to cv/lm_lstm_epoch50.00_2.2082.t7	
2700/2700 (epoch 50.000), train_loss = 0.57890811, grad/param norm = 2.1019e-01, time/batch = 0.2465s	
